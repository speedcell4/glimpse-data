{
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_Unmixing_Diffusion_for_Self-Supervised_Hyperspectral_Image_Denoising_CVPR_2024_paper.html": {
    "title": "Unmixing Diffusion for Self-Supervised Hyperspectral Image Denoising",
    "volume": "main",
    "abstract": "Hyperspectral images (HSIs) have extensive applications in various fields such as medicine agriculture and industry. Nevertheless acquiring high signal-to-noise ratio HSI poses a challenge due to narrow-band spectral filtering. Consequently the importance of HSI denoising is substantial especially for snapshot hyperspectral imaging technology. While most previous HSI denoising methods are supervised creating supervised training datasets for the diverse scenes hyperspectral cameras and scan parameters is impractical. In this work we present Diff-Unmix a self-supervised denoising method for HSI using diffusion denoising generative models. Specifically Diff-Unmix addresses the challenge of recovering noise-degraded HSI through a fusion of Spectral Unmixing and conditional abundance generation. Firstly it employs a learnable block-based spectral unmixing strategy complemented by a pure transformer-based backbone. Then we introduce a self-supervised generative diffusion network to enhance abundance maps from the spectral unmixing block. This network reconstructs noise-free Unmixing probability distributions effectively mitigating noise-induced degradations within these components. Finally the reconstructed HSI is reconstructed through unmixing reconstruction by blending the diffusion-adjusted abundance map with the spectral endmembers. Experimental results on both simulated and real-world noisy datasets show that Diff-Unmix achieves state-of-the-art performance",
    "checked": false,
    "id": "2e76f9e4ae025c93ca9c5439d2d15960f0c97fb0",
    "semantic_title": "dds2m: self-supervised denoising diffusion spatio-spectral model for hyperspectral image restoration",
    "citation_count": 14,
    "authors": [
      "Haijin Zeng",
      "Jiezhang Cao",
      "Kai Zhang",
      "Yongyong Chen",
      "Hiep Luong",
      "Wilfried Philips"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Alzayer_Seeing_the_World_through_Your_Eyes_CVPR_2024_paper.html": {
    "title": "Seeing the World through Your Eyes",
    "volume": "main",
    "abstract": "The reflective nature of the human eye is an under-appreciated source of information about what the world around us looks like. By imaging the eyes of a moving person we capture multiple views of a scene outside the camera's direct line of sight through the reflections in the eyes. In this paper we reconstruct a radiance field beyond the camera's line of sight using portrait images containing eye reflections. This task is challenging due to 1) the difficulty of accurately estimating eye poses and 2) the entangled appearance of the iris textures and the scene reflections. To address these our method jointly optimizes the cornea poses the radiance field depicting the scene and the observer's eye iris texture. We further present a regularization prior on the iris texture to improve scene reconstruction quality. Through various experiments on synthetic and real-world captures featuring people with varied eye colors and lighting conditions we demonstrate the feasibility of our approach to recover the radiance field using cornea reflections",
    "checked": true,
    "id": "4a979d69d363c524fb1dac8a7e214e0755fa44f3",
    "semantic_title": "seeing the world through your eyes",
    "citation_count": 12,
    "authors": [
      "Hadi Alzayer",
      "Kevin Zhang",
      "Brandon Feng",
      "Christopher A. Metzler",
      "Jia-Bin Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_DPMesh_Exploiting_Diffusion_Prior_for_Occluded_Human_Mesh_Recovery_CVPR_2024_paper.html": {
    "title": "DPMesh: Exploiting Diffusion Prior for Occluded Human Mesh Recovery",
    "volume": "main",
    "abstract": "The recovery of occluded human meshes poses challenges for current methods due to the difficulty in extracting effective image features under severe occlusion. In this paper we introduce DPMesh an innovative framework for occluded human mesh recovery that capitalizes on the profound knowledge about object structure and spatial relationships embedded in a pre-trained text-to-image diffusion model. Unlike previous methods reliant on conventional backbones for vanilla feature extraction DPMesh seamlessly integrates the pre-trained denoising U-Net with potent priors as its image backbone and performs a single-step inference to provide occlusion-aware information. To enhance the perception capability for occluded poses DPMesh incorporates judicious guidance via condition injection which produces effective controls from 2D observations for the denoising U-Net. Furthermore we explore a dedicated noisy key-point reasoning approach to mitigate disturbances arising from occlusion and crowded scenarios. This strategy fully unleashes the perceptual capability of the diffusion prior thereby enhancing accuracy. Extensive quantitative and qualitative experiments affirm the efficacy of our framework as we outperform state-of-the-art methods on both occlusion-specific and standard datasets underscoring its ability to achieve precise and robust 3D human mesh recovery particularly in challenging scenarios involving occlusion and crowded scenes. Code is available at https://github.com/EternalEvan/DPMesh",
    "checked": true,
    "id": "edf1056827c7fdbf3b6b203910f18e6562de210f",
    "semantic_title": "dpmesh: exploiting diffusion prior for occluded human mesh recovery",
    "citation_count": 0,
    "authors": [
      "Yixuan Zhu",
      "Ao Li",
      "Yansong Tang",
      "Wenliang Zhao",
      "Jie Zhou",
      "Jiwen Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Ungeneralizable_Examples_CVPR_2024_paper.html": {
    "title": "Ungeneralizable Examples",
    "volume": "main",
    "abstract": "The training of contemporary deep learning models heavily relies on publicly available data posing a risk of unauthorized access to online data and raising concerns about data privacy. Current approaches to creating unlearnable data involve incorporating small specially designed noises but these methods strictly limit data usability overlooking its potential usage in authorized scenarios. In this paper we extend the concept of unlearnable data to conditional data learnability and introduce UnGeneralizable Examples (UGEs). UGEs exhibit learnability for authorized users while maintaining unlearnability for potential hackers. The protector defines the authorized network and optimizes UGEs to match the gradients of the original data and its ungeneralizable version ensuring learnability. To prevent unauthorized learning UGEs are trained by maximizing a designated distance loss in a common feature space. Additionally to further safeguard the authorized side from potential attacks we introduce additional undistillation optimization. Experimental results on multiple datasets and various networks demonstrate that the proposed UGEs framework preserves data usability while reducing training performance on hacker networks even under different types of attacks",
    "checked": true,
    "id": "4b6dbdedb0fd7c62ed04c78ed99c86af4dd7b096",
    "semantic_title": "ungeneralizable examples",
    "citation_count": 1,
    "authors": [
      "Jingwen Ye",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pittner_LaneCPP_Continuous_3D_Lane_Detection_using_Physical_Priors_CVPR_2024_paper.html": {
    "title": "LaneCPP: Continuous 3D Lane Detection using Physical Priors",
    "volume": "main",
    "abstract": "Monocular 3D lane detection has become a fundamental problem in the context of autonomous driving which comprises the tasks of finding the road surface and locating lane markings. One major challenge lies in a flexible but robust line representation capable of modeling complex lane structures while still avoiding unpredictable behavior. While previous methods rely on fully data-driven approaches we instead introduce a novel approach LaneCPP that uses a continuous 3D lane detection model leveraging physical prior knowledge about the lane structure and road geometry. While our sophisticated lane model is capable of modeling complex road structures it also shows robust behavior since physical constraints are incorporated by means of a regularization scheme that can be analytically applied to our parametric representation. Moreover we incorporate prior knowledge about the road geometry into the 3D feature space by modeling geometry-aware spatial features guiding the network to learn an internal road surface representation. In our experiments we show the benefits of our contributions and prove the meaningfulness of using priors to make 3D lane detection more robust. The results show that LaneCPP achieves state-of-the-art performance in terms of F-Score and geometric errors",
    "checked": true,
    "id": "863eaadf3153d924ccb6fbe78763ac81b43c4b5d",
    "semantic_title": "lanecpp: continuous 3d lane detection using physical priors",
    "citation_count": 0,
    "authors": [
      "Maximilian Pittner",
      "Joel Janai",
      "Alexandru P. Condurache"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_CityDreamer_Compositional_Generative_Model_of_Unbounded_3D_Cities_CVPR_2024_paper.html": {
    "title": "CityDreamer: Compositional Generative Model of Unbounded 3D Cities",
    "volume": "main",
    "abstract": "3D city generation is a desirable yet challenging task since humans are more sensitive to structural distortions in urban environments. Additionally generating 3D cities is more complex than 3D natural scenes since buildings as objects of the same class exhibit a wider range of appearances compared to the relatively consistent appearance of objects like trees in natural scenes. To address these challenges we propose CityDreamer a compositional generative model designed specifically for unbounded 3D cities. Our key insight is that 3D city generation should be a composition of different types of neural fields: 1) various building instances and 2) background stuff such as roads and green lands. Specifically we adopt the bird's eye view scene representation and employ a volumetric render for both instance-oriented and stuff-oriented neural fields. The generative hash grid and periodic positional embedding are tailored as scene parameterization to suit the distinct characteristics of building instances and background stuff. Furthermore we contribute a suite of CityGen Datasets including OSM and GoogleEarth which comprises a vast amount of real-world city imagery to enhance the realism of the generated 3D cities both in their layouts and appearances. CityDreamer achieves state-of-the-art performance not only in generating realistic 3D cities but also in localized editing within the generated cities",
    "checked": true,
    "id": "ddc64a5ce980b7b97e9bcad122682f289ac854ae",
    "semantic_title": "citydreamer: compositional generative model of unbounded 3d cities",
    "citation_count": 13,
    "authors": [
      "Haozhe Xie",
      "Zhaoxi Chen",
      "Fangzhou Hong",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Carlsson_HEAL-SWIN_A_Vision_Transformer_On_The_Sphere_CVPR_2024_paper.html": {
    "title": "HEAL-SWIN: A Vision Transformer On The Sphere",
    "volume": "main",
    "abstract": "High-resolution wide-angle fisheye images are becoming more and more important for robotics applications such as autonomous driving. However using ordinary convolutional neural networks or vision transformers on this data is problematic due to projection and distortion losses introduced when projecting to a rectangular grid on the plane. We introduce the HEAL-SWIN transformer which combines the highly uniform Hierarchical Equal Area iso-Latitude Pixelation (HEALPix) grid used in astrophysics and cosmology with the Hierarchical Shifted-Window (SWIN) transformer to yield an efficient and flexible model capable of training on high-resolution distortion-free spherical data. In HEAL-SWIN the nested structure of the HEALPix grid is used to perform the patching and windowing operations of the SWIN transformer enabling the network to process spherical representations with minimal computational overhead. We demonstrate the superior performance of our model on both synthetic and real automotive datasets as well as a selection of other image datasets for semantic segmentation depth regression and classification tasks. Our code is publicly available",
    "checked": true,
    "id": "fdc638fecb5a92ed11fda753b8748dee046c2858",
    "semantic_title": "heal-swin: a vision transformer on the sphere",
    "citation_count": 1,
    "authors": [
      "Oscar Carlsson",
      "Jan E. Gerken",
      "Hampus Linander",
      "Heiner Spieß",
      "Fredrik Ohlsson",
      "Christoffer Petersson",
      "Daniel Persson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Decatur_3D_Paintbrush_Local_Stylization_of_3D_Shapes_with_Cascaded_Score_CVPR_2024_paper.html": {
    "title": "3D Paintbrush: Local Stylization of 3D Shapes with Cascaded Score Distillation",
    "volume": "main",
    "abstract": "We present 3D Paintbrush a technique for automatically texturing local semantic regions on meshes via text descriptions. Our method is designed to operate directly on meshes producing texture maps which seamlessly integrate into standard graphics pipelines. We opt to simultaneously produce a localization map (to specify the edit region) and a texture map which conforms to it. This approach improves the quality of both the localization and the stylization. To enhance the details and resolution of the textured area we leverage multiple stages of a cascaded diffusion model to supervise our local editing technique with generative priors learned from images at different resolutions. Our technique referred to as Cascaded Score Distillation (CSD) simultaneously distills scores at multiple resolutions in a cascaded fashion enabling control over both the granularity and global understanding of the supervision. We demonstrate the effectiveness of 3D Paintbrush to locally texture different semantic regions on a variety of shapes",
    "checked": true,
    "id": "496bdd2804a231a3336463fca8e0a4c6a46f0304",
    "semantic_title": "3d paintbrush: local stylization of 3d shapes with cascaded score distillation",
    "citation_count": 6,
    "authors": [
      "Dale Decatur",
      "Itai Lang",
      "Kfir Aberman",
      "Rana Hanocka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Test-Time_Linear_Out-of-Distribution_Detection_CVPR_2024_paper.html": {
    "title": "Test-Time Linear Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "Out-of-Distribution (OOD) detection aims to address the excessive confidence prediction by neural networks by triggering an alert when the input sample deviates significantly from the training distribution (in-distribution) indicating that the output may not be reliable. Current OOD detection approaches explore all kinds of cues to identify OOD data such as finding irregular patterns in the feature space logit space gradient space or the raw image space. Surprisingly we observe a linear trend between the OOD score produced by current OOD detection algorithms and the network features on several datasets. We conduct a thorough investigation theoretically and empirically to analyze and understand the meaning of such a linear trend in OOD detection. This paper proposes a Robust Test-time Linear method (RTL) to utilize such linear trends like a `free lunch' when we have a batch of data to perform OOD detection. By using a simple linear regression as a test time adaptation we can make a more precise OOD prediction. We further propose an online variant of the proposed method which achieves promising performance and is more practical for real applications. Theoretical analysis is given to prove the effectiveness of our methods. Extensive experiments on several OOD datasets show the efficacy of RTL for OOD detection tasks significantly improving the results of base OOD detectors. Project will be available at https://github.com/kfan21/RTL",
    "checked": false,
    "id": "346e3d1871d17ce2b64a8f691e93c7792b96974c",
    "semantic_title": "a simple test-time method for out-of-distribution detection",
    "citation_count": 5,
    "authors": [
      "Ke Fan",
      "Tong Liu",
      "Xingyu Qiu",
      "Yikai Wang",
      "Lian Huai",
      "Zeyu Shangguan",
      "Shuang Gou",
      "Fengjian Liu",
      "Yuqian Fu",
      "Yanwei Fu",
      "Xingqun Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Guided_Slot_Attention_for_Unsupervised_Video_Object_Segmentation_CVPR_2024_paper.html": {
    "title": "Guided Slot Attention for Unsupervised Video Object Segmentation",
    "volume": "main",
    "abstract": "Unsupervised video object segmentation aims to segment the most prominent object in a video sequence. However the existence of complex backgrounds and multiple foreground objects make this task challenging. To address this issue we propose a guided slot attention network to reinforce spatial structural information and obtain better foreground-background separation. The foreground and background slots which are initialized with query guidance are iteratively refined based on interactions with template information. Furthermore to improve slot-template interaction and effectively fuse global and local features in the target and reference frames K-nearest neighbors filtering and a feature aggregation transformer are introduced. The proposed model achieves state-of-the-art performance on two popular datasets. Additionally we demonstrate the robustness of the proposed model in challenging scenes through various comparative experiments",
    "checked": true,
    "id": "f37057c3208645a49783e165a6dd4130419363f0",
    "semantic_title": "guided slot attention for unsupervised video object segmentation",
    "citation_count": 0,
    "authors": [
      "Minhyeok Lee",
      "Suhwan Cho",
      "Dogyoon Lee",
      "Chaewon Park",
      "Jungho Lee",
      "Sangyoun Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Unsupervised_Blind_Image_Deblurring_Based_on_Self-Enhancement_CVPR_2024_paper.html": {
    "title": "Unsupervised Blind Image Deblurring Based on Self-Enhancement",
    "volume": "main",
    "abstract": "Significant progress in image deblurring has been achieved by deep learning methods especially the remarkable performance of supervised models on paired synthetic data. However real-world quality degradation is more complex than synthetic datasets and acquiring paired data in real-world scenarios poses significant challenges. To address these challenges we propose a novel unsupervised image deblurring framework based on self-enhancement. The framework progressively generates improved pseudo-sharp and blurry image pairs without the need for real paired datasets and the generated image pairs with higher qualities can be used to enhance the performance of the reconstructor. To ensure the generated blurry images are closer to the real blurry images we propose a novel re-degradation principal component consistency loss which enforces the principal components of the generated low-quality images to be similar to those of re-degraded images from the original sharp ones. Furthermore we introduce the self-enhancement strategy that significantly improves deblurring performance without increasing the computational complexity of network during inference. Through extensive experiments on multiple real-world blurry datasets we demonstrate the superiority of our approach over other state-of-the-art unsupervised methods",
    "checked": false,
    "id": "8be907e7b08217d46c1b394e52148f542f691c77",
    "semantic_title": "microdeblur: image motion deblurring on microcontroller-based vision systems",
    "citation_count": 2,
    "authors": [
      "Lufei Chen",
      "Xiangpeng Tian",
      "Shuhua Xiong",
      "Yinjie Lei",
      "Chao Ren"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Foo_Action_Detection_via_an_Image_Diffusion_Process_CVPR_2024_paper.html": {
    "title": "Action Detection via an Image Diffusion Process",
    "volume": "main",
    "abstract": "Action detection aims to localize the starting and ending points of action instances in untrimmed videos and predict the classes of those instances. In this paper we make the observation that the outputs of the action detection task can be formulated as images. Thus from a novel perspective we tackle action detection via a three-image generation process to generate starting point ending point and action-class predictions as images via our proposed Action Detection Image Diffusion (ADI-Diff) framework. Furthermore since our images differ from natural images and exhibit special properties we further explore a Discrete Action-Detection Diffusion Process and a Row-Column Transformer design to better handle their processing. Our ADI-Diff framework achieves state-of-the-art results on two widely-used datasets",
    "checked": true,
    "id": "4742206bab324f1c386bc61d550b77c87a9ee222",
    "semantic_title": "action detection via an image diffusion process",
    "citation_count": 0,
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Programmable_Motion_Generation_for_Open-Set_Motion_Control_Tasks_CVPR_2024_paper.html": {
    "title": "Programmable Motion Generation for Open-Set Motion Control Tasks",
    "volume": "main",
    "abstract": "Character animation in real-world scenarios necessitates a variety of constraints such as trajectories key-frames interactions etc. Existing methodologies typically treat single or a finite set of these constraint(s) as separate control tasks. These methods are often specialized and the tasks they address are rarely extendable or customizable. We categorize these as solutions to the close-set motion control problem. In response to the complexity of practical motion control we propose and attempt to solve the open-set motion control problem. This problem is characterized by an open and fully customizable set of motion control tasks. To address this we introduce a new paradigm programmable motion generation. In this paradigm any given motion control task is broken down into a combination of atomic constraints. These constraints are then programmed into an error function that quantifies the degree to which a motion sequence adheres to them. We utilize a pre-trained motion generation model and optimize its latent code to minimize the error function of the generated motion. Consequently the generated motion not only inherits the prior of the generative model but also satisfies the requirements of the compounded constraints. Our experiments demonstrate that our approach can generate high-quality motions when addressing a wide range of unseen tasks. These tasks encompass motion control by motion dynamics geometric constraints physical laws interactions with scenes objects or the character's own body parts etc. All of these are achieved in a unified approach without the need for ad-hoc paired training data collection or specialized network designs. During the programming of novel tasks we observed the emergence of new skills beyond those of the prior model. With the assistance of large language models we also achieved automatic programming. We hope that this work will pave the way for the motion control of general AI agents",
    "checked": true,
    "id": "e0abc8584aaf22b3bd4016d441ebc8a4c05238ca",
    "semantic_title": "programmable motion generation for open-set motion control tasks",
    "citation_count": 0,
    "authors": [
      "Hanchao Liu",
      "Xiaohang Zhan",
      "Shaoli Huang",
      "Tai-Jiang Mu",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_SCE-MAE_Selective_Correspondence_Enhancement_with_Masked_Autoencoder_for_Self-Supervised_Landmark_CVPR_2024_paper.html": {
    "title": "SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder for Self-Supervised Landmark Estimation",
    "volume": "main",
    "abstract": "Self-supervised landmark estimation is a challenging task that demands the formation of locally distinct feature representations to identify sparse facial landmarks in the absence of annotated data. To tackle this task existing state-of-the-art (SOTA) methods (1) extract coarse features from backbones that are trained with instance-level self-supervised learning (SSL) paradigms which neglect the dense prediction nature of the task (2) aggregate them into memory-intensive hypercolumn formations and (3) supervise lightweight projector networks to naively establish full local correspondences among all pairs of spatial features. In this paper we introduce SCE-MAE a framework that (1) leverages the MAE [??] a region-level SSL method that naturally better suits the landmark prediction task (2) operates on the vanilla feature map instead of on expensive hypercolumns and (3) employs a Correspondence Approximation and Refinement Block (CARB) that utilizes a simple density peak clustering algorithm and our proposed Locality-Constrained Repellence Loss to directly hone only select local correspondences. We demonstrate through extensive experiments that SCE-MAE is highly effective and robust outperforming existing SOTA methods by large margins of 20%-44% on the landmark matching and 9%-15% on the landmark detection tasks",
    "checked": true,
    "id": "e4208e726cbe2de148967017864e44f1044be29d",
    "semantic_title": "sce-mae: selective correspondence enhancement with masked autoencoder for self-supervised landmark estimation",
    "citation_count": 0,
    "authors": [
      "Kejia Yin",
      "Varshanth Rao",
      "Ruowei Jiang",
      "Xudong Liu",
      "Parham Aarabi",
      "David B. Lindell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_LAKE-RED_Camouflaged_Images_Generation_by_Latent_Background_Knowledge_Retrieval-Augmented_Diffusion_CVPR_2024_paper.html": {
    "title": "LAKE-RED: Camouflaged Images Generation by Latent Background Knowledge Retrieval-Augmented Diffusion",
    "volume": "main",
    "abstract": "Camouflaged vision perception is an important vision task with numerous practical applications. Due to the expensive collection and labeling costs this community struggles with a major bottleneck that the species category of its datasets is limited to a small number of object species. However the existing camouflaged generation methods require specifying the background manually thus failing to extend the camouflaged sample diversity in a low-cost manner. In this paper we propose a Latent Background Knowledge Retrieval-Augmented Diffusion (LAKE-RED) for camouflaged image generation. To our knowledge our contributions mainly include: (1) For the first time we propose a camouflaged generation paradigm that does not need to receive any background inputs. (2) Our LAKE-RED is the first knowledge retrieval-augmented method with interpretability for camouflaged generation in which we propose an idea that knowledge retrieval and reasoning enhancement are separated explicitly to alleviate the task-specific challenges. Moreover our method is not restricted to specific foreground targets or backgrounds offering a potential for extending camouflaged vision perception to more diverse domains. (3) Experimental results demonstrate that our method outperforms the existing approaches generating more realistic camouflage images",
    "checked": true,
    "id": "59bf9d56d57386aac83926da4b4c22a3ae6d1804",
    "semantic_title": "lake-red: camouflaged images generation by latent background knowledge retrieval-augmented diffusion",
    "citation_count": 1,
    "authors": [
      "Pancheng Zhao",
      "Peng Xu",
      "Pengda Qin",
      "Deng-Ping Fan",
      "Zhicheng Zhang",
      "Guoli Jia",
      "Bowen Zhou",
      "Jufeng Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_TIGER_Time-Varying_Denoising_Model_for_3D_Point_Cloud_Generation_with_CVPR_2024_paper.html": {
    "title": "TIGER: Time-Varying Denoising Model for 3D Point Cloud Generation with Diffusion Process",
    "volume": "main",
    "abstract": "Recently diffusion models have emerged as a new powerful generative method for 3D point cloud generation tasks. However few works study the effect of the architecture of the diffusion model in the 3D point cloud resorting to the typical UNet model developed for 2D images. Inspired by the wide adoption of Transformers we study the complementary role of convolution (from UNet) and attention (from Transformers). We discover that their respective importance change according to the timestep in the diffusion process. At early stage attention has an outsized influence because Transformers are found to generate the overall shape more quickly and at later stages when adding fine detail convolution starts having a larger impact on the generated point cloud's local surface quality. In light of this observation we propose a time-varying two-stream denoising model combined with convolution layers and transformer blocks. We generate an optimizable mask from each timestep to reweigh global and local features obtaining time-varying fused features. Experimentally we demonstrate that our proposed method quantitatively outperforms other state-of-the-art methods regarding visual quality and diversity. Code is avaiable github.com/Zhiyuan-R/Tiger-Time-varying-Diffusion-Model-for-Point-Cloud-Generation",
    "checked": true,
    "id": "543a8c4b01b902352fdd342c9ec8cd2e8a5ea589",
    "semantic_title": "tiger: time-varying denoising model for 3d point cloud generation with diffusion process",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Ren",
      "Minchul Kim",
      "Feng Liu",
      "Xiaoming Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_ConTex-Human_Free-View_Rendering_of_Human_from_a_Single_Image_with_CVPR_2024_paper.html": {
    "title": "ConTex-Human: Free-View Rendering of Human from a Single Image with Texture-Consistent Synthesis",
    "volume": "main",
    "abstract": "In this work we propose a method to address the challenge of rendering a 3D human from a single image in a free-view manner. Some existing approaches could achieve this by using generalizable pixel-aligned implicit fields to reconstruct a textured mesh of a human or by employing a 2D diffusion model as guidance with the Score Distillation Sampling (SDS) method to lift the 2D image into 3D space. However a generalizable implicit field often results in an over-smooth texture field while the SDS method tends to lead to a texture-inconsistent novel view with the input image. In this paper we introduce a texture-consistent back view synthesis method that could transfer the reference image content to the back view through depth-guided mutual self-attention. With this method we could achieve high-fidelity and texture-consistent human rendering from a single image. Moreover to alleviate the color distortion that occurs in the side region we propose a visibility-aware patch consistency regularization combined with the synthesized back view texture. Experiments conducted on both real and synthetic data demonstrate the effectiveness of our method and show that our approach outperforms previous baseline methods",
    "checked": true,
    "id": "e076b22b24ec5e2f11625fe5a9b3e577581e7d82",
    "semantic_title": "contex-human: free-view rendering of human from a single image with texture-consistent synthesis",
    "citation_count": 2,
    "authors": [
      "Xiangjun Gao",
      "Xiaoyu Li",
      "Chaopeng Zhang",
      "Qi Zhang",
      "Yanpei Cao",
      "Ying Shan",
      "Long Quan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zuo_UFineBench_Towards_Text-based_Person_Retrieval_with_Ultra-fine_Granularity_CVPR_2024_paper.html": {
    "title": "UFineBench: Towards Text-based Person Retrieval with Ultra-fine Granularity",
    "volume": "main",
    "abstract": "Existing text-based person retrieval datasets often have relatively coarse-grained text annotations. This hinders the model to comprehend the fine-grained semantics of query texts in real scenarios. To address this problem we contribute a new benchmark named UFineBench for text-based person retrieval with ultra-fine granularity. Firstly we construct a new dataset named UFine6926. We collect a large number of person images and manually annotate each image with two detailed textual descriptions averaging 80.8 words each. The average word count is three to four times that of the previous datasets. In addition of standard in-domain evaluation we also propose a special evaluation paradigm more representative of real scenarios. It contains a new evaluation set with cross domains cross textual granularity and cross textual styles named UFine3C and a new evaluation metric for accurately measuring retrieval ability named mean Similarity Distribution (mSD). Moreover we propose CFAM a more efficient algorithm especially designed for text-based person retrieval with ultra fine-grained texts. It achieves fine granularity mining by adopting a shared cross-modal granularity decoder and hard negative match mechanism. With standard in-domain evaluation CFAM establishes competitive performance across various datasets especially on our ultra fine-grained UFine6926. Furthermore by evaluating on UFine3C we demonstrate that training on our UFine6926 significantly improves generalization to real scenarios compared with other coarse-grained datasets. The dataset and code will be made publicly available at https://github.com/Zplusdragon/UFineBench",
    "checked": true,
    "id": "8f51370df2913eb4a83f496d932fd75b03794c90",
    "semantic_title": "ufinebench: towards text-based person retrieval with ultra-fine granularity",
    "citation_count": 2,
    "authors": [
      "Jialong Zuo",
      "Hanyu Zhou",
      "Ying Nie",
      "Feng Zhang",
      "Tianyu Guo",
      "Nong Sang",
      "Yunhe Wang",
      "Changxin Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Efficient_Hyperparameter_Optimization_with_Adaptive_Fidelity_Identification_CVPR_2024_paper.html": {
    "title": "Efficient Hyperparameter Optimization with Adaptive Fidelity Identification",
    "volume": "main",
    "abstract": "Hyperparameter Optimization and Neural Architecture Search are powerful in attaining state-of-the-art machine learning models with Bayesian Optimization (BO) standing out as a mainstream method. Extending BO into the multi-fidelity setting has been an emerging research topic in this field but faces the challenge of determining an appropriate fidelity for each hyperparameter configuration to fit the surrogate model. To tackle the challenge we propose a multi-fidelity BO method named FastBO which excels in adaptively deciding the fidelity for each configuration and providing strong performance while ensuring efficient resource usage. These advantages are achieved through our proposed techniques based on the concepts of efficient point and saturation point for each configuration which can be obtained from the empirical learning curve of the configuration estimated from early observations. Extensive experiments demonstrate FastBO's superior anytime performance and efficiency in identifying high-quality configurations and architectures. We also show that our method provides a way to extend any single-fidelity method to the multi-fidelity setting highlighting the wide applicability of our approach",
    "checked": false,
    "id": "2cfd902e6a19994e953444e14a3460b932c2cc5f",
    "semantic_title": "efficient time-delay system optimization with auto-configured metaheuristics",
    "citation_count": 0,
    "authors": [
      "Jiantong Jiang",
      "Zeyi Wen",
      "Atif Mansoor",
      "Ajmal Mian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pang_ASH_Animatable_Gaussian_Splats_for_Efficient_and_Photoreal_Human_Rendering_CVPR_2024_paper.html": {
    "title": "ASH: Animatable Gaussian Splats for Efficient and Photoreal Human Rendering",
    "volume": "main",
    "abstract": "Real-time rendering of photorealistic and controllable human avatars stands as a cornerstone in Computer Vision and Graphics. While recent advances in neural implicit rendering have unlocked unprecedented photorealism for digital avatars real-time performance has mostly been demonstrated for static scenes only. To address this we propose ASH an animatable Gaussian splatting approach for photorealistic rendering of dynamic humans in real time. We parameterize the clothed human as animatable 3D Gaussians which can be efficiently splatted into image space to generate the final rendering. However naively learning the Gaussian parameters in 3D space poses a severe challenge in terms of compute. Instead we attach the Gaussians onto a deformable character model and learn their parameters in 2D texture space which allows leveraging efficient 2D convolutional architectures that easily scale with the required number of Gaussians. We benchmark ASH with competing methods on pose-controllable avatars demonstrating that our method outperforms existing real-time methods by a large margin and shows comparable or even better results than offline methods",
    "checked": true,
    "id": "5227b0552e2b11016ca0c4809914de642df4c822",
    "semantic_title": "ash: animatable gaussian splats for efficient and photoreal human rendering",
    "citation_count": 17,
    "authors": [
      "Haokai Pang",
      "Heming Zhu",
      "Adam Kortylewski",
      "Christian Theobalt",
      "Marc Habermann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Focus_on_Hiders_Exploring_Hidden_Threats_for_Enhancing_Adversarial_Training_CVPR_2024_paper.html": {
    "title": "Focus on Hiders: Exploring Hidden Threats for Enhancing Adversarial Training",
    "volume": "main",
    "abstract": "Adversarial training is often formulated as a min-max problem however concentrating only on the worst adversarial examples causes alternating repetitive confusion of the model i.e. previously defended or correctly classified samples are not defensible or accurately classifiable in subsequent adversarial training. We characterize such non-ignorable samples as \"hiders\" which reveal the hidden high-risk regions within the secure area obtained through adversarial training and prevent the model from finding the real worst cases. We demand the model to prevent hiders when defending against adversarial examples for improving accuracy and robustness simultaneously. By rethinking and redefining the min-max optimization problem for adversarial training we propose a generalized adversarial training algorithm called Hider-Focused Adversarial Training (HFAT). HFAT introduces the iterative evolution optimization strategy to simplify the optimization problem and employs an auxiliary model to reveal hiders effectively combining the optimization directions of standard adversarial training and prevention hiders. Furthermore we introduce an adaptive weighting mechanism that facilitates the model in adaptively adjusting its focus between adversarial examples and hiders during different training periods. We demonstrate the effectiveness of our method based on extensive experiments and ensure that HFAT can provide higher robustness and accuracy. We will release the source code upon publication",
    "checked": true,
    "id": "9d44dae161b4765011c52b322f352e33dfefc6e6",
    "semantic_title": "focus on hiders: exploring hidden threats for enhancing adversarial training",
    "citation_count": 1,
    "authors": [
      "Qian Li",
      "Yuxiao Hu",
      "Yinpeng Dong",
      "Dongxiao Zhang",
      "Yuntian Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_ArtAdapter_Text-to-Image_Style_Transfer_using_Multi-Level_Style_Encoder_and_Explicit_CVPR_2024_paper.html": {
    "title": "ArtAdapter: Text-to-Image Style Transfer using Multi-Level Style Encoder and Explicit Adaptation",
    "volume": "main",
    "abstract": "This work introduces ArtAdapter a transformative text-to-image (T2I) style transfer framework that transcends traditional limitations of color brushstrokes and object shape capturing high-level style elements such as composition and distinctive artistic expression. The integration of a multi-level style encoder with our proposed explicit adaptation mechanism enables ArtAdapter to achieve unprecedented fidelity in style transfer ensuring close alignment with textual descriptions. Additionally the incorporation of an Auxiliary Content Adapter (ACA) effectively separates content from style alleviating the borrowing of content from style references. Moreover our novel fast finetuning approach could further enhance zero-shot style representation while mitigating the risk of overfitting. Comprehensive evaluations confirm that ArtAdapter surpasses current state-of-the-art methods",
    "checked": true,
    "id": "22d45b7b4cd23162dd38c9b577749d86db34075b",
    "semantic_title": "artadapter: text-to-image style transfer using multi-level style encoder and explicit adaptation",
    "citation_count": 2,
    "authors": [
      "Dar-Yen Chen",
      "Hamish Tennent",
      "Ching-Wen Hsu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_GoodSAM_Bridging_Domain_and_Capacity_Gaps_via_Segment_Anything_Model_CVPR_2024_paper.html": {
    "title": "GoodSAM: Bridging Domain and Capacity Gaps via Segment Anything Model for Distortion-aware Panoramic Semantic Segmentation",
    "volume": "main",
    "abstract": "This paper tackles a novel yet challenging problem: how to transfer knowledge from the emerging Segment Anything Model (SAM) -- which reveals impressive zero-shot instance segmentation capacity -- to learn a compact panoramic semantic segmentation model i.e. student without requiring any labeled data. This poses considerable challenges due to SAM's inability to provide semantic labels and the large capacity gap between SAM and the student. To this end we propose a novel framework called GoodSAM that introduces a teacher assistant (TA) to provide semantic information integrated with SAM to generate ensemble logits to achieve knowledge transfer. Specifically we propose a Distortion-Aware Rectification (DAR) module that first addresses the distortion problem of panoramic images by imposing prediction-level consistency and boundary enhancement. This subtly enhances TA's prediction capacity on panoramic images. DAR then incorporates a cross-task complementary fusion block to adaptively merge the predictions of SAM and TA to obtain more reliable ensemble logits. Moreover we introduce a Multi-level Knowledge Adaptation (MKA) module to efficiently transfer the multi-level feature knowledge from TA and ensemble logits to learn a compact student model. Extensive experiments on two benchmarks show that our GoodSAM achieves a remarkable +3.75% mIoU improvement over the state-of-the-art (SOTA) domain adaptation methods e.g. [41]. Also our most lightweight model achieves comparable performance to the SOTA methods with only 3.7M parameters",
    "checked": true,
    "id": "accb16b4983501d1ff0df2ba84c634f2c8741b52",
    "semantic_title": "goodsam: bridging domain and capacity gaps via segment anything model for distortion-aware panoramic semantic segmentation",
    "citation_count": 2,
    "authors": [
      "Weiming Zhang",
      "Yexin Liu",
      "Xu Zheng",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_DYSON_Dynamic_Feature_Space_Self-Organization_for_Online_Task-Free_Class_Incremental_CVPR_2024_paper.html": {
    "title": "DYSON: Dynamic Feature Space Self-Organization for Online Task-Free Class Incremental Learning",
    "volume": "main",
    "abstract": "In this paper we focus on a challenging Online Task-Free Class Incremental Learning (OTFCIL) problem. Different from the existing methods that continuously learn the feature space from data streams we propose a novel compute-and-align paradigm for the OTFCIL. It first computes an optimal geometry i.e. the class prototype distribution for classifying existing classes and updates it when new classes emerge and then trains a DNN model by aligning its feature space to the optimal geometry. To this end we develop a novel Dynamic Neural Collapse (DNC) algorithm to compute and update the optimal geometry. The DNC expands the geometry when new classes emerge without loss of the geometry optimality and guarantees the drift distance of old class prototypes with an explicit upper bound. Then we propose a novel Dynamic feature space Self-Organization (DYSON) method containing three major components including 1) a feature extractor 2) a Dynamic Feature-Geometry Alignment (DFGA) module aligning the feature space to the optimal geometry computed by DNC and 3) a training-free class-incremental classifier derived from the DNC geometry. Experimental comparison results on four benchmark datasets including CIFAR10 CIFAR100 CUB200 and CoRe50 demonstrate the efficiency and superiority of the DYSON method. The source code is provided in the supplementary material",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang He",
      "Yingjie Chen",
      "Yuhan Jin",
      "Songlin Dong",
      "Xing Wei",
      "Yihong Gong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Streaming_Dense_Video_Captioning_CVPR_2024_paper.html": {
    "title": "Streaming Dense Video Captioning",
    "volume": "main",
    "abstract": "An ideal model for dense video captioning -- predicting captions localized temporally in a video -- should be able to handle long input videos predict rich detailed textual descriptions and be able to produce outputs before processing the entire video. Current state-of-the-art models however process a fixed number of downsampled frames and make a single full prediction after seeing the whole video. We propose a streaming dense video captioning model that consists of two novel components: First we propose a new memory module based on clustering incoming tokens which can handle arbitrarily long videos as the memory is of a fixed size. Second we develop a streaming decoding algorithm that enables our model to make predictions before the entire video has been processed. Our model achieves this streaming ability and significantly improves the state-of-the-art on three dense video captioning benchmarks: ActivityNet YouCook2 and ViTT. Our code is released at https://github.com/google-research/scenic",
    "checked": true,
    "id": "e5cdc8f4271376de7dc39a5f65de039f0250f02f",
    "semantic_title": "streaming dense video captioning",
    "citation_count": 2,
    "authors": [
      "Xingyi Zhou",
      "Anurag Arnab",
      "Shyamal Buch",
      "Shen Yan",
      "Austin Myers",
      "Xuehan Xiong",
      "Arsha Nagrani",
      "Cordelia Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bae_Rethinking_Inductive_Biases_for_Surface_Normal_Estimation_CVPR_2024_paper.html": {
    "title": "Rethinking Inductive Biases for Surface Normal Estimation",
    "volume": "main",
    "abstract": "Despite the growing demand for accurate surface normal estimation models existing methods use general-purpose dense prediction models adopting the same inductive biases as other tasks. In this paper we discuss the inductive biases needed for surface normal estimation and propose to (1) utilize the per-pixel ray direction and (2) encode the relationship between neighboring surface normals by learning their relative rotation. The proposed method can generate crisp - yet piecewise smooth - predictions for challenging in-the-wild images of arbitrary resolution and aspect ratio. Compared to a recent ViT-based state-of-the-art model our method shows a stronger generalization ability despite being trained on an orders of magnitude smaller dataset. The code is available at https://github.com/baegwangbin/DSINE",
    "checked": true,
    "id": "23f1b69e8d21aa6236bae4a8b7087115a3b9bd70",
    "semantic_title": "rethinking inductive biases for surface normal estimation",
    "citation_count": 6,
    "authors": [
      "Gwangbin Bae",
      "Andrew J. Davison"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Elms_Event-based_Structure-from-Orbit_CVPR_2024_paper.html": {
    "title": "Event-based Structure-from-Orbit",
    "volume": "main",
    "abstract": "Event sensors offer high temporal resolution visual sensing which makes them ideal for perceiving fast visual phenomena without suffering from motion blur. Certain applications in robotics and vision-based navigation require 3D perception of an object undergoing circular or spinning motion in front of a static camera such as recovering the angular velocity and shape of the object. The setting is equivalent to observing a static object with an orbiting camera. In this paper we propose event-based structure-from-orbit (eSfO) where the aim is to simultaneously reconstruct the 3D structure of a fast spinning object observed from a static event camera and recover the equivalent orbital motion of the camera. Our contributions are threefold: since state-of-the-art event feature trackers cannot handle periodic self-occlusion due to the spinning motion we develop a novel event feature tracker based on spatio-temporal clustering and data association that can better track the helical trajectories of valid features in the event data. The feature tracks are then fed to our novel factor graph-based structure-from-orbit back-end that calculates the orbital motion parameters (e.g. spin rate relative rotational axis) that minimize the reprojection error. For evaluation we produce a new event dataset of objects under spinning motion. Comparisons against ground truth indicate the efficacy of eSfO",
    "checked": true,
    "id": "320c9d4abcc74f9800418641691adce94f97f227",
    "semantic_title": "event-based structure-from-orbit",
    "citation_count": 0,
    "authors": [
      "Ethan Elms",
      "Yasir Latif",
      "Tae Ha Park",
      "Tat-Jun Chin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Duan_LED_A_Large-scale_Real-world_Paired_Dataset_for_Event_Camera_Denoising_CVPR_2024_paper.html": {
    "title": "LED: A Large-scale Real-world Paired Dataset for Event Camera Denoising",
    "volume": "main",
    "abstract": "Event camera has significant advantages in capturingdynamic scene information while being prone to noise interferenceparticularly in challenging conditions like lowthreshold and low illumination. However most existing researchfocuses on gentle situations hindering event cameraapplications in realistic complex scenarios. To tackle thislimitation and advance the field we construct a new pairedreal-world event denoising dataset (LED) including 3K sequenceswith 18K seconds of high-resolution (1200*680)event streams and showing three notable distinctions comparedto others: diverse noise levels and scenes largerscalewith high-resolution and high-quality GT. Specificallyit contains stepped parameters and varying illuminationwith diverse scenarios. Moreover based on theproperty of noise events inconsistency and signal eventsconsistency we propose a novel effective denoising framework(DED) using homogeneous dual events to generate theGT with better separating noise from the raw. Furthermorewe design a bio-inspired baseline leveraging Leaky-Integrate-and-Fire (LIF) neurons with dynamic thresholdsto realize accurate denoising. The experimental resultsdemonstrate that the remarkable performance of the proposedapproach on different datasets.The dataset and codeare at https://github.com/Yee-Sing/led",
    "checked": true,
    "id": "0b09ce54baace186a32aca6e303cc8cc7a60d6ad",
    "semantic_title": "led: a large-scale real-world paired dataset for event camera denoising",
    "citation_count": 0,
    "authors": [
      "Yuxing Duan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Fair_Federated_Learning_under_Domain_Skew_with_Local_Consistency_and_CVPR_2024_paper.html": {
    "title": "Fair Federated Learning under Domain Skew with Local Consistency and Domain Diversity",
    "volume": "main",
    "abstract": "Federated learning (FL) has emerged as a new paradigm for privacy-preserving collaborative training. Under domain skew the current FL approaches are biased and face two fairness problems. 1) Parameter Update Conflict: data disparity among clients leads to varying parameter importance and inconsistent update directions. These two disparities cause important parameters to potentially be overwhelmed by unimportant ones of dominant updates. It consequently results in significant performance decreases for lower-performing clients. 2) Model Aggregation Bias: existing FL approaches introduce unfair weight allocation and neglect domain diversity. It leads to biased model convergence objective and distinct performance among domains. We discover a pronounced directional update consistency in Federated Learning and propose a novel framework to tackle above issues. First leveraging the discovered characteristic we selectively discard unimportant parameter updates to prevent updates from clients with lower performance overwhelmed by unimportant parameters resulting in fairer generalization performance. Second we propose a fair aggregation objective to prevent global model bias towards some domains ensuring that the global model continuously aligns with an unbiased model. The proposed method is generic and can be combined with other existing FL methods to enhance fairness. Comprehensive experiments on Digits and Office-Caltech demonstrate the high fairness and performance of our method",
    "checked": true,
    "id": "d83af51009fd529b7439f86e7ba4b17935496516",
    "semantic_title": "fair federated learning under domain skew with local consistency and domain diversity",
    "citation_count": 1,
    "authors": [
      "Yuhang Chen",
      "Wenke Huang",
      "Mang Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Azad_Activity-Biometrics_Person_Identification_from_Daily_Activities_CVPR_2024_paper.html": {
    "title": "Activity-Biometrics: Person Identification from Daily Activities",
    "volume": "main",
    "abstract": "In this work we study a novel problem which focuses on person identification while performing daily activities. Learning biometric features from RGB videos is challenging due to spatio-temporal complexity and presence of appearance biases such as clothing color and background. We propose ABNet a novel framework which leverages disentanglement of biometric and non-biometric features to perform effective person identification from daily activities. ABNet relies on a bias-less teacher to learn biometric features from RGB videos and explicitly disentangle non-biometric features with the help of biometric distortion. In addition ABNet also exploits activity prior for biometrics which is enabled by joint biometric and activity learning. We perform comprehensive evaluation of the proposed approach across five different datasets which are derived from existing activity recognition benchmarks. Furthermore we extensively compare ABNet with existing works in person identification and demonstrate its effectiveness for activity-based biometrics across all five datasets. The code and dataset can be accessed at: https://github.com/sacrcv/Activity-Biometrics/",
    "checked": true,
    "id": "7c149225ba4157ff7f5997e6ebee61f6c95f5fff",
    "semantic_title": "activity-biometrics: person identification from daily activities",
    "citation_count": 0,
    "authors": [
      "Shehreen Azad",
      "Yogesh Singh Rawat"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_Z_Zero-shot_Style_Transfer_via_Attention_Reweighting_CVPR_2024_paper.html": {
    "title": "Z*: Zero-shot Style Transfer via Attention Reweighting",
    "volume": "main",
    "abstract": "Despite the remarkable progress in image style transfer formulating style in the context of art is inherently subjective and challenging. In contrast to existing methods this study shows that vanilla diffusion models can directly extract style information and seamlessly integrate the generative prior into the content image without retraining. Specifically we adopt dual denoising paths to represent content/style references in latent space and then guide the content image denoising process with style latent codes. We further reveal that the cross-attention mechanism in latent diffusion models tends to blend the content and style images resulting in stylized outputs that deviate from the original content image. To overcome this limitation we introduce a cross-attention reweighting strategy. Through theoretical analysis and experiments we demonstrate the effectiveness and superiority of the diffusion-based zero-shot style transfer via attention reweighting Z-STAR",
    "checked": false,
    "id": "bf3adc7ae7763c029c19fbc36cf5042210ec6275",
    "semantic_title": "z*: zero-shot style transfer via attention rearrangement",
    "citation_count": 2,
    "authors": [
      "Yingying Deng",
      "Xiangyu He",
      "Fan Tang",
      "Weiming Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_HIG_Hierarchical_Interlacement_Graph_Approach_to_Scene_Graph_Generation_in_CVPR_2024_paper.html": {
    "title": "HIG: Hierarchical Interlacement Graph Approach to Scene Graph Generation in Video Understanding",
    "volume": "main",
    "abstract": "Visual interactivity understanding within visual scenes presents a significant challenge in computer vision. Existing methods focus on complex interactivities while leveraging a simple relationship model. These methods however struggle with a diversity of appearance situation position interaction and relation in videos. This limitation hinders the ability to fully comprehend the interplay within the complex visual dynamics of subjects. In this paper we delve into interactivities understanding within visual content by deriving scene graph representations from dense interactivities among humans and objects. To achieve this goal we first present a new dataset containing Appearance-Situation-Position-Interaction-Relation predicates named ASPIRe offering an extensive collection of videos marked by a wide range of interactivities. Then we propose a new approach named Hierarchical Interlacement Graph (HIG) which leverages a unified layer and graph within a hierarchical structure to provide deep insights into scene changes across five distinct tasks. Our approach demonstrates superior performance to other methods through extensive experiments conducted in various scenarios",
    "checked": true,
    "id": "52a652f031f29a027b26411ba1c174541d24cc84",
    "semantic_title": "hig: hierarchical interlacement graph approach to scene graph generation in video understanding",
    "citation_count": 3,
    "authors": [
      "Trong-Thuan Nguyen",
      "Pha Nguyen",
      "Khoa Luu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_OOSTraj_Out-of-Sight_Trajectory_Prediction_With_Vision-Positioning_Denoising_CVPR_2024_paper.html": {
    "title": "OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising",
    "volume": "main",
    "abstract": "Trajectory prediction is fundamental in computer vision and autonomous driving particularly for understanding pedestrian behavior and enabling proactive decision-making. Existing approaches in this field often assume precise and complete observational data neglecting the challenges associated with out-of-view objects and the noise inherent in sensor data due to limited camera range physical obstructions and the absence of ground truth for denoised sensor data. Such oversights are critical safety concerns as they can result in missing essential non-visible objects. To bridge this gap we present a novel method for out-of-sight trajectory prediction that leverages a vision-positioning technique. Our approach denoises noisy sensor observations in an unsupervised manner and precisely maps sensor-based trajectories of out-of-sight objects into visual trajectories. This method has demonstrated state-of-the-art performance in out-of-sight noisy sensor trajectory denoising and prediction on the Vi-Fi and JRDB datasets. By enhancing trajectory prediction accuracy and addressing the challenges of out-of-sight objects our work significantly contributes to improving the safety and reliability of autonomous driving in complex environments. Our work represents the first initiative towards Out-Of-Sight Trajectory prediction (OOSTraj) setting a new benchmark for future research",
    "checked": true,
    "id": "bed2f47d4979a2ab3bae0074e37720bd0d1c23b0",
    "semantic_title": "oostraj: out-of-sight trajectory prediction with vision-positioning denoising",
    "citation_count": 0,
    "authors": [
      "Haichao Zhang",
      "Yi Xu",
      "Hongsheng Lu",
      "Takayuki Shimizu",
      "Yun Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jang_FADES_Fair_Disentanglement_with_Sensitive_Relevance_CVPR_2024_paper.html": {
    "title": "FADES: Fair Disentanglement with Sensitive Relevance",
    "volume": "main",
    "abstract": "Learning fair representation in deep learning is essential to mitigate discriminatory outcomes and enhance trustworthiness. However previous research has been commonly established on inappropriate assumptions prone to unrealistic counterfactuals and performance degradation. Although some proposed alternative approaches such as employing correlation-aware causal graphs or proxies for mutual information these methods are less practical and not applicable in general. In this work we propose FAir DisEntanglement with Sensitive relevance (FADES) a novel approach that leverages conditional mutual information from the information theory perspective to address these challenges. We employ sensitive relevant code to direct correlated information between target labels and sensitive attributes by imposing conditional independence allowing better separation of the features of interest in the latent space. Utilizing an intuitive disentangling approach FADES consistently achieves superior performance and fairness both quantitatively and qualitatively with its straightforward structure. Specifically the proposed method outperforms existing works in downstream classification and counterfactual generations on various benchmarks",
    "checked": false,
    "id": "8d3e6ebd5188b48c1a277bcf16b4cd81b4798bf4",
    "semantic_title": "rectifying unfairness in recommendation feedback loop",
    "citation_count": 5,
    "authors": [
      "Taeuk Jang",
      "Xiaoqian Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Learning_Continuous_3D_Words_for_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Learning Continuous 3D Words for Text-to-Image Generation",
    "volume": "main",
    "abstract": "Current controls over diffusion models (e.g. through text or ControlNet) for image generation fall short in recognizing abstract continuous attributes like illumination direction or non-rigid shape change. In this paper we present an approach for allowing users of text-to-image models to have fine-grained control of several attributes in an image. We do this by engineering special sets of input tokens that can be transformed in a continuous manner we call them Continuous 3D Words. These attributes can for example be represented as sliders and applied jointly with text prompts for fine-grained control over image generation. Given only a single mesh and a rendering engine we show that our approach can be adopted to provide continuous user control over several 3D-aware attributes including time-of-day illumination bird wing orientation dollyzoom effect and object poses. Our method is capable of conditioning image creation with multiple Continuous 3D Words and text descriptions simultaneously while adding no overhead to the generative process",
    "checked": true,
    "id": "65b86d30d34a808233f18058f03412d9b230931e",
    "semantic_title": "learning continuous 3d words for text-to-image generation",
    "citation_count": 2,
    "authors": [
      "Ta-Ying Cheng",
      "Matheus Gadelha",
      "Thibault Groueix",
      "Matthew Fisher",
      "Radomir Mech",
      "Andrew Markham",
      "Niki Trigoni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jayasumana_MarkovGen_Structured_Prediction_for_Efficient_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "MarkovGen: Structured Prediction for Efficient Text-to-Image Generation",
    "volume": "main",
    "abstract": "Modern text-to-image generation models produce high-quality images that are both photorealistic and faithful to the text prompts. However this quality comes at significant computational cost: nearly all of these models are iterative and require running sampling multiple times with large models. This iterative process is needed to ensure that different regions of the image are not only aligned with the text prompt but also compatible with each other. In this work we propose a light-weight approach to achieving this compatibility between different regions of an image using a Markov Random Field (MRF) model. We demonstrate the effectiveness of this method on top of the latent token-based Muse text-to-image model. The MRF richly encodes the compatibility among image tokens at different spatial locations to improve quality and significantly reduce the required number of Muse sampling steps. Inference with the MRF is significantly cheaper and its parameters can be quickly learned through back-propagation by modeling MRF inference as a differentiable neural-network layer. Our full model MarkovGen uses this proposed MRF model to both speed up Muse by 1.5xand produce higher quality images by decreasing undesirable image artifacts",
    "checked": true,
    "id": "6a4dbb87accd644d9750d2399494d2e531d47f7f",
    "semantic_title": "markovgen: structured prediction for efficient text-to-image generation",
    "citation_count": 0,
    "authors": [
      "Sadeep Jayasumana",
      "Daniel Glasner",
      "Srikumar Ramalingam",
      "Andreas Veit",
      "Ayan Chakrabarti",
      "Sanjiv Kumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Self-Supervised_Class-Agnostic_Motion_Prediction_with_Spatial_and_Temporal_Consistency_Regularizations_CVPR_2024_paper.html": {
    "title": "Self-Supervised Class-Agnostic Motion Prediction with Spatial and Temporal Consistency Regularizations",
    "volume": "main",
    "abstract": "The perception of motion behavior in a dynamic environment holds significant importance for autonomous driving systems wherein class-agnostic motion prediction methods directly predict the motion of the entire point cloud. While most existing methods rely on fully-supervised learning the manual labeling of point cloud data is laborious and time-consuming. Therefore several annotation-efficient methods have been proposed to address this challenge. Although effective these methods rely on weak annotations or additional multi-modal data like images and the potential benefits inherent in the point cloud sequence are still underexplored. To this end we explore the feasibility of self-supervised motion prediction with only unlabeled LiDAR point clouds. Initially we employ an optimal transport solver to establish coarse correspondences between current and future point clouds as the coarse pseudo motion labels. Training models directly using such coarse labels leads to noticeable spatial and temporal prediction inconsistencies. To mitigate these issues we introduce three simple spatial and temporal regularization losses which facilitate the self-supervised training process effectively. Experimental results demonstrate the significant superiority of our approach over the state-of-the-art self-supervised methods. Code will be available",
    "checked": true,
    "id": "b26c810e1e345a2cea8e7c1e0e3605da92cddef5",
    "semantic_title": "self-supervised class-agnostic motion prediction with spatial and temporal consistency regularizations",
    "citation_count": 0,
    "authors": [
      "Kewei Wang",
      "Yizheng Wu",
      "Jun Cen",
      "Zhiyu Pan",
      "Xingyi Li",
      "Zhe Wang",
      "Zhiguo Cao",
      "Guosheng Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_HashPoint_Accelerated_Point_Searching_and_Sampling_for_Neural_Rendering_CVPR_2024_paper.html": {
    "title": "HashPoint: Accelerated Point Searching and Sampling for Neural Rendering",
    "volume": "main",
    "abstract": "In this paper we address the problem of efficient point searching and sampling for volume neural rendering. Within this realm two typical approaches are employed: rasterization and ray tracing. The rasterization-based methods enable real-time rendering at the cost of increased memory and lower fidelity. In contrast the ray-tracing-based methods yield superior quality but demand longer rendering time. We solve this problem by our HashPoint method combining these two strategies leveraging rasterization for efficient point searching and sampling and ray marching for rendering. Our method optimizes point searching by rasterizing points within the camera's view organizing them in a hash table and facilitating rapid searches. Notably we accelerate the rendering process by adaptive sampling on the primary surface encountered by the ray. Our approach yields substantial speed-up for a range of state-of-the-art ray-tracing-based methods maintaining equivalent or superior accuracy across synthetic and real test datasets. The code will be available at https://jiahao-ma.github.io/hashpoint/",
    "checked": true,
    "id": "1e347d26e450d170ca72df3f590b12ed8b4a0f7d",
    "semantic_title": "hashpoint: accelerated point searching and sampling for neural rendering",
    "citation_count": 0,
    "authors": [
      "Jiahao Ma",
      "Miaomiao Liu",
      "David Ahmedt-Aristizabal",
      "Chuong Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_MFP_Making_Full_Use_of_Probability_Maps_for_Interactive_Image_CVPR_2024_paper.html": {
    "title": "MFP: Making Full Use of Probability Maps for Interactive Image Segmentation",
    "volume": "main",
    "abstract": "In recent interactive segmentation algorithms previous probability maps are used as network input to help predictions in the current segmentation round. However despite the utilization of previous masks useful information contained in the probability maps is not well propagated to the current predictions. In this paper to overcome this limitation we propose a novel and effective algorithm for click-based interactive image segmentation called MFP which attempts to make full use of probability maps. We first modulate previous probability maps to enhance their representations of user-specified objects. Then we feed the modulated probability maps as additional input to the segmentation network. We implement the proposed MFP algorithm based on the ResNet-34 HRNet-18 and ViT-B backbones and assess the performance extensively on various datasets. It is demonstrated that MFP meaningfully outperforms the existing algorithms using identical backbones. The source codes are available at https://github.com/cwlee00/MFP",
    "checked": true,
    "id": "2f825ba945aefb05467bc4209c6804053181e4d4",
    "semantic_title": "mfp: making full use of probability maps for interactive image segmentation",
    "citation_count": 1,
    "authors": [
      "Chaewon Lee",
      "Seon-Ho Lee",
      "Chang-Su Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kennerley_CAT_Exploiting_Inter-Class_Dynamics_for_Domain_Adaptive_Object_Detection_CVPR_2024_paper.html": {
    "title": "CAT: Exploiting Inter-Class Dynamics for Domain Adaptive Object Detection",
    "volume": "main",
    "abstract": "Domain adaptive object detection aims to adapt detection models to domains where annotated data is unavailable. Existing methods have been proposed to address the domain gap using the semi-supervised student-teacher framework. However a fundamental issue arises from the class imbalance in the labelled training set which can result in inaccurate pseudo-labels. The relationship between classes especially where one class is a majority and the other minority has a large impact on class bias. We propose Class-Aware Teacher (CAT) to address the class bias issue in the domain adaptation setting. In our work we approximate the class relationships with our Inter-Class Relation module (ICRm) and exploit it to reduce the bias within the model. In this way we are able to apply augmentations to highly related classes both inter- and intra-domain to boost the performance of minority classes while having minimal impact on majority classes. We further reduce the bias by implementing a class-relation weight to our classification loss. Experiments conducted on various datasets and ablation studies show that our method is able to address the class bias in the domain adaptation setting. On the Cityscapes ? Foggy Cityscapes dataset we attained a 52.5 mAP a substantial improvement over the 51.2 mAP achieved by the state-of-the-art method",
    "checked": true,
    "id": "5855cd278336c000723fcb36d9f6a71c342bb040",
    "semantic_title": "cat: exploiting inter-class dynamics for domain adaptive object detection",
    "citation_count": 0,
    "authors": [
      "Mikhail Kennerley",
      "Jian-Gang Wang",
      "Bharadwaj Veeravalli",
      "Robby T. Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bhattad_StyLitGAN_Image-Based_Relighting_via_Latent_Control_CVPR_2024_paper.html": {
    "title": "StyLitGAN: Image-Based Relighting via Latent Control",
    "volume": "main",
    "abstract": "We describe a novel method StyLitGAN for relighting and resurfacing images in the absence of labeled data. StyLitGAN generates images with realistic lighting effects including cast shadows soft shadows inter-reflections and glossy effects without the need for paired or CGI data. StyLitGAN uses an intrinsic image method to decompose an image followed by a search of the latent space of a pretrained StyleGAN to identify a set of directions. By prompting the model to fix one component (e.g. albedo) and vary another (e.g. shading) we generate relighted images by adding the identified directions to the latent style codes. Quantitative metrics of change in albedo and lighting diversity allow us to choose effective directions using a forward selection process. Qualitative evaluation confirms the effectiveness of our method",
    "checked": true,
    "id": "29c8c6d87a37f950d902fd0e9352672b6d147f39",
    "semantic_title": "stylitgan: image-based relighting via latent control",
    "citation_count": 2,
    "authors": [
      "Anand Bhattad",
      "James Soole",
      "D.A. Forsyth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rang_An_Empirical_Study_of_Scaling_Law_for_Scene_Text_Recognition_CVPR_2024_paper.html": {
    "title": "An Empirical Study of Scaling Law for Scene Text Recognition",
    "volume": "main",
    "abstract": "The laws of model size data volume computation and model performance have been extensively studied in the field of Natural Language Processing (NLP). However the scaling laws in Scene Text Recognition (STR) have not yet been investigated. To address this we conducted comprehensive studies that involved examining the correlations between performance and the scale of models data volume and computation in the field of text recognition. Conclusively the study demonstrates smooth power laws between performance and model size as well as training data volume when other influencing factors are held constant. Additionally we have constructed a large-scale dataset called REBU-Syn which comprises 6 million real samples and 18 million synthetic samples. Based on our scaling law and new dataset we have successfully trained a scene text recognition model achieving a new state-of-the-art on 6 common test benchmarks with a top-1 average accuracy of 97.42%. The models and dataset are publicly available at \\href https://github.com/large-ocr-model/large-ocr-model.github.io large-ocr-model.github.io",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miao Rang",
      "Zhenni Bi",
      "Chuanjian Liu",
      "Yunhe Wang",
      "Kai Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_Text2Loc_3D_Point_Cloud_Localization_from_Natural_Language_CVPR_2024_paper.html": {
    "title": "Text2Loc: 3D Point Cloud Localization from Natural Language",
    "volume": "main",
    "abstract": "We tackle the problem of 3D point cloud localization based on a few natural linguistic descriptions and introduce a novel neural network Text2Loc that fully interprets the semantic relationship between points and text. Text2Loc follows a coarse-to-fine localization pipeline: text-submap global place recognition followed by fine localization. In global place recognition relational dynamics among each textual hint are captured in a hierarchical transformer with max-pooling (HTM) whereas a balance between positive and negative pairs is maintained using text-submap contrastive learning. Moreover we propose a novel matching-free fine localization method to further refine the location predictions which completely removes the need for complicated text-instance matching and is lighter faster and more accurate than previous methods. Extensive experiments show that Text2Loc improves the localization accuracy by up to 2x over the state-of-the-art on the KITTI360Pose dataset. Our project page is publicly available at: https: //yan-xia.github.io/projects/text2loc/",
    "checked": true,
    "id": "815fa328e0cebc1fb00772a81845ec27ed6098ae",
    "semantic_title": "text2loc: 3d point cloud localization from natural language",
    "citation_count": 7,
    "authors": [
      "Yan Xia",
      "Letian Shi",
      "Zifeng Ding",
      "Joao F. Henriques",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_SVDinsTN_A_Tensor_Network_Paradigm_for_Efficient_Structure_Search_from_CVPR_2024_paper.html": {
    "title": "SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from Regularized Modeling Perspective",
    "volume": "main",
    "abstract": "Tensor network (TN) representation is a powerful technique for computer vision and machine learning. TN structure search (TN-SS) aims to search for a customized structure to achieve a compact representation which is a challenging NP-hard problem. Recent \"sampling-evaluation\"-based methods require sampling an extensive collection of structures and evaluating them one by one resulting in prohibitively high computational costs. To address this issue we propose a novel TN paradigm named SVD-inspired TN decomposition (SVDinsTN) which allows us to efficiently solve the TN-SS problem from a regularized modeling perspective eliminating the repeated structure evaluations. To be specific by inserting a diagonal factor for each edge of the fully-connected TN SVDinsTN allows us to calculate TN cores and diagonal factors simultaneously with the factor sparsity revealing a compact TN structure. In theory we prove a convergence guarantee for the proposed method. Experimental results demonstrate that the proposed method achieves approximately 100 1000 times acceleration compared to the state-of-the-art TN-SS methods while maintaining a comparable level of representation ability",
    "checked": true,
    "id": "addb2fa199fe640891daa30c697d58d08badacbc",
    "semantic_title": "svdinstn: a tensor network paradigm for efficient structure search from regularized modeling perspective",
    "citation_count": 0,
    "authors": [
      "Yu-Bang Zheng",
      "Xi-Le Zhao",
      "Junhua Zeng",
      "Chao Li",
      "Qibin Zhao",
      "Heng-Chao Li",
      "Ting-Zhu Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Phan_Decomposing_Disease_Descriptions_for_Enhanced_Pathology_Detection_A_Multi-Aspect_Vision-Language_CVPR_2024_paper.html": {
    "title": "Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Pre-training Framework",
    "volume": "main",
    "abstract": "Medical vision language pre-training (VLP) has emerged as a frontier of research enabling zero-shot pathological recognition by comparing the query image with the textual descriptions for each disease. Due to the complex semantics of biomedical texts current methods struggle to align medical images with key pathological findings in unstructured reports. This leads to the misalignment with the target disease's textual representation. In this paper we introduce a novel VLP framework designed to dissect disease descriptions into their fundamental aspects leveraging prior knowledge about the visual manifestations of pathologies. This is achieved by consulting a large language model and medical experts. Integrating a Transformer module our approach aligns an input image with the diverse elements of a disease generating aspect-centric image representations. By consolidating the matches from each aspect we improve the compatibility between an image and its associated disease. Additionally capitalizing on the aspect-oriented representations we present a dual-head Transformer tailored to process known and unknown diseases optimizing the comprehensive detection efficacy. Conducting experiments on seven downstream datasets ours improves the accuracy of recent methods by up to 8.56% and 17.26% for seen and unseen categories respectively. Our code is released at https://github.com/HieuPhan33/MAVL",
    "checked": true,
    "id": "12d09914aee2a84625209f41aeb118c991d84ec1",
    "semantic_title": "decomposing disease descriptions for enhanced pathology detection: a multi-aspect vision-language pre-training framework",
    "citation_count": 0,
    "authors": [
      "Vu Minh Hieu Phan",
      "Yutong Xie",
      "Yuankai Qi",
      "Lingqiao Liu",
      "Liyang Liu",
      "Bowen Zhang",
      "Zhibin Liao",
      "Qi Wu",
      "Minh-Son To",
      "Johan W. Verjans"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_MoMask_Generative_Masked_Modeling_of_3D_Human_Motions_CVPR_2024_paper.html": {
    "title": "MoMask: Generative Masked Modeling of 3D Human Motions",
    "volume": "main",
    "abstract": "We introduce MoMask a novel masked modeling framework for text-driven 3D human motion generation. In MoMask a hierarchical quantization scheme is employed to represent human motion as multi-layer discrete motion tokens with high-fidelity details. Starting at the base layer with a sequence of motion tokens obtained by vector quantization the residual tokens of increasing orders are derived and stored at the subsequent layers of the hierarchy. This is consequently followed by two distinct bidirectional transformers. For the base-layer motion tokens a Masked Transformer is designated to predict randomly masked motion tokens conditioned on text input at training stage. During generation (i.e. inference) stage starting from an empty sequence our Masked Transformer iteratively fills up the missing tokens; Subsequently a Residual Transformer learns to progressively predict the next-layer tokens based on the results from current layer. Extensive experiments demonstrate that MoMask outperforms the state-of-art methods on the text-to-motion generation task with an FID of 0.045 (vs e.g. 0.141 of T2M-GPT) on the HumanML3D dataset and 0.228 (vs 0.514) on KIT-ML respectively. MoMask can also be seamlessly applied in related tasks without further model fine-tuning such as text-guided temporal inpainting",
    "checked": true,
    "id": "f52af2c0cf521b48edd50670e9ba9cd02646d2b4",
    "semantic_title": "momask: generative masked modeling of 3d human motions",
    "citation_count": 15,
    "authors": [
      "Chuan Guo",
      "Yuxuan Mu",
      "Muhammad Gohar Javed",
      "Sen Wang",
      "Li Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Inverse_Rendering_of_Glossy_Objects_via_the_Neural_Plenoptic_Function_CVPR_2024_paper.html": {
    "title": "Inverse Rendering of Glossy Objects via the Neural Plenoptic Function and Radiance Fields",
    "volume": "main",
    "abstract": "Inverse rendering aims at recovering both geometry and materials of objects. It provides a more compatible reconstruction for conventional rendering engines compared with the neural radiance fields (NeRFs). On the other hand existing NeRF-based inverse rendering methods cannot handle glossy objects with local light interactions well as they typically oversimplify the illumination as a 2D environmental map which assumes infinite lights only. Observing the superiority of NeRFs in recovering radiance fields we propose a novel 5D Neural Plenoptic Function (NeP) based on NeRFs and ray tracing such that more accurate lighting-object interactions can be formulated via the rendering equation. We also design a material-aware cone sampling strategy to efficiently integrate lights inside the BRDF lobes with the help of pre-filtered radiance fields. Our method has two stages: the geometry of the target object and the pre-filtered environmental radiance fields are reconstructed in the first stage and materials of the target object are estimated in the second stage with the proposed NeP and material-aware cone sampling strategy. Extensive experiments on the proposed real-world and synthetic datasets demonstrate that our method can reconstruct high-fidelity geometry/materials of challenging glossy objects with complex lighting interactions from nearby objects. Project webpage: https://whyy.site/paper/nep",
    "checked": true,
    "id": "65079c7dfa674ba686495839a6792989e9b0cf78",
    "semantic_title": "inverse rendering of glossy objects via the neural plenoptic function and radiance fields",
    "citation_count": 0,
    "authors": [
      "Haoyuan Wang",
      "Wenbo Hu",
      "Lei Zhu",
      "Rynson W.H. Lau"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Split_to_Merge_Unifying_Separated_Modalities_for_Unsupervised_Domain_Adaptation_CVPR_2024_paper.html": {
    "title": "Split to Merge: Unifying Separated Modalities for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "Large vision-language models (VLMs) like CLIP have demonstrated good zero-shot learning performance in the unsupervised domain adaptation task. Yet most transfer approaches for VLMs focus on either the language or visual branches overlooking the nuanced interplay between both modalities. In this work we introduce a Unified Modality Separation (UniMoS) framework for unsupervised domain adaptation. Leveraging insights from modality gap studies we craft a nimble modality separation network that distinctly disentangles CLIP's features into language-associated and vision-associated components. Our proposed Modality-Ensemble Training (MET) method fosters the exchange of modality-agnostic information while maintaining modality-specific nuances. We align features across domains using a modality discriminator. Comprehensive evaluations on three benchmarks reveal our approach sets a new state-of-the-art with minimal computational costs. Code: https://github.com/TL-UESTC/UniMoS",
    "checked": true,
    "id": "b2420186a79aff2db599bf90b3b26ca2f8cbb051",
    "semantic_title": "split to merge: unifying separated modalities for unsupervised domain adaptation",
    "citation_count": 0,
    "authors": [
      "Xinyao Li",
      "Yuke Li",
      "Zhekai Du",
      "Fengling Li",
      "Ke Lu",
      "Jingjing Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dogadov_Fitting_Flats_to_Flats_CVPR_2024_paper.html": {
    "title": "Fitting Flats to Flats",
    "volume": "main",
    "abstract": "Affine subspaces of Euclidean spaces are also referred to as flats. A standard task in computer vision or more generally in engineering and applied sciences is fitting a flat to a set of points which is commonly solved using the PCA. We generalize this technique to enable fitting a flat to a set of other flats possibly of varying dimensions based on representing the flats as squared distance fields. Compared to previous approaches such as Riemannian centers of mass in the manifold of affine Grassmannians our approach is conceptually much simpler and computationally more efficient yet offers desirable properties such as respecting symmetries and being equivariant to rigid transformations leading to more intuitive and useful results in practice. We demonstrate these claims in a number of synthetic experiments and a multi-view reconstruction task of line-like objects",
    "checked": false,
    "id": "b1246e0b71085708527e61243f9f90edb353fb9d",
    "semantic_title": "data-driven intelligent recognition of flatness control efficiency for cold rolling mills",
    "citation_count": 3,
    "authors": [
      "Gabriel Dogadov",
      "Ugo Finnendahl",
      "Marc Alexa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Fusing_Personal_and_Environmental_Cues_for_Identification_and_Segmentation_of_CVPR_2024_paper.html": {
    "title": "Fusing Personal and Environmental Cues for Identification and Segmentation of First-Person Camera Wearers in Third-Person Views",
    "volume": "main",
    "abstract": "As wearable cameras become more popular an important question emerges: how to identify camera wearers within the perspective of conventional static cameras. The drastic difference between first-person (egocentric) and third-person (exocentric) camera views makes this a challenging task. We present PersonEnvironmentNet (PEN) a framework designed to integrate information from both the individuals in the two views and geometric cues inferred from the background environment. To facilitate research in this direction we also present TF2023 a novel dataset comprising synchronized first-person and third-person views along with masks of camera wearers and labels associating these masks with the respective first-person views. In addition we propose a novel quantitative metric designed to measure a model's ability to comprehend the relationship between the two views. Our experiments reveal that PEN outperforms existing methods. The code and dataset are available at https://github.com/ziweizhao1993/PEN",
    "checked": true,
    "id": "14db8a81972f26ff2ddfefccedbcfc0e3ea993c4",
    "semantic_title": "fusing personal and environmental cues for identification and segmentation of first-person camera wearers in third-person views",
    "citation_count": 0,
    "authors": [
      "Ziwei Zhao",
      "Yuchen Wang",
      "Chuhua Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bastico_Coupled_Laplacian_Eigenmaps_for_Locally-Aware_3D_Rigid_Point_Cloud_Matching_CVPR_2024_paper.html": {
    "title": "Coupled Laplacian Eigenmaps for Locally-Aware 3D Rigid Point Cloud Matching",
    "volume": "main",
    "abstract": "Point cloud matching a crucial technique in computer vision medical and robotics fields is primarily concerned with finding correspondences between pairs of point clouds or voxels. In some practical scenarios emphasizing local differences is crucial for accurately identifying a correct match thereby enhancing the overall robustness and reliability of the matching process. Commonly used shape descriptors have several limitations and often fail to provide meaningful local insights about the paired geometries. In this work we propose a new technique based on graph Laplacian eigenmaps to match point clouds by taking into account fine local structures. To deal with the order and sign ambiguity of Laplacian eigenmaps we introduce a new operator called Coupled Laplacian that allows to easily generate aligned eigenspaces for multiple registered geometries. We show that the similarity between those aligned high-dimensional spaces provides a locally meaningful score to match shapes. We firstly evaluate the performance of the proposed technique in a point-wise manner focusing on the task of object anomaly localization on the MVTec 3D-AD dataset. Additionally we define a new medical task called automatic Bone Side Estimation (BSE) which we address through a global similarity score derived from coupled eigenspaces. In order to test it we propose a benchmark collecting bone surface structures from various public datasets. Our matching technique based on Coupled Laplacian outperforms other methods by reaching an impressive accuracy on both tasks",
    "checked": true,
    "id": "ce85345f2a3eb9bf423da7ce6675ccefe2ecd0f3",
    "semantic_title": "coupled laplacian eigenmaps for locally-aware 3d rigid point cloud matching",
    "citation_count": 0,
    "authors": [
      "Matteo Bastico",
      "Etienne Decencière",
      "Laurent Corté",
      "Yannick Tillier",
      "David Ryckelynck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Overcoming_Generic_Knowledge_Loss_with_Selective_Parameter_Update_CVPR_2024_paper.html": {
    "title": "Overcoming Generic Knowledge Loss with Selective Parameter Update",
    "volume": "main",
    "abstract": "Foundation models encompass an extensive knowledge base and offer remarkable transferability. However this knowledge becomes outdated or insufficient over time. The challenge lies in continuously updating foundation models to accommodate novel information while retaining their original capabilities. Leveraging the fact that foundation models have initial knowledge on various tasks and domains we propose a novel approach that instead of updating all parameters equally localizes the updates to a sparse set of parameters relevant to the task being learned. We strike a balance between efficiency and new task performance while maintaining the transferability and generalizability of foundation models. We extensively evaluate our method on foundational vision-language models with a diverse spectrum of continual learning tasks. Our method achieves improvements on the accuracy of the newly learned tasks up to 7% while preserving the pretraining knowledge with a negligible decrease of 0.9% on a representative control set accuracy",
    "checked": true,
    "id": "e3abb313326ab2937d1a73dc4a45877d21af0075",
    "semantic_title": "overcoming generic knowledge loss with selective parameter update",
    "citation_count": 1,
    "authors": [
      "Wenxuan Zhang",
      "Paul Janson",
      "Rahaf Aljundi",
      "Mohamed Elhoseiny"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Weng_Desigen_A_Pipeline_for_Controllable_Design_Template_Generation_CVPR_2024_paper.html": {
    "title": "Desigen: A Pipeline for Controllable Design Template Generation",
    "volume": "main",
    "abstract": "Templates serve as a good starting point to implement a design (e.g. banner slide) but it takes great effort from designers to manually create. In this paper we present Desigen an automatic template creation pipeline which generates background images as well as harmonious layout elements over the background. Different from natural images a background image should preserve enough non-salient space for the overlaying layout elements. To equip existing advanced diffusion-based models with stronger spatial control we propose two simple but effective techniques to constrain the saliency distribution and reduce the attention weight in desired regions during the background generation process. Then conditioned on the background we synthesize the layout with a Transformer-based autoregressive generator. To achieve a more harmonious composition we propose an iterative inference strategy to adjust the synthesized background and layout in multiple rounds. We constructed a design dataset with more than 40k advertisement banners to verify our approach. Extensive experiments demonstrate that the proposed pipeline generates high-quality templates comparable to human designers. More than a single-page design we further show an application of presentation generation that outputs a set of theme-consistent slides. The data and code are available at https://whaohan.github.io/desigen",
    "checked": true,
    "id": "4f0254bc8989693d96275cc281d45c51197beb8b",
    "semantic_title": "desigen: a pipeline for controllable design template generation",
    "citation_count": 0,
    "authors": [
      "Haohan Weng",
      "Danqing Huang",
      "Yu Qiao",
      "Zheng Hu",
      "Chin-Yew Lin",
      "Tong Zhang",
      "C. L. Philip Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Diff-BGM_A_Diffusion_Model_for_Video_Background_Music_Generation_CVPR_2024_paper.html": {
    "title": "Diff-BGM: A Diffusion Model for Video Background Music Generation",
    "volume": "main",
    "abstract": "When editing a video a piece of attractive background music is indispensable. However video background music generation tasks face several challenges for example the lack of suitable training datasets and the difficulties in flexibly controlling the music generation process and sequentially aligning the video and music. In this work we first propose a high-quality music-video dataset BGM909 with detailed annotation and shot detection to provide multi-modal information about the video and music. We then present evaluation metrics to assess music quality including music diversity and alignment between music and video with retrieval precision metrics. Finally we propose the Diff-BGM framework to automatically generate the background music for a given video which uses different signals to control different aspects of the music during the generation process i.e. uses dynamic video features to control music rhythm and semantic features to control the melody and atmosphere. We propose to align the video and music sequentially by introducing a segment-aware cross-attention layer. Experiments verify the effectiveness of our proposed method. The code and models are available at https://github.com/sizhelee/Diff-BGM",
    "checked": true,
    "id": "28f130fefee31483110d6d387208ea74cf2e6224",
    "semantic_title": "diff-bgm: a diffusion model for video background music generation",
    "citation_count": 0,
    "authors": [
      "Sizhe Li",
      "Yiming Qin",
      "Minghang Zheng",
      "Xin Jin",
      "Yang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Singh_Looking_Similar_Sounding_Different_Leveraging_Counterfactual_Cross-Modal_Pairs_for_Audiovisual_CVPR_2024_paper.html": {
    "title": "Looking Similar Sounding Different: Leveraging Counterfactual Cross-Modal Pairs for Audiovisual Representation Learning",
    "volume": "main",
    "abstract": "Audiovisual representation learning typically relies on the correspondence between sight and sound. However there are often multiple audio tracks that can correspond with a visual scene. Consider for example different conversations on the same crowded street. The effect of such counterfactual pairs on audiovisual representation learning has not been previously explored. To investigate this we use dubbed versions of movies and television shows to augment cross-modal contrastive learning. Our approach learns to represent alternate audio tracks differing only in speech similarly to the same video. Our results from a comprehensive set of experiments investigating different training strategies show this general approach improves performance on a range of downstream auditory and audiovisual tasks without majorly affecting linguistic task performance overall. These findings highlight the importance of considering speech variation when learning scene-level audiovisual correspondences and suggest that dubbed audio can be a useful augmentation technique for training audiovisual models toward more robust performance on diverse downstream tasks",
    "checked": false,
    "id": "d893920196c5679bb6cbd5e493a178b828abdc9e",
    "semantic_title": "looking similar, sounding different: leveraging counterfactual cross-modal pairs for audiovisual representation learning",
    "citation_count": 1,
    "authors": [
      "Nikhil Singh",
      "Chih-Wei Wu",
      "Iroro Orife",
      "Mahdi Kalayeh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Multi-criteria_Token_Fusion_with_One-step-ahead_Attention_for_Efficient_Vision_Transformers_CVPR_2024_paper.html": {
    "title": "Multi-criteria Token Fusion with One-step-ahead Attention for Efficient Vision Transformers",
    "volume": "main",
    "abstract": "Vision Transformer (ViT) has emerged as a prominent backbone for computer vision. For more efficient ViTs recent works lessen the quadratic cost of the self-attention layer by pruning or fusing the redundant tokens. However these works faced the speed-accuracy trade-off caused by the loss of information. Here we argue that token fusion needs to consider diverse relations between tokens to minimize information loss. In this paper we propose a Multi-criteria Token Fusion (MCTF) that gradually fuses the tokens based on multi-criteria (i.e. similarity informativeness and size of fused tokens). Further we utilize the one-step-ahead attention which is the improved approach to capture the informativeness of the tokens. By training the model equipped with MCTF using a token reduction consistency we achieve the best speed-accuracy trade-off in the image classification (ImageNet1K). Experimental results prove that MCTF consistently surpasses the previous reduction methods with and without training. Specifically DeiT-T and DeiT-S with MCTF reduce FLOPs by about 44% while improving the performance (+0.5% and +0.3%) over the base model respectively. We also demonstrate the applicability of MCTF in various Vision Transformers (e.g. T2T-ViT LV-ViT) achieving at least 31% speedup without performance degradation. Code is available at https://github.com/mlvlab/MCTF",
    "checked": true,
    "id": "dd6aeda65eb040fad7a9618342349de5b7f701e4",
    "semantic_title": "multi-criteria token fusion with one-step-ahead attention for efficient vision transformers",
    "citation_count": 0,
    "authors": [
      "Sanghyeok Lee",
      "Joonmyung Choi",
      "Hyunwoo J. Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chang_Towards_HDR_and_HFR_Video_from_Rolling-Mixed-Bit_Spikings_CVPR_2024_paper.html": {
    "title": "Towards HDR and HFR Video from Rolling-Mixed-Bit Spikings",
    "volume": "main",
    "abstract": "The spiking cameras offer the benefits of high dynamic range (HDR) high temporal resolution and low data redundancy. However reconstructing HDR videos in high-speed conditions using single-bit spikings presents challenges due to the limited bit depth. Increasing the bit depth of the spikings is advantageous for boosting HDR performance but the readout efficiency will be decreased which is unfavorable for achieving a high frame rate (HFR) video. To address these challenges we propose a readout mechanism to obtain rolling-mixed-bit (RMB) spikings which involves interleaving multi-bit spikings within the single-bit spikings in a rolling manner thereby combining the characteristics of high bit depth and efficient readout. Furthermore we introduce RMB-Net for reconstructing HDR and HFR videos. RMB-Net comprises a cross-bit attention block for fusing mixed-bit spikings and a cross-time attention block for achieving temporal fusion. Extensive experiments conducted on synthetic and real-synthetic data demonstrate the superiority of our method. For instance pure 3-bit spikings result in 3 times of data volume whereas our method achieves comparable performance with less than 2% increase in data volume",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yakun Chang",
      "Yeliduosi Xiaokaiti",
      "Yujia Liu",
      "Bin Fan",
      "Zhaojun Huang",
      "Tiejun Huang",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Argaw_Scaling_Up_Video_Summarization_Pretraining_with_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "Scaling Up Video Summarization Pretraining with Large Language Models",
    "volume": "main",
    "abstract": "Long-form video content constitutes a significant portion of internet traffic making automated video summarization an essential research problem. However existing video summarization datasets are notably limited in their size constraining the effectiveness of state-of-the-art methods for generalization. Our work aims to overcome this limitation by capitalizing on the abundance of long-form videos with dense speech-to-video alignment and the remarkable capabilities of recent large language models (LLMs) in summarizing long text. We introduce an automated and scalable pipeline for generating a large-scale video summarization dataset using LLMs as Oracle summarizers. By leveraging the generated dataset we analyze the limitations of existing approaches and propose a new video summarization model that effectively addresses them. To facilitate further research in the field our work also presents a new benchmark dataset that contains 1200 long videos each with high-quality summaries annotated by professionals. Extensive experiments clearly indicate that our proposed approach sets a new state-of-the-art in video summarization across several benchmarks",
    "checked": true,
    "id": "4b9967c741d26a3e497236cee898d1bfaf24c3b5",
    "semantic_title": "scaling up video summarization pretraining with large language models",
    "citation_count": 0,
    "authors": [
      "Dawit Mureja Argaw",
      "Seunghyun Yoon",
      "Fabian Caba Heilbron",
      "Hanieh Deilamsalehy",
      "Trung Bui",
      "Zhaowen Wang",
      "Franck Dernoncourt",
      "Joon Son Chung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Continuous_Optical_Zooming_A_Benchmark_for_Arbitrary-Scale_Image_Super-Resolution_in_CVPR_2024_paper.html": {
    "title": "Continuous Optical Zooming: A Benchmark for Arbitrary-Scale Image Super-Resolution in Real World",
    "volume": "main",
    "abstract": "Most current arbitrary-scale image super-resolution (SR) methods has commonly relied on simulated data generated by simple synthetic degradation models (e.g. bicubic downsampling) at continuous various scales thereby falling short in capturing the complex degradation of real-world images. This limitation hinders the visual quality of these methods when applied to real-world images. To address this issue we propose the Continuous Optical Zooming dataset (COZ) by constructing an automatic imaging system to collect images at fine-grained various focal lengths within a specific range and providing strict image pair alignment. The COZ dataset serves as a benchmark to provide real-world data for training and testing arbitrary-scale SR models. To enhance the model's robustness against real-world image degradation we propose a Local Mix Implicit network (LMI) based on the MLP-mixer architecture and meta-learning which directly learns the local texture information by simultaneously mixing features and coordinates of multiple independent points. The extensive experiments demonstrate the superior performance of the arbitrary-scale SR models trained on the COZ dataset compared to models trained on simulated data. Our LMI model exhibits the superior effectiveness compared to other models. This study is of great significance in developing more efficient algorithms and improving the performance of arbitrary-scale image SR methods in practical applications. Our dataset and codes are available at https://github.com/pf0607/COZ",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiyuan Fu",
      "Fei Peng",
      "Xianwei Li",
      "Yejun Li",
      "Xin Wang",
      "Huadong Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tafasca_Sharingan_A_Transformer_Architecture_for_Multi-Person_Gaze_Following_CVPR_2024_paper.html": {
    "title": "Sharingan: A Transformer Architecture for Multi-Person Gaze Following",
    "volume": "main",
    "abstract": "Gaze is a powerful form of non-verbal communication that humans develop from an early age. As such modeling this behavior is an important task that can benefit a broad set of application domains ranging from robotics to sociology. In particular the gaze following task in computer vision is defined as the prediction of the 2D pixel coordinates where a person in the image is looking. Previous attempts in this area have primarily centered on CNN-based architectures but they have been constrained by the need to process one person at a time which proves to be highly inefficient. In this paper we introduce a novel and effective multi-person transformer-based architecture for gaze prediction. While there exist prior works using transformers for multi-person gaze prediction they use a fixed set of learnable embeddings to decode both the person and its gaze target which requires a matching step afterward to link the predictions with the annotations. Thus it is difficult to quantitatively evaluate these methods reliably with the available benchmarks or integrate them into a larger human behavior understanding system. Instead we are the first to propose a multi-person transformer-based architecture that maintains the original task formulation and ensures control over the people fed as input. Our main contribution lies in encoding the person-specific information into a single controlled token to be processed alongside image tokens and using its output for prediction based on a novel multiscale decoding mechanism. Our new architecture achieves state-of-the-art results on the GazeFollow VideoAttentionTarget and ChildPlay datasets and outperforms comparable multi-person architectures with a notable margin. Our code checkpoints and data extractions will be made publicly available soon",
    "checked": false,
    "id": "a9dd2e127ce053ed1410190d204ded82bcc45066",
    "semantic_title": "sharingan: a transformer-based architecture for gaze following",
    "citation_count": 2,
    "authors": [
      "Samy Tafasca",
      "Anshul Gupta",
      "Jean-Marc Odobez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_ViewFusion_Towards_Multi-View_Consistency_via_Interpolated_Denoising_CVPR_2024_paper.html": {
    "title": "ViewFusion: Towards Multi-View Consistency via Interpolated Denoising",
    "volume": "main",
    "abstract": "Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this we introduce ViewFusion a novel training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views",
    "checked": true,
    "id": "14c5e0769218e78151965b1a93627bd7db683ee0",
    "semantic_title": "viewfusion: towards multi-view consistency via interpolated denoising",
    "citation_count": 0,
    "authors": [
      "Xianghui Yang",
      "Yan Zuo",
      "Sameera Ramasinghe",
      "Loris Bazzani",
      "Gil Avraham",
      "Anton van den Hengel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bandyopadhyay_SketchINR_A_First_Look_into_Sketches_as_Implicit_Neural_Representations_CVPR_2024_paper.html": {
    "title": "SketchINR: A First Look into Sketches as Implicit Neural Representations",
    "volume": "main",
    "abstract": "We propose SketchINR to advance the representation of vector sketches with implicit neural models. A variable length vector sketch is compressed into a latent space of fixed dimension that implicitly encodes the underlying shape as a function of time and strokes. The learned function predicts the xy point coordinates in a sketch at each time and stroke. Despite its simplicity SketchINR outperforms existing representations at multiple tasks: (i) Encoding an entire sketch dataset into a fixed size latent vector SketchINR gives 60x and 10x data compression over raster and vector sketches respectively. (ii) SketchINR's auto-decoder provides a much higher-fidelity representation than other learned vector sketch representations and is uniquely able to scale to complex vector sketches such as FS-COCO. (iii) SketchINR supports parallelisation that can decode/render 100x faster than other learned vector representations such as SketchRNN. (iv) SketchINR for the first time emulates the human ability to reproduce a sketch with varying abstraction in terms of number and complexity of strokes. As a first look at implicit sketches SketchINR's compact high-fidelity representation will support future work in modelling long and complex sketches",
    "checked": true,
    "id": "b0fbcf89c2fc064054c0572329f4665c340967b6",
    "semantic_title": "sketchinr: a first look into sketches as implicit neural representations",
    "citation_count": 3,
    "authors": [
      "Hmrishav Bandyopadhyay",
      "Ayan Kumar Bhunia",
      "Pinaki Nath Chowdhury",
      "Aneeshan Sain",
      "Tao Xiang",
      "Timothy Hospedales",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Open-Vocabulary_Segmentation_with_Semantic-Assisted_Calibration_CVPR_2024_paper.html": {
    "title": "Open-Vocabulary Segmentation with Semantic-Assisted Calibration",
    "volume": "main",
    "abstract": "This paper studies open-vocabulary segmentation (OVS) through calibrating in-vocabulary and domain-biased embedding space with generalized contextual prior of CLIP. As the core of open-vocabulary understanding alignment of visual content with the semantics of unbounded text has become the bottleneck of this field. To address this challenge recent works propose to utilize CLIP as an additional classifier and aggregate model predictions with CLIP classification results. Despite their remarkable progress performance of OVS methods in relevant scenarios is still unsatisfactory compared with supervised counterparts. We attribute this to the in-vocabulary embedding and domain-biased CLIP prediction. To this end we present a Semantic-assisted CAlibration Network (SCAN). In SCAN we incorporate generalized semantic prior of CLIP into proposal embedding to avoid collapsing on known categories. Besides a contextual shift strategy is applied to mitigate the lack of global context and unnatural background noise. With above designs SCAN achieves state-of-the-art performance on all popular open-vocabulary segmentation benchmarks. Furthermore we also focus on the problem of existing evaluation system that ignores semantic duplication across categories and propose a new metric called Semantic-Guided IoU (SG-IoU)",
    "checked": true,
    "id": "28c2a8cd598dbb7651f29402e808e90977696bf6",
    "semantic_title": "open-vocabulary segmentation with semantic-assisted calibration",
    "citation_count": 4,
    "authors": [
      "Yong Liu",
      "Sule Bai",
      "Guanbin Li",
      "Yitong Wang",
      "Yansong Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_MatchU_Matching_Unseen_Objects_for_6D_Pose_Estimation_from_RGB-D_CVPR_2024_paper.html": {
    "title": "MatchU: Matching Unseen Objects for 6D Pose Estimation from RGB-D Images",
    "volume": "main",
    "abstract": "Recent learning methods for object pose estimation require resource-intensive training for each individual object instance or category hampering their scalability in real applications when confronted with previously unseen objects. In this paper we propose MatchU a Fuse-Describe-Match strategy for 6D pose estimation from RGB-D images. MatchU is a generic approach that fuses 2D texture and 3D geometric cues for 6D pose prediction of unseen objects. We rely on learning geometric 3D descriptors that are rotation-invariant by design. By encoding pose-agnostic geometry the learned descriptors naturally generalize to unseen objects and capture symmetries. To tackle ambiguous associations using 3D geometry only we fuse additional RGB information into our descriptor. This is achieved through a novel attention-based mechanism that fuses cross-modal information together with a matching loss that leverages the latent space learned from RGB data to guide the descriptor learning process. Extensive experiments reveal the generalizability of both the RGB-D fusion strategy as well as the descriptor efficacy. Benefiting from the novel designs MatchU surpasses all existing methods by a significant margin in terms of both accuracy and speed even without the requirement of expensive re-training or rendering",
    "checked": true,
    "id": "b917198d8b001bb23fa23be3134842e84f6c93c6",
    "semantic_title": "matchu: matching unseen objects for 6d pose estimation from rgb-d images",
    "citation_count": 1,
    "authors": [
      "Junwen Huang",
      "Hao Yu",
      "Kuan-Ting Yu",
      "Nassir Navab",
      "Slobodan Ilic",
      "Benjamin Busam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Giroux_Towards_a_Perceptual_Evaluation_Framework_for_Lighting_Estimation_CVPR_2024_paper.html": {
    "title": "Towards a Perceptual Evaluation Framework for Lighting Estimation",
    "volume": "main",
    "abstract": "Progress in lighting estimation is tracked by computing existing image quality assessment (IQA) metrics on images from standard datasets. While this may appear to be a reasonable approach we demonstrate that doing so does not correlate to human preference when the estimated lighting is used to relight a virtual scene into a real photograph. To study this we design a controlled psychophysical experiment where human observers must choose their preference amongst rendered scenes lit using a set of lighting estimation algorithms selected from the recent literature and use it to analyse how these algorithms perform according to human perception. Then we demonstrate that none of the most popular IQA metrics from the literature taken individually correctly represent human perception. Finally we show that by learning a combination of existing IQA metrics we can more accurately represent human preference. This provides a new perceptual framework to help evaluate future lighting estimation algorithms. To encourage future research all (anonymised) perceptual data and code are available at https://lvsn.github.io/PerceptionMetric/",
    "checked": true,
    "id": "8eb0c6672866f1507ae1648680d64b61105b08ac",
    "semantic_title": "towards a perceptual evaluation framework for lighting estimation",
    "citation_count": 0,
    "authors": [
      "Justine Giroux",
      "Mohammad Reza Karimi Dastjerdi",
      "Yannick Hold-Geoffroy",
      "Javier Vazquez-Corral",
      "Jean-François Lalonde"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Bridging_the_Synthetic-to-Authentic_Gap_Distortion-Guided_Unsupervised_Domain_Adaptation_for_Blind_CVPR_2024_paper.html": {
    "title": "Bridging the Synthetic-to-Authentic Gap: Distortion-Guided Unsupervised Domain Adaptation for Blind Image Quality Assessment",
    "volume": "main",
    "abstract": "The annotation of blind image quality assessment (BIQA) is labor-intensive and time-consuming especially for authentic images. Training on synthetic data is expected to be beneficial but synthetically trained models often suffer from poor generalization in real domains due to domain gaps. In this work we make a key observation that introducing more distortion types in the synthetic dataset may not improve or even be harmful to generalizing authentic image quality assessment. To solve this challenge we propose distortion-guided unsupervised domain adaptation for BIQA (DGQA) a novel framework that leverages adaptive multi-domain selection via prior knowledge from distortion to match the data distribution between the source domains and the target domain thereby reducing negative transfer from the outlier source domains. Extensive experiments on two cross-domain settings (synthetic distortion to authentic distortion and synthetic distortion to algorithmic distortion) have demonstrated the effectiveness of our proposed DGQA. Besides DGQA is orthogonal to existing model-based BIQA methods and can be used in combination with such models to improve performance with less training data",
    "checked": true,
    "id": "be40bb2fe8be392830b2d8e330ac59c52fb1709e",
    "semantic_title": "bridging the synthetic-to-authentic gap: distortion-guided unsupervised domain adaptation for blind image quality assessment",
    "citation_count": 0,
    "authors": [
      "Aobo Li",
      "Jinjian Wu",
      "Yongxu Liu",
      "Leida Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Coherent_Temporal_Synthesis_for_Incremental_Action_Segmentation_CVPR_2024_paper.html": {
    "title": "Coherent Temporal Synthesis for Incremental Action Segmentation",
    "volume": "main",
    "abstract": "Data replay is a successful incremental learning technique for images. It prevents catastrophic forgetting by keeping a reservoir of previous data original or synthesized to ensure the model retains past knowledge while adapting to novel concepts. However its application in the video domain is rudimentary as it simply stores frame exemplars for action recognition. This paper presents the first exploration of video data replay techniques for incremental action segmentation focusing on action temporal modeling. We propose a Temporally Coherent Action (TCA) model which represents actions using a generative model instead of storing individual frames. The integration of a conditioning variable that captures temporal coherence allows our model to understand the evolution of action features over time. Therefore action segments generated by TCA for replay are diverse and temporally coherent. In a 10-task incremental setup on the Breakfast dataset our approach achieves significant increases in accuracy for up to 22% compared to the baselines",
    "checked": true,
    "id": "ffbf4db22063da5f4c25b76e4bcd48efdba8c063",
    "semantic_title": "coherent temporal synthesis for incremental action segmentation",
    "citation_count": 0,
    "authors": [
      "Guodong Ding",
      "Hans Golong",
      "Angela Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_HiFi4G_High-Fidelity_Human_Performance_Rendering_via_Compact_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian Splatting",
    "volume": "main",
    "abstract": "We have recently seen tremendous progress in photo-real human modeling and rendering. Yet efficiently rendering realistic human performance and integrating it into the rasterization pipeline remains challenging. In this paper we present HiFi4G an explicit and compact Gaussian-based approach for high-fidelity human performance rendering from dense footage. Our core intuition is to marry the 3D Gaussian representation with non-rigid tracking achieving a compact and compression-friendly representation. We first propose a dual-graph mechanism to obtain motion priors with a coarse deformation graph for effective initialization and a fine-grained Gaussian graph to enforce subsequent constraints. Then we utilize a 4D Gaussian optimization scheme with adaptive spatial-temporal regularizers to effectively balance the non-rigid prior and Gaussian updating. We also present a companion compression scheme with residual compensation for immersive experiences on various platforms. It achieves a substantial compression rate of approximately 25 times with less than 2MB of storage per frame. Extensive experiments demonstrate the effectiveness of our approach which significantly outperforms existing approaches in terms of optimization speed rendering quality and storage overhead",
    "checked": true,
    "id": "ffa2b507088deb9097f11c951c5a9c5d8d29562b",
    "semantic_title": "hifi4g: high-fidelity human performance rendering via compact gaussian splatting",
    "citation_count": 9,
    "authors": [
      "Yuheng Jiang",
      "Zhehao Shen",
      "Penghao Wang",
      "Zhuo Su",
      "Yu Hong",
      "Yingliang Zhang",
      "Jingyi Yu",
      "Lan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_G-FARS_Gradient-Field-based_Auto-Regressive_Sampling_for_3D_Part_Grouping_CVPR_2024_paper.html": {
    "title": "G-FARS: Gradient-Field-based Auto-Regressive Sampling for 3D Part Grouping",
    "volume": "main",
    "abstract": "This paper proposes a novel task named \"3D part grouping\". Suppose there is a mixed set containing scattered parts from various shapes. This task requires algorithms to find out every possible combination among all the parts. To address this challenge we propose the so called Gradient Field-based Auto-Regressive Sampling framework (G-FARS) tailored specifically for the 3D part grouping task. In our framework we design a gradient-field-based selection graph neural network (GNN) to learn the gradients of a log conditional probability density in terms of part selection where the condition is the given mixed part set. This innovative approach implemented through the gradient-field-based selection GNN effectively captures complex relationships among all the parts in the input. Upon completion of the training process our framework becomes capable of autonomously grouping 3D parts by iteratively selecting them from the mixed part set leveraging the knowledge acquired by the trained gradient-field-based selection GNN. Our code is available at: https://github.com/J-F-Cheng/G-FARS-3DPartGrouping",
    "checked": true,
    "id": "b9eb52d0028b127c57589c849a15d1ee04d46c8f",
    "semantic_title": "g-fars: gradient-field-based auto-regressive sampling for 3d part grouping",
    "citation_count": 0,
    "authors": [
      "Junfeng Cheng",
      "Tania Stathaki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Towards_High-fidelity_Artistic_Image_Vectorization_via_Texture-Encapsulated_Shape_Parameterization_CVPR_2024_paper.html": {
    "title": "Towards High-fidelity Artistic Image Vectorization via Texture-Encapsulated Shape Parameterization",
    "volume": "main",
    "abstract": "We develop a novel vectorized image representation scheme accommodating both shape/geometry and texture in a decoupled way particularly tailored for reconstruction and editing tasks of artistic/design images such as Emojis and Cliparts. In the heart of this representation is a set of sparsely and unevenly located 2D control points. On one hand these points constitute a collection of parametric/vectorized geometric primitives (e.g. curves and closed shapes) describing the shape characteristics of the target image. On the other hand local texture codes in terms of implicit neural network parameters are spatially distributed into each control point yielding local coordinate-to-RGB mappings within the anchored region of each control point. In the meantime a zero-shot learning algorithm is developed to decompose an arbitrary raster image into the above representation for the sake of high-fidelity image vectorization with convenient editing ability. Extensive experiments on a series of image vectorization and editing tasks well demonstrate the high accuracy offered by our proposed method with a significantly higher image compression ratio over prior art",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ye Chen",
      "Bingbing Ni",
      "Jinfan Liu",
      "Xiaoyang Huang",
      "Xuanhong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_On_Exact_Inversion_of_DPM-Solvers_CVPR_2024_paper.html": {
    "title": "On Exact Inversion of DPM-Solvers",
    "volume": "main",
    "abstract": "Diffusion probabilistic models (DPMs) are a key component in modern generative models. DPM-solvers have achieved reduced latency and enhanced quality significantly but have posed challenges to find the exact inverse (i.e. finding the initial noise from the given image). Here we investigate the exact inversions for DPM-solvers and propose algorithms to perform them when samples are generated by the first-order as well as higher-order DPM-solvers. For each explicit denoising step in DPM-solvers we formulated the inversions using implicit methods such as gradient descent or forward step method to ensure the robustness to large classifier-free guidance unlike the prior approach using fixed-point iteration. Experimental results demonstrated that our proposed exact inversion methods significantly reduced the error of both image and noise reconstructions greatly enhanced the ability to distinguish invisible watermarks and well prevented unintended background changes consistently during image editing",
    "checked": true,
    "id": "9083d00c0240a04a67a1dc6d8be0f1f5bd4080a4",
    "semantic_title": "on exact inversion of dpm-solvers",
    "citation_count": 2,
    "authors": [
      "Seongmin Hong",
      "Kyeonghyun Lee",
      "Suh Yoon Jeon",
      "Hyewon Bae",
      "Se Young Chun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiong_EfficientSAM_Leveraged_Masked_Image_Pretraining_for_Efficient_Segment_Anything_CVPR_2024_paper.html": {
    "title": "EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything",
    "volume": "main",
    "abstract": "Segment Anything Model (SAM) has emerged as a powerful tool for numerous vision applications. A key component that drives the impressive performance for zero-shot transfer and high versatility is a super large Transformer model trained on the extensive high-quality SA-1B dataset. While beneficial the huge computation cost of SAM model has limited its applications to wider real-world applications. To address this limitation we propose EfficientSAMs light-weight SAM models that exhibits decent performance with largely reduced complexity. Our idea is based on leveraging masked image pretraining SAMI which learns to reconstruct features from SAM image encoder for effective visual representation learning. Further we take SAMI-pretrained light-weight image encoders and mask decoder to build EfficientSAMs and finetune the models on SA-1B for segment anything task. We perform evaluations on multiple vision tasks including image classification object detection instance segmentation and semantic segmentation and find that our proposed pretraining method SAMI consistently outperforms other masked image pretraining methods. On segment anything task such as zero-shot instance segmentation our EfficientSAMs with SAMI-pretrained lightweight image encoders perform favorably with a significant gain (e.g. 4 AP on COCO/LVIS) over other fast SAM models. Our EfficientSAM code and models are available at https://github.com/yformer/EfficientSAM",
    "checked": true,
    "id": "30ee82b45277ff528e8419ee9543cb7e27d09311",
    "semantic_title": "efficientsam: leveraged masked image pretraining for efficient segment anything",
    "citation_count": 30,
    "authors": [
      "Yunyang Xiong",
      "Bala Varadarajan",
      "Lemeng Wu",
      "Xiaoyu Xiang",
      "Fanyi Xiao",
      "Chenchen Zhu",
      "Xiaoliang Dai",
      "Dilin Wang",
      "Fei Sun",
      "Forrest Iandola",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_ChatScene_Knowledge-Enabled_Safety-Critical_Scenario_Generation_for_Autonomous_Vehicles_CVPR_2024_paper.html": {
    "title": "ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles",
    "volume": "main",
    "abstract": "We present ChatScene a Large Language Model (LLM)-based agent that leverages the capabilities of LLMs to generate safety-critical scenarios for autonomous vehicles. Given unstructured language instructions the agent first generates textually described traffic scenarios using LLMs. These scenario descriptions are subsequently broken down into several sub-descriptions for specified details such as behaviors and locations of vehicles. The agent then distinctively transforms the textually described sub-scenarios into domain-specific languages which then generate actual code for prediction and control in simulators facilitating the creation of diverse and complex scenarios within the CARLA simulation environment. A key part of our agent is a comprehensive knowledge retrieval component which efficiently translates specific textual descriptions into corresponding domain-specific code snippets by training a knowledge database containing the scenario description and code pairs. Extensive experimental results underscore the efficacy of ChatScene in improving the safety of autonomous vehicles. For instance the scenarios generated by ChatScene show a 15% increase in collision rates compared to state-of-the-art baselines when tested against different reinforcement learning-based ego vehicles. Furthermore we show that by using our generated safety-critical scenarios to fine-tune different RL-based autonomous driving models they can achieve a 9% reduction in collision rates surpassing current SOTA methods. ChatScene effectively bridges the gap between textual descriptions of traffic scenarios and practical CARLA simulations providing a unified way to conveniently generate safety-critical scenarios for safety testing and improvement for AVs",
    "checked": true,
    "id": "a3326a57275d3f36794ec71bf2722a06904bb785",
    "semantic_title": "chatscene: knowledge-enabled safety-critical scenario generation for autonomous vehicles",
    "citation_count": 0,
    "authors": [
      "Jiawei Zhang",
      "Chejian Xu",
      "Bo Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_CAMEL_CAusal_Motion_Enhancement_Tailored_for_Lifting_Text-driven_Video_Editing_CVPR_2024_paper.html": {
    "title": "CAMEL: CAusal Motion Enhancement Tailored for Lifting Text-driven Video Editing",
    "volume": "main",
    "abstract": "Text-driven video editing poses significant challenges in exhibiting flicker-free visual continuity while preserving the inherent motion patterns of original videos. Existing methods operate under a paradigm where motion and appearance are intricately intertwined. This coupling leads to the network either over-fitting appearance content -- failing to capture motion patterns -- or focusing on motion patterns at the expense of content generalization to diverse textual scenarios. Inspired by the pivotal role of wavelet transform in dissecting video sequences we propose CAusal Motion Enhancement tailored for Lifting text-driven video editing (CAMEL) a novel technique with two core designs. First we introduce motion prompts designed to summarize motion concepts from video templates through direct optimization. The optimized prompts are purposefully integrated into latent representations of diffusion models to enhance the motion fidelity of generated results. Second to enhance motion coherence and extend the generalization of appearance content to creative textual prompts we propose the causal motion-enhanced attention mechanism. This mechanism is implemented in tandem with a novel causal motion filter synergistically enhancing the motion coherence of disentangled high-frequency components and concurrently preserving the generalization of appearance content across various textual scenarios. Extensive experimental results show the superior performance of CAMEL",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guiwei Zhang",
      "Tianyu Zhang",
      "Guanglin Niu",
      "Zichang Tan",
      "Yalong Bai",
      "Qing Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zou_Teeth-SEG_An_Efficient_Instance_Segmentation_Framework_for_Orthodontic_Treatment_based_CVPR_2024_paper.html": {
    "title": "Teeth-SEG: An Efficient Instance Segmentation Framework for Orthodontic Treatment based on Multi-Scale Aggregation and Anthropic Prior Knowledge",
    "volume": "main",
    "abstract": "Teeth localization segmentation and labeling in 2D images have great potential in modern dentistry to enhance dental diagnostics treatment planning and population-based studies on oral health. However general instance segmentation frameworks are incompetent due to 1) the subtle differences between some teeth' shapes (e.g. maxillary first premolar and second premolar) 2) the teeth's position and shape variation across subjects and 3) the presence of abnormalities in the dentition (e.g. caries and edentulism). To address these problems we propose a ViT-based framework named TeethSEG which consists of stacked Multi-Scale Aggregation (MSA) blocks and an Anthropic Prior Knowledge (APK) layer. Specifically to compose the two modules we design 1) a unique permutation-based upscaler to ensure high efficiency while establishing clear segmentation boundaries with 2) multi-head self/cross-gating layers to emphasize particular semantics meanwhile maintaining the divergence between token embeddings. Besides we collect 3) the first open-sourced intraoral image dataset IO150K which comprises over 150k intraoral photos and all photos are annotated by orthodontists using a human-machine hybrid algorithm. Experiments on IO150K demonstrate that our TeethSEG outperforms the state-of-the-art segmentation models on dental image segmentation",
    "checked": false,
    "id": "f0c7983ed5f2bf06a5eac68a3cf92c78ae38a667",
    "semantic_title": "teeth-seg: an efficient instance segmentation framework for orthodontic treatment based on anthropic prior knowledge",
    "citation_count": 0,
    "authors": [
      "Bo Zou",
      "Shaofeng Wang",
      "Hao Liu",
      "Gaoyue Sun",
      "Yajie Wang",
      "FeiFei Zuo",
      "Chengbin Quan",
      "Youjian Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_FocSAM_Delving_Deeply_into_Focused_Objects_in_Segmenting_Anything_CVPR_2024_paper.html": {
    "title": "FocSAM: Delving Deeply into Focused Objects in Segmenting Anything",
    "volume": "main",
    "abstract": "The Segment Anything Model (SAM) marks a notable milestone in segmentation models highlighted by its robust zero-shot capabilities and ability to handle diverse prompts. SAM follows a pipeline that separates interactive segmentation into image preprocessing through a large encoder and interactive inference via a lightweight decoder ensuring efficient real-time performance. However SAM faces stability issues in challenging samples upon this pipeline. These issues arise from two main factors. Firstly the image preprocessing disables SAM to dynamically use image-level zoom-in strategies to refocus on the target object during interaction. Secondly the lightweight decoder struggles to sufficiently integrate interactive information with image embeddings. To address these two limitations we propose FocSAM with a pipeline redesigned on two pivotal aspects. First we propose Dynamic Window Multi-head Self-Attention (Dwin-MSA) to dynamically refocus SAM's image embeddings on the target object. Dwin-MSA localizes attention computations around the target object enhancing object-related embeddings with minimal computational overhead. Second we propose Pixel-wise Dynamic ReLU (P-DyReLU) to enable sufficient integration of interactive information from a few initial clicks that have significant impacts on the overall segmentation results. Experimentally FocSAM augments SAM's interactive segmentation performance to match the existing state-of-the-art method in segmentation quality requiring only about 5.6% of this method's inference time on CPUs. Code is available at https://github.com/YouHuang67/focsam",
    "checked": true,
    "id": "190ae0d8aba4d0211fded77766bc08fb92875e18",
    "semantic_title": "focsam: delving deeply into focused objects in segmenting anything",
    "citation_count": 0,
    "authors": [
      "You Huang",
      "Zongyu Lan",
      "Liujuan Cao",
      "Xianming Lin",
      "Shengchuan Zhang",
      "Guannan Jiang",
      "Rongrong Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_DMR_Decomposed_Multi-Modality_Representations_for_Frames_and_Events_Fusion_in_CVPR_2024_paper.html": {
    "title": "DMR: Decomposed Multi-Modality Representations for Frames and Events Fusion in Visual Reinforcement Learning",
    "volume": "main",
    "abstract": "We explore visual reinforcement learning (RL) using two complementary visual modalities: frame-based RGB camera and event-based Dynamic Vision Sensor (DVS). Existing multi-modality visual RL methods often encounter challenges in effectively extracting task-relevant information from multiple modalities while suppressing the increased noise only using indirect reward signals instead of pixel-level supervision. To tackle this we propose a Decomposed Multi-Modality Representation (DMR) framework for visual RL. It explicitly decomposes the inputs into three distinct components: combined task-relevant features (co-features) RGB-specific noise and DVS-specific noise. The co-features represent the full information from both modalities that is relevant to the RL task; the two noise components each constrained by a data reconstruction loss to avoid information leak are contrasted with the co-features to maximize their difference. Extensive experiments demonstrate that by explicitly separating the different types of information our approach achieves substantially improved policy performance compared to state-of-the-art approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Xu",
      "Peixi Peng",
      "Guang Tan",
      "Yuan Li",
      "Xinhai Xu",
      "Yonghong Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Islam_DiffuseMix_Label-Preserving_Data_Augmentation_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "DiffuseMix: Label-Preserving Data Augmentation with Diffusion Models",
    "volume": "main",
    "abstract": "Recently a number of image-mixing-based augmentation techniques have been introduced to improve the generalization of deep neural networks. In these techniques two or more randomly selected natural images are mixed together to generate an augmented image. Such methods may not only omit important portions of the input images but also introduce label ambiguities by mixing images across labels resulting in misleading supervisory signals. To address these limitations we propose DIFFUSEMIX a novel data augmentation technique that leverages a diffusion model to reshape training images supervised by our bespoke conditional prompts. First concatenation of a partial natural image and its generated counterpart is obtained which helps in avoiding the generation of unrealistic images or label ambiguities. Then to enhance resilience against adversarial attacks and improves safety measures a randomly selected structural pattern from a set of fractal images is blended into the concatenated image to form the final augmented image for training. Our empirical results on seven different datasets reveal that DIFFUSEMIX achieves superior performance compared to existing state- of-the-art methods on tasks including general classification fine-grained classification fine-tuning data scarcity and adversarial robustness",
    "checked": true,
    "id": "2ea61c0e925e2bdcb9fff0b5eb07eb015ac8fbd7",
    "semantic_title": "diffusemix: label-preserving data augmentation with diffusion models",
    "citation_count": 1,
    "authors": [
      "Khawar Islam",
      "Muhammad Zaigham Zaheer",
      "Arif Mahmood",
      "Karthik Nandakumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_PRDP_Proximal_Reward_Difference_Prediction_for_Large-Scale_Reward_Finetuning_of_CVPR_2024_paper.html": {
    "title": "PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models",
    "volume": "main",
    "abstract": "Reward finetuning has emerged as a promising approach to aligning foundation models with downstream objectives. Remarkable success has been achieved in the language domain by using reinforcement learning (RL) to maximize rewards that reflect human preference. However in the vision domain existing RL-based reward finetuning methods are limited by their instability in large-scale training rendering them incapable of generalizing to complex unseen prompts. In this paper we propose Proximal Reward Difference Prediction (PRDP) enabling stable black-box reward finetuning for diffusion models for the first time on large-scale prompt datasets with over 100K prompts. Our key innovation is the Reward Difference Prediction (RDP) objective that has the same optimal solution as the RL objective while enjoying better training stability. Specifically the RDP objective is a supervised regression objective that tasks the diffusion model with predicting the reward difference of generated image pairs from their denoising trajectories. We theoretically prove that the diffusion model that obtains perfect reward difference prediction is exactly the maximizer of the RL objective. We further develop an online algorithm with proximal updates to stably optimize the RDP objective. In experiments we demonstrate that PRDP can match the reward maximization ability of well-established RL-based methods in small-scale training. Furthermore through large-scale training on text prompts from the Human Preference Dataset v2 and the Pick-a-Pic v1 dataset PRDP achieves superior generation quality on a diverse set of complex unseen prompts whereas RL-based methods completely fail",
    "checked": true,
    "id": "87362cbd9039011e990511d4668f77de6c17a6ef",
    "semantic_title": "prdp: proximal reward difference prediction for large-scale reward finetuning of diffusion models",
    "citation_count": 3,
    "authors": [
      "Fei Deng",
      "Qifei Wang",
      "Wei Wei",
      "Tingbo Hou",
      "Matthias Grundmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_FREE_Faster_and_Better_Data-Free_Meta-Learning_CVPR_2024_paper.html": {
    "title": "FREE: Faster and Better Data-Free Meta-Learning",
    "volume": "main",
    "abstract": "Data-Free Meta-Learning (DFML) aims to extract knowledge from a collection of pre-trained models without requiring the original data presenting practical benefits in contexts constrained by data privacy concerns. Current DFML methods primarily focus on the data recovery from these pre-trained models. However they suffer from slow recovery speed and overlook gaps inherent in heterogeneous pre-trained models. In response to these challenges we introduce the Faster and Better Data-Free Meta-Learning (FREE) framework which contains: (i) a meta-generator for rapidly recovering training tasks from pre-trained models; and (ii) a meta-learner for generalizing to new unseen tasks. Specifically within the module Faster Inversion via Meta-Generator each pre-trained model is perceived as a distinct task. The meta-generator can rapidly adapt to a specific task in just five steps significantly accelerating the data recovery. Furthermore we propose Better Generalization via Meta-Learner and introduce an implicit gradient alignment algorithm to optimize the meta-learner. This is achieved as aligned gradient directions alleviate potential conflicts among tasks from heterogeneous pre-trained models. Empirical experiments on multiple benchmarks affirm the superiority of our approach marking a notable speed-up (20x) and performance enhancement (1.42% 4.78%) in comparison to the state-of-the-art",
    "checked": true,
    "id": "23cde0fddb6e5e72fdb9c4532ce2d2dff48dd6ca",
    "semantic_title": "free: faster and better data-free meta-learning",
    "citation_count": 0,
    "authors": [
      "Yongxian Wei",
      "Zixuan Hu",
      "Zhenyi Wang",
      "Li Shen",
      "Chun Yuan",
      "Dacheng Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Bayesian_Diffusion_Models_for_3D_Shape_Reconstruction_CVPR_2024_paper.html": {
    "title": "Bayesian Diffusion Models for 3D Shape Reconstruction",
    "volume": "main",
    "abstract": "We present Bayesian Diffusion Models (BDM) a prediction algorithm that performs effective Bayesian inference by tightly coupling the top-down (prior) information with the bottom-up (data-driven) procedure via joint diffusion processes. We demonstrate the application of BDM on the 3D shape reconstruction task. Compared to standard deep learning data-driven approaches relying on supervised data our BDM can bring in rich prior information trained in an unsupervised manner to improve the bottom-up 3D reconstruction. As opposed to the traditional Bayesian frameworks where explicitly learned prior and data-driven distributions are required for gradient computation and combination BDM performs a seamless fusion of the two via coupled diffusion processes with learned gradient computation networks. The specialty of our Bayesian Diffusion Models (BDM) lies in its capability to engage the active and effective information exchange and fusion of the top-down and bottom-up processes where each itself is a diffusion process. We demonstrate state-of-the-art results on both synthetic and real-world benchmarks for 3D shape reconstruction. Project link: https://mlpc-ucsd.github.io/BDM",
    "checked": true,
    "id": "f440d229cd42d35290e1c64cfb13a4ee96c22eea",
    "semantic_title": "bayesian diffusion models for 3d shape reconstruction",
    "citation_count": 0,
    "authors": [
      "Haiyang Xu",
      "Yu Lei",
      "Zeyuan Chen",
      "Xiang Zhang",
      "Yue Zhao",
      "Yilin Wang",
      "Zhuowen Tu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Task-Customized_Mixture_of_Adapters_for_General_Image_Fusion_CVPR_2024_paper.html": {
    "title": "Task-Customized Mixture of Adapters for General Image Fusion",
    "volume": "main",
    "abstract": "General image fusion aims at integrating important information from multi-source images. However due to the significant cross-task gap the respective fusion mechanism varies considerably in practice resulting in limited performance across subtasks. To handle this problem we propose a novel task-customized mixture of adapters (TC-MoA) for general image fusion adaptively prompting various fusion tasks in a unified model. We borrow the insight from the mixture of experts (MoE) taking the experts as efficient tuning adapters to prompt a pre-trained foundation model. These adapters are shared across different tasks and constrained by mutual information regularization ensuring compatibility with different tasks while complementarity for multi-source images. The task-specific routing networks customize these adapters to extract task-specific information from different sources with dynamic dominant intensity performing adaptive visual feature prompt fusion. Notably our TC-MoA controls the dominant intensity bias for different fusion tasks successfully unifying multiple fusion tasks in a single model. Extensive experiments show that TC-MoA outperforms the competing approaches in learning commonalities while retaining compatibility for general image fusion (multi-modal multi-exposure and multi-focus) and also demonstrating striking controllability on more generalization experiments. The code is available at https://github.com/YangSun22/TC-MoA",
    "checked": true,
    "id": "4a87a17d8a7051abd8801f0bb73f013c7b40e59c",
    "semantic_title": "task-customized mixture of adapters for general image fusion",
    "citation_count": 2,
    "authors": [
      "Pengfei Zhu",
      "Yang Sun",
      "Bing Cao",
      "Qinghua Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_Bi-SSC_Geometric-Semantic_Bidirectional_Fusion_for_Camera-based_3D_Semantic_Scene_Completion_CVPR_2024_paper.html": {
    "title": "Bi-SSC: Geometric-Semantic Bidirectional Fusion for Camera-based 3D Semantic Scene Completion",
    "volume": "main",
    "abstract": "Camera-based Semantic Scene Completion (SSC) is to infer the full geometry of objects and scenes from only 2D images. The task is particularly challenging for those invisible areas due to the inherent occlusions and lighting ambiguity. Existing works ignore the information missing or ambiguous in those shaded and occluded areas resulting in distorted geometric prediction. To address this issue we propose a novel method Bi-SSC bidirectional geometric semantic fusion for camera-based 3D semantic scene completion. The key insight is to use the neighboring structure of objects in the image and the spatial differences from different perspectives to compensate for the lack of information in occluded areas. Specifically we introduce a spatial sensory fusion module with multiple association attention to improve semantic correlation in geometric distributions. This module works within single view and across stereo views to achieve global spatial consistency. Experimental results demonstrate that Bi-SSC outperforms state-of-the-art camera-based methods on SemanticKITTI particularly excelling in those invisible and shaded areas",
    "checked": false,
    "id": "74d0f0e82ef81462802ebc9aa2abb23703b04960",
    "semantic_title": "bridging stereo geometry and bev representation with reliable mutual interaction for semantic scene completion",
    "citation_count": 6,
    "authors": [
      "Yujie Xue",
      "Ruihui Li",
      "Fan Wu",
      "Zhuo Tang",
      "Kenli Li",
      "Mingxing Duan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_CrossKD_Cross-Head_Knowledge_Distillation_for_Object_Detection_CVPR_2024_paper.html": {
    "title": "CrossKD: Cross-Head Knowledge Distillation for Object Detection",
    "volume": "main",
    "abstract": "Knowledge Distillation (KD) has been validated as an effective model compression technique for learning compact object detectors. Existing state-of-the-art KD methods for object detection are mostly based on feature imitation. In this paper we present a general and effective prediction mimicking distillation scheme called CrossKD which delivers the intermediate features of the student's detection head to the teacher's detection head. The resulting cross-head predictions are then forced to mimic the teacher's predictions. This manner relieves the student's head from receiving contradictory supervision signals from the annotations and the teacher's predictions greatly improving the student's detection performance. Moreover as mimicking the teacher's predictions is the target of KD CrossKD offers more task-oriented information in contrast with feature imitation. On MS COCO with only prediction mimicking losses applied our CrossKD boosts the average precision of GFL ResNet-50 with 1x training schedule from 40.2 to 43.7 outperforming all existing KD methods. In addition our method also works well when distilling detectors with heterogeneous backbones",
    "checked": true,
    "id": "d263c8efdb9fe1a14c249461dc06353814648f32",
    "semantic_title": "crosskd: cross-head knowledge distillation for object detection",
    "citation_count": 4,
    "authors": [
      "Jiabao Wang",
      "Yuming Chen",
      "Zhaohui Zheng",
      "Xiang Li",
      "Ming-Ming Cheng",
      "Qibin Hou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Bi-level_Learning_of_Task-Specific_Decoders_for_Joint_Registration_and_One-Shot_CVPR_2024_paper.html": {
    "title": "Bi-level Learning of Task-Specific Decoders for Joint Registration and One-Shot Medical Image Segmentation",
    "volume": "main",
    "abstract": "One-shot medical image segmentation (MIS) aims to cope with the expensive time-consuming and inherent human bias annotations. One prevalent method to address one-shot MIS is joint registration and segmentation (JRS) with a shared encoder which mainly explores the voxel-wise correspondence between the labeled data and unlabeled data for better segmentation. However this method omits underlying connections between task-specific decoders for segmentation and registration leading to unstable training. In this paper we propose a novel Bi-level Learning of Task-Specific Decoders for one-shot MIS employing a pretrained fixed shared encoder that is proved to be more quickly adapted to brand-new datasets than existing JRS without fixed shared encoder paradigm. To be more specific we introduce a bi-level optimization training strategy considering registration as a major objective and segmentation as a learnable constraint by leveraging inter-task coupling dependencies. Furthermore we design an appearance conformity constraint strategy that learns the backward transformations generating the fake labeled data used to perform data augmentation instead of the labeled image to avoid performance degradation caused by inconsistent styles between unlabeled data and labeled data in previous methods. Extensive experiments on the brain MRI task across ABIDE ADNI and PPMI datasets demonstrate that the proposed Bi-JROS outperforms state-of-the-art one-shot MIS methods for both segmentation and registration tasks. The code will be available at https://github.com/Coradlut/Bi-JROS",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Fan",
      "Xiaolin Wang",
      "Jiaxin Gao",
      "Jia Wang",
      "Zhongxuan Luo",
      "Risheng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Scheibenreif_Parameter_Efficient_Self-Supervised_Geospatial_Domain_Adaptation_CVPR_2024_paper.html": {
    "title": "Parameter Efficient Self-Supervised Geospatial Domain Adaptation",
    "volume": "main",
    "abstract": "As large-scale foundation models become publicly available for different domains efficiently adapting them to individual downstream applications and additional data modalities has turned into a central challenge. For example foundation models for geospatial and satellite remote sensing applications are commonly trained on large optical RGB or multi-spectral datasets although data from a wide variety of heterogeneous sensors are available in the remote sensing domain. This leads to significant discrepancies between pre-training and downstream target data distributions for many important applications. Fine-tuning large foundation models to bridge that gap incurs high computational cost and can be infeasible when target datasets are small. In this paper we address the question of how large pre-trained foundational transformer models can be efficiently adapted to downstream remote sensing tasks involving different data modalities or limited dataset size. We present a self-supervised adaptation method that boosts downstream linear evaluation accuracy of different foundation models by 4-6% (absolute) across 8 remote sensing datasets while outperforming full fine-tuning when training only 1-2% of the model parameters. Our method significantly improves label efficiency and increases few-shot accuracy by 6-10% on different datasets",
    "checked": false,
    "id": "f142d9058f22f1f7dcb1a5a0a262690c6600887e",
    "semantic_title": "lleda - lifelong self-supervised domain adaptation",
    "citation_count": 2,
    "authors": [
      "Linus Scheibenreif",
      "Michael Mommert",
      "Damian Borth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Defense_without_Forgetting_Continual_Adversarial_Defense_with_Anisotropic__Isotropic_CVPR_2024_paper.html": {
    "title": "Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay",
    "volume": "main",
    "abstract": "Deep neural networks have demonstrated susceptibility to adversarial attacks. Adversarial defense techniques often focus on one-shot setting to maintain robustness against attack. However new attacks can emerge in sequences in real-world deployment scenarios. As a result it is crucial for a defense model to constantly adapt to new attacks but the adaptation process can lead to catastrophic forgetting of previously defended against attacks. In this paper we discuss for the first time the concept of continual adversarial defense under a sequence of attacks and propose a lifelong defense baseline called Anisotropic & Isotropic Replay (AIR) which offers three advantages: (1) Isotropic replay ensures model consistency in the neighborhood distribution of new data indirectly aligning the output preference between old and new tasks. (2) Anisotropic replay enables the model to learn a compromise data manifold with fresh mixed semantics for further replay constraints and potential future attacks. (3) A straightforward regularizer mitigates the 'plasticity-stability' trade-off by aligning model output between new and old tasks. Experiment results demonstrate that AIR can approximate or even exceed the empirical performance upper bounds achieved by Joint Training",
    "checked": true,
    "id": "0649abd6cb56de09549e00b88072fc201d840224",
    "semantic_title": "defense without forgetting: continual adversarial defense with anisotropic & isotropic pseudo replay",
    "citation_count": 0,
    "authors": [
      "Yuhang Zhou",
      "Zhongyun Hua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kong_EscherNet_A_Generative_Model_for_Scalable_View_Synthesis_CVPR_2024_paper.html": {
    "title": "EscherNet: A Generative Model for Scalable View Synthesis",
    "volume": "main",
    "abstract": "We introduce EscherNet a multi-view conditioned diffusion model for view synthesis. EscherNet learns implicit and generative 3D representations coupled with a specialised camera positional encoding allowing precise and continuous relative control of the camera transformation between an arbitrary number of reference and target views. EscherNet offers exceptional generality flexibility and scalability in view synthesis --- it can generate more than 100 consistent target views simultaneously on a single consumer-grade GPU despite being trained with a fixed number of 3 reference views to 3 target views. As a result EscherNet not only addresses zero-shot novel view synthesis but also naturally unifies single- and multi-image 3D reconstruction combining these diverse tasks into a single cohesive framework. Our extensive experiments demonstrate that EscherNet achieves state-of-the-art performance in multiple benchmarks even when compared to methods specifically tailored for each individual problem. This remarkable versatility opens up new directions for designing scalable neural architectures for 3D vision. Project page: https://kxhit.github.io/EscherNet",
    "checked": true,
    "id": "41652069c6a9c26e1366c8146005478ebd1e4cb0",
    "semantic_title": "eschernet: a generative model for scalable view synthesis",
    "citation_count": 10,
    "authors": [
      "Xin Kong",
      "Shikun Liu",
      "Xiaoyang Lyu",
      "Marwan Taher",
      "Xiaojuan Qi",
      "Andrew J. Davison"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_MeaCap_Memory-Augmented_Zero-shot_Image_Captioning_CVPR_2024_paper.html": {
    "title": "MeaCap: Memory-Augmented Zero-shot Image Captioning",
    "volume": "main",
    "abstract": "Zero-shot image captioning (IC) without well-paired image-text data can be categorized into two main types: training-free and text-only-training methods. While both types integrate pre-trained vision-language models such as CLIP for image-text similarity evaluation and a pre-trained language model (LM) for caption generation their distinction lies in the utilization of textual corpus for LM training. Despite achieving promising performance on certain metrics existing methods commonly suffer from drawbacks. Training-free methods often generate hallucinations whereas text-only-training methods may lack generalization capability. To address these challenges we propose a novel Memory-Augmented zero-shot image Captioning framework (MeaCap). This framework equipped with a textual memory incorporates a retrieve-then-filter module to extract key concepts highly relevant to the image. By leveraging our proposed memory-augmented visual-related fusion score within a keywords-to-sentence LM MeaCap generates concept-centered captions that exhibit high consistency with the image with reduced hallucinations and enriched world knowledge. MeaCap achieves state-of-the-art performance across various zero-shot IC settings. Our code is publicly available at https://github.com/joeyz0z/MeaCap",
    "checked": true,
    "id": "70faf1731707ddb329877031a00d4b262902ba3c",
    "semantic_title": "meacap: memory-augmented zero-shot image captioning",
    "citation_count": 0,
    "authors": [
      "Zequn Zeng",
      "Yan Xie",
      "Hao Zhang",
      "Chiyu Chen",
      "Bo Chen",
      "Zhengjue Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Artist-Friendly_Relightable_and_Animatable_Neural_Heads_CVPR_2024_paper.html": {
    "title": "Artist-Friendly Relightable and Animatable Neural Heads",
    "volume": "main",
    "abstract": "An increasingly common approach for creating photo-realistic digital avatars is through the use of volumetric neural fields. The original neural radiance field (NeRF) allowed for impressive novel view synthesis of static heads when trained on a set of multi-view images and follow up methods showed that these neural representations can be extended to dynamic avatars. Recently new variants also surpassed the usual drawback of baked-in illumination in neural representations showing that static neural avatars can be relit in any environment. In this work we simultaneously tackle both the motion and illumination problem proposing a new method for relightable and animatable neural heads. Our method builds on a proven dynamic avatar approach based on a mixture of volumetric primitives combined with a recently-proposed lightweight hardware setup for relightable neural fields and includes a novel architecture that allows relighting dynamic neural avatars performing unseen expressions in any environment even with nearfield illumination and viewpoints",
    "checked": true,
    "id": "f5e2f8bac28a9da6547f854f650831ba121e8d7e",
    "semantic_title": "artist-friendly relightable and animatable neural heads",
    "citation_count": 0,
    "authors": [
      "Yingyan Xu",
      "Prashanth Chandran",
      "Sebastian Weiss",
      "Markus Gross",
      "Gaspard Zoss",
      "Derek Bradley"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ai_Elite360D_Towards_Efficient_360_Depth_Estimation_via_Semantic-_and_Distance-Aware_CVPR_2024_paper.html": {
    "title": "Elite360D: Towards Efficient 360 Depth Estimation via Semantic- and Distance-Aware Bi-Projection Fusion",
    "volume": "main",
    "abstract": "360 depth estimation has recently received great attention for 3D reconstruction owing to its omnidirectional field of view (FoV). Recent approaches are predominantly focused on cross-projection fusion with geometry-based re-projection: they fuse 360 images with equirectangular projection (ERP) and another projection type e.g. cubemap projection to estimate depth with the ERP format. However these methods suffer from 1) limited local receptive fields making it hardly possible to capture large FoV scenes and 2) prohibitive computational cost caused by the complex cross-projection fusion module design. In this paper we propose Elite360D a novel framework that inputs the ERP image and icosahedron projection (ICOSAP) point set which is undistorted and spatially continuous. Elite360D is superior in its capacity in learning a representation from a local-with-global perspective. With a flexible ERP image encoder it includes an ICOSAP point encoder and a Bi-projection Bi-attention Fusion (B2F) module (totally 1M parameters). Specifically the ERP image encoder can take various perspective image-trained backbones (e.g. ResNet Transformer) to extract local features. The point encoder extracts the global features from the ICOSAP. Then the B2F module captures the semantic- and distance-aware dependencies between each pixel of the ERP feature and the entire ICOSAP feature set. Without specific backbone design and obvious computational cost increase Elite360D outperforms the prior arts on several benchmark datasets",
    "checked": true,
    "id": "c26aea5ec852c374e672dc0de7f207ee76c76c3d",
    "semantic_title": "elite360d: towards efficient 360 depth estimation via semantic- and distance-aware bi-projection fusion",
    "citation_count": 0,
    "authors": [
      "Hao Ai",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bao_From_Feature_to_Gaze_A_Generalizable_Replacement_of_Linear_Layer_CVPR_2024_paper.html": {
    "title": "From Feature to Gaze: A Generalizable Replacement of Linear Layer for Gaze Estimation",
    "volume": "main",
    "abstract": "Deep-learning-based gaze estimation approaches often suffer from notable performance degradation in unseen target domains. One of the primary reasons is that the Fully Connected layer is highly prone to overfitting when mapping the high-dimensional image feature to 3D gaze. In this paper we propose Analytical Gaze Generalization framework (AGG) to improve the generalization ability of gaze estimation models without touching target domain data. The AGG consists of two modules the Geodesic Projection Module (GPM) and the Sphere-Oriented Training (SOT). GPM is a generalizable replacement of FC layer which projects high-dimensional image features to 3D space analytically to extract the principle components of gaze. Then we propose Sphere-Oriented Training (SOT) to incorporate the GPM into the training process and further improve cross-domain performances. Experimental results demonstrate that the AGG effectively alleviate the overfitting problem and consistently improves the cross-domain gaze estimation accuracy in 12 cross-domain settings without requiring any target domain data. The insight from the Analytical Gaze Generalization framework has the potential to benefit other regression tasks with physical meanings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Bao",
      "Feng Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dai_Curriculum_Point_Prompting_for_Weakly-Supervised_Referring_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Curriculum Point Prompting for Weakly-Supervised Referring Image Segmentation",
    "volume": "main",
    "abstract": "Referring image segmentation (RIS) aims to precisely segment referents in images through corresponding natural language expressions yet relying on cost-intensive mask annotations. Weakly supervised RIS thus learns from image-text pairs to pixel-level semantics which is challenging for segmenting fine-grained masks. A natural approach to enhancing segmentation precision is to empower weakly supervised RIS with the image segmentation foundation model SAM. Nevertheless we observe that simply integrating SAM yields limited benefits and can even lead to performance regression due to the inevitable noise issues and challenges in excessive focus on object parts. In this paper we present an innovative framework Point PrompTing (PPT) incorporated with the proposed multi-source curriculum learning strategy to address these challenges. Specifically the core of PPT is a point generator that not only harnesses CLIP's text-image alignment capability and SAM's powerful mask generation ability but also generates negative point prompts to address the noisy and excessive focus issues inherently and effectively. In addition we introduce a curriculum learning strategy with object-centric images to help PPT gradually learn from simpler yet precise semantic alignment to more complex RIS. Experiments demonstrate that our PPT significantly and consistently outperforms prior weakly supervised techniques on mIoU by 11.34% 14.14% and 6.97% across RefCOCO RefCOCO+ and G-Ref respectively",
    "checked": true,
    "id": "c678debb68a68db3a33461a1682251139d0a649e",
    "semantic_title": "curriculum point prompting for weakly-supervised referring image segmentation",
    "citation_count": 1,
    "authors": [
      "Qiyuan Dai",
      "Sibei Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_EventDance_Unsupervised_Source-free_Cross-modal_Adaptation_for_Event-based_Object_Recognition_CVPR_2024_paper.html": {
    "title": "EventDance: Unsupervised Source-free Cross-modal Adaptation for Event-based Object Recognition",
    "volume": "main",
    "abstract": "In this paper we make the first attempt at achieving the cross-modal (i.e. image-to-events) adaptation for event-based object recognition without accessing any labeled source image data owning to privacy and commercial issues. Tackling this novel problem is non-trivial due to the novelty of event cameras and the distinct modality gap between images and events. In particular as only the source model is available a hurdle is how to extract the knowledge from the source model by only using the unlabeled target event data while achieving knowledge transfer. To this end we propose a novel framework dubbed EventDance for this unsupervised source-free cross-modal adaptation problem. Importantly inspired by event-to-video reconstruction methods we propose a reconstruction-based modality bridging (RMB) module which reconstructs intensity frames from events in a self-supervised manner. This makes it possible to build up the surrogate images to extract the knowledge (i.e. labels) from the source model. We then propose a multi-representation knowledge adaptation (MKA) module that transfers the knowledge to target models learning events with multiple representation types for fully exploring the spatiotemporal information of events. The two modules connecting the source and target models are mutually updated so as to achieve the best performance. Experiments on three benchmark datasets with two adaption settings show that EventDance is on par with prior methods utilizing the source data",
    "checked": true,
    "id": "63358e4af3f2d045bda3224864091a87e4a66eb9",
    "semantic_title": "eventdance: unsupervised source-free cross-modal adaptation for event-based object recognition",
    "citation_count": 3,
    "authors": [
      "Xu Zheng",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fang_CycleINR_Cycle_Implicit_Neural_Representation_for_Arbitrary-Scale_Volumetric_Super-Resolution_of_CVPR_2024_paper.html": {
    "title": "CycleINR: Cycle Implicit Neural Representation for Arbitrary-Scale Volumetric Super-Resolution of Medical Data",
    "volume": "main",
    "abstract": "In the realm of medical 3D data such as CT and MRI images prevalent anisotropic resolution is characterized by high intra-slice but diminished inter-slice resolution. The lowered resolution between adjacent slices poses challenges hindering optimal viewing experiences and impeding the development of robust downstream analysis algorithms. Various volumetric super-resolution algorithms aim to surmount these challenges enhancing inter-slice resolution and overall 3D medical imaging quality. However existing approaches confront inherent challenges: 1) often tailored to specific upsampling factors lacking flexibility for diverse clinical scenarios; 2) newly generated slices frequently suffer from over-smoothing degrading fine details and leading to inter-slice inconsistency. In response this study presents CycleINR a novel enhanced Implicit Neural Representation model for 3D medical data volumetric super-resolution. Leveraging the continuity of the learned implicit function the CycleINR model can achieve results with arbitrary up-sampling rates eliminating the need for separate training. Additionally we enhance the grid sampling in CycleINR with a local attention mechanism and mitigate over-smoothing by integrating cycle-consistent loss. We introduce a new metric Slice-wise Noise Level Inconsistency (SNLI) to quantitatively assess inter-slice noise level inconsistency. The effectiveness of our approach is demonstrated through image quality evaluations on an in-house dataset and a downstream task analysis on the Medical Segmentation Decathlon liver tumor dataset",
    "checked": true,
    "id": "201d0df0b95e998a6682fcff307230485166f083",
    "semantic_title": "cycleinr: cycle implicit neural representation for arbitrary-scale volumetric super-resolution of medical data",
    "citation_count": 0,
    "authors": [
      "Wei Fang",
      "Yuxing Tang",
      "Heng Guo",
      "Mingze Yuan",
      "Tony C. W. Mok",
      "Ke Yan",
      "Jiawen Yao",
      "Xin Chen",
      "Zaiyi Liu",
      "Le Lu",
      "Ling Zhang",
      "Minfeng Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Boosting_Image_Restoration_via_Priors_from_Pre-trained_Models_CVPR_2024_paper.html": {
    "title": "Boosting Image Restoration via Priors from Pre-trained Models",
    "volume": "main",
    "abstract": "Pre-trained models with large-scale training data such as CLIP and Stable Diffusion have demonstrated remarkable performance in various high-level computer vision tasks such as image understanding and generation from language descriptions. Yet their potential for low-level tasks such as image restoration remains relatively unexplored. In this paper we explore such models to enhance image restoration. As off-the-shelf features (OSF) from pre-trained models do not directly serve image restoration we propose to learn an additional lightweight module called Pre-Train-Guided Refinement Module (PTG-RM) to refine restoration results of a target restoration network with OSF. PTG-RM consists of two components Pre-Train-Guided Spatial-Varying Enhancement (PTG-SVE) and Pre-Train-Guided Channel-Spatial Attention (PTG-CSA). PTG-SVE enables optimal short- and long-range neural operations while PTG-CSA enhances spatial-channel attention for restoration-related learning. Extensive experiments demonstrate that PTG-RM with its compact size (<1M parameters) effectively enhances restoration performance of various models across different tasks including low-light enhancement deraining deblurring and denoising",
    "checked": true,
    "id": "fafe8e55740bc023354190e3c325b4f81f26bb0f",
    "semantic_title": "boosting image restoration via priors from pre-trained models",
    "citation_count": 0,
    "authors": [
      "Xiaogang Xu",
      "Shu Kong",
      "Tao Hu",
      "Zhe Liu",
      "Hujun Bao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_VRetouchEr_Learning_Cross-frame_Feature_Interdependence_with_Imperfection_Flow_for_Face_CVPR_2024_paper.html": {
    "title": "VRetouchEr: Learning Cross-frame Feature Interdependence with Imperfection Flow for Face Retouching in Videos",
    "volume": "main",
    "abstract": "Face Video Retouching is a complex task that often requires labor-intensive manual editing. Conventional image retouching methods perform less satisfactorily in terms of generalization performance and stability when applied to videos without exploiting the correlation among frames. To address this issue we propose a Video Retouching transformEr to remove facial imperfections in videos which is referred to as VRetouchEr. Specifically we estimate the apparent motion of imperfections between two consecutive frames and the resulting displacement vectors are used to refine the imperfection map which is synthesized from the current frame together with the corresponding encoder features. The flow-based imperfection refinement is critical for precise and stable retouching across frames. To leverage the temporal contextual information we inject the refined imperfection map into each transformer block for multi-frame masked attention computation such that we can capture the interdependence between the current frame and multiple reference frames. As a result the imperfection regions can be replaced with normal skin with high fidelity while at the same time keeping the other regions unchanged. Extensive experiments are performed to verify the superiority of VRetouchEr over state-of-the-art image retouching methods in terms of fidelity and stability",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Xue",
      "Le Jiang",
      "Lianxin Xie",
      "Si Wu",
      "Yong Xu",
      "Hau San Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ming_Transferable_Structural_Sparse_Adversarial_Attack_Via_Exact_Group_Sparsity_Training_CVPR_2024_paper.html": {
    "title": "Transferable Structural Sparse Adversarial Attack Via Exact Group Sparsity Training",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) are vulnerable to highly transferable adversarial attacks. Especially many studies have shown that sparse attacks pose a significant threat to DNNs on account of their exceptional imperceptibility. Current sparse attack methods mostly limit only the magnitude and number of perturbations while generally overlooking the location of the perturbations resulting in decreased performances on attack transferability. A subset of studies indicates that perturbations existing in the significant regions with rich classification-relevant features are more effective. Leveraging this insight we introduce the structural sparsity constraint in the framework of generative models to limit the perturbation positions. To ensure that the perturbations are generated towards classification-relevant regions we propose an exact group sparsity training method to learn pixel-level and group-level sparsity. For purpose of improving the effectiveness of sparse training we further put forward masked quantization network and multi-stage optimization algorithm in the training process. Utilizing CNNs as surrogate models extensive experiments demonstrate that our method has higher transferability in image classification attack compared to state-of-the-art methods at approximately same sparsity levels. In cross-model ViT object detection and semantic segmentation attack tasks we also achieve a better attack success rate. Code is available at https://github.com/MisterRpeng/EGS-TSSA",
    "checked": false,
    "id": "c8323e6906483bf18bed267306a5081bb843beb4",
    "semantic_title": "model sparsity can simplify machine unlearning",
    "citation_count": 25,
    "authors": [
      "Di Ming",
      "Peng Ren",
      "Yunlong Wang",
      "Xin Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Holistic_Autonomous_Driving_Understanding_by_Birds-Eye-View_Injected_Multi-Modal_Large_Models_CVPR_2024_paper.html": {
    "title": "Holistic Autonomous Driving Understanding by Bird's-Eye-View Injected Multi-Modal Large Models",
    "volume": "main",
    "abstract": "The rise of multimodal large language models (MLLMs) has spurred interest in language-based driving tasks. However existing research typically focuses on limited tasks and often omits key multi-view and temporal information which is crucial for robust autonomous driving. To bridge these gaps we introduce NuInstruct a novel dataset with 91K multi-view video-QA pairs across 17 subtasks where each task demands holistic information (e.g. temporal multi-view and spatial) significantly elevating the challenge level. To obtain NuInstruct we propose a novel SQL-based method to generate instruction-response pairs automatically which is inspired by the driving logical progression of humans. We further present BEV-InMLLM an end-to-end method for efficiently deriving instruction-aware Bird's-Eye-View (BEV) features language-aligned for large language models. BEV-InMLLM integrates multi-view spatial awareness and temporal semantics to enhance MLLMs' capabilities on NuInstruct tasks. Moreover our proposed BEV injection module is a plug-and-play method for existing MLLMs. Our experiments on NuInstruct demonstrate that BEV-InMLLM significantly outperforms existing MLLMs e.g 9% improvement on various tasks. We release our NuInstruct at https://github.com/xmed-lab/NuInstruct",
    "checked": true,
    "id": "cd49101103f73d88a4a3b368898066f03984c339",
    "semantic_title": "holistic autonomous driving understanding by bird's-eye-view injected multi-modal large models",
    "citation_count": 6,
    "authors": [
      "Xinpeng Ding",
      "Jianhua Han",
      "Hang Xu",
      "Xiaodan Liang",
      "Wei Zhang",
      "Xiaomeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Arbitrary-Scale_Image_Generation_and_Upsampling_using_Latent_Diffusion_Model_and_CVPR_2024_paper.html": {
    "title": "Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion Model and Implicit Neural Decoder",
    "volume": "main",
    "abstract": "Super-resolution (SR) and image generation are important tasks in computer vision and are widely adopted in real-world applications. Most existing methods however generate images only at fixed-scale magnification and suffer from over-smoothing and artifacts. Additionally they do not offer enough diversity of output images nor image consistency at different scales. Most relevant work applied Implicit Neural Representation (INR) to the denoising diffusion model to obtain continuous-resolution yet diverse and high-quality SR results. Since this model operates in the image space the larger the resolution of image is produced the more memory and inference time is required and it also does not maintain scale-specific consistency. We propose a novel pipeline that can super-resolve an input image or generate from a random noise a novel image at arbitrary scales. The method consists of a pretrained auto-encoder a latent diffusion model and an implicit neural decoder and their learning strategies. The proposed method adopts diffusion processes in a latent space thus efficient yet aligned with output image space decoded by MLPs at arbitrary scales. More specifically our arbitrary-scale decoder is designed by the symmetric decoder w/o up-scaling from the pretrained auto-encoder and Local Implicit Image Function (LIIF) in series. The latent diffusion process is learnt by the denoising and the alignment losses jointly. Errors in output images are backpropagated via the fixed decoder improving the quality of output images. In the extensive experiments using multiple public benchmarks on the two tasks i.e. image super-resolution and novel image generation at arbitrary scales the proposed method outperforms relevant methods in metrics of image quality diversity and scale consistency. It is significantly better than the relevant prior-art in the inference speed and memory usage",
    "checked": true,
    "id": "b5606209bd009530173ce8bb47ccd895c0176b68",
    "semantic_title": "arbitrary-scale image generation and upsampling using latent diffusion model and implicit neural decoder",
    "citation_count": 0,
    "authors": [
      "Jinseok Kim",
      "Tae-Kyun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ouasfi_Unsupervised_Occupancy_Learning_from_Sparse_Point_Cloud_CVPR_2024_paper.html": {
    "title": "Unsupervised Occupancy Learning from Sparse Point Cloud",
    "volume": "main",
    "abstract": "Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities encompassing a wide range from 3D shapes to images and audio. Within the realm of 3D shape representation Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry. However learning SDFs from 3D point clouds in the absence of ground truth supervision remains a very challenging task. In this paper we propose a method to infer occupancy fields instead of SDFs as they are easier to learn from sparse inputs. We leverage a margin-based uncertainty measure to differentiably sample from the decision boundary of the occupancy function and supervise the sampled boundary points using the input point cloud. We further stabilise the optimization process at the early stages of the training by biasing the occupancy function towards minimal entropy fields while maximizing its entropy at the input point cloud. Through extensive experiments and evaluations we illustrate the efficacy of our proposed method highlighting its capacity to improve implicit shape inference with respect to baselines and the state-of-the-art using synthetic and real data",
    "checked": true,
    "id": "3b527ed8c7e3d17eb9ef98d4a72e92de61d87036",
    "semantic_title": "unsupervised occupancy learning from sparse point cloud",
    "citation_count": 1,
    "authors": [
      "Amine Ouasfi",
      "Adnane Boukhayma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Extreme_Point_Supervised_Instance_Segmentation_CVPR_2024_paper.html": {
    "title": "Extreme Point Supervised Instance Segmentation",
    "volume": "main",
    "abstract": "This paper introduces a novel approach to learning instance segmentation using extreme points i.e. the topmost leftmost bottommost and rightmost points of each object. These points are readily available in the modern bounding box annotation process while offering strong clues for precise segmentation and thus allows to improve performance at the same annotation cost with box-supervised methods. Our work considers extreme points as a part of the true instance mask and propagates them to identify potential foreground and background points which are all together used for training a pseudo label generator. Then pseudo labels given by the generator are in turn used for supervised learning of our final model. On three public benchmarks our method significantly outperforms existing box-supervised methods further narrowing the gap with its fully supervised counterpart. In particular our model generates high-quality masks when a target object is separated into multiple parts where previous box-supervised methods often fail",
    "checked": true,
    "id": "387dbdcac7ed9f47d10572e38a07edc65faf6f7c",
    "semantic_title": "extreme point supervised instance segmentation",
    "citation_count": 0,
    "authors": [
      "Hyeonjun Lee",
      "Sehyun Hwang",
      "Suha Kwak"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ben-Shabat_3DInAction_Understanding_Human_Actions_in_3D_Point_Clouds_CVPR_2024_paper.html": {
    "title": "3DInAction: Understanding Human Actions in 3D Point Clouds",
    "volume": "main",
    "abstract": "We propose a novel method for 3D point cloud action recognition. Understanding human actions in RGB videos has been widely studied in recent years however its 3D point cloud counterpart remains under-explored despite the clear value that 3D information may bring. This is mostly due to the inherent limitation of the point cloud data modality---lack of structure permutation invariance and varying number of points---which makes it difficult to learn a spatio-temporal representation. To address this limitation we propose the 3DinAction pipeline that first estimates patches moving in time (t-patches) as a key building block alongside a hierarchical architecture that learns an informative spatio-temporal representation. We show that our method achieves improved performance on existing datasets including DFAUST and IKEA ASM. Code is publicly available at https://github.com/sitzikbs/3dincaction",
    "checked": true,
    "id": "ceda690b89d1ebaf2beee41c7905ba42e4a0b541",
    "semantic_title": "3dinaction: understanding human actions in 3d point clouds",
    "citation_count": 0,
    "authors": [
      "Yizhak Ben-Shabat",
      "Oren Shrout",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wimbauer_Cache_Me_if_You_Can_Accelerating_Diffusion_Models_through_Block_CVPR_2024_paper.html": {
    "title": "Cache Me if You Can: Accelerating Diffusion Models through Block Caching",
    "volume": "main",
    "abstract": "Diffusion models have recently revolutionized the field of image synthesis due to their ability to generate photorealistic images. However one of the major drawbacks of diffusion models is that the image generation process is costly. A large image-to-image network has to be applied many times to iteratively refine an image from random noise. While many recent works propose techniques to reduce the number of required steps they generally treat the underlying denoising network as a black box. In this work we investigate the behavior of the layers within the network and find that 1) the layers' output changes smoothly over time 2) the layers show distinct patterns of change and 3) the change from step to step is often very small. We hypothesize that many layer computations in the denoising network are redundant. Leveraging this we introduce Block Caching in which we reuse outputs from layer blocks of previous steps to speed up inference. Furthermore we propose a technique to automatically determine caching schedules based on each block's changes over timesteps. In our experiments we show through FID human evaluation and qualitative analysis that Block Caching allows to generate images with higher visual quality at the same computational cost. We demonstrate this for different state-of-the-art models (LDM and EMU) and solvers (DDIM and DPM)",
    "checked": true,
    "id": "feb49aec3ed748bb15c5375363b21f01baef8b24",
    "semantic_title": "cache me if you can: accelerating diffusion models through block caching",
    "citation_count": 9,
    "authors": [
      "Felix Wimbauer",
      "Bichen Wu",
      "Edgar Schoenfeld",
      "Xiaoliang Dai",
      "Ji Hou",
      "Zijian He",
      "Artsiom Sanakoyeu",
      "Peizhao Zhang",
      "Sam Tsai",
      "Jonas Kohler",
      "Christian Rupprecht",
      "Daniel Cremers",
      "Peter Vajda",
      "Jialiang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhan_MedM2G_Unifying_Medical_Multi-Modal_Generation_via_Cross-Guided_Diffusion_with_Visual_CVPR_2024_paper.html": {
    "title": "MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant",
    "volume": "main",
    "abstract": "Medical generative models acknowledged for their high-quality sample generation ability have accelerated the fast growth of medical applications. However recent works concentrate on separate medical generation models for distinct medical tasks and are restricted to inadequate medical multi-modal knowledge constraining medical comprehensive diagnosis. In this paper we propose MedM2G a Medical Multi-Modal Generative framework with the key innovation to align extract and generate medical multi-modal within a unified model. Extending beyond single or two medical modalities we efficiently align medical multi-modal through the central alignment approach in the unified space. Significantly our framework extracts valuable clinical knowledge by preserving the medical visual invariant of each imaging modal thereby enhancing specific medical information for multi-modal generation. By conditioning the adaptive cross-guided parameters into the multi-flow diffusion framework our model promotes flexible interactions among medical multi-modal for generation. MedM2G is the first medical generative model that unifies medical generation tasks of text-to-image image-to-text and unified generation of medical modalities (CT MRI X-ray). It performs 5 medical generation tasks across 10 datasets consistently outperforming various state-of-the-art works",
    "checked": true,
    "id": "291dddd5bd0150387af2990deeeb36aff91fcc74",
    "semantic_title": "medm2g: unifying medical multi-modal generation via cross-guided diffusion with visual invariant",
    "citation_count": 0,
    "authors": [
      "Chenlu Zhan",
      "Yu Lin",
      "Gaoang Wang",
      "Hongwei Wang",
      "Jian Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_SDDGR_Stable_Diffusion-based_Deep_Generative_Replay_for_Class_Incremental_Object_CVPR_2024_paper.html": {
    "title": "SDDGR: Stable Diffusion-based Deep Generative Replay for Class Incremental Object Detection",
    "volume": "main",
    "abstract": "In the field of class incremental learning (CIL) generative replay has become increasingly prominent as a method to mitigate the catastrophic forgetting alongside the continuous improvements in generative models. However its application in class incremental object detection (CIOD) has been significantly limited primarily due to the complexities of scenes involving multiple labels. In this paper we propose a novel approach called stable diffusion deep generative replay (SDDGR) for CIOD. Our method utilizes a diffusion-based generative model with pre-trained text-to-image diffusion networks to generate realistic and diverse synthetic images. SDDGR incorporates an iterative refinement strategy to produce high-quality images encompassing old classes. Additionally we adopt an L2 knowledge distillation technique to improve the retention of prior knowledge in synthetic images. Furthermore our approach includes pseudo-labeling for old objects within new task images preventing misclassification as background elements. Extensive experiments on the COCO 2017 dataset demonstrate that SDDGR significantly outperforms existing algorithms achieving a new state-of-the-art in various CIOD scenarios",
    "checked": true,
    "id": "ec4dea18648803f4cbdbf884470225d5fbdab204",
    "semantic_title": "sddgr: stable diffusion-based deep generative replay for class incremental object detection",
    "citation_count": 1,
    "authors": [
      "Junsu Kim",
      "Hoseong Cho",
      "Jihyeon Kim",
      "Yihalem Yimolal Tiruneh",
      "Seungryul Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Das_Neural_Parametric_Gaussians_for_Monocular_Non-Rigid_Object_Reconstruction_CVPR_2024_paper.html": {
    "title": "Neural Parametric Gaussians for Monocular Non-Rigid Object Reconstruction",
    "volume": "main",
    "abstract": "Reconstructing dynamic objects from monocular videos is a severely underconstrained and challenging problem and recent work has approached it in various directions. However owing to the ill-posed nature of this problem there has been no solution that can provide consistent high-quality novel views from camera positions that are significantly different from the training views. In this work we introduce Neural Parametric Gaussians (NPGs) to take on this challenge by imposing a two-stage approach: first we fit a low-rank neural deformation model which then is used as regularization for non-rigid reconstruction in the second stage. The first stage learns the object's deformations such that it preserves consistency in novel views. The second stage obtains high reconstruction quality by optimizing 3D Gaussians that are driven by the coarse model. To this end we introduce a local 3D Gaussian representation where temporally shared Gaussians are anchored in and deformed by local oriented volumes. The resulting combined model can be rendered as radiance fields resulting in high-quality photo-realistic reconstructions of the non-rigidly deforming objects. We demonstrate that NPGs achieve superior results compared to previous works especially in challenging scenarios with few multi-view cues",
    "checked": true,
    "id": "b8f37149729b919bb4f972a88665e6f66976997a",
    "semantic_title": "neural parametric gaussians for monocular non-rigid object reconstruction",
    "citation_count": 13,
    "authors": [
      "Devikalyan Das",
      "Christopher Wewer",
      "Raza Yunus",
      "Eddy Ilg",
      "Jan Eric Lenssen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Physical_3D_Adversarial_Attacks_against_Monocular_Depth_Estimation_in_Autonomous_CVPR_2024_paper.html": {
    "title": "Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving",
    "volume": "main",
    "abstract": "Deep learning-based monocular depth estimation (MDE) extensively applied in autonomous driving is known to be vulnerable to adversarial attacks. Previous physical attacks against MDE models rely on 2D adversarial patches so they only affect a small localized region in the MDE map but fail under various viewpoints. To address these limitations we propose 3D Depth Fool (3D^2Fool) the first 3D texture-based adversarial attack against MDE models. 3D^2Fool is specifically optimized to generate 3D adversarial textures agnostic to model types of vehicles and to have improved robustness in bad weather conditions such as rain and fog. Experimental results validate the superior performance of our 3D^2Fool across various scenarios including vehicles MDE models weather conditions and viewpoints. Real-world experiments with printed 3D textures on physical vehicle models further demonstrate that our 3D^2Fool can cause an MDE error of over 10 meters",
    "checked": true,
    "id": "b1d8a5496b18159a2e15865eb51eb34debadf273",
    "semantic_title": "physical 3d adversarial attacks against monocular depth estimation in autonomous driving",
    "citation_count": 1,
    "authors": [
      "Junhao Zheng",
      "Chenhao Lin",
      "Jiahao Sun",
      "Zhengyu Zhao",
      "Qian Li",
      "Chao Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yamaguchi_Adaptive_Random_Feature_Regularization_on_Fine-tuning_Deep_Neural_Networks_CVPR_2024_paper.html": {
    "title": "Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks",
    "volume": "main",
    "abstract": "While fine-tuning is a de facto standard method for training deep neural networks it still suffers from overfitting when using small target datasets. Previous methods improve fine-tuning performance by maintaining knowledge of the source datasets or introducing regularization terms such as contrastive loss. However these methods require auxiliary source information (e.g. source labels or datasets) or heavy additional computations. In this paper we propose a simple method called adaptive random feature regularization (AdaRand). AdaRand helps the feature extractors of training models to adaptively change the distribution of feature vectors for downstream classification tasks without auxiliary source information and with reasonable computation costs. To this end AdaRand minimizes the gap between feature vectors and random reference vectors that are sampled from class conditional Gaussian distributions. Furthermore AdaRand dynamically updates the conditional distribution to follow the currently updated feature extractors and balance the distance between classes in feature spaces. Our experiments show that AdaRand outperforms the other fine-tuning regularization requiring auxiliary source information and heavy computation costs",
    "checked": true,
    "id": "1140139f9b0ef98cbacc4bcd6e4899e509f42607",
    "semantic_title": "adaptive random feature regularization on fine-tuning deep neural networks",
    "citation_count": 0,
    "authors": [
      "Shin'ya Yamaguchi",
      "Sekitoshi Kanai",
      "Kazuki Adachi",
      "Daiki Chijiwa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_PH-Net_Semi-Supervised_Breast_Lesion_Segmentation_via_Patch-wise_Hardness_CVPR_2024_paper.html": {
    "title": "PH-Net: Semi-Supervised Breast Lesion Segmentation via Patch-wise Hardness",
    "volume": "main",
    "abstract": "We present a novel semi-supervised framework for breast ultrasound (BUS) image segmentation which is a very challenging task owing to (1) large scale and shape variations of breast lesions and (2) extremely ambiguous boundaries caused by massive speckle noise and artifacts in BUS images. While existing models achieved certain progress in this task we believe the main bottleneck nowadays for further improvement is that we still cannot deal with hard cases well. Our framework aims to break through this bottleneck which includes two innovative components: an adaptive patch augmentation scheme and a hard-patch contrastive learning module. We first identify hard patches by computing the average entropy of each patch and then shield hard patches to prevent them from being cropped out while performing random patch cutmix. Such a scheme is able to prevent hard regions from being inadequately trained under strong augmentation. We further develop a new hard-patch contrastive learning algorithm to direct model attention to hard regions by applying extra contrast to pixels in hard patches further improving segmentation performance on hard cases. We demonstrate the superiority of our framework to state-of-the-art approaches on two famous BUS datasets achieving better performance under different labeling conditions. The code is available at https://github.com/jjjsyyy/PH-Net",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyao Jiang",
      "Huisi Wu",
      "Junyang Chen",
      "Qin Zhang",
      "Jing Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ai_Multimodal_Prompt_Perceiver_Empower_Adaptiveness_Generalizability_and_Fidelity_for_All-in-One_CVPR_2024_paper.html": {
    "title": "Multimodal Prompt Perceiver: Empower Adaptiveness Generalizability and Fidelity for All-in-One Image Restoration",
    "volume": "main",
    "abstract": "Despite substantial progress all-in-one image restoration (IR) grapples with persistent challenges in handling intricate real-world degradations. This paper introduces MPerceiver: a novel multimodal prompt learning approach that harnesses Stable Diffusion (SD) priors to enhance adaptiveness generalizability and fidelity for all-in-one image restoration. Specifically we develop a dual-branch module to master two types of SD prompts: textual for holistic representation and visual for multiscale detail representation. Both prompts are dynamically adjusted by degradation predictions from the CLIP image encoder enabling adaptive responses to diverse unknown degradations. Moreover a plug-in detail refinement module improves restoration fidelity via direct encoder-to-decoder information transformation. To assess our method MPerceiver is trained on 9 tasks for all-in-one IR and outperforms state-of-the-art task-specific methods across many tasks. Post multitask pre-training MPerceiver attains a generalized representation in low-level vision exhibiting remarkable zero-shot and few-shot capabilities in unseen tasks. Extensive experiments on 16 IR tasks underscore the superiority of MPerceiver in terms of adaptiveness generalizability and fidelity",
    "checked": false,
    "id": "64243671eaba33ed0c8d4794889feb6ec48640b9",
    "semantic_title": "multimodal prompt perceiver: empower adaptiveness, generalizability and fidelity for all-in-one image restoration",
    "citation_count": 6,
    "authors": [
      "Yuang Ai",
      "Huaibo Huang",
      "Xiaoqiang Zhou",
      "Jiexiang Wang",
      "Ran He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_ExACT_Language-guided_Conceptual_Reasoning_and_Uncertainty_Estimation_for_Event-based_Action_CVPR_2024_paper.html": {
    "title": "ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action Recognition and More",
    "volume": "main",
    "abstract": "Event cameras have recently been shown beneficial for practical vision tasks such as action recognition thanks to their high temporal resolution power efficiency and reduced privacy concerns. However current research is hindered by 1) the difficulty in processing events because of their prolonged duration and dynamic actions with complex and ambiguous semantics and 2) the redundant action depiction of the event frame representation with fixed stacks. We find language naturally conveys abundant semantic information rendering it stunningly superior in reducing semantic uncertainty. In light of this we propose ExACT a novel approach that for the first time tackles event-based action recognition from a cross-modal conceptualizing perspective. Our ExACT brings two technical contributions. Firstly we propose an adaptive fine-grained event (AFE) representation to adaptively filter out the repeated events for the stationary objects while preserving dynamic ones. This subtly enhances the performance of ExACT without extra computational cost. Then we propose a conceptual reasoning-based uncertainty estimation module which simulates the recognition process to enrich the semantic representation. In particular conceptual reasoning builds the temporal relation based on the action semantics and uncertainty estimation tackles the semantic uncertainty of actions based on the distributional representation. Experiments show that our ExACT achieves superior recognition accuracy of 94.83%(+2.23%) 90.10%(+37.47%) and 67.24% on PAF HARDVS and our SeAct datasets respectively",
    "checked": true,
    "id": "8304244ae39d7db6d4a4b08046c26febf9f9e941",
    "semantic_title": "exact: language-guided conceptual reasoning and uncertainty estimation for event-based action recognition and more",
    "citation_count": 0,
    "authors": [
      "Jiazhou Zhou",
      "Xu Zheng",
      "Yuanhuiyi Lyu",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Color_Shift_Estimation-and-Correction_for_Image_Enhancement_CVPR_2024_paper.html": {
    "title": "Color Shift Estimation-and-Correction for Image Enhancement",
    "volume": "main",
    "abstract": "Images captured under sub-optimal illumination conditions may contain both over- and under-exposures. We observe that over- and over-exposed regions display opposite color tone distribution shifts which may not be easily normalized in joint modeling as they usually do not have \"normal-exposed\" regions/pixels as reference. In this paper we propose a novel method to enhance images with both over- and under-exposures by learning to estimate and correct such color shifts. Specifically we first derive the color feature maps of the brightened and darkened versions of the input image via a UNet-based network followed by a pseudo-normal feature generator to produce pseudo-normal color feature maps. We then propose a novel COlor Shift Estimation (COSE) module to estimate the color shifts between the derived brightened (or darkened) color feature maps and the pseudo-normal color feature maps. The COSE module corrects the estimated color shifts of the over- and under-exposed regions separately. We further propose a novel COlor MOdulation (COMO) module to modulate the separately corrected colors in the over- and under-exposed regions to produce the enhanced image. Comprehensive experiments show that our method outperforms existing approaches",
    "checked": true,
    "id": "5587fd51e7eb4fb2baff4a15affab2b1d6c49008",
    "semantic_title": "color shift estimation-and-correction for image enhancement",
    "citation_count": 0,
    "authors": [
      "Yiyu Li",
      "Ke Xu",
      "Gerhard Petrus Hancke",
      "Rynson W.H. Lau"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kwon_Improving_Visual_Recognition_with_Hyperbolical_Visual_Hierarchy_Mapping_CVPR_2024_paper.html": {
    "title": "Improving Visual Recognition with Hyperbolical Visual Hierarchy Mapping",
    "volume": "main",
    "abstract": "Visual scenes are naturally organized in a hierarchy where a coarse semantic is recursively comprised of several fine details. Exploring such a visual hierarchy is crucial to recognize the complex relations of visual elements leading to a comprehensive scene understanding. In this paper we propose a Visual Hierarchy Mapper (Hi-Mapper) a novel approach for enhancing the structured understanding of the pre-trained Deep Neural Networks (DNNs). Hi-Mapper investigates the hierarchical organization of the visual scene by 1) pre-defining a hierarchy tree through the encapsulation of probability densities; and 2) learning the hierarchical relations in hyperbolic space with a novel hierarchical contrastive loss. The pre-defined hierarchy tree recursively interacts with the visual features of the pre-trained DNNs through hierarchy decomposition and encoding procedures thereby effectively identifying the visual hierarchy and enhancing the recognition of an entire scene. Extensive experiments demonstrate that Hi-Mapper significantly enhances the representation capability of DNNs leading to an improved performance on various tasks including image classification and dense prediction tasks",
    "checked": true,
    "id": "47338c6409898c3e771704b01595648a9249d47d",
    "semantic_title": "improving visual recognition with hyperbolical visual hierarchy mapping",
    "citation_count": 0,
    "authors": [
      "Hyeongjun Kwon",
      "Jinhyun Jang",
      "Jin Kim",
      "Kwonyoung Kim",
      "Kwanghoon Sohn"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_ParameterNet_Parameters_Are_All_You_Need_for_Large-scale_Visual_Pretraining_CVPR_2024_paper.html": {
    "title": "ParameterNet: Parameters Are All You Need for Large-scale Visual Pretraining of Mobile Networks",
    "volume": "main",
    "abstract": "The large-scale visual pretraining has significantly improve the performance of large vision models. However we observe the low FLOPs pitfall that the existing low-FLOPs models cannot benefit from large-scale pretraining. In this paper we introduce a novel design principle termed ParameterNet aimed at augmenting the number of parameters in large-scale visual pretraining models while minimizing the increase in FLOPs. We leverage dynamic convolutions to incorporate additional parameters into the networks with only a marginal rise in FLOPs. The ParameterNet approach allows low-FLOPs networks to take advantage of large-scale visual pretraining. Furthermore we extend the ParameterNet concept to the language domain to enhance inference results while preserving inference speed. Experiments on the large-scale ImageNet-22K have shown the superiority of our ParameterNet scheme. For example ParameterNet-600M can achieve higher accuracy than the widely-used Swin Transformer (81.6% vs. 80.9%) and has much lower FLOPs (0.6G vs. 4.5G). The code will be released at https://parameternet.github.io/",
    "checked": true,
    "id": "a03a940371c44daf1ff0373aa8bab3a79581db7c",
    "semantic_title": "parameternet: parameters are all you need for large-scale visual pretraining of mobile networks",
    "citation_count": 0,
    "authors": [
      "Kai Han",
      "Yunhe Wang",
      "Jianyuan Guo",
      "Enhua Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ke_Repurposing_Diffusion-Based_Image_Generators_for_Monocular_Depth_Estimation_CVPR_2024_paper.html": {
    "title": "Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation",
    "volume": "main",
    "abstract": "Monocular depth estimation is a fundamental computer vision task. Recovering 3D depth from a single image is geometrically ill-posed and requires scene understanding so it is not surprising that the rise of deep learning has led to a breakthrough. The impressive progress of monocular depth estimators has mirrored the growth in model capacity from relatively modest CNNs to large Transformer architectures. Still monocular depth estimators tend to struggle when presented with images with unfamiliar content and layout since their knowledge of the visual world is restricted by the data seen during training and challenged by zero-shot generalization to new domains. This motivates us to explore whether the extensive priors captured in recent generative diffusion models can enable better more generalizable depth estimation. We introduce Marigold a method for affine-invariant monocular depth estimation that is derived from Stable Diffusion and retains its rich prior knowledge. The estimator can be fine-tuned in a couple of days on a single GPU using only synthetic training data. It delivers state-of-the-art performance across a wide range of datasets including over 20% performance gains in specific cases. Project page: https://marigoldmonodepth.github.io",
    "checked": true,
    "id": "c896257eea2cb25dc36dfc4d0d1f8812e68c8ce3",
    "semantic_title": "repurposing diffusion-based image generators for monocular depth estimation",
    "citation_count": 20,
    "authors": [
      "Bingxin Ke",
      "Anton Obukhov",
      "Shengyu Huang",
      "Nando Metzger",
      "Rodrigo Caye Daudt",
      "Konrad Schindler"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sumiyasu_Identifying_Important_Group_of_Pixels_using_Interactions_CVPR_2024_paper.html": {
    "title": "Identifying Important Group of Pixels using Interactions",
    "volume": "main",
    "abstract": "To better understand the behavior of image classifiers it is useful to visualize the contribution of individual pixels to the model prediction. In this study we propose a method MoXI(Model eXplanation by Interactions) that efficiently and accurately identifies a group of pixels with high prediction confidence. The proposed method employs game-theoretic concepts Shapley values and interactions taking into account the effects of individual pixels and the cooperative influence of pixels on model confidence. Theoretical analysis and experiments demonstrate that our method better identifies the pixels that are highly contributing to the model outputs than widely-used by Grad-CAM Attention rollout and Shapley value. While prior studies have suffered from the exponential computational cost in the computation of Shapley value and interactions we show that this can be reduced to quadratic cost for our task. The code is available at https://github.com/KosukeSumiyasu/MoXI",
    "checked": true,
    "id": "a29058d0487d78d738c521ab0b2abbd86e2e9032",
    "semantic_title": "identifying important group of pixels using interactions",
    "citation_count": 1,
    "authors": [
      "Kosuke Sumiyasu",
      "Kazuhiko Kawamoto",
      "Hiroshi Kera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Towards_Scalable_3D_Anomaly_Detection_and_Localization_A_Benchmark_via_CVPR_2024_paper.html": {
    "title": "Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via 3D Anomaly Synthesis and A Self-Supervised Learning Network",
    "volume": "main",
    "abstract": "Recently 3D anomaly detection a crucial problem involving fine-grained geometry discrimination is getting more attention. However the lack of abundant real 3D anomaly data limits the scalability of current models. To enable scalable anomaly data collection we propose a 3D anomaly synthesis pipeline to adapt existing large-scale 3D models for 3D anomaly detection. Specifically we construct a synthetic dataset i.e. Anomaly-ShapeNet based on ShapeNet. Anomaly-ShapeNet consists of 1600 point cloud samples under 40 categories which provides a rich and varied collection of data enabling efficient training and enhancing adaptability to industrial scenarios. Meanwhile to enable scalable representation learning for 3D anomaly localization we propose a self-supervised method i.e. Iterative Mask Reconstruction Network (IMRNet). During training we propose a geometry-aware sample module to preserve potentially anomalous local regions during point cloud down-sampling. Then we randomly mask out point patches and sent the visible patches to a transformer for reconstruction-based self-supervision. During testing the point cloud repeatedly goes through the Mask Reconstruction Network with each iteration's output becoming the next input. By merging and contrasting the final reconstructed point cloud with the initial input our method successfully locates anomalies. Experiments show that IMRNet outperforms previous state-of-the-art methods achieving 66.1% in I-AUC on our Anomaly-ShapeNet dataset and 72.5% in I-AUC on Real3D-AD dataset. Our benchmark will be released at https://github.com/Chopper233/Anomaly-ShapeNet",
    "checked": true,
    "id": "1548e6f03f933ee3ee248bdb4710b9f0e0da551c",
    "semantic_title": "towards scalable 3d anomaly detection and localization: a benchmark via 3d anomaly synthesis and a self-supervised learning network",
    "citation_count": 2,
    "authors": [
      "Wenqiao Li",
      "Xiaohao Xu",
      "Yao Gu",
      "Bozhong Zheng",
      "Shenghua Gao",
      "Yingna Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Cam4DOcc_Benchmark_for_Camera-Only_4D_Occupancy_Forecasting_in_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications",
    "volume": "main",
    "abstract": "Understanding how the surrounding environment changes is crucial for performing downstream tasks safely and reliably in autonomous driving applications. Recent occupancy estimation techniques using only camera images as input can provide dense occupancy representations of large-scale scenes based on the current observation. However they are mostly limited to representing the current 3D space and do not consider the future state of surrounding objects along the time axis. To extend camera-only occupancy estimation into spatiotemporal prediction we propose Cam4DOcc a new benchmark for camera-only 4D occupancy forecasting evaluating the surrounding scene changes in a near future. We build our benchmark based on multiple publicly available datasets including nuScenes nuScenes-Occupancy and Lyft-Level5 which provides sequential occupancy states of general movable and static objects as well as their 3D backward centripetal flow. To establish this benchmark for future research with comprehensive comparisons we introduce four baseline types from diverse camera-based perception and prediction implementations including a static-world occupancy model voxelization of point cloud prediction 2D-3D instance-based prediction and our proposed novel end-to-end 4D occupancy forecasting network. Furthermore the standardized evaluation protocol for preset multiple tasks is also provided to compare the performance of all the proposed baselines on present and future occupancy estimation with respect to objects of interest in autonomous driving scenarios. The dataset and our implementation of all four baselines in the proposed Cam4DOcc benchmark are released as open source at https://github.com/haomo-ai/Cam4DOcc",
    "checked": true,
    "id": "f690c4af9922dc5f76a17da48eb11567fafdf6cb",
    "semantic_title": "cam4docc: benchmark for camera-only 4d occupancy forecasting in autonomous driving applications",
    "citation_count": 5,
    "authors": [
      "Junyi Ma",
      "Xieyuanli Chen",
      "Jiawei Huang",
      "Jingyi Xu",
      "Zhen Luo",
      "Jintao Xu",
      "Weihao Gu",
      "Rui Ai",
      "Hesheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kara_DIOD_Self-Distillation_Meets_Object_Discovery_CVPR_2024_paper.html": {
    "title": "DIOD: Self-Distillation Meets Object Discovery",
    "volume": "main",
    "abstract": "Instance segmentation demands substantial labeling resources. This has prompted increased interest to explore the object discovery task as an unsupervised alternative. In particular promising results were achieved in localizing instances using motion supervision only. However the motion signal introduces complexities due to its inherent noise and sparsity which constrains the effectiveness of current methodologies. In the present paper we propose DIOD (self DIstillation meets Object Discovery) the first method that places the motion-guided object discovery within a framework of continuous improvement through knowledge distillation providing solutions to existing limitations (i) DIOD robustly eliminates the noise present in the exploited motion maps providing accurate motion-supervision (ii) DIOD leverages the discovered objects within an iterative pseudo-labeling framework enriching the initial motion-supervision with static objects which results in a cost-efficient increase in performance. Through experiments on synthetic and real-world datasets we demonstrate the benefits of bridging the gap between object discovery and distillation by significantly improving the state-of-the-art. This enhancement is also sustained across other demanding metrics so far reserved for supervised tasks",
    "checked": false,
    "id": "7e42c1c54af7928fcf21703abf57706bbb9fef1d",
    "semantic_title": "scale-equivalent distillation for semi-supervised object detection",
    "citation_count": 17,
    "authors": [
      "Sandra Kara",
      "Hejer Ammar",
      "Julien Denize",
      "Florian Chabot",
      "Quoc-Cuong Pham"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wen_GoMAvatar_Efficient_Animatable_Human_Modeling_from_Monocular_Video_Using_Gaussians-on-Mesh_CVPR_2024_paper.html": {
    "title": "GoMAvatar: Efficient Animatable Human Modeling from Monocular Video Using Gaussians-on-Mesh",
    "volume": "main",
    "abstract": "We introduce GoMAvatar a novel approach for real-time memory-efficient high-quality animatable human modeling. GoMAvatar takes as input a single monocular video to create a digital avatar capable of re-articulation in new poses and real-time rendering from novel viewpoints while seamlessly integrating with rasterization-based graphics pipelines. Central to our method is the Gaussians-on-Mesh (GoM) representation a hybrid 3D model combining rendering quality and speed of Gaussian splatting with geometry modeling and compatibility of deformable meshes. We assess GoMAvatar on ZJU-MoCap PeopleSnapshot and various YouTube videos. GoMAvatar matches or surpasses current monocular human modeling algorithms in rendering quality and significantly outperforms them in computational efficiency (43 FPS) while being memory-efficient (3.63 MB per subject)",
    "checked": true,
    "id": "2b5cac130d0002674e80f3b954f024aa17af1edd",
    "semantic_title": "gomavatar: efficient animatable human modeling from monocular video using gaussians-on-mesh",
    "citation_count": 3,
    "authors": [
      "Jing Wen",
      "Xiaoming Zhao",
      "Zhongzheng Ren",
      "Alexander G. Schwing",
      "Shenlong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Teney_Neural_Redshift_Random_Networks_are_not_Random_Functions_CVPR_2024_paper.html": {
    "title": "Neural Redshift: Random Networks are not Random Functions",
    "volume": "main",
    "abstract": "Our understanding of the generalization capabilities of neural networks NNs is still incomplete. Prevailing explanations are based on implicit biases of gradient descent GD but they cannot account for the capabilities of models from gradientfree methods nor the simplicity bias recently observed in untrained networks This paper seeks other sources of generalization in NNs. To understand the inductive biases provided by architectures independently from GD we examine untrained randomweight networks Even simple MLPs show strong inductive biases uniform sampling in weight space yields a very biased distribution of functions in terms of complexity But unlike common wisdom NNs do not have an inherent simplicity bias This property depends on components such as ReLUs residual connections and layer normalizations Alternative architectures can be built with a bias for any level of complexity. Transformers also inherit all these properties from their building blocks. We provide a fresh explanation for the success of deep learning independent from gradientbased training It points at promising avenues for controlling the solutions implemented by trained models",
    "checked": true,
    "id": "6286168d822890ba7bad2bdadcccbbb01edfbd45",
    "semantic_title": "neural redshift: random networks are not random functions",
    "citation_count": 2,
    "authors": [
      "Damien Teney",
      "Armand Mihai Nicolicioiu",
      "Valentin Hartmann",
      "Ehsan Abbasnejad"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_HumanGaussian_Text-Driven_3D_Human_Generation_with_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting",
    "volume": "main",
    "abstract": "Realistic 3D human generation from text prompts is a desirable yet challenging task. Existing methods optimize 3D representations like mesh or neural fields via score distillation sampling (SDS) which suffers from inadequate fine details or excessive training time. In this paper we propose an efficient yet effective framework HumanGaussian that generates high-quality 3D humans with fine-grained geometry and realistic appearance. Our key insight is that 3D Gaussian Splatting is an efficient renderer with periodic Gaussian shrinkage or growing where such adaptive density control can be naturally guided by intrinsic human structures. Specifically 1) we first propose a Structure-Aware SDS that simultaneously optimizes human appearance and geometry. The multi-modal score function from both RGB and depth space is leveraged to distill the Gaussian densification and pruning process. 2) Moreover we devise an Annealed Negative Prompt Guidance by decomposing SDS into a noisier generative score and a cleaner classifier score which well addresses the over-saturation issue. The floating artifacts are further eliminated based on Gaussian size in a prune-only phase to enhance generation smoothness. Extensive experiments demonstrate the superior efficiency and competitive quality of our framework rendering vivid 3D humans under diverse scenarios",
    "checked": true,
    "id": "7665642af9e682e012bec045102a4d009421067c",
    "semantic_title": "humangaussian: text-driven 3d human generation with gaussian splatting",
    "citation_count": 26,
    "authors": [
      "Xian Liu",
      "Xiaohang Zhan",
      "Jiaxiang Tang",
      "Ying Shan",
      "Gang Zeng",
      "Dahua Lin",
      "Xihui Liu",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_DIEM_Decomposition-Integration_Enhancing_Multimodal_Insights_CVPR_2024_paper.html": {
    "title": "DIEM: Decomposition-Integration Enhancing Multimodal Insights",
    "volume": "main",
    "abstract": "In image question answering due to the abundant and sometimes redundant information precisely matching and integrating the information from both text and images is a challenge. In this paper we propose the Decomposition-Integration Enhancing Multimodal Insight (DIEM) which initially decomposes the given question and image into multiple subquestions and several sub-images aiming to isolate specific elements for more focused analysis. We then integrate these sub-elements by matching each subquestion with its relevant sub-images while also retaining the original image to construct a comprehensive answer to the original question without losing sight of the overall context. This strategy mirrors the human cognitive process of simplifying complex problems into smaller components for individual analysis followed by an integration of these insights. We implement DIEM on the LLaVA-v1.5 model and evaluate its performance on ScienceQA and MM-Vet. Experimental results indicate that our method boosts accuracy in most question classes of the ScienceQA (+2.03% in average) especially in the image modality (+3.40%). On MM-Vet our method achieves an improvement in MM-Vet scores increasing from 31.1 to 32.4. These findings highlight DIEM's effectiveness in harmonizing the complexities of multimodal data demonstrating its ability to enhance accuracy and depth in image question answering through its decomposition-integration process",
    "checked": false,
    "id": "f9df0599e9fab871ed26ddb8e9fbdcecbc6644ca",
    "semantic_title": "unraveling emotional regulation through multimodal neuroimaging techniques",
    "citation_count": 2,
    "authors": [
      "Xinyi Jiang",
      "Guoming Wang",
      "Junhao Guo",
      "Juncheng Li",
      "Wenqiao Zhang",
      "Rongxing Lu",
      "Siliang Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_CosmicMan_A_Text-to-Image_Foundation_Model_for_Humans_CVPR_2024_paper.html": {
    "title": "CosmicMan: A Text-to-Image Foundation Model for Humans",
    "volume": "main",
    "abstract": "We present CosmicMan a text-to-image foundation model specialized for generating high-fidelity human images. Unlike current general-purpose foundation models that are stuck in the dilemma of inferior quality and text-image misalignment for humans CosmicMan enables generating photo-realistic human images with meticulous appearance reasonable structure and precise text-image alignment with detailed dense descriptions. At the heart of CosmicMan's success are the new reflections and perspectives on data and models: (1) We found that data quality and a scalable data production flow are essential for the final results from trained models. Hence we propose a new data production paradigm Annotate Anyone which serves as a perpetual data flywheel to produce high-quality data with accurate yet cost-effective annotations over time. Based on this we constructed a large-scale dataset CosmicMan-HQ 1.0 with 6 Million high-quality real-world human images in a mean resolution of 1488x1255 and attached with precise text annotations deriving from 115 Million attributes in diverse granularities. (2) We argue that a text-to-image foundation model specialized for humans must be pragmatic - easy to integrate into down-streaming tasks while effective in producing high-quality human images. Hence we propose to model the relationship between dense text descriptions and image pixels in a decomposed manner and present Decomposed-Attention-Refocusing (Daring) training framework. It seamlessly decomposes the cross-attention features in existing text-to-image diffusion model and enforces attention refocusing without adding extra modules. Through Daring we show that explicitly discretizing continuous text space into several basic groups that align with human body structure is the key to tackling the misalignment problem in a breeze. Project page: https://cosmicman-cvpr2024.github.io/",
    "checked": true,
    "id": "6fa94f9818b7fc16f998d8a229f39f57a48ffb98",
    "semantic_title": "cosmicman: a text-to-image foundation model for humans",
    "citation_count": 1,
    "authors": [
      "Shikai Li",
      "Jianglin Fu",
      "Kaiyuan Liu",
      "Wentao Wang",
      "Kwan-Yee Lin",
      "Wayne Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_LLMs_are_Good_Sign_Language_Translators_CVPR_2024_paper.html": {
    "title": "LLMs are Good Sign Language Translators",
    "volume": "main",
    "abstract": "Sign Language Translation (SLT) is a challenging task that aims to translate sign videos into spoken language. Inspired by the strong translation capabilities of large language models (LLMs) that are trained on extensive multilingual text corpora we aim to harness off-the-shelf LLMs to handle SLT. In this paper we regularize the sign videos to embody linguistic characteristics of spoken language and propose a novel SignLLM framework to transform sign videos into a language-like representation for improved readability by off-the-shelf LLMs. SignLLM comprises two key modules: (1) The Vector-Quantized Visual Sign module converts sign videos into a sequence of discrete character-level sign tokens and (2) the Codebook Reconstruction and Alignment module converts these character-level tokens into word-level sign representations using an optimal transport formulation. A sign-text alignment loss further bridges the gap between sign and text tokens enhancing semantic compatibility. We achieve state-of-the-art gloss-free results on two widely-used SLT benchmarks",
    "checked": true,
    "id": "832dd2923e8821bf8c664101a62ffa3ef46e6b47",
    "semantic_title": "llms are good sign language translators",
    "citation_count": 2,
    "authors": [
      "Jia Gong",
      "Lin Geng Foo",
      "Yixuan He",
      "Hossein Rahmani",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shan_Contrastive_Pre-Training_with_Multi-View_Fusion_for_No-Reference_Point_Cloud_Quality_CVPR_2024_paper.html": {
    "title": "Contrastive Pre-Training with Multi-View Fusion for No-Reference Point Cloud Quality Assessment",
    "volume": "main",
    "abstract": "No-reference point cloud quality assessment (NR-PCQA) aims to automatically evaluate the perceptual quality of distorted point clouds without available reference which have achieved tremendous improvements due to the utilization of deep neural networks. However learning-based NR-PCQA methods suffer from the scarcity of labeled data and usually perform suboptimally in terms of generalization. To solve the problem we propose a novel contrastive pre-training framework tailored for PCQA (CoPA) which enables the pre-trained model to learn quality-aware representations from unlabeled data. To obtain anchors in the representation space we project point clouds with different distortions into images and randomly mix their local patches to form mixed images with multiple distortions. Utilizing the generated anchors we constrain the pre-training process via a quality-aware contrastive loss following the philosophy that perceptual quality is closely related to both content and distortion. Furthermore in the model fine-tuning stage we propose a semantic-guided multi-view fusion module to effectively integrate the features of projected images from multiple perspectives. Extensive experiments show that our method outperforms the state-of-the-art PCQA methods on popular benchmarks. Further investigations demonstrate that CoPA can also benefit existing learning-based PCQA models",
    "checked": true,
    "id": "63ba5b95392e9bc1045e8808d92b3e72833dd12b",
    "semantic_title": "contrastive pre-training with multi-view fusion for no-reference point cloud quality assessment",
    "citation_count": 1,
    "authors": [
      "Ziyu Shan",
      "Yujie Zhang",
      "Qi Yang",
      "Haichen Yang",
      "Yiling Xu",
      "Jenq-Neng Hwang",
      "Xiaozhong Xu",
      "Shan Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_JDEC_JPEG_Decoding_via_Enhanced_Continuous_Cosine_Coefficients_CVPR_2024_paper.html": {
    "title": "JDEC: JPEG Decoding via Enhanced Continuous Cosine Coefficients",
    "volume": "main",
    "abstract": "We propose a practical approach to JPEG image decoding utilizing a local implicit neural representation with continuous cosine formulation. The JPEG algorithm significantly quantizes discrete cosine transform (DCT) spectra to achieve a high compression rate inevitably resulting in quality degradation while encoding an image. We have designed a continuous cosine spectrum estimator to address the quality degradation issue that restores the distorted spectrum. By leveraging local DCT formulations our network has the privilege to exploit dequantization and upsampling simultaneously. Our proposed model enables decoding compressed images directly across different quality factors using a single pre-trained model without relying on a conventional JPEG decoder. As a result our proposed network achieves state-of-the-art performance in flexible color image JPEG artifact removal tasks. Our source code is available at https://github.com/WooKyoungHan/JDEC",
    "checked": true,
    "id": "dcc401bbb641d1ecefc6cc2c5283cefdb12557ee",
    "semantic_title": "jdec: jpeg decoding via enhanced continuous cosine coefficients",
    "citation_count": 0,
    "authors": [
      "Woo Kyoung Han",
      "Sunghoon Im",
      "Jaedeok Kim",
      "Kyong Hwan Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Revisiting_the_Domain_Shift_and_Sample_Uncertainty_in_Multi-source_Active_CVPR_2024_paper.html": {
    "title": "Revisiting the Domain Shift and Sample Uncertainty in Multi-source Active Domain Transfer",
    "volume": "main",
    "abstract": "Active Domain Adaptation (ADA) aims to maximally boost model adaptation in a new target domain by actively selecting a limited number of target data to annotate. This setting neglects the more practical scenario where training data are collected from multiple sources. This motivates us to extend ADA from a single source domain to multiple source domains termed Multi-source Active Domain Adaptation (MADA). Not surprisingly we find that most traditional ADA methods cannot work directly in such a setting mainly due to the excessive domain gap introduced by all the source domains. Considering this we propose a Detective framework that comprehensively considers the domain shift between multi-source domains and target domains to detect the informative target samples. Specifically the Detective leverages a dynamic Domain Adaptation (DA) model that learns how to adapt the model's parameters to fit the union of multi-source domains. This enables an approximate single-source domain modeling by the dynamic model. We then comprehensively measure both domain uncertainty and predictive uncertainty in the target domain to detect informative target samples using evidential deep learning thereby mitigating uncertainty miscalibration. Experiments demonstrate that our solution outperforms existing methods by a considerable margin on three domain adaptation benchmarks",
    "checked": true,
    "id": "e49f4fad3f4fd6a4ea4161e942d01781fb81fcad",
    "semantic_title": "revisiting the domain shift and sample uncertainty in multi-source active domain transfer",
    "citation_count": 5,
    "authors": [
      "Wenqiao Zhang",
      "Zheqi Lv",
      "Hao Zhou",
      "Jia-Wei Liu",
      "Juncheng Li",
      "Mengze Li",
      "Yunfei Li",
      "Dongping Zhang",
      "Yueting Zhuang",
      "Siliang Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cui_Learning_Continual_Compatible_Representation_for_Re-indexing_Free_Lifelong_Person_Re-identification_CVPR_2024_paper.html": {
    "title": "Learning Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification",
    "volume": "main",
    "abstract": "Lifelong Person Re-identification (L-ReID) aims to learn from sequentially collected data to match a person across different scenes. Once an L-ReID model is updated using new data all historical images in the gallery are required to be re-calculated to obtain new features for testing known as \"re-indexing\". However it is infeasible when raw images in the gallery are unavailable due to data privacy concerns resulting in incompatible retrieval between the query and the gallery features calculated by different models which causes significant performance degradation. In this paper we focus on a new task called Re-indexing Free Lifelong Person Re-identification (RFL-ReID) which requires achieving effective L-ReID without re-indexing raw images in the gallery. To this end we propose a Continual Compatible Representation (C2R) method which facilitates the query feature calculated by the continuously updated model to effectively retrieve the gallery feature calculated by the old model in a compatible manner. Specifically we design a Continual Compatible Transfer (CCT) network to continuously transfer and consolidate the old gallery feature into the new feature space. Besides a Balanced Compatible Distillation module is introduced to achieve compatibility by aligning the transferred feature space with the new feature space. Finally a Balanced Anti-forgetting Distillation module is proposed to eliminate the accumulated forgetting of old knowledge during the continual compatible transfer. Extensive experiments on several benchmark L-ReID datasets demonstrate the effectiveness of our method against state-of-the-art methods for both RFL-ReID and L-ReID tasks. The source code of this paper is available at https://github.com/PKU-ICST-MIPL/C2R_CVPR2024",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Cui",
      "Jiahuan Zhou",
      "Xun Wang",
      "Manyu Zhu",
      "Yuxin Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Revisiting_Spatial-Frequency_Information_Integration_from_a_Hierarchical_Perspective_for_Panchromatic_CVPR_2024_paper.html": {
    "title": "Revisiting Spatial-Frequency Information Integration from a Hierarchical Perspective for Panchromatic and Multi-Spectral Image Fusion",
    "volume": "main",
    "abstract": "Pan-sharpening is a super-resolution problem that essentially relies on spectra fusion of panchromatic (PAN) images and low-resolution multi-spectral (LRMS) images. The previous methods have validated the effectiveness of information fusion in the Fourier space of the whole image. However they haven't fully explored the Fourier relationships at different hierarchies between PAN and LRMS images. To this end we propose a Hierarchical Frequency Integration Network (HFIN) to facilitate hierarchical Fourier information integration for pan-sharpening. Specifically our network consists of two designs: information stratification and information integration. For information stratification we hierarchically decompose PAN and LRMS information into spatial global Fourier and local Fourier information and fuse them independently. For information integration the above hierarchical fused information is processed to further enhance their relationships and undergo comprehensive integration. Our method extend a new space for exploring the relationships of PAN and LRMS images enhancing the integration of spatial-frequency information. Extensive experiments robustly validate the effectiveness of the proposed network showcasing its superior performance compared to other state-of-the-art methods and generalization in real-world scenes and other fusion tasks as a general image fusion framework. Code is available at https://github.com/JosephTiTan/HFIN",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangtong Tan",
      "Jie Huang",
      "Naishan Zheng",
      "Man Zhou",
      "Keyu Yan",
      "Danfeng Hong",
      "Feng Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_BSNet_Box-Supervised_Simulation-assisted_Mean_Teacher_for_3D_Instance_Segmentation_CVPR_2024_paper.html": {
    "title": "BSNet: Box-Supervised Simulation-assisted Mean Teacher for 3D Instance Segmentation",
    "volume": "main",
    "abstract": "3D instance segmentation (3DIS) is a crucial task but point-level annotations are tedious in fully supervised settings. Thus using bounding boxes (bboxes) as annotations has shown great potential. The current mainstream approach is a two-step process involving the generation of pseudo-labels from box annotations and the training of a 3DIS network with the pseudo-labels. However due to the presence of intersections among bboxes not every point has a determined instance label especially in overlapping areas. To generate higher quality pseudo-labels and achieve more precise weakly supervised 3DIS results we propose the Box-Supervised Simulation-assisted Mean Teacher for 3D Instance Segmentation (BSNet) which devises a novel pseudo-labeler called Simulation-assisted Transformer. The labeler consists of two main components. The first is Simulation-assisted Mean Teacher which introduces Mean Teacher for the first time in this task and constructs simulated samples to assist the labeler in acquiring prior knowledge about overlapping areas. To better model local-global structure we also propose Local-Global Aware Attention as the decoder for teacher and student labelers. Extensive experiments conducted on the ScanNetV2 and S3DIS datasets verify the superiority of our designs",
    "checked": true,
    "id": "77c6b990e0c43730ffe76a3a9cc7511126285bbf",
    "semantic_title": "bsnet: box-supervised simulation-assisted mean teacher for 3d instance segmentation",
    "citation_count": 0,
    "authors": [
      "Jiahao Lu",
      "Jiacheng Deng",
      "Tianzhu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Adaptive_Slot_Attention_Object_Discovery_with_Dynamic_Slot_Number_CVPR_2024_paper.html": {
    "title": "Adaptive Slot Attention: Object Discovery with Dynamic Slot Number",
    "volume": "main",
    "abstract": "Object-centric learning (OCL) extracts the representation of objects with slots offering an exceptional blend of flexibility and interpretability for abstracting low-level perceptual features. A widely adopted method within OCL is slot attention which utilizes attention mechanisms to iteratively refine slot representations. However a major drawback of most object-centric models including slot attention is their reliance on predefining the number of slots. This not only necessitates prior knowledge of the dataset but also overlooks the inherent variability in the number of objects present in each instance. To overcome this fundamental limitation we present a novel complexity-aware object auto-encoder framework. Within this framework we introduce an adaptive slot attention (AdaSlot) mechanism that dynamically determines the optimal number of slots based on the content of the data. This is achieved by proposing a discrete slot sampling module that is responsible for selecting an appropriate number of slots from a candidate list. Furthermore we introduce a masked slot decoder that suppresses unselected slots during the decoding process. Our framework tested extensively on object discovery tasks with various datasets shows performance matching or exceeding top fixed-slot models. Moreover our analysis substantiates that our method exhibits the capability to dynamically adapt the slot number according to each instance's complexity offering the potential for further exploration in slot attention research. Project will be available at https://kfan21.github.io/AdaSlot/",
    "checked": true,
    "id": "de9402a5e259f2c5eb919914bc898a3ca9eccdef",
    "semantic_title": "adaptive slot attention: object discovery with dynamic slot number",
    "citation_count": 0,
    "authors": [
      "Ke Fan",
      "Zechen Bai",
      "Tianjun Xiao",
      "Tong He",
      "Max Horn",
      "Yanwei Fu",
      "Francesco Locatello",
      "Zheng Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_CORES_Convolutional_Response-based_Score_for_Out-of-distribution_Detection_CVPR_2024_paper.html": {
    "title": "CORES: Convolutional Response-based Score for Out-of-distribution Detection",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) often display overconfidence when encountering out-of-distribution (OOD) samples posing significant challenges in real-world applications. Capitalizing on the observation that responses on convolutional kernels are generally more pronounced for in-distribution (ID) samples than for OOD ones this paper proposes the COnvolutional REsponse-based Score (CORES) to exploit these discrepancies for OOD detection. Initially CORES delves into the extremities of convolutional responses by considering both their magnitude and the frequency of significant values. Moreover through backtracking from the most prominent predictions CORES effectively pinpoints sample-relevant kernels across different layers. These kernels which exhibit a strong correlation to input samples are integral to CORES's OOD detection capability. Comprehensive experiments across various ID and OOD settings demonstrate CORES's effectiveness in OOD detection and its superiority to the state-of-the-art methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keke Tang",
      "Chao Hou",
      "Weilong Peng",
      "Runnan Chen",
      "Peican Zhu",
      "Wenping Wang",
      "Zhihong Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Marcus_Task-Driven_Wavelets_using_Constrained_Empirical_Risk_Minimization_CVPR_2024_paper.html": {
    "title": "Task-Driven Wavelets using Constrained Empirical Risk Minimization",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) are widely used for their ability to effectively approximate large classes of functions. This flexibility however makes the strict enforcement of constraints on DNNs a difficult problem. In contexts where it is critical to limit the function space to which certain network components belong such as wavelets employed in Multi-Resolution Analysis (MRA) naive constraints via additional terms in the loss function are inadequate. To address this we introduce a Convolutional Neural Network (CNN) wherein the convolutional filters are strictly constrained to be wavelets. This allows the filters to update to task-optimized wavelets during the training procedure. Our primary contribution lies in the rigorous formulation of these filters via a constrained empirical risk minimization framework thereby providing an exact mechanism to enforce these structural constraints. While our work is grounded in theory we investigate our approach empirically through applications in medical imaging particularly in the task of contour prediction around various organs achieving superior performance compared to baseline methods",
    "checked": false,
    "id": "b799fa39024abfe8b8c5a571cc36d6ca054707a3",
    "semantic_title": "constrained empirical risk minimization: theory and practice",
    "citation_count": 1,
    "authors": [
      "Eric Marcus",
      "Ray Sheombarsing",
      "Jan-Jakob Sonke",
      "Jonas Teuwen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_HOI-M3_Capture_Multiple_Humans_and_Objects_Interaction_within_Contextual_Environment_CVPR_2024_paper.html": {
    "title": "HOI-M^3: Capture Multiple Humans and Objects Interaction within Contextual Environment",
    "volume": "main",
    "abstract": "Humans naturally interact with both others and the surrounding multiple objects engaging in various social activities. However recent advances in modeling human-object interactions mostly focus on perceiving isolated individuals and objects due to fundamental data scarcity. In this paper we introduce HOI-M^3 a novel large-scale dataset for modeling the interactions of Multiple huMans and Multiple objects. Notably it provides accurate 3D tracking for both humans and objects from dense RGB and object-mounted IMU inputs covering 199 sequences and 181M frames of diverse humans and objects under rich activities. With the unique HOI-M^3 dataset we introduce two novel data-driven tasks with companion strong baselines: monocular capture and unstructured generation of multiple human-object interactions. Extensive experiments demonstrate that our dataset is challenging and worthy of further research about multiple human-object interactions and behavior analysis. Our HOI-M^3 dataset corresponding codes and pre-trained models will be disseminated to the community for future research",
    "checked": false,
    "id": "875ed9ccfb0910ae5ba88387f5b13e57c2383216",
    "semantic_title": "hoi-m3: capture multiple humans and objects interaction within contextual environment",
    "citation_count": 0,
    "authors": [
      "Juze Zhang",
      "Jingyan Zhang",
      "Zining Song",
      "Zhanhe Shi",
      "Chengfeng Zhao",
      "Ye Shi",
      "Jingyi Yu",
      "Lan Xu",
      "Jingya Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_Interactive3D_Create_What_You_Want_by_Interactive_3D_Generation_CVPR_2024_paper.html": {
    "title": "Interactive3D: Create What You Want by Interactive 3D Generation",
    "volume": "main",
    "abstract": "3D object generation has undergone significant advancements yielding high-quality results. However fall short in achieving precise user control often yielding results that do not align with user expectations thus limiting their applicability. User-envisioning 3D object generation faces significant challenges in realizing its concepts using current generative models due to limited interaction capabilities. Existing methods mainly offer two approaches: (i) interpreting textual instructions with constrained controllability or (ii) reconstructing 3D objects from 2D images. Both of them limit customization to the confines of the 2D reference and potentially introduce undesirable artifacts during the 3D lifting process restricting the scope for direct and versatile 3D modifications. In this work we introduce Interactive3D an innovative framework for interactive 3D generation that grants users precise control over the generative process through extensive 3D interaction capabilities. Interactive3D is constructed in two cascading stages utilizing distinct 3D representations. The first stage employs Gaussian Splatting for direct user interaction allowing modifications and guidance of the generative direction at any intermediate step through (i) Adding and Removing components (ii) Deformable and Rigid Dragging (iii) Geometric Transformations and (iv) Semantic Editing. Subsequently the Gaussian splats are transformed into InstantNGP. We introduce a novel (v) Interactive Hash Refinement module to further add details and extract the geometry in the second stage. Our experiments demonstrate that proposed Interactive3D markedly improves the controllability and quality of 3D generation. Our project webpage is available at https://interactive-3d.github.io/",
    "checked": true,
    "id": "f0ef583e331d9696f3db10090f86d5e00e7869f1",
    "semantic_title": "interactive3d: create what you want by interactive 3d generation",
    "citation_count": 0,
    "authors": [
      "Shaocong Dong",
      "Lihe Ding",
      "Zhanpeng Huang",
      "Zibin Wang",
      "Tianfan Xue",
      "Dan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rangwani_DeiT-LT_Distillation_Strikes_Back_for_Vision_Transformer_Training_on_Long-Tailed_CVPR_2024_paper.html": {
    "title": "DeiT-LT: Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets",
    "volume": "main",
    "abstract": "Vision Transformer (ViT) has emerged as a prominent architecture for various computer vision tasks. In ViT we divide the input image into patch tokens and process them through a stack of self-attention blocks. However unlike Convolutional Neural Network (CNN) ViT's simple architecture has no informative inductive bias (e.g. locality etc.). Due to this ViT requires a large amount of data for pre-training. Various data-efficient approaches (DeiT) have been proposed to train ViT on balanced datasets effectively. However limited literature discusses the use of ViT for datasets with long-tailed imbalances. In this work we introduce DeiT-LT to tackle the problem of training ViTs from scratch on long-tailed datasets. In DeiT-LT we introduce an efficient and effective way of distillation from CNN via distillation \\texttt DIST token by using out-of-distribution images and re-weighting the distillation loss to enhance focus on tail classes. This leads to the learning of local CNN-like features in early ViT blocks improving generalization for tail classes. Further to mitigate overfitting we propose distilling from a flat CNN teacher which leads to learning low-rank generalizable features for DIST tokens across all ViT blocks. With the proposed DeiT-LT scheme the distillation DIST token becomes an expert on the tail classes and the classifier CLS token becomes an expert on the head classes. The experts help to effectively learn features corresponding to both the majority and minority classes using a distinct set of tokens within the same ViT architecture. We show the effectiveness of DeiT-LT for training ViT from scratch on datasets ranging from small-scale CIFAR-10 LT to large-scale iNaturalist-2018. Project Page: https://rangwani-harsh.github.io/DeiT-LT",
    "checked": false,
    "id": "85dd4da86c6f5c462a5285c4547d4afc6aa7b913",
    "semantic_title": "deit-lt distillation strikes back for vision transformer training on long-tailed datasets",
    "citation_count": 0,
    "authors": [
      "Harsh Rangwani",
      "Pradipto Mondal",
      "Mayank Mishra",
      "Ashish Ramayee Asokan",
      "R. Venkatesh Babu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chung_Accurate_Spatial_Gene_Expression_Prediction_by_Integrating_Multi-Resolution_Features_CVPR_2024_paper.html": {
    "title": "Accurate Spatial Gene Expression Prediction by Integrating Multi-Resolution Features",
    "volume": "main",
    "abstract": "Recent advancements in Spatial Transcriptomics (ST) technology have facilitated detailed gene expression analysis within tissue contexts. However the high costs and methodological limitations of ST necessitate a more robust predictive model. In response this paper introduces TRIPLEX a novel deep learning framework designed to predict spatial gene expression from Whole Slide Images (WSIs). TRIPLEX uniquely harnesses multi-resolution features capturing cellular morphology at individual spots the local context around these spots and the global tissue organization. By integrating these features through an effective fusion strategy TRIPLEX achieves accurate gene expression prediction. Our comprehensive benchmark study conducted on three public ST datasets and supplemented with Visium data from 10X Genomics demonstrates that TRIPLEX outperforms current state-of-the-art models in Mean Squared Error (MSE) Mean Absolute Error (MAE) and Pearson Correlation Coefficient (PCC). The model's predictions align closely with ground truth gene expression profiles and tumor annotations underscoring TRIPLEX's potential in advancing cancer diagnosis and treatment",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youngmin Chung",
      "Ji Hun Ha",
      "Kyeong Chan Im",
      "Joo Sang Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_FCS_Feature_Calibration_and_Separation_for_Non-Exemplar_Class_Incremental_Learning_CVPR_2024_paper.html": {
    "title": "FCS: Feature Calibration and Separation for Non-Exemplar Class Incremental Learning",
    "volume": "main",
    "abstract": "Non-Exemplar Class Incremental Learning (NECIL) involves learning a classification model on a sequence of data without access to exemplars from previously encountered old classes. Such a stringent constraint always leads to catastrophic forgetting of the learned knowledge. Currently existing methods either employ knowledge distillation techniques or preserved class prototypes to sustain prior knowledge. However two critical issues still persist. On the one hand as the model is continually updated the preserved prototypes of old classes will inevitably derive from the suitable location in the feature space of the new model. On the other hand due to the lack of exemplars the features of new classes will take the place of similar old classes which breaks the classification boundary. To address these challenges we propose a Feature Calibration and Separation (FCS) method for NECIL. Our approach comprises a Feature Calibration Network (FCN) that adapts prototypes of old classes to the new model via optimal transport learning approximating the drift of prototypes caused by model evolution. Additionally we also propose a Prototype-Involved Contrastive Loss (PIC) that enhances feature separation among different classes. Specifically to mitigate the boundary distortion arising from the interplay of classes from different learning stages prototypes are involved in pushing the feature of new classes away from the old classes. Extensive experiments on three datasets with different settings have demonstrated the superiority of our FCS method against the state-of-the-art class incremental learning approaches. Code is available at https://github.com/zhoujiahuan1991/CVPR2024-FCS",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiwei Li",
      "Yuxin Peng",
      "Jiahuan Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Daroya_Task2Box_Box_Embeddings_for_Modeling_Asymmetric_Task_Relationships_CVPR_2024_paper.html": {
    "title": "Task2Box: Box Embeddings for Modeling Asymmetric Task Relationships",
    "volume": "main",
    "abstract": "Modeling and visualizing relationships between tasks or datasets is an important step towards solving various meta-tasks such as dataset discovery multi-tasking and transfer learning. However many relationships such as containment and transferability are naturally asymmetric and current approaches for representation and visualization (e.g. t-SNE) do not readily support this. We propose Task2Box an approach to represent tasks using box embeddings---axis-aligned hyperrectangles in low dimensional spaces---that can capture asymmetric relationships between them through volumetric overlaps. We show that Task2Box accurately predicts unseen hierarchical relationships between nodes in ImageNet and iNaturalist datasets as well as transferability between tasks in the Taskonomy benchmark. We also show that box embeddings estimated from task representations (e.g. CLIP Task2Vec or attribute based) can be used to predict relationships between unseen tasks more accurately than classifiers trained on the same representations as well as handcrafted asymmetric distances (e.g. KL divergence). This suggests that low-dimensional box embeddings can effectively capture these task relationships and have the added advantage of being interpretable. We use the approach to visualize relationships among publicly available image classification datasets on popular dataset hosting platform called Hugging Face",
    "checked": true,
    "id": "76211f34bf5947f524cce3742ed930174c3db758",
    "semantic_title": "task2box: box embeddings for modeling asymmetric task relationships",
    "citation_count": 0,
    "authors": [
      "Rangel Daroya",
      "Aaron Sun",
      "Subhransu Maji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Behind_the_Veil_Enhanced_Indoor_3D_Scene_Reconstruction_with_Occluded_CVPR_2024_paper.html": {
    "title": "Behind the Veil: Enhanced Indoor 3D Scene Reconstruction with Occluded Surfaces Completion",
    "volume": "main",
    "abstract": "In this paper we present a novel indoor 3D reconstruction method with occluded surface completion given a sequence of depth readings. Prior state-of-the-art (SOTA) methods only focus on the reconstruction of the visible areas in a scene neglecting the invisible areas due to the occlusions e.g. the contact surface between furniture occluded wall and floor. Our method tackles the task of completing the occluded scene surfaces resulting in a complete 3D scene mesh. The core idea of our method is learning 3D geometry prior from various complete scenes to infer the occluded geometry of an unseen scene from solely depth measurements. We design a coarse-fine hierarchical octree representation coupled with a dual-decoder architecture i.e. Geo-decoder and 3D Inpainter which jointly reconstructs the complete 3D scene geometry. The Geo-decoder with detailed representation at fine levels is optimized online for each scene to reconstruct visible surfaces. The 3D Inpainter with abstract representation at coarse levels is trained offline using various scenes to complete occluded surfaces. As a result while the Geo-decoder is specialized for an individual scene the 3D Inpainter can be generally applied across different scenes. We evaluate the proposed method on the 3D Completed Room Scene (3D-CRS) and iTHOR datasets significantly outperforming the SOTA methods by a gain of 16.8% and 24.2% in terms of the completeness of 3D reconstruction. 3D-CRS dataset including a complete 3D mesh of each scene is provided at project webpage",
    "checked": true,
    "id": "7e9ef88761bacd6c421f602b327aadba802ce994",
    "semantic_title": "behind the veil: enhanced indoor 3d scene reconstruction with occluded surfaces completion",
    "citation_count": 0,
    "authors": [
      "Su Sun",
      "Cheng Zhao",
      "Yuliang Guo",
      "Ruoyu Wang",
      "Xinyu Huang",
      "Yingjie Victor Chen",
      "Liu Ren"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wasim_VideoGrounding-DINO_Towards_Open-Vocabulary_Spatio-Temporal_Video_Grounding_CVPR_2024_paper.html": {
    "title": "VideoGrounding-DINO: Towards Open-Vocabulary Spatio-Temporal Video Grounding",
    "volume": "main",
    "abstract": "Video grounding aims to localize a spatio-temporal section in a video corresponding to an input text query. This paper addresses a critical limitation in current video grounding methodologies by introducing an Open-Vocabulary Spatio-Temporal Video Grounding task. Unlike prevalent closed-set approaches that struggle with open-vocabulary scenarios due to limited training data and predefined vocabularies our model leverages pre-trained representations from foundational spatial grounding models. This empowers it to effectively bridge the semantic gap between natural language and diverse visual content achieving strong performance in closed-set and open-vocabulary settings. Our contributions include a novel spatio-temporal video grounding model surpassing state-of-the-art results in closed-set evaluations on multiple datasets and demonstrating superior performance in open-vocabulary scenarios. Notably the proposed model outperforms state-of-the-art methods in closed-set settings on VidSTG (Declarative and Interrogative) and HC-STVG (V1 and V2) datasets. Furthermore in open-vocabulary evaluations on HC-STVG V1 and YouCook-Interactions our model surpasses the recent best-performing models by 4.88 m_vIoU and 1.83 accuracy demonstrating its efficacy in handling diverse linguistic and visual concepts for improved video understanding. Our codes will be publicly released",
    "checked": false,
    "id": "89bdb9240a26f3abbb31d144e5fb210c44c3ffa1",
    "semantic_title": "video-groundingdino: towards open-vocabulary spatio-temporal video grounding",
    "citation_count": 0,
    "authors": [
      "Syed Talal Wasim",
      "Muzammal Naseer",
      "Salman Khan",
      "Ming-Hsuan Yang",
      "Fahad Shahbaz Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_OmniLocalRF_Omnidirectional_Local_Radiance_Fields_from_Dynamic_Videos_CVPR_2024_paper.html": {
    "title": "OmniLocalRF: Omnidirectional Local Radiance Fields from Dynamic Videos",
    "volume": "main",
    "abstract": "Omnidirectional cameras are extensively used in various applications to provide a wide field of vision. However they face a challenge in synthesizing novel views due to the inevitable presence of dynamic objects including the photographer in their wide field of view. In this paper we introduce a new approach called Omnidirectional Local Radiance Fields (OmniLocalRF) that can render static-only scene views removing and inpainting dynamic objects simultaneously. Our approach combines the principles of local radiance fields with the bidirectional optimization of omnidirectional rays. Our input is an omnidirectional video and we evaluate the mutual observations of the entire angle between the previous and current frames. To reduce ghosting artifacts of dynamic objects and inpaint occlusions we devise a multi-resolution motion mask prediction module. Unlike existing methods that primarily separate dynamic components through the temporal domain our method uses multi-resolution neural feature planes for precise segmentation which is more suitable for long 360-degree videos. Our experiments validate that OmniLocalRF outperforms existing methods in both qualitative and quantitative metrics especially in scenarios with complex real-world scenes. In particular our approach eliminates the need for manual interaction such as drawing motion masks by hand and additional pose estimation making it a highly effective and efficient solution",
    "checked": true,
    "id": "5abf5d36ac40f8937d691966d7f3da3652b8e1d2",
    "semantic_title": "omnilocalrf: omnidirectional local radiance fields from dynamic videos",
    "citation_count": 0,
    "authors": [
      "Dongyoung Choi",
      "Hyeonjoong Jang",
      "Min H. Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_LoS_Local_Structure-Guided_Stereo_Matching_CVPR_2024_paper.html": {
    "title": "LoS: Local Structure-Guided Stereo Matching",
    "volume": "main",
    "abstract": "Estimating disparities in challenging areas is difficult and limits the performance of stereo matching models. In this paper we exploit local structure information (LSI) to enhance stereo matching. Specifically our LSI comprises a series of key elements including the slant plane (parameterised by disparity gradients) disparity offset details and neighbouring relations. This LSI empowers our method to effectively handle intricate structures including object boundaries and curved surfaces. We bootstrap the LSI from monocular depth and subsequently iteratively refine it to better capture the underlying scene geometry constraints. Building upon the LSI we introduce the Local Structure-Guided Propagation (LSGP) which enhances the disparity initialization optimization and refinement processes. By combining LSGP with a Gated Recurrent Unit (GRU) we present our novel stereo matching method referred to as Local Structure-guided stereo matching (LoS). Remarkably LoS achieves top-ranking results on four widely recognized public benchmark datasets (ETH3D Middlebury KITTI 15 & 12) demonstrating the superior capabilities of our proposed model",
    "checked": false,
    "id": "5223a5a9f83d13f4d7411eb8253ac3c8c1421372",
    "semantic_title": "rethinking training strategy in stereo matching",
    "citation_count": 22,
    "authors": [
      "Kunhong Li",
      "Longguang Wang",
      "Ye Zhang",
      "Kaiwen Xue",
      "Shunbo Zhou",
      "Yulan Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhan_Semantic_Human_Mesh_Reconstruction_with_Textures_CVPR_2024_paper.html": {
    "title": "Semantic Human Mesh Reconstruction with Textures",
    "volume": "main",
    "abstract": "The field of 3D detailed human mesh reconstruction has made significant progress in recent years. However current methods still face challenges when used in industrial applications due to unstable results low-quality meshes and a lack of UV unwrapping and skinning weights. In this paper we present SHERT a novel pipeline that can reconstruct semantic human meshes with textures and high-precision details. SHERT applies semantic- and normal-based sampling between the detailed surface (e.g. mesh and SDF) and the corresponding SMPL-X model to obtain a partially sampled semantic mesh and then generates the complete semantic mesh by our specifically designed self-supervised completion and refinement networks. Using the complete semantic mesh as a basis we employ a texture diffusion model to create human textures that are driven by both images and texts. Our reconstructed meshes have stable UV unwrapping high-quality triangle meshes and consistent semantic information. The given SMPL-X model provides semantic information and shape priors allowing SHERT to perform well even with incorrect and incomplete inputs. The semantic information also makes it easy to substitute and animate different body parts such as the face body and hands. Quantitative and qualitative experiments demonstrate that SHERT is capable of producing high-fidelity and robust semantic meshes that outperform state-of-the-art methods",
    "checked": true,
    "id": "745029c07aca43a0ac47c9bb2ceea65a7e712cc4",
    "semantic_title": "semantic human mesh reconstruction with textures",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Zhan",
      "Jianxin Yang",
      "Yuanqi Li",
      "Jie Guo",
      "Yanwen Guo",
      "Wenping Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Think_Twice_Before_Selection_Federated_Evidential_Active_Learning_for_Medical_CVPR_2024_paper.html": {
    "title": "Think Twice Before Selection: Federated Evidential Active Learning for Medical Image Analysis with Domain Shifts",
    "volume": "main",
    "abstract": "Federated learning facilitates the collaborative learning of a global model across multiple distributed medical institutions without centralizing data. Nevertheless the expensive cost of annotation on local clients remains an obstacle to effectively utilizing local data. To mitigate this issue federated active learning methods suggest leveraging local and global model predictions to select a relatively small amount of informative local data for annotation. However existing methods mainly focus on all local data sampled from the same domain making them unreliable in realistic medical scenarios with domain shifts among different clients. In this paper we make the first attempt to assess the informativeness of local data derived from diverse domains and propose a novel methodology termed Federated Evidential Active Learning (FEAL) to calibrate the data evaluation under domain shift. Specifically we introduce a Dirichlet prior distribution in both local and global models to treat the prediction as a distribution over the probability simplex and capture both aleatoric and epistemic uncertainties by using the Dirichlet-based evidential model. Then we employ the epistemic uncertainty to calibrate the aleatoric uncertainty. Afterward we design a diversity relaxation strategy to reduce data redundancy and maintain data diversity. Extensive experiments and analysis on five real multi-center medical image datasets demonstrate the superiority of FEAL over the state-of-the-art active learning methods in federated scenarios with domain shifts. The code will be available at https://github.com/JiayiChen815/FEAL",
    "checked": true,
    "id": "2b997d8a527cf0f9f2a0c0dca097ef67a7d04f17",
    "semantic_title": "think twice before selection: federated evidential active learning for medical image analysis with domain shifts",
    "citation_count": 1,
    "authors": [
      "Jiayi Chen",
      "Benteng Ma",
      "Hengfei Cui",
      "Yong Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Banani_Probing_the_3D_Awareness_of_Visual_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Probing the 3D Awareness of Visual Foundation Models",
    "volume": "main",
    "abstract": "Recent advances in large-scale pretraining have yielded visual foundation models with strong capabilities. Not only can recent models generalize to arbitrary images for their training task their intermediate representations are useful for other visual tasks such as detection and segmentation. Given that such models can classify delineate and localize objects in 2D we ask whether they also represent their 3D structure? In this work we analyze the 3D awareness of visual foundation models. We posit that 3D awareness implies that representations (1) encode the 3D structure of the scene and (2) consistently represent the surface across views. We conduct a series of experiments using task-specific probes and zero-shot inference procedures on frozen features. Our experiments reveal several limitations of the current models. Our code and analysis can be found at https://github.com/mbanani/probe3d",
    "checked": true,
    "id": "7620caa2eff7836b039ade247909268b3af1ebab",
    "semantic_title": "probing the 3d awareness of visual foundation models",
    "citation_count": 11,
    "authors": [
      "Mohamed El Banani",
      "Amit Raj",
      "Kevis-Kokitsi Maninis",
      "Abhishek Kar",
      "Yuanzhen Li",
      "Michael Rubinstein",
      "Deqing Sun",
      "Leonidas Guibas",
      "Justin Johnson",
      "Varun Jampani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_PIA_Your_Personalized_Image_Animator_via_Plug-and-Play_Modules_in_Text-to-Image_CVPR_2024_paper.html": {
    "title": "PIA: Your Personalized Image Animator via Plug-and-Play Modules in Text-to-Image Models",
    "volume": "main",
    "abstract": "Recent advancements in personalized text-to-image (T2I) models have revolutionized content creation empowering non-experts to generate stunning images with unique styles. While promising animating these personalized images with realistic motions poses significant challenges in preserving distinct styles high-fidelity details and achieving motion controllability by text. In this paper we present PIA a Personalized Image Animator that excels in aligning with condition images achieving motion controllability by text and the compatibility with various personalized T2I models without specific tuning. To achieve these goals PIA builds upon a base T2I model with well-trained temporal alignment layers allowing for the seamless transformation of any personalized T2I model into an image animation model. A key component of PIA is the introduction of the condition module which takes as inputs the condition frame and inter-frame affinity. This module leverages the affinity hint to transfer appearance information from the condition frame to individual frames in the latent space. This design mitigates the challenges of appearance-related frame alignment within PIA and allows for a stronger focus on aligning with motion-related guidance. To address the lack of a benchmark for this field we introduce AnimateBench a comprehensive benchmark comprising diverse personalized T2I models curated images and motion-related prompts. We show extensive evaluations and applications on AnimateBench to verify the superiority of PIA",
    "checked": true,
    "id": "183230c342973a8bdf715ab813d188cdf6b988d1",
    "semantic_title": "pia: your personalized image animator via plug-and-play modules in text-to-image models",
    "citation_count": 8,
    "authors": [
      "Yiming Zhang",
      "Zhening Xing",
      "Yanhong Zeng",
      "Youqing Fang",
      "Kai Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_When_Visual_Grounding_Meets_Gigapixel-level_Large-scale_Scenes_Benchmark_and_Approach_CVPR_2024_paper.html": {
    "title": "When Visual Grounding Meets Gigapixel-level Large-scale Scenes: Benchmark and Approach",
    "volume": "main",
    "abstract": "Visual grounding refers to the process of associating natural language expressions with corresponding regions within an image. Existing benchmarks for visual grounding primarily operate within small-scale scenes with a few objects. Nevertheless recent advances in imaging technology have enabled the acquisition of gigapixel-level images providing high-resolution details in large-scale scenes containing numerous objects. To bridge this gap between imaging and computer vision benchmarks and make grounding more practically valuable we introduce a novel dataset named GigaGrounding designed to challenge visual grounding models in gigapixel-level large-scale scenes. We extensively analyze and compare the dataset with existing benchmarks demonstrating that GigaGrounding presents unique challenges such as large-scale scene understanding gigapixel-level resolution significant variations in object scales and the \"multi-hop expressions\". Furthermore we introduced a simple yet effective grounding approach which employs a \"glance-to-zoom-in\" paradigm and exhibits enhanced capabilities for addressing the GigaGrounding task. The dataset is available at www.gigavision.ai",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Ma",
      "Bing Bai",
      "Haozhe Lin",
      "Heyuan Wang",
      "Yu Wang",
      "Lin Luo",
      "Lu Fang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fischer_NeRF_Analogies_Example-Based_Visual_Attribute_Transfer_for_NeRFs_CVPR_2024_paper.html": {
    "title": "NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs",
    "volume": "main",
    "abstract": "A Neural Radiance Field (NeRF) encodes the specific relation of 3D geometry and appearance of a scene. We here ask the question whether we can transfer the appearance from a source NeRF onto a target 3D geometry in a semantically meaningful way such that the resulting new NeRF retains the target geometry but has an appearance that is an analogy to the source NeRF. To this end we generalize classic image analogies from 2D images to NeRFs. We leverage correspondence transfer along semantic affinity that is driven by semantic features from large pre-trained 2D image models to achieve multi-view consistent appearance transfer. Our method allows exploring the mix-and-match product space of 3D geometry and appearance. We show that our method outperforms traditional stylization-based methods and that a large majority of users prefer our method over several typical baselines. Project page: https://mfischer-ucl.github.io/nerf_analogies",
    "checked": true,
    "id": "aa97a40c6bdf0fd151c65506772dfa6967ef0cb7",
    "semantic_title": "nerf analogies: example-based visual attribute transfer for nerfs",
    "citation_count": 3,
    "authors": [
      "Michael Fischer",
      "Zhengqin Li",
      "Thu Nguyen-Phuoc",
      "Aljaz Bozic",
      "Zhao Dong",
      "Carl Marshall",
      "Tobias Ritschel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Mind_Artist_Creating_Artistic_Snapshots_with_Human_Thought_CVPR_2024_paper.html": {
    "title": "Mind Artist: Creating Artistic Snapshots with Human Thought",
    "volume": "main",
    "abstract": "We introduce Mind Artist (MindArt) a novel and efficient neural decoding architecture to snap artistic photographs from our mind in a controllable manner. Recently progress has been made in image reconstruction with non-invasive brain recordings but it's still difficult to generate realistic images with high semantic fidelity due to the scarcity of data annotations. Unlike previous methods this work casts the neural decoding into optimal transport (OT) and representation decoupling problems. Specifically under discrete OT theory we design a graph matching-guided neural representation learning framework to seek the underlying correspondences between conceptual semantics and neural signals which yields a natural and meaningful self-supervisory task. Moreover the proposed MindArt structured with multiple stand-alone modal branches enables the seamless incorporation of semantic representation into any visual style information thus leaving it to have multi-modal reconstruction and training-free semantic editing capabilities. By doing so the reconstructed images of MindArt have phenomenal realism both in terms of semantics and appearance. We compare our MindArt with leading alternatives and achieve SOTA performance in different decoding tasks. Importantly our approach can directly generate a series of stylized \"mind snapshots\" w/o extra optimizations which may open up more potential applications. Code is available at https://github.com/JxuanC/MindArt",
    "checked": false,
    "id": "8b0c93d2f1353960bf1affcf6ada46720b03619a",
    "semantic_title": "creative expression on how do artists communicate their message: an arts in development article critique",
    "citation_count": 0,
    "authors": [
      "Jiaxuan Chen",
      "Yu Qi",
      "Yueming Wang",
      "Gang Pan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era_CVPR_2024_paper.html": {
    "title": "ViTamin: Designing Scalable Vision Models in the Vision-Language Era",
    "volume": "main",
    "abstract": "Recent breakthroughs in vision-language models (VLMs) start a new page in the vision community. The VLMs provide stronger and more generalizable feature embeddings compared to those from ImageNet-pretrained models thanks to the training on the large-scale Internet image-text pairs. However despite the amazing achievement from the VLMs vanilla Vision Transformers (ViTs) remain the default choice for the image encoder. Although pure transformer proves its effectiveness in the text encoding area it remains questionable whether it is also the case for image encoding especially considering that various types of networks are proposed on the ImageNet benchmark which unfortunately are rarely studied in VLMs. Due to small data/model scale the original conclusions of model design on ImageNet can be limited and biased. In this paper we aim at building an evaluation protocol of vision models in the vision-language era under the contrastive language-image pretraining (CLIP) framework. We provide a comprehensive way to benchmark different vision models covering their zero-shot performance and scalability in both model and training data sizes. To this end we introduce ViTamin a new vision models tailored for VLMs. ViTamin-L significantly outperforms ViT-L by 2.0% ImageNet zero-shot accuracy when using the same publicly available DataComp-1B dataset and the same OpenCLIP training scheme. ViTamin-L presents promising results on 60 diverse benchmarks including classification retrieval open-vocabulary detection and segmentation and large multi-modal models. When further scaling up the model size our ViTamin-XL with only 436M parameters attains 82.9% ImageNet zero-shot accuracy surpassing 82.0% achieved by EVA-E that has ten times more parameters (4.4B)",
    "checked": true,
    "id": "9efea405e5dfd277472f24f1dd95a26ca5734a6a",
    "semantic_title": "vitamin: designing scalable vision models in the vision-language era",
    "citation_count": 2,
    "authors": [
      "Jieneng Chen",
      "Qihang Yu",
      "Xiaohui Shen",
      "Alan Yuille",
      "Liang-Chieh Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ramasinghe_Accept_the_Modality_Gap_An_Exploration_in_the_Hyperbolic_Space_CVPR_2024_paper.html": {
    "title": "Accept the Modality Gap: An Exploration in the Hyperbolic Space",
    "volume": "main",
    "abstract": "Recent advancements in machine learning have spotlighted the potential of hyperbolic spaces as they effectively learn hierarchical feature representations. While there has been progress in leveraging hyperbolic spaces in single-modality contexts its exploration in multimodal settings remains under explored. Some recent efforts have sought to transpose Euclidean multimodal learning techniques to hyperbolic spaces by adopting geodesic distance based contrastive losses. However we show both theoretically and empirically that such spatial proximity based contrastive loss significantly disrupts hierarchies in the latent space. To remedy this we advocate that the cross-modal representations should accept the inherent modality gap between text and images and introduce a novel approach to measure cross-modal similarity that does not enforce spatial proximity. Our approach show remarkable capabilities in preserving unimodal hierarchies while aligning the two modalities. Our experiments on a series of downstream tasks demonstrate that better latent structure emerges with our objective function while being superior in text-to-image and image-to-text retrieval tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sameera Ramasinghe",
      "Violetta Shevchenko",
      "Gil Avraham",
      "Ajanthan Thalaiyasingam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Unraveling_Instance_Associations_A_Closer_Look_for_Audio-Visual_Segmentation_CVPR_2024_paper.html": {
    "title": "Unraveling Instance Associations: A Closer Look for Audio-Visual Segmentation",
    "volume": "main",
    "abstract": "Audio-visual segmentation (AVS) is a challenging task that involves accurately segmenting sounding objects based on audio-visual cues. The effectiveness of audio-visual learning critically depends on achieving accurate cross-modal alignment between sound and visual objects. Successful audio-visual learning requires two essential components: 1) a challenging dataset with high-quality pixel-level multi-class annotated images associated with audio files and 2) a model that can establish strong links between audio information and its corresponding visual object. However these requirements are only partially addressed by current methods with training sets containing biased audio-visual data and models that generalise poorly beyond this biased training set. In this work we propose a new cost-effective strategy to build challenging and relatively unbiased high-quality audio-visual segmentation benchmarks. We also propose a new informative sample mining method for audio-visual supervised contrastive learning to leverage discriminative contrastive samples to enforce cross-modal understanding. We show empirical results that demonstrate the effectiveness of our benchmark. Furthermore experiments conducted on existing AVS datasets and on our new benchmark show that our method achieves state-of-the-art (SOTA) segmentation accuracy",
    "checked": true,
    "id": "93ed8ac3198db2a420c9e3bc3dcebbf7ac30a6a2",
    "semantic_title": "unraveling instance associations: a closer look for audio-visual segmentation",
    "citation_count": 1,
    "authors": [
      "Yuanhong Chen",
      "Yuyuan Liu",
      "Hu Wang",
      "Fengbei Liu",
      "Chong Wang",
      "Helen Frazer",
      "Gustavo Carneiro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_Few-Shot_Object_Detection_with_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Few-Shot Object Detection with Foundation Models",
    "volume": "main",
    "abstract": "Few-shot object detection (FSOD) aims to detect objects with only a few training examples. Visual feature extraction and query-support similarity learning are the two critical components. Existing works are usually developed based on ImageNet pre-trained vision backbones and design sophisticated metric-learning networks for few-shot learning but still have inferior accuracy. In this work we study few-shot object detection using modern foundation models. First vision-only contrastive pre-trained DINOv2 model is used for the vision backbone which shows strong transferable performance without tuning the parameters. Second Large Language Model (LLM) is employed for contextualized few-shot learning with the input of all classes and query image proposals. Language instructions are carefully designed to prompt the LLM to classify each proposal in context. The contextual information include proposal-proposal relations proposal-class relations and class-class relations which can largely promote few-shot learning. We comprehensively evaluate the proposed model (FM-FSOD) in multiple FSOD benchmarks achieving state-of-the-arts performance",
    "checked": false,
    "id": "afc3dd0176d67df1e5200eaec4a738ccd17c9cc9",
    "semantic_title": "revisiting few-shot object detection with vision-language models",
    "citation_count": 2,
    "authors": [
      "Guangxing Han",
      "Ser-Nam Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_FedMef_Towards_Memory-efficient_Federated_Dynamic_Pruning_CVPR_2024_paper.html": {
    "title": "FedMef: Towards Memory-efficient Federated Dynamic Pruning",
    "volume": "main",
    "abstract": "Federated learning (FL) promotes decentralized training while prioritizing data confidentiality. However its application on resource-constrained devices is challenging due to the high demand for computation and memory resources to train deep learning models. Neural network pruning techniques such as dynamic pruning could enhance model efficiency but directly adopting them in FL still poses substantial challenges including post-pruning performance degradation high activation memory usage etc. To address these challenges we propose FedMef a novel and memory-efficient federated dynamic pruning framework. FedMef comprises two key components. First we introduce the budget-aware extrusion that maintains pruning efficiency while preserving post-pruning performance by salvaging crucial information from parameters marked for pruning within a given budget. Second we propose scaled activation pruning to effectively reduce activation memory footprints which is particularly beneficial for deploying FL to memory-limited devices. Extensive experiments demonstrate the effectiveness of our proposed FedMef. In particular it achieves a significant reduction of 28.5% in memory footprint compared to state-of-the-art methods while obtaining superior accuracy",
    "checked": true,
    "id": "5f154312bedaadac420212ce94a21fe9e871714f",
    "semantic_title": "fedmef: towards memory-efficient federated dynamic pruning",
    "citation_count": 0,
    "authors": [
      "Hong Huang",
      "Weiming Zhuang",
      "Chen Chen",
      "Lingjuan Lyu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ramrakhya_Seeing_the_Unseen_Visual_Common_Sense_for_Semantic_Placement_CVPR_2024_paper.html": {
    "title": "Seeing the Unseen: Visual Common Sense for Semantic Placement",
    "volume": "main",
    "abstract": "Computer vision tasks typically involve describing what is visible in an image (e.g. classification detection segmentation and captioning). We study a visual common sense task that requires understanding 'what is not visible'. Specifically given an image (e.g. of a living room) and a name of an object (\"cushion\") a vision system is asked to predict semantically-meaningful regions (masks or bounding boxes) in the image where that object could be placed or is likely be placed by humans (e.g. on the sofa). We call this task: Semantic Placement (SP) and believe that such common-sense visual understanding is critical for assitive robots (tidying a house) AR devices (automatically rendering an object in the user's space) and visually-grounded chatbots with common sense. Studying the invisible is hard. Datasets for image description are typically constructed by curating relevant images (e.g. via image search with object names) and asking humans to annotate the contents of the image; neither of those two steps are straightforward for objects not present in the image. We overcome this challenge by operating in the opposite direction: we start with an image of an object in context (which is easy to find online) and remove that object from the image via inpainting. This automated pipeline converts unstructured web data into a paired with/without object dataset. With this proposed data generation pipeline we collect a novel dataset containing 1.3M images across 9 object categories. We then train a SP prediction model called CLIP-UNet on our dataset. The CLIP-UNet outperforms existing VLMs and baselines that combine semantic priors with object detectors generalizes well to real-world and simulated images exhibits semantics-aware reasoning for object placement and enables downstream applications like tidying robots in indoor environments",
    "checked": true,
    "id": "d291f736a53b48c95edfb213e8d2a5fdeed31dd0",
    "semantic_title": "seeing the unseen: visual common sense for semantic placement",
    "citation_count": 0,
    "authors": [
      "Ram Ramrakhya",
      "Aniruddha Kembhavi",
      "Dhruv Batra",
      "Zsolt Kira",
      "Kuo-Hao Zeng",
      "Luca Weihs"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Texture-Preserving_Diffusion_Models_for_High-Fidelity_Virtual_Try-On_CVPR_2024_paper.html": {
    "title": "Texture-Preserving Diffusion Models for High-Fidelity Virtual Try-On",
    "volume": "main",
    "abstract": "Image-based virtual try-on is an increasingly important task for online shopping. It aims to synthesize images of a specific person wearing a specified garment. Diffusion model-based approaches have recently become popular as they are excellent at image synthesis tasks. However these approaches usually employ additional image encoders and rely on the cross-attention mechanism for texture transfer from the garment to the person image which affects the try-on's efficiency and fidelity. To address these issues we propose an Texture-Preserving Diffusion (TPD) model for virtual try-on which enhances the fidelity of the results and introduces no additional image encoders. Accordingly we make contributions from two aspects. First we propose to concatenate the masked person and reference garment images along the spatial dimension and utilize the resulting image as the input for the diffusion model's denoising UNet. This enables the original self-attention layers contained in the diffusion model to achieve efficient and accurate texture transfer. Second we propose a novel diffusion-based method that predicts a precise inpainting mask based on the person and reference garment images further enhancing the reliability of the try-on results. In addition we integrate mask prediction and image synthesis into a single compact model. The experimental results show that our approach can be applied to various try-on tasks e.g. garment-to-person and person-to-person try-ons and significantly outperforms state-of-the-art methods on popular VITON VITON-HD databases. Code is available at https://github.com/Gal4way/TPD",
    "checked": true,
    "id": "2d33241e726c4b607c1db6ae2a46fab83a079ab2",
    "semantic_title": "texture-preserving diffusion models for high-fidelity virtual try-on",
    "citation_count": 1,
    "authors": [
      "Xu Yang",
      "Changxing Ding",
      "Zhibin Hong",
      "Junhao Huang",
      "Jin Tao",
      "Xiangmin Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_PracticalDG_Perturbation_Distillation_on_Vision-Language_Models_for_Hybrid_Domain_Generalization_CVPR_2024_paper.html": {
    "title": "PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid Domain Generalization",
    "volume": "main",
    "abstract": "Domain Generalization (DG) aims to resolve distribution shifts between source and target domains and current DG methods are default to the setting that data from source and target domains share identical categories. Nevertheless there exists unseen classes from target domains in practical scenarios. To address this issue Open Set Domain Generalization (OSDG) has emerged and several methods have been exclusively proposed. However most existing methods adopt complex architectures with slight improvement compared with DG methods. Recently vision-language models (VLMs) have been introduced in DG following the fine-tuning paradigm but consume huge training overhead with large vision models. Therefore in this paper we innovate to transfer knowledge from VLMs to lightweight vision models and improve the robustness by introducing Perturbation Distillation (PD) from three perspectives including Score Class and Instance (SCI) named SCI-PD. Moreover previous methods are oriented by the benchmarks with identical and fixed splits ignoring the divergence between source domains. These methods are revealed to suffer from sharp performance decay with our proposed new benchmark Hybrid Domain Generalization (HDG) and a novel metric H^ 2 -CV which construct various splits to comprehensively assess the robustness of algorithms. Extensive experiments demonstrate that our method outperforms state-of-the-art algorithms on multiple datasets especially improving the robustness when confronting data scarcity",
    "checked": true,
    "id": "c3e7fd4568a46693e349b9d8da74bf63e477cec7",
    "semantic_title": "practicaldg: perturbation distillation on vision-language models for hybrid domain generalization",
    "citation_count": 0,
    "authors": [
      "Zining Chen",
      "Weiqiu Wang",
      "Zhicheng Zhao",
      "Fei Su",
      "Aidong Men",
      "Hongying Meng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hudson_SODA_Bottleneck_Diffusion_Models_for_Representation_Learning_CVPR_2024_paper.html": {
    "title": "SODA: Bottleneck Diffusion Models for Representation Learning",
    "volume": "main",
    "abstract": "We introduce SODA a self-supervised diffusion model designed for representation learning. The model incorporates an image encoder which distills a source view into a compact representation that in turn guides the generation of related novel views. We show that by imposing a tight bottleneck between the encoder and a denoising decoder and leveraging novel view synthesis as a self-supervised objective we can turn diffusion models into strong representation learners capable of capturing visual semantics in an unsupervised manner. To the best of our knowledge SODA is the first diffusion model to succeed at ImageNet linear-probe classification and at the same time it accomplishes reconstruction editing and synthesis tasks across a wide range of datasets. Further investigation reveals the disentangled nature of its emergent latent space that serves as an effective interface to control and manipulate the produced images. All in all we aim to shed light on the exciting and promising potential of diffusion models not only for image generation but also for learning rich and robust representations. See our website at soda-diffusion.github.io",
    "checked": true,
    "id": "3852b468bd6c5a22e1c13a425fdd7604b5bcb7e2",
    "semantic_title": "soda: bottleneck diffusion models for representation learning",
    "citation_count": 5,
    "authors": [
      "Drew A. Hudson",
      "Daniel Zoran",
      "Mateusz Malinowski",
      "Andrew K. Lampinen",
      "Andrew Jaegle",
      "James L. McClelland",
      "Loic Matthey",
      "Felix Hill",
      "Alexander Lerchner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_Towards_Robust_Event-guided_Low-Light_Image_Enhancement_A_Large-Scale_Real-World_Event-Image_CVPR_2024_paper.html": {
    "title": "Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale Real-World Event-Image Dataset and Novel Approach",
    "volume": "main",
    "abstract": "Event camera has recently received much attention for low-light image enhancement (LIE) thanks to their distinct advantages such as high dynamic range. However current research is prohibitively restricted by the lack of large-scale real-world and spatial-temporally aligned event-image datasets. To this end we propose a real-world (indoor and outdoor) dataset comprising over 30K pairs of images and events under both low and normal illumination conditions. To achieve this we utilize a robotic arm that traces a consistent non-linear trajectory to curate the dataset with spatial alignment precision under 0.03mm. We then introduce a matching alignment strategy rendering 90% of our dataset with errors less than 0.01s. Based on the dataset we propose a novel event-guided LIE approach called EvLight towards robust performance in real-world low-light scenes. Specifically we first design the multi-scale holistic fusion branch to extract holistic structural and textural information from both events and images. To ensure robustness against variations in the regional illumination and noise we then introduce a Signal-to-Noise-Ratio (SNR)-guided regional feature selection to selectively fuse features of images from regions with high SNR and enhance those with low SNR by extracting regional structural information from events. our EvLight significantly surpasses the frame-based methods e.g. Retinexformer by 1.14 dB and 2.62 dB respectively. Code and datasets are available at https://vlislab22.github.io/eg-lowlight/",
    "checked": true,
    "id": "95c900205dcbdfa166a62d3833fe45bd75f47fba",
    "semantic_title": "towards robust event-guided low-light image enhancement: a large-scale real-world event-image dataset and novel approach",
    "citation_count": 1,
    "authors": [
      "Guoqiang Liang",
      "Kanghao Chen",
      "Hangyu Li",
      "Yunfan Lu",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Zero-Reference_Low-Light_Enhancement_via_Physical_Quadruple_Priors_CVPR_2024_paper.html": {
    "title": "Zero-Reference Low-Light Enhancement via Physical Quadruple Priors",
    "volume": "main",
    "abstract": "Understanding illumination and reducing the need for supervision pose a significant challenge in low-light enhancement. Current approaches are highly sensitive to data usage during training and illumination-specific hyper-parameters limiting their ability to handle unseen scenarios. In this paper we propose a new zero-reference low-light enhancement framework trainable solely with normal light images. To accomplish this we devise an illumination-invariant prior inspired by the theory of physical light transfer. This prior serves as the bridge between normal and low-light images. Then we develop a prior-to-image framework trained without low-light data. During testing this framework is able to restore our illumination-invariant prior back to images automatically achieving low-light enhancement. Within this framework we leverage a pretrained generative diffusion model for model ability introduce a bypass decoder to handle detail distortion as well as offer a lightweight version for practicality. Extensive experiments demonstrate our framework's superiority in various scenarios as well as good interpretability robustness and efficiency. Code is available on our project homepage: http://daooshee.github.io/QuadPrior-Website/",
    "checked": true,
    "id": "1303dc04e2b62da76d52c5f46b9face33c3767a5",
    "semantic_title": "zero-reference low-light enhancement via physical quadruple priors",
    "citation_count": 1,
    "authors": [
      "Wenjing Wang",
      "Huan Yang",
      "Jianlong Fu",
      "Jiaying Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zou_LLaMA-Excitor_General_Instruction_Tuning_via_Indirect_Feature_Interaction_CVPR_2024_paper.html": {
    "title": "LLaMA-Excitor: General Instruction Tuning via Indirect Feature Interaction",
    "volume": "main",
    "abstract": "Existing methods to fine-tune LLMs like Adapter Prefix-tuning and LoRA which introduce extra modules or additional input sequences to inject new skills or knowledge may compromise the innate abilities of LLMs. In this paper we propose LLaMA-Excitor a lightweight method that stimulates the LLMs' potential to better follow instructions by gradually paying more attention to worthwhile information. Specifically the LLaMA-Excitor does not directly change the intermediate hidden state during the self-attention calculation of the transformer structure. We designed the Excitor block as a bypass module for the similarity score computation in LLMs' self-attention to reconstruct keys and change the importance of values by learnable prompts. LLaMA-Excitor ensures a self-adaptive allocation of additional attention to input instructions thus effectively preserving LLMs' pre-trained knowledge when fine-tuning LLMs on low-quality instruction-following datasets. Furthermore we unify the modeling of multi-modal tuning and language-only tuning extending LLaMA-Excitor to a powerful visual instruction follower without the need for complex multi-modal alignment. Our proposed approach is evaluated in language-only and multi-modal tuning experimental scenarios. Notably LLaMA-Excitor is the only method that maintains basic capabilities while achieving a significant improvement (+6%) on the MMLU benchmark. In the visual instruction tuning we achieve a new state-of-the-art image captioning performance of 157.5 CIDEr on MSCOCO and a comparable performance (88.39%) on ScienceQA to cutting-edge models with more parameters and extensive vision-language pertaining",
    "checked": true,
    "id": "f6dcdc1ec9f0103bf28cb84fd9b704cc1d042fe9",
    "semantic_title": "llama-excitor: general instruction tuning via indirect feature interaction",
    "citation_count": 2,
    "authors": [
      "Bo Zou",
      "Chao Yang",
      "Yu Qiao",
      "Chengbin Quan",
      "Youjian Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_NeRFCodec_Neural_Feature_Compression_Meets_Neural_Radiance_Fields_for_Memory-Efficient_CVPR_2024_paper.html": {
    "title": "NeRFCodec: Neural Feature Compression Meets Neural Radiance Fields for Memory-Efficient Scene Representation",
    "volume": "main",
    "abstract": "The emergence of Neural Radiance Fields (NeRF) has greatly impacted 3D scene modeling and novel-view synthesis. As a kind of visual media for 3D scene representation compression with high rate-distortion performance is an eternal target. Motivated by advances in neural compression and neural field representation we propose NeRFCodec an end-to-end NeRF compression framework that integrates non-linear transform quantization and entropy coding for memory-efficient scene representation. Since training a non-linear transform directly on a large scale of NeRF feature planes is impractical we discover that pre-trained neural 2D image codec can be utilized for compressing the features when adding content-specific parameters. Specifically we reuse neural 2D image codec but modify its encoder and decoder heads while keeping the other parts of the pre-trained decoder frozen. This allows us to train the full pipeline via supervision of rendering loss and entropy loss yielding the rate-distortion balance by updating the content-specific parameters. At test time the bitstreams containing latent code feature decoder head and other side information are transmitted for communication. Experimental results demonstrate our method outperforms existing NeRF compression methods enabling high-quality novel view synthesis with a memory budget of 0.5 MB",
    "checked": true,
    "id": "019a29f933af19a813ae28f36a41926bbe792743",
    "semantic_title": "nerfcodec: neural feature compression meets neural radiance fields for memory-efficient scene representation",
    "citation_count": 1,
    "authors": [
      "Sicheng Li",
      "Hao Li",
      "Yiyi Liao",
      "Lu Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qian_From_a_Birds_Eye_View_to_See_Joint_Camera_and_CVPR_2024_paper.html": {
    "title": "From a Bird's Eye View to See: Joint Camera and Subject Registration without the Camera Calibration",
    "volume": "main",
    "abstract": "We tackle a new problem of multi-view camera and subject registration in the bird's eye view (BEV) without pre-given camera calibration which promotes the multi-view subject registration problem to a new calibration-free stage. This greatly alleviates the limitation in many practical applications. However this is a very challenging problem since its only input is several RGB images from different first-person views (FPVs) without the BEV image and the calibration of the FPVs while the output is a unified plane aggregated from all views with the positions and orientations of both the subjects and cameras in a BEV. For this purpose we propose an end-to-end framework solving camera and subject registration together by taking advantage of their mutual dependence whose main idea is as below: i) creating a subject view-transform module (VTM) to project each pedestrian from FPV to a virtual BEV ii) deriving a multi-view geometry-based spatial alignment module (SAM) to estimate the relative camera pose in a unified BEV iii) selecting and refining the subject and camera registration results within the unified BEV. We collect a new large-scale synthetic dataset with rich annotations for training and evaluation. Additionally we also collect a real dataset for cross-domain evaluation. The experimental results show the remarkable effectiveness of our method. The code and proposed datasets are available at https://github.com/zekunqian/BEVSee",
    "checked": true,
    "id": "f3f5c0bdb6578b7ecbcf7fc5e7f7efdd1fcdfbd4",
    "semantic_title": "from a bird's eye view to see: joint camera and subject registration without the camera calibration",
    "citation_count": 0,
    "authors": [
      "Zekun Qian",
      "Ruize Han",
      "Wei Feng",
      "Song Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bokman_Steerers_A_Framework_for_Rotation_Equivariant_Keypoint_Descriptors_CVPR_2024_paper.html": {
    "title": "Steerers: A Framework for Rotation Equivariant Keypoint Descriptors",
    "volume": "main",
    "abstract": "Image keypoint descriptions that are discriminative and matchable over large changes in viewpoint are vital for 3D reconstruction. However descriptions output by learned descriptors are typically not robust to camera rotation. While they can be made more robust by e.g. data aug-mentation this degrades performance on upright images. Another approach is test-time augmentation which incurs a significant increase in runtime. Instead we learn a lin-ear transform in description space that encodes rotations of the input image. We call this linear transform a steerer since it allows us to transform the descriptions as if the im-age was rotated. From representation theory we know all possible steerers for the rotation group. Steerers can be optimized (A) given a fixed descriptor (B) jointly with a de-scriptor or (C) we can optimize a descriptor given a fixed steerer. We perform experiments in these three settings and obtain state-of-the-art results on the rotation invariant im-age matching benchmarks AIMS and Roto-360",
    "checked": true,
    "id": "2bb9eb456810821a7c1856d489bca34084e3e631",
    "semantic_title": "steerers: a framework for rotation equivariant keypoint descriptors",
    "citation_count": 3,
    "authors": [
      "Georg Bökman",
      "Johan Edstedt",
      "Michael Felsberg",
      "Fredrik Kahl"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_Efficient_Dataset_Distillation_via_Minimax_Diffusion_CVPR_2024_paper.html": {
    "title": "Efficient Dataset Distillation via Minimax Diffusion",
    "volume": "main",
    "abstract": "Dataset distillation reduces the storage and computational consumption of training a network by generating a small surrogate dataset that encapsulates rich information of the original large-scale one. However previous distillation methods heavily rely on the sample-wise iterative optimization scheme. As the images-per-class (IPC) setting or image resolution grows larger the necessary computation will demand overwhelming time and resources. In this work we intend to incorporate generative diffusion techniques for computing the surrogate dataset. Observing that key factors for constructing an effective surrogate dataset are representativeness and diversity we design additional minimax criteria in the generative training to enhance these facets for the generated images of diffusion models. We present a theoretical model of the process as hierarchical diffusion control demonstrating the flexibility of the diffusion process to target these criteria without jeopardizing the faithfulness of the sample to the desired distribution. The proposed method achieves state-of-the-art validation performance while demanding much less computational resources. Under the 100-IPC setting on ImageWoof our method requires less than one-twentieth the distillation time of previous methods yet yields even better performance. Source code and generated data are available in https://github.com/vimar-gu/MinimaxDiffusion",
    "checked": true,
    "id": "0cf54616ef7279938085e41fb49f1b472c7d9ad7",
    "semantic_title": "efficient dataset distillation via minimax diffusion",
    "citation_count": 4,
    "authors": [
      "Jianyang Gu",
      "Saeed Vahidian",
      "Vyacheslav Kungurtsev",
      "Haonan Wang",
      "Wei Jiang",
      "Yang You",
      "Yiran Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Koo_Posterior_Distillation_Sampling_CVPR_2024_paper.html": {
    "title": "Posterior Distillation Sampling",
    "volume": "main",
    "abstract": "We introduce Posterior Distillation Sampling (PDS) a novel optimization method for parametric image editing based on diffusion models. Existing optimization-based methods which leverage the powerful 2D prior of diffusion models to handle various parametric images have mainly focused on generation. Unlike generation editing requires a balance between conforming to the target attribute and preserving the identity of the source content. Recent 2D image editing methods have achieved this balance by leveraging the stochastic latent encoded in the generative process of diffusion models. To extend the editing capabilities of diffusion models shown in pixel space to parameter space we reformulate the 2D image editing method into an optimization form named PDS. PDS matches the stochastic latents of the source and the target enabling the sampling of targets in diverse parameter spaces that align with a desired attribute while maintaining the source's identity. We demonstrate that this optimization resembles running a generative process with the target attribute but aligning this process with the trajectory of the source's generative process. Extensive editing results in Neural Radiance Fields and Scalable Vector Graphics representations demonstrate that PDS is capable of sampling targets to fulfill the aforementioned balance across various parameter spaces",
    "checked": true,
    "id": "0a7d4e469dc469d47f366b10d687b71208dc5c09",
    "semantic_title": "posterior distillation sampling",
    "citation_count": 5,
    "authors": [
      "Juil Koo",
      "Chanho Park",
      "Minhyuk Sung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_HOISDF_Constraining_3D_Hand-Object_Pose_Estimation_with_Global_Signed_Distance_CVPR_2024_paper.html": {
    "title": "HOISDF: Constraining 3D Hand-Object Pose Estimation with Global Signed Distance Fields",
    "volume": "main",
    "abstract": "Human hands are highly articulated and versatile at handling objects. Jointly estimating the 3D poses of a hand and the object it manipulates from a monocular camera is challenging due to frequent occlusions. Thus existing methods often rely on intermediate 3D shape representations to increase performance. These representations are typically explicit such as 3D point clouds or meshes and thus provide information in the direct surroundings of the intermediate hand pose estimate. To address this we introduce HOISDF a Signed Distance Field (SDF) guided hand-object pose estimation network which jointly exploits hand and object SDFs to provide a global implicit representation over the complete reconstruction volume. Specifically the role of the SDFs is threefold: equip the visual encoder with implicit shape information help to encode hand-object interactions and guide the hand and object pose regression via SDF-based sampling and by augmenting the feature representations. We show that HOISDF achieves state-of-the-art results on hand-object pose estimation benchmarks (DexYCB and HO3Dv2). Code is available https://github.com/amathislab/HOISDF",
    "checked": true,
    "id": "488f9362c39a5da81dcec5e677e687b37ddd030d",
    "semantic_title": "hoisdf: constraining 3d hand-object pose estimation with global signed distance fields",
    "citation_count": 3,
    "authors": [
      "Haozhe Qi",
      "Chen Zhao",
      "Mathieu Salzmann",
      "Alexander Mathis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Enhancing_Video_Super-Resolution_via_Implicit_Resampling-based_Alignment_CVPR_2024_paper.html": {
    "title": "Enhancing Video Super-Resolution via Implicit Resampling-based Alignment",
    "volume": "main",
    "abstract": "In video super-resolution it is common to use a frame-wise alignment to support the propagation of information over time. The role of alignment is well-studied for low-level enhancement in video but existing works overlook a critical step -- resampling. We show through extensive experiments that for alignment to be effective the resampling should preserve the reference frequency spectrum while minimizing spatial distortions. However most existing works simply use a default choice of bilinear interpolation for resampling even though bilinear interpolation has a smoothing effect and hinders super-resolution. From these observations we propose an implicit resampling-based alignment. The sampling positions are encoded by a sinusoidal positional encoding while the value is estimated with a coordinate network and a window-based cross-attention. We show that bilinear interpolation inherently attenuates high-frequency information while an MLP-based coordinate network can approximate more frequencies. Experiments on synthetic and real-world datasets show that alignment with our proposed implicit resampling enhances the performance of state-of-the-art frameworks with minimal impact on both compute and parameters",
    "checked": true,
    "id": "45261217a804750f64dde7d2569ce559c696f06c",
    "semantic_title": "enhancing video super-resolution via implicit resampling-based alignment",
    "citation_count": 1,
    "authors": [
      "Kai Xu",
      "Ziwei Yu",
      "Xin Wang",
      "Michael Bi Mi",
      "Angela Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_DiffPortrait3D_Controllable_Diffusion_for_Zero-Shot_Portrait_View_Synthesis_CVPR_2024_paper.html": {
    "title": "DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis",
    "volume": "main",
    "abstract": "We present DiffPortrait3D a conditional diffusion model that is capable of synthesizing 3D-consistent photo-realistic novel views from as few as a single in-the-wild portrait. Specifically given a single RGB input we aim to synthesize plausible but consistent facial details rendered from novel camera views with retained both identity and facial expression. In lieu of time-consuming optimization and fine-tuning our zero-shot method generalizes well to arbitrary face portraits with unposed camera views extreme facial expressions and diverse artistic depictions. At its core we leverage the generative prior of 2D diffusion models pre-trained on large-scale image datasets as our rendering backbone while the denoising is guided with disentangled attentive control of appearance and camera pose. To achieve this we first inject the appearance context from the reference image into the self-attention layers of the frozen UNets. The rendering view is then manipulated with a novel conditional control module that interprets the camera pose by watching a condition image of a crossed subject from the same view. Furthermore we insert a trainable cross-view attention module to enhance view consistency which is further strengthened with a novel 3D-aware noise generation process during inference. We demonstrate state-of-the-art results both qualitatively and quantitatively on our challenging in-the-wild and multi-view benchmarks",
    "checked": true,
    "id": "d344e6dac4c33e016839046316d92355a8059263",
    "semantic_title": "diffportrait3d: controllable diffusion for zero-shot portrait view synthesis",
    "citation_count": 2,
    "authors": [
      "Yuming Gu",
      "Hongyi Xu",
      "You Xie",
      "Guoxian Song",
      "Yichun Shi",
      "Di Chang",
      "Jing Yang",
      "Linjie Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Noman_Rethinking_Transformers_Pre-training_for_Multi-Spectral_Satellite_Imagery_CVPR_2024_paper.html": {
    "title": "Rethinking Transformers Pre-training for Multi-Spectral Satellite Imagery",
    "volume": "main",
    "abstract": "Recent advances in unsupervised learning have demonstrated the ability of large vision models to achieve promising results on downstream tasks by pre-training on large amount of unlabelled data. Such pre-training techniques have also been explored recently in the remote sensing domain due to the availability of large amount of unlabelled data. Different from standard natural image datasets remote sensing data is acquired from various sensor technologies and exhibit diverse range of scale variations as well as modalities. Existing satellite image pre-training methods either ignore the scale information present in the remote sensing imagery or restrict themselves to use only a single type of data modality. In this paper we re-visit transformers pre-training and leverage multi-scale information that is effectively utilized with multiple modalities. Our proposed approach named SatMAE++ performs multi-scale pre-training and utilizes convolution based upsampling blocks to reconstruct the image at higher scales making it extensible to include more scales. Compared to existing works the proposed SatMAE++ with multi-scale pre-training is equally effective for both optical as well as multi-spectral imagery. Extensive experiments on six datasets reveal the merits of proposed contributions leading to state-of-the-art performance on all datasets. SatMAE++ achieves mean average precision (mAP) gain of 2.5% for multi-label classification task on BigEarthNet dataset",
    "checked": true,
    "id": "166b87a538dcabd950699870ed9e7c666d0792eb",
    "semantic_title": "rethinking transformers pre-training for multi-spectral satellite imagery",
    "citation_count": 8,
    "authors": [
      "Mubashir Noman",
      "Muzammal Naseer",
      "Hisham Cholakkal",
      "Rao Muhammad Anwer",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_LLM4SGG_Large_Language_Models_for_Weakly_Supervised_Scene_Graph_Generation_CVPR_2024_paper.html": {
    "title": "LLM4SGG: Large Language Models for Weakly Supervised Scene Graph Generation",
    "volume": "main",
    "abstract": "Weakly-Supervised Scene Graph Generation (WSSGG) research has recently emerged as an alternative to the fully-supervised approach that heavily relies on costly annotations. In this regard studies on WSSGG have utilized image captions to obtain unlocalized triplets while primarily focusing on grounding the unlocalized triplets over image regions. However they have overlooked the two issues involved in the triplet formation process from the captions: 1) Semantic over-simplification issue arises when extracting triplets from captions where fine-grained predicates in captions are undesirably converted into coarse-grained predicates resulting in a long-tailed predicate distribution and 2) Low-density scene graph issue arises when aligning the triplets in the caption with entity/predicate classes of interest where many triplets are discarded and not used in training leading to insufficient supervision. To tackle the two issues we propose a new approach i.e. Large Language Model for weakly-supervised SGG (LLM4SGG) where we mitigate the two issues by leveraging the LLM's in-depth understanding of language and reasoning ability during the extraction of triplets from captions and alignment of entity/predicate classes with target data. To further engage the LLM in these processes we adopt the idea of Chain-of-Thought and the in-context few-shot learning strategy. To validate the effectiveness of LLM4SGG we conduct extensive experiments on Visual Genome and GQA datasets showing significant improvements in both Recall@K and mean Recall@K compared to the state-of-the-art WSSGG methods. A further appeal is that LLM4SGG is data-efficient enabling effective model training with a small amount of training images",
    "checked": true,
    "id": "630d0905750582385aadb8c23df5ff7f1346cc9d",
    "semantic_title": "llm4sgg: large language models for weakly supervised scene graph generation",
    "citation_count": 5,
    "authors": [
      "Kibum Kim",
      "Kanghoon Yoon",
      "Jaehyeong Jeon",
      "Yeonjun In",
      "Jinyoung Moon",
      "Donghyun Kim",
      "Chanyoung Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_Parameter_Efficient_Fine-tuning_via_Cross_Block_Orchestration_for_Segment_Anything_CVPR_2024_paper.html": {
    "title": "Parameter Efficient Fine-tuning via Cross Block Orchestration for Segment Anything Model",
    "volume": "main",
    "abstract": "Parameter-efficient fine-tuning (PEFT) is an effective methodology to unleash the potential of large foundation models in novel scenarios with limited training data. In the computer vision community PEFT has shown effectiveness in image classification but little research has studied its ability for image segmentation. Fine-tuning segmentation models usually require a heavier adjustment of parameters to align the proper projection directions in the parameter space for new scenarios. This raises a challenge to existing PEFT algorithms as they often inject a limited number of individual parameters into each block which prevents substantial adjustment of the projection direction of the parameter space due to the limitation of Hidden Markov Chain along blocks. In this paper we equip PEFT with a cross-block orchestration mechanism to enable the adaptation of the Segment Anything Model (SAM) to various downstream scenarios. We introduce a novel inter-block communication module which integrates a learnable relation matrix to facilitate communication among different coefficient sets of each PEFT block's parameter space. Moreover we propose an intra-block enhancement module which introduces a linear projection head whose weights are generated from a hyper-complex layer further enhancing the impact of the adjustment of projection directions on the entire parameter space. Extensive experiments on diverse benchmarks demonstrate that our proposed approach consistently improves the segmentation performance significantly on novel scenarios with only around 1K additional parameters",
    "checked": true,
    "id": "210492a9053bb82f0d6a4b3794bde36d2240595f",
    "semantic_title": "parameter efficient fine-tuning via cross block orchestration for segment anything model",
    "citation_count": 1,
    "authors": [
      "Zelin Peng",
      "Zhengqin Xu",
      "Zhilin Zeng",
      "Lingxi Xie",
      "Qi Tian",
      "Wei Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Neural_Directional_Encoding_for_Efficient_and_Accurate_View-Dependent_Appearance_Modeling_CVPR_2024_paper.html": {
    "title": "Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling",
    "volume": "main",
    "abstract": "Novel-view synthesis of specular objects like shiny metals or glossy paints remains a significant challenge. Not only the glossy appearance but also global illumination effects including reflections of other objects in the environment are critical components to faithfully reproduce a scene. In this paper we present Neural Directional Encoding (NDE) a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects. NDE transfers the concept of feature-grid-based spatial encoding to the angular domain significantly improving the ability to model high-frequency angular signals. In contrast to previous methods that use encoding functions with only angular input we additionally cone-trace spatial features to obtain a spatially varying directional encoding which addresses the challenging interreflection effects. Extensive experiments on both synthetic and real datasets show that a NeRF model with NDE (1) outperforms the state of the art on view synthesis of specular objects and (2) works with small networks to allow fast (real-time) inference. The source code is available at: https://github.com/lwwu2/nde",
    "checked": true,
    "id": "37894ad3a2c5f98c33e3643df6e629aee85f73b7",
    "semantic_title": "neural directional encoding for efficient and accurate view-dependent appearance modeling",
    "citation_count": 1,
    "authors": [
      "Liwen Wu",
      "Sai Bi",
      "Zexiang Xu",
      "Fujun Luan",
      "Kai Zhang",
      "Iliyan Georgiev",
      "Kalyan Sunkavalli",
      "Ravi Ramamoorthi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chihaoui_Masked_and_Shuffled_Blind_Spot_Denoising_for_Real-World_Images_CVPR_2024_paper.html": {
    "title": "Masked and Shuffled Blind Spot Denoising for Real-World Images",
    "volume": "main",
    "abstract": "We introduce a novel approach to single image denoising based on the Blind Spot Denoising principle which we call MAsked and SHuffled Blind Spot Denoising (MASH). We focus on the case of correlated noise which often plagues real images. MASH is the result of a careful analysis to determine the relationships between the level of blindness (masking) of the input and the (unknown) noise correlation. Moreover we introduce a shuffling technique to weaken the local correlation of noise which in turn yields an additional denoising performance improvement. We evaluate MASH via extensive experiments on real-world noisy image datasets. We demonstrate state-of-the-art results compared to existing self-supervised denoising methods",
    "checked": true,
    "id": "004b12cdde7afc5ad6eccba88018f18906f0fe70",
    "semantic_title": "masked and shuffled blind spot denoising for real-world images",
    "citation_count": 0,
    "authors": [
      "Hamadi Chihaoui",
      "Paolo Favaro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Stojni_Label_Propagation_for_Zero-shot_Classification_with_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Label Propagation for Zero-shot Classification with Vision-Language Models",
    "volume": "main",
    "abstract": "Vision-Language Models (VLMs) have demonstrated impressive performance on zero-shot classification i.e. classification when provided merely with a list of class names. In this paper we tackle the case of zero-shot classification in the presence of unlabeled data. We leverage the graph structure of the unlabeled data and introduce ZLaP a method based on label propagation (LP) that utilizes geodesic distances for classification. We tailor LP to graphs containing both text and image features and further propose an efficient method for performing inductive inference based on a dual solution and a sparsification step. We perform extensive experiments to evaluate the effectiveness of our method on 14 common datasets and show that ZLaP outperforms the latest related works. Code: https://github.com/vladan-stojnic/ZLaP",
    "checked": true,
    "id": "0e1edb328b02e4a98072dcf22357ee78dfdec3c4",
    "semantic_title": "label propagation for zero-shot classification with vision-language models",
    "citation_count": 1,
    "authors": [
      "Vladan Stojni?",
      "Yannis Kalantidis",
      "Giorgos Tolias"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kirschstein_DiffusionAvatars_Deferred_Diffusion_for_High-fidelity_3D_Head_Avatars_CVPR_2024_paper.html": {
    "title": "DiffusionAvatars: Deferred Diffusion for High-fidelity 3D Head Avatars",
    "volume": "main",
    "abstract": "DiffusionAvatars synthesizes a high-fidelity 3D head avatar of a person offering intuitive control over both pose and expression. We propose a diffusion-based neural renderer that leverages generic 2D priors to produce compelling images of faces. For coarse guidance of the expression and head pose we render a neural parametric head model (NPHM) from the target viewpoint which acts as a proxy geometry of the person. Additionally to enhance the modeling of intricate facial expressions we condition DiffusionAvatars directly on the expression codes obtained from NPHM via cross-attention. Finally to synthesize consistent surface details across different viewpoints and expressions we rig learnable spatial features to the head's surface via TriPlane lookup in NPHM's canonical space. We train DiffusionAvatars on RGB videos and corresponding fitted NPHM meshes of a person and test the obtained avatars in both self-reenactment and animation scenarios. Our experiments demonstrate that DiffusionAvatars generates temporally consistent and visually appealing videos for novel poses and expressions of a person outperforming existing approaches",
    "checked": true,
    "id": "74c2a506073528c65e58a98620049c4090cdf52d",
    "semantic_title": "diffusionavatars: deferred diffusion for high-fidelity 3d head avatars",
    "citation_count": 3,
    "authors": [
      "Tobias Kirschstein",
      "Simon Giebenhain",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Data-Free_Quantization_via_Pseudo-label_Filtering_CVPR_2024_paper.html": {
    "title": "Data-Free Quantization via Pseudo-label Filtering",
    "volume": "main",
    "abstract": "Quantization for model compression can efficiently reduce the network complexity and storage requirement but the original training data is necessary to remedy the performance loss caused by quantization. The Data-Free Quantization (DFQ) methods have been proposed to handle the absence of original training data with synthetic data. However there are differences between the synthetic and original training data which affects the performance of the quantized network but none of the existing methods considers the differences. In this paper we propose an efficient data-free quantization via pseudo-label filtering which is the first to evaluate the synthetic data before quantization. We design a new metric for evaluating synthetic data using self-entropy which indicates the reliability of synthetic data. The synthetic data can be categorized with the metric into high- and low-reliable datasets for the following training process. Besides the multiple pseudo-labels are designed to label the synthetic data with different reliability which can provide valuable supervision information and avoid misleading training by low-reliable samples. Extensive experiments are implemented on several datasets including CIFAR-10 CIFAR-100 and ImageNet with various models. The experimental results show that our method can perform excellently and outperform existing methods in accuracy",
    "checked": false,
    "id": "6fc0fa563148f768e3c18d67b405bbfbc5b907cf",
    "semantic_title": "federated domain adaptation via pseudo-label refinement",
    "citation_count": 0,
    "authors": [
      "Chunxiao Fan",
      "Ziqi Wang",
      "Dan Guo",
      "Meng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tao_Revisiting_Global_Translation_Estimation_with_Feature_Tracks_CVPR_2024_paper.html": {
    "title": "Revisiting Global Translation Estimation with Feature Tracks",
    "volume": "main",
    "abstract": "Global translation estimation is a highly challenging step in the global structure from motion (SfM) algorithm. Many existing methods depend solely on relative translations leading to inaccuracies in low parallax scenes and degradation under collinear camera motion. While recent approaches aim to address these issues by incorporating feature tracks into objective functions they are often sensitive to outliers. In this paper we first revisit global translation estimation methods with feature tracks and categorize them into explicit and implicit methods. Then we highlight the superiority of the objective function based on the cross-product distance metric and propose a novel explicit global translation estimation framework that integrates both relative translations and feature tracks as input. To enhance the accuracy of input observations we re-estimate relative translations with the coplanarity constraint of the epipolar plane and propose a simple yet effective strategy to select reliable feature tracks. Finally the effectiveness of our approach is demonstrated through experiments on urban image sequences and unordered Internet images showcasing its superior accuracy and robustness compared to many state-of-the-art techniques",
    "checked": false,
    "id": "b029d810d34829db20d2e42ac32f0b6b2cc86ce5",
    "semantic_title": "learning cross-modal interaction for rgb-t tracking",
    "citation_count": 0,
    "authors": [
      "Peilin Tao",
      "Hainan Cui",
      "Mengqi Rong",
      "Shuhan Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choe_Open-Set_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Open-Set Domain Adaptation for Semantic Segmentation",
    "volume": "main",
    "abstract": "Unsupervised domain adaptation (UDA) for semantic segmentation aims to transfer the pixel-wise knowledge from the labeled source domain to the unlabeled target domain. However current UDA methods typically assume a shared label space between source and target limiting their applicability in real-world scenarios where novel categories may emerge in the target domain. In this paper we introduce Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) for the first time where the target domain includes unknown classes. We identify two major problems in the OSDA-SS scenario as follows: 1) the existing UDA methods struggle to predict the exact boundary of the unknown classes and 2) they fail to accurately predict the shape of the unknown classes. To address these issues we propose Boundary and Unknown Shape-Aware open-set domain adaptation coined BUS. Our BUS can accurately discern the boundaries between known and unknown classes in a contrastive manner using a novel dilation-erosion-based contrastive loss. In addition we propose OpenReMix a new domain mixing augmentation method that guides our model to effectively learn domain and size-invariant features for improving the shape detection of the known and unknown classes. Through extensive experiments we demonstrate that our proposed BUS effectively detects unknown classes in the challenging OSDA-SS scenario compared to the previous methods by a large margin",
    "checked": true,
    "id": "ff1e14330b66816f89b11b9aaeaec1928944e9fb",
    "semantic_title": "open-set domain adaptation for semantic segmentation",
    "citation_count": 0,
    "authors": [
      "Seun-An Choe",
      "Ah-Hyung Shin",
      "Keon-Hee Park",
      "Jinwoo Choi",
      "Gyeong-Moon Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Generative_Powers_of_Ten_CVPR_2024_paper.html": {
    "title": "Generative Powers of Ten",
    "volume": "main",
    "abstract": "We present a method that uses a text-to-image model to generate consistent content across multiple image scales enabling extreme semantic zooms into a scene e.g. ranging from a wide-angle landscape view of a forest to a macro shot of an insect sitting on one of the tree branches. We achieve this through a joint multi-scale diffusion sampling approach that encourages consistency across different scales while preserving the integrity of each individual sampling process. Since each generated scale is guided by a different text prompt our method enables deeper levels of zoom than traditional super-resolution methods that may struggle to create new contextual structure at vastly different scales. We compare our method qualitatively with alternative techniques in image super-resolution and outpainting and show that our method is most effective at generating consistent multi-scale content",
    "checked": true,
    "id": "da2686ac2d469467ac28982d3d1d79d6b6420190",
    "semantic_title": "generative powers of ten",
    "citation_count": 3,
    "authors": [
      "Xiaojuan Wang",
      "Janne Kontkanen",
      "Brian Curless",
      "Steven M. Seitz",
      "Ira Kemelmacher-Shlizerman",
      "Ben Mildenhall",
      "Pratul Srinivasan",
      "Dor Verbin",
      "Aleksander Holynski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ghahremani_H-ViT_A_Hierarchical_Vision_Transformer_for_Deformable_Image_Registration_CVPR_2024_paper.html": {
    "title": "H-ViT: A Hierarchical Vision Transformer for Deformable Image Registration",
    "volume": "main",
    "abstract": "This paper introduces a novel top-down representation approach for deformable image registration which estimates the deformation field by capturing various short- and long-range flow features at different scale levels. As a Hierarchical Vision Transformer (H-ViT) we propose a dual self-attention and cross-attention mechanism that uses high-level features in the deformation field to represent low-level ones enabling information streams in the deformation field across all voxel patch embeddings irrespective of their spatial proximity. Since high-level features contain abstract flow patterns such patterns are expected to effectively contribute to the representation of the deformation field in lower scales. When the self-attention module utilizes within-scale short-range patterns for representation the cross-attention modules dynamically look for the key tokens across different scales to further interact with the local query voxel patches. Our method shows superior accuracy and visual quality over the state-of-the-art registration methods in five publicly available datasets highlighting a substantial enhancement in the performance of medical imaging registration. The project link is available at https://mogvision.github.io/hvit",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Morteza Ghahremani",
      "Mohammad Khateri",
      "Bailiang Jian",
      "Benedikt Wiestler",
      "Ehsan Adeli",
      "Christian Wachinger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Sculpting_Holistic_3D_Representation_in_Contrastive_Language-Image-3D_Pre-training_CVPR_2024_paper.html": {
    "title": "Sculpting Holistic 3D Representation in Contrastive Language-Image-3D Pre-training",
    "volume": "main",
    "abstract": "Contrastive learning has emerged as a promising paradigm for 3D open-world understanding i.e. aligning point cloud representation to image and text embedding space individually. In this paper we introduce MixCon3D a simple yet effective method aiming to sculpt holistic 3D representation in contrastive language-image-3D pre-training. In contrast to point cloud only we develop the 3D object-level representation from complementary perspectives e.g. multi-view rendered images with the point cloud. Then MixCon3D performs language-3D contrastive learning comprehensively depicting real-world 3D objects and bolstering text alignment. Additionally we pioneer the first thorough investigation of various training recipes for the 3D contrastive learning paradigm building a solid baseline with improved performance. Extensive experiments conducted on three representative benchmarks reveal that our method significantly improves over the baseline surpassing the previous state-of-the-art performance on the challenging 1156-category Objaverse-LVIS dataset by 5.7%. The versatility of MixCon3D is showcased in applications such as text-to-3D retrieval and point cloud captioning further evidencing its efficacy in diverse scenarios. The code is available at https://github.com/UCSC-VLAA/MixCon3D",
    "checked": true,
    "id": "762ab66917f4d36e44c2781b553846198741b621",
    "semantic_title": "sculpting holistic 3d representation in contrastive language-image-3d pre-training",
    "citation_count": 1,
    "authors": [
      "Yipeng Gao",
      "Zeyu Wang",
      "Wei-Shi Zheng",
      "Cihang Xie",
      "Yuyin Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Probing_Synergistic_High-Order_Interaction_in_Infrared_and_Visible_Image_Fusion_CVPR_2024_paper.html": {
    "title": "Probing Synergistic High-Order Interaction in Infrared and Visible Image Fusion",
    "volume": "main",
    "abstract": "Infrared and visible image fusion aims to generate a fused image by integrating and distinguishing complementary information from multiple sources. While the cross-attention mechanism with global spatial interactions appears promising it only capture second-order spatial interactions neglecting higher-order interactions in both spatial and channel dimensions. This limitation hampers the exploitation of synergies between multi-modalities. To bridge this gap we introduce a Synergistic High-order Interaction Paradigm (SHIP) designed to systematically investigate spatial fine-grained and global statistics collaborations between infrared and visible images across two fundamental dimensions: 1) Spatial dimension: we construct spatial fine-grained interactions through element-wise multiplication mathematically equivalent to global interactions and then foster high-order formats by iteratively aggregating and evolving complementary information enhancing both efficiency and flexibility. 2) Channel dimension: expanding on channel interactions with first-order statistics (mean) we devise high-order channel interactions to facilitate the discernment of inter-dependencies between source images based on global statistics. Harnessing high-order interactions significantly enhances our model's ability to exploit multi-modal synergies leading in superior performance over state-of-the-art alternatives as shown through comprehensive experiments across various benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naishan Zheng",
      "Man Zhou",
      "Jie Huang",
      "Junming Hou",
      "Haoying Li",
      "Yuan Xu",
      "Feng Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_VideoLLM-online_Online_Video_Large_Language_Model_for_Streaming_Video_CVPR_2024_paper.html": {
    "title": "VideoLLM-online: Online Video Large Language Model for Streaming Video",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) have been enhanced with vision capabilities enabling them to comprehend images videos and interleaved vision-language content. However the learning methods of these large multimodal models (LMMs) typically treat videos as predetermined clips rendering them less effective and efficient at handling streaming video inputs. In this paper we propose a novel Learning-In-Video-Stream (LIVE) framework which enables temporally aligned long-context and real-time dialogue within a continuous video stream. Our LIVE framework comprises comprehensive approaches to achieve video streaming dialogue encompassing: (1) a training objective designed to perform language modeling for continuous streaming inputs (2) a data generation scheme that converts offline temporal annotations into a streaming dialogue format and (3) an optimized inference pipeline to speed up interactive chat in real-world video streams. With our LIVE framework we develop a simplified model called VideoLLM-online and demonstrate its significant advantages in processing streaming videos. For instance our VideoLLM-online-7B model can operate at over 10 FPS on an A100 GPU for a 5-minute video clip from Ego4D narration. Moreover VideoLLM-online also showcases state-of-the-art performance on public offline video benchmarks such as recognition captioning and forecasting. The code model data and demo have been made available at showlab.github.io/videollm-online",
    "checked": true,
    "id": "d019f8a137f62cd2c08ef42be54bbb980a8362f2",
    "semantic_title": "videollm-online: online video large language model for streaming video",
    "citation_count": 0,
    "authors": [
      "Joya Chen",
      "Zhaoyang Lv",
      "Shiwei Wu",
      "Kevin Qinghong Lin",
      "Chenan Song",
      "Difei Gao",
      "Jia-Wei Liu",
      "Ziteng Gao",
      "Dongxing Mao",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Text-conditional_Attribute_Alignment_across_Latent_Spaces_for_3D_Controllable_Face_CVPR_2024_paper.html": {
    "title": "Text-conditional Attribute Alignment across Latent Spaces for 3D Controllable Face Image Synthesis",
    "volume": "main",
    "abstract": "With the advent of generative models and vision language pretraining significant improvement has been made in text-driven face manipulation. The text embedding can be used as target supervision for expression control.However it is non-trivial to associate with its 3D attributesi.e. pose and illumination. To address these issues we propose a Text-conditional Attribute aLignment approach for 3D controllable face image synthesis and our model is referred to as TcALign. Specifically since the 3D rendered image can be precisely controlled with the 3D face representation we first propose a Text-conditional 3D Editor to produce the target face representation to realize text-driven manipulation in the 3D space. An attribute embedding space spanned by the target-related attributes embeddings is also introduced to infer the disentangled task-specific direction. Next we train a cross-modal latent mapping network conditioned on the derived difference of 3D representation to infer a correct vector in the latent space of StyleGAN.Thiscorrection vector learning design can accurately transfer the attribute manipulation on 3D images to 2D images. We show that the proposed method delivers more precise text-driven multi-attribute manipulation for 3D controllable face image synthesis. Extensive qualitative and quantitative experiments verify the effectiveness and superiority of our method over the other competing methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feifan Xu",
      "Rui Li",
      "Si Wu",
      "Yong Xu",
      "Hau San Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_ESCAPE_Encoding_Super-keypoints_for_Category-Agnostic_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "ESCAPE: Encoding Super-keypoints for Category-Agnostic Pose Estimation",
    "volume": "main",
    "abstract": "In this paper we tackle the task of category-agnostic pose estimation (CAPE) which aims to predict poses for objects of any category with few annotated samples. Previous works either rely on local matching between features of support and query samples or require support keypoint identifier. The former is prone to overfitting due to its sensitivity to sparse samples while the latter is impractical for the open-world nature of the task. To overcome these limitations we propose ESCAPE - a Bayesian framework that learns a prior over the features of keypoints. The prior can be expressed as a mixture of super-keypoints each being a high-level abstract keypoint that captures the statistics of semantically related keypoints from different categories. We estimate the super-keypoints from base categories and use them in adaptation to novel categories. The adaptation to an unseen category involves two steps: first we match each novel keypoint to a related super-keypoint; and second we transfer the knowledge encoded in the matched super-keypoints to the novel keypoints. For the first step we propose a learnable matching network to capture the relationship between the novel keypoints and the super-keypoints resulting in a more reliable matching. ESCAPE mitigates overfitting by directly transferring learned knowledge to novel categories while it does not use keypoint identifiers. We achieve state-of-the-art performance on the standard MP-100 benchmark",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khoi Duc Nguyen",
      "Chen Li",
      "Gim Hee Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Correcting_Diffusion_Generation_through_Resampling_CVPR_2024_paper.html": {
    "title": "Correcting Diffusion Generation through Resampling",
    "volume": "main",
    "abstract": "Despite diffusion models' superior capabilities in modeling complex distributions there are still non-trivial distributional discrepancies between generated and ground-truth images which has resulted in several notable problems in image generation including missing object errors in text-to-image generation and low image quality. Existing methods that attempt to address these problems mostly do not tend to address the fundamental cause behind these problems which is the distributional discrepancies and hence achieve sub-optimal results. In this paper we propose a particle filtering framework that can effectively address both problems by explicitly reducing the distributional discrepancies. Specifically our method relies on a set of external guidance including a small set of real images and a pre-trained object detector to gauge the distribution gap and then design the resampling weight accordingly to correct the gap. Experiments show that our methods can effectively correct missing object errors and improve image quality in various image generation tasks. Notably our method outperforms the existing strongest baseline by 5% in object occurrence and 1.0 in FID on MS-COCO. Our code is available at https://github.com/UCSB-NLP-Chang/diffusion_resampling.git",
    "checked": true,
    "id": "3e81532857f0027bec2d7d0c600adc3a04ab2e23",
    "semantic_title": "correcting diffusion generation through resampling",
    "citation_count": 0,
    "authors": [
      "Yujian Liu",
      "Yang Zhang",
      "Tommi Jaakkola",
      "Shiyu Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Towards_Better_Vision-Inspired_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Towards Better Vision-Inspired Vision-Language Models",
    "volume": "main",
    "abstract": "Vision-language (VL) models have achieved unprecedented success recently in which the connection module is the key to bridge the modality gap. Nevertheless the abundant visual clues are not sufficiently exploited in most existing methods. On the vision side most existing approaches only use the last feature of the vision tower without using the low-level features. On the language side most existing methods only introduce shallow vision-language interactions. In this paper we present a vision-inspired vision-language connection module dubbed as VIVL which efficiently exploits the vision cue for VL models. To take advantage of the lowerlevel information from the vision tower a feature pyramid extractor (FPE) is introduced to combine features from different intermediate layers which enriches the visual cue with negligible parameters and computation overhead. To enhance VL interactions we propose deep vision-conditioned prompts (DVCP) that allows deep interactions of vision and language features efficiently. Our VIVL exceeds the previous state-of-the-art method by 18.1 CIDEr when training from scratch on the COCO caption task which greatly improves the data efficiency. When used as a plug-in module VIVL consistently improves the performance for various backbones and VL frameworks delivering new state-of-the-art results on multiple benchmarks e.g. NoCaps and VQAv2",
    "checked": false,
    "id": "b73a4e21c894c7d1f8eabbc7d5b4e9b4e86f2e08",
    "semantic_title": "towards robust prompts on vision-language models",
    "citation_count": 6,
    "authors": [
      "Yun-Hao Cao",
      "Kaixiang Ji",
      "Ziyuan Huang",
      "Chuanyang Zheng",
      "Jiajia Liu",
      "Jian Wang",
      "Jingdong Chen",
      "Ming Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_VSRD_Instance-Aware_Volumetric_Silhouette_Rendering_for_Weakly_Supervised_3D_Object_CVPR_2024_paper.html": {
    "title": "VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly Supervised 3D Object Detection",
    "volume": "main",
    "abstract": "Monocular 3D object detection poses a significant challenge in 3D scene understanding due to its inherently ill-posed nature in monocular depth estimation. Existing methods heavily rely on supervised learning using abundant 3D labels typically obtained through expensive and labor-intensive annotation on LiDAR point clouds. To tackle this problem we propose a novel weakly supervised 3D object detection framework named VSRD (Volumetric Silhouette Rendering for Detection) to train 3D object detectors without any 3D supervision but only weak 2D supervision. VSRD consists of multi-view 3D auto-labeling and subsequent training of monocular 3D object detectors using the pseudo labels generated in the auto-labeling stage. In the auto-labeling stage we represent the surface of each instance as a signed distance field (SDF) and render its silhouette as an instance mask through our proposed instance-aware volumetric silhouette rendering. To directly optimize the 3D bounding boxes through rendering we decompose the SDF of each instance into the SDF of a cuboid and the residual distance field (RDF) that represents the residual from the cuboid. This mechanism enables us to optimize the 3D bounding boxes in an end-to-end manner by comparing the rendered instance masks with the ground truth instance masks. The optimized 3D bounding boxes serve as effective training data for 3D object detection. We conduct extensive experiments on the KITTI-360 dataset demonstrating that our method outperforms the existing weakly supervised 3D object detection methods. The code is available at https://github.com/skmhrk1209/VSRD",
    "checked": true,
    "id": "21b4ffa1fb6b27627bb915396736442ca3361540",
    "semantic_title": "vsrd: instance-aware volumetric silhouette rendering for weakly supervised 3d object detection",
    "citation_count": 0,
    "authors": [
      "Zihua Liu",
      "Hiroki Sakuma",
      "Masatoshi Okutomi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_RILA_Reflective_and_Imaginative_Language_Agent_for_Zero-Shot_Semantic_Audio-Visual_CVPR_2024_paper.html": {
    "title": "RILA: Reflective and Imaginative Language Agent for Zero-Shot Semantic Audio-Visual Navigation",
    "volume": "main",
    "abstract": "We leverage Large Language Models (LLM) for zeroshot Semantic Audio Visual Navigation (SAVN). Existing methods utilize extensive training demonstrations for reinforcement learning yet achieve relatively low success rates and lack generalizability. The intermittent nature of auditory signals further poses additional obstacles to inferring the goal information. To address this challenge we present the Reflective and Imaginative Language Agent (RILA). By employing multi-modal models to process sensory data we instruct an LLM-based planner to actively explore the environment. During the exploration our agent adaptively evaluates and dismisses inaccurate perceptual descriptions. Additionally we introduce an auxiliary LLMbased assistant to enhance global environmental comprehension by mapping room layouts and providing strategic insights. Through comprehensive experiments and analysis we show that our method outperforms relevant baselines without training demonstrations from the environment and complementary semantic information",
    "checked": false,
    "id": "df5e59d7dce631037b572d64f93963dba5a7a7eb",
    "semantic_title": "rila: reﬂective and imaginative language agent for zero-shot semantic audio-visual navigation",
    "citation_count": 0,
    "authors": [
      "Zeyuan Yang",
      "Jiageng Liu",
      "Peihao Chen",
      "Anoop Cherian",
      "Tim K. Marks",
      "Jonathan Le Roux",
      "Chuang Gan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hui_Endow_SAM_with_Keen_Eyes_Temporal-spatial_Prompt_Learning_for_Video_CVPR_2024_paper.html": {
    "title": "Endow SAM with Keen Eyes: Temporal-spatial Prompt Learning for Video Camouflaged Object Detection",
    "volume": "main",
    "abstract": "The Segment Anything Model (SAM) a prompt-driven foundational model has demonstrated remarkable performance in natural image segmentation. However its application in video camouflaged object detection (VCOD) encounters challenges chiefly stemming from the overlooked temporal-spatial associations and the unreliability of user-provided prompts for camouflaged objects that are difficult to discern with the naked eye. To tackle the above issues we endow SAM with keen eyes and propose the Temporal-spatial Prompt SAM (TSP-SAM) a novel approach tailored for VCOD via an ingenious prompted learning scheme. Firstly motion-driven self-prompt learning is employed to capture the camouflaged object thereby bypassing the need for user-provided prompts. With the detected subtle motion cues across consecutive video frames the overall movement of the camouflaged object is captured for more precise spatial localization. Subsequently to eliminate the prompt bias resulting from inter-frame discontinuities the long-range consistency within the video sequences is taken into account to promote the robustness of the self-prompts. It is also injected into the encoder of SAM to enhance the representational capabilities. Extensive experimental results on two benchmarks demonstrate that the proposed TSP-SAM achieves a significant improvement over the state-of-the-art methods. With the mIoU metric increasing by 7.8% and 9.6% TSP-SAM emerges as a groundbreaking step forward in the field of VCOD",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjun Hui",
      "Zhenfeng Zhu",
      "Shuai Zheng",
      "Yao Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_TULIP_Multi-camera_3D_Precision_Assessment_of_Parkinsons_Disease_CVPR_2024_paper.html": {
    "title": "TULIP: Multi-camera 3D Precision Assessment of Parkinson's Disease",
    "volume": "main",
    "abstract": "Parkinson's disease (PD) is a devastating movement disorder accelerating in global prevalence but a lack of precision symptom measurement has made the development of effective therapies challenging. The Unified Parkinson's Disease Rating Scale (UPDRS) is the gold-standard for assessing motor symptom severity yet its manual scoring criteria are vague and subjective resulting in coarse and noisy clinical assessments. Machine learning approaches have the potential to modernize PD symptom assessments by making them more quantitative objective and scalable. However the lack of benchmark video datasets for PD motor exams hinders model development. Here we introduce the TULIP dataset to bridge this gap. TULIP emphasizes precision and comprehensiveness comprising multi-view video recordings (6 cameras) of all 25 UPDRS motor exam components together with ratings by 3 clinical experts in a cohort of Parkinson's patients and healthy controls. The multi-view recordings enable 3D reconstructions of body movement that better capture disease signatures than more conventional 2D methods. Using the dataset we establish a baseline model for predicting UPDRS scores from 3D poses illustrating how existing diagnostics could be automated. Looking ahead TULIP could aid the development of new precision diagnostics that transcend UPDRS scores providing a deeper understanding of PD and its potential treatments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyungdo Kim",
      "Sihan Lyu",
      "Sneha Mantri",
      "Timothy W. Dunn"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Turki_HybridNeRF_Efficient_Neural_Rendering_via_Adaptive_Volumetric_Surfaces_CVPR_2024_paper.html": {
    "title": "HybridNeRF: Efficient Neural Rendering via Adaptive Volumetric Surfaces",
    "volume": "main",
    "abstract": "Neural radiance fields provide state-of-the-art view synthesis quality but tend to be slow to render. One reason is that they make use of volume rendering thus requiring many samples (and model queries) per ray at render time. Although this representation is flexible and easy to optimize most real-world objects can be modeled more efficiently with surfaces instead of volumes requiring far fewer samples per ray. This observation has spurred considerable progress in surface representations such as signed distance functions but these may struggle to model semi-opaque and thin structures. We propose a method HybridNeRF that leverages the strengths of both representations by rendering most objects as surfaces while modeling the (typically) small fraction of challenging regions volumetrically. We evaluate HybridNeRF against the challenging Eyeful Tower dataset along with other commonly used view synthesis datasets. When comparing to state-of-the-art baselines including recent rasterization-based approaches we improve error rates by 15-30% while achieving real-time framerates (at least 36 FPS) for virtual-reality resolutions (2K x 2K)",
    "checked": true,
    "id": "8d7f9725a2a5524345e3ede9d1bb5ed364f7a799",
    "semantic_title": "hybridnerf: efficient neural rendering via adaptive volumetric surfaces",
    "citation_count": 8,
    "authors": [
      "Haithem Turki",
      "Vasu Agrawal",
      "Samuel Rota Bulò",
      "Lorenzo Porzi",
      "Peter Kontschieder",
      "Deva Ramanan",
      "Michael Zollhöfer",
      "Christian Richardt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Watson_AirPlanes_Accurate_Plane_Estimation_via_3D-Consistent_Embeddings_CVPR_2024_paper.html": {
    "title": "AirPlanes: Accurate Plane Estimation via 3D-Consistent Embeddings",
    "volume": "main",
    "abstract": "Extracting planes from a 3D scene is useful for downstream tasks in robotics and augmented reality. In this paper we tackle the problem of estimating the planar surfaces in a scene from posed images. Our first finding is that a surprisingly competitive baseline results from combining popular clustering algorithms with recent improvements in 3D geometry estimation. However such purely geometric methods are understandably oblivious to plane semantics which are crucial to discerning distinct planes. To overcome this limitation we propose a method that predicts multi-view consistent plane embeddings that complement geometry when clustering points into planes. We show through extensive evaluation on the ScanNetV2 dataset that our new method outperforms existing approaches and our strong geometric baseline for the task of plane estimation",
    "checked": true,
    "id": "c82de50f9a8f2547fe8141e3f6c1ad1cbf5118ec",
    "semantic_title": "airplanes: accurate plane estimation via 3d-consistent embeddings",
    "citation_count": 0,
    "authors": [
      "Jamie Watson",
      "Filippo Aleotti",
      "Mohamed Sayed",
      "Zawar Qureshi",
      "Oisin Mac Aodha",
      "Gabriel Brostow",
      "Michael Firman",
      "Sara Vicente"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Forgery-aware_Adaptive_Transformer_for_Generalizable_Synthetic_Image_Detection_CVPR_2024_paper.html": {
    "title": "Forgery-aware Adaptive Transformer for Generalizable Synthetic Image Detection",
    "volume": "main",
    "abstract": "In this paper we study the problem of generalizable synthetic image detection aiming to detect forgery images from diverse generative methods e.g. GANs and diffusion models. Cutting-edge solutions start to explore the benefits of pre-trained models and mainly follow the fixed paradigm of solely training an attached classifier e.g. combining frozen CLIP-ViT with a learnable linear layer in UniFD. However our analysis shows that such a fixed paradigm is prone to yield detectors with insufficient learning regarding forgery representations. We attribute the key challenge to the lack of forgery adaptation and present a novel forgery-aware adaptive transformer approach namely FatFormer. Based on the pre-trained vision-language spaces of CLIP FatFormer introduces two core designs for the adaption to build generalized forgery representations. First motivated by the fact that both image and frequency analysis are essential for synthetic image detection we develop a forgery-aware adapter to adapt image features to discern and integrate local forgery traces within image and frequency domains. Second we find that considering the contrastive objectives between adapted image features and text prompt embeddings a previously overlooked aspect results in a nontrivial generalization improvement. Accordingly we introduce language-guided alignment to supervise the forgery adaptation with image and text prompts in FatFormer. Experiments show that by coupling these two designs our approach tuned on 4-class ProGAN data attains a remarkable detection performance achieving an average of 98% accuracy to unseen GANs and surprisingly generalizes to unseen diffusion models with 95% accuracy",
    "checked": true,
    "id": "15cda7c4604c983fce3f037b14791e0fa629d355",
    "semantic_title": "forgery-aware adaptive transformer for generalizable synthetic image detection",
    "citation_count": 4,
    "authors": [
      "Huan Liu",
      "Zichang Tan",
      "Chuangchuang Tan",
      "Yunchao Wei",
      "Jingdong Wang",
      "Yao Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_PostureHMR_Posture_Transformation_for_3D_Human_Mesh_Recovery_CVPR_2024_paper.html": {
    "title": "PostureHMR: Posture Transformation for 3D Human Mesh Recovery",
    "volume": "main",
    "abstract": "Human Mesh Recovery (HMR) aims to estimate the 3D human body from 2D images which is a challenging task due to inherent ambiguities in translating 2D observations to 3D space. A novel approach called PostureHMR is proposed to leverage a multi-step diffusion-style process which converts this task into a posture transformation from an SMPL T-pose mesh to the target mesh. To inject the learning process of posture transformation with the physical structure of the human body model a kinematics-based forward process is proposed to interpolate the intermediate state with pose and shape decomposition. Moreover a mesh-to-posture (M2P) decoder is designed by combining the input of 3D and 2D mesh constraints estimated from the image to model the posture changes in the reverse process. It mitigates the difficulties of posture change learning directly from RGB pixels. To overcome the limitation of pixel-level misalignment of modeling results with the input image a new trimap-based rendering loss is designed to highlight the areas with poor recognition. Experiments conducted on three widely used datasets demonstrate that the proposed approach outperforms the state-of-the-art methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Pei Song",
      "Xiao Wu",
      "Zhaoquan Yuan",
      "Jian-Jun Qiao",
      "Qiang Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pham_Blur2Blur_Blur_Conversion_for_Unsupervised_Image_Deblurring_on_Unknown_Domains_CVPR_2024_paper.html": {
    "title": "Blur2Blur: Blur Conversion for Unsupervised Image Deblurring on Unknown Domains",
    "volume": "main",
    "abstract": "This paper presents an innovative framework designed to train an image deblurring algorithm tailored to a specific camera device. This algorithm works by transforming a blurry input image which is challenging to deblur into another blurry image that is more amenable to deblurring. The transformation process from one blurry state to another leverages unpaired data consisting of sharp and blurry images captured by the target camera device. Learning this blur-to-blur transformation is inherently simpler than direct blur-to-sharp conversion as it primarily involves modifying blur patterns rather than the intricate task of reconstructing fine image details. The efficacy of the proposed approach has been demonstrated through comprehensive experiments on various benchmarks where it significantly outperforms state-of-the-art methods both quantitatively and qualitatively. Our code and data are available at https://github.com/VinAIResearch/Blur2Blur",
    "checked": true,
    "id": "cf27719f86d4bc1f03c25d4c7156480338e53a21",
    "semantic_title": "blur2blur: blur conversion for unsupervised image deblurring on unknown domains",
    "citation_count": 0,
    "authors": [
      "Bang-Dang Pham",
      "Phong Tran",
      "Anh Tran",
      "Cuong Pham",
      "Rang Nguyen",
      "Minh Hoai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Dynamic_Adapter_Meets_Prompt_Tuning_Parameter-Efficient_Transfer_Learning_for_Point_CVPR_2024_paper.html": {
    "title": "Dynamic Adapter Meets Prompt Tuning: Parameter-Efficient Transfer Learning for Point Cloud Analysis",
    "volume": "main",
    "abstract": "Point cloud analysis has achieved outstanding performance by transferring point cloud pre-trained models. However existing methods for model adaptation usually update all model parameters i.e. full fine-tuning paradigm which is inefficient as it relies on high computational costs (e.g. training GPU memory) and massive storage space. In this paper we aim to study parameter-efficient transfer learning for point cloud analysis with an ideal trade-off between task performance and parameter efficiency. To achieve this goal we freeze the parameters of the default pre-trained models and then propose the Dynamic Adapter which generates a dynamic scale for each token considering the token significance to the downstream task. We further seamlessly integrate Dynamic Adapter with Prompt Tuning (DAPT) by constructing Internal Prompts capturing the instance-specific features for interaction. Extensive experiments conducted on five challenging datasets demonstrate that the proposed DAPT achieves superior performance compared to the full fine-tuning counterparts while significantly reducing the trainable parameters and training GPU memory by 95% and 35% respectively. Code is available at https://github.com/LMD0311/DAPT",
    "checked": true,
    "id": "6b533de65b3d2cee190415f5a2a2e6afe2ac7c78",
    "semantic_title": "dynamic adapter meets prompt tuning: parameter-efficient transfer learning for point cloud analysis",
    "citation_count": 2,
    "authors": [
      "Xin Zhou",
      "Dingkang Liang",
      "Wei Xu",
      "Xingkui Zhu",
      "Yihan Xu",
      "Zhikang Zou",
      "Xiang Bai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Exploring_Vision_Transformers_for_3D_Human_Motion-Language_Models_with_Motion_CVPR_2024_paper.html": {
    "title": "Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches",
    "volume": "main",
    "abstract": "To build a cross-modal latent space between 3D human motion and language acquiring large-scale and high-quality human motion data is crucial. However unlike the abundance of image data the scarcity of motion data has limited the performance of existing motion-language models. To counter this we introduce \"motion patches\" a new representation of motion sequences and propose using Vision Transformers (ViT) as motion encoders via transfer learning aiming to extract useful knowledge from the image domain and apply it to the motion domain. These motion patches created by dividing and sorting skeleton joints based on body parts in motion sequences are robust to varying skeleton structures and can be regarded as color image patches in ViT. We find that transfer learning with pre-trained weights of ViT obtained through training with 2D image data can boost the performance of motion analysis presenting a promising direction for addressing the issue of limited motion data. Our extensive experiments show that the proposed motion patches used jointly with ViT achieve state-of-the-art performance in the benchmarks of text-to-motion retrieval and other novel challenging tasks such as cross-skeleton recognition zero-shot motion classification and human interaction recognition which are currently impeded by the lack of data",
    "checked": true,
    "id": "830339fbbe8f3a0fb960e651e4c4015beb39691a",
    "semantic_title": "exploring vision transformers for 3d human motion-language models with motion patches",
    "citation_count": 0,
    "authors": [
      "Qing Yu",
      "Mikihiro Tanaka",
      "Kent Fujiwara"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Motion-adaptive_Separable_Collaborative_Filters_for_Blind_Motion_Deblurring_CVPR_2024_paper.html": {
    "title": "Motion-adaptive Separable Collaborative Filters for Blind Motion Deblurring",
    "volume": "main",
    "abstract": "Eliminating image blur produced by various kinds of motion has been a challenging problem. Dominant approaches rely heavily on model capacity to remove blurring by reconstructing residual from blurry observation in feature space. These practices not only prevent the capture of spatially variable motion in the real world but also ignore the tailored handling of various motions in image space. In this paper we propose a novel real-world deblurring filtering model called the Motion-adaptive Separable Collaborative (MISC) Filter. In particular we use a motion estimation network to capture motion information from neighborhoods thereby adaptively estimating spatially-variant motion flow mask kernels weights and offsets to obtain the MISC Filter. The MISC Filter first aligns the motion-induced blurring patterns to the motion middle along the predicted flow direction and then collaboratively filters the aligned image through the predicted kernels weights and offsets to generate the output. This design can handle more generalized and complex motion in a spatially differentiated manner. Furthermore we analyze the relationships between the motion estimation network and the residual reconstruction network. Extensive experiments on four widely used benchmarks demonstrate that our method provides an effective solution for real-world motion blur removal and achieves state-of-the-art performance. Code is available at https://github.com/ChengxuLiu/MISCFilter",
    "checked": true,
    "id": "2d19ff541831c273e6c175c4fac57eb1b31ec060",
    "semantic_title": "motion-adaptive separable collaborative filters for blind motion deblurring",
    "citation_count": 0,
    "authors": [
      "Chengxu Liu",
      "Xuan Wang",
      "Xiangyu Xu",
      "Ruhao Tian",
      "Shuai Li",
      "Xueming Qian",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_DART_Implicit_Doppler_Tomography_for_Radar_Novel_View_Synthesis_CVPR_2024_paper.html": {
    "title": "DART: Implicit Doppler Tomography for Radar Novel View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianshu Huang",
      "John Miller",
      "Akarsh Prabhakara",
      "Tao Jin",
      "Tarana Laroia",
      "Zico Kolter",
      "Anthony Rowe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Long_Wonder3D_Single_Image_to_3D_using_Cross-Domain_Diffusion_CVPR_2024_paper.html": {
    "title": "Wonder3D: Single Image to 3D using Cross-Domain Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoxiao Long",
      "Yuan-Chen Guo",
      "Cheng Lin",
      "Yuan Liu",
      "Zhiyang Dou",
      "Lingjie Liu",
      "Yuexin Ma",
      "Song-Hai Zhang",
      "Marc Habermann",
      "Christian Theobalt",
      "Wenping Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Genuine_Knowledge_from_Practice_Diffusion_Test-Time_Adaptation_for_Video_Adverse_CVPR_2024_paper.html": {
    "title": "Genuine Knowledge from Practice: Diffusion Test-Time Adaptation for Video Adverse Weather Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijun Yang",
      "Hongtao Wu",
      "Angelica I. Aviles-Rivero",
      "Yulun Zhang",
      "Jing Qin",
      "Lei Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Gradient-based_Parameter_Selection_for_Efficient_Fine-Tuning_CVPR_2024_paper.html": {
    "title": "Gradient-based Parameter Selection for Efficient Fine-Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Zhang",
      "Qizhe Zhang",
      "Zijun Gao",
      "Renrui Zhang",
      "Ekaterina Shutova",
      "Shiji Zhou",
      "Shanghang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Quan_Clustering_for_Protein_Representation_Learning_CVPR_2024_paper.html": {
    "title": "Clustering for Protein Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruijie Quan",
      "Wenguan Wang",
      "Fan Ma",
      "Hehe Fan",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_CorrMatch_Label_Propagation_via_Correlation_Matching_for_Semi-Supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "CorrMatch: Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyuan Sun",
      "Yuqi Yang",
      "Le Zhang",
      "Ming-Ming Cheng",
      "Qibin Hou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dekel_Estimating_Extreme_3D_Image_Rotations_using_Cascaded_Attention_CVPR_2024_paper.html": {
    "title": "Estimating Extreme 3D Image Rotations using Cascaded Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shay Dekel",
      "Yosi Keller",
      "Martin Cadik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qiu_RichDreamer_A_Generalizable_Normal-Depth_Diffusion_Model_for_Detail_Richness_in_CVPR_2024_paper.html": {
    "title": "RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail Richness in Text-to-3D",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingteng Qiu",
      "Guanying Chen",
      "Xiaodong Gu",
      "Qi Zuo",
      "Mutian Xu",
      "Yushuang Wu",
      "Weihao Yuan",
      "Zilong Dong",
      "Liefeng Bo",
      "Xiaoguang Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Adapt_or_Perish_Adaptive_Sparse_Transformer_with_Attentive_Feature_Refinement_CVPR_2024_paper.html": {
    "title": "Adapt or Perish: Adaptive Sparse Transformer with Attentive Feature Refinement for Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shihao Zhou",
      "Duosheng Chen",
      "Jinshan Pan",
      "Jinglei Shi",
      "Jufeng Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liao_VINECS_Video-based_Neural_Character_Skinning_CVPR_2024_paper.html": {
    "title": "VINECS: Video-based Neural Character Skinning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhouyingcheng Liao",
      "Vladislav Golyanik",
      "Marc Habermann",
      "Christian Theobalt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_Zero-shot_Referring_Expression_Comprehension_via_Structural_Similarity_Between_Images_and_CVPR_2024_paper.html": {
    "title": "Zero-shot Referring Expression Comprehension via Structural Similarity Between Images and Captions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyu Han",
      "Fangrui Zhu",
      "Qianru Lao",
      "Huaizu Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Domain_Prompt_Learning_with_Quaternion_Networks_CVPR_2024_paper.html": {
    "title": "Domain Prompt Learning with Quaternion Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinglong Cao",
      "Zhengqin Xu",
      "Yuntian Chen",
      "Chao Ma",
      "Xiaokang Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ge_BEHAVIOR_Vision_Suite_Customizable_Dataset_Generation_via_Simulation_CVPR_2024_paper.html": {
    "title": "BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhao Ge",
      "Yihe Tang",
      "Jiashu Xu",
      "Cem Gokmen",
      "Chengshu Li",
      "Wensi Ai",
      "Benjamin Jose Martinez",
      "Arman Aydin",
      "Mona Anvari",
      "Ayush K Chakravarthy",
      "Hong-Xing Yu",
      "Josiah Wong",
      "Sanjana Srivastava",
      "Sharon Lee",
      "Shengxin Zha",
      "Laurent Itti",
      "Yunzhu Li",
      "Roberto Martín-Martín",
      "Miao Liu",
      "Pengchuan Zhang",
      "Ruohan Zhang",
      "Li Fei-Fei",
      "Jiajun Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zou_Triplane_Meets_Gaussian_Splatting_Fast_and_Generalizable_Single-View_3D_Reconstruction_CVPR_2024_paper.html": {
    "title": "Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zi-Xin Zou",
      "Zhipeng Yu",
      "Yuan-Chen Guo",
      "Yangguang Li",
      "Ding Liang",
      "Yan-Pei Cao",
      "Song-Hai Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jang_WateRF_Robust_Watermarks_in_Radiance_Fields_for_Protection_of_Copyrights_CVPR_2024_paper.html": {
    "title": "WateRF: Robust Watermarks in Radiance Fields for Protection of Copyrights",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youngdong Jang",
      "Dong In Lee",
      "MinHyuk Jang",
      "Jong Wook Kim",
      "Feng Yang",
      "Sangpil Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Gaussian-Flow_4D_Reconstruction_with_Dynamic_3D_Gaussian_Particle_CVPR_2024_paper.html": {
    "title": "Gaussian-Flow: 4D Reconstruction with Dynamic 3D Gaussian Particle",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youtian Lin",
      "Zuozhuo Dai",
      "Siyu Zhu",
      "Yao Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Starodubcev_Your_Student_is_Better_Than_Expected_Adaptive_Teacher-Student_Collaboration_for_CVPR_2024_paper.html": {
    "title": "Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Starodubcev",
      "Dmitry Baranchuk",
      "Artem Fedorov",
      "Artem Babenko"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fernandez-Labrador_DiVAS_Video_and_Audio_Synchronization_with_Dynamic_Frame_Rates_CVPR_2024_paper.html": {
    "title": "DiVAS: Video and Audio Synchronization with Dynamic Frame Rates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Clara Fernandez-Labrador",
      "Mertcan Akçay",
      "Eitan Abecassis",
      "Joan Massich",
      "Christopher Schroers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yun_SHViT_Single-Head_Vision_Transformer_with_Memory_Efficient_Macro_Design_CVPR_2024_paper.html": {
    "title": "SHViT: Single-Head Vision Transformer with Memory Efficient Macro Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seokju Yun",
      "Youngmin Ro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_HDRFlow_Real-Time_HDR_Video_Reconstruction_with_Large_Motions_CVPR_2024_paper.html": {
    "title": "HDRFlow: Real-Time HDR Video Reconstruction with Large Motions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gangwei Xu",
      "Yujin Wang",
      "Jinwei Gu",
      "Tianfan Xue",
      "Xin Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ichikawa_SPIDeRS_Structured_Polarization_for_Invisible_Depth_and_Reflectance_Sensing_CVPR_2024_paper.html": {
    "title": "SPIDeRS: Structured Polarization for Invisible Depth and Reflectance Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tomoki Ichikawa",
      "Shohei Nobuhara",
      "Ko Nishino"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_SuperNormal_Neural_Surface_Reconstruction_via_Multi-View_Normal_Integration_CVPR_2024_paper.html": {
    "title": "SuperNormal: Neural Surface Reconstruction via Multi-View Normal Integration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Cao",
      "Takafumi Taketomi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gwon_Instance-aware_Contrastive_Learning_for_Occluded_Human_Mesh_Reconstruction_CVPR_2024_paper.html": {
    "title": "Instance-aware Contrastive Learning for Occluded Human Mesh Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mi-Gyeong Gwon",
      "Gi-Mun Um",
      "Won-Sik Cheong",
      "Wonjun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ling_ADFactory_An_Effective_Framework_for_Generalizing_Optical_Flow_with_NeRF_CVPR_2024_paper.html": {
    "title": "ADFactory: An Effective Framework for Generalizing Optical Flow with NeRF",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Ling",
      "Quansen Sun",
      "Yinghui Sun",
      "Xian Xu",
      "Xinfeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Robust_Noisy_Correspondence_Learning_with_Equivariant_Similarity_Consistency_CVPR_2024_paper.html": {
    "title": "Robust Noisy Correspondence Learning with Equivariant Similarity Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen Yang",
      "Likai Wang",
      "Erkun Yang",
      "Cheng Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gokaslan_CommonCanvas_Open_Diffusion_Models_Trained_on_Creative-Commons_Images_CVPR_2024_paper.html": {
    "title": "CommonCanvas: Open Diffusion Models Trained on Creative-Commons Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aaron Gokaslan",
      "A. Feder Cooper",
      "Jasmine Collins",
      "Landan Seguin",
      "Austin Jacobson",
      "Mihir Patel",
      "Jonathan Frankle",
      "Cory Stephenson",
      "Volodymyr Kuleshov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shang_Prompt-Driven_Referring_Image_Segmentation_with_Instance_Contrasting_CVPR_2024_paper.html": {
    "title": "Prompt-Driven Referring Image Segmentation with Instance Contrasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Shang",
      "Zichen Song",
      "Heqian Qiu",
      "Lanxiao Wang",
      "Fanman Meng",
      "Hongliang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yenphraphai_Image_Sculpting_Precise_Object_Editing_with_3D_Geometry_Control_CVPR_2024_paper.html": {
    "title": "Image Sculpting: Precise Object Editing with 3D Geometry Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiraphon Yenphraphai",
      "Xichen Pan",
      "Sainan Liu",
      "Daniele Panozzo",
      "Saining Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yun_Compositional_Video_Understanding_with_Spatiotemporal_Structure-based_Transformers_CVPR_2024_paper.html": {
    "title": "Compositional Video Understanding with Spatiotemporal Structure-based Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoyeoung Yun",
      "Jinwoo Ahn",
      "Minseo Kim",
      "Eun-Sol Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhong_3D_LiDAR_Mapping_in_Dynamic_Environments_using_a_4D_Implicit_CVPR_2024_paper.html": {
    "title": "3D LiDAR Mapping in Dynamic Environments using a 4D Implicit Neural Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingguang Zhong",
      "Yue Pan",
      "Cyrill Stachniss",
      "Jens Behley"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_What_When_and_Where_Self-Supervised_Spatio-Temporal_Grounding_in_Untrimmed_Multi-Action_CVPR_2024_paper.html": {
    "title": "What When and Where? Self-Supervised Spatio-Temporal Grounding in Untrimmed Multi-Action Videos from Narrated Instructions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brian Chen",
      "Nina Shvetsova",
      "Andrew Rouditchenko",
      "Daniel Kondermann",
      "Samuel Thomas",
      "Shih-Fu Chang",
      "Rogerio Feris",
      "James Glass",
      "Hilde Kuehne"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wen_FoundationPose_Unified_6D_Pose_Estimation_and_Tracking_of_Novel_Objects_CVPR_2024_paper.html": {
    "title": "FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Wen",
      "Wei Yang",
      "Jan Kautz",
      "Stan Birchfield"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_How_Far_Can_We_Compress_Instant-NGP-Based_NeRF_CVPR_2024_paper.html": {
    "title": "How Far Can We Compress Instant-NGP-Based NeRF?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihang Chen",
      "Qianyi Wu",
      "Mehrtash Harandi",
      "Jianfei Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Varanka_PFStorer_Personalized_Face_Restoration_and_Super-Resolution_CVPR_2024_paper.html": {
    "title": "PFStorer: Personalized Face Restoration and Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuomas Varanka",
      "Tapani Toivonen",
      "Soumya Tripathy",
      "Guoying Zhao",
      "Erman Acar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yeh_TextureDreamer_Image-Guided_Texture_Synthesis_Through_Geometry-Aware_Diffusion_CVPR_2024_paper.html": {
    "title": "TextureDreamer: Image-Guided Texture Synthesis Through Geometry-Aware Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Ying Yeh",
      "Jia-Bin Huang",
      "Changil Kim",
      "Lei Xiao",
      "Thu Nguyen-Phuoc",
      "Numair Khan",
      "Cheng Zhang",
      "Manmohan Chandraker",
      "Carl S Marshall",
      "Zhao Dong",
      "Zhengqin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Boosting_Image_Quality_Assessment_through_Efficient_Transformer_Adaptation_with_Local_CVPR_2024_paper.html": {
    "title": "Boosting Image Quality Assessment through Efficient Transformer Adaptation with Local Feature Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangmin Xu",
      "Liang Liao",
      "Jing Xiao",
      "Chaofeng Chen",
      "Haoning Wu",
      "Qiong Yan",
      "Weisi Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Hyperbolic_Anomaly_Detection_CVPR_2024_paper.html": {
    "title": "Hyperbolic Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huimin Li",
      "Zhentao Chen",
      "Yunhao Xu",
      "Junlin Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pan_VLP_Vision_Language_Planning_for_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "VLP: Vision Language Planning for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenbin Pan",
      "Burhaneddin Yaman",
      "Tommaso Nesti",
      "Abhirup Mallik",
      "Alessandro G Allievi",
      "Senem Velipasalar",
      "Liu Ren"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Attention_Calibration_for_Disentangled_Text-to-Image_Personalization_CVPR_2024_paper.html": {
    "title": "Attention Calibration for Disentangled Text-to-Image Personalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanbing Zhang",
      "Mengping Yang",
      "Qin Zhou",
      "Zhe Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Asnani_ProMark_Proactive_Diffusion_Watermarking_for_Causal_Attribution_CVPR_2024_paper.html": {
    "title": "ProMark: Proactive Diffusion Watermarking for Causal Attribution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vishal Asnani",
      "John Collomosse",
      "Tu Bui",
      "Xiaoming Liu",
      "Shruti Agarwal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cho_One-Shot_Structure-Aware_Stylized_Image_Synthesis_CVPR_2024_paper.html": {
    "title": "One-Shot Structure-Aware Stylized Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hansam Cho",
      "Jonghyun Lee",
      "Seunggyu Chang",
      "Yonghyun Jeong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_GPT4Point_A_Unified_Framework_for_Point-Language_Understanding_and_Generation_CVPR_2024_paper.html": {
    "title": "GPT4Point: A Unified Framework for Point-Language Understanding and Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangyang Qi",
      "Ye Fang",
      "Zeyi Sun",
      "Xiaoyang Wu",
      "Tong Wu",
      "Jiaqi Wang",
      "Dahua Lin",
      "Hengshuang Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_SemCity_Semantic_Scene_Generation_with_Triplane_Diffusion_CVPR_2024_paper.html": {
    "title": "SemCity: Semantic Scene Generation with Triplane Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jumin Lee",
      "Sebin Lee",
      "Changho Jo",
      "Woobin Im",
      "Juhyeong Seon",
      "Sung-Eui Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mariotti_Improving_Semantic_Correspondence_with_Viewpoint-Guided_Spherical_Maps_CVPR_2024_paper.html": {
    "title": "Improving Semantic Correspondence with Viewpoint-Guided Spherical Maps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Octave Mariotti",
      "Oisin Mac Aodha",
      "Hakan Bilen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Roheda_MR-VNet_Media_Restoration_using_Volterra_Networks_CVPR_2024_paper.html": {
    "title": "MR-VNet: Media Restoration using Volterra Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Roheda",
      "Amit Unde",
      "Loay Rashid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Dual_Memory_Networks_A_Versatile_Adaptation_Approach_for_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yabin Zhang",
      "Wenjie Zhu",
      "Hui Tang",
      "Zhiyuan Ma",
      "Kaiyang Zhou",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mitchel_Single_Mesh_Diffusion_Models_with_Field_Latents_for_Texture_Generation_CVPR_2024_paper.html": {
    "title": "Single Mesh Diffusion Models with Field Latents for Texture Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas W. Mitchel",
      "Carlos Esteves",
      "Ameesh Makadia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_LION_Empowering_Multimodal_Large_Language_Model_with_Dual-Level_Visual_Knowledge_CVPR_2024_paper.html": {
    "title": "LION: Empowering Multimodal Large Language Model with Dual-Level Visual Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gongwei Chen",
      "Leyang Shen",
      "Rui Shao",
      "Xiang Deng",
      "Liqiang Nie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hou_Learning_to_Select_Views_for_Efficient_Multi-View_Understanding_CVPR_2024_paper.html": {
    "title": "Learning to Select Views for Efficient Multi-View Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunzhong Hou",
      "Stephen Gould",
      "Liang Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Khan_Consistency_and_Uncertainty_Identifying_Unreliable_Responses_From_Black-Box_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Consistency and Uncertainty: Identifying Unreliable Responses From Black-Box Vision-Language Models for Selective Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zaid Khan",
      "Yun Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_SAI3D_Segment_Any_Instance_in_3D_Scenes_CVPR_2024_paper.html": {
    "title": "SAI3D: Segment Any Instance in 3D Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingda Yin",
      "Yuzheng Liu",
      "Yang Xiao",
      "Daniel Cohen-Or",
      "Jingwei Huang",
      "Baoquan Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Implicit_Motion_Function_CVPR_2024_paper.html": {
    "title": "Implicit Motion Function",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Gao",
      "Jiahao Li",
      "Lei Chu",
      "Yan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Unified_Entropy_Optimization_for_Open-Set_Test-Time_Adaptation_CVPR_2024_paper.html": {
    "title": "Unified Entropy Optimization for Open-Set Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengqing Gao",
      "Xu-Yao Zhang",
      "Cheng-Lin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_TexOct_Generating_Textures_of_3D_Models_with_Octree-based_Diffusion_CVPR_2024_paper.html": {
    "title": "TexOct: Generating Textures of 3D Models with Octree-based Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialun Liu",
      "Chenming Wu",
      "Xinqi Liu",
      "Xing Liu",
      "Jinbo Wu",
      "Haotian Peng",
      "Chen Zhao",
      "Haocheng Feng",
      "Jingtuo Liu",
      "Errui Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chandran_Anatomically_Constrained_Implicit_Face_Models_CVPR_2024_paper.html": {
    "title": "Anatomically Constrained Implicit Face Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prashanth Chandran",
      "Gaspard Zoss"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Expandable_Subspace_Ensemble_for_Pre-Trained_Model-Based_Class-Incremental_Learning_CVPR_2024_paper.html": {
    "title": "Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Da-Wei Zhou",
      "Hai-Long Sun",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Capturing_Closely_Interacted_Two-Person_Motions_with_Reaction_Priors_CVPR_2024_paper.html": {
    "title": "Capturing Closely Interacted Two-Person Motions with Reaction Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Fang",
      "Yinghui Fan",
      "Yanjun Li",
      "Junting Dong",
      "Dingwei Wu",
      "Weidong Zhang",
      "Kang Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_RobustSAM_Segment_Anything_Robustly_on_Degraded_Images_CVPR_2024_paper.html": {
    "title": "RobustSAM: Segment Anything Robustly on Degraded Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Ting Chen",
      "Yu-Jiet Vong",
      "Sy-Yen Kuo",
      "Sizhou Ma",
      "Jian Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Muller_MultiDiff_Consistent_Novel_View_Synthesis_from_a_Single_Image_CVPR_2024_paper.html": {
    "title": "MultiDiff: Consistent Novel View Synthesis from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Norman Müller",
      "Katja Schwarz",
      "Barbara Rössle",
      "Lorenzo Porzi",
      "Samuel Rota Bulò",
      "Matthias Nießner",
      "Peter Kontschieder"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_In-N-Out_Faithful_3D_GAN_Inversion_with_Volumetric_Decomposition_for_Face_CVPR_2024_paper.html": {
    "title": "In-N-Out: Faithful 3D GAN Inversion with Volumetric Decomposition for Face Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiran Xu",
      "Zhixin Shu",
      "Cameron Smith",
      "Seoung Wug Oh",
      "Jia-Bin Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Oldenhof_Atom-Level_Optical_Chemical_Structure_Recognition_with_Limited_Supervision_CVPR_2024_paper.html": {
    "title": "Atom-Level Optical Chemical Structure Recognition with Limited Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martijn Oldenhof",
      "Edward De Brouwer",
      "Adam Arany",
      "Yves Moreau"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_L4D-Track_Language-to-4D_Modeling_Towards_6-DoF_Tracking_and_Shape_Reconstruction_in_CVPR_2024_paper.html": {
    "title": "L4D-Track: Language-to-4D Modeling Towards 6-DoF Tracking and Shape Reconstruction in 3D Point Cloud Stream",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingtao Sun",
      "Yaonan Wang",
      "Mingtao Feng",
      "Yulan Guo",
      "Ajmal Mian",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_General_Point_Model_Pretraining_with_Autoencoding_and_Autoregressive_CVPR_2024_paper.html": {
    "title": "General Point Model Pretraining with Autoencoding and Autoregressive",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Li",
      "Zhangyang Gao",
      "Cheng Tan",
      "Bocheng Ren",
      "Laurence T. Yang",
      "Stan Z. Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saethre_Combining_Frame_and_GOP_Embeddings_for_Neural_Video_Representation_CVPR_2024_paper.html": {
    "title": "Combining Frame and GOP Embeddings for Neural Video Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jens Eirik Saethre",
      "Roberto Azevedo",
      "Christopher Schroers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_LiDAR-based_Person_Re-identification_CVPR_2024_paper.html": {
    "title": "LiDAR-based Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Guo",
      "Zhiyu Pan",
      "Yingping Liang",
      "Ziheng Xi",
      "Zhicheng Zhong",
      "Jianjiang Feng",
      "Jie Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Fantastic_Animals_and_Where_to_Find_Them_Segment_Any_Marine_CVPR_2024_paper.html": {
    "title": "Fantastic Animals and Where to Find Them: Segment Any Marine Animal with Dual SAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pingping Zhang",
      "Tianyu Yan",
      "Yang Liu",
      "Huchuan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xing_Seeing_and_Hearing_Open-domain_Visual-Audio_Generation_with_Diffusion_Latent_Aligners_CVPR_2024_paper.html": {
    "title": "Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yazhou Xing",
      "Yingqing He",
      "Zeyue Tian",
      "Xintao Wang",
      "Qifeng Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Model_Adaptation_for_Time_Constrained_Embodied_Control_CVPR_2024_paper.html": {
    "title": "Model Adaptation for Time Constrained Embodied Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaehyun Song",
      "Minjong Yoo",
      "Honguk Woo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Miller_Objects_as_Volumes_A_Stochastic_Geometry_View_of_Opaque_Solids_CVPR_2024_paper.html": {
    "title": "Objects as Volumes: A Stochastic Geometry View of Opaque Solids",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bailey Miller",
      "Hanyu Chen",
      "Alice Lai",
      "Ioannis Gkioulekas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_ActiveDC_Distribution_Calibration_for_Active_Finetuning_CVPR_2024_paper.html": {
    "title": "ActiveDC: Distribution Calibration for Active Finetuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenshuai Xu",
      "Zhenghui Hu",
      "Yu Lu",
      "Jinzhou Meng",
      "Qingjie Liu",
      "Yunhong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Seeing_Unseen_Discover_Novel_Biomedical_Concepts_via_Geometry-Constrained_Probabilistic_Modeling_CVPR_2024_paper.html": {
    "title": "Seeing Unseen: Discover Novel Biomedical Concepts via Geometry-Constrained Probabilistic Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianan Fan",
      "Dongnan Liu",
      "Hang Chang",
      "Heng Huang",
      "Mei Chen",
      "Weidong Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiong_MVHumanNet_A_Large-scale_Dataset_of_Multi-view_Daily_Dressing_Human_Captures_CVPR_2024_paper.html": {
    "title": "MVHumanNet: A Large-scale Dataset of Multi-view Daily Dressing Human Captures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangyang Xiong",
      "Chenghong Li",
      "Kenkun Liu",
      "Hongjie Liao",
      "Jianqiao Hu",
      "Junyi Zhu",
      "Shuliang Ning",
      "Lingteng Qiu",
      "Chongjie Wang",
      "Shijie Wang",
      "Shuguang Cui",
      "Xiaoguang Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Communication-Efficient_Federated_Learning_with_Accelerated_Client_Gradient_CVPR_2024_paper.html": {
    "title": "Communication-Efficient Federated Learning with Accelerated Client Gradient",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geeho Kim",
      "Jinkyu Kim",
      "Bohyung Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_LLMs_are_Good_Action_Recognizers_CVPR_2024_paper.html": {
    "title": "LLMs are Good Action Recognizers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxuan Qu",
      "Yujun Cai",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dalva_NoiseCLR_A_Contrastive_Learning_Approach_for_Unsupervised_Discovery_of_Interpretable_CVPR_2024_paper.html": {
    "title": "NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuf Dalva",
      "Pinar Yanardag"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_SpecNeRF_Gaussian_Directional_Encoding_for_Specular_Reflections_CVPR_2024_paper.html": {
    "title": "SpecNeRF: Gaussian Directional Encoding for Specular Reflections",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Ma",
      "Vasu Agrawal",
      "Haithem Turki",
      "Changil Kim",
      "Chen Gao",
      "Pedro Sander",
      "Michael Zollhöfer",
      "Christian Richardt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chan_Improving_Subject-Driven_Image_Synthesis_with_Subject-Agnostic_Guidance_CVPR_2024_paper.html": {
    "title": "Improving Subject-Driven Image Synthesis with Subject-Agnostic Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kelvin C.K. Chan",
      "Yang Zhao",
      "Xuhui Jia",
      "Ming-Hsuan Yang",
      "Huisheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wallace_Diffusion_Model_Alignment_Using_Direct_Preference_Optimization_CVPR_2024_paper.html": {
    "title": "Diffusion Model Alignment Using Direct Preference Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bram Wallace",
      "Meihua Dang",
      "Rafael Rafailov",
      "Linqi Zhou",
      "Aaron Lou",
      "Senthil Purushwalkam",
      "Stefano Ermon",
      "Caiming Xiong",
      "Shafiq Joty",
      "Nikhil Naik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_Interactive_Continual_Learning_Fast_and_Slow_Thinking_CVPR_2024_paper.html": {
    "title": "Interactive Continual Learning: Fast and Slow Thinking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Biqing Qi",
      "Xinquan Chen",
      "Junqi Gao",
      "Dong Li",
      "Jianxing Liu",
      "Ligang Wu",
      "Bowen Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sargent_ZeroNVS_Zero-Shot_360-Degree_View_Synthesis_from_a_Single_Image_CVPR_2024_paper.html": {
    "title": "ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyle Sargent",
      "Zizhang Li",
      "Tanmay Shah",
      "Charles Herrmann",
      "Hong-Xing Yu",
      "Yunzhi Zhang",
      "Eric Ryan Chan",
      "Dmitry Lagun",
      "Li Fei-Fei",
      "Deqing Sun",
      "Jiajun Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Restoration_by_Generation_with_Constrained_Priors_CVPR_2024_paper.html": {
    "title": "Restoration by Generation with Constrained Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Ding",
      "Xuaner Zhang",
      "Zhuowen Tu",
      "Zhihao Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Friday_Snapshot_Lidar_Fourier_Embedding_of_Amplitude_and_Phase_for_Single-Image_CVPR_2024_paper.html": {
    "title": "Snapshot Lidar: Fourier Embedding of Amplitude and Phase for Single-Image Depth Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sarah Friday",
      "Yunzi Shi",
      "Yaswanth Cherivirala",
      "Vishwanath Saragadam",
      "Adithya Pediredla"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Roy_Convolutional_Prompting_meets_Language_Models_for_Continual_Learning_CVPR_2024_paper.html": {
    "title": "Convolutional Prompting meets Language Models for Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anurag Roy",
      "Riddhiman Moulick",
      "Vinay K. Verma",
      "Saptarshi Ghosh",
      "Abir Das"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Blur-aware_Spatio-temporal_Sparse_Transformer_for_Video_Deblurring_CVPR_2024_paper.html": {
    "title": "Blur-aware Spatio-temporal Sparse Transformer for Video Deblurring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huicong Zhang",
      "Haozhe Xie",
      "Hongxun Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Towards_Learning_a_Generalist_Model_for_Embodied_Navigation_CVPR_2024_paper.html": {
    "title": "Towards Learning a Generalist Model for Embodied Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duo Zheng",
      "Shijia Huang",
      "Lin Zhao",
      "Yiwu Zhong",
      "Liwei Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Van_Wouwe_DiffusionPoser_Real-time_Human_Motion_Reconstruction_From_Arbitrary_Sparse_Sensors_Using_CVPR_2024_paper.html": {
    "title": "DiffusionPoser: Real-time Human Motion Reconstruction From Arbitrary Sparse Sensors Using Autoregressive Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Van Wouwe",
      "Seunghwan Lee",
      "Antoine Falisse",
      "Scott Delp",
      "C. Karen Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pokhariya_MANUS_Markerless_Grasp_Capture_using_Articulated_3D_Gaussians_CVPR_2024_paper.html": {
    "title": "MANUS: Markerless Grasp Capture using Articulated 3D Gaussians",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chandradeep Pokhariya",
      "Ishaan Nikhil Shah",
      "Angela Xing",
      "Zekun Li",
      "Kefan Chen",
      "Avinash Sharma",
      "Srinath Sridhar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Distilling_Semantic_Priors_from_SAM_to_Efficient_Image_Restoration_Models_CVPR_2024_paper.html": {
    "title": "Distilling Semantic Priors from SAM to Efficient Image Restoration Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Zhang",
      "Xiaoyu Liu",
      "Wei Li",
      "Hanting Chen",
      "Junchao Liu",
      "Jie Hu",
      "Zhiwei Xiong",
      "Chun Yuan",
      "Yunhe Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_Learning_Intra-view_and_Cross-view_Geometric_Knowledge_for_Stereo_Matching_CVPR_2024_paper.html": {
    "title": "Learning Intra-view and Cross-view Geometric Knowledge for Stereo Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Gong",
      "Weide Liu",
      "Zaiwang Gu",
      "Xulei Yang",
      "Jun Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Rethinking_the_Evaluation_Protocol_of_Domain_Generalization_CVPR_2024_paper.html": {
    "title": "Rethinking the Evaluation Protocol of Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Yu",
      "Xingxuan Zhang",
      "Renzhe Xu",
      "Jiashuo Liu",
      "Yue He",
      "Peng Cui"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Aligning_Logits_Generatively_for_Principled_Black-Box_Knowledge_Distillation_CVPR_2024_paper.html": {
    "title": "Aligning Logits Generatively for Principled Black-Box Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Ma",
      "Xiang Xiang",
      "Ke Wang",
      "Yuchuan Wu",
      "Yongbin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_BerfScene_Bev-conditioned_Equivariant_Radiance_Fields_for_Infinite_3D_Scene_Generation_CVPR_2024_paper.html": {
    "title": "BerfScene: Bev-conditioned Equivariant Radiance Fields for Infinite 3D Scene Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihang Zhang",
      "Yinghao Xu",
      "Yujun Shen",
      "Bo Dai",
      "Bolei Zhou",
      "Ceyuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Retsinas_3D_Facial_Expressions_through_Analysis-by-Neural-Synthesis_CVPR_2024_paper.html": {
    "title": "3D Facial Expressions through Analysis-by-Neural-Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George Retsinas",
      "Panagiotis P. Filntisis",
      "Radek Danecek",
      "Victoria F. Abrevaya",
      "Anastasios Roussos",
      "Timo Bolkart",
      "Petros Maragos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_HoloVIC_Large-scale_Dataset_and_Benchmark_for_Multi-Sensor_Holographic_Intersection_and_CVPR_2024_paper.html": {
    "title": "HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic Intersection and Vehicle-Infrastructure Cooperative",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cong Ma",
      "Lei Qiao",
      "Chengkai Zhu",
      "Kai Liu",
      "Zelong Kong",
      "Qing Li",
      "Xueqi Zhou",
      "Yuheng Kan",
      "Wei Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Unleashing_the_Potential_of_SAM_for_Medical_Adaptation_via_Hierarchical_CVPR_2024_paper.html": {
    "title": "Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiheng Cheng",
      "Qingyue Wei",
      "Hongru Zhu",
      "Yan Wang",
      "Liangqiong Qu",
      "Wei Shao",
      "Yuyin Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Puff-Net_Efficient_Style_Transfer_with_Pure_Content_and_Style_Feature_CVPR_2024_paper.html": {
    "title": "Puff-Net: Efficient Style Transfer with Pure Content and Style Feature Fusion Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sizhe Zheng",
      "Pan Gao",
      "Peng Zhou",
      "Jie Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Towards_Progressive_Multi-Frequency_Representation_for_Image_Warping_CVPR_2024_paper.html": {
    "title": "Towards Progressive Multi-Frequency Representation for Image Warping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Xiao",
      "Zihang Lyu",
      "Cong Zhang",
      "Yakun Ju",
      "Changjian Shui",
      "Kin-Man Lam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Learning_to_Control_Camera_Exposure_via_Reinforcement_Learning_CVPR_2024_paper.html": {
    "title": "Learning to Control Camera Exposure via Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyunghyun Lee",
      "Ukcheol Shin",
      "Byeong-Uk Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Szymanowicz_Splatter_Image_Ultra-Fast_Single-View_3D_Reconstruction_CVPR_2024_paper.html": {
    "title": "Splatter Image: Ultra-Fast Single-View 3D Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stanislaw Szymanowicz",
      "Chrisitian Rupprecht",
      "Andrea Vedaldi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Toubal_Modeling_Collaborator_Enabling_Subjective_Vision_Classification_With_Minimal_Human_Effort_CVPR_2024_paper.html": {
    "title": "Modeling Collaborator: Enabling Subjective Vision Classification With Minimal Human Effort via LLM Tool-Use",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Imad Eddine Toubal",
      "Aditya Avinash",
      "Neil Gordon Alldrin",
      "Jan Dlabal",
      "Wenlei Zhou",
      "Enming Luo",
      "Otilia Stretcu",
      "Hao Xiong",
      "Chun-Ta Lu",
      "Howard Zhou",
      "Ranjay Krishna",
      "Ariel Fuxman",
      "Tom Duerig"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Brument_RNb-NeuS_Reflectance_and_Normal-based_Multi-View_3D_Reconstruction_CVPR_2024_paper.html": {
    "title": "RNb-NeuS: Reflectance and Normal-based Multi-View 3D Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baptiste Brument",
      "Robin Bruneau",
      "Yvain Quéau",
      "Jean Mélou",
      "François Bernard Lauze",
      "Jean-Denis Durou",
      "Lilian Calvet"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_LOTUS_Evasive_and_Resilient_Backdoor_Attacks_through_Sub-Partitioning_CVPR_2024_paper.html": {
    "title": "LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Cheng",
      "Guanhong Tao",
      "Yingqi Liu",
      "Guangyu Shen",
      "Shengwei An",
      "Shiwei Feng",
      "Xiangzhe Xu",
      "Kaiyuan Zhang",
      "Shiqing Ma",
      "Xiangyu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_GeoReF_Geometric_Alignment_Across_Shape_Variation_for_Category-level_Object_Pose_CVPR_2024_paper.html": {
    "title": "GeoReF: Geometric Alignment Across Shape Variation for Category-level Object Pose Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linfang Zheng",
      "Tze Ho Elden Tse",
      "Chen Wang",
      "Yinghan Sun",
      "Hua Chen",
      "Ales Leonardis",
      "Wei Zhang",
      "Hyung Jin Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_LAN_Learning_to_Adapt_Noise_for_Image_Denoising_CVPR_2024_paper.html": {
    "title": "LAN: Learning to Adapt Noise for Image Denoising",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changjin Kim",
      "Tae Hyun Kim",
      "Sungyong Baik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Scaling_Up_Dynamic_Human-Scene_Interaction_Modeling_CVPR_2024_paper.html": {
    "title": "Scaling Up Dynamic Human-Scene Interaction Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Jiang",
      "Zhiyuan Zhang",
      "Hongjie Li",
      "Xiaoxuan Ma",
      "Zan Wang",
      "Yixin Chen",
      "Tengyu Liu",
      "Yixin Zhu",
      "Siyuan Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_Semantic-aware_SAM_for_Point-Prompted_Instance_Segmentation_CVPR_2024_paper.html": {
    "title": "Semantic-aware SAM for Point-Prompted Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Wei",
      "Pengfei Chen",
      "Xuehui Yu",
      "Guorong Li",
      "Jianbin Jiao",
      "Zhenjun Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nakatani_Learning_Group_Activity_Features_Through_Person_Attribute_Prediction_CVPR_2024_paper.html": {
    "title": "Learning Group Activity Features Through Person Attribute Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chihiro Nakatani",
      "Hiroaki Kawashima",
      "Norimichi Ukita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yao_HUNTER_Unsupervised_Human-centric_3D_Detection_via_Transferring_Knowledge_from_Synthetic_CVPR_2024_paper.html": {
    "title": "HUNTER: Unsupervised Human-centric 3D Detection via Transferring Knowledge from Synthetic Instances to Real Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Yao",
      "Zimo Jiang",
      "Yujing Sun",
      "Zhencai Zhu",
      "Xinge Zhu",
      "Runnan Chen",
      "Yuexin Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Improving_Transferable_Targeted_Adversarial_Attacks_with_Model_Self-Enhancement_CVPR_2024_paper.html": {
    "title": "Improving Transferable Targeted Adversarial Attacks with Model Self-Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Wu",
      "Guanyan Ou",
      "Weibin Wu",
      "Zibin Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sommer_Unsupervised_Learning_of_Category-Level_3D_Pose_from_Object-Centric_Videos_CVPR_2024_paper.html": {
    "title": "Unsupervised Learning of Category-Level 3D Pose from Object-Centric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leonhard Sommer",
      "Artur Jesslen",
      "Eddy Ilg",
      "Adam Kortylewski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hsiao_Plug-and-Play_Diffusion_Distillation_CVPR_2024_paper.html": {
    "title": "Plug-and-Play Diffusion Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi-Ting Hsiao",
      "Siavash Khodadadeh",
      "Kevin Duarte",
      "Wei-An Lin",
      "Hui Qu",
      "Mingi Kwon",
      "Ratheesh Kalarot"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_MindBridge_A_Cross-Subject_Brain_Decoding_Framework_CVPR_2024_paper.html": {
    "title": "MindBridge: A Cross-Subject Brain Decoding Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shizun Wang",
      "Songhua Liu",
      "Zhenxiong Tan",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_Make_Pixels_Dance_High-Dynamic_Video_Generation_CVPR_2024_paper.html": {
    "title": "Make Pixels Dance: High-Dynamic Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Zeng",
      "Guoqiang Wei",
      "Jiani Zheng",
      "Jiaxin Zou",
      "Yang Wei",
      "Yuchen Zhang",
      "Hang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MM-Narrator_Narrating_Long-form_Videos_with_Multimodal_In-Context_Learning_CVPR_2024_paper.html": {
    "title": "MM-Narrator: Narrating Long-form Videos with Multimodal In-Context Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoyi Zhang",
      "Kevin Lin",
      "Zhengyuan Yang",
      "Jianfeng Wang",
      "Linjie Li",
      "Chung-Ching Lin",
      "Zicheng Liu",
      "Lijuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Morphable_Diffusion_3D-Consistent_Diffusion_for_Single-image_Avatar_Creation_CVPR_2024_paper.html": {
    "title": "Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiyi Chen",
      "Marko Mihajlovic",
      "Shaofei Wang",
      "Sergey Prokudin",
      "Siyu Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Young_Fully_Convolutional_Slice-to-Volume_Reconstruction_for_Single-Stack_MRI_CVPR_2024_paper.html": {
    "title": "Fully Convolutional Slice-to-Volume Reconstruction for Single-Stack MRI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sean I. Young",
      "Yael Balbastre",
      "Bruce Fischl",
      "Polina Golland",
      "Juan Eugenio Iglesias"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Enhance_Image_Classification_via_Inter-Class_Image_Mixup_with_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "Enhance Image Classification via Inter-Class Image Mixup with Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicai Wang",
      "Longhui Wei",
      "Tan Wang",
      "Heyu Chen",
      "Yanbin Hao",
      "Xiang Wang",
      "Xiangnan He",
      "Qi Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_AB_BNN_AddBit-Operation-Only_Hardware-Friendly_Binary_Neural_Network_CVPR_2024_paper.html": {
    "title": "A&B BNN: Add&Bit-Operation-Only Hardware-Friendly Binary Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruichen Ma",
      "Guanchao Qiao",
      "Yian Liu",
      "Liwei Meng",
      "Ning Ning",
      "Yang Liu",
      "Shaogang Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Alpha-CLIP_A_CLIP_Model_Focusing_on_Wherever_You_Want_CVPR_2024_paper.html": {
    "title": "Alpha-CLIP: A CLIP Model Focusing on Wherever You Want",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyi Sun",
      "Ye Fang",
      "Tong Wu",
      "Pan Zhang",
      "Yuhang Zang",
      "Shu Kong",
      "Yuanjun Xiong",
      "Dahua Lin",
      "Jiaqi Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Diller_FutureHuman3D_Forecasting_Complex_Long-Term_3D_Human_Behavior_from_Video_Observations_CVPR_2024_paper.html": {
    "title": "FutureHuman3D: Forecasting Complex Long-Term 3D Human Behavior from Video Observations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christian Diller",
      "Thomas Funkhouser",
      "Angela Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_NightCC_Nighttime_Color_Constancy_via_Adaptive_Channel_Masking_CVPR_2024_paper.html": {
    "title": "NightCC: Nighttime Color Constancy via Adaptive Channel Masking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuwei Li",
      "Robby T. Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/de_Geus_Task-aligned_Part-aware_Panoptic_Segmentation_through_Joint_Object-Part_Representations_CVPR_2024_paper.html": {
    "title": "Task-aligned Part-aware Panoptic Segmentation through Joint Object-Part Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daan de Geus",
      "Gijs Dubbelman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saratchandran_From_Activation_to_Initialization_Scaling_Insights_for_Optimizing_Neural_Fields_CVPR_2024_paper.html": {
    "title": "From Activation to Initialization: Scaling Insights for Optimizing Neural Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hemanth Saratchandran",
      "Sameera Ramasinghe",
      "Simon Lucey"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rozenberszki_UnScene3D_Unsupervised_3D_Instance_Segmentation_for_Indoor_Scenes_CVPR_2024_paper.html": {
    "title": "UnScene3D: Unsupervised 3D Instance Segmentation for Indoor Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Rozenberszki",
      "Or Litany",
      "Angela Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Nearest_is_Not_Dearest_Towards_Practical_Defense_against_Quantization-conditioned_Backdoor_CVPR_2024_paper.html": {
    "title": "Nearest is Not Dearest: Towards Practical Defense against Quantization-conditioned Backdoor Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boheng Li",
      "Yishuo Cai",
      "Haowei Li",
      "Feng Xue",
      "Zhifeng Li",
      "Yiming Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_DiffAvatar_Simulation-Ready_Garment_Optimization_with_Differentiable_Simulation_CVPR_2024_paper.html": {
    "title": "DiffAvatar: Simulation-Ready Garment Optimization with Differentiable Simulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Li",
      "Hsiao-yu Chen",
      "Egor Larionov",
      "Nikolaos Sarafianos",
      "Wojciech Matusik",
      "Tuur Stuyck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_AlignSAM_Aligning_Segment_Anything_Model_to_Open_Context_via_Reinforcement_CVPR_2024_paper.html": {
    "title": "AlignSAM: Aligning Segment Anything Model to Open Context via Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duojun Huang",
      "Xinyu Xiong",
      "Jie Ma",
      "Jichang Li",
      "Zequn Jie",
      "Lin Ma",
      "Guanbin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fahes_A_Simple_Recipe_for_Language-guided_Domain_Generalized_Segmentation_CVPR_2024_paper.html": {
    "title": "A Simple Recipe for Language-guided Domain Generalized Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Fahes",
      "Tuan-Hung Vu",
      "Andrei Bursuc",
      "Patrick Pérez",
      "Raoul de Charette"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Learning_Spatial_Adaptation_and_Temporal_Coherence_in_Diffusion_Models_for_CVPR_2024_paper.html": {
    "title": "Learning Spatial Adaptation and Temporal Coherence in Diffusion Models for Video Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhikai Chen",
      "Fuchen Long",
      "Zhaofan Qiu",
      "Ting Yao",
      "Wengang Zhou",
      "Jiebo Luo",
      "Tao Mei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Multiagent_Multitraversal_Multimodal_Self-Driving_Open_MARS_Dataset_CVPR_2024_paper.html": {
    "title": "Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Li",
      "Zhiheng Li",
      "Nuo Chen",
      "Moonjun Gong",
      "Zonglin Lyu",
      "Zehong Wang",
      "Peili Jiang",
      "Chen Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gurumurthy_From_Variance_to_Veracity_Unbundling_and_Mitigating_Gradient_Variance_in_CVPR_2024_paper.html": {
    "title": "From Variance to Veracity: Unbundling and Mitigating Gradient Variance in Differentiable Bundle Adjustment Layers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Swaminathan Gurumurthy",
      "Karnik Ram",
      "Bingqing Chen",
      "Zachary Manchester",
      "Zico Kolter"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mao_Denoising_Point_Clouds_in_Latent_Space_via_Graph_Convolution_and_CVPR_2024_paper.html": {
    "title": "Denoising Point Clouds in Latent Space via Graph Convolution and Invertible Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aihua Mao",
      "Biao Yan",
      "Zijing Ma",
      "Ying He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_ADA-Track_End-to-End_Multi-Camera_3D_Multi-Object_Tracking_with_Alternating_Detection_and_CVPR_2024_paper.html": {
    "title": "ADA-Track: End-to-End Multi-Camera 3D Multi-Object Tracking with Alternating Detection and Association",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuxiao Ding",
      "Lukas Schneider",
      "Marius Cordts",
      "Juergen Gall"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pang_HIR-Diff_Unsupervised_Hyperspectral_Image_Restoration_Via_Improved_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Pang",
      "Xiangyu Rui",
      "Long Cui",
      "Hongzhong Wang",
      "Deyu Meng",
      "Xiangyong Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Talker_Mind_The_Edge_Refining_Depth_Edges_in_Sparsely-Supervised_Monocular_Depth_CVPR_2024_paper.html": {
    "title": "Mind The Edge: Refining Depth Edges in Sparsely-Supervised Monocular Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lior Talker",
      "Aviad Cohen",
      "Erez Yosef",
      "Alexandra Dana",
      "Michael Dinerstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Attention-Driven_Training-Free_Efficiency_Enhancement_of_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongjie Wang",
      "Difan Liu",
      "Yan Kang",
      "Yijun Li",
      "Zhe Lin",
      "Niraj K. Jha",
      "Yuchen Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Golatkar_CPR_Retrieval_Augmented_Generation_for_Copyright_Protection_CVPR_2024_paper.html": {
    "title": "CPR: Retrieval Augmented Generation for Copyright Protection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aditya Golatkar",
      "Alessandro Achille",
      "Luca Zancato",
      "Yu-Xiang Wang",
      "Ashwin Swaminathan",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ling_FreeDrag_Feature_Dragging_for_Reliable_Point-based_Image_Editing_CVPR_2024_paper.html": {
    "title": "FreeDrag: Feature Dragging for Reliable Point-based Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengyang Ling",
      "Lin Chen",
      "Pan Zhang",
      "Huaian Chen",
      "Yi Jin",
      "Jinjin Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Image-Text_Co-Decomposition_for_Text-Supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Image-Text Co-Decomposition for Text-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ji-Jia Wu",
      "Andy Chia-Hao Chang",
      "Chieh-Yu Chuang",
      "Chun-Pei Chen",
      "Yu-Lun Liu",
      "Min-Hung Chen",
      "Hou-Ning Hu",
      "Yung-Yu Chuang",
      "Yen-Yu Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Orchestrate_Latent_Expertise_Advancing_Online_Continual_Learning_with_Multi-Level_Supervision_CVPR_2024_paper.html": {
    "title": "Orchestrate Latent Expertise: Advancing Online Continual Learning with Multi-Level Supervision and Reverse Self-Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongwei Yan",
      "Liyuan Wang",
      "Kaisheng Ma",
      "Yi Zhong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Vision-and-Language_Navigation_via_Causal_Learning_CVPR_2024_paper.html": {
    "title": "Vision-and-Language Navigation via Causal Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liuyi Wang",
      "Zongtao He",
      "Ronghao Dang",
      "Mengjiao Shen",
      "Chengju Liu",
      "Qijun Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Mitigating_Object_Dependencies_Improving_Point_Cloud_Self-Supervised_Learning_through_Object_CVPR_2024_paper.html": {
    "title": "Mitigating Object Dependencies: Improving Point Cloud Self-Supervised Learning through Object Exchange",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhao Wu",
      "Tong Zhang",
      "Wei Ke",
      "Congpei Qiu",
      "Sabine Süsstrunk",
      "Mathieu Salzmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hsiao_Confronting_Ambiguity_in_6D_Object_Pose_Estimation_via_Score-Based_Diffusion_CVPR_2024_paper.html": {
    "title": "Confronting Ambiguity in 6D Object Pose Estimation via Score-Based Diffusion on SE(3)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsu-Ching Hsiao",
      "Hao-Wei Chen",
      "Hsuan-Kung Yang",
      "Chun-Yi Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Geng_Visual_Anagrams_Generating_Multi-View_Optical_Illusions_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Geng",
      "Inbum Park",
      "Andrew Owens"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Unveiling_Parts_Beyond_Objects_Towards_Finer-Granularity_Referring_Expression_Segmentation_CVPR_2024_paper.html": {
    "title": "Unveiling Parts Beyond Objects: Towards Finer-Granularity Referring Expression Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Wang",
      "Tongtian Yue",
      "Yisi Zhang",
      "Longteng Guo",
      "Xingjian He",
      "Xinlong Wang",
      "Jing Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ju_DiffInDScene_Diffusion-based_High-Quality_3D_Indoor_Scene_Generation_CVPR_2024_paper.html": {
    "title": "DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoliang Ju",
      "Zhaoyang Huang",
      "Yijin Li",
      "Guofeng Zhang",
      "Yu Qiao",
      "Hongsheng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MAPSeg_Unified_Unsupervised_Domain_Adaptation_for_Heterogeneous_Medical_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuzhe Zhang",
      "Yuhao Wu",
      "Elsa Angelini",
      "Ang Li",
      "Jia Guo",
      "Jerod M. Rasmussen",
      "Thomas G. O'Connor",
      "Pathik D. Wadhwa",
      "Andrea Parolin Jackowski",
      "Hai Li",
      "Jonathan Posner",
      "Andrew F. Laine",
      "Yun Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Leveraging_Predicate_and_Triplet_Learning_for_Scene_Graph_Generation_CVPR_2024_paper.html": {
    "title": "Leveraging Predicate and Triplet Learning for Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiankai Li",
      "Yunhong Wang",
      "Xiefan Guo",
      "Ruijie Yang",
      "Weixin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lou_DaReNeRF_Direction-aware_Representation_for_Dynamic_Scenes_CVPR_2024_paper.html": {
    "title": "DaReNeRF: Direction-aware Representation for Dynamic Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ange Lou",
      "Benjamin Planche",
      "Zhongpai Gao",
      "Yamin Li",
      "Tianyu Luan",
      "Hao Ding",
      "Terrence Chen",
      "Jack Noble",
      "Ziyan Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SfmCAD_Unsupervised_CAD_Reconstruction_by_Learning_Sketch-based_Feature_Modeling_Operations_CVPR_2024_paper.html": {
    "title": "SfmCAD: Unsupervised CAD Reconstruction by Learning Sketch-based Feature Modeling Operations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pu Li",
      "Jianwei Guo",
      "Huibin Li",
      "Bedrich Benes",
      "Dong-Ming Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_CoDi-2_In-Context_Interleaved_and_Interactive_Any-to-Any_Generation_CVPR_2024_paper.html": {
    "title": "CoDi-2: In-Context Interleaved and Interactive Any-to-Any Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zineng Tang",
      "Ziyi Yang",
      "Mahmoud Khademi",
      "Yang Liu",
      "Chenguang Zhu",
      "Mohit Bansal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_Tuning_Stable_Rank_Shrinkage_Aiming_at_the_Overlooked_Structural_Risk_CVPR_2024_paper.html": {
    "title": "Tuning Stable Rank Shrinkage: Aiming at the Overlooked Structural Risk in Fine-tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sicong Shen",
      "Yang Zhou",
      "Bingzheng Wei",
      "Eric I-Chao Chang",
      "Yan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_Differentiable_Display_Photometric_Stereo_CVPR_2024_paper.html": {
    "title": "Differentiable Display Photometric Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seokjun Choi",
      "Seungwoo Yoon",
      "Giljoo Nam",
      "Seungyong Lee",
      "Seung-Hwan Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_In-distribution_Public_Data_Synthesis_with_Diffusion_Models_for_Differentially_Private_CVPR_2024_paper.html": {
    "title": "In-distribution Public Data Synthesis with Diffusion Models for Differentially Private Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinseong Park",
      "Yujin Choi",
      "Jaewook Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Learning_Degradation-unaware_Representation_with_Prior-based_Latent_Transformations_for_Blind_Face_CVPR_2024_paper.html": {
    "title": "Learning Degradation-unaware Representation with Prior-based Latent Transformations for Blind Face Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lianxin Xie",
      "Csbingbing Zheng",
      "Wen Xue",
      "Le Jiang",
      "Cheng Liu",
      "Si Wu",
      "Hau San Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_LSK3DNet_Towards_Effective_and_Efficient_3D_Perception_with_Large_Sparse_CVPR_2024_paper.html": {
    "title": "LSK3DNet: Towards Effective and Efficient 3D Perception with Large Sparse Kernels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuo Feng",
      "Wenguan Wang",
      "Fan Ma",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jang_Faces_that_Speak_Jointly_Synthesising_Talking_Face_and_Speech_from_CVPR_2024_paper.html": {
    "title": "Faces that Speak: Jointly Synthesising Talking Face and Speech from Text",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youngjoon Jang",
      "Ji-Hoon Kim",
      "Junseok Ahn",
      "Doyeop Kwak",
      "Hong-Sun Yang",
      "Yoon-Cheol Ju",
      "Il-Hwan Kim",
      "Byeong-Yeol Kim",
      "Joon Son Chung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Diversified_and_Personalized_Multi-rater_Medical_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Diversified and Personalized Multi-rater Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicheng Wu",
      "Xiangde Luo",
      "Zhe Xu",
      "Xiaoqing Guo",
      "Lie Ju",
      "Zongyuan Ge",
      "Wenjun Liao",
      "Jianfei Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Towards_Automatic_Power_Battery_Detection_New_Challenge_Benchmark_Dataset_and_CVPR_2024_paper.html": {
    "title": "Towards Automatic Power Battery Detection: New Challenge Benchmark Dataset and Baseline",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqi Zhao",
      "Youwei Pang",
      "Zhenyu Chen",
      "Qian Yu",
      "Lihe Zhang",
      "Hanqi Liu",
      "Jiaming Zuo",
      "Huchuan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Oorloff_AVFF_Audio-Visual_Feature_Fusion_for_Video_Deepfake_Detection_CVPR_2024_paper.html": {
    "title": "AVFF: Audio-Visual Feature Fusion for Video Deepfake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Trevine Oorloff",
      "Surya Koppisetti",
      "Nicolò Bonettini",
      "Divyaraj Solanki",
      "Ben Colman",
      "Yaser Yacoob",
      "Ali Shahriyari",
      "Gaurav Bharaj"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Discover_and_Mitigate_Multiple_Biased_Subgroups_in_Image_Classifiers_CVPR_2024_paper.html": {
    "title": "Discover and Mitigate Multiple Biased Subgroups in Image Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeliang Zhang",
      "Mingqian Feng",
      "Zhiheng Li",
      "Chenliang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_DiffusionRegPose_Enhancing_Multi-Person_Pose_Estimation_using_a_Diffusion-Based_End-to-End_Regression_CVPR_2024_paper.html": {
    "title": "DiffusionRegPose: Enhancing Multi-Person Pose Estimation using a Diffusion-Based End-to-End Regression Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dayi Tan",
      "Hansheng Chen",
      "Wei Tian",
      "Lu Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Magnet_Memory-Scalable_and_Simplified_Functional_Map_Learning_CVPR_2024_paper.html": {
    "title": "Memory-Scalable and Simplified Functional Map Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robin Magnet",
      "Maks Ovsjanikov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kukleva_X-MIC_Cross-Modal_Instance_Conditioning_for_Egocentric_Action_Generalization_CVPR_2024_paper.html": {
    "title": "X-MIC: Cross-Modal Instance Conditioning for Egocentric Action Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna Kukleva",
      "Fadime Sener",
      "Edoardo Remelli",
      "Bugra Tekin",
      "Eric Sauser",
      "Bernt Schiele",
      "Shugao Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chakraborty_ExMap_Leveraging_Explainability_Heatmaps_for_Unsupervised_Group_Robustness_to_Spurious_CVPR_2024_paper.html": {
    "title": "ExMap: Leveraging Explainability Heatmaps for Unsupervised Group Robustness to Spurious Correlations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rwiddhi Chakraborty",
      "Adrian Sletten",
      "Michael C. Kampffmeyer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Gaussian_Head_Avatar_Ultra_High-fidelity_Head_Avatar_via_Dynamic_Gaussians_CVPR_2024_paper.html": {
    "title": "Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic Gaussians",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuelang Xu",
      "Benwang Chen",
      "Zhe Li",
      "Hongwen Zhang",
      "Lizhen Wang",
      "Zerong Zheng",
      "Yebin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_Stratified_Avatar_Generation_from_Sparse_Observations_CVPR_2024_paper.html": {
    "title": "Stratified Avatar Generation from Sparse Observations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Feng",
      "Wenchao Ma",
      "Quankai Gao",
      "Xianwei Zheng",
      "Nan Xue",
      "Huijuan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_Learning_to_Segment_Referred_Objects_from_Narrated_Egocentric_Videos_CVPR_2024_paper.html": {
    "title": "Learning to Segment Referred Objects from Narrated Egocentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Shen",
      "Huiyu Wang",
      "Xitong Yang",
      "Matt Feiszli",
      "Ehsan Elhamifar",
      "Lorenzo Torresani",
      "Effrosyni Mavroudi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Rewrite_the_Stars_CVPR_2024_paper.html": {
    "title": "Rewrite the Stars",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Ma",
      "Xiyang Dai",
      "Yue Bai",
      "Yizhou Wang",
      "Yun Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Adapting_Visual-Language_Models_for_Generalizable_Anomaly_Detection_in_Medical_Images_CVPR_2024_paper.html": {
    "title": "Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoqin Huang",
      "Aofan Jiang",
      "Jinghao Feng",
      "Ya Zhang",
      "Xinchao Wang",
      "Yanfeng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ratnarajah_AV-RIR_Audio-Visual_Room_Impulse_Response_Estimation_CVPR_2024_paper.html": {
    "title": "AV-RIR: Audio-Visual Room Impulse Response Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anton Ratnarajah",
      "Sreyan Ghosh",
      "Sonal Kumar",
      "Purva Chiniya",
      "Dinesh Manocha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Depth-aware_Test-Time_Training_for_Zero-shot_Video_Object_Segmentation_CVPR_2024_paper.html": {
    "title": "Depth-aware Test-Time Training for Zero-shot Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weihuang Liu",
      "Xi Shen",
      "Haolun Li",
      "Xiuli Bi",
      "Bo Liu",
      "Chi-Man Pun",
      "Xiaodong Cun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qiu_Dual-Consistency_Model_Inversion_for_Non-Exemplar_Class_Incremental_Learning_CVPR_2024_paper.html": {
    "title": "Dual-Consistency Model Inversion for Non-Exemplar Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihuan Qiu",
      "Yi Xu",
      "Fanman Meng",
      "Hongliang Li",
      "Linfeng Xu",
      "Qingbo Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_RMem_Restricted_Memory_Banks_Improve_Video_Object_Segmentation_CVPR_2024_paper.html": {
    "title": "RMem: Restricted Memory Banks Improve Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junbao Zhou",
      "Ziqi Pang",
      "Yu-Xiong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Not_All_Prompts_Are_Secure_A_Switchable_Backdoor_Attack_Against_CVPR_2024_paper.html": {
    "title": "Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transfomers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sheng Yang",
      "Jiawang Bai",
      "Kuofeng Gao",
      "Yong Yang",
      "Yiming Li",
      "Shu-Tao Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ali_PairDETR__Joint_Detection_and_Association_of_Human_Bodies_and_CVPR_2024_paper.html": {
    "title": "PairDETR : Joint Detection and Association of Human Bodies and Faces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ammar Ali",
      "Georgii Gaikov",
      "Denis Rybalchenko",
      "Alexander Chigorin",
      "Ivan Laptev",
      "Sergey Zagoruyko"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_PortraitBooth_A_Versatile_Portrait_Model_for_Fast_Identity-preserved_Personalization_CVPR_2024_paper.html": {
    "title": "PortraitBooth: A Versatile Portrait Model for Fast Identity-preserved Personalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Peng",
      "Junwei Zhu",
      "Boyuan Jiang",
      "Ying Tai",
      "Donghao Luo",
      "Jiangning Zhang",
      "Wei Lin",
      "Taisong Jin",
      "Chengjie Wang",
      "Rongrong Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Learn_from_View_Correlation_An_Anchor_Enhancement_Strategy_for_Multi-view_CVPR_2024_paper.html": {
    "title": "Learn from View Correlation: An Anchor Enhancement Strategy for Multi-view Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suyuan Liu",
      "Ke Liang",
      "Zhibin Dong",
      "Siwei Wang",
      "Xihong Yang",
      "Sihang Zhou",
      "En Zhu",
      "Xinwang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SportsSloMo_A_New_Benchmark_and_Baselines_for_Human-centric_Video_Frame_CVPR_2024_paper.html": {
    "title": "SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame Interpolation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaben Chen",
      "Huaizu Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_APSeg_Auto-Prompt_Network_for_Cross-Domain_Few-Shot_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "APSeg: Auto-Prompt Network for Cross-Domain Few-Shot Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weizhao He",
      "Yang Zhang",
      "Wei Zhuo",
      "Linlin Shen",
      "Jiaqi Yang",
      "Songhe Deng",
      "Liang Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cha_Text2HOI_Text-guided_3D_Motion_Generation_for_Hand-Object_Interaction_CVPR_2024_paper.html": {
    "title": "Text2HOI: Text-guided 3D Motion Generation for Hand-Object Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junuk Cha",
      "Jihyeon Kim",
      "Jae Shin Yoon",
      "Seungryul Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Zero-TPrune_Zero-Shot_Token_Pruning_through_Leveraging_of_the_Attention_Graph_CVPR_2024_paper.html": {
    "title": "Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention Graph in Pre-Trained Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongjie Wang",
      "Bhishma Dedhia",
      "Niraj K. Jha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ni_Enhancing_Visual_Continual_Learning_with_Language-Guided_Supervision_CVPR_2024_paper.html": {
    "title": "Enhancing Visual Continual Learning with Language-Guided Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bolin Ni",
      "Hongbo Zhao",
      "Chenghao Zhang",
      "Ke Hu",
      "Gaofeng Meng",
      "Zhaoxiang Zhang",
      "Shiming Xiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_MACE_Mass_Concept_Erasure_in_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "MACE: Mass Concept Erasure in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shilin Lu",
      "Zilan Wang",
      "Leyang Li",
      "Yanzhu Liu",
      "Adams Wai-Kin Kong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_DIBS_Enhancing_Dense_Video_Captioning_with_Unlabeled_Videos_via_Pseudo_CVPR_2024_paper.html": {
    "title": "DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Wu",
      "Huabin Liu",
      "Yu Qiao",
      "Xiao Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_PeLK_Parameter-efficient_Large_Kernel_ConvNets_with_Peripheral_Convolution_CVPR_2024_paper.html": {
    "title": "PeLK: Parameter-efficient Large Kernel ConvNets with Peripheral Convolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honghao Chen",
      "Xiangxiang Chu",
      "Yongjian Ren",
      "Xin Zhao",
      "Kaiqi Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_AiOS_All-in-One-Stage_Expressive_Human_Pose_and_Shape_Estimation_CVPR_2024_paper.html": {
    "title": "AiOS: All-in-One-Stage Expressive Human Pose and Shape Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingping Sun",
      "Yanjun Wang",
      "Ailing Zeng",
      "Wanqi Yin",
      "Chen Wei",
      "Wenjia Wang",
      "Haiyi Mei",
      "Chi-Sing Leung",
      "Ziwei Liu",
      "Lei Yang",
      "Zhongang Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_SOK-Bench_A_Situated_Video_Reasoning_Benchmark_with_Aligned_Open-World_Knowledge_CVPR_2024_paper.html": {
    "title": "SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andong Wang",
      "Bo Wu",
      "Sunli Chen",
      "Zhenfang Chen",
      "Haotian Guan",
      "Wei-Ning Lee",
      "Li Erran Li",
      "Chuang Gan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_LORS_Low-rank_Residual_Structure_for_Parameter-Efficient_Network_Stacking_CVPR_2024_paper.html": {
    "title": "LORS: Low-rank Residual Structure for Parameter-Efficient Network Stacking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialin Li",
      "Qiang Nie",
      "Weifu Fu",
      "Yuhuan Lin",
      "Guangpin Tao",
      "Yong Liu",
      "Chengjie Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Design2Cloth_3D_Cloth_Generation_from_2D_Masks_CVPR_2024_paper.html": {
    "title": "Design2Cloth: 3D Cloth Generation from 2D Masks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiali Zheng",
      "Rolandos Alexandros Potamias",
      "Stefanos Zafeiriou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Multi-modal_In-Context_Learning_Makes_an_Ego-evolving_Scene_Text_Recognizer_CVPR_2024_paper.html": {
    "title": "Multi-modal In-Context Learning Makes an Ego-evolving Scene Text Recognizer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Zhao",
      "Jingqun Tang",
      "Chunhui Lin",
      "Binghong Wu",
      "Can Huang",
      "Hao Liu",
      "Xin Tan",
      "Zhizhong Zhang",
      "Yuan Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Amodal_Completion_via_Progressive_Mixed_Context_Diffusion_CVPR_2024_paper.html": {
    "title": "Amodal Completion via Progressive Mixed Context Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katherine Xu",
      "Lingzhi Zhang",
      "Jianbo Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Miao_Training_Diffusion_Models_Towards_Diverse_Image_Generation_with_Reinforcement_Learning_CVPR_2024_paper.html": {
    "title": "Training Diffusion Models Towards Diverse Image Generation with Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zichen Miao",
      "Jiang Wang",
      "Ze Wang",
      "Zhengyuan Yang",
      "Lijuan Wang",
      "Qiang Qiu",
      "Zicheng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dutt_Diffusion_3D_Features_Diff3F_Decorating_Untextured_Shapes_with_Distilled_Semantic_CVPR_2024_paper.html": {
    "title": "Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with Distilled Semantic Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niladri Shekhar Dutt",
      "Sanjeev Muralikrishnan",
      "Niloy J. Mitra"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_LASIL_Learner-Aware_Supervised_Imitation_Learning_For_Long-term_Microscopic_Traffic_Simulation_CVPR_2024_paper.html": {
    "title": "LASIL: Learner-Aware Supervised Imitation Learning For Long-term Microscopic Traffic Simulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Guo",
      "Zhenwei Miao",
      "Wei Jing",
      "Weiwei Liu",
      "Weizi Li",
      "Dayang Hao",
      "Jia Pan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kumar_Revamping_Federated_Learning_Security_from_a_Defenders_Perspective_A_Unified_CVPR_2024_paper.html": {
    "title": "Revamping Federated Learning Security from a Defender's Perspective: A Unified Defense with Homomorphic Encrypted Data Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "K Naveen Kumar",
      "Reshmi Mitra",
      "C Krishna Mohan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_A_Dynamic_Kernel_Prior_Model_for_Unsupervised_Blind_Image_Super-Resolution_CVPR_2024_paper.html": {
    "title": "A Dynamic Kernel Prior Model for Unsupervised Blind Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixiong Yang",
      "Jingyuan Xia",
      "Shengxi Li",
      "Xinghua Huang",
      "Shuanghui Zhang",
      "Zhen Liu",
      "Yaowen Fu",
      "Yongxiang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Cinematic_Behavior_Transfer_via_NeRF-based_Differentiable_Filming_CVPR_2024_paper.html": {
    "title": "Cinematic Behavior Transfer via NeRF-based Differentiable Filming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuekun Jiang",
      "Anyi Rao",
      "Jingbo Wang",
      "Dahua Lin",
      "Bo Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kumar_SeaBird_Segmentation_in_Birds_View_with_Dice_Loss_Improves_Monocular_CVPR_2024_paper.html": {
    "title": "SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhinav Kumar",
      "Yuliang Guo",
      "Xinyu Huang",
      "Liu Ren",
      "Xiaoming Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Text-Driven_Image_Editing_via_Learnable_Regions_CVPR_2024_paper.html": {
    "title": "Text-Driven Image Editing via Learnable Regions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanze Lin",
      "Yi-Wen Chen",
      "Yi-Hsuan Tsai",
      "Lu Jiang",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Relation_Rectification_in_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "Relation Rectification in Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinwei Wu",
      "Xingyi Yang",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_NOPE_Novel_Object_Pose_Estimation_from_a_Single_Image_CVPR_2024_paper.html": {
    "title": "NOPE: Novel Object Pose Estimation from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Van Nguyen Nguyen",
      "Thibault Groueix",
      "Georgy Ponimatkin",
      "Yinlin Hu",
      "Renaud Marlet",
      "Mathieu Salzmann",
      "Vincent Lepetit"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Mocap_Everyone_Everywhere_Lightweight_Motion_Capture_With_Smartwatches_and_a_CVPR_2024_paper.html": {
    "title": "Mocap Everyone Everywhere: Lightweight Motion Capture With Smartwatches and a Head-Mounted Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiye Lee",
      "Hanbyul Joo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Fast_ODE-based_Sampling_for_Diffusion_Models_in_Around_5_Steps_CVPR_2024_paper.html": {
    "title": "Fast ODE-based Sampling for Diffusion Models in Around 5 Steps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Zhou",
      "Defang Chen",
      "Can Wang",
      "Chun Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kil_Dual-View_Visual_Contextualization_for_Web_Navigation_CVPR_2024_paper.html": {
    "title": "Dual-View Visual Contextualization for Web Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyung Kil",
      "Chan Hee Song",
      "Boyuan Zheng",
      "Xiang Deng",
      "Yu Su",
      "Wei-Lun Chao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vuong_Language-driven_Grasp_Detection_CVPR_2024_paper.html": {
    "title": "Language-driven Grasp Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "An Dinh Vuong",
      "Minh Nhat Vu",
      "Baoru Huang",
      "Nghia Nguyen",
      "Hieu Le",
      "Thieu Vo",
      "Anh Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_Towards_Modern_Image_Manipulation_Localization_A_Large-Scale_Dataset_and_Novel_CVPR_2024_paper.html": {
    "title": "Towards Modern Image Manipulation Localization: A Large-Scale Dataset and Novel Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenfan Qu",
      "Yiwu Zhong",
      "Chongyu Liu",
      "Guitao Xu",
      "Dezhi Peng",
      "Fengjun Guo",
      "Lianwen Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Mitigating_Noisy_Correspondence_by_Geometrical_Structure_Consistency_Learning_CVPR_2024_paper.html": {
    "title": "Mitigating Noisy Correspondence by Geometrical Structure Consistency Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihua Zhao",
      "Mengxi Chen",
      "Tianjie Dai",
      "Jiangchao Yao",
      "Bo Han",
      "Ya Zhang",
      "Yanfeng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Safaee_CLiC_Concept_Learning_in_Context_CVPR_2024_paper.html": {
    "title": "CLiC: Concept Learning in Context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehdi Safaee",
      "Aryan Mikaeili",
      "Or Patashnik",
      "Daniel Cohen-Or",
      "Ali Mahdavi-Amiri"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Khan_CAD-SIGNet_CAD_Language_Inference_from_Point_Clouds_using_Layer-wise_Sketch_CVPR_2024_paper.html": {
    "title": "CAD-SIGNet: CAD Language Inference from Point Clouds using Layer-wise Sketch Instance Guided Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Sadil Khan",
      "Elona Dupont",
      "Sk Aziz Ali",
      "Kseniya Cherenkova",
      "Anis Kacem",
      "Djamila Aouada"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yue_Object_Recognition_as_Next_Token_Prediction_CVPR_2024_paper.html": {
    "title": "Object Recognition as Next Token Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyu Yue",
      "Bor-Chun Chen",
      "Jonas Geiping",
      "Hengduo Li",
      "Tom Goldstein",
      "Ser-Nam Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ou_CLIB-FIQA_Face_Image_Quality_Assessment_with_Confidence_Calibration_CVPR_2024_paper.html": {
    "title": "CLIB-FIQA: Face Image Quality Assessment with Confidence Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fu-Zhao Ou",
      "Chongyi Li",
      "Shiqi Wang",
      "Sam Kwong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_DVMNet_Computing_Relative_Pose_for_Unseen_Objects_Beyond_Hypotheses_CVPR_2024_paper.html": {
    "title": "DVMNet: Computing Relative Pose for Unseen Objects Beyond Hypotheses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhao",
      "Tong Zhang",
      "Zheng Dang",
      "Mathieu Salzmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jaume_Transcriptomics-guided_Slide_Representation_Learning_in_Computational_Pathology_CVPR_2024_paper.html": {
    "title": "Transcriptomics-guided Slide Representation Learning in Computational Pathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillaume Jaume",
      "Lukas Oldenburg",
      "Anurag Vaidya",
      "Richard J. Chen",
      "Drew F.K. Williamson",
      "Thomas Peeters",
      "Andrew H. Song",
      "Faisal Mahmood"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sueyoshi_Predicated_Diffusion_Predicate_Logic-Based_Attention_Guidance_for_Text-to-Image_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Predicated Diffusion: Predicate Logic-Based Attention Guidance for Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kota Sueyoshi",
      "Takashi Matsubara"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_MuRF_Multi-Baseline_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "MuRF: Multi-Baseline Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haofei Xu",
      "Anpei Chen",
      "Yuedong Chen",
      "Christos Sakaridis",
      "Yulun Zhang",
      "Marc Pollefeys",
      "Andreas Geiger",
      "Fisher Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pan_CLIP-BEVFormer_Enhancing_Multi-View_Image-Based_BEV_Detector_with_Ground_Truth_Flow_CVPR_2024_paper.html": {
    "title": "CLIP-BEVFormer: Enhancing Multi-View Image-Based BEV Detector with Ground Truth Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenbin Pan",
      "Burhaneddin Yaman",
      "Senem Velipasalar",
      "Liu Ren"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_CLOVA_A_Closed-LOop_Visual_Assistant_with_Tool_Usage_and_Update_CVPR_2024_paper.html": {
    "title": "CLOVA: A Closed-LOop Visual Assistant with Tool Usage and Update",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Gao",
      "Yuntao Du",
      "Xintong Zhang",
      "Xiaojian Ma",
      "Wenjuan Han",
      "Song-Chun Zhu",
      "Qing Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Depth_Prompting_for_Sensor-Agnostic_Depth_Estimation_CVPR_2024_paper.html": {
    "title": "Depth Prompting for Sensor-Agnostic Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin-Hwi Park",
      "Chanhwi Jeong",
      "Junoh Lee",
      "Hae-Gon Jeon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Reddy_G3DR_Generative_3D_Reconstruction_in_ImageNet_CVPR_2024_paper.html": {
    "title": "G3DR: Generative 3D Reconstruction in ImageNet",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pradyumna Reddy",
      "Ismail Elezi",
      "Jiankang Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_MoML_Online_Meta_Adaptation_for_3D_Human_Motion_Prediction_CVPR_2024_paper.html": {
    "title": "MoML: Online Meta Adaptation for 3D Human Motion Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoning Sun",
      "Huaijiang Sun",
      "Bin Li",
      "Dong Wei",
      "Weiqing Li",
      "Jianfeng Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_CAT-DM_Controllable_Accelerated_Virtual_Try-on_with_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "CAT-DM: Controllable Accelerated Virtual Try-on with Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianhao Zeng",
      "Dan Song",
      "Weizhi Nie",
      "Hongshuo Tian",
      "Tongtong Wang",
      "An-An Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saadabadi_Hyperspherical_Classification_with_Dynamic_Label-to-Prototype_Assignment_CVPR_2024_paper.html": {
    "title": "Hyperspherical Classification with Dynamic Label-to-Prototype Assignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Saeed Ebrahimi Saadabadi",
      "Ali Dabouei",
      "Sahar Rahimi Malakshan",
      "Nasser M. Nasrabadi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_VTimeLLM_Empower_LLM_to_Grasp_Video_Moments_CVPR_2024_paper.html": {
    "title": "VTimeLLM: Empower LLM to Grasp Video Moments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Huang",
      "Xin Wang",
      "Hong Chen",
      "Zihan Song",
      "Wenwu Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_FLHetBench_Benchmarking_Device_and_State_Heterogeneity_in_Federated_Learning_CVPR_2024_paper.html": {
    "title": "FLHetBench: Benchmarking Device and State Heterogeneity in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyuan Zhang",
      "Shuang Zeng",
      "Miao Zhang",
      "Runxi Wang",
      "Feifei Wang",
      "Yuyin Zhou",
      "Paul Pu Liang",
      "Liangqiong Qu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Weber_Flattening_the_Parent_Bias_Hierarchical_Semantic_Segmentation_in_the_Poincare_CVPR_2024_paper.html": {
    "title": "Flattening the Parent Bias: Hierarchical Semantic Segmentation in the Poincare Ball",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Weber",
      "Bar?? Zöngür",
      "Nikita Araslanov",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lopez_Privacy-Preserving_Optics_for_Enhancing_Protection_in_Face_De-Identification_CVPR_2024_paper.html": {
    "title": "Privacy-Preserving Optics for Enhancing Protection in Face De-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jhon Lopez",
      "Carlos Hinojosa",
      "Henry Arguello",
      "Bernard Ghanem"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_SmartRefine_A_Scenario-Adaptive_Refinement_Framework_for_Efficient_Motion_Prediction_CVPR_2024_paper.html": {
    "title": "SmartRefine: A Scenario-Adaptive Refinement Framework for Efficient Motion Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhou",
      "Hao Shao",
      "Letian Wang",
      "Steven L. Waslander",
      "Hongsheng Li",
      "Yu Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_MVBench_A_Comprehensive_Multi-modal_Video_Understanding_Benchmark_CVPR_2024_paper.html": {
    "title": "MVBench: A Comprehensive Multi-modal Video Understanding Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunchang Li",
      "Yali Wang",
      "Yinan He",
      "Yizhuo Li",
      "Yi Wang",
      "Yi Liu",
      "Zun Wang",
      "Jilan Xu",
      "Guo Chen",
      "Ping Luo",
      "Limin Wang",
      "Yu Qiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Multi-Scale_Video_Anomaly_Detection_by_Multi-Grained_Spatio-Temporal_Representation_Learning_CVPR_2024_paper.html": {
    "title": "Multi-Scale Video Anomaly Detection by Multi-Grained Spatio-Temporal Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Menghao Zhang",
      "Jingyu Wang",
      "Qi Qi",
      "Haifeng Sun",
      "Zirui Zhuang",
      "Pengfei Ren",
      "Ruilong Ma",
      "Jianxin Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_An_Aggregation-Free_Federated_Learning_for_Tackling_Data_Heterogeneity_CVPR_2024_paper.html": {
    "title": "An Aggregation-Free Federated Learning for Tackling Data Heterogeneity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Wang",
      "Huazhu Fu",
      "Renuga Kanagavelu",
      "Qingsong Wei",
      "Yong Liu",
      "Rick Siow Mong Goh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Generative_Multimodal_Models_are_In-Context_Learners_CVPR_2024_paper.html": {
    "title": "Generative Multimodal Models are In-Context Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Sun",
      "Yufeng Cui",
      "Xiaosong Zhang",
      "Fan Zhang",
      "Qiying Yu",
      "Yueze Wang",
      "Yongming Rao",
      "Jingjing Liu",
      "Tiejun Huang",
      "Xinlong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Synergistic_Global-space_Camera_and_Human_Reconstruction_from_Videos_CVPR_2024_paper.html": {
    "title": "Synergistic Global-space Camera and Human Reconstruction from Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhou Zhao",
      "Tuanfeng Yang Wang",
      "Bhiksha Raj",
      "Min Xu",
      "Jimei Yang",
      "Chun-Hao Paul Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kang_Hierarchical_Intra-modal_Correlation_Learning_for_Label-free_3D_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Hierarchical Intra-modal Correlation Learning for Label-free 3D Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Kang",
      "Lei Chu",
      "Jiahao Li",
      "Xuejin Chen",
      "Yan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Feature_Re-Embedding_Towards_Foundation_Model-Level_Performance_in_Computational_Pathology_CVPR_2024_paper.html": {
    "title": "Feature Re-Embedding: Towards Foundation Model-Level Performance in Computational Pathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Tang",
      "Fengtao Zhou",
      "Sheng Huang",
      "Xiang Zhu",
      "Yi Zhang",
      "Bo Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiong_DiffSal_Joint_Audio_and_Video_Learning_for_Diffusion_Saliency_Prediction_CVPR_2024_paper.html": {
    "title": "DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwen Xiong",
      "Peng Zhang",
      "Tao You",
      "Chuanyue Li",
      "Wei Huang",
      "Yufei Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Revisiting_Single_Image_Reflection_Removal_In_the_Wild_CVPR_2024_paper.html": {
    "title": "Revisiting Single Image Reflection Removal In the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yurui Zhu",
      "Xueyang Fu",
      "Peng-Tao Jiang",
      "Hao Zhang",
      "Qibin Sun",
      "Jinwei Chen",
      "Zheng-Jun Zha",
      "Bo Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_3D_Face_Reconstruction_with_the_Geometric_Guidance_of_Facial_Part_CVPR_2024_paper.html": {
    "title": "3D Face Reconstruction with the Geometric Guidance of Facial Part Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zidu Wang",
      "Xiangyu Zhu",
      "Tianshuo Zhang",
      "Baiqin Wang",
      "Zhen Lei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.html": {
    "title": "FreeU: Free Lunch in Diffusion U-Net",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyang Si",
      "Ziqi Huang",
      "Yuming Jiang",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Text_Prompt_with_Normality_Guidance_for_Weakly_Supervised_Video_Anomaly_CVPR_2024_paper.html": {
    "title": "Text Prompt with Normality Guidance for Weakly Supervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei Yang",
      "Jing Liu",
      "Peng Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_SparseOcc_Rethinking_Sparse_Latent_Representation_for_Vision-Based_Semantic_Occupancy_Prediction_CVPR_2024_paper.html": {
    "title": "SparseOcc: Rethinking Sparse Latent Representation for Vision-Based Semantic Occupancy Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pin Tang",
      "Zhongdao Wang",
      "Guoqing Wang",
      "Jilai Zheng",
      "Xiangxuan Ren",
      "Bailan Feng",
      "Chao Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_SinSR_Diffusion-Based_Image_Super-Resolution_in_a_Single_Step_CVPR_2024_paper.html": {
    "title": "SinSR: Diffusion-Based Image Super-Resolution in a Single Step",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Wang",
      "Wenhan Yang",
      "Xinyuan Chen",
      "Yaohui Wang",
      "Lanqing Guo",
      "Lap-Pui Chau",
      "Ziwei Liu",
      "Yu Qiao",
      "Alex C. Kot",
      "Bihan Wen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Frequency_Decoupling_for_Motion_Magnification_via_Multi-Level_Isomorphic_Architecture_CVPR_2024_paper.html": {
    "title": "Frequency Decoupling for Motion Magnification via Multi-Level Isomorphic Architecture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Wang",
      "Dan Guo",
      "Kun Li",
      "Zhun Zhong",
      "Meng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Systematic_Comparison_of_Semi-supervised_and_Self-supervised_Learning_for_Medical_Image_CVPR_2024_paper.html": {
    "title": "Systematic Comparison of Semi-supervised and Self-supervised Learning for Medical Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Huang",
      "Ruijie Jiang",
      "Shuchin Aeron",
      "Michael C. Hughes"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hollein_ViewDiff_3D-Consistent_Image_Generation_with_Text-to-Image_Models_CVPR_2024_paper.html": {
    "title": "ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Höllein",
      "Aljaž Boži?",
      "Norman Müller",
      "David Novotny",
      "Hung-Yu Tseng",
      "Christian Richardt",
      "Michael Zollhöfer",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kong_Hyperbolic_Learning_with_Synthetic_Captions_for_Open-World_Detection_CVPR_2024_paper.html": {
    "title": "Hyperbolic Learning with Synthetic Captions for Open-World Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fanjie Kong",
      "Yanbei Chen",
      "Jiarui Cai",
      "Davide Modolo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Diffusion_Models_Without_Attention_CVPR_2024_paper.html": {
    "title": "Diffusion Models Without Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Nathan Yan",
      "Jiatao Gu",
      "Alexander M. Rush"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Achille_Interpretable_Measures_of_Conceptual_Similarity_by_Complexity-Constrained_Descriptive_Auto-Encoding_CVPR_2024_paper.html": {
    "title": "Interpretable Measures of Conceptual Similarity by Complexity-Constrained Descriptive Auto-Encoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessandro Achille",
      "Greg Ver Steeg",
      "Tian Yu Liu",
      "Matthew Trager",
      "Carson Klingenberg",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chhatre_Emotional_Speech-driven_3D_Body_Animation_via_Disentangled_Latent_Diffusion_CVPR_2024_paper.html": {
    "title": "Emotional Speech-driven 3D Body Animation via Disentangled Latent Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiran Chhatre",
      "Radek Dan??ek",
      "Nikos Athanasiou",
      "Giorgio Becherini",
      "Christopher Peters",
      "Michael J. Black",
      "Timo Bolkart"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_3D_Feature_Tracking_via_Event_Camera_CVPR_2024_paper.html": {
    "title": "3D Feature Tracking via Event Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqi Li",
      "Zhikuan Zhou",
      "Zhou Xue",
      "Yipeng Li",
      "Shaoyi Du",
      "Yue Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Horita_Retrieval-Augmented_Layout_Transformer_for_Content-Aware_Layout_Generation_CVPR_2024_paper.html": {
    "title": "Retrieval-Augmented Layout Transformer for Content-Aware Layout Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daichi Horita",
      "Naoto Inoue",
      "Kotaro Kikuchi",
      "Kota Yamaguchi",
      "Kiyoharu Aizawa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kent_MSU-4S_-_The_Michigan_State_University_Four_Seasons_Dataset_CVPR_2024_paper.html": {
    "title": "MSU-4S - The Michigan State University Four Seasons Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Kent",
      "Mohammed Alyaqoub",
      "Xiaohu Lu",
      "Hamed Khatounabadi",
      "Kookjin Sung",
      "Cole Scheller",
      "Alexander Dalat",
      "Asma bin Thabit",
      "Roberto Whitley",
      "Hayder Radha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Improving_Plasticity_in_Online_Continual_Learning_via_Collaborative_Learning_CVPR_2024_paper.html": {
    "title": "Improving Plasticity in Online Continual Learning via Collaborative Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maorong Wang",
      "Nicolas Michel",
      "Ling Xiao",
      "Toshihiko Yamasaki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_InstantBooth_Personalized_Text-to-Image_Generation_without_Test-Time_Finetuning_CVPR_2024_paper.html": {
    "title": "InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Shi",
      "Wei Xiong",
      "Zhe Lin",
      "Hyun Joon Jung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiang_MaxQ_Multi-Axis_Query_for_NM_Sparsity_Network_CVPR_2024_paper.html": {
    "title": "MaxQ: Multi-Axis Query for N:M Sparsity Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyang Xiang",
      "Siqi Li",
      "Junhao Chen",
      "Zhuangzhi Chen",
      "Tianxin Huang",
      "Linpeng Peng",
      "Yong Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Part-aware_Unified_Representation_of_Language_and_Skeleton_for_Zero-shot_Action_CVPR_2024_paper.html": {
    "title": "Part-aware Unified Representation of Language and Skeleton for Zero-shot Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anqi Zhu",
      "Qiuhong Ke",
      "Mingming Gong",
      "James Bailey"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_SD2EventSelf-supervised_Learning_of_Dynamic_Detectors_and_Contextual_Descriptors_for_Event_CVPR_2024_paper.html": {
    "title": "SD2Event:Self-supervised Learning of Dynamic Detectors and Contextual Descriptors for Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Gao",
      "Yuqing Zhu",
      "Xinjun Li",
      "Yimin Du",
      "Tianzhu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pham_Composing_Object_Relations_and_Attributes_for_Image-Text_Matching_CVPR_2024_paper.html": {
    "title": "Composing Object Relations and Attributes for Image-Text Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khoi Pham",
      "Chuong Huynh",
      "Ser-Nam Lim",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Singh_Previously_on_..._From_Recaps_to_Story_Summarization_CVPR_2024_paper.html": {
    "title": "Previously on ... From Recaps to Story Summarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aditya Kumar Singh",
      "Dhruv Srivastava",
      "Makarand Tapaswi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_PaReNeRF_Toward_Fast_Large-scale_Dynamic_NeRF_with_Patch-based_Reference_CVPR_2024_paper.html": {
    "title": "PaReNeRF: Toward Fast Large-scale Dynamic NeRF with Patch-based Reference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Tang",
      "Min Yang",
      "Penghui Sun",
      "Hui Li",
      "Yuchao Dai",
      "Feng Zhu",
      "Hojae Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_mPLUG-Owl2_Revolutionizing_Multi-modal_Large_Language_Model_with_Modality_Collaboration_CVPR_2024_paper.html": {
    "title": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinghao Ye",
      "Haiyang Xu",
      "Jiabo Ye",
      "Ming Yan",
      "Anwen Hu",
      "Haowei Liu",
      "Qi Qian",
      "Ji Zhang",
      "Fei Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jeon_Spectral_and_Polarization_Vision_Spectro-polarimetric_Real-world_Dataset_CVPR_2024_paper.html": {
    "title": "Spectral and Polarization Vision: Spectro-polarimetric Real-world Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujin Jeon",
      "Eunsue Choi",
      "Youngchan Kim",
      "Yunseong Moon",
      "Khalid Omer",
      "Felix Heide",
      "Seung-Hwan Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_CVPR_2024_paper.html": {
    "title": "Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongjie Li",
      "Yu Wu",
      "Xuming He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Baitieva_Supervised_Anomaly_Detection_for_Complex_Industrial_Images_CVPR_2024_paper.html": {
    "title": "Supervised Anomaly Detection for Complex Industrial Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aimira Baitieva",
      "David Hurych",
      "Victor Besnier",
      "Olivier Bernard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Koch_Open3DSG_Open-Vocabulary_3D_Scene_Graphs_from_Point_Clouds_with_Queryable_CVPR_2024_paper.html": {
    "title": "Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with Queryable Objects and Open-Set Relationships",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sebastian Koch",
      "Narunas Vaskevicius",
      "Mirco Colosi",
      "Pedro Hermosilla",
      "Timo Ropinski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SURE_SUrvey_REcipes_for_building_reliable_and_robust_deep_networks_CVPR_2024_paper.html": {
    "title": "SURE: SUrvey REcipes for building reliable and robust deep networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuting Li",
      "Yingyi Chen",
      "Xuanlong Yu",
      "Dexiong Chen",
      "Xi Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_PolarRec_Improving_Radio_Interferometric_Data_Reconstruction_Using_Polar_Coordinates_CVPR_2024_paper.html": {
    "title": "PolarRec: Improving Radio Interferometric Data Reconstruction Using Polar Coordinates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoqi Wang",
      "Zhuoyang Chen",
      "Jiayi Zhu",
      "Qiong Luo",
      "Feng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Affine_Equivariant_Networks_Based_on_Differential_Invariants_CVPR_2024_paper.html": {
    "title": "Affine Equivariant Networks Based on Differential Invariants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yikang Li",
      "Yeqing Qiu",
      "Yuxuan Chen",
      "Lingshen He",
      "Zhouchen Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Selectively_Informative_Description_can_Reduce_Undesired_Embedding_Entanglements_in_Text-to-Image_CVPR_2024_paper.html": {
    "title": "Selectively Informative Description can Reduce Undesired Embedding Entanglements in Text-to-Image Personalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jimyeong Kim",
      "Jungwon Park",
      "Wonjong Rhee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pasca_Summarize_the_Past_to_Predict_the_Future_Natural_Language_Descriptions_CVPR_2024_paper.html": {
    "title": "Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction Anticipation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Razvan-George Pasca",
      "Alexey Gavryushin",
      "Muhammad Hamza",
      "Yen-Ling Kuo",
      "Kaichun Mo",
      "Luc Van Gool",
      "Otmar Hilliges",
      "Xi Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Transfer_CLIP_for_Generalizable_Image_Denoising_CVPR_2024_paper.html": {
    "title": "Transfer CLIP for Generalizable Image Denoising",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Cheng",
      "Dong Liang",
      "Shan Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Smooth_Diffusion_Crafting_Smooth_Latent_Spaces_in_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Guo",
      "Xingqian Xu",
      "Yifan Pu",
      "Zanlin Ni",
      "Chaofei Wang",
      "Manushree Vasu",
      "Shiji Song",
      "Gao Huang",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Towards_CLIP-driven_Language-free_3D_Visual_Grounding_via_2D-3D_Relational_Enhancement_CVPR_2024_paper.html": {
    "title": "Towards CLIP-driven Language-free 3D Visual Grounding via 2D-3D Relational Enhancement and Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Zhang",
      "Han Luo",
      "Yinjie Lei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Izquierdo_Optimal_Transport_Aggregation_for_Visual_Place_Recognition_CVPR_2024_paper.html": {
    "title": "Optimal Transport Aggregation for Visual Place Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sergio Izquierdo",
      "Javier Civera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_FlowIE_Efficient_Image_Enhancement_via_Rectified_Flow_CVPR_2024_paper.html": {
    "title": "FlowIE: Efficient Image Enhancement via Rectified Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Zhu",
      "Wenliang Zhao",
      "Ao Li",
      "Yansong Tang",
      "Jie Zhou",
      "Jiwen Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_Aligning_and_Prompting_Everything_All_at_Once_for_Universal_Visual_CVPR_2024_paper.html": {
    "title": "Aligning and Prompting Everything All at Once for Universal Visual Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhang Shen",
      "Chaoyou Fu",
      "Peixian Chen",
      "Mengdan Zhang",
      "Ke Li",
      "Xing Sun",
      "Yunsheng Wu",
      "Shaohui Lin",
      "Rongrong Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Correlation-Decoupled_Knowledge_Distillation_for_Multimodal_Sentiment_Analysis_with_Incomplete_Modalities_CVPR_2024_paper.html": {
    "title": "Correlation-Decoupled Knowledge Distillation for Multimodal Sentiment Analysis with Incomplete Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingcheng Li",
      "Dingkang Yang",
      "Xiao Zhao",
      "Shuaibing Wang",
      "Yan Wang",
      "Kun Yang",
      "Mingyang Sun",
      "Dongliang Kou",
      "Ziyun Qian",
      "Lihua Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Revisiting_Adversarial_Training_at_Scale_CVPR_2024_paper.html": {
    "title": "Revisiting Adversarial Training at Scale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyu Wang",
      "Xianhang Li",
      "Hongru Zhu",
      "Cihang Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Towards_Fairness-Aware_Adversarial_Learning_CVPR_2024_paper.html": {
    "title": "Towards Fairness-Aware Adversarial Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanghao Zhang",
      "Tianle Zhang",
      "Ronghui Mu",
      "Xiaowei Huang",
      "Wenjie Ruan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_LoSh_Long-Short_Text_Joint_Prediction_Network_for_Referring_Video_Object_CVPR_2024_paper.html": {
    "title": "LoSh: Long-Short Text Joint Prediction Network for Referring Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linfeng Yuan",
      "Miaojing Shi",
      "Zijie Yue",
      "Qijun Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_MirageRoom_3D_Scene_Segmentation_with_2D_Pre-trained_Models_by_Mirage_CVPR_2024_paper.html": {
    "title": "MirageRoom: 3D Scene Segmentation with 2D Pre-trained Models by Mirage Projection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haowen Sun",
      "Yueqi Duan",
      "Juncheng Yan",
      "Yifan Liu",
      "Jiwen Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_In2SET_Intra-Inter_Similarity_Exploiting_Transformer_for_Dual-Camera_Compressive_Hyperspectral_Imaging_CVPR_2024_paper.html": {
    "title": "In2SET: Intra-Inter Similarity Exploiting Transformer for Dual-Camera Compressive Hyperspectral Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Wang",
      "Lizhi Wang",
      "Xiangtian Ma",
      "Maoqing Zhang",
      "Lin Zhu",
      "Hua Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cho_Dual_Prototype_Attention_for_Unsupervised_Video_Object_Segmentation_CVPR_2024_paper.html": {
    "title": "Dual Prototype Attention for Unsupervised Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suhwan Cho",
      "Minhyeok Lee",
      "Seunghoon Lee",
      "Dogyoon Lee",
      "Heeseung Choi",
      "Ig-Jae Kim",
      "Sangyoun Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Look-Up_Table_Compression_for_Efficient_Image_Restoration_CVPR_2024_paper.html": {
    "title": "Look-Up Table Compression for Efficient Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinglong Li",
      "Jiacheng Li",
      "Zhiwei Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cui_TextNeRF_A_Novel_Scene-Text_Image_Synthesis_Method_based_on_Neural_CVPR_2024_paper.html": {
    "title": "TextNeRF: A Novel Scene-Text Image Synthesis Method based on Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialei Cui",
      "Jianwei Du",
      "Wenzhuo Liu",
      "Zhouhui Lian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Takimoto_Dr.Hair_Reconstructing_Scalp-Connected_Hair_Strands_without_Pre-Training_via_Differentiable_Rendering_CVPR_2024_paper.html": {
    "title": "Dr.Hair: Reconstructing Scalp-Connected Hair Strands without Pre-Training via Differentiable Rendering of Line Segments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusuke Takimoto",
      "Hikari Takehara",
      "Hiroyuki Sato",
      "Zihao Zhu",
      "Bo Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Improving_Training_Efficiency_of_Diffusion_Models_via_Multi-Stage_Framework_and_CVPR_2024_paper.html": {
    "title": "Improving Training Efficiency of Diffusion Models via Multi-Stage Framework and Tailored Multi-Decoder Architecture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huijie Zhang",
      "Yifu Lu",
      "Ismail Alkhouri",
      "Saiprasad Ravishankar",
      "Dogyoon Song",
      "Qing Qu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_In-Context_Matting_CVPR_2024_paper.html": {
    "title": "In-Context Matting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Guo",
      "Zixuan Ye",
      "Zhiguo Cao",
      "Hao Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Navigate_Beyond_Shortcuts_Debiased_Learning_Through_the_Lens_of_Neural_CVPR_2024_paper.html": {
    "title": "Navigate Beyond Shortcuts: Debiased Learning Through the Lens of Neural Collapse",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yining Wang",
      "Junjie Sun",
      "Chenyue Wang",
      "Mi Zhang",
      "Min Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_DiVa-360_The_Dynamic_Visual_Dataset_for_Immersive_Neural_Fields_CVPR_2024_paper.html": {
    "title": "DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng-You Lu",
      "Peisen Zhou",
      "Angela Xing",
      "Chandradeep Pokhariya",
      "Arnab Dey",
      "Ishaan Nikhil Shah",
      "Rugved Mavidipalli",
      "Dylan Hu",
      "Andrew I. Comport",
      "Kefan Chen",
      "Srinath Sridhar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_A_Subspace-Constrained_Tylers_Estimator_and_its_Applications_to_Structure_from_CVPR_2024_paper.html": {
    "title": "A Subspace-Constrained Tyler's Estimator and its Applications to Structure from Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Yu",
      "Teng Zhang",
      "Gilad Lerman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_FSC_Few-point_Shape_Completion_CVPR_2024_paper.html": {
    "title": "FSC: Few-point Shape Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianzu Wu",
      "Xianfeng Wu",
      "Tianyu Luan",
      "Yajing Bai",
      "Zhongyuan Lai",
      "Junsong Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wan_CAD_Photorealistic_3D_Generation_via_Adversarial_Distillation_CVPR_2024_paper.html": {
    "title": "CAD: Photorealistic 3D Generation via Adversarial Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Wan",
      "Despoina Paschalidou",
      "Ian Huang",
      "Hongyu Liu",
      "Bokui Shen",
      "Xiaoyu Xiang",
      "Jing Liao",
      "Leonidas Guibas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions_CVPR_2024_paper.html": {
    "title": "Enhancing Vision-Language Pre-training with Rich Supervisions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Gao",
      "Kunyu Shi",
      "Pengkai Zhu",
      "Edouard Belval",
      "Oren Nuriel",
      "Srikar Appalaraju",
      "Shabnam Ghadar",
      "Zhuowen Tu",
      "Vijay Mahadevan",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mahmud_T-VSL_Text-Guided_Visual_Sound_Source_Localization_in_Mixtures_CVPR_2024_paper.html": {
    "title": "T-VSL: Text-Guided Visual Sound Source Localization in Mixtures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tanvir Mahmud",
      "Yapeng Tian",
      "Diana Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_DemoCaricature_Democratising_Caricature_Generation_with_a_Rough_Sketch_CVPR_2024_paper.html": {
    "title": "DemoCaricature: Democratising Caricature Generation with a Rough Sketch",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dar-Yen Chen",
      "Ayan Kumar Bhunia",
      "Subhadeep Koley",
      "Aneeshan Sain",
      "Pinaki Nath Chowdhury",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_CapHuman_Capture_Your_Moments_in_Parallel_Universes_CVPR_2024_paper.html": {
    "title": "CapHuman: Capture Your Moments in Parallel Universes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Liang",
      "Fan Ma",
      "Linchao Zhu",
      "Yingying Deng",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SDPose_Tokenized_Pose_Estimation_via_Circulation-Guide_Self-Distillation_CVPR_2024_paper.html": {
    "title": "SDPose: Tokenized Pose Estimation via Circulation-Guide Self-Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sichen Chen",
      "Yingyi Zhang",
      "Siming Huang",
      "Ran Yi",
      "Ke Fan",
      "Ruixin Zhang",
      "Peixian Chen",
      "Jun Wang",
      "Shouhong Ding",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Moon_Authentic_Hand_Avatar_from_a_Phone_Scan_via_Universal_Hand_CVPR_2024_paper.html": {
    "title": "Authentic Hand Avatar from a Phone Scan via Universal Hand Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gyeongsik Moon",
      "Weipeng Xu",
      "Rohan Joshi",
      "Chenglei Wu",
      "Takaaki Shiratori"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jain_VCoder_Versatile_Vision_Encoders_for_Multimodal_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "VCoder: Versatile Vision Encoders for Multimodal Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jitesh Jain",
      "Jianwei Yang",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Geng_Event-based_Visible_and_Infrared_Fusion_via_Multi-task_Collaboration_CVPR_2024_paper.html": {
    "title": "Event-based Visible and Infrared Fusion via Multi-task Collaboration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengyue Geng",
      "Lin Zhu",
      "Lizhi Wang",
      "Wei Zhang",
      "Ruiqin Xiong",
      "Yonghong Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sodano_Open-World_Semantic_Segmentation_Including_Class_Similarity_CVPR_2024_paper.html": {
    "title": "Open-World Semantic Segmentation Including Class Similarity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matteo Sodano",
      "Federico Magistri",
      "Lucas Nunes",
      "Jens Behley",
      "Cyrill Stachniss"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_RegionPLC_Regional_Point-Language_Contrastive_Learning_for_Open-World_3D_Scene_Understanding_CVPR_2024_paper.html": {
    "title": "RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihan Yang",
      "Runyu Ding",
      "Weipeng Deng",
      "Zhe Wang",
      "Xiaojuan Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pan_Adaptive_VIO_Deep_Visual-Inertial_Odometry_with_Online_Continual_Learning_CVPR_2024_paper.html": {
    "title": "Adaptive VIO: Deep Visual-Inertial Odometry with Online Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youqi Pan",
      "Wugen Zhou",
      "Yingdian Cao",
      "Hongbin Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Towards_Memorization-Free_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Towards Memorization-Free Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Chen",
      "Daochang Liu",
      "Chang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shao_Generalized_Large-Scale_Data_Condensation_via_Various_Backbone_and_Statistical_Matching_CVPR_2024_paper.html": {
    "title": "Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shitong Shao",
      "Zeyuan Yin",
      "Muxin Zhou",
      "Xindong Zhang",
      "Zhiqiang Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Puy_Three_Pillars_Improving_Vision_Foundation_Model_Distillation_for_Lidar_CVPR_2024_paper.html": {
    "title": "Three Pillars Improving Vision Foundation Model Distillation for Lidar",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gilles Puy",
      "Spyros Gidaris",
      "Alexandre Boulch",
      "Oriane Siméoni",
      "Corentin Sautier",
      "Patrick Pérez",
      "Andrei Bursuc",
      "Renaud Marlet"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_On_Train-Test_Class_Overlap_and_Detection_for_Image_Retrieval_CVPR_2024_paper.html": {
    "title": "On Train-Test Class Overlap and Detection for Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chull Hwan Song",
      "Jooyoung Yoon",
      "Taebaek Hwang",
      "Shunghyun Choi",
      "Yeong Hyeon Gu",
      "Yannis Avrithis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_AttriHuman-3D_Editable_3D_Human_Avatar_Generation_with_Attribute_Decomposition_and_CVPR_2024_paper.html": {
    "title": "AttriHuman-3D: Editable 3D Human Avatar Generation with Attribute Decomposition and Indexing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Yang",
      "Tianyi Chen",
      "Xiaosheng He",
      "Zhongang Cai",
      "Lei Yang",
      "Si Wu",
      "Guosheng Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_IQ-VFI_Implicit_Quadratic_Motion_Estimation_for_Video_Frame_Interpolation_CVPR_2024_paper.html": {
    "title": "IQ-VFI: Implicit Quadratic Motion Estimation for Video Frame Interpolation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengshun Hu",
      "Kui Jiang",
      "Zhihang Zhong",
      "Zheng Wang",
      "Yinqiang Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_KeyPoint_Relative_Position_Encoding_for_Face_Recognition_CVPR_2024_paper.html": {
    "title": "KeyPoint Relative Position Encoding for Face Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minchul Kim",
      "Yiyang Su",
      "Feng Liu",
      "Anil Jain",
      "Xiaoming Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Hyper-MD_Mesh_Denoising_with_Customized_Parameters_Aware_of_Noise_Intensity_CVPR_2024_paper.html": {
    "title": "Hyper-MD: Mesh Denoising with Customized Parameters Aware of Noise Intensity and Geometric Characteristics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingtao Wang",
      "Hongliang Wei",
      "Xiaopeng Fan",
      "Debin Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_Learning_Object_State_Changes_in_Videos_An_Open-World_Perspective_CVPR_2024_paper.html": {
    "title": "Learning Object State Changes in Videos: An Open-World Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihui Xue",
      "Kumar Ashutosh",
      "Kristen Grauman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rout_Beyond_First-Order_Tweedie_Solving_Inverse_Problems_using_Latent_Diffusion_CVPR_2024_paper.html": {
    "title": "Beyond First-Order Tweedie: Solving Inverse Problems using Latent Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Litu Rout",
      "Yujia Chen",
      "Abhishek Kumar",
      "Constantine Caramanis",
      "Sanjay Shakkottai",
      "Wen-Sheng Chu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_Rethinking_the_Objectives_of_Vector-Quantized_Tokenizers_for_Image_Synthesis_CVPR_2024_paper.html": {
    "title": "Rethinking the Objectives of Vector-Quantized Tokenizers for Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchao Gu",
      "Xintao Wang",
      "Yixiao Ge",
      "Ying Shan",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Slim_ShapeWalk_Compositional_Shape_Editing_Through_Language-Guided_Chains_CVPR_2024_paper.html": {
    "title": "ShapeWalk: Compositional Shape Editing Through Language-Guided Chains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Habib Slim",
      "Mohamed Elhoseiny"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MESA_Matching_Everything_by_Segmenting_Anything_CVPR_2024_paper.html": {
    "title": "MESA: Matching Everything by Segmenting Anything",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yesheng Zhang",
      "Xu Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Learning_Degradation-Independent_Representations_for_Camera_ISP_Pipelines_CVPR_2024_paper.html": {
    "title": "Learning Degradation-Independent Representations for Camera ISP Pipelines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhui Guo",
      "Fangzhou Luo",
      "Xiaolin Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_SCoFT_Self-Contrastive_Fine-Tuning_for_Equitable_Image_Generation_CVPR_2024_paper.html": {
    "title": "SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixuan Liu",
      "Peter Schaldenbrand",
      "Beverley-Claire Okogwu",
      "Wenxuan Peng",
      "Youngsik Yun",
      "Andrew Hundt",
      "Jihie Kim",
      "Jean Oh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Continuous_Pose_for_Monocular_Cameras_in_Neural_Implicit_Representation_CVPR_2024_paper.html": {
    "title": "Continuous Pose for Monocular Cameras in Neural Implicit Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Ma",
      "Danda Pani Paudel",
      "Ajad Chhatkuli",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_OmniGlue_Generalizable_Feature_Matching_with_Foundation_Model_Guidance_CVPR_2024_paper.html": {
    "title": "OmniGlue: Generalizable Feature Matching with Foundation Model Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanwen Jiang",
      "Arjun Karpur",
      "Bingyi Cao",
      "Qixing Huang",
      "André Araujo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Su_D4_Dataset_Distillation_via_Disentangled_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "D^4: Dataset Distillation via Disentangled Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duo Su",
      "Junjie Hou",
      "Weizhi Gao",
      "Yingjie Tian",
      "Bowen Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_OmniSDF_Scene_Reconstruction_using_Omnidirectional_Signed_Distance_Functions_and_Adaptive_CVPR_2024_paper.html": {
    "title": "OmniSDF: Scene Reconstruction using Omnidirectional Signed Distance Functions and Adaptive Binoctrees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hakyeong Kim",
      "Andreas Meuleman",
      "Hyeonjoong Jang",
      "James Tompkin",
      "Min H. Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Generating_Content_for_HDR_Deghosting_from_Frequency_View_CVPR_2024_paper.html": {
    "title": "Generating Content for HDR Deghosting from Frequency View",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Hu",
      "Qingsen Yan",
      "Yuankai Qi",
      "Yanning Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Iterated_Learning_Improves_Compositionality_in_Large_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Iterated Learning Improves Compositionality in Large Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenhao Zheng",
      "Jieyu Zhang",
      "Aniruddha Kembhavi",
      "Ranjay Krishna"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Event_Stream-based_Visual_Object_Tracking_A_High-Resolution_Benchmark_Dataset_and_CVPR_2024_paper.html": {
    "title": "Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Wang",
      "Shiao Wang",
      "Chuanming Tang",
      "Lin Zhu",
      "Bo Jiang",
      "Yonghong Tian",
      "Jin Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_LiDAR-Net_A_Real-scanned_3D_Point_Cloud_Dataset_for_Indoor_Scenes_CVPR_2024_paper.html": {
    "title": "LiDAR-Net: A Real-scanned 3D Point Cloud Dataset for Indoor Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanwen Guo",
      "Yuanqi Li",
      "Dayong Ren",
      "Xiaohong Zhang",
      "Jiawei Li",
      "Liang Pu",
      "Changfeng Ma",
      "Xiaoyu Zhan",
      "Jie Guo",
      "Mingqiang Wei",
      "Yan Zhang",
      "Piaopiao Yu",
      "Shuangyu Yang",
      "Donghao Ji",
      "Huisheng Ye",
      "Hao Sun",
      "Yansong Liu",
      "Yinuo Chen",
      "Jiaqi Zhu",
      "Hongyu Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Dual_DETRs_for_Multi-Label_Temporal_Action_Detection_CVPR_2024_paper.html": {
    "title": "Dual DETRs for Multi-Label Temporal Action Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Zhu",
      "Guozhen Zhang",
      "Jing Tan",
      "Gangshan Wu",
      "Limin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_Rich_Human_Feedback_for_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Rich Human Feedback for Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youwei Liang",
      "Junfeng He",
      "Gang Li",
      "Peizhao Li",
      "Arseniy Klimovskiy",
      "Nicholas Carolan",
      "Jiao Sun",
      "Jordi Pont-Tuset",
      "Sarah Young",
      "Feng Yang",
      "Junjie Ke",
      "Krishnamurthy Dj Dvijotham",
      "Katherine M. Collins",
      "Yiwen Luo",
      "Yang Li",
      "Kai J Kohlhoff",
      "Deepak Ramachandran",
      "Vidhya Navalpakkam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_360DVD_Controllable_Panorama_Video_Generation_with_360-Degree_Video_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian Wang",
      "Weiqi Li",
      "Chong Mou",
      "Xinhua Cheng",
      "Jian Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Map-Relative_Pose_Regression_for_Visual_Re-Localization_CVPR_2024_paper.html": {
    "title": "Map-Relative Pose Regression for Visual Re-Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Chen",
      "Tommaso Cavallari",
      "Victor Adrian Prisacariu",
      "Eric Brachmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_Implicit_Event-RGBD_Neural_SLAM_CVPR_2024_paper.html": {
    "title": "Implicit Event-RGBD Neural SLAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Delin Qu",
      "Chi Yan",
      "Dong Wang",
      "Jie Yin",
      "Qizhi Chen",
      "Dan Xu",
      "Yiting Zhang",
      "Bin Zhao",
      "Xuelong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Virtual_Immunohistochemistry_Staining_for_Histological_Images_Assisted_by_Weakly-supervised_Learning_CVPR_2024_paper.html": {
    "title": "Virtual Immunohistochemistry Staining for Histological Images Assisted by Weakly-supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahan Li",
      "Jiuyang Dong",
      "Shenjin Huang",
      "Xi Li",
      "Junjun Jiang",
      "Xiaopeng Fan",
      "Yongbing Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_DeCoTR_Enhancing_Depth_Completion_with_2D_and_3D_Attentions_CVPR_2024_paper.html": {
    "title": "DeCoTR: Enhancing Depth Completion with 2D and 3D Attentions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunxiao Shi",
      "Manish Kumar Singh",
      "Hong Cai",
      "Fatih Porikli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dehdashtian_Utility-Fairness_Trade-Offs_and_How_to_Find_Them_CVPR_2024_paper.html": {
    "title": "Utility-Fairness Trade-Offs and How to Find Them",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sepehr Dehdashtian",
      "Bashir Sadeghi",
      "Vishnu Naresh Boddeti"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Domain-Specific_Block_Selection_and_Paired-View_Pseudo-Labeling_for_Online_Test-Time_Adaptation_CVPR_2024_paper.html": {
    "title": "Domain-Specific Block Selection and Paired-View Pseudo-Labeling for Online Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yeonguk Yu",
      "Sungho Shin",
      "Seunghyeok Back",
      "Mihwan Ko",
      "Sangjun Noh",
      "Kyoobin Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Aerial_Lifting_Neural_Urban_Semantic_and_Building_Instance_Lifting_from_CVPR_2024_paper.html": {
    "title": "Aerial Lifting: Neural Urban Semantic and Building Instance Lifting from Aerial Imagery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Zhang",
      "Guanying Chen",
      "Jiaxing Chen",
      "Shuguang Cui"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Aygun_SAOR_Single-View_Articulated_Object_Reconstruction_CVPR_2024_paper.html": {
    "title": "SAOR: Single-View Articulated Object Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehmet Aygun",
      "Oisin Mac Aodha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ramanagopal_A_Theory_of_Joint_Light_and_Heat_Transport_for_Lambertian_CVPR_2024_paper.html": {
    "title": "A Theory of Joint Light and Heat Transport for Lambertian Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mani Ramanagopal",
      "Sriram Narayanan",
      "Aswin C. Sankaranarayanan",
      "Srinivasa G. Narasimhan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Du_iKUN_Speak_to_Trackers_without_Retraining_CVPR_2024_paper.html": {
    "title": "iKUN: Speak to Trackers without Retraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhao Du",
      "Cheng Lei",
      "Zhicheng Zhao",
      "Fei Su"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mai_RankMatch_Exploring_the_Better_Consistency_Regularization_for_Semi-supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "RankMatch: Exploring the Better Consistency Regularization for Semi-supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huayu Mai",
      "Rui Sun",
      "Tianzhu Zhang",
      "Feng Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kuang_Facial_Identity_Anonymization_via_Intrinsic_and_Extrinsic_Attention_Distraction_CVPR_2024_paper.html": {
    "title": "Facial Identity Anonymization via Intrinsic and Extrinsic Attention Distraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenzhong Kuang",
      "Xiaochen Yang",
      "Yingjie Shen",
      "Chao Hu",
      "Jun Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_3D-SceneDreamer_Text-Driven_3D-Consistent_Scene_Generation_CVPR_2024_paper.html": {
    "title": "3D-SceneDreamer: Text-Driven 3D-Consistent Scene Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songchun Zhang",
      "Yibo Zhang",
      "Quan Zheng",
      "Rui Ma",
      "Wei Hua",
      "Hujun Bao",
      "Weiwei Xu",
      "Changqing Zou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fei_VMINer_Versatile_Multi-view_Inverse_Rendering_with_Near-_and_Far-field_Light_CVPR_2024_paper.html": {
    "title": "VMINer: Versatile Multi-view Inverse Rendering with Near- and Far-field Light Sources",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Fei",
      "Jiajun Tang",
      "Ping Tan",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_RoHM_Robust_Human_Motion_Reconstruction_via_Diffusion_CVPR_2024_paper.html": {
    "title": "RoHM: Robust Human Motion Reconstruction via Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siwei Zhang",
      "Bharat Lal Bhatnagar",
      "Yuanlu Xu",
      "Alexander Winkler",
      "Petr Kadlecek",
      "Siyu Tang",
      "Federica Bogo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Do_You_Remember_Dense_Video_Captioning_with_Cross-Modal_Memory_Retrieval_CVPR_2024_paper.html": {
    "title": "Do You Remember? Dense Video Captioning with Cross-Modal Memory Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minkuk Kim",
      "Hyeon Bae Kim",
      "Jinyoung Moon",
      "Jinwoo Choi",
      "Seong Tae Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_DuPL_Dual_Student_with_Trustworthy_Progressive_Learning_for_Robust_Weakly_CVPR_2024_paper.html": {
    "title": "DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanchen Wu",
      "Xichen Ye",
      "Kequan Yang",
      "Jide Li",
      "Xiaoqiang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Learning_with_Structural_Labels_for_Learning_with_Noisy_Labels_CVPR_2024_paper.html": {
    "title": "Learning with Structural Labels for Learning with Noisy Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Noo-ri Kim",
      "Jin-Seop Lee",
      "Jee-Hyong Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_SurMo_Surface-based_4D_Motion_Modeling_for_Dynamic_Human_Rendering_CVPR_2024_paper.html": {
    "title": "SurMo: Surface-based 4D Motion Modeling for Dynamic Human Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Hu",
      "Fangzhou Hong",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kant_SPAD_Spatially_Aware_Multi-View_Diffusers_CVPR_2024_paper.html": {
    "title": "SPAD: Spatially Aware Multi-View Diffusers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yash Kant",
      "Aliaksandr Siarohin",
      "Ziyi Wu",
      "Michael Vasilkovsky",
      "Guocheng Qian",
      "Jian Ren",
      "Riza Alp Guler",
      "Bernard Ghanem",
      "Sergey Tulyakov",
      "Igor Gilitschenski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Gradient_Reweighting_Towards_Imbalanced_Class-Incremental_Learning_CVPR_2024_paper.html": {
    "title": "Gradient Reweighting: Towards Imbalanced Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangpeng He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qing_Hierarchical_Spatio-temporal_Decoupling_for_Text-to-Video_Generation_CVPR_2024_paper.html": {
    "title": "Hierarchical Spatio-temporal Decoupling for Text-to-Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwu Qing",
      "Shiwei Zhang",
      "Jiayu Wang",
      "Xiang Wang",
      "Yujie Wei",
      "Yingya Zhang",
      "Changxin Gao",
      "Nong Sang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lv_PLACE_Adaptive_Layout-Semantic_Fusion_for_Semantic_Image_Synthesis_CVPR_2024_paper.html": {
    "title": "PLACE: Adaptive Layout-Semantic Fusion for Semantic Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengyao Lv",
      "Yuxiang Wei",
      "Wangmeng Zuo",
      "Kwan-Yee K. Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Exploring_Efficient_Asymmetric_Blind-Spots_for_Self-Supervised_Denoising_in_Real-World_Scenarios_CVPR_2024_paper.html": {
    "title": "Exploring Efficient Asymmetric Blind-Spots for Self-Supervised Denoising in Real-World Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyan Chen",
      "Jiyuan Zhang",
      "Zhaofei Yu",
      "Tiejun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Matsuki_Gaussian_Splatting_SLAM_CVPR_2024_paper.html": {
    "title": "Gaussian Splatting SLAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hidenobu Matsuki",
      "Riku Murai",
      "Paul H.J. Kelly",
      "Andrew J. Davison"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Not_All_Classes_Stand_on_Same_Embeddings_Calibrating_a_Semantic_CVPR_2024_paper.html": {
    "title": "Not All Classes Stand on Same Embeddings: Calibrating a Semantic Distance with Metric Tensor",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jae Hyeon Park",
      "Gyoomin Lee",
      "Seunggi Park",
      "Sung In Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Papalampidi_A_Simple_Recipe_for_Contrastively_Pre-training_Video-First_Encoders_Beyond_16_CVPR_2024_paper.html": {
    "title": "A Simple Recipe for Contrastively Pre-training Video-First Encoders Beyond 16 Frames",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pinelopi Papalampidi",
      "Skanda Koppula",
      "Shreya Pathak",
      "Justin Chiu",
      "Joe Heyward",
      "Viorica Patraucean",
      "Jiajun Shen",
      "Antoine Miech",
      "Andrew Zisserman",
      "Aida Nematzdeh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_DeMatch_Deep_Decomposition_of_Motion_Field_for_Two-View_Correspondence_Learning_CVPR_2024_paper.html": {
    "title": "DeMatch: Deep Decomposition of Motion Field for Two-View Correspondence Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shihua Zhang",
      "Zizhuo Li",
      "Yuan Gao",
      "Jiayi Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Hierarchical_Diffusion_Policy_for_Kinematics-Aware_Multi-Task_Robotic_Manipulation_CVPR_2024_paper.html": {
    "title": "Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Ma",
      "Sumit Patidar",
      "Iain Haughton",
      "Stephen James"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Efficient_Multi-scale_Network_with_Learnable_Discrete_Wavelet_Transform_for_Blind_CVPR_2024_paper.html": {
    "title": "Efficient Multi-scale Network with Learnable Discrete Wavelet Transform for Blind Motion Deblurring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Gao",
      "Tianheng Qiu",
      "Xinyu Zhang",
      "Hanlin Bai",
      "Kang Liu",
      "Xuan Huang",
      "Hu Wei",
      "Guoying Zhang",
      "Huaping Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MaskPLAN_Masked_Generative_Layout_Planning_from_Partial_Input_CVPR_2024_paper.html": {
    "title": "MaskPLAN: Masked Generative Layout Planning from Partial Input",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Zhang",
      "Anton Savov",
      "Benjamin Dillenburger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_Benchmarking_the_Robustness_of_Temporal_Action_Detection_Models_Against_Temporal_CVPR_2024_paper.html": {
    "title": "Benchmarking the Robustness of Temporal Action Detection Models Against Temporal Corruptions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runhao Zeng",
      "Xiaoyong Chen",
      "Jiaming Liang",
      "Huisi Wu",
      "Guangzhong Cao",
      "Yong Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Open-World_Human-Object_Interaction_Detection_via_Multi-modal_Prompts_CVPR_2024_paper.html": {
    "title": "Open-World Human-Object Interaction Detection via Multi-modal Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Yang",
      "Bingliang Li",
      "Ailing Zeng",
      "Lei Zhang",
      "Ruimao Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dai_HMD-Poser_On-Device_Real-time_Human_Motion_Tracking_from_Scalable_Sparse_Observations_CVPR_2024_paper.html": {
    "title": "HMD-Poser: On-Device Real-time Human Motion Tracking from Scalable Sparse Observations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Dai",
      "Yang Zhang",
      "Tao Liu",
      "Zhen Fan",
      "Tianyuan Du",
      "Zhuo Su",
      "Xiaozheng Zheng",
      "Zeming Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_UniMODE_Unified_Monocular_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "UniMODE: Unified Monocular 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoling Li",
      "Xiaogang Xu",
      "SerNam Lim",
      "Hengshuang Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Sherpa3D_Boosting_High-Fidelity_Text-to-3D_Generation_via_Coarse_3D_Prior_CVPR_2024_paper.html": {
    "title": "Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangfu Liu",
      "Diankun Wu",
      "Yi Wei",
      "Yongming Rao",
      "Yueqi Duan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tiong_Flexible_Biometrics_Recognition_Bridging_the_Multimodality_Gap_through_Attention_Alignment_CVPR_2024_paper.html": {
    "title": "Flexible Biometrics Recognition: Bridging the Multimodality Gap through Attention Alignment and Prompt Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leslie Ching Ow Tiong",
      "Dick Sigmund",
      "Chen-Hui Chan",
      "Andrew Beng Jin Teoh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_Multi-agent_Collaborative_Perception_via_Motion-aware_Robust_Communication_Network_CVPR_2024_paper.html": {
    "title": "Multi-agent Collaborative Perception via Motion-aware Robust Communication Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shixin Hong",
      "Yu Liu",
      "Zhi Li",
      "Shaohui Li",
      "You He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sachdeva_The_Manga_Whisperer_Automatically_Generating_Transcriptions_for_Comics_CVPR_2024_paper.html": {
    "title": "The Manga Whisperer: Automatically Generating Transcriptions for Comics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ragav Sachdeva",
      "Andrew Zisserman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Exploring_Region-Word_Alignment_in_Built-in_Detector_for_Open-Vocabulary_Object_Detection_CVPR_2024_paper.html": {
    "title": "Exploring Region-Word Alignment in Built-in Detector for Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heng Zhang",
      "Qiuyu Zhao",
      "Linyu Zheng",
      "Hao Zeng",
      "Zhiwei Ge",
      "Tianhao Li",
      "Sulong Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_MovieChat_From_Dense_Token_to_Sparse_Memory_for_Long_Video_CVPR_2024_paper.html": {
    "title": "MovieChat: From Dense Token to Sparse Memory for Long Video Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enxin Song",
      "Wenhao Chai",
      "Guanhong Wang",
      "Yucheng Zhang",
      "Haoyang Zhou",
      "Feiyang Wu",
      "Haozhe Chi",
      "Xun Guo",
      "Tian Ye",
      "Yanting Zhang",
      "Yan Lu",
      "Jenq-Neng Hwang",
      "Gaoang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Comparing_the_Decision-Making_Mechanisms_by_Transformers_and_CNNs_via_Explanation_CVPR_2024_paper.html": {
    "title": "Comparing the Decision-Making Mechanisms by Transformers and CNNs via Explanation Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingqi Jiang",
      "Saeed Khorram",
      "Li Fuxin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_A_Unified_Diffusion_Framework_for_Scene-aware_Human_Motion_Estimation_from_CVPR_2024_paper.html": {
    "title": "A Unified Diffusion Framework for Scene-aware Human Motion Estimation from Sparse Signals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangnan Tang",
      "Jingya Wang",
      "Kaiyang Ji",
      "Lan Xu",
      "Jingyi Yu",
      "Ye Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_Single_Domain_Generalization_for_Crowd_Counting_CVPR_2024_paper.html": {
    "title": "Single Domain Generalization for Crowd Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoxuan Peng",
      "S.-H. Gary Chan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Atlantis_Enabling_Underwater_Depth_Estimation_with_Stable_Diffusion_CVPR_2024_paper.html": {
    "title": "Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Zhang",
      "Shaodi You",
      "Yu Li",
      "Ying Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Matching_Anything_by_Segmenting_Anything_CVPR_2024_paper.html": {
    "title": "Matching Anything by Segmenting Anything",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Li",
      "Lei Ke",
      "Martin Danelljan",
      "Luigi Piccinelli",
      "Mattia Segu",
      "Luc Van Gool",
      "Fisher Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ge_Task-Aware_Encoder_Control_for_Deep_Video_Compression_CVPR_2024_paper.html": {
    "title": "Task-Aware Encoder Control for Deep Video Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingtong Ge",
      "Jixiang Luo",
      "Xinjie Zhang",
      "Tongda Xu",
      "Guo Lu",
      "Dailan He",
      "Jing Geng",
      "Yan Wang",
      "Jun Zhang",
      "Hongwei Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Multi-scale_Dynamic_and_Hierarchical_Relationship_Modeling_for_Facial_Action_Units_CVPR_2024_paper.html": {
    "title": "Multi-scale Dynamic and Hierarchical Relationship Modeling for Facial Action Units Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Wang",
      "Siyang Song",
      "Cheng Luo",
      "Songhe Deng",
      "Weicheng Xie",
      "Linlin Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Decoupled_Pseudo-labeling_for_Semi-Supervised_Monocular_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "Decoupled Pseudo-labeling for Semi-Supervised Monocular 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiacheng Zhang",
      "Jiaming Li",
      "Xiangru Lin",
      "Wei Zhang",
      "Xiao Tan",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang",
      "Guanbin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Temporally_Consistent_Unbalanced_Optimal_Transport_for_Unsupervised_Action_Segmentation_CVPR_2024_paper.html": {
    "title": "Temporally Consistent Unbalanced Optimal Transport for Unsupervised Action Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Xu",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Learning_Transferable_Negative_Prompts_for_Out-of-Distribution_Detection_CVPR_2024_paper.html": {
    "title": "Learning Transferable Negative Prompts for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianqi Li",
      "Guansong Pang",
      "Xiao Bai",
      "Wenjun Miao",
      "Jin Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Long-Tail_Class_Incremental_Learning_via_Independent_Sub-prototype_Construction_CVPR_2024_paper.html": {
    "title": "Long-Tail Class Incremental Learning via Independent Sub-prototype Construction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Wang",
      "Xu Yang",
      "Jie Yin",
      "Kun Wei",
      "Cheng Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Learning_with_Unreliability_Fast_Few-shot_Voxel_Radiance_Fields_with_Relative_CVPR_2024_paper.html": {
    "title": "Learning with Unreliability: Fast Few-shot Voxel Radiance Fields with Relative Geometric Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingjie Xu",
      "Bangzhen Liu",
      "Hao Tang",
      "Bailin Deng",
      "Shengfeng He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jain_Towards_Understanding_and_Improving_Adversarial_Robustness_of_Vision_Transformers_CVPR_2024_paper.html": {
    "title": "Towards Understanding and Improving Adversarial Robustness of Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samyak Jain",
      "Tanima Dutta"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Millerdurai_EventEgo3D_3D_Human_Motion_Capture_from_Egocentric_Event_Streams_CVPR_2024_paper.html": {
    "title": "EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christen Millerdurai",
      "Hiroyasu Akada",
      "Jian Wang",
      "Diogo Luvizon",
      "Christian Theobalt",
      "Vladislav Golyanik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tian_Holistic_Features_are_almost_Sufficient_for_Text-to-Video_Retrieval_CVPR_2024_paper.html": {
    "title": "Holistic Features are almost Sufficient for Text-to-Video Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaibin Tian",
      "Ruixiang Zhao",
      "Zijie Xin",
      "Bangxiang Lan",
      "Xirong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Paplham_A_Call_to_Reflect_on_Evaluation_Practices_for_Age_Estimation_CVPR_2024_paper.html": {
    "title": "A Call to Reflect on Evaluation Practices for Age Estimation: Comparative Analysis of the State-of-the-Art and a Unified Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jakub Paplhám",
      "Vojt?ch Franc"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_CosalPure_Learning_Concept_from_Group_Images_for_Robust_Co-Saliency_Detection_CVPR_2024_paper.html": {
    "title": "CosalPure: Learning Concept from Group Images for Robust Co-Saliency Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Zhu",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Yihao Huang",
      "Yang Liu",
      "Geguang Pu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Uncertainty-aware_Action_Decoupling_Transformer_for_Action_Anticipation_CVPR_2024_paper.html": {
    "title": "Uncertainty-aware Action Decoupling Transformer for Action Anticipation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongji Guo",
      "Nakul Agarwal",
      "Shao-Yuan Lo",
      "Kwonjoon Lee",
      "Qiang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Udupa_MRFP_Learning_Generalizable_Semantic_Segmentation_from_Sim-2-Real_with_Multi-Resolution_Feature_CVPR_2024_paper.html": {
    "title": "MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with Multi-Resolution Feature Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sumanth Udupa",
      "Prajwal Gurunath",
      "Aniruddh Sikdar",
      "Suresh Sundaram"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_S-DyRF_Reference-Based_Stylized_Radiance_Fields_for_Dynamic_Scenes_CVPR_2024_paper.html": {
    "title": "S-DyRF: Reference-Based Stylized Radiance Fields for Dynamic Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyi Li",
      "Zhiguo Cao",
      "Yizheng Wu",
      "Kewei Wang",
      "Ke Xian",
      "Zhe Wang",
      "Guosheng Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tu_MotionEditor_Editing_Video_Motion_via_Content-Aware_Diffusion_CVPR_2024_paper.html": {
    "title": "MotionEditor: Editing Video Motion via Content-Aware Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuyuan Tu",
      "Qi Dai",
      "Zhi-Qi Cheng",
      "Han Hu",
      "Xintong Han",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yoo_What_How_and_When_Should_Object_Detectors_Update_in_Continually_CVPR_2024_paper.html": {
    "title": "What How and When Should Object Detectors Update in Continually Changing Test Domains?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jayeon Yoo",
      "Dongkwan Lee",
      "Inseop Chung",
      "Donghyun Kim",
      "Nojun Kwak"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_One-Prompt_to_Segment_All_Medical_Images_CVPR_2024_paper.html": {
    "title": "One-Prompt to Segment All Medical Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junde Wu",
      "Min Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Miao_Bayesian_Exploration_of_Pre-trained_Models_for_Low-shot_Image_Classification_CVPR_2024_paper.html": {
    "title": "Bayesian Exploration of Pre-trained Models for Low-shot Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibo Miao",
      "Yu Lei",
      "Feng Zhou",
      "Zhijie Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_GROUNDHOG_Grounding_Large_Language_Models_to_Holistic_Segmentation_CVPR_2024_paper.html": {
    "title": "GROUNDHOG: Grounding Large Language Models to Holistic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichi Zhang",
      "Ziqiao Ma",
      "Xiaofeng Gao",
      "Suhaila Shakiah",
      "Qiaozi Gao",
      "Joyce Chai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Doubly_Abductive_Counterfactual_Inference_for_Text-based_Image_Editing_CVPR_2024_paper.html": {
    "title": "Doubly Abductive Counterfactual Inference for Text-based Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xue Song",
      "Jiequan Cui",
      "Hanwang Zhang",
      "Jingjing Chen",
      "Richang Hong",
      "Yu-Gang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Edstedt_RoMa_Robust_Dense_Feature_Matching_CVPR_2024_paper.html": {
    "title": "RoMa: Robust Dense Feature Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johan Edstedt",
      "Qiyu Sun",
      "Georg Bökman",
      "Mårten Wadenbäck",
      "Michael Felsberg"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Omni-SMoLA_Boosting_Generalist_Multimodal_Models_with_Soft_Mixture_of_Low-rank_CVPR_2024_paper.html": {
    "title": "Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialin Wu",
      "Xia Hu",
      "Yaqing Wang",
      "Bo Pang",
      "Radu Soricut"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Seidenschwarz_SeMoLi_What_Moves_Together_Belongs_Together_CVPR_2024_paper.html": {
    "title": "SeMoLi: What Moves Together Belongs Together",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jenny Seidenschwarz",
      "Aljosa Osep",
      "Francesco Ferroni",
      "Simon Lucey",
      "Laura Leal-Taixe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Geada_Insights_from_the_Use_of_Previously_Unseen_Neural_Architecture_Search_CVPR_2024_paper.html": {
    "title": "Insights from the Use of Previously Unseen Neural Architecture Search Datasets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rob Geada",
      "David Towers",
      "Matthew Forshaw",
      "Amir Atapour-Abarghouei",
      "A. Stephen McGough"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_Adversarially_Robust_Few-shot_Learning_via_Parameter_Co-distillation_of_Similarity_and_CVPR_2024_paper.html": {
    "title": "Adversarially Robust Few-shot Learning via Parameter Co-distillation of Similarity and Class Concept Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhao Dong",
      "Piotr Koniusz",
      "Junxi Chen",
      "Xiaohua Xie",
      "Yew-Soon Ong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_Context-Guided_Spatio-Temporal_Video_Grounding_CVPR_2024_paper.html": {
    "title": "Context-Guided Spatio-Temporal Video Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Gu",
      "Heng Fan",
      "Yan Huang",
      "Tiejian Luo",
      "Libo Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Padmanabhan_Explaining_the_Implicit_Neural_Canvas_Connecting_Pixels_to_Neurons_by_CVPR_2024_paper.html": {
    "title": "Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by Tracing their Contributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Namitha Padmanabhan",
      "Matthew Gwilliam",
      "Pulkit Kumar",
      "Shishira R Maiya",
      "Max Ehrlich",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_APISR_Anime_Production_Inspired_Real-World_Anime_Super-Resolution_CVPR_2024_paper.html": {
    "title": "APISR: Anime Production Inspired Real-World Anime Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyang Wang",
      "Fengyu Yang",
      "Xihang Yu",
      "Chao Zhang",
      "Hanbin Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Santo_MVCPS-NeuS_Multi-view_Constrained_Photometric_Stereo_for_Neural_Surface_Reconstruction_CVPR_2024_paper.html": {
    "title": "MVCPS-NeuS: Multi-view Constrained Photometric Stereo for Neural Surface Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hiroaki Santo",
      "Fumio Okura",
      "Yasuyuki Matsushita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_ULIP-2_Towards_Scalable_Multimodal_Pre-training_for_3D_Understanding_CVPR_2024_paper.html": {
    "title": "ULIP-2: Towards Scalable Multimodal Pre-training for 3D Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Le Xue",
      "Ning Yu",
      "Shu Zhang",
      "Artemis Panagopoulou",
      "Junnan Li",
      "Roberto Martín-Martín",
      "Jiajun Wu",
      "Caiming Xiong",
      "Ran Xu",
      "Juan Carlos Niebles",
      "Silvio Savarese"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dunkel_Normalizing_Flows_on_the_Product_Space_of_SO3_Manifolds_for_CVPR_2024_paper.html": {
    "title": "Normalizing Flows on the Product Space of SO(3) Manifolds for Probabilistic Human Pose Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Olaf Dünkel",
      "Tim Salzmann",
      "Florian Pfaff"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Adapting_to_Length_Shift_FlexiLength_Network_for_Trajectory_Prediction_CVPR_2024_paper.html": {
    "title": "Adapting to Length Shift: FlexiLength Network for Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Xu",
      "Yun Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_WorDepth_Variational_Language_Prior_for_Monocular_Depth_Estimation_CVPR_2024_paper.html": {
    "title": "WorDepth: Variational Language Prior for Monocular Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyao Zeng",
      "Daniel Wang",
      "Fengyu Yang",
      "Hyoungseob Park",
      "Stefano Soatto",
      "Dong Lao",
      "Alex Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_WaveMo_Learning_Wavefront_Modulations_to_See_Through_Scattering_CVPR_2024_paper.html": {
    "title": "WaveMo: Learning Wavefront Modulations to See Through Scattering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyang Xie",
      "Haiyun Guo",
      "Brandon Y. Feng",
      "Lingbo Jin",
      "Ashok Veeraraghavan",
      "Christopher A. Metzler"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_ReGenNet_Towards_Human_Action-Reaction_Synthesis_CVPR_2024_paper.html": {
    "title": "ReGenNet: Towards Human Action-Reaction Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Xu",
      "Yizhou Zhou",
      "Yichao Yan",
      "Xin Jin",
      "Wenhan Zhu",
      "Fengyun Rao",
      "Xiaokang Yang",
      "Wenjun Zeng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_A_Simple_Baseline_for_Efficient_Hand_Mesh_Reconstruction_CVPR_2024_paper.html": {
    "title": "A Simple Baseline for Efficient Hand Mesh Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhishan Zhou",
      "Shihao Zhou",
      "Zhi Lv",
      "Minqiang Zou",
      "Yao Tang",
      "Jiajun Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Le_Integrating_Efficient_Optimal_Transport_and_Functional_Maps_For_Unsupervised_Shape_CVPR_2024_paper.html": {
    "title": "Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tung Le",
      "Khai Nguyen",
      "Shanlin Sun",
      "Nhat Ho",
      "Xiaohui Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_PhotoMaker_Customizing_Realistic_Human_Photos_via_Stacked_ID_Embedding_CVPR_2024_paper.html": {
    "title": "PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Li",
      "Mingdeng Cao",
      "Xintao Wang",
      "Zhongang Qi",
      "Ming-Ming Cheng",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Stathopoulos_Score-Guided_Diffusion_for_3D_Human_Recovery_CVPR_2024_paper.html": {
    "title": "Score-Guided Diffusion for 3D Human Recovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anastasis Stathopoulos",
      "Ligong Han",
      "Dimitris Metaxas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_Check_Locate_Rectify_A_Training-Free_Layout_Calibration_System_for_Text-to-Image_CVPR_2024_paper.html": {
    "title": "Check Locate Rectify: A Training-Free Layout Calibration System for Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Biao Gong",
      "Siteng Huang",
      "Yutong Feng",
      "Shiwei Zhang",
      "Yuyuan Li",
      "Yu Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_ODCR_Orthogonal_Decoupling_Contrastive_Regularization_for_Unpaired_Image_Dehazing_CVPR_2024_paper.html": {
    "title": "ODCR: Orthogonal Decoupling Contrastive Regularization for Unpaired Image Dehazing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongze Wang",
      "Haitao Zhao",
      "Jingchao Peng",
      "Lujian Yao",
      "Kaijie Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Pose-Transformed_Equivariant_Network_for_3D_Point_Trajectory_Prediction_CVPR_2024_paper.html": {
    "title": "Pose-Transformed Equivariant Network for 3D Point Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruixuan Yu",
      "Jian Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ying_OmniSeg3D_Omniversal_3D_Segmentation_via_Hierarchical_Contrastive_Learning_CVPR_2024_paper.html": {
    "title": "OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiyang Ying",
      "Yixuan Yin",
      "Jinzhi Zhang",
      "Fan Wang",
      "Tao Yu",
      "Ruqi Huang",
      "Lu Fang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rydell_Revisiting_Sampson_Approximations_for_Geometric_Estimation_Problems_CVPR_2024_paper.html": {
    "title": "Revisiting Sampson Approximations for Geometric Estimation Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Rydell",
      "Angélica Torres",
      "Viktor Larsson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bai_Fixed_Point_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Fixed Point Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingjian Bai",
      "Luke Melas-Kyriazi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Simple_Semantic-Aided_Few-Shot_Learning_CVPR_2024_paper.html": {
    "title": "Simple Semantic-Aided Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Zhang",
      "Junzhe Xu",
      "Shanlin Jiang",
      "Zhenan He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_A_Unified_Framework_for_Microscopy_Defocus_Deblur_with_Multi-Pyramid_Transformer_CVPR_2024_paper.html": {
    "title": "A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuelin Zhang",
      "Pengyu Zheng",
      "Wanquan Yan",
      "Chengyu Fang",
      "Shing Shin Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bar_Frozen_Feature_Augmentation_for_Few-Shot_Image_Classification_CVPR_2024_paper.html": {
    "title": "Frozen Feature Augmentation for Few-Shot Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Bär",
      "Neil Houlsby",
      "Mostafa Dehghani",
      "Manoj Kumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Residual_Learning_in_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Residual Learning in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyu Zhang",
      "Daochang Liu",
      "Eunbyung Park",
      "Shichao Zhang",
      "Chang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yi_Leveraging_Cross-Modal_Neighbor_Representation_for_Improved_CLIP_Classification_CVPR_2024_paper.html": {
    "title": "Leveraging Cross-Modal Neighbor Representation for Improved CLIP Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Yi",
      "Lu Ren",
      "De-Chuan Zhan",
      "Han-Jia Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Beyond_Textual_Constraints_Learning_Novel_Diffusion_Conditions_with_Fewer_Examples_CVPR_2024_paper.html": {
    "title": "Beyond Textual Constraints: Learning Novel Diffusion Conditions with Fewer Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyang Yu",
      "Bangzhen Liu",
      "Chenxi Zheng",
      "Xuemiao Xu",
      "Huaidong Zhang",
      "Shengfeng He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Buettner_Incorporating_Geo-Diverse_Knowledge_into_Prompting_for_Increased_Geographical_Robustness_in_CVPR_2024_paper.html": {
    "title": "Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyle Buettner",
      "Sina Malakouti",
      "Xiang Lorraine Li",
      "Adriana Kovashka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yue_Revisiting_Adversarial_Training_Under_Long-Tailed_Distributions_CVPR_2024_paper.html": {
    "title": "Revisiting Adversarial Training Under Long-Tailed Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinli Yue",
      "Ningping Mou",
      "Qian Wang",
      "Lingchen Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_Exploiting_Style_Latent_Flows_for_Generalizing_Deepfake_Video_Detection_CVPR_2024_paper.html": {
    "title": "Exploiting Style Latent Flows for Generalizing Deepfake Video Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongwook Choi",
      "Taehoon Kim",
      "Yonghyun Jeong",
      "Seungryul Baek",
      "Jongwon Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dorkenwald_PIN_Positional_Insert_Unlocks_Object_Localisation_Abilities_in_VLMs_CVPR_2024_paper.html": {
    "title": "PIN: Positional Insert Unlocks Object Localisation Abilities in VLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Dorkenwald",
      "Nimrod Barazani",
      "Cees G. M. Snoek",
      "Yuki M. Asano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_UniGarmentManip_A_Unified_Framework_for_Category-Level_Garment_Manipulation_via_Dense_CVPR_2024_paper.html": {
    "title": "UniGarmentManip: A Unified Framework for Category-Level Garment Manipulation via Dense Visual Correspondence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruihai Wu",
      "Haoran Lu",
      "Yiyan Wang",
      "Yubo Wang",
      "Hao Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Multi-Attribute_Interactions_Matter_for_3D_Visual_Grounding_CVPR_2024_paper.html": {
    "title": "Multi-Attribute Interactions Matter for 3D Visual Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Can Xu",
      "Yuehui Han",
      "Rui Xu",
      "Le Hui",
      "Jin Xie",
      "Jian Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Video-P2P_Video_Editing_with_Cross-attention_Control_CVPR_2024_paper.html": {
    "title": "Video-P2P: Video Editing with Cross-attention Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaoteng Liu",
      "Yuechen Zhang",
      "Wenbo Li",
      "Zhe Lin",
      "Jiaya Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Hunting_Attributes_Context_Prototype-Aware_Learning_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Hunting Attributes: Context Prototype-Aware Learning for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feilong Tang",
      "Zhongxing Xu",
      "Zhaojun Qu",
      "Wei Feng",
      "Xingjian Jiang",
      "Zongyuan Ge"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SCINeRF_Neural_Radiance_Fields_from_a_Snapshot_Compressive_Image_CVPR_2024_paper.html": {
    "title": "SCINeRF: Neural Radiance Fields from a Snapshot Compressive Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhao Li",
      "Xiaodong Wang",
      "Ping Wang",
      "Xin Yuan",
      "Peidong Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_PIE-NeRF_Physics-based_Interactive_Elastodynamics_with_NeRF_CVPR_2024_paper.html": {
    "title": "PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutao Feng",
      "Yintong Shang",
      "Xuan Li",
      "Tianjia Shao",
      "Chenfanfu Jiang",
      "Yin Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Improved_Visual_Grounding_through_Self-Consistent_Explanations_CVPR_2024_paper.html": {
    "title": "Improved Visual Grounding through Self-Consistent Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruozhen He",
      "Paola Cascante-Bonilla",
      "Ziyan Yang",
      "Alexander C. Berg",
      "Vicente Ordonez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Monkey_Image_Resolution_and_Text_Label_Are_Important_Things_for_CVPR_2024_paper.html": {
    "title": "Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhang Li",
      "Biao Yang",
      "Qiang Liu",
      "Zhiyin Ma",
      "Shuo Zhang",
      "Jingxu Yang",
      "Yabo Sun",
      "Yuliang Liu",
      "Xiang Bai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiang_FlashAvatar_High-fidelity_Head_Avatar_with_Efficient_Gaussian_Embedding_CVPR_2024_paper.html": {
    "title": "FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Xiang",
      "Xuan Gao",
      "Yudong Guo",
      "Juyong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_DifFlow3D_Toward_Robust_Uncertainty-Aware_Scene_Flow_Estimation_with_Iterative_Diffusion-Based_CVPR_2024_paper.html": {
    "title": "DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with Iterative Diffusion-Based Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiuming Liu",
      "Guangming Wang",
      "Weicai Ye",
      "Chaokang Jiang",
      "Jinru Han",
      "Zhe Liu",
      "Guofeng Zhang",
      "Dalong Du",
      "Hesheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Noohdani_Decompose-and-Compose_A_Compositional_Approach_to_Mitigating_Spurious_Correlation_CVPR_2024_paper.html": {
    "title": "Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fahimeh Hosseini Noohdani",
      "Parsa Hosseini",
      "Aryan Yazdan Parast",
      "Hamidreza Yaghoubi Araghi",
      "Mahdieh Soleymani Baghshah"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_FlashEval_Towards_Fast_and_Accurate_Evaluation_of_Text-to-image_Diffusion_Generative_CVPR_2024_paper.html": {
    "title": "FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Zhao",
      "Tianchen Zhao",
      "Zinan Lin",
      "Xuefei Ning",
      "Guohao Dai",
      "Huazhong Yang",
      "Yu Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_ZERO-IG_Zero-Shot_Illumination-Guided_Joint_Denoising_and_Adaptive_Enhancement_for_Low-Light_CVPR_2024_paper.html": {
    "title": "ZERO-IG: Zero-Shot Illumination-Guided Joint Denoising and Adaptive Enhancement for Low-Light Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqi Shi",
      "Duo Liu",
      "Liguo Zhang",
      "Ye Tian",
      "Xuezhi Xia",
      "Xiaojing Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_View_From_Above_Orthogonal-View_aware_Cross-view_Localization_CVPR_2024_paper.html": {
    "title": "View From Above: Orthogonal-View aware Cross-view Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shan Wang",
      "Chuong Nguyen",
      "Jiawei Liu",
      "Yanhao Zhang",
      "Sundaram Muthu",
      "Fahira Afzal Maken",
      "Kaihao Zhang",
      "Hongdong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_FinePOSE_Fine-Grained_Prompt-Driven_3D_Human_Pose_Estimation_via_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinglin Xu",
      "Yijie Guo",
      "Yuxin Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_BEM_Balanced_and_Entropy-based_Mix_for_Long-Tailed_Semi-Supervised_Learning_CVPR_2024_paper.html": {
    "title": "BEM: Balanced and Entropy-based Mix for Long-Tailed Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongwei Zheng",
      "Linyuan Zhou",
      "Han Li",
      "Jinming Su",
      "Xiaoming Wei",
      "Xiaoming Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_HUGS_Holistic_Urban_3D_Scene_Understanding_via_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyu Zhou",
      "Jiahao Shao",
      "Lu Xu",
      "Dongfeng Bai",
      "Weichao Qiu",
      "Bingbing Liu",
      "Yue Wang",
      "Andreas Geiger",
      "Yiyi Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_DreamPropeller_Supercharge_Text-to-3D_Generation_with_Parallel_Sampling_CVPR_2024_paper.html": {
    "title": "DreamPropeller: Supercharge Text-to-3D Generation with Parallel Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linqi Zhou",
      "Andy Shih",
      "Chenlin Meng",
      "Stefano Ermon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_PeVL_Pose-Enhanced_Vision-Language_Model_for_Fine-Grained_Human_Action_Recognition_CVPR_2024_paper.html": {
    "title": "PeVL: Pose-Enhanced Vision-Language Model for Fine-Grained Human Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haosong Zhang",
      "Mei Chee Leong",
      "Liyuan Li",
      "Weisi Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_DeepCache_Accelerating_Diffusion_Models_for_Free_CVPR_2024_paper.html": {
    "title": "DeepCache: Accelerating Diffusion Models for Free",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyin Ma",
      "Gongfan Fang",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_GeoAuxNet_Towards_Universal_3D_Representation_Learning_for_Multi-sensor_Point_Clouds_CVPR_2024_paper.html": {
    "title": "GeoAuxNet: Towards Universal 3D Representation Learning for Multi-sensor Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengjun Zhang",
      "Xin Fei",
      "Yueqi Duan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mo_Unveiling_the_Power_of_Audio-Visual_Early_Fusion_Transformers_with_Dense_CVPR_2024_paper.html": {
    "title": "Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shentong Mo",
      "Pedro Morgado"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Learning_Correlation_Structures_for_Vision_Transformers_CVPR_2024_paper.html": {
    "title": "Learning Correlation Structures for Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manjin Kim",
      "Paul Hongsuck Seo",
      "Cordelia Schmid",
      "Minsu Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fei_Dysen-VDM_Empowering_Dynamics-aware_Text-to-Video_Diffusion_with_LLMs_CVPR_2024_paper.html": {
    "title": "Dysen-VDM: Empowering Dynamics-aware Text-to-Video Diffusion with LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Fei",
      "Shengqiong Wu",
      "Wei Ji",
      "Hanwang Zhang",
      "Tat-Seng Chua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_PrPSeg_Universal_Proposition_Learning_for_Panoramic_Renal_Pathology_Segmentation_CVPR_2024_paper.html": {
    "title": "PrPSeg: Universal Proposition Learning for Panoramic Renal Pathology Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruining Deng",
      "Quan Liu",
      "Can Cui",
      "Tianyuan Yao",
      "Jialin Yue",
      "Juming Xiong",
      "Lining Yu",
      "Yifei Wu",
      "Mengmeng Yin",
      "Yu Wang",
      "Shilin Zhao",
      "Yucheng Tang",
      "Haichun Yang",
      "Yuankai Huo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rong_RepKPU_Point_Cloud_Upsampling_with_Kernel_Point_Representation_and_Deformation_CVPR_2024_paper.html": {
    "title": "RepKPU: Point Cloud Upsampling with Kernel Point Representation and Deformation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Rong",
      "Haoran Zhou",
      "Kang Xia",
      "Cheng Mei",
      "Jiahao Wang",
      "Tong Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rosasco_ConCon-Chi_Concept-Context_Chimera_Benchmark_for_Personalized_Vision-Language_Tasks_CVPR_2024_paper.html": {
    "title": "ConCon-Chi: Concept-Context Chimera Benchmark for Personalized Vision-Language Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Rosasco",
      "Stefano Berti",
      "Giulia Pasquale",
      "Damiano Malafronte",
      "Shogo Sato",
      "Hiroyuki Segawa",
      "Tetsugo Inada",
      "Lorenzo Natale"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rachavarapu_Weakly-Supervised_Audio-Visual_Video_Parsing_with_Prototype-based_Pseudo-Labeling_CVPR_2024_paper.html": {
    "title": "Weakly-Supervised Audio-Visual Video Parsing with Prototype-based Pseudo-Labeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kranthi Kumar Rachavarapu",
      "Kalyan Ramakrishnan",
      "Rajagopalan A. N."
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gopalakrishnan_Intraoperative_2D3D_Image_Registration_via_Differentiable_X-ray_Rendering_CVPR_2024_paper.html": {
    "title": "Intraoperative 2D/3D Image Registration via Differentiable X-ray Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vivek Gopalakrishnan",
      "Neel Dey",
      "Polina Golland"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Raajesh_MICap_A_Unified_Model_for_Identity-Aware_Movie_Descriptions_CVPR_2024_paper.html": {
    "title": "MICap: A Unified Model for Identity-Aware Movie Descriptions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haran Raajesh",
      "Naveen Reddy Desanur",
      "Zeeshan Khan",
      "Makarand Tapaswi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ranasinghe_MonoDiff_Monocular_3D_Object_Detection_and_Pose_Estimation_with_Diffusion_CVPR_2024_paper.html": {
    "title": "MonoDiff: Monocular 3D Object Detection and Pose Estimation with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasiru Ranasinghe",
      "Deepti Hegde",
      "Vishal M. Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_General_Object_Foundation_Model_for_Images_and_Videos_at_Scale_CVPR_2024_paper.html": {
    "title": "General Object Foundation Model for Images and Videos at Scale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junfeng Wu",
      "Yi Jiang",
      "Qihao Liu",
      "Zehuan Yuan",
      "Xiang Bai",
      "Song Bai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_An_Upload-Efficient_Scheme_for_Transferring_Knowledge_From_a_Server-Side_Pre-trained_CVPR_2024_paper.html": {
    "title": "An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side Pre-trained Generator to Clients in Heterogeneous Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianqing Zhang",
      "Yang Liu",
      "Yang Hua",
      "Jian Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Siddiqui_MeshGPT_Generating_Triangle_Meshes_with_Decoder-Only_Transformers_CVPR_2024_paper.html": {
    "title": "MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yawar Siddiqui",
      "Antonio Alliegro",
      "Alexey Artemov",
      "Tatiana Tommasi",
      "Daniele Sirigatti",
      "Vladislav Rosov",
      "Angela Dai",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Inlier_Confidence_Calibration_for_Point_Cloud_Registration_CVPR_2024_paper.html": {
    "title": "Inlier Confidence Calibration for Point Cloud Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongzhe Yuan",
      "Yue Wu",
      "Xiaolong Fan",
      "Maoguo Gong",
      "Qiguang Miao",
      "Wenping Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lei_Instance-aware_Exploration-Verification-Exploitation_for_Instance_ImageGoal_Navigation_CVPR_2024_paper.html": {
    "title": "Instance-aware Exploration-Verification-Exploitation for Instance ImageGoal Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohan Lei",
      "Min Wang",
      "Wengang Zhou",
      "Li Li",
      "Houqiang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_One-2-3-45_Fast_Single_Image_to_3D_Objects_with_Consistent_Multi-View_CVPR_2024_paper.html": {
    "title": "One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghua Liu",
      "Ruoxi Shi",
      "Linghao Chen",
      "Zhuoyang Zhang",
      "Chao Xu",
      "Xinyue Wei",
      "Hansheng Chen",
      "Chong Zeng",
      "Jiayuan Gu",
      "Hao Su"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Garber_Image_Restoration_by_Denoising_Diffusion_Models_with_Iteratively_Preconditioned_Guidance_CVPR_2024_paper.html": {
    "title": "Image Restoration by Denoising Diffusion Models with Iteratively Preconditioned Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tomer Garber",
      "Tom Tirer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhong_Lets_Think_Outside_the_Box_Exploring_Leap-of-Thought_in_Large_Language_CVPR_2024_paper.html": {
    "title": "Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanshan Zhong",
      "Zhongzhan Huang",
      "Shanghua Gao",
      "Wushao Wen",
      "Liang Lin",
      "Marinka Zitnik",
      "Pan Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Delitzas_SceneFun3D_Fine-Grained_Functionality_and_Affordance_Understanding_in_3D_Scenes_CVPR_2024_paper.html": {
    "title": "SceneFun3D: Fine-Grained Functionality and Affordance Understanding in 3D Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandros Delitzas",
      "Ayca Takmaz",
      "Federico Tombari",
      "Robert Sumner",
      "Marc Pollefeys",
      "Francis Engelmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Readout_Guidance_Learning_Control_from_Diffusion_Features_CVPR_2024_paper.html": {
    "title": "Readout Guidance: Learning Control from Diffusion Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Grace Luo",
      "Trevor Darrell",
      "Oliver Wang",
      "Dan B Goldman",
      "Aleksander Holynski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_A_Unified_Approach_for_Text-_and_Image-guided_4D_Scene_Generation_CVPR_2024_paper.html": {
    "title": "A Unified Approach for Text- and Image-guided 4D Scene Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufeng Zheng",
      "Xueting Li",
      "Koki Nagano",
      "Sifei Liu",
      "Otmar Hilliges",
      "Shalini De Mello"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_GaussianAvatar_Towards_Realistic_Human_Avatar_Modeling_from_a_Single_Video_CVPR_2024_paper.html": {
    "title": "GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liangxiao Hu",
      "Hongwen Zhang",
      "Yuxiang Zhang",
      "Boyao Zhou",
      "Boning Liu",
      "Shengping Zhang",
      "Liqiang Nie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Woo_MTMMC_A_Large-Scale_Real-World_Multi-Modal_Camera_Tracking_Benchmark_CVPR_2024_paper.html": {
    "title": "MTMMC: A Large-Scale Real-World Multi-Modal Camera Tracking Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanghyun Woo",
      "Kwanyong Park",
      "Inkyu Shin",
      "Myungchul Kim",
      "In So Kweon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Enhanced_Motion-Text_Alignment_for_Image-to-Video_Transfer_Learning_CVPR_2024_paper.html": {
    "title": "Enhanced Motion-Text Alignment for Image-to-Video Transfer Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhang",
      "Chaoqun Wan",
      "Tongliang Liu",
      "Xinmei Tian",
      "Xu Shen",
      "Jieping Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guesmi_DAP_A_Dynamic_Adversarial_Patch_for_Evading_Person_Detectors_CVPR_2024_paper.html": {
    "title": "DAP: A Dynamic Adversarial Patch for Evading Person Detectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amira Guesmi",
      "Ruitian Ding",
      "Muhammad Abdullah Hanif",
      "Ihsen Alouani",
      "Muhammad Shafique"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Learned_Lossless_Image_Compression_based_on_Bit_Plane_Slicing_CVPR_2024_paper.html": {
    "title": "Learned Lossless Image Compression based on Bit Plane Slicing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Zhang",
      "Huairui Wang",
      "Zhenzhong Chen",
      "Shan Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_UV-IDM_Identity-Conditioned_Latent_Diffusion_Model_for_Face_UV-Texture_Generation_CVPR_2024_paper.html": {
    "title": "UV-IDM: Identity-Conditioned Latent Diffusion Model for Face UV-Texture Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Li",
      "Yutang Feng",
      "Song Xue",
      "Xuhui Liu",
      "Bohan Zeng",
      "Shanglin Li",
      "Boyu Liu",
      "Jianzhuang Liu",
      "Shumin Han",
      "Baochang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yariv_Mosaic-SDF_for_3D_Generative_Models_CVPR_2024_paper.html": {
    "title": "Mosaic-SDF for 3D Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lior Yariv",
      "Omri Puny",
      "Oran Gafni",
      "Yaron Lipman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pandey_Diffusion_Handles_Enabling_3D_Edits_for_Diffusion_Models_by_Lifting_CVPR_2024_paper.html": {
    "title": "Diffusion Handles Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karran Pandey",
      "Paul Guerrero",
      "Matheus Gadelha",
      "Yannick Hold-Geoffroy",
      "Karan Singh",
      "Niloy J. Mitra"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_A_Pedestrian_is_Worth_One_Prompt_Towards_Language_Guidance_Person_CVPR_2024_paper.html": {
    "title": "A Pedestrian is Worth One Prompt: Towards Language Guidance Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zexian Yang",
      "Dayan Wu",
      "Chenming Wu",
      "Zheng Lin",
      "Jingzi Gu",
      "Weiping Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Friendly_Sharpness-Aware_Minimization_CVPR_2024_paper.html": {
    "title": "Friendly Sharpness-Aware Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Li",
      "Pan Zhou",
      "Zhengbao He",
      "Xinwen Cheng",
      "Xiaolin Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_BIVDiff_A_Training-Free_Framework_for_General-Purpose_Video_Synthesis_via_Bridging_CVPR_2024_paper.html": {
    "title": "BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengyuan Shi",
      "Jiaxi Gu",
      "Hang Xu",
      "Songcen Xu",
      "Wei Zhang",
      "Limin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Osowiechi_NC-TTT_A_Noise_Constrastive_Approach_for_Test-Time_Training_CVPR_2024_paper.html": {
    "title": "NC-TTT: A Noise Constrastive Approach for Test-Time Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Osowiechi",
      "Gustavo A. Vargas Hakim",
      "Mehrdad Noori",
      "Milad Cheraghalikhani",
      "Ali Bahri",
      "Moslem Yazdanpanah",
      "Ismail Ben Ayed",
      "Christian Desrosiers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_NetTrack_Tracking_Highly_Dynamic_Objects_with_a_Net_CVPR_2024_paper.html": {
    "title": "NetTrack: Tracking Highly Dynamic Objects with a Net",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangze Zheng",
      "Shijie Lin",
      "Haobo Zuo",
      "Changhong Fu",
      "Jia Pan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Di_Grounded_Question-Answering_in_Long_Egocentric_Videos_CVPR_2024_paper.html": {
    "title": "Grounded Question-Answering in Long Egocentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangzhe Di",
      "Weidi Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_HPNet_Dynamic_Trajectory_Forecasting_with_Historical_Prediction_Attention_CVPR_2024_paper.html": {
    "title": "HPNet: Dynamic Trajectory Forecasting with Historical Prediction Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaolong Tang",
      "Meina Kan",
      "Shiguang Shan",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Xilin Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Flexible_Depth_Completion_for_Sparse_and_Varying_Point_Densities_CVPR_2024_paper.html": {
    "title": "Flexible Depth Completion for Sparse and Varying Point Densities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinhyung Park",
      "Yu-Jhe Li",
      "Kris Kitani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Small_Scale_Data-Free_Knowledge_Distillation_CVPR_2024_paper.html": {
    "title": "Small Scale Data-Free Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Liu",
      "Yikai Wang",
      "Huaping Liu",
      "Fuchun Sun",
      "Anbang Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sarkar_Shadows_Dont_Lie_and_Lines_Cant_Bend_Generative_Models_dont_CVPR_2024_paper.html": {
    "title": "Shadows Don't Lie and Lines Can't Bend! Generative Models don't know Projective Geometry...for now",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayush Sarkar",
      "Hanlin Mai",
      "Amitabh Mahapatra",
      "Svetlana Lazebnik",
      "D.A. Forsyth",
      "Anand Bhattad"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_CFPL-FAS_Class_Free_Prompt_Learning_for_Generalizable_Face_Anti-spoofing_CVPR_2024_paper.html": {
    "title": "CFPL-FAS: Class Free Prompt Learning for Generalizable Face Anti-spoofing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ajian Liu",
      "Shuai Xue",
      "Jianwen Gan",
      "Jun Wan",
      "Yanyan Liang",
      "Jiankang Deng",
      "Sergio Escalera",
      "Zhen Lei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kapse_SI-MIL_Taming_Deep_MIL_for_Self-Interpretability_in_Gigapixel_Histopathology_CVPR_2024_paper.html": {
    "title": "SI-MIL: Taming Deep MIL for Self-Interpretability in Gigapixel Histopathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saarthak Kapse",
      "Pushpak Pati",
      "Srijan Das",
      "Jingwei Zhang",
      "Chao Chen",
      "Maria Vakalopoulou",
      "Joel Saltz",
      "Dimitris Samaras",
      "Rajarsi R. Gupta",
      "Prateek Prasanna"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_GEARS_Local_Geometry-aware_Hand-object_Interaction_Synthesis_CVPR_2024_paper.html": {
    "title": "GEARS: Local Geometry-aware Hand-object Interaction Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyang Zhou",
      "Bharat Lal Bhatnagar",
      "Jan Eric Lenssen",
      "Gerard Pons-Moll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bourouis_Open_Vocabulary_Semantic_Scene_Sketch_Understanding_CVPR_2024_paper.html": {
    "title": "Open Vocabulary Semantic Scene Sketch Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Bourouis",
      "Judith E. Fan",
      "Yulia Gryaditskaya"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_IntrinsicAvatar_Physically_Based_Inverse_Rendering_of_Dynamic_Humans_from_Monocular_CVPR_2024_paper.html": {
    "title": "IntrinsicAvatar: Physically Based Inverse Rendering of Dynamic Humans from Monocular Videos via Explicit Ray Tracing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaofei Wang",
      "Bozidar Antic",
      "Andreas Geiger",
      "Siyu Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Efficient_Detection_of_Long_Consistent_Cycles_and_its_Application_to_CVPR_2024_paper.html": {
    "title": "Efficient Detection of Long Consistent Cycles and its Application to Distributed Synchronization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaohan Li",
      "Yunpeng Shi",
      "Gilad Lerman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_LayoutFormer_Hierarchical_Text_Detection_Towards_Scene_Text_Understanding_CVPR_2024_paper.html": {
    "title": "LayoutFormer: Hierarchical Text Detection Towards Scene Text Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Liang",
      "Jia-Wei Ma",
      "Xiaobin Zhu",
      "Jingyan Qin",
      "Xu-Cheng Yin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhuang_Vlogger_Make_Your_Dream_A_Vlog_CVPR_2024_paper.html": {
    "title": "Vlogger: Make Your Dream A Vlog",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaobin Zhuang",
      "Kunchang Li",
      "Xinyuan Chen",
      "Yaohui Wang",
      "Ziwei Liu",
      "Yu Qiao",
      "Yali Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shah_CodedEvents_Optimal_Point-Spread-Function_Engineering_for_3D-Tracking_with_Event_Cameras_CVPR_2024_paper.html": {
    "title": "CodedEvents: Optimal Point-Spread-Function Engineering for 3D-Tracking with Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sachin Shah",
      "Matthew A. Chan",
      "Haoming Cai",
      "Jingxi Chen",
      "Sakshum Kulshrestha",
      "Chahat Deep Singh",
      "Yiannis Aloimonos",
      "Christopher A. Metzler"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bao_GLOW_Global_Layout_Aware_Attacks_on_Object_Detection_CVPR_2024_paper.html": {
    "title": "GLOW: Global Layout Aware Attacks on Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Bao",
      "Buyu Liu",
      "Kui Ren",
      "Jun Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Learning_Discriminative_Dynamics_with_Label_Corruption_for_Noisy_Label_Detection_CVPR_2024_paper.html": {
    "title": "Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suyeon Kim",
      "Dongha Lee",
      "SeongKu Kang",
      "Sukang Chae",
      "Sanghwan Jang",
      "Hwanjo Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Duan_Neural_3D_Strokes_Creating_Stylized_3D_Scenes_with_Vectorized_3D_CVPR_2024_paper.html": {
    "title": "Neural 3D Strokes: Creating Stylized 3D Scenes with Vectorized 3D Strokes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao-Bin Duan",
      "Miao Wang",
      "Yan-Xun Li",
      "Yong-Liang Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yataka_SIRA_Scalable_Inter-frame_Relation_and_Association_for_Radar_Perception_CVPR_2024_paper.html": {
    "title": "SIRA: Scalable Inter-frame Relation and Association for Radar Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryoma Yataka",
      "Pu Wang",
      "Petros Boufounos",
      "Ryuhei Takahashi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tran_VOODOO_3D_Volumetric_Portrait_Disentanglement_For_One-Shot_3D_Head_Reenactment_CVPR_2024_paper.html": {
    "title": "VOODOO 3D: Volumetric Portrait Disentanglement For One-Shot 3D Head Reenactment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phong Tran",
      "Egor Zakharov",
      "Long-Nhat Ho",
      "Anh Tuan Tran",
      "Liwen Hu",
      "Hao Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ge_Visual_Fact_Checker_Enabling_High-Fidelity_Detailed_Caption_Generation_CVPR_2024_paper.html": {
    "title": "Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhao Ge",
      "Xiaohui Zeng",
      "Jacob Samuel Huffman",
      "Tsung-Yi Lin",
      "Ming-Yu Liu",
      "Yin Cui"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Communication-Efficient_Collaborative_Perception_via_Information_Filling_with_Codebook_CVPR_2024_paper.html": {
    "title": "Communication-Efficient Collaborative Perception via Information Filling with Codebook",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Hu",
      "Juntong Peng",
      "Sifei Liu",
      "Junhao Ge",
      "Si Liu",
      "Siheng Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bai_DiPrompT_Disentangled_Prompt_Tuning_for_Multiple_Latent_Domain_Generalization_in_CVPR_2024_paper.html": {
    "title": "DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sikai Bai",
      "Jie Zhang",
      "Song Guo",
      "Shuaicheng Li",
      "Jingcai Guo",
      "Jun Hou",
      "Tao Han",
      "Xiaocheng Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_MVD-Fusion_Single-view_3D_via_Depth-consistent_Multi-view_Generation_CVPR_2024_paper.html": {
    "title": "MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanzhe Hu",
      "Zhizhuo Zhou",
      "Varun Jampani",
      "Shubham Tulsiani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Warren_Effective_Video_Mirror_Detection_with_Inconsistent_Motion_Cues_CVPR_2024_paper.html": {
    "title": "Effective Video Mirror Detection with Inconsistent Motion Cues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Warren",
      "Ke Xu",
      "Jiaying Lin",
      "Gary K.L. Tam",
      "Rynson W.H. Lau"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Multi-Object_Tracking_in_the_Dark_CVPR_2024_paper.html": {
    "title": "Multi-Object Tracking in the Dark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinzhe Wang",
      "Kang Ma",
      "Qiankun Liu",
      "Yunhao Zou",
      "Ying Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_UniHuman_A_Unified_Model_For_Editing_Human_Images_in_the_CVPR_2024_paper.html": {
    "title": "UniHuman: A Unified Model For Editing Human Images in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nannan Li",
      "Qing Liu",
      "Krishna Kumar Singh",
      "Yilin Wang",
      "Jianming Zhang",
      "Bryan A. Plummer",
      "Zhe Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_DiffAgent_Fast_and_Accurate_Text-to-Image_API_Selection_with_Large_Language_CVPR_2024_paper.html": {
    "title": "DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lirui Zhao",
      "Yue Yang",
      "Kaipeng Zhang",
      "Wenqi Shao",
      "Yuxin Zhang",
      "Yu Qiao",
      "Ping Luo",
      "Rongrong Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Seo_In_Search_of_a_Data_Transformation_That_Accelerates_Neural_Field_CVPR_2024_paper.html": {
    "title": "In Search of a Data Transformation That Accelerates Neural Field Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwon Seo",
      "Sangyoon Lee",
      "Kwang In Kim",
      "Jaeho Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ohanyan_Zero-Painter_Training-Free_Layout_Control_for_Text-to-Image_Synthesis_CVPR_2024_paper.html": {
    "title": "Zero-Painter: Training-Free Layout Control for Text-to-Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marianna Ohanyan",
      "Hayk Manukyan",
      "Zhangyang Wang",
      "Shant Navasardyan",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_DiffLoc_Diffusion_Model_for_Outdoor_LiDAR_Localization_CVPR_2024_paper.html": {
    "title": "DiffLoc: Diffusion Model for Outdoor LiDAR Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Li",
      "Yuyang Yang",
      "Shangshu Yu",
      "Guosheng Hu",
      "Chenglu Wen",
      "Ming Cheng",
      "Cheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mu_Towards_3D_Vision_with_Low-Cost_Single-Photon_Cameras_CVPR_2024_paper.html": {
    "title": "Towards 3D Vision with Low-Cost Single-Photon Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangzhou Mu",
      "Carter Sifferman",
      "Sacha Jungerman",
      "Yiquan Li",
      "Mark Han",
      "Michael Gleicher",
      "Mohit Gupta",
      "Yin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_WonderJourney_Going_from_Anywhere_to_Everywhere_CVPR_2024_paper.html": {
    "title": "WonderJourney: Going from Anywhere to Everywhere",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong-Xing Yu",
      "Haoyi Duan",
      "Junhwa Hur",
      "Kyle Sargent",
      "Michael Rubinstein",
      "William T. Freeman",
      "Forrester Cole",
      "Deqing Sun",
      "Noah Snavely",
      "Jiajun Wu",
      "Charles Herrmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_On_Scaling_Up_a_Multilingual_Vision_and_Language_Model_CVPR_2024_paper.html": {
    "title": "On Scaling Up a Multilingual Vision and Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Chen",
      "Josip Djolonga",
      "Piotr Padlewski",
      "Basil Mustafa",
      "Soravit Changpinyo",
      "Jialin Wu",
      "Carlos Riquelme Ruiz",
      "Sebastian Goodman",
      "Xiao Wang",
      "Yi Tay",
      "Siamak Shakeri",
      "Mostafa Dehghani",
      "Daniel Salz",
      "Mario Lucic",
      "Michael Tschannen",
      "Arsha Nagrani",
      "Hexiang Hu",
      "Mandar Joshi",
      "Bo Pang",
      "Ceslee Montgomery",
      "Paulina Pietrzyk",
      "Marvin Ritter",
      "AJ Piergiovanni",
      "Matthias Minderer",
      "Filip Pavetic",
      "Austin Waters",
      "Gang Li",
      "Ibrahim Alabdulmohsin",
      "Lucas Beyer",
      "Julien Amelot",
      "Kenton Lee",
      "Andreas Peter Steiner",
      "Yang Li",
      "Daniel Keysers",
      "Anurag Arnab",
      "Yuanzhong Xu",
      "Keran Rong",
      "Alexander Kolesnikov",
      "Mojtaba Seyedhosseini",
      "Anelia Angelova",
      "Xiaohua Zhai",
      "Neil Houlsby",
      "Radu Soricut"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Day-Night_Cross-domain_Vehicle_Re-identification_CVPR_2024_paper.html": {
    "title": "Day-Night Cross-domain Vehicle Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongchao Li",
      "Jingong Chen",
      "Aihua Zheng",
      "Yong Wu",
      "Yonglong Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bahmani_4D-fy_Text-to-4D_Generation_Using_Hybrid_Score_Distillation_Sampling_CVPR_2024_paper.html": {
    "title": "4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sherwin Bahmani",
      "Ivan Skorokhodov",
      "Victor Rong",
      "Gordon Wetzstein",
      "Leonidas Guibas",
      "Peter Wonka",
      "Sergey Tulyakov",
      "Jeong Joon Park",
      "Andrea Tagliasacchi",
      "David B. Lindell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_Adversarial_Distillation_Based_on_Slack_Matching_and_Attribution_Region_Alignment_CVPR_2024_paper.html": {
    "title": "Adversarial Distillation Based on Slack Matching and Attribution Region Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenglin Yin",
      "Zhen Xiao",
      "Mingxuan Song",
      "Jieyi Long"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Boosting_Spike_Camera_Image_Reconstruction_from_a_Perspective_of_Dealing_CVPR_2024_paper.html": {
    "title": "Boosting Spike Camera Image Reconstruction from a Perspective of Dealing with Spike Fluctuations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Zhao",
      "Ruiqin Xiong",
      "Jing Zhao",
      "Jian Zhang",
      "Xiaopeng Fan",
      "Zhaofei Yu",
      "Tiejun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gandikota_Text-guided_Explorable_Image_Super-resolution_CVPR_2024_paper.html": {
    "title": "Text-guided Explorable Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kanchana Vaishnavi Gandikota",
      "Paramanand Chandramouli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mo_FreeControl_Training-Free_Spatial_Control_of_Any_Text-to-Image_Diffusion_Model_with_CVPR_2024_paper.html": {
    "title": "FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sicheng Mo",
      "Fangzhou Mu",
      "Kuan Heng Lin",
      "Yanli Liu",
      "Bochen Guan",
      "Yin Li",
      "Bolei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jeong_VMC_Video_Motion_Customization_using_Temporal_Attention_Adaption_for_Text-to-Video_CVPR_2024_paper.html": {
    "title": "VMC: Video Motion Customization using Temporal Attention Adaption for Text-to-Video Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeonho Jeong",
      "Geon Yeong Park",
      "Jong Chul Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Holodeck_Language_Guided_Generation_of_3D_Embodied_AI_Environments_CVPR_2024_paper.html": {
    "title": "Holodeck: Language Guided Generation of 3D Embodied AI Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Yang",
      "Fan-Yun Sun",
      "Luca Weihs",
      "Eli VanderBilt",
      "Alvaro Herrasti",
      "Winson Han",
      "Jiajun Wu",
      "Nick Haber",
      "Ranjay Krishna",
      "Lingjie Liu",
      "Chris Callison-Burch",
      "Mark Yatskar",
      "Aniruddha Kembhavi",
      "Christopher Clark"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Distilled_Datamodel_with_Reverse_Gradient_Matching_CVPR_2024_paper.html": {
    "title": "Distilled Datamodel with Reverse Gradient Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingwen Ye",
      "Ruonan Yu",
      "Songhua Liu",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_DistriFusion_Distributed_Parallel_Inference_for_High-Resolution_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muyang Li",
      "Tianle Cai",
      "Jiaxin Cao",
      "Qinsheng Zhang",
      "Han Cai",
      "Junjie Bai",
      "Yangqing Jia",
      "Kai Li",
      "Song Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Improving_the_Generalization_of_Segmentation_Foundation_Model_under_Distribution_Shift_CVPR_2024_paper.html": {
    "title": "Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haojie Zhang",
      "Yongyi Su",
      "Xun Xu",
      "Kui Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Pseudo_Label_Refinery_for_Unsupervised_Domain_Adaptation_on_Cross-dataset_3D_CVPR_2024_paper.html": {
    "title": "Pseudo Label Refinery for Unsupervised Domain Adaptation on Cross-dataset 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanwei Zhang",
      "Minghao Chen",
      "Shuai Xiao",
      "Liang Peng",
      "Hengjia Li",
      "Binbin Lin",
      "Ping Li",
      "Wenxiao Wang",
      "Boxi Wu",
      "Deng Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pavlakos_Reconstructing_Hands_in_3D_with_Transformers_CVPR_2024_paper.html": {
    "title": "Reconstructing Hands in 3D with Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georgios Pavlakos",
      "Dandan Shan",
      "Ilija Radosavovic",
      "Angjoo Kanazawa",
      "David Fouhey",
      "Jitendra Malik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_AZ-NAS_Assembling_Zero-Cost_Proxies_for_Network_Architecture_Search_CVPR_2024_paper.html": {
    "title": "AZ-NAS: Assembling Zero-Cost Proxies for Network Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junghyup Lee",
      "Bumsub Ham"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Correspondence-Free_Non-Rigid_Point_Set_Registration_Using_Unsupervised_Clustering_Analysis_CVPR_2024_paper.html": {
    "title": "Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised Clustering Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyang Zhao",
      "Jingen Jiang",
      "Lei Ma",
      "Shiqing Xin",
      "Gaofeng Meng",
      "Dong-Ming Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kaneko_Improving_Physics-Augmented_Continuum_Neural_Radiance_Field-Based_Geometry-Agnostic_System_Identification_with_CVPR_2024_paper.html": {
    "title": "Improving Physics-Augmented Continuum Neural Radiance Field-Based Geometry-Agnostic System Identification with Lagrangian Particle Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takuhiro Kaneko"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bai_BadCLIP_Trigger-Aware_Prompt_Learning_for_Backdoor_Attacks_on_CLIP_CVPR_2024_paper.html": {
    "title": "BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawang Bai",
      "Kuofeng Gao",
      "Shaobo Min",
      "Shu-Tao Xia",
      "Zhifeng Li",
      "Wei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Beyond_Image_Super-Resolution_for_Image_Recognition_with_Task-Driven_Perceptual_Loss_CVPR_2024_paper.html": {
    "title": "Beyond Image Super-Resolution for Image Recognition with Task-Driven Perceptual Loss",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeha Kim",
      "Junghun Oh",
      "Kyoung Mu Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_PELA_Learning_Parameter-Efficient_Models_with_Low-Rank_Approximation_CVPR_2024_paper.html": {
    "title": "PELA: Learning Parameter-Efficient Models with Low-Rank Approximation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangyang Guo",
      "Guangzhi Wang",
      "Mohan Kankanhalli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_XCube_Large-Scale_3D_Generative_Modeling_using_Sparse_Voxel_Hierarchies_CVPR_2024_paper.html": {
    "title": "XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanchi Ren",
      "Jiahui Huang",
      "Xiaohui Zeng",
      "Ken Museth",
      "Sanja Fidler",
      "Francis Williams"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/So_PixelRNN_In-pixel_Recurrent_Neural_Networks_for_End-to-end-optimized_Perception_with_Neural_CVPR_2024_paper.html": {
    "title": "PixelRNN: In-pixel Recurrent Neural Networks for End-to-end-optimized Perception with Neural Sensors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haley M. So",
      "Laurie Bose",
      "Piotr Dudek",
      "Gordon Wetzstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qiu_Reconstruction-free_Cascaded_Adaptive_Compressive_Sensing_CVPR_2024_paper.html": {
    "title": "Reconstruction-free Cascaded Adaptive Compressive Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenxi Qiu",
      "Tao Yue",
      "Xuemei Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Auto-Train-Once_Controller_Network_Guided_Automatic_Network_Pruning_from_Scratch_CVPR_2024_paper.html": {
    "title": "Auto-Train-Once: Controller Network Guided Automatic Network Pruning from Scratch",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xidong Wu",
      "Shangqian Gao",
      "Zeyu Zhang",
      "Zhenzhen Li",
      "Runxue Bao",
      "Yanfu Zhang",
      "Xiaoqian Wang",
      "Heng Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Constructing_and_Exploring_Intermediate_Domains_in_Mixed_Domain_Semi-supervised_Medical_CVPR_2024_paper.html": {
    "title": "Constructing and Exploring Intermediate Domains in Mixed Domain Semi-supervised Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qinghe Ma",
      "Jian Zhang",
      "Lei Qi",
      "Qian Yu",
      "Yinghuan Shi",
      "Yang Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_DUSt3R_Geometric_3D_Vision_Made_Easy_CVPR_2024_paper.html": {
    "title": "DUSt3R: Geometric 3D Vision Made Easy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuzhe Wang",
      "Vincent Leroy",
      "Yohann Cabon",
      "Boris Chidlovskii",
      "Jerome Revaud"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_From_Isolated_Islands_to_Pangea_Unifying_Semantic_Space_for_Human_CVPR_2024_paper.html": {
    "title": "From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yong-Lu Li",
      "Xiaoqian Wu",
      "Xinpeng Liu",
      "Zehao Wang",
      "Yiming Dou",
      "Yikun Ji",
      "Junyi Zhang",
      "Yixing Li",
      "Xudong Lu",
      "Jingru Tan",
      "Cewu Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hao_Bootstrapping_Autonomous_Driving_Radars_with_Self-Supervised_Learning_CVPR_2024_paper.html": {
    "title": "Bootstrapping Autonomous Driving Radars with Self-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiduo Hao",
      "Sohrab Madani",
      "Junfeng Guan",
      "Mohammed Alloulah",
      "Saurabh Gupta",
      "Haitham Hassanieh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_Robust_Distillation_via_Untargeted_and_Targeted_Intermediate_Adversarial_Samples_CVPR_2024_paper.html": {
    "title": "Robust Distillation via Untargeted and Targeted Intermediate Adversarial Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junhao Dong",
      "Piotr Koniusz",
      "Junxi Chen",
      "Z. Jane Wang",
      "Yew-Soon Ong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_USE_Universal_Segment_Embeddings_for_Open-Vocabulary_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqi Wang",
      "Wenbin He",
      "Xiwei Xuan",
      "Clint Sebastian",
      "Jorge Piazentin Ono",
      "Xin Li",
      "Sima Behpour",
      "Thang Doan",
      "Liang Gou",
      "Han-Wei Shen",
      "Liu Ren"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Functional_Diffusion_CVPR_2024_paper.html": {
    "title": "Functional Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Biao Zhang",
      "Peter Wonka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Soften_to_Defend_Towards_Adversarial_Robustness_via_Self-Guided_Label_Refinement_CVPR_2024_paper.html": {
    "title": "Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuorong Li",
      "Daiwei Yu",
      "Lina Wei",
      "Canghong Jin",
      "Yun Zhang",
      "Sixian Chan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Weakly_Supervised_Monocular_3D_Detection_with_a_Single-View_Image_CVPR_2024_paper.html": {
    "title": "Weakly Supervised Monocular 3D Detection with a Single-View Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueying Jiang",
      "Sheng Jin",
      "Lewei Lu",
      "Xiaoqin Zhang",
      "Shijian Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tourani_Pose-Guided_Self-Training_with_Two-Stage_Clustering_for_Unsupervised_Landmark_Discovery_CVPR_2024_paper.html": {
    "title": "Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised Landmark Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Tourani",
      "Ahmed Alwheibi",
      "Arif Mahmood",
      "Muhammad Haris Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chang_Learning_from_Synthetic_Human_Group_Activities_CVPR_2024_paper.html": {
    "title": "Learning from Synthetic Human Group Activities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Che-Jui Chang",
      "Danrui Li",
      "Deep Patel",
      "Parth Goel",
      "Honglu Zhou",
      "Seonghyeon Moon",
      "Samuel S. Sohn",
      "Sejong Yoon",
      "Vladimir Pavlovic",
      "Mubbasir Kapadia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shin_Blind_Image_Quality_Assessment_Based_on_Geometric_Order_Learning_CVPR_2024_paper.html": {
    "title": "Blind Image Quality Assessment Based on Geometric Order Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nyeong-Ho Shin",
      "Seon-Ho Lee",
      "Chang-Su Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bi_Text_Grouping_Adapter_Adapting_Pre-trained_Text_Detector_for_Layout_Analysis_CVPR_2024_paper.html": {
    "title": "Text Grouping Adapter: Adapting Pre-trained Text Detector for Layout Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianci Bi",
      "Xiaoyi Zhang",
      "Zhizheng Zhang",
      "Wenxuan Xie",
      "Cuiling Lan",
      "Yan Lu",
      "Nanning Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Generalizable_Whole_Slide_Image_Classification_with_Fine-Grained_Visual-Semantic_Interaction_CVPR_2024_paper.html": {
    "title": "Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Li",
      "Ying Chen",
      "Yifei Chen",
      "Rongshan Yu",
      "Wenxian Yang",
      "Liansheng Wang",
      "Bowen Ding",
      "Yuchen Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kaul_THRONE_An_Object-based_Hallucination_Benchmark_for_the_Free-form_Generations_of_CVPR_2024_paper.html": {
    "title": "THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prannay Kaul",
      "Zhizhong Li",
      "Hao Yang",
      "Yonatan Dukler",
      "Ashwin Swaminathan",
      "C. J. Taylor",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_Wired_Perspectives_Multi-View_Wire_Art_Embraces_Generative_AI_CVPR_2024_paper.html": {
    "title": "Wired Perspectives: Multi-View Wire Art Embraces Generative AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyu Qu",
      "Lan Yang",
      "Honggang Zhang",
      "Tao Xiang",
      "Kaiyue Pang",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_LUWA_Dataset_Learning_Lithic_Use-Wear_Analysis_on_Microscopic_Images_CVPR_2024_paper.html": {
    "title": "LUWA Dataset: Learning Lithic Use-Wear Analysis on Microscopic Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Zhang",
      "Irving Fang",
      "Hao Wu",
      "Akshat Kaushik",
      "Alice Rodriguez",
      "Hanwen Zhao",
      "Juexiao Zhang",
      "Zhuo Zheng",
      "Radu Iovita",
      "Chen Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Generalizing_6-DoF_Grasp_Detection_via_Domain_Prior_Knowledge_CVPR_2024_paper.html": {
    "title": "Generalizing 6-DoF Grasp Detection via Domain Prior Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxiang Ma",
      "Modi Shi",
      "Boyang Gao",
      "Di Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jia_The_Audio-Visual_Conversational_Graph_From_an_Egocentric-Exocentric_Perspective_CVPR_2024_paper.html": {
    "title": "The Audio-Visual Conversational Graph: From an Egocentric-Exocentric Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqi Jia",
      "Miao Liu",
      "Hao Jiang",
      "Ishwarya Ananthabhotla",
      "James M. Rehg",
      "Vamsi Krishna Ithapu",
      "Ruohan Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Byzantine-robust_Decentralized_Federated_Learning_via_Dual-domain_Clustering_and_Trust_Bootstrapping_CVPR_2024_paper.html": {
    "title": "Byzantine-robust Decentralized Federated Learning via Dual-domain Clustering and Trust Bootstrapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Sun",
      "Xinyang Liu",
      "Zhibo Wang",
      "Bo Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Manam_Leveraging_Camera_Triplets_for_Efficient_and_Accurate_Structure-from-Motion_CVPR_2024_paper.html": {
    "title": "Leveraging Camera Triplets for Efficient and Accurate Structure-from-Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lalit Manam",
      "Venu Madhav Govindu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xing_SimDA_Simple_Diffusion_Adapter_for_Efficient_Video_Generation_CVPR_2024_paper.html": {
    "title": "SimDA: Simple Diffusion Adapter for Efficient Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Xing",
      "Qi Dai",
      "Han Hu",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Multi-view_Aggregation_Network_for_Dichotomous_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Multi-view Aggregation Network for Dichotomous Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qian Yu",
      "Xiaoqi Zhao",
      "Youwei Pang",
      "Lihe Zhang",
      "Huchuan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_A_Recipe_for_Scaling_up_Text-to-Video_Generation_with_Text-free_Videos_CVPR_2024_paper.html": {
    "title": "A Recipe for Scaling up Text-to-Video Generation with Text-free Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Wang",
      "Shiwei Zhang",
      "Hangjie Yuan",
      "Zhiwu Qing",
      "Biao Gong",
      "Yingya Zhang",
      "Yujun Shen",
      "Changxin Gao",
      "Nong Sang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Juan_Molecular_Data_Programming_Towards_Molecule_Pseudo-labeling_with_Systematic_Weak_Supervision_CVPR_2024_paper.html": {
    "title": "Molecular Data Programming: Towards Molecule Pseudo-labeling with Systematic Weak Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Juan",
      "Kaixiong Zhou",
      "Ninghao Liu",
      "Tianlong Chen",
      "Xin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bialer_RadSimReal_Bridging_the_Gap_Between_Synthetic_and_Real_Data_in_CVPR_2024_paper.html": {
    "title": "RadSimReal: Bridging the Gap Between Synthetic and Real Data in Radar Object Detection With Simulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oded Bialer",
      "Yuval Haitman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tsai_No_More_Ambiguity_in_360deg_Room_Layout_via_Bi-Layout_Estimation_CVPR_2024_paper.html": {
    "title": "No More Ambiguity in 360deg Room Layout via Bi-Layout Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu-Ju Tsai",
      "Jin-Cheng Jhang",
      "Jingjing Zheng",
      "Wei Wang",
      "Albert Y. C. Chen",
      "Min Sun",
      "Cheng-Hao Kuo",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Residual_Denoising_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Residual Denoising Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Liu",
      "Qiang Wang",
      "Huijie Fan",
      "Yinong Wang",
      "Yandong Tang",
      "Liangqiong Qu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ou_Towards_Accurate_and_Robust_Architectures_via_Neural_Architecture_Search_CVPR_2024_paper.html": {
    "title": "Towards Accurate and Robust Architectures via Neural Architecture Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwei Ou",
      "Yuqi Feng",
      "Yanan Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Closely_Interactive_Human_Reconstruction_with_Proxemics_and_Physics-Guided_Adaption_CVPR_2024_paper.html": {
    "title": "Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Buzhen Huang",
      "Chen Li",
      "Chongyang Xu",
      "Liang Pan",
      "Yangang Wang",
      "Gim Hee Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Humblot-Renaux_A_Noisy_Elephant_in_the_Room_Is_Your_Out-of-Distribution_Detector_CVPR_2024_paper.html": {
    "title": "A Noisy Elephant in the Room: Is Your Out-of-Distribution Detector Robust to Label Noise?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Galadrielle Humblot-Renaux",
      "Sergio Escalera",
      "Thomas B. Moeslund"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pei_VideoMAC_Video_Masked_Autoencoders_Meet_ConvNets_CVPR_2024_paper.html": {
    "title": "VideoMAC: Video Masked Autoencoders Meet ConvNets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gensheng Pei",
      "Tao Chen",
      "Xiruo Jiang",
      "Huafeng Liu",
      "Zeren Sun",
      "Yazhou Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Taming_Stable_Diffusion_for_Text_to_360_Panorama_Image_Generation_CVPR_2024_paper.html": {
    "title": "Taming Stable Diffusion for Text to 360 Panorama Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Zhang",
      "Qianyi Wu",
      "Camilo Cruz Gambardella",
      "Xiaoshui Huang",
      "Dinh Phung",
      "Wanli Ouyang",
      "Jianfei Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_3DSFLabelling_Boosting_3D_Scene_Flow_Estimation_by_Pseudo_Auto-labelling_CVPR_2024_paper.html": {
    "title": "3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo Auto-labelling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaokang Jiang",
      "Guangming Wang",
      "Jiuming Liu",
      "Hesheng Wang",
      "Zhuang Ma",
      "Zhenqiang Liu",
      "Zhujin Liang",
      "Yi Shan",
      "Dalong Du"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Unsigned_Orthogonal_Distance_Fields_An_Accurate_Neural_Implicit_Representation_for_CVPR_2024_paper.html": {
    "title": "Unsigned Orthogonal Distance Fields: An Accurate Neural Implicit Representation for Diverse 3D Shapes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Lu",
      "Long Wan",
      "Nayu Ding",
      "Yulong Wang",
      "Shuhan Shen",
      "Shen Cai",
      "Lin Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wen_Modular_Blind_Video_Quality_Assessment_CVPR_2024_paper.html": {
    "title": "Modular Blind Video Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Wen",
      "Mu Li",
      "Yabin Zhang",
      "Yiting Liao",
      "Junlin Li",
      "Li Zhang",
      "Kede Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ganz_Question_Aware_Vision_Transformer_for_Multimodal_Reasoning_CVPR_2024_paper.html": {
    "title": "Question Aware Vision Transformer for Multimodal Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roy Ganz",
      "Yair Kittenplon",
      "Aviad Aberdam",
      "Elad Ben Avraham",
      "Oren Nuriel",
      "Shai Mazor",
      "Ron Litman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_OST_Refining_Text_Knowledge_with_Optimal_Spatio-Temporal_Descriptor_for_General_CVPR_2024_paper.html": {
    "title": "OST: Refining Text Knowledge with Optimal Spatio-Temporal Descriptor for General Video Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongjia Chen",
      "Hongshan Yu",
      "Zhengeng Yang",
      "Zechuan Li",
      "Wei Sun",
      "Chen Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Khanna_Habitat_Synthetic_Scenes_Dataset_HSSD-200_An_Analysis_of_3D_Scene_CVPR_2024_paper.html": {
    "title": "Habitat Synthetic Scenes Dataset (HSSD-200): An Analysis of 3D Scene Scale and Realism Tradeoffs for ObjectGoal Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mukul Khanna",
      "Yongsen Mao",
      "Hanxiao Jiang",
      "Sanjay Haresh",
      "Brennan Shacklett",
      "Dhruv Batra",
      "Alexander Clegg",
      "Eric Undersander",
      "Angel X. Chang",
      "Manolis Savva"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_OA-CNNs_Omni-Adaptive_Sparse_CNNs_for_3D_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "OA-CNNs: Omni-Adaptive Sparse CNNs for 3D Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bohao Peng",
      "Xiaoyang Wu",
      "Li Jiang",
      "Yukang Chen",
      "Hengshuang Zhao",
      "Zhuotao Tian",
      "Jiaya Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_RELI11D_A_Comprehensive_Multimodal_Human_Motion_Dataset_and_Method_CVPR_2024_paper.html": {
    "title": "RELI11D: A Comprehensive Multimodal Human Motion Dataset and Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Yan",
      "Yan Zhang",
      "Shuqiang Cai",
      "Shuqi Fan",
      "Xincheng Lin",
      "Yudi Dai",
      "Siqi Shen",
      "Chenglu Wen",
      "Lan Xu",
      "Yuexin Ma",
      "Cheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Generative_Image_Dynamics_CVPR_2024_paper.html": {
    "title": "Generative Image Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengqi Li",
      "Richard Tucker",
      "Noah Snavely",
      "Aleksander Holynski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_One-Class_Face_Anti-spoofing_via_Spoof_Cue_Map-Guided_Feature_Learning_CVPR_2024_paper.html": {
    "title": "One-Class Face Anti-spoofing via Spoof Cue Map-Guided Feature Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pei-Kai Huang",
      "Cheng-Hsuan Chiang",
      "Tzu-Hsien Chen",
      "Jun-Xiong Chong",
      "Tyng-Luh Liu",
      "Chiou-Ting Hsu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zanella_On_the_Test-Time_Zero-Shot_Generalization_of_Vision-Language_Models_Do_We_CVPR_2024_paper.html": {
    "title": "On the Test-Time Zero-Shot Generalization of Vision-Language Models: Do We Really Need Prompt Learning?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxime Zanella",
      "Ismail Ben Ayed"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hoe_InteractDiffusion_Interaction_Control_in_Text-to-Image_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiun Tian Hoe",
      "Xudong Jiang",
      "Chee Seng Chan",
      "Yap-Peng Tan",
      "Weipeng Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jang_NViST_In_the_Wild_New_View_Synthesis_from_a_Single_CVPR_2024_paper.html": {
    "title": "NViST: In the Wild New View Synthesis from a Single Image with Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonbong Jang",
      "Lourdes Agapito"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Beyond_Text_Frozen_Large_Language_Models_in_Visual_Signal_Comprehension_CVPR_2024_paper.html": {
    "title": "Beyond Text: Frozen Large Language Models in Visual Signal Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Zhu",
      "Fangyun Wei",
      "Yanye Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Rotated_Multi-Scale_Interaction_Network_for_Referring_Remote_Sensing_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Rotated Multi-Scale Interaction Network for Referring Remote Sensing Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihan Liu",
      "Yiwei Ma",
      "Xiaoqing Zhang",
      "Haowei Wang",
      "Jiayi Ji",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_GLACE_Global_Local_Accelerated_Coordinate_Encoding_CVPR_2024_paper.html": {
    "title": "GLACE: Global Local Accelerated Coordinate Encoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangjinhua Wang",
      "Xudong Jiang",
      "Silvano Galliani",
      "Christoph Vogel",
      "Marc Pollefeys"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Emergent_Open-Vocabulary_Semantic_Segmentation_from_Off-the-shelf_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayun Luo",
      "Siddhesh Khandelwal",
      "Leonid Sigal",
      "Boyang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lilja_Localization_Is_All_You_Evaluate_Data_Leakage_in_Online_Mapping_CVPR_2024_paper.html": {
    "title": "Localization Is All You Evaluate: Data Leakage in Online Mapping Datasets and How to Fix It",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam Lilja",
      "Junsheng Fu",
      "Erik Stenborg",
      "Lars Hammarstrand"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sharma_Alchemist_Parametric_Control_of_Material_Properties_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Alchemist: Parametric Control of Material Properties with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prafull Sharma",
      "Varun Jampani",
      "Yuanzhen Li",
      "Xuhui Jia",
      "Dmitry Lagun",
      "Fredo Durand",
      "Bill Freeman",
      "Mark Matthews"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nagarajan_Step_Differences_in_Instructional_Video_CVPR_2024_paper.html": {
    "title": "Step Differences in Instructional Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tushar Nagarajan",
      "Lorenzo Torresani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Depth_Anything_Unleashing_the_Power_of_Large-Scale_Unlabeled_Data_CVPR_2024_paper.html": {
    "title": "Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lihe Yang",
      "Bingyi Kang",
      "Zilong Huang",
      "Xiaogang Xu",
      "Jiashi Feng",
      "Hengshuang Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Srivastav_SelfPose3d_Self-Supervised_Multi-Person_Multi-View_3d_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "SelfPose3d: Self-Supervised Multi-Person Multi-View 3d Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vinkle Srivastav",
      "Keqi Chen",
      "Nicolas Padoy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_MoDE_CLIP_Data_Experts_via_Clustering_CVPR_2024_paper.html": {
    "title": "MoDE: CLIP Data Experts via Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Ma",
      "Po-Yao Huang",
      "Saining Xie",
      "Shang-Wen Li",
      "Luke Zettlemoyer",
      "Shih-Fu Chang",
      "Wen-Tau Yih",
      "Hu Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Joint2Human_High-Quality_3D_Human_Generation_via_Compact_Spherical_Embedding_of_CVPR_2024_paper.html": {
    "title": "Joint2Human: High-Quality 3D Human Generation via Compact Spherical Embedding of 3D Joints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muxin Zhang",
      "Qiao Feng",
      "Zhuo Su",
      "Chao Wen",
      "Zhou Xue",
      "Kun Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Prompt-Free_Diffusion_Taking_Text_out_of_Text-to-Image_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Prompt-Free Diffusion: Taking \"Text\" out of Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingqian Xu",
      "Jiayi Guo",
      "Zhangyang Wang",
      "Gao Huang",
      "Irfan Essa",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_MPOD123_One_Image_to_3D_Content_Generation_Using_Mask-enhanced_Progressive_CVPR_2024_paper.html": {
    "title": "MPOD123: One Image to 3D Content Generation Using Mask-enhanced Progressive Outline-to-Detail Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jimin Xu",
      "Tianbao Wang",
      "Tao Jin",
      "Shengyu Zhang",
      "Dongjie Fu",
      "Zhe Wang",
      "Jiangjing Lyu",
      "Chengfei Lv",
      "Chaoyue Niu",
      "Zhou Yu",
      "Zhou Zhao",
      "Fei Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jeong_Multi-agent_Long-term_3D_Human_Pose_Forecasting_via_Interaction-aware_Trajectory_Conditioning_CVPR_2024_paper.html": {
    "title": "Multi-agent Long-term 3D Human Pose Forecasting via Interaction-aware Trajectory Conditioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewoo Jeong",
      "Daehee Park",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_UnionFormer_Unified-Learning_Transformer_with_Multi-View_Representation_for_Image_Manipulation_Detection_CVPR_2024_paper.html": {
    "title": "UnionFormer: Unified-Learning Transformer with Multi-View Representation for Image Manipulation Detection and Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuaibo Li",
      "Wei Ma",
      "Jianwei Guo",
      "Shibiao Xu",
      "Benchong Li",
      "Xiaopeng Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Man_Situational_Awareness_Matters_in_3D_Vision_Language_Reasoning_CVPR_2024_paper.html": {
    "title": "Situational Awareness Matters in 3D Vision Language Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunze Man",
      "Liang-Yan Gui",
      "Yu-Xiong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_RCBEVDet_Radar-camera_Fusion_in_Birds_Eye_View_for_3D_Object_CVPR_2024_paper.html": {
    "title": "RCBEVDet: Radar-camera Fusion in Bird's Eye View for 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei Lin",
      "Zhe Liu",
      "Zhongyu Xia",
      "Xinhao Wang",
      "Yongtao Wang",
      "Shengxiang Qi",
      "Yang Dong",
      "Nan Dong",
      "Le Zhang",
      "Ce Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Davydov_CLOAF_CoLlisiOn-Aware_Human_Flow_CVPR_2024_paper.html": {
    "title": "CLOAF: CoLlisiOn-Aware Human Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrey Davydov",
      "Martin Engilberge",
      "Mathieu Salzmann",
      "Pascal Fua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bastian_Hybrid_Functional_Maps_for_Crease-Aware_Non-Isometric_Shape_Matching_CVPR_2024_paper.html": {
    "title": "Hybrid Functional Maps for Crease-Aware Non-Isometric Shape Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lennart Bastian",
      "Yizheng Xie",
      "Nassir Navab",
      "Zorah Lähner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Density-Guided_Semi-Supervised_3D_Semantic_Segmentation_with_Dual-Space_Hardness_Sampling_CVPR_2024_paper.html": {
    "title": "Density-Guided Semi-Supervised 3D Semantic Segmentation with Dual-Space Hardness Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianan Li",
      "Qiulei Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_Adaptive_Softassign_via_Hadamard-Equipped_Sinkhorn_CVPR_2024_paper.html": {
    "title": "Adaptive Softassign via Hadamard-Equipped Sinkhorn",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Binrui Shen",
      "Qiang Niu",
      "Shengxin Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Re-thinking_Data_Availability_Attacks_Against_Deep_Neural_Networks_CVPR_2024_paper.html": {
    "title": "Re-thinking Data Availability Attacks Against Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Fang",
      "Bo Li",
      "Shuang Wu",
      "Shouhong Ding",
      "Ran Yi",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Haji-Ali_ElasticDiffusion_Training-free_Arbitrary_Size_Image_Generation_through_Global-Local_Content_Separation_CVPR_2024_paper.html": {
    "title": "ElasticDiffusion: Training-free Arbitrary Size Image Generation through Global-Local Content Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moayed Haji-Ali",
      "Guha Balakrishnan",
      "Vicente Ordonez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tarasiou_Locally_Adaptive_Neural_3D_Morphable_Models_CVPR_2024_paper.html": {
    "title": "Locally Adaptive Neural 3D Morphable Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michail Tarasiou",
      "Rolandos Alexandros Potamias",
      "Eimear O'Sullivan",
      "Stylianos Ploumpis",
      "Stefanos Zafeiriou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_ICON_Incremental_CONfidence_for_Joint_Pose_and_Radiance_Field_Optimization_CVPR_2024_paper.html": {
    "title": "ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyao Wang",
      "Pierre Gleize",
      "Hao Tang",
      "Xingyu Chen",
      "Kevin J Liang",
      "Matt Feiszli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Learned_Scanpaths_Aid_Blind_Panoramic_Video_Quality_Assessment_CVPR_2024_paper.html": {
    "title": "Learned Scanpaths Aid Blind Panoramic Video Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kanglong Fan",
      "Wen Wen",
      "Mu Li",
      "Yifan Peng",
      "Kede Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_FineSports_A_Multi-person_Hierarchical_Sports_Video_Dataset_for_Fine-grained_Action_CVPR_2024_paper.html": {
    "title": "FineSports: A Multi-person Hierarchical Sports Video Dataset for Fine-grained Action Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinglin Xu",
      "Guohao Zhao",
      "Sibo Yin",
      "Wenhao Zhou",
      "Yuxin Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_SHiNe_Semantic_Hierarchy_Nexus_for_Open-vocabulary_Object_Detection_CVPR_2024_paper.html": {
    "title": "SHiNe: Semantic Hierarchy Nexus for Open-vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingxuan Liu",
      "Tyler L. Hayes",
      "Elisa Ricci",
      "Gabriela Csurka",
      "Riccardo Volpi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ni_TI2V-Zero_Zero-Shot_Image_Conditioning_for_Text-to-Video_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "TI2V-Zero: Zero-Shot Image Conditioning for Text-to-Video Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haomiao Ni",
      "Bernhard Egger",
      "Suhas Lohit",
      "Anoop Cherian",
      "Ye Wang",
      "Toshiaki Koike-Akino",
      "Sharon X. Huang",
      "Tim K. Marks"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_Ranking_Distillation_for_Open-Ended_Video_Question_Answering_with_Insufficient_Labels_CVPR_2024_paper.html": {
    "title": "Ranking Distillation for Open-Ended Video Question Answering with Insufficient Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianming Liang",
      "Chaolei Tan",
      "Beihao Xia",
      "Wei-Shi Zheng",
      "Jian-Fang Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_GARField_Group_Anything_with_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "GARField: Group Anything with Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chung Min Kim",
      "Mingxuan Wu",
      "Justin Kerr",
      "Ken Goldberg",
      "Matthew Tancik",
      "Angjoo Kanazawa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Depth-Aware_Concealed_Crop_Detection_in_Dense_Agricultural_Scenes_CVPR_2024_paper.html": {
    "title": "Depth-Aware Concealed Crop Detection in Dense Agricultural Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liqiong Wang",
      "Jinyu Yang",
      "Yanfu Zhang",
      "Fangyi Wang",
      "Feng Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Seo_Learning_Equi-angular_Representations_for_Online_Continual_Learning_CVPR_2024_paper.html": {
    "title": "Learning Equi-angular Representations for Online Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minhyuk Seo",
      "Hyunseo Koh",
      "Wonje Jeung",
      "Minjae Lee",
      "San Kim",
      "Hankook Lee",
      "Sungjun Cho",
      "Sungik Choi",
      "Hyunwoo Kim",
      "Jonghyun Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Meng_iToF-flow-based_High_Frame_Rate_Depth_Imaging_CVPR_2024_paper.html": {
    "title": "iToF-flow-based High Frame Rate Depth Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Meng",
      "Zhou Xue",
      "Xu Chang",
      "Xuemei Hu",
      "Tao Yue"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Solving_the_Catastrophic_Forgetting_Problem_in_Generalized_Category_Discovery_CVPR_2024_paper.html": {
    "title": "Solving the Catastrophic Forgetting Problem in Generalized Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinzi Cao",
      "Xiawu Zheng",
      "Guanhong Wang",
      "Weijiang Yu",
      "Yunhang Shen",
      "Ke Li",
      "Yutong Lu",
      "Yonghong Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Data-Efficient_Unsupervised_Interpolation_Without_Any_Intermediate_Frame_for_4D_Medical_CVPR_2024_paper.html": {
    "title": "Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "JungEun Kim",
      "Hangyul Yoon",
      "Geondo Park",
      "Kyungsu Kim",
      "Eunho Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guan_POCE_Primal_Policy_Optimization_with_Conservative_Estimation_for_Multi-constraint_Offline_CVPR_2024_paper.html": {
    "title": "POCE: Primal Policy Optimization with Conservative Estimation for Multi-constraint Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Guan",
      "Li Shen",
      "Ao Zhou",
      "Lusong Li",
      "Han Hu",
      "Xiaodong He",
      "Guang Chen",
      "Changjun Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Learning_the_3D_Fauna_of_the_Web_CVPR_2024_paper.html": {
    "title": "Learning the 3D Fauna of the Web",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zizhang Li",
      "Dor Litvak",
      "Ruining Li",
      "Yunzhi Zhang",
      "Tomas Jakab",
      "Christian Rupprecht",
      "Shangzhe Wu",
      "Andrea Vedaldi",
      "Jiajun Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jun_Masked_Spatial_Propagation_Network_for_Sparsity-Adaptive_Depth_Refinement_CVPR_2024_paper.html": {
    "title": "Masked Spatial Propagation Network for Sparsity-Adaptive Depth Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyoung Jun",
      "Jae-Han Lee",
      "Chang-Su Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lai_LISA_Reasoning_Segmentation_via_Large_Language_Model_CVPR_2024_paper.html": {
    "title": "LISA: Reasoning Segmentation via Large Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Lai",
      "Zhuotao Tian",
      "Yukang Chen",
      "Yanwei Li",
      "Yuhui Yuan",
      "Shu Liu",
      "Jiaya Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_Relightful_Harmonization_Lighting-aware_Portrait_Background_Replacement_CVPR_2024_paper.html": {
    "title": "Relightful Harmonization: Lighting-aware Portrait Background Replacement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengwei Ren",
      "Wei Xiong",
      "Jae Shin Yoon",
      "Zhixin Shu",
      "Jianming Zhang",
      "HyunJoon Jung",
      "Guido Gerig",
      "He Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Bridging_the_Gap_A_Unified_Video_Comprehension_Framework_for_Moment_CVPR_2024_paper.html": {
    "title": "Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicheng Xiao",
      "Zhuoyan Luo",
      "Yong Liu",
      "Yue Ma",
      "Hengwei Bian",
      "Yatai Ji",
      "Yujiu Yang",
      "Xiu Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_MuseChat_A_Conversational_Music_Recommendation_System_for_Videos_CVPR_2024_paper.html": {
    "title": "MuseChat: A Conversational Music Recommendation System for Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhikang Dong",
      "Xiulong Liu",
      "Bin Chen",
      "Pawel Polak",
      "Peng Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cannici_Mitigating_Motion_Blur_in_Neural_Radiance_Fields_with_Events_and_CVPR_2024_paper.html": {
    "title": "Mitigating Motion Blur in Neural Radiance Fields with Events and Frames",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Cannici",
      "Davide Scaramuzza"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_C3Net_Compound_Conditioned_ControlNet_for_Multimodal_Content_Generation_CVPR_2024_paper.html": {
    "title": "C3Net: Compound Conditioned ControlNet for Multimodal Content Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juntao Zhang",
      "Yuehuai Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Device-Wise_Federated_Network_Pruning_CVPR_2024_paper.html": {
    "title": "Device-Wise Federated Network Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangqian Gao",
      "Junyi Li",
      "Zeyu Zhang",
      "Yanfu Zhang",
      "Weidong Cai",
      "Heng Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Herzog_Adapt_Before_Comparison_A_New_Perspective_on_Cross-Domain_Few-Shot_Segmentation_CVPR_2024_paper.html": {
    "title": "Adapt Before Comparison: A New Perspective on Cross-Domain Few-Shot Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas Herzog"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dwivedi_TokenHMR_Advancing_Human_Mesh_Recovery_with_a_Tokenized_Pose_Representation_CVPR_2024_paper.html": {
    "title": "TokenHMR: Advancing Human Mesh Recovery with a Tokenized Pose Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Kumar Dwivedi",
      "Yu Sun",
      "Priyanka Patel",
      "Yao Feng",
      "Michael J. Black"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Min_MoReVQA_Exploring_Modular_Reasoning_Models_for_Video_Question_Answering_CVPR_2024_paper.html": {
    "title": "MoReVQA: Exploring Modular Reasoning Models for Video Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juhong Min",
      "Shyamal Buch",
      "Arsha Nagrani",
      "Minsu Cho",
      "Cordelia Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_Low-Rank_Rescaled_Vision_Transformer_Fine-Tuning_A_Residual_Design_Approach_CVPR_2024_paper.html": {
    "title": "Low-Rank Rescaled Vision Transformer Fine-Tuning: A Residual Design Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Dong",
      "Xing Zhang",
      "Bihui Chen",
      "Dawei Yan",
      "Zhijun Lin",
      "Qingsen Yan",
      "Peng Wang",
      "Yang Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_FaceCom_Towards_High-fidelity_3D_Facial_Shape_Completion_via_Optimization_and_CVPR_2024_paper.html": {
    "title": "FaceCom: Towards High-fidelity 3D Facial Shape Completion via Optimization and Inpainting Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinglong Li",
      "Hongyu Wu",
      "Xiaogang Wang",
      "Qingzhao Qin",
      "Yijiao Zhao",
      "Yong Wang",
      "Aimin Hao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Distribution-aware_Knowledge_Prototyping_for_Non-exemplar_Lifelong_Person_Re-identification_CVPR_2024_paper.html": {
    "title": "Distribution-aware Knowledge Prototyping for Non-exemplar Lifelong Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunlun Xu",
      "Xu Zou",
      "Yuxin Peng",
      "Jiahuan Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_LightOctree_Lightweight_3D_Spatially-Coherent_Indoor_Lighting_Estimation_CVPR_2024_paper.html": {
    "title": "LightOctree: Lightweight 3D Spatially-Coherent Indoor Lighting Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuecan Wang",
      "Shibang Xiao",
      "Xiaohui Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Generating_Enhanced_Negatives_for_Training_Language-Based_Object_Detectors_CVPR_2024_paper.html": {
    "title": "Generating Enhanced Negatives for Training Language-Based Object Detectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Zhao",
      "Long Zhao",
      "Vijay Kumar B G",
      "Yumin Suh",
      "Dimitris N. Metaxas",
      "Manmohan Chandraker",
      "Samuel Schulter"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_Insect-Foundation_A_Foundation_Model_and_Large-scale_1M_Dataset_for_Visual_CVPR_2024_paper.html": {
    "title": "Insect-Foundation: A Foundation Model and Large-scale 1M Dataset for Visual Insect Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoang-Quan Nguyen",
      "Thanh-Dat Truong",
      "Xuan Bac Nguyen",
      "Ashley Dowling",
      "Xin Li",
      "Khoa Luu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vouitsis_Data-Efficient_Multimodal_Fusion_on_a_Single_GPU_CVPR_2024_paper.html": {
    "title": "Data-Efficient Multimodal Fusion on a Single GPU",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Noël Vouitsis",
      "Zhaoyan Liu",
      "Satya Krishna Gorti",
      "Valentin Villecroze",
      "Jesse C. Cresswell",
      "Guangwei Yu",
      "Gabriel Loaiza-Ganem",
      "Maksims Volkovs"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tamirisa_FedSelect_Personalized_Federated_Learning_with_Customized_Selection_of_Parameters_for_CVPR_2024_paper.html": {
    "title": "FedSelect: Personalized Federated Learning with Customized Selection of Parameters for Fine-Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishub Tamirisa",
      "Chulin Xie",
      "Wenxuan Bao",
      "Andy Zhou",
      "Ron Arel",
      "Aviv Shamsian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ferman_FaceLift_Semi-supervised_3D_Facial_Landmark_Localization_CVPR_2024_paper.html": {
    "title": "FaceLift: Semi-supervised 3D Facial Landmark Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Ferman",
      "Pablo Garrido",
      "Gaurav Bharaj"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_PSDPM_Prototype-based_Secondary_Discriminative_Pixels_Mining_for_Weakly_Supervised_Semantic_CVPR_2024_paper.html": {
    "title": "PSDPM: Prototype-based Secondary Discriminative Pixels Mining for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinqiao Zhao",
      "Ziqian Yang",
      "Tianhong Dai",
      "Bingfeng Zhang",
      "Jimin Xiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Bidirectional_Multi-Scale_Implicit_Neural_Representations_for_Image_Deraining_CVPR_2024_paper.html": {
    "title": "Bidirectional Multi-Scale Implicit Neural Representations for Image Deraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Chen",
      "Jinshan Pan",
      "Jiangxin Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Frozen_CLIP_A_Strong_Backbone_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Frozen CLIP: A Strong Backbone for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingfeng Zhang",
      "Siyue Yu",
      "Yunchao Wei",
      "Yao Zhao",
      "Jimin Xiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_FedAS_Bridging_Inconsistency_in_Personalized_Federated_Learning_CVPR_2024_paper.html": {
    "title": "FedAS: Bridging Inconsistency in Personalized Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiyuan Yang",
      "Wenke Huang",
      "Mang Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_LAFS_Landmark-based_Facial_Self-supervised_Learning_for_Face_Recognition_CVPR_2024_paper.html": {
    "title": "LAFS: Landmark-based Facial Self-supervised Learning for Face Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhonglin Sun",
      "Chen Feng",
      "Ioannis Patras",
      "Georgios Tzimiropoulos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_SED_A_Simple_Encoder-Decoder_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Xie",
      "Jiale Cao",
      "Jin Xie",
      "Fahad Shahbaz Khan",
      "Yanwei Pang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_GPLD3D_Latent_Diffusion_of_3D_Shape_Generative_Models_by_Enforcing_CVPR_2024_paper.html": {
    "title": "GPLD3D: Latent Diffusion of 3D Shape Generative Models by Enforcing Geometric and Physical Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Dong",
      "Qi Zuo",
      "Xiaodong Gu",
      "Weihao Yuan",
      "Zhengyi Zhao",
      "Zilong Dong",
      "Liefeng Bo",
      "Qixing Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xing_Enhancing_Quality_of_Compressed_Images_by_Mitigating_Enhancement_Bias_Towards_CVPR_2024_paper.html": {
    "title": "Enhancing Quality of Compressed Images by Mitigating Enhancement Bias Towards Compression Domain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qunliang Xing",
      "Mai Xu",
      "Shengxi Li",
      "Xin Deng",
      "Meisong Zheng",
      "Huaida Liu",
      "Ying Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qin_LangSplat_3D_Language_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "LangSplat: 3D Language Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghan Qin",
      "Wanhua Li",
      "Jiawei Zhou",
      "Haoqian Wang",
      "Hanspeter Pfister"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mu_MoST_Multi-Modality_Scene_Tokenization_for_Motion_Prediction_CVPR_2024_paper.html": {
    "title": "MoST: Multi-Modality Scene Tokenization for Motion Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Norman Mu",
      "Jingwei Ji",
      "Zhenpei Yang",
      "Nate Harada",
      "Haotian Tang",
      "Kan Chen",
      "Charles R. Qi",
      "Runzhou Ge",
      "Kratarth Goel",
      "Zoey Yang",
      "Scott Ettinger",
      "Rami Al-Rfou",
      "Dragomir Anguelov",
      "Yin Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Haas_PIGEON_Predicting_Image_Geolocations_CVPR_2024_paper.html": {
    "title": "PIGEON: Predicting Image Geolocations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Haas",
      "Michal Skreta",
      "Silas Alberti",
      "Chelsea Finn"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Improving_Spectral_Snapshot_Reconstruction_with_Spectral-Spatial_Rectification_CVPR_2024_paper.html": {
    "title": "Improving Spectral Snapshot Reconstruction with Spectral-Spatial Rectification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiancheng Zhang",
      "Haijin Zeng",
      "Yongyong Chen",
      "Dengxiu Yu",
      "Yin-Ping Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Self-correcting_LLM-controlled_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Self-correcting LLM-controlled Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsung-Han Wu",
      "Long Lian",
      "Joseph E. Gonzalez",
      "Boyi Li",
      "Trevor Darrell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_PACER_On-Demand_Pedestrian_Animation_Controller_in_Driving_Scenarios_CVPR_2024_paper.html": {
    "title": "PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingbo Wang",
      "Zhengyi Luo",
      "Ye Yuan",
      "Yixuan Li",
      "Bo Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_LTM_Lightweight_Textured_Mesh_Extraction_and_Refinement_of_Large_Unbounded_CVPR_2024_paper.html": {
    "title": "LTM: Lightweight Textured Mesh Extraction and Refinement of Large Unbounded Scenes for Efficient Storage and Real-time Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaehoon Choi",
      "Rajvi Shah",
      "Qinbo Li",
      "Yipeng Wang",
      "Ayush Saraf",
      "Changil Kim",
      "Jia-Bin Huang",
      "Dinesh Manocha",
      "Suhib Alsisan",
      "Johannes Kopf"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dufour_Dont_Drop_Your_Samples_Coherence-Aware_Training_Benefits_Conditional_Diffusion_CVPR_2024_paper.html": {
    "title": "Don't Drop Your Samples! Coherence-Aware Training Benefits Conditional Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Dufour",
      "Victor Besnier",
      "Vicky Kalogeiton",
      "David Picard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kumar_Flow-Guided_Online_Stereo_Rectification_for_Wide_Baseline_Stereo_CVPR_2024_paper.html": {
    "title": "Flow-Guided Online Stereo Rectification for Wide Baseline Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anush Kumar",
      "Fahim Mannan",
      "Omid Hosseini Jafari",
      "Shile Li",
      "Felix Heide"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_DNGaussian_Optimizing_Sparse-View_3D_Gaussian_Radiance_Fields_with_Global-Local_Depth_CVPR_2024_paper.html": {
    "title": "DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahe Li",
      "Jiawei Zhang",
      "Xiao Bai",
      "Jin Zheng",
      "Xin Ning",
      "Jun Zhou",
      "Lin Gu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mu_ColorPCR_Color_Point_Cloud_Registration_with_Multi-Stage_Geometric-Color_Fusion_CVPR_2024_paper.html": {
    "title": "ColorPCR: Color Point Cloud Registration with Multi-Stage Geometric-Color Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juncheng Mu",
      "Lin Bie",
      "Shaoyi Du",
      "Yue Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_HomoFormer_Homogenized_Transformer_for_Image_Shadow_Removal_CVPR_2024_paper.html": {
    "title": "HomoFormer: Homogenized Transformer for Image Shadow Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Xiao",
      "Xueyang Fu",
      "Yurui Zhu",
      "Dong Li",
      "Jie Huang",
      "Kai Zhu",
      "Zheng-Jun Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_What_If_the_TV_Was_Off_Examining_Counterfactual_Reasoning_Abilities_CVPR_2024_paper.html": {
    "title": "What If the TV Was Off? Examining Counterfactual Reasoning Abilities of Multi-modal Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Letian Zhang",
      "Xiaotong Zhai",
      "Zhongkai Zhao",
      "Yongshuo Zong",
      "Xin Wen",
      "Bingchen Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_What_Do_You_See_in_Vehicle_Comprehensive_Vision_Solution_for_CVPR_2024_paper.html": {
    "title": "What Do You See in Vehicle? Comprehensive Vision Solution for In-Vehicle Gaze Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihua Cheng",
      "Yaning Zhu",
      "Zongji Wang",
      "Hongquan Hao",
      "Yongwei Liu",
      "Shiqing Cheng",
      "Xi Wang",
      "Hyung Jin Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Driving_Everywhere_with_Large_Language_Model_Policy_Adaptation_CVPR_2024_paper.html": {
    "title": "Driving Everywhere with Large Language Model Policy Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyi Li",
      "Yue Wang",
      "Jiageng Mao",
      "Boris Ivanovic",
      "Sushant Veer",
      "Karen Leung",
      "Marco Pavone"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Na_UFORecon_Generalizable_Sparse-View_Surface_Reconstruction_from_Arbitrary_and_Unfavorable_Sets_CVPR_2024_paper.html": {
    "title": "UFORecon: Generalizable Sparse-View Surface Reconstruction from Arbitrary and Unfavorable Sets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youngju Na",
      "Woo Jae Kim",
      "Kyu Beom Han",
      "Suhyeon Ha",
      "Sung-Eui Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rockwell_FAR_Flexible_Accurate_and_Robust_6DoF_Relative_Camera_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "FAR: Flexible Accurate and Robust 6DoF Relative Camera Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris Rockwell",
      "Nilesh Kulkarni",
      "Linyi Jin",
      "Jeong Joon Park",
      "Justin Johnson",
      "David F. Fouhey"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Verma_eTraM_Event-based_Traffic_Monitoring_Dataset_CVPR_2024_paper.html": {
    "title": "eTraM: Event-based Traffic Monitoring Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aayush Atul Verma",
      "Bharatesh Chakravarthi",
      "Arpitsinh Vaghela",
      "Hua Wei",
      "Yezhou Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_MoCha-Stereo_Motif_Channel_Attention_Network_for_Stereo_Matching_CVPR_2024_paper.html": {
    "title": "MoCha-Stereo: Motif Channel Attention Network for Stereo Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Chen",
      "Wei Long",
      "He Yao",
      "Yongjun Zhang",
      "Bingshu Wang",
      "Yongbin Qin",
      "Jia Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Koala_Key_Frame-Conditioned_Long_Video-LLM_CVPR_2024_paper.html": {
    "title": "Koala: Key Frame-Conditioned Long Video-LLM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reuben Tan",
      "Ximeng Sun",
      "Ping Hu",
      "Jui-hsien Wang",
      "Hanieh Deilamsalehy",
      "Bryan A. Plummer",
      "Bryan Russell",
      "Kate Saenko"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Extend_Your_Own_Correspondences_Unsupervised_Distant_Point_Cloud_Registration_by_CVPR_2024_paper.html": {
    "title": "Extend Your Own Correspondences: Unsupervised Distant Point Cloud Registration by Progressive Distance Extension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Liu",
      "Hongzi Zhu",
      "Zhenxi Wang",
      "Yunsong Zhou",
      "Shan Chang",
      "Minyi Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guan_HallusionBench_An_Advanced_Diagnostic_Suite_for_Entangled_Language_Hallucination_and_CVPR_2024_paper.html": {
    "title": "HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianrui Guan",
      "Fuxiao Liu",
      "Xiyang Wu",
      "Ruiqi Xian",
      "Zongxia Li",
      "Xiaoyu Liu",
      "Xijun Wang",
      "Lichang Chen",
      "Furong Huang",
      "Yaser Yacoob",
      "Dinesh Manocha",
      "Tianyi Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bai_ID-like_Prompt_Learning_for_Few-Shot_Out-of-Distribution_Detection_CVPR_2024_paper.html": {
    "title": "ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Bai",
      "Zongbo Han",
      "Bing Cao",
      "Xiaoheng Jiang",
      "Qinghua Hu",
      "Changqing Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gal_Breathing_Life_Into_Sketches_Using_Text-to-Video_Priors_CVPR_2024_paper.html": {
    "title": "Breathing Life Into Sketches Using Text-to-Video Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rinon Gal",
      "Yael Vinker",
      "Yuval Alaluf",
      "Amit Bermano",
      "Daniel Cohen-Or",
      "Ariel Shamir",
      "Gal Chechik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Benson_Multi-modal_Learning_for_Geospatial_Vegetation_Forecasting_CVPR_2024_paper.html": {
    "title": "Multi-modal Learning for Geospatial Vegetation Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vitus Benson",
      "Claire Robin",
      "Christian Requena-Mesa",
      "Lazaro Alonso",
      "Nuno Carvalhais",
      "José Cortés",
      "Zhihan Gao",
      "Nora Linscheid",
      "Mélanie Weynants",
      "Markus Reichstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Learning_Diffusion_Texture_Priors_for_Image_Restoration_CVPR_2024_paper.html": {
    "title": "Learning Diffusion Texture Priors for Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tian Ye",
      "Sixiang Chen",
      "Wenhao Chai",
      "Zhaohu Xing",
      "Jing Qin",
      "Ge Lin",
      "Lei Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Bring_Event_into_RGB_and_LiDAR_Hierarchical_Visual-Motion_Fusion_for_CVPR_2024_paper.html": {
    "title": "Bring Event into RGB and LiDAR: Hierarchical Visual-Motion Fusion for Scene Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanyu Zhou",
      "Yi Chang",
      "Zhiwei Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Min_Entangled_View-Epipolar_Information_Aggregation_for_Generalizable_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "Entangled View-Epipolar Information Aggregation for Generalizable Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Min",
      "Yawei Luo",
      "Wei Yang",
      "Yuesong Wang",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pramanick_Jack_of_All_Tasks_Master_of_Many_Designing_General-Purpose_Coarse-to-Fine_CVPR_2024_paper.html": {
    "title": "Jack of All Tasks Master of Many: Designing General-Purpose Coarse-to-Fine Vision-Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shraman Pramanick",
      "Guangxing Han",
      "Rui Hou",
      "Sayan Nag",
      "Ser-Nam Lim",
      "Nicolas Ballas",
      "Qifan Wang",
      "Rama Chellappa",
      "Amjad Almahairi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MMVP_A_Multimodal_MoCap_Dataset_with_Vision_and_Pressure_Sensors_CVPR_2024_paper.html": {
    "title": "MMVP: A Multimodal MoCap Dataset with Vision and Pressure Sensors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Zhang",
      "Shenghao Ren",
      "Haolei Yuan",
      "Jianhui Zhao",
      "Fan Li",
      "Shuangpeng Sun",
      "Zhenghao Liang",
      "Tao Yu",
      "Qiu Shen",
      "Xun Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zolfi_YolOOD_Utilizing_Object_Detection_Concepts_for_Multi-Label_Out-of-Distribution_Detection_CVPR_2024_paper.html": {
    "title": "YolOOD: Utilizing Object Detection Concepts for Multi-Label Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alon Zolfi",
      "Guy Amit",
      "Amit Baras",
      "Satoru Koda",
      "Ikuya Morikawa",
      "Yuval Elovici",
      "Asaf Shabtai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_SchurVINS_Schur_Complement-Based_Lightweight_Visual_Inertial_Navigation_System_CVPR_2024_paper.html": {
    "title": "SchurVINS: Schur Complement-Based Lightweight Visual Inertial Navigation System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunfei Fan",
      "Tianyu Zhao",
      "Guidong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Benigmim_Collaborating_Foundation_Models_for_Domain_Generalized_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Collaborating Foundation Models for Domain Generalized Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasser Benigmim",
      "Subhankar Roy",
      "Slim Essid",
      "Vicky Kalogeiton",
      "Stéphane Lathuilière"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Towards_Variable_and_Coordinated_Holistic_Co-Speech_Motion_Generation_CVPR_2024_paper.html": {
    "title": "Towards Variable and Coordinated Holistic Co-Speech Motion Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Liu",
      "Qiong Cao",
      "Yandong Wen",
      "Huaiguang Jiang",
      "Changxing Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_JoAPR_Cleaning_the_Lens_of_Prompt_Learning_for_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "JoAPR: Cleaning the Lens of Prompt Learning for Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuncheng Guo",
      "Xiaodong Gu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_AllSpark_Reborn_Labeled_Features_from_Unlabeled_in_Transformer_for_Semi-Supervised_CVPR_2024_paper.html": {
    "title": "AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haonan Wang",
      "Qixiang Zhang",
      "Yi Li",
      "Xiaomeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Open-Vocabulary_3D_Semantic_Segmentation_with_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Open-Vocabulary 3D Semantic Segmentation with Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Jiang",
      "Shaoshuai Shi",
      "Bernt Schiele"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dihlmann_SIGNeRF_Scene_Integrated_Generation_for_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "SIGNeRF: Scene Integrated Generation for Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan-Niklas Dihlmann",
      "Andreas Engelhardt",
      "Hendrik Lensch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_ViP-LLaVA_Making_Large_Multimodal_Models_Understand_Arbitrary_Visual_Prompts_CVPR_2024_paper.html": {
    "title": "ViP-LLaVA: Making Large Multimodal Models Understand Arbitrary Visual Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mu Cai",
      "Haotian Liu",
      "Siva Karthik Mustikovela",
      "Gregory P. Meyer",
      "Yuning Chai",
      "Dennis Park",
      "Yong Jae Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_OVER-NAV_Elevating_Iterative_Vision-and-Language_Navigation_with_Open-Vocabulary_Detection_and_StructurEd_CVPR_2024_paper.html": {
    "title": "OVER-NAV: Elevating Iterative Vision-and-Language Navigation with Open-Vocabulary Detection and StructurEd Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ganlong Zhao",
      "Guanbin Li",
      "Weikai Chen",
      "Yizhou Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Prach_1-Lipschitz_Layers_Compared_Memory_Speed_and_Certifiable_Robustness_CVPR_2024_paper.html": {
    "title": "1-Lipschitz Layers Compared: Memory Speed and Certifiable Robustness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bernd Prach",
      "Fabio Brau",
      "Giorgio Buttazzo",
      "Christoph H. Lampert"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Niu_All_Rivers_Run_to_the_Sea_Private_Learning_with_Asymmetric_CVPR_2024_paper.html": {
    "title": "All Rivers Run to the Sea: Private Learning with Asymmetric Flows",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Niu",
      "Ramy E. Ali",
      "Saurav Prakash",
      "Salman Avestimehr"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Menon_Generating_Illustrated_Instructions_CVPR_2024_paper.html": {
    "title": "Generating Illustrated Instructions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sachit Menon",
      "Ishan Misra",
      "Rohit Girdhar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Construct_to_Associate_Cooperative_Context_Learning_for_Domain_Adaptive_Point_CVPR_2024_paper.html": {
    "title": "Construct to Associate: Cooperative Context Learning for Domain Adaptive Point Cloud Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangrui Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ryou_Robust_Image_Denoising_through_Adversarial_Frequency_Mixup_CVPR_2024_paper.html": {
    "title": "Robust Image Denoising through Adversarial Frequency Mixup",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Donghun Ryou",
      "Inju Ha",
      "Hyewon Yoo",
      "Dongwan Kim",
      "Bohyung Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_HandBooster_Boosting_3D_Hand-Mesh_Reconstruction_by_Conditional_Synthesis_and_Sampling_CVPR_2024_paper.html": {
    "title": "HandBooster: Boosting 3D Hand-Mesh Reconstruction by Conditional Synthesis and Sampling of Hand-Object Interactions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Xu",
      "Haipeng Li",
      "Yinqiao Wang",
      "Shuaicheng Liu",
      "Chi-Wing Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_A-Teacher_Asymmetric_Network_for_3D_Semi-Supervised_Object_Detection_CVPR_2024_paper.html": {
    "title": "A-Teacher: Asymmetric Network for 3D Semi-Supervised Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanshi Wang",
      "Zhipeng Zhang",
      "Jin Gao",
      "Weiming Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_GoMVS_Geometrically_Consistent_Cost_Aggregation_for_Multi-View_Stereo_CVPR_2024_paper.html": {
    "title": "GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiang Wu",
      "Rui Li",
      "Haofei Xu",
      "Wenxun Zhao",
      "Yu Zhu",
      "Jinqiu Sun",
      "Yanning Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dai_Evaluating_Transferability_in_Retrieval_Tasks_An_Approach_Using_MMD_and_CVPR_2024_paper.html": {
    "title": "Evaluating Transferability in Retrieval Tasks: An Approach Using MMD and Kernel Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengyu Dai",
      "Amir Hossein Raffiee",
      "Aashish Jain",
      "Joshua Correa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_AnyScene_Customized_Image_Synthesis_with_Composited_Foreground_CVPR_2024_paper.html": {
    "title": "AnyScene: Customized Image Synthesis with Composited Foreground",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruidong Chen",
      "Lanjun Wang",
      "Weizhi Nie",
      "Yongdong Zhang",
      "An-An Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Korkmaz_Training_Generative_Image_Super-Resolution_Models_by_Wavelet-Domain_Losses_Enables_Better_CVPR_2024_paper.html": {
    "title": "Training Generative Image Super-Resolution Models by Wavelet-Domain Losses Enables Better Control of Artifacts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cansu Korkmaz",
      "A. Murat Tekalp",
      "Zafer Dogan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tores_Visual_Objectification_in_Films_Towards_a_New_AI_Task_for_CVPR_2024_paper.html": {
    "title": "Visual Objectification in Films: Towards a New AI Task for Video Interpretation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julie Tores",
      "Lucile Sassatelli",
      "Hui-Yin Wu",
      "Clement Bergman",
      "Léa Andolfi",
      "Victor Ecrement",
      "Frédéric Precioso",
      "Thierry Devars",
      "Magali Guaresi",
      "Virginie Julliard",
      "Sarah Lecossais"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_OMG-Seg_Is_One_Model_Good_Enough_For_All_Segmentation_CVPR_2024_paper.html": {
    "title": "OMG-Seg: Is One Model Good Enough For All Segmentation?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangtai Li",
      "Haobo Yuan",
      "Wei Li",
      "Henghui Ding",
      "Size Wu",
      "Wenwei Zhang",
      "Yining Li",
      "Kai Chen",
      "Chen Change Loy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_BiTT_Bi-directional_Texture_Reconstruction_of_Interacting_Two_Hands_from_a_CVPR_2024_paper.html": {
    "title": "BiTT: Bi-directional Texture Reconstruction of Interacting Two Hands from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minje Kim",
      "Tae-Kyun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yao_DetCLIPv3_Towards_Versatile_Generative_Open-vocabulary_Object_Detection_CVPR_2024_paper.html": {
    "title": "DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lewei Yao",
      "Renjie Pi",
      "Jianhua Han",
      "Xiaodan Liang",
      "Hang Xu",
      "Wei Zhang",
      "Zhenguo Li",
      "Dan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_UVEB_A_Large-scale_Benchmark_and_Baseline_Towards_Real-World_Underwater_Video_CVPR_2024_paper.html": {
    "title": "UVEB: A Large-scale Benchmark and Baseline Towards Real-World Underwater Video Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaofeng Xie",
      "Lingwei Kong",
      "Kai Chen",
      "Ziqiang Zheng",
      "Xiao Yu",
      "Zhibin Yu",
      "Bing Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ranasinghe_Learning_to_Localize_Objects_Improves_Spatial_Reasoning_in_Visual-LLMs_CVPR_2024_paper.html": {
    "title": "Learning to Localize Objects Improves Spatial Reasoning in Visual-LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kanchana Ranasinghe",
      "Satya Narayan Shukla",
      "Omid Poursaeed",
      "Michael S. Ryoo",
      "Tsung-Yu Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_Monocular_Identity-Conditioned_Facial_Reflectance_Reconstruction_CVPR_2024_paper.html": {
    "title": "Monocular Identity-Conditioned Facial Reflectance Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Ren",
      "Jiankang Deng",
      "Yuhao Cheng",
      "Jia Guo",
      "Chao Ma",
      "Yichao Yan",
      "Wenhan Zhu",
      "Xiaokang Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_C3_High-Performance_and_Low-Complexity_Neural_Compression_from_a_Single_Image_CVPR_2024_paper.html": {
    "title": "C3: High-Performance and Low-Complexity Neural Compression from a Single Image or Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunjik Kim",
      "Matthias Bauer",
      "Lucas Theis",
      "Jonathan Richard Schwarz",
      "Emilien Dupont"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ristea_Self-Distilled_Masked_Auto-Encoders_are_Efficient_Video_Anomaly_Detectors_CVPR_2024_paper.html": {
    "title": "Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly Detectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolae-C?t?lin Ristea",
      "Florinel-Alin Croitoru",
      "Radu Tudor Ionescu",
      "Marius Popescu",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ni_Revisiting_Non-Autoregressive_Transformers_for_Efficient_Image_Synthesis_CVPR_2024_paper.html": {
    "title": "Revisiting Non-Autoregressive Transformers for Efficient Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zanlin Ni",
      "Yulin Wang",
      "Renping Zhou",
      "Jiayi Guo",
      "Jinyi Hu",
      "Zhiyuan Liu",
      "Shiji Song",
      "Yuan Yao",
      "Gao Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Distilling_Vision-Language_Models_on_Millions_of_Videos_CVPR_2024_paper.html": {
    "title": "Distilling Vision-Language Models on Millions of Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Zhao",
      "Long Zhao",
      "Xingyi Zhou",
      "Jialin Wu",
      "Chun-Te Chu",
      "Hui Miao",
      "Florian Schroff",
      "Hartwig Adam",
      "Ting Liu",
      "Boqing Gong",
      "Philipp Krahenbuhl",
      "Liangzhe Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pesavento_ANIM_Accurate_Neural_Implicit_Model_for_Human_Reconstruction_from_a_CVPR_2024_paper.html": {
    "title": "ANIM: Accurate Neural Implicit Model for Human Reconstruction from a single RGB-D Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Pesavento",
      "Yuanlu Xu",
      "Nikolaos Sarafianos",
      "Robert Maier",
      "Ziyan Wang",
      "Chun-Han Yao",
      "Marco Volino",
      "Edmond Boyer",
      "Adrian Hilton",
      "Tony Tung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Real-Time_Simulated_Avatar_from_Head-Mounted_Sensors_CVPR_2024_paper.html": {
    "title": "Real-Time Simulated Avatar from Head-Mounted Sensors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengyi Luo",
      "Jinkun Cao",
      "Rawal Khirodkar",
      "Alexander Winkler",
      "Kris Kitani",
      "Weipeng Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Discovering_Syntactic_Interaction_Clues_for_Human-Object_Interaction_Detection_CVPR_2024_paper.html": {
    "title": "Discovering Syntactic Interaction Clues for Human-Object Interaction Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinguo Luo",
      "Weihong Ren",
      "Weibo Jiang",
      "Xi'ai Chen",
      "Qiang Wang",
      "Zhi Han",
      "Honghai Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Inter-X_Towards_Versatile_Human-Human_Interaction_Analysis_CVPR_2024_paper.html": {
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Xu",
      "Xintao Lv",
      "Yichao Yan",
      "Xin Jin",
      "Shuwen Wu",
      "Congsheng Xu",
      "Yifan Liu",
      "Yizhou Zhou",
      "Fengyun Rao",
      "Xingdong Sheng",
      "Yunhui Liu",
      "Wenjun Zeng",
      "Xiaokang Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Generalized_Predictive_Model_for_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "Generalized Predictive Model for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiazhi Yang",
      "Shenyuan Gao",
      "Yihang Qiu",
      "Li Chen",
      "Tianyu Li",
      "Bo Dai",
      "Kashyap Chitta",
      "Penghao Wu",
      "Jia Zeng",
      "Ping Luo",
      "Jun Zhang",
      "Andreas Geiger",
      "Yu Qiao",
      "Hongyang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_FACT_Frame-Action_Cross-Attention_Temporal_Modeling_for_Efficient_Action_Segmentation_CVPR_2024_paper.html": {
    "title": "FACT: Frame-Action Cross-Attention Temporal Modeling for Efficient Action Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijia Lu",
      "Ehsan Elhamifar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liberatori_Test-Time_Zero-Shot_Temporal_Action_Localization_CVPR_2024_paper.html": {
    "title": "Test-Time Zero-Shot Temporal Action Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benedetta Liberatori",
      "Alessandro Conti",
      "Paolo Rota",
      "Yiming Wang",
      "Elisa Ricci"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ranzinger_AM-RADIO_Agglomerative_Vision_Foundation_Model_Reduce_All_Domains_Into_One_CVPR_2024_paper.html": {
    "title": "AM-RADIO: Agglomerative Vision Foundation Model Reduce All Domains Into One",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mike Ranzinger",
      "Greg Heinrich",
      "Jan Kautz",
      "Pavlo Molchanov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_MaskClustering_View_Consensus_based_Mask_Graph_Clustering_for_Open-Vocabulary_3D_CVPR_2024_paper.html": {
    "title": "MaskClustering: View Consensus based Mask Graph Clustering for Open-Vocabulary 3D Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mi Yan",
      "Jiazhao Zhang",
      "Yan Zhu",
      "He Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Barquero_Seamless_Human_Motion_Composition_with_Blended_Positional_Encodings_CVPR_2024_paper.html": {
    "title": "Seamless Human Motion Composition with Blended Positional Encodings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "German Barquero",
      "Sergio Escalera",
      "Cristina Palmero"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jung_PeerAiD_Improving_Adversarial_Distillation_from_a_Specialized_Peer_Tutor_CVPR_2024_paper.html": {
    "title": "PeerAiD: Improving Adversarial Distillation from a Specialized Peer Tutor",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewon Jung",
      "Hongsun Jang",
      "Jaeyong Song",
      "Jinho Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Goyal_Scaling_Laws_for_Data_Filtering--_Data_Curation_cannot_be_Compute_CVPR_2024_paper.html": {
    "title": "Scaling Laws for Data Filtering-- Data Curation cannot be Compute Agnostic",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sachin Goyal",
      "Pratyush Maini",
      "Zachary C. Lipton",
      "Aditi Raghunathan",
      "J. Zico Kolter"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_FastMAC_Stochastic_Spectral_Sampling_of_Correspondence_Graph_CVPR_2024_paper.html": {
    "title": "FastMAC: Stochastic Spectral Sampling of Correspondence Graph",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Zhang",
      "Hao Zhao",
      "Hongyang Li",
      "Siheng Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Son_FedUV_Uniformity_and_Variance_for_Heterogeneous_Federated_Learning_CVPR_2024_paper.html": {
    "title": "FedUV: Uniformity and Variance for Heterogeneous Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ha Min Son",
      "Moon-Hyun Kim",
      "Tai-Myoung Chung",
      "Chao Huang",
      "Xin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_FedSOL_Stabilized_Orthogonal_Learning_with_Proximal_Restrictions_in_Federated_Learning_CVPR_2024_paper.html": {
    "title": "FedSOL: Stabilized Orthogonal Learning with Proximal Restrictions in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gihun Lee",
      "Minchan Jeong",
      "Sangmook Kim",
      "Jaehoon Oh",
      "Se-Young Yun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_GAvatar_Animatable_3D_Gaussian_Avatars_with_Implicit_Mesh_Learning_CVPR_2024_paper.html": {
    "title": "GAvatar: Animatable 3D Gaussian Avatars with Implicit Mesh Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ye Yuan",
      "Xueting Li",
      "Yangyi Huang",
      "Shalini De Mello",
      "Koki Nagano",
      "Jan Kautz",
      "Umar Iqbal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Beyond_Average_Individualized_Visual_Scanpath_Prediction_CVPR_2024_paper.html": {
    "title": "Beyond Average: Individualized Visual Scanpath Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianyu Chen",
      "Ming Jiang",
      "Qi Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_A_Category_Agnostic_Model_for_Visual_Rearrangment_CVPR_2024_paper.html": {
    "title": "A Category Agnostic Model for Visual Rearrangment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyi Liu",
      "Xinhang Song",
      "Weijie Li",
      "Xiaohan Wang",
      "Shuqiang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bousselham_Grounding_Everything_Emerging_Localization_Properties_in_Vision-Language_Transformers_CVPR_2024_paper.html": {
    "title": "Grounding Everything: Emerging Localization Properties in Vision-Language Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Walid Bousselham",
      "Felix Petersen",
      "Vittorio Ferrari",
      "Hilde Kuehne"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Seeing_Motion_at_Nighttime_with_an_Event_Camera_CVPR_2024_paper.html": {
    "title": "Seeing Motion at Nighttime with an Event Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyue Liu",
      "Shihan Peng",
      "Lin Zhu",
      "Yi Chang",
      "Hanyu Zhou",
      "Luxin Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Taher_Representing_Part-Whole_Hierarchies_in_Foundation_Models_by_Learning_Localizability_Composability_CVPR_2024_paper.html": {
    "title": "Representing Part-Whole Hierarchies in Foundation Models by Learning Localizability Composability and Decomposability from Anatomy via Self Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Reza Hosseinzadeh Taher",
      "Michael B. Gotway",
      "Jianming Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Karmanov_Efficient_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Efficient Test-Time Adaptation of Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adilbek Karmanov",
      "Dayan Guan",
      "Shijian Lu",
      "Abdulmotaleb El Saddik",
      "Eric Xing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tong_Eyes_Wide_Shut_Exploring_the_Visual_Shortcomings_of_Multimodal_LLMs_CVPR_2024_paper.html": {
    "title": "Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengbang Tong",
      "Zhuang Liu",
      "Yuexiang Zhai",
      "Yi Ma",
      "Yann LeCun",
      "Saining Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kobayashi_Mean-Shift_Feature_Transformer_CVPR_2024_paper.html": {
    "title": "Mean-Shift Feature Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takumi Kobayashi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Domain_Separation_Graph_Neural_Networks_for_Saliency_Object_Ranking_CVPR_2024_paper.html": {
    "title": "Domain Separation Graph Neural Networks for Saliency Object Ranking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijian Wu",
      "Jun Lu",
      "Jing Han",
      "Lianfa Bai",
      "Yi Zhang",
      "Zhuang Zhao",
      "Siyang Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Mind_Marginal_Non-Crack_Regions_Clustering-Inspired_Representation_Learning_for_Crack_Segmentation_CVPR_2024_paper.html": {
    "title": "Mind Marginal Non-Crack Regions: Clustering-Inspired Representation Learning for Crack Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuangzhuang Chen",
      "Zhuonan Lai",
      "Jie Chen",
      "Jianqiang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mais_FISBe_A_Real-World_Benchmark_Dataset_for_Instance_Segmentation_of_Long-Range_CVPR_2024_paper.html": {
    "title": "FISBe: A Real-World Benchmark Dataset for Instance Segmentation of Long-Range Thin Filamentous Structures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lisa Mais",
      "Peter Hirsch",
      "Claire Managan",
      "Ramya Kandarpa",
      "Josef Lorenz Rumberger",
      "Annika Reinke",
      "Lena Maier-Hein",
      "Gudrun Ihrke",
      "Dagmar Kainmueller"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_RegionGPT_Towards_Region_Understanding_Vision_Language_Model_CVPR_2024_paper.html": {
    "title": "RegionGPT: Towards Region Understanding Vision Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiushan Guo",
      "Shalini De Mello",
      "Hongxu Yin",
      "Wonmin Byeon",
      "Ka Chun Cheung",
      "Yizhou Yu",
      "Ping Luo",
      "Sifei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_LL3DA_Visual_Interactive_Instruction_Tuning_for_Omni-3D_Understanding_Reasoning_and_CVPR_2024_paper.html": {
    "title": "LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding Reasoning and Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijin Chen",
      "Xin Chen",
      "Chi Zhang",
      "Mingsheng Li",
      "Gang Yu",
      "Hao Fei",
      "Hongyuan Zhu",
      "Jiayuan Fan",
      "Tao Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_4D_Gaussian_Splatting_for_Real-Time_Dynamic_Scene_Rendering_CVPR_2024_paper.html": {
    "title": "4D Gaussian Splatting for Real-Time Dynamic Scene Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanjun Wu",
      "Taoran Yi",
      "Jiemin Fang",
      "Lingxi Xie",
      "Xiaopeng Zhang",
      "Wei Wei",
      "Wenyu Liu",
      "Qi Tian",
      "Xinggang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_RAM-Avatar_Real-time_Photo-Realistic_Avatar_from_Monocular_Videos_with_Full-body_Control_CVPR_2024_paper.html": {
    "title": "RAM-Avatar: Real-time Photo-Realistic Avatar from Monocular Videos with Full-body Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Deng",
      "Zerong Zheng",
      "Yuxiang Zhang",
      "Jingxiang Sun",
      "Chao Xu",
      "Xiaodong Yang",
      "Lizhen Wang",
      "Yebin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Selective-Stereo_Adaptive_Frequency_Information_Selection_for_Stereo_Matching_CVPR_2024_paper.html": {
    "title": "Selective-Stereo: Adaptive Frequency Information Selection for Stereo Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianqi Wang",
      "Gangwei Xu",
      "Hao Jia",
      "Xin Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_PerAda_Parameter-Efficient_Federated_Learning_Personalization_with_Generalization_Guarantees_CVPR_2024_paper.html": {
    "title": "PerAda: Parameter-Efficient Federated Learning Personalization with Generalization Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chulin Xie",
      "De-An Huang",
      "Wenda Chu",
      "Daguang Xu",
      "Chaowei Xiao",
      "Bo Li",
      "Anima Anandkumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Byun_MAFA_Managing_False_Negatives_for_Vision-Language_Pre-training_CVPR_2024_paper.html": {
    "title": "MAFA: Managing False Negatives for Vision-Language Pre-training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeseok Byun",
      "Dohoon Kim",
      "Taesup Moon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shrivastava_Video_Prediction_by_Modeling_Videos_as_Continuous_Multi-Dimensional_Processes_CVPR_2024_paper.html": {
    "title": "Video Prediction by Modeling Videos as Continuous Multi-Dimensional Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaurav Shrivastava",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ning_PICTURE_PhotorealistIC_virtual_Try-on_from_UnconstRained_dEsigns_CVPR_2024_paper.html": {
    "title": "PICTURE: PhotorealistIC virtual Try-on from UnconstRained dEsigns",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuliang Ning",
      "Duomin Wang",
      "Yipeng Qin",
      "Zirong Jin",
      "Baoyuan Wang",
      "Xiaoguang Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_InfLoRA_Interference-Free_Low-Rank_Adaptation_for_Continual_Learning_CVPR_2024_paper.html": {
    "title": "InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan-Shuo Liang",
      "Wu-Jun Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Towards_Robust_3D_Pose_Transfer_with_Adversarial_Learning_CVPR_2024_paper.html": {
    "title": "Towards Robust 3D Pose Transfer with Adversarial Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Chen",
      "Hao Tang",
      "Ehsan Adeli",
      "Guoying Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Error_Detection_in_Egocentric_Procedural_Task_Videos_CVPR_2024_paper.html": {
    "title": "Error Detection in Egocentric Procedural Task Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shih-Po Lee",
      "Zijia Lu",
      "Zekun Zhang",
      "Minh Hoai",
      "Ehsan Elhamifar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_EAGLE_Eigen_Aggregation_Learning_for_Object-Centric_Unsupervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "EAGLE: Eigen Aggregation Learning for Object-Centric Unsupervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chanyoung Kim",
      "Woojung Han",
      "Dayun Ju",
      "Seong Jae Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_AVID_Any-Length_Video_Inpainting_with_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "AVID: Any-Length Video Inpainting with Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixing Zhang",
      "Bichen Wu",
      "Xiaoyan Wang",
      "Yaqiao Luo",
      "Luxin Zhang",
      "Yinan Zhao",
      "Peter Vajda",
      "Dimitris Metaxas",
      "Licheng Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shirakawa_NoiseCollage_A_Layout-Aware_Text-to-Image_Diffusion_Model_Based_on_Noise_Cropping_CVPR_2024_paper.html": {
    "title": "NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on Noise Cropping and Merging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takahiro Shirakawa",
      "Seiichi Uchida"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lai_Uncertainty-Guided_Never-Ending_Learning_to_Drive_CVPR_2024_paper.html": {
    "title": "Uncertainty-Guided Never-Ending Learning to Drive",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Lai",
      "Eshed Ohn-Bar",
      "Sanjay Arora",
      "John Seon Keun Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cazenavette_FakeInversion_Learning_to_Detect_Images_from_Unseen_Text-to-Image_Models_by_CVPR_2024_paper.html": {
    "title": "FakeInversion: Learning to Detect Images from Unseen Text-to-Image Models by Inverting Stable Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George Cazenavette",
      "Avneesh Sud",
      "Thomas Leung",
      "Ben Usman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_PLGSLAM_Progressive_Neural_Scene_Represenation_with_Local_to_Global_Bundle_CVPR_2024_paper.html": {
    "title": "PLGSLAM: Progressive Neural Scene Represenation with Local to Global Bundle Adjustment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianchen Deng",
      "Guole Shen",
      "Tong Qin",
      "Jianyu Wang",
      "Wentao Zhao",
      "Jingchuan Wang",
      "Danwei Wang",
      "Weidong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Multi-Task_Dense_Prediction_via_Mixture_of_Low-Rank_Experts_CVPR_2024_paper.html": {
    "title": "Multi-Task Dense Prediction via Mixture of Low-Rank Experts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Yang",
      "Peng-Tao Jiang",
      "Qibin Hou",
      "Hao Zhang",
      "Jinwei Chen",
      "Bo Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Binding_Touch_to_Everything_Learning_Unified_Multimodal_Tactile_Representations_CVPR_2024_paper.html": {
    "title": "Binding Touch to Everything: Learning Unified Multimodal Tactile Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengyu Yang",
      "Chao Feng",
      "Ziyang Chen",
      "Hyoungseob Park",
      "Daniel Wang",
      "Yiming Dou",
      "Ziyao Zeng",
      "Xien Chen",
      "Rit Gangopadhyay",
      "Andrew Owens",
      "Alex Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Attribute-Guided_Pedestrian_Retrieval_Bridging_Person_Re-ID_with_Internal_Attribute_Variability_CVPR_2024_paper.html": {
    "title": "Attribute-Guided Pedestrian Retrieval: Bridging Person Re-ID with Internal Attribute Variability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Huang",
      "Zhang Zhang",
      "Qiang Wu",
      "Yi Zhong",
      "Liang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Text_Is_MASS_Modeling_as_Stochastic_Embedding_for_Text-Video_Retrieval_CVPR_2024_paper.html": {
    "title": "Text Is MASS: Modeling as Stochastic Embedding for Text-Video Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiamian Wang",
      "Guohao Sun",
      "Pichao Wang",
      "Dongfang Liu",
      "Sohail Dianat",
      "Majid Rabbani",
      "Raghuveer Rao",
      "Zhiqiang Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_Your_Transferability_Barrier_is_Fragile_Free-Lunch_for_Transferring_the_Non-Transferable_CVPR_2024_paper.html": {
    "title": "Your Transferability Barrier is Fragile: Free-Lunch for Transferring the Non-Transferable Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziming Hong",
      "Li Shen",
      "Tongliang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Arbitrary_Motion_Style_Transfer_with_Multi-condition_Motion_Latent_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "Arbitrary Motion Style Transfer with Multi-condition Motion Latent Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenfeng Song",
      "Xingliang Jin",
      "Shuai Li",
      "Chenglizhao Chen",
      "Aimin Hao",
      "Xia Hou",
      "Ning Li",
      "Hong Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Know_Your_Neighbors_Improving_Single-View_Reconstruction_via_Spatial_Vision-Language_Reasoning_CVPR_2024_paper.html": {
    "title": "Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Li",
      "Tobias Fischer",
      "Mattia Segu",
      "Marc Pollefeys",
      "Luc Van Gool",
      "Federico Tombari"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Complementing_Event_Streams_and_RGB_Frames_for_Hand_Mesh_Reconstruction_CVPR_2024_paper.html": {
    "title": "Complementing Event Streams and RGB Frames for Hand Mesh Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianping Jiang",
      "Xinyu Zhou",
      "Bingxuan Wang",
      "Xiaoming Deng",
      "Chao Xu",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Empowering_Resampling_Operation_for_Ultra-High-Definition_Image_Enhancement_with_Model-Aware_Guidance_CVPR_2024_paper.html": {
    "title": "Empowering Resampling Operation for Ultra-High-Definition Image Enhancement with Model-Aware Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Yu",
      "Jie Huang",
      "Bing Li",
      "Kaiwen Zheng",
      "Qi Zhu",
      "Man Zhou",
      "Feng Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_ViT-CoMer_Vision_Transformer_with_Convolutional_Multi-scale_Feature_Interaction_for_Dense_CVPR_2024_paper.html": {
    "title": "ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunlong Xia",
      "Xinliang Wang",
      "Feng Lv",
      "Xin Hao",
      "Yifeng Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yao_PromptCoT_Align_Prompt_Distribution_via_Adapted_Chain-of-Thought_CVPR_2024_paper.html": {
    "title": "PromptCoT: Align Prompt Distribution via Adapted Chain-of-Thought",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Yao",
      "Yijiang Liu",
      "Zhen Dong",
      "Mingfei Guo",
      "Helan Hu",
      "Kurt Keutzer",
      "Li Du",
      "Daquan Zhou",
      "Shanghang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Hallucination_Augmented_Contrastive_Learning_for_Multimodal_Large_Language_Model_CVPR_2024_paper.html": {
    "title": "Hallucination Augmented Contrastive Learning for Multimodal Large Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoya Jiang",
      "Haiyang Xu",
      "Mengfan Dong",
      "Jiaxing Chen",
      "Wei Ye",
      "Ming Yan",
      "Qinghao Ye",
      "Ji Zhang",
      "Fei Huang",
      "Shikun Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Preserving_Fairness_Generalization_in_Deepfake_Detection_CVPR_2024_paper.html": {
    "title": "Preserving Fairness Generalization in Deepfake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Lin",
      "Xinan He",
      "Yan Ju",
      "Xin Wang",
      "Feng Ding",
      "Shu Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hwang_Anomaly_Score_Evaluating_Generative_Models_and_Individual_Generated_Images_based_CVPR_2024_paper.html": {
    "title": "Anomaly Score: Evaluating Generative Models and Individual Generated Images based on Complexity and Vulnerability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaehui Hwang",
      "Junghyuk Lee",
      "Jong-Seok Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Structure-Aware_Sparse-View_X-ray_3D_Reconstruction_CVPR_2024_paper.html": {
    "title": "Structure-Aware Sparse-View X-ray 3D Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanhao Cai",
      "Jiahao Wang",
      "Alan Yuille",
      "Zongwei Zhou",
      "Angtian Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Dexterous_Grasp_Transformer_CVPR_2024_paper.html": {
    "title": "Dexterous Grasp Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guo-Hao Xu",
      "Yi-Lin Wei",
      "Dian Zheng",
      "Xiao-Ming Wu",
      "Wei-Shi Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Cooperation_Does_Matter_Exploring_Multi-Order_Bilateral_Relations_for_Audio-Visual_Segmentation_CVPR_2024_paper.html": {
    "title": "Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for Audio-Visual Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Yang",
      "Xing Nie",
      "Tong Li",
      "Pengfei Gao",
      "Ying Guo",
      "Cheng Zhen",
      "Pengfei Yan",
      "Shiming Xiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_EgoThink_Evaluating_First-Person_Perspective_Thinking_Capability_of_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijie Cheng",
      "Zhicheng Guo",
      "Jingwen Wu",
      "Kechen Fang",
      "Peng Li",
      "Huaping Liu",
      "Yang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Hearing_Anything_Anywhere_CVPR_2024_paper.html": {
    "title": "Hearing Anything Anywhere",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mason Long Wang",
      "Ryosuke Sawata",
      "Samuel Clarke",
      "Ruohan Gao",
      "Shangzhe Wu",
      "Jiajun Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_PatchFusion_An_End-to-End_Tile-Based_Framework_for_High-Resolution_Monocular_Metric_Depth_CVPR_2024_paper.html": {
    "title": "PatchFusion: An End-to-End Tile-Based Framework for High-Resolution Monocular Metric Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Li",
      "Shariq Farooq Bhat",
      "Peter Wonka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bao_GeneAvatar_Generic_Expression-Aware_Volumetric_Head_Avatar_Editing_from_a_Single_CVPR_2024_paper.html": {
    "title": "GeneAvatar: Generic Expression-Aware Volumetric Head Avatar Editing from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Bao",
      "Yinda Zhang",
      "Yuan Li",
      "Xiyu Zhang",
      "Bangbang Yang",
      "Hujun Bao",
      "Marc Pollefeys",
      "Guofeng Zhang",
      "Zhaopeng Cui"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Improved_Self-Training_for_Test-Time_Adaptation_CVPR_2024_paper.html": {
    "title": "Improved Self-Training for Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Learn_to_Rectify_the_Bias_of_CLIP_for_Unsupervised_Semantic_CVPR_2024_paper.html": {
    "title": "Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyun Wang",
      "Guoliang Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Unsupervised_Feature_Learning_with_Emergent_Data-Driven_Prototypicality_CVPR_2024_paper.html": {
    "title": "Unsupervised Feature Learning with Emergent Data-Driven Prototypicality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhui Guo",
      "Youren Zhang",
      "Yubei Chen",
      "Stella X. Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ifriqi_Unlocking_Pre-trained_Image_Backbones_for_Semantic_Image_Synthesis_CVPR_2024_paper.html": {
    "title": "Unlocking Pre-trained Image Backbones for Semantic Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tariq Berrada Ifriqi",
      "Jakob Verbeek",
      "Camille Couprie",
      "Karteek Alahari"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Retrieval-Augmented_Egocentric_Video_Captioning_CVPR_2024_paper.html": {
    "title": "Retrieval-Augmented Egocentric Video Captioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jilan Xu",
      "Yifei Huang",
      "Junlin Hou",
      "Guo Chen",
      "Yuejie Zhang",
      "Rui Feng",
      "Weidi Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_SkillDiffuser_Interpretable_Hierarchical_Planning_via_Skill_Abstractions_in_Diffusion-Based_Task_CVPR_2024_paper.html": {
    "title": "SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixuan Liang",
      "Yao Mu",
      "Hengbo Ma",
      "Masayoshi Tomizuka",
      "Mingyu Ding",
      "Ping Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Improving_Generalized_Zero-Shot_Learning_by_Exploring_the_Diverse_Semantics_from_CVPR_2024_paper.html": {
    "title": "Improving Generalized Zero-Shot Learning by Exploring the Diverse Semantics from External Class Names",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yapeng Li",
      "Yong Luo",
      "Zengmao Wang",
      "Bo Du"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_TeMO_Towards_Text-Driven_3D_Stylization_for_Multi-Object_Meshes_CVPR_2024_paper.html": {
    "title": "TeMO: Towards Text-Driven 3D Stylization for Multi-Object Meshes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuying Zhang",
      "Bo-Wen Yin",
      "Yuming Chen",
      "Zheng Lin",
      "Yunheng Li",
      "Qibin Hou",
      "Ming-Ming Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_TE-TAD_Towards_Full_End-to-End_Temporal_Action_Detection_via_Time-Aligned_Coordinate_CVPR_2024_paper.html": {
    "title": "TE-TAD: Towards Full End-to-End Temporal Action Detection via Time-Aligned Coordinate Expression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ho-Joong Kim",
      "Jung-Ho Hong",
      "Heejo Kong",
      "Seong-Whan Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chou_GSNeRF_Generalizable_Semantic_Neural_Radiance_Fields_with_Enhanced_3D_Scene_CVPR_2024_paper.html": {
    "title": "GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zi-Ting Chou",
      "Sheng-Yu Huang",
      "I-Jieh Liu",
      "Yu-Chiang Frank Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ahn_Alpha_Invariance_On_Inverse_Scaling_Between_Distance_and_Volume_Density_CVPR_2024_paper.html": {
    "title": "Alpha Invariance: On Inverse Scaling Between Distance and Volume Density in Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua Ahn",
      "Haochen Wang",
      "Raymond A. Yeh",
      "Greg Shakhnarovich"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rodriguez-Pardo_TexTile_A_Differentiable_Metric_for_Texture_Tileability_CVPR_2024_paper.html": {
    "title": "TexTile: A Differentiable Metric for Texture Tileability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carlos Rodriguez-Pardo",
      "Dan Casas",
      "Elena Garces",
      "Jorge Lopez-Moreno"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Phat_D3T_Distinctive_Dual-Domain_Teacher_Zigzagging_Across_RGB-Thermal_Gap_for_Domain-Adaptive_CVPR_2024_paper.html": {
    "title": "D3T: Distinctive Dual-Domain Teacher Zigzagging Across RGB-Thermal Gap for Domain-Adaptive Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dinh Phat Do",
      "Taehoon Kim",
      "Jaemin Na",
      "Jiwon Kim",
      "Keonho Lee",
      "Kyunghwan Cho",
      "Wonjun Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Long_Positive-Unlabeled_Learning_by_Latent_Group-Aware_Meta_Disambiguation_CVPR_2024_paper.html": {
    "title": "Positive-Unlabeled Learning by Latent Group-Aware Meta Disambiguation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Long",
      "Haobo Wang",
      "Zhijie Jiang",
      "Lei Feng",
      "Chang Yao",
      "Gang Chen",
      "Junbo Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Improving_Image_Restoration_through_Removing_Degradations_in_Textual_Representations_CVPR_2024_paper.html": {
    "title": "Improving Image Restoration through Removing Degradations in Textual Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingbo Lin",
      "Zhilu Zhang",
      "Yuxiang Wei",
      "Dongwei Ren",
      "Dongsheng Jiang",
      "Qi Tian",
      "Wangmeng Zuo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_ZONE_Zero-Shot_Instruction-Guided_Local_Editing_CVPR_2024_paper.html": {
    "title": "ZONE: Zero-Shot Instruction-Guided Local Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanglin Li",
      "Bohan Zeng",
      "Yutang Feng",
      "Sicheng Gao",
      "Xiuhui Liu",
      "Jiaming Liu",
      "Lin Li",
      "Xu Tang",
      "Yao Hu",
      "Jianzhuang Liu",
      "Baochang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_U-VAP_User-specified_Visual_Appearance_Personalization_via_Decoupled_Self_Augmentation_CVPR_2024_paper.html": {
    "title": "U-VAP: User-specified Visual Appearance Personalization via Decoupled Self Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "You Wu",
      "Kean Liu",
      "Xiaoyue Mi",
      "Fan Tang",
      "Juan Cao",
      "Jintao Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chambon_PointBeV_A_Sparse_Approach_for_BeV_Predictions_CVPR_2024_paper.html": {
    "title": "PointBeV: A Sparse Approach for BeV Predictions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Loick Chambon",
      "Eloi Zablocki",
      "Mickaël Chen",
      "Florent Bartoccioni",
      "Patrick Pérez",
      "Matthieu Cord"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Moon_From-Ground-To-Objects_Coarse-to-Fine_Self-supervised_Monocular_Depth_Estimation_of_Dynamic_Objects_with_CVPR_2024_paper.html": {
    "title": "From-Ground-To-Objects: Coarse-to-Fine Self-supervised Monocular Depth Estimation of Dynamic Objects with Ground Contact Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeho Moon",
      "Juan Luis Gonzalez Bello",
      "Byeongjun Kwon",
      "Munchurl Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Linguistic-Aware_Patch_Slimming_Framework_for_Fine-grained_Cross-Modal_Alignment_CVPR_2024_paper.html": {
    "title": "Linguistic-Aware Patch Slimming Framework for Fine-grained Cross-Modal Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheren Fu",
      "Lei Zhang",
      "Hou Xia",
      "Zhendong Mao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_HHMR_Holistic_Hand_Mesh_Recovery_by_Enhancing_the_Multimodal_Controllability_CVPR_2024_paper.html": {
    "title": "HHMR: Holistic Hand Mesh Recovery by Enhancing the Multimodal Controllability of Graph Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengcheng Li",
      "Hongwen Zhang",
      "Yuxiang Zhang",
      "Ruizhi Shao",
      "Tao Yu",
      "Yebin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_SRTube_Video-Language_Pre-Training_with_Action-Centric_Video_Tube_Features_and_Semantic_CVPR_2024_paper.html": {
    "title": "SRTube: Video-Language Pre-Training with Action-Centric Video Tube Features and Semantic Role Labeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ju-Hee Lee",
      "Je-Won Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Prompt_Highlighter_Interactive_Control_for_Multi-Modal_LLMs_CVPR_2024_paper.html": {
    "title": "Prompt Highlighter: Interactive Control for Multi-Modal LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuechen Zhang",
      "Shengju Qian",
      "Bohao Peng",
      "Shu Liu",
      "Jiaya Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Su_Domain-Rectifying_Adapter_for_Cross-Domain_Few-Shot_Segmentation_CVPR_2024_paper.html": {
    "title": "Domain-Rectifying Adapter for Cross-Domain Few-Shot Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiapeng Su",
      "Qi Fan",
      "Wenjie Pei",
      "Guangming Lu",
      "Fanglin Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kocur_Robust_Self-calibration_of_Focal_Lengths_from_the_Fundamental_Matrix_CVPR_2024_paper.html": {
    "title": "Robust Self-calibration of Focal Lengths from the Fundamental Matrix",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Viktor Kocur",
      "Daniel Kyselica",
      "Zuzana Kukelova"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kang_Continual_Learning_for_Motion_Prediction_Model_via_Meta-Representation_Learning_and_CVPR_2024_paper.html": {
    "title": "Continual Learning for Motion Prediction Model via Meta-Representation Learning and Optimal Memory Buffer Retention Strategy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "DaeJun Kang",
      "Dongsuk Kum",
      "Sanmin Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Umam_PartDistill_3D_Shape_Part_Segmentation_by_Vision-Language_Model_Distillation_CVPR_2024_paper.html": {
    "title": "PartDistill: 3D Shape Part Segmentation by Vision-Language Model Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ardian Umam",
      "Cheng-Kun Yang",
      "Min-Hung Chen",
      "Jen-Hui Chuang",
      "Yen-Yu Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_CPP-Net_Embracing_Multi-Scale_Feature_Fusion_into_Deep_Unfolding_CP-PPA_Network_CVPR_2024_paper.html": {
    "title": "CPP-Net: Embracing Multi-Scale Feature Fusion into Deep Unfolding CP-PPA Network for Compressive Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Guo",
      "Hongping Gan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_EditGuard_Versatile_Image_Watermarking_for_Tamper_Localization_and_Copyright_Protection_CVPR_2024_paper.html": {
    "title": "EditGuard: Versatile Image Watermarking for Tamper Localization and Copyright Protection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanyu Zhang",
      "Runyi Li",
      "Jiwen Yu",
      "Youmin Xu",
      "Weiqi Li",
      "Jian Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_3DGStream_On-the-Fly_Training_of_3D_Gaussians_for_Efficient_Streaming_of_CVPR_2024_paper.html": {
    "title": "3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming of Photo-Realistic Free-Viewpoint Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiakai Sun",
      "Han Jiao",
      "Guangyuan Li",
      "Zhanjie Zhang",
      "Lei Zhao",
      "Wei Xing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shrestha_FairRAG_Fair_Human_Generation_via_Fair_Retrieval_Augmentation_CVPR_2024_paper.html": {
    "title": "FairRAG: Fair Human Generation via Fair Retrieval Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robik Shrestha",
      "Yang Zou",
      "Qiuyu Chen",
      "Zhiheng Li",
      "Yusheng Xie",
      "Siqi Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_DragDiffusion_Harnessing_Diffusion_Models_for_Interactive_Point-based_Image_Editing_CVPR_2024_paper.html": {
    "title": "DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujun Shi",
      "Chuhui Xue",
      "Jun Hao Liew",
      "Jiachun Pan",
      "Hanshu Yan",
      "Wenqing Zhang",
      "Vincent Y. F. Tan",
      "Song Bai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Aneja_FaceTalk_Audio-Driven_Motion_Diffusion_for_Neural_Parametric_Head_Models_CVPR_2024_paper.html": {
    "title": "FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivangi Aneja",
      "Justus Thies",
      "Angela Dai",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Mip-Splatting_Alias-free_3D_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "Mip-Splatting: Alias-free 3D Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehao Yu",
      "Anpei Chen",
      "Binbin Huang",
      "Torsten Sattler",
      "Andreas Geiger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Learning_Coupled_Dictionaries_from_Unpaired_Data_for_Image_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Learning Coupled Dictionaries from Unpaired Data for Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longguang Wang",
      "Juncheng Li",
      "Yingqian Wang",
      "Qingyong Hu",
      "Yulan Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Template_Free_Reconstruction_of_Human-object_Interaction_with_Procedural_Interaction_Generation_CVPR_2024_paper.html": {
    "title": "Template Free Reconstruction of Human-object Interaction with Procedural Interaction Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianghui Xie",
      "Bharat Lal Bhatnagar",
      "Jan Eric Lenssen",
      "Gerard Pons-Moll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Deep_Video_Inverse_Tone_Mapping_Based_on_Temporal_Clues_CVPR_2024_paper.html": {
    "title": "Deep Video Inverse Tone Mapping Based on Temporal Clues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyao Ye",
      "Ning Zhang",
      "Yang Zhao",
      "Hongbin Cao",
      "Ronggang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_NeRF-HuGS_Improved_Neural_Radiance_Fields_in_Non-static_Scenes_Using_Heuristics-Guided_CVPR_2024_paper.html": {
    "title": "NeRF-HuGS: Improved Neural Radiance Fields in Non-static Scenes Using Heuristics-Guided Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Chen",
      "Yipeng Qin",
      "Lingjie Liu",
      "Jiangbo Lu",
      "Guanbin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Addressing_Background_Context_Bias_in_Few-Shot_Segmentation_through_Iterative_Modulation_CVPR_2024_paper.html": {
    "title": "Addressing Background Context Bias in Few-Shot Segmentation through Iterative Modulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lanyun Zhu",
      "Tianrun Chen",
      "Jianxiong Yin",
      "Simon See",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Open-Vocabulary_Video_Anomaly_Detection_CVPR_2024_paper.html": {
    "title": "Open-Vocabulary Video Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Wu",
      "Xuerong Zhou",
      "Guansong Pang",
      "Yujia Sun",
      "Jing Liu",
      "Peng Wang",
      "Yanning Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Duan_ODM_A_Text-Image_Further_Alignment_Pre-training_Approach_for_Scene_Text_CVPR_2024_paper.html": {
    "title": "ODM: A Text-Image Further Alignment Pre-training Approach for Scene Text Detection and Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Duan",
      "Pei Fu",
      "Shan Guo",
      "Qianyi Jiang",
      "Xiaoming Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_TiNO-Edit_Timestep_and_Noise_Optimization_for_Robust_Diffusion-Based_Image_Editing_CVPR_2024_paper.html": {
    "title": "TiNO-Edit: Timestep and Noise Optimization for Robust Diffusion-Based Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sherry X Chen",
      "Yaron Vaxman",
      "Elad Ben Baruch",
      "David Asulin",
      "Aviad Moreshet",
      "Kuo-Chin Lien",
      "Misha Sra",
      "Pradeep Sen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Epistemic_Uncertainty_Quantification_For_Pre-Trained_Neural_Networks_CVPR_2024_paper.html": {
    "title": "Epistemic Uncertainty Quantification For Pre-Trained Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanjing Wang",
      "Qiang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Diffusion-ES_Gradient-free_Planning_with_Diffusion_for_Autonomous_and_Instruction-guided_Driving_CVPR_2024_paper.html": {
    "title": "Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous and Instruction-guided Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brian Yang",
      "Huangyuan Su",
      "Nikolaos Gkanatsios",
      "Tsung-Wei Ke",
      "Ayush Jain",
      "Jeff Schneider",
      "Katerina Fragkiadaki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_AdaShift_Learning_Discriminative_Self-Gated_Neural_Feature_Activation_With_an_Adaptive_CVPR_2024_paper.html": {
    "title": "AdaShift: Learning Discriminative Self-Gated Neural Feature Activation With an Adaptive Shift Factor",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sudong Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_SCEdit_Efficient_and_Controllable_Image_Diffusion_Generation_via_Skip_Connection_CVPR_2024_paper.html": {
    "title": "SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeyinzi Jiang",
      "Chaojie Mao",
      "Yulin Pan",
      "Zhen Han",
      "Jingfeng Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_MRC-Net_6-DoF_Pose_Estimation_with_MultiScale_Residual_Correlation_CVPR_2024_paper.html": {
    "title": "MRC-Net: 6-DoF Pose Estimation with MultiScale Residual Correlation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuelong Li",
      "Yafei Mao",
      "Raja Bala",
      "Sunil Hadap"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_MonoCD_Monocular_3D_Object_Detection_with_Complementary_Depths_CVPR_2024_paper.html": {
    "title": "MonoCD: Monocular 3D Object Detection with Complementary Depths",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longfei Yan",
      "Pei Yan",
      "Shengzhou Xiong",
      "Xuanyu Xiang",
      "Yihua Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_ImageNet-D_Benchmarking_Neural_Network_Robustness_on_Diffusion_Synthetic_Object_CVPR_2024_paper.html": {
    "title": "ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenshuang Zhang",
      "Fei Pan",
      "Junmo Kim",
      "In So Kweon",
      "Chengzhi Mao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Consistent3D_Towards_Consistent_High-Fidelity_Text-to-3D_Generation_with_Deterministic_Sampling_Prior_CVPR_2024_paper.html": {
    "title": "Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zike Wu",
      "Pan Zhou",
      "Xuanyu Yi",
      "Xiaoding Yuan",
      "Hanwang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_ManipLLM_Embodied_Multimodal_Large_Language_Model_for_Object-Centric_Robotic_Manipulation_CVPR_2024_paper.html": {
    "title": "ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqi Li",
      "Mingxu Zhang",
      "Yiran Geng",
      "Haoran Geng",
      "Yuxing Long",
      "Yan Shen",
      "Renrui Zhang",
      "Jiaming Liu",
      "Hao Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_BA-SAM_Scalable_Bias-Mode_Attention_Mask_for_Segment_Anything_Model_CVPR_2024_paper.html": {
    "title": "BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiran Song",
      "Qianyu Zhou",
      "Xiangtai Li",
      "Deng-Ping Fan",
      "Xuequan Lu",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tran_Text-Enhanced_Data-free_Approach_for_Federated_Class-Incremental_Learning_CVPR_2024_paper.html": {
    "title": "Text-Enhanced Data-free Approach for Federated Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minh-Tuan Tran",
      "Trung Le",
      "Xuan-May Le",
      "Mehrtash Harandi",
      "Dinh Phung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Deciphering_What_and_Where_Visual_Pathways_from_Spectral_Clustering_of_CVPR_2024_paper.html": {
    "title": "Deciphering 'What' and 'Where' Visual Pathways from Spectral Clustering of Layer-Distributed Neural Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Zhang",
      "David Yunis",
      "Michael Maire"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rasheed_GLaMM_Pixel_Grounding_Large_Multimodal_Model_CVPR_2024_paper.html": {
    "title": "GLaMM: Pixel Grounding Large Multimodal Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanoona Rasheed",
      "Muhammad Maaz",
      "Sahal Shaji",
      "Abdelrahman Shaker",
      "Salman Khan",
      "Hisham Cholakkal",
      "Rao M. Anwer",
      "Eric Xing",
      "Ming-Hsuan Yang",
      "Fahad S. Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shang_Incremental_Residual_Concept_Bottleneck_Models_CVPR_2024_paper.html": {
    "title": "Incremental Residual Concept Bottleneck Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenming Shang",
      "Shiji Zhou",
      "Hengyuan Zhang",
      "Xinzhe Ni",
      "Yujiu Yang",
      "Yuwang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ehsani_SPOC_Imitating_Shortest_Paths_in_Simulation_Enables_Effective_Navigation_and_CVPR_2024_paper.html": {
    "title": "SPOC: Imitating Shortest Paths in Simulation Enables Effective Navigation and Manipulation in the Real World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiana Ehsani",
      "Tanmay Gupta",
      "Rose Hendrix",
      "Jordi Salvador",
      "Luca Weihs",
      "Kuo-Hao Zeng",
      "Kunal Pratap Singh",
      "Yejin Kim",
      "Winson Han",
      "Alvaro Herrasti",
      "Ranjay Krishna",
      "Dustin Schwenk",
      "Eli VanderBilt",
      "Aniruddha Kembhavi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Real-Time_Exposure_Correction_via_Collaborative_Transformations_and_Adaptive_Sampling_CVPR_2024_paper.html": {
    "title": "Real-Time Exposure Correction via Collaborative Transformations and Adaptive Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziwen Li",
      "Feng Zhang",
      "Meng Cao",
      "Jinpu Zhang",
      "Yuanjie Shao",
      "Yuehuan Wang",
      "Nong Sang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Lodge_A_Coarse_to_Fine_Diffusion_Network_for_Long_Dance_CVPR_2024_paper.html": {
    "title": "Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation Guided by the Characteristic Dance Primitives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ronghui Li",
      "YuXiang Zhang",
      "Yachao Zhang",
      "Hongwen Zhang",
      "Jie Guo",
      "Yan Zhang",
      "Yebin Liu",
      "Xiu Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_UDiFF_Generating_Conditional_Unsigned_Distance_Fields_with_Optimal_Wavelet_Diffusion_CVPR_2024_paper.html": {
    "title": "UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junsheng Zhou",
      "Weiqi Zhang",
      "Baorui Ma",
      "Kanle Shi",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_LoCoNet_Long-Short_Context_Network_for_Active_Speaker_Detection_CVPR_2024_paper.html": {
    "title": "LoCoNet: Long-Short Context Network for Active Speaker Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xizi Wang",
      "Feng Cheng",
      "Gedas Bertasius"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_D3still_Decoupled_Differential_Distillation_for_Asymmetric_Image_Retrieval_CVPR_2024_paper.html": {
    "title": "D3still: Decoupled Differential Distillation for Asymmetric Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Xie",
      "Yihong Lin",
      "Wenjie Cai",
      "Xuemiao Xu",
      "Huaidong Zhang",
      "Yong Du",
      "Shengfeng He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Transcending_Forgery_Specificity_with_Latent_Space_Augmentation_for_Generalizable_Deepfake_CVPR_2024_paper.html": {
    "title": "Transcending Forgery Specificity with Latent Space Augmentation for Generalizable Deepfake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Yan",
      "Yuhao Luo",
      "Siwei Lyu",
      "Qingshan Liu",
      "Baoyuan Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Scaling_Laws_of_Synthetic_Images_for_Model_Training_..._for_CVPR_2024_paper.html": {
    "title": "Scaling Laws of Synthetic Images for Model Training ... for Now",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lijie Fan",
      "Kaifeng Chen",
      "Dilip Krishnan",
      "Dina Katabi",
      "Phillip Isola",
      "Yonglong Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Towards_Large-scale_3D_Representation_Learning_with_Multi-dataset_Point_Prompt_Training_CVPR_2024_paper.html": {
    "title": "Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Wu",
      "Zhuotao Tian",
      "Xin Wen",
      "Bohao Peng",
      "Xihui Liu",
      "Kaicheng Yu",
      "Hengshuang Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Learning_Triangular_Distribution_in_Visual_World_CVPR_2024_paper.html": {
    "title": "Learning Triangular Distribution in Visual World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ping Chen",
      "Xingpeng Zhang",
      "Chengtao Zhou",
      "Dichao Fan",
      "Peng Tu",
      "Le Zhang",
      "Yanlin Qian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zubic_State_Space_Models_for_Event_Cameras_CVPR_2024_paper.html": {
    "title": "State Space Models for Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikola Zubic",
      "Mathias Gehrig",
      "Davide Scaramuzza"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_EmbodiedScan_A_Holistic_Multi-Modal_3D_Perception_Suite_Towards_Embodied_AI_CVPR_2024_paper.html": {
    "title": "EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tai Wang",
      "Xiaohan Mao",
      "Chenming Zhu",
      "Runsen Xu",
      "Ruiyuan Lyu",
      "Peisen Li",
      "Xiao Chen",
      "Wenwei Zhang",
      "Kai Chen",
      "Tianfan Xue",
      "Xihui Liu",
      "Cewu Lu",
      "Dahua Lin",
      "Jiangmiao Pang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Engelhardt_SHINOBI_Shape_and_Illumination_using_Neural_Object_Decomposition_via_BRDF_CVPR_2024_paper.html": {
    "title": "SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Engelhardt",
      "Amit Raj",
      "Mark Boss",
      "Yunzhi Zhang",
      "Abhishek Kar",
      "Yuanzhen Li",
      "Deqing Sun",
      "Ricardo Martin Brualla",
      "Jonathan T. Barron",
      "Hendrik P. A. Lensch",
      "Varun Jampani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_ES3_Evolving_Self-Supervised_Learning_of_Robust_Audio-Visual_Speech_Representations_CVPR_2024_paper.html": {
    "title": "ES3: Evolving Self-Supervised Learning of Robust Audio-Visual Speech Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanhang Zhang",
      "Shuang Yang",
      "Shiguang Shan",
      "Xilin Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_TeTriRF_Temporal_Tri-Plane_Radiance_Fields_for_Efficient_Free-Viewpoint_Video_CVPR_2024_paper.html": {
    "title": "TeTriRF: Temporal Tri-Plane Radiance Fields for Efficient Free-Viewpoint Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minye Wu",
      "Zehao Wang",
      "Georgios Kouros",
      "Tinne Tuytelaars"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Motion2VecSets_4D_Latent_Vector_Set_Diffusion_for_Non-rigid_Shape_Reconstruction_CVPR_2024_paper.html": {
    "title": "Motion2VecSets: 4D Latent Vector Set Diffusion for Non-rigid Shape Reconstruction and Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Cao",
      "Chang Luo",
      "Biao Zhang",
      "Matthias Nießner",
      "Jiapeng Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_DiaLoc_An_Iterative_Approach_to_Embodied_Dialog_Localization_CVPR_2024_paper.html": {
    "title": "DiaLoc: An Iterative Approach to Embodied Dialog Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Zhang",
      "Mohan Li",
      "Ignas Budvytis",
      "Stephan Liwicki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Khan_Self-Training_Large_Language_Models_for_Improved_Visual_Program_Synthesis_With_CVPR_2024_paper.html": {
    "title": "Self-Training Large Language Models for Improved Visual Program Synthesis With Visual Reinforcement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zaid Khan",
      "Vijay Kumar BG",
      "Samuel Schulter",
      "Yun Fu",
      "Manmohan Chandraker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_A2XP_Towards_Private_Domain_Generalization_CVPR_2024_paper.html": {
    "title": "A2XP: Towards Private Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geunhyeok Yu",
      "Hyoseok Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Event-assisted_Low-Light_Video_Object_Segmentation_CVPR_2024_paper.html": {
    "title": "Event-assisted Low-Light Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hebei Li",
      "Jin Wang",
      "Jiahui Yuan",
      "Yue Li",
      "Wenming Weng",
      "Yansong Peng",
      "Yueyi Zhang",
      "Zhiwei Xiong",
      "Xiaoyan Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nakamura_Active_Domain_Adaptation_with_False_Negative_Prediction_for_Object_Detection_CVPR_2024_paper.html": {
    "title": "Active Domain Adaptation with False Negative Prediction for Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzuru Nakamura",
      "Yasunori Ishii",
      "Takayoshi Yamashita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_MLIP_Enhancing_Medical_Visual_Representation_with_Divergence_Encoder_and_Knowledge-guided_CVPR_2024_paper.html": {
    "title": "MLIP: Enhancing Medical Visual Representation with Divergence Encoder and Knowledge-guided Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Li",
      "Laurence T. Yang",
      "Bocheng Ren",
      "Xin Nie",
      "Zhangyang Gao",
      "Cheng Tan",
      "Stan Z. Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Du_Generative_3D_Part_Assembly_via_Part-Whole-Hierarchy_Message_Passing_CVPR_2024_paper.html": {
    "title": "Generative 3D Part Assembly via Part-Whole-Hierarchy Message Passing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bi'an Du",
      "Xiang Gao",
      "Wei Hu",
      "Renjie Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_VidToMe_Video_Token_Merging_for_Zero-Shot_Video_Editing_CVPR_2024_paper.html": {
    "title": "VidToMe: Video Token Merging for Zero-Shot Video Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xirui Li",
      "Chao Ma",
      "Xiaokang Yang",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qiao_FaceChain-SuDe_Building_Derived_Class_to_Inherit_Category_Attributes_for_One-shot_CVPR_2024_paper.html": {
    "title": "FaceChain-SuDe: Building Derived Class to Inherit Category Attributes for One-shot Subject-Driven Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengchong Qiao",
      "Lei Shang",
      "Chang Liu",
      "Baigui Sun",
      "Xiangyang Ji",
      "Jie Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_Benchmarking_Segmentation_Models_with_Mask-Preserved_Attribute_Editing_CVPR_2024_paper.html": {
    "title": "Benchmarking Segmentation Models with Mask-Preserved Attribute Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijin Yin",
      "Kongming Liang",
      "Bing Li",
      "Zhanyu Ma",
      "Jun Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Karras_Analyzing_and_Improving_the_Training_Dynamics_of_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Analyzing and Improving the Training Dynamics of Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tero Karras",
      "Miika Aittala",
      "Jaakko Lehtinen",
      "Janne Hellsten",
      "Timo Aila",
      "Samuli Laine"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chehreghani_Hierarchical_Correlation_Clustering_and_Tree_Preserving_Embedding_CVPR_2024_paper.html": {
    "title": "Hierarchical Correlation Clustering and Tree Preserving Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Morteza Haghir Chehreghani",
      "Mostafa Haghir Chehreghani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_StableVITON_Learning_Semantic_Correspondence_with_Latent_Diffusion_Model_for_Virtual_CVPR_2024_paper.html": {
    "title": "StableVITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeongho Kim",
      "Guojung Gu",
      "Minho Park",
      "Sunghyun Park",
      "Jaegul Choo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Can_Protective_Perturbation_Safeguard_Personal_Data_from_Being_Exploited_by_CVPR_2024_paper.html": {
    "title": "Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengyue Zhao",
      "Jinhao Duan",
      "Kaidi Xu",
      "Chenan Wang",
      "Rui Zhang",
      "Zidong Du",
      "Qi Guo",
      "Xing Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Make-Your-Anchor_A_Diffusion-based_2D_Avatar_Generation_Framework_CVPR_2024_paper.html": {
    "title": "Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyao Huang",
      "Fan Tang",
      "Yong Zhang",
      "Xiaodong Cun",
      "Juan Cao",
      "Jintao Li",
      "Tong-Yee Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_MultiPLY_A_Multisensory_Object-Centric_Embodied_Large_Language_Model_in_3D_CVPR_2024_paper.html": {
    "title": "MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in 3D World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yining Hong",
      "Zishuo Zheng",
      "Peihao Chen",
      "Yian Wang",
      "Junyan Li",
      "Chuang Gan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Learning_to_Visually_Localize_Sound_Sources_from_Mixtures_without_Prior_CVPR_2024_paper.html": {
    "title": "Learning to Visually Localize Sound Sources from Mixtures without Prior Source Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongjin Kim",
      "Sung Jin Um",
      "Sangmin Lee",
      "Jung Uk Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Learning_Dynamic_Tetrahedra_for_High-Quality_Talking_Head_Synthesis_CVPR_2024_paper.html": {
    "title": "Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zicheng Zhang",
      "Ruobing Zheng",
      "Bonan Li",
      "Congying Han",
      "Tianqi Li",
      "Meng Wang",
      "Tiande Guo",
      "Jingdong Chen",
      "Ziwen Liu",
      "Ming Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Al-lahham_Collaborative_Learning_of_Anomalies_with_Privacy_CLAP_for_Unsupervised_Video_CVPR_2024_paper.html": {
    "title": "Collaborative Learning of Anomalies with Privacy (CLAP) for Unsupervised Video Anomaly Detection: A New Baseline",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anas Al-lahham",
      "Muhammad Zaigham Zaheer",
      "Nurbek Tastan",
      "Karthik Nandakumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Regressor-Segmenter_Mutual_Prompt_Learning_for_Crowd_Counting_CVPR_2024_paper.html": {
    "title": "Regressor-Segmenter Mutual Prompt Learning for Crowd Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyue Guo",
      "Li Yuan",
      "Zhaoyi Yan",
      "Binghui Chen",
      "Yaowei Wang",
      "Qixiang Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Instantaneous_Perception_of_Moving_Objects_in_3D_CVPR_2024_paper.html": {
    "title": "Instantaneous Perception of Moving Objects in 3D",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Liu",
      "Bingbing Zhuang",
      "Dimitris N. Metaxas",
      "Manmohan Chandraker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yoon_CORE-MPI_Consistency_Object_Removal_with_Embedding_MultiPlane_Image_CVPR_2024_paper.html": {
    "title": "CORE-MPI: Consistency Object Removal with Embedding MultiPlane Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Donggeun Yoon",
      "Donghyeon Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_3D_Geometry-Aware_Deformable_Gaussian_Splatting_for_Dynamic_View_Synthesis_CVPR_2024_paper.html": {
    "title": "3D Geometry-Aware Deformable Gaussian Splatting for Dynamic View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicheng Lu",
      "Xiang Guo",
      "Le Hui",
      "Tianrui Chen",
      "Min Yang",
      "Xiao Tang",
      "Feng Zhu",
      "Yuchao Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Person-in-WiFi_3D_End-to-End_Multi-Person_3D_Pose_Estimation_with_Wi-Fi_CVPR_2024_paper.html": {
    "title": "Person-in-WiFi 3D: End-to-End Multi-Person 3D Pose Estimation with Wi-Fi",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangwei Yan",
      "Fei Wang",
      "Bo Qian",
      "Han Ding",
      "Jinsong Han",
      "Xing Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Backpropagation-free_Network_for_3D_Test-time_Adaptation_CVPR_2024_paper.html": {
    "title": "Backpropagation-free Network for 3D Test-time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanshuo Wang",
      "Ali Cheraghian",
      "Zeeshan Hayder",
      "Jie Hong",
      "Sameera Ramasinghe",
      "Shafin Rahman",
      "David Ahmedt-Aristizabal",
      "Xuesong Li",
      "Lars Petersson",
      "Mehrtash Harandi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ilhan_Resource-Efficient_Transformer_Pruning_for_Finetuning_of_Large_Models_CVPR_2024_paper.html": {
    "title": "Resource-Efficient Transformer Pruning for Finetuning of Large Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fatih Ilhan",
      "Gong Su",
      "Selim Furkan Tekin",
      "Tiansheng Huang",
      "Sihao Hu",
      "Ling Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_ParamISP_Learned_Forward_and_Inverse_ISPs_using_Camera_Parameters_CVPR_2024_paper.html": {
    "title": "ParamISP: Learned Forward and Inverse ISPs using Camera Parameters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Woohyeok Kim",
      "Geonu Kim",
      "Junyong Lee",
      "Seungyong Lee",
      "Seung-Hwan Baek",
      "Sunghyun Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Perturbing_Attention_Gives_You_More_Bang_for_the_Buck_Subtle_CVPR_2024_paper.html": {
    "title": "Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyao Xu",
      "Yuetong Lu",
      "Yandong Li",
      "Siyang Lu",
      "Dongdong Wang",
      "Xiang Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Fairy_Fast_Parallelized_Instruction-Guided_Video-to-Video_Synthesis_CVPR_2024_paper.html": {
    "title": "Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bichen Wu",
      "Ching-Yao Chuang",
      "Xiaoyan Wang",
      "Yichen Jia",
      "Kapil Krishnakumar",
      "Tong Xiao",
      "Feng Liang",
      "Licheng Yu",
      "Peter Vajda"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_SmartEdit_Exploring_Complex_Instruction-based_Image_Editing_with_Multimodal_Large_Language_CVPR_2024_paper.html": {
    "title": "SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhou Huang",
      "Liangbin Xie",
      "Xintao Wang",
      "Ziyang Yuan",
      "Xiaodong Cun",
      "Yixiao Ge",
      "Jiantao Zhou",
      "Chao Dong",
      "Rui Huang",
      "Ruimao Zhang",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_SeNM-VAE_Semi-Supervised_Noise_Modeling_with_Hierarchical_Variational_Autoencoder_CVPR_2024_paper.html": {
    "title": "SeNM-VAE: Semi-Supervised Noise Modeling with Hierarchical Variational Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dihan Zheng",
      "Yihang Zou",
      "Xiaowen Zhang",
      "Chenglong Bao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Costanzino_Multimodal_Industrial_Anomaly_Detection_by_Crossmodal_Feature_Mapping_CVPR_2024_paper.html": {
    "title": "Multimodal Industrial Anomaly Detection by Crossmodal Feature Mapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Costanzino",
      "Pierluigi Zama Ramirez",
      "Giuseppe Lisanti",
      "Luigi Di Stefano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bulat_FFF_Fixing_Flawed_Foundations_in_Contrastive_Pre-Training_Results_in_Very_CVPR_2024_paper.html": {
    "title": "FFF: Fixing Flawed Foundations in Contrastive Pre-Training Results in Very Strong Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrian Bulat",
      "Yassine Ouali",
      "Georgios Tzimiropoulos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_Anchor-based_Robust_Finetuning_of_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Anchor-based Robust Finetuning of Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinwei Han",
      "Zhiwen Lin",
      "Zhongyisun Sun",
      "Yingguo Gao",
      "Ke Yan",
      "Shouhong Ding",
      "Yuan Gao",
      "Gui-Song Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hamann_Low-power_Continuous_Remote_Behavioral_Localization_with_Event_Cameras_CVPR_2024_paper.html": {
    "title": "Low-power Continuous Remote Behavioral Localization with Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Friedhelm Hamann",
      "Suman Ghosh",
      "Ignacio Juarez Martinez",
      "Tom Hart",
      "Alex Kacelnik",
      "Guillermo Gallego"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_SportsHHI_A_Dataset_for_Human-Human_Interaction_Detection_in_Sports_Videos_CVPR_2024_paper.html": {
    "title": "SportsHHI: A Dataset for Human-Human Interaction Detection in Sports Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wu",
      "Runyu He",
      "Gangshan Wu",
      "Limin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_DiSR-NeRF_Diffusion-Guided_View-Consistent_Super-Resolution_NeRF_CVPR_2024_paper.html": {
    "title": "DiSR-NeRF: Diffusion-Guided View-Consistent Super-Resolution NeRF",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Long Lee",
      "Chen Li",
      "Gim Hee Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shin_Dispersed_Structured_Light_for_Hyperspectral_3D_Imaging_CVPR_2024_paper.html": {
    "title": "Dispersed Structured Light for Hyperspectral 3D Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suhyun Shin",
      "Seokjun Choi",
      "Felix Heide",
      "Seung-Hwan Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ranasinghe_CrowdDiff_Multi-hypothesis_Crowd_Density_Estimation_using_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "CrowdDiff: Multi-hypothesis Crowd Density Estimation using Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasiru Ranasinghe",
      "Nithin Gopalakrishnan Nair",
      "Wele Gedara Chaminda Bandara",
      "Vishal M. Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Koley_Its_All_About_Your_Sketch_Democratising_Sketch_Control_in_Diffusion_CVPR_2024_paper.html": {
    "title": "It's All About Your Sketch: Democratising Sketch Control in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhadeep Koley",
      "Ayan Kumar Bhunia",
      "Deeptanshu Sekhri",
      "Aneeshan Sain",
      "Pinaki Nath Chowdhury",
      "Tao Xiang",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_GLID_Pre-training_a_Generalist_Encoder-Decoder_Vision_Model_CVPR_2024_paper.html": {
    "title": "GLID: Pre-training a Generalist Encoder-Decoder Vision Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihao Liu",
      "Jinliang Zheng",
      "Yu Liu",
      "Hongsheng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Diffusion-FOF_Single-View_Clothed_Human_Reconstruction_via_Diffusion-Based_Fourier_Occupancy_Field_CVPR_2024_paper.html": {
    "title": "Diffusion-FOF: Single-View Clothed Human Reconstruction via Diffusion-Based Fourier Occupancy Field",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanzhen Li",
      "Fei Luo",
      "Chunxia Xiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_When_StyleGAN_Meets_Stable_Diffusion_a_W_Adapter_for_Personalized_CVPR_2024_paper.html": {
    "title": "When StyleGAN Meets Stable Diffusion: a W+ Adapter for Personalized Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoming Li",
      "Xinyu Hou",
      "Chen Change Loy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Schmidt-Mengin_ToNNO_Tomographic_Reconstruction_of_a_Neural_Networks_Output_for_Weakly_CVPR_2024_paper.html": {
    "title": "ToNNO: Tomographic Reconstruction of a Neural Network's Output for Weakly Supervised Segmentation of 3D Medical Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marius Schmidt-Mengin",
      "Alexis Benichoux",
      "Shibeshih Belachew",
      "Nikos Komodakis",
      "Nikos Paragios"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bono_Learning_to_Navigate_Efficiently_and_Precisely_in_Real_Environments_CVPR_2024_paper.html": {
    "title": "Learning to Navigate Efficiently and Precisely in Real Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillaume Bono",
      "Hervé Poirier",
      "Leonid Antsfeld",
      "Gianluca Monaci",
      "Boris Chidlovskii",
      "Christian Wolf"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yasuki_CAM_Back_Again_Large_Kernel_CNNs_from_a_Weakly_Supervised_CVPR_2024_paper.html": {
    "title": "CAM Back Again: Large Kernel CNNs from a Weakly Supervised Object Localization Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shunsuke Yasuki",
      "Masato Taki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Miles_VkD_Improving_Knowledge_Distillation_using_Orthogonal_Projections_CVPR_2024_paper.html": {
    "title": "VkD: Improving Knowledge Distillation using Orthogonal Projections",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roy Miles",
      "Ismail Elezi",
      "Jiankang Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Putting_the_Object_Back_into_Video_Object_Segmentation_CVPR_2024_paper.html": {
    "title": "Putting the Object Back into Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ho Kei Cheng",
      "Seoung Wug Oh",
      "Brian Price",
      "Joon-Young Lee",
      "Alexander Schwing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kwon_Concept_Weaver_Enabling_Multi-Concept_Fusion_in_Text-to-Image_Models_CVPR_2024_paper.html": {
    "title": "Concept Weaver: Enabling Multi-Concept Fusion in Text-to-Image Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gihyun Kwon",
      "Simon Jenni",
      "Dingzeyu Li",
      "Joon-Young Lee",
      "Jong Chul Ye",
      "Fabian Caba Heilbron"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_PKU-DyMVHumans_A_Multi-View_Video_Benchmark_for_High-Fidelity_Dynamic_Human_Modeling_CVPR_2024_paper.html": {
    "title": "PKU-DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyun Zheng",
      "Liwei Liao",
      "Xufeng Li",
      "Jianbo Jiao",
      "Rongjie Wang",
      "Feng Gao",
      "Shiqi Wang",
      "Ronggang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nie_Cross-Domain_Few-Shot_Segmentation_via_Iterative_Support-Query_Correspondence_Mining_CVPR_2024_paper.html": {
    "title": "Cross-Domain Few-Shot Segmentation via Iterative Support-Query Correspondence Mining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Nie",
      "Yun Xing",
      "Gongjie Zhang",
      "Pei Yan",
      "Aoran Xiao",
      "Yap-Peng Tan",
      "Alex C. Kot",
      "Shijian Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_CausalPC_Improving_the_Robustness_of_Point_Cloud_Classification_by_Causal_CVPR_2024_paper.html": {
    "title": "CausalPC: Improving the Robustness of Point Cloud Classification by Causal Effect Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanmin Huang",
      "Mi Zhang",
      "Daizong Ding",
      "Erling Jiang",
      "Zhaoxiang Wang",
      "Min Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_LASA_Instance_Reconstruction_from_Real_Scans_using_A_Large-scale_Aligned_CVPR_2024_paper.html": {
    "title": "LASA: Instance Reconstruction from Real Scans using A Large-scale Aligned Shape Annotation Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haolin Liu",
      "Chongjie Ye",
      "Yinyu Nie",
      "Yingfan He",
      "Xiaoguang Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_LaRE2_Latent_Reconstruction_Error_Based_Method_for_Diffusion-Generated_Image_Detection_CVPR_2024_paper.html": {
    "title": "LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunpeng Luo",
      "Junlong Du",
      "Ke Yan",
      "Shouhong Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pan_DiffSCI_Zero-Shot_Snapshot_Compressive_Imaging_via_Iterative_Spectral_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "DiffSCI: Zero-Shot Snapshot Compressive Imaging via Iterative Spectral Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenghao Pan",
      "Haijin Zeng",
      "Jiezhang Cao",
      "Kai Zhang",
      "Yongyong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_DiffSHEG_A_Diffusion-Based_Approach_for_Real-Time_Speech-driven_Holistic_3D_Expression_CVPR_2024_paper.html": {
    "title": "DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junming Chen",
      "Yunfei Liu",
      "Jianan Wang",
      "Ailing Zeng",
      "Yu Li",
      "Qifeng Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chowdhury_MeLFusion_Synthesizing_Music_from_Image_and_Language_Cues_using_Diffusion_CVPR_2024_paper.html": {
    "title": "MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanjoy Chowdhury",
      "Sayan Nag",
      "K J Joseph",
      "Balaji Vasan Srinivasan",
      "Dinesh Manocha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_T4P_Test-Time_Training_of_Trajectory_Prediction_via_Masked_Autoencoder_and_CVPR_2024_paper.html": {
    "title": "T4P: Test-Time Training of Trajectory Prediction via Masked Autoencoder and Actor-specific Token Memory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daehee Park",
      "Jaeseok Jeong",
      "Sung-Hoon Yoon",
      "Jaewoo Jeong",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qin_Noisy-Correspondence_Learning_for_Text-to-Image_Person_Re-identification_CVPR_2024_paper.html": {
    "title": "Noisy-Correspondence Learning for Text-to-Image Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Qin",
      "Yingke Chen",
      "Dezhong Peng",
      "Xi Peng",
      "Joey Tianyi Zhou",
      "Peng Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_InstaGen_Enhancing_Object_Detection_by_Training_on_Synthetic_Dataset_CVPR_2024_paper.html": {
    "title": "InstaGen: Enhancing Object Detection by Training on Synthetic Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengjian Feng",
      "Yujie Zhong",
      "Zequn Jie",
      "Weidi Xie",
      "Lin Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_PanoRecon_Real-Time_Panoptic_3D_Reconstruction_from_Monocular_Video_CVPR_2024_paper.html": {
    "title": "PanoRecon: Real-Time Panoptic 3D Reconstruction from Monocular Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Wu",
      "Zike Yan",
      "Hongbin Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Animating_General_Image_with_Large_Visual_Motion_Model_CVPR_2024_paper.html": {
    "title": "Animating General Image with Large Visual Motion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dengsheng Chen",
      "Xiaoming Wei",
      "Xiaolin Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Visual_Point_Cloud_Forecasting_enables_Scalable_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "Visual Point Cloud Forecasting enables Scalable Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zetong Yang",
      "Li Chen",
      "Yanan Sun",
      "Hongyang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Towards_Transferable_Targeted_3D_Adversarial_Attack_in_the_Physical_World_CVPR_2024_paper.html": {
    "title": "Towards Transferable Targeted 3D Adversarial Attack in the Physical World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Huang",
      "Yinpeng Dong",
      "Shouwei Ruan",
      "Xiao Yang",
      "Hang Su",
      "Xingxing Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_SwitchLight_Co-design_of_Physics-driven_Architecture_and_Pre-training_Framework_for_Human_CVPR_2024_paper.html": {
    "title": "SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoon Kim",
      "Minje Jang",
      "Wonjun Yoon",
      "Jisoo Lee",
      "Donghyun Na",
      "Sanghyun Woo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_DIRECT-3D_Learning_Direct_Text-to-3D_Generation_on_Massive_Noisy_3D_Data_CVPR_2024_paper.html": {
    "title": "DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihao Liu",
      "Yi Zhang",
      "Song Bai",
      "Adam Kortylewski",
      "Alan Yuille"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Synthesize_Step-by-Step_Tools_Templates_and_LLMs_as_Data_Generators_for_CVPR_2024_paper.html": {
    "title": "Synthesize Step-by-Step: Tools Templates and LLMs as Data Generators for Reasoning-Based Chart VQA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuowan Li",
      "Bhavan Jasani",
      "Peng Tang",
      "Shabnam Ghadar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_LayoutLLM_Layout_Instruction_Tuning_with_Large_Language_Models_for_Document_CVPR_2024_paper.html": {
    "title": "LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuwei Luo",
      "Yufan Shen",
      "Zhaoqing Zhu",
      "Qi Zheng",
      "Zhi Yu",
      "Cong Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_ProTeCt_Prompt_Tuning_for_Taxonomic_Open_Set_Classification_CVPR_2024_paper.html": {
    "title": "ProTeCt: Prompt Tuning for Taxonomic Open Set Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tz-Ying Wu",
      "Chih-Hui Ho",
      "Nuno Vasconcelos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Steitz_Adapters_Strike_Back_CVPR_2024_paper.html": {
    "title": "Adapters Strike Back",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan-Martin O. Steitz",
      "Stefan Roth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kraus_Masked_Autoencoders_for_Microscopy_are_Scalable_Learners_of_Cellular_Biology_CVPR_2024_paper.html": {
    "title": "Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oren Kraus",
      "Kian Kenyon-Dean",
      "Saber Saberian",
      "Maryam Fallah",
      "Peter McLean",
      "Jess Leung",
      "Vasudev Sharma",
      "Ayla Khan",
      "Jia Balakrishnan",
      "Safiye Celik",
      "Dominique Beaini",
      "Maciej Sypetkowski",
      "Chi Vicky Cheng",
      "Kristen Morse",
      "Maureen Makes",
      "Ben Mabey",
      "Berton Earnshaw"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_OHTA_One-shot_Hand_Avatar_via_Data-driven_Implicit_Priors_CVPR_2024_paper.html": {
    "title": "OHTA: One-shot Hand Avatar via Data-driven Implicit Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaozheng Zheng",
      "Chao Wen",
      "Zhuo Su",
      "Zeran Xu",
      "Zhaohu Li",
      "Yang Zhao",
      "Zhou Xue"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Segment_and_Caption_Anything_CVPR_2024_paper.html": {
    "title": "Segment and Caption Anything",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoke Huang",
      "Jianfeng Wang",
      "Yansong Tang",
      "Zheng Zhang",
      "Han Hu",
      "Jiwen Lu",
      "Lijuan Wang",
      "Zicheng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yue_Human_Motion_Prediction_Under_Unexpected_Perturbation_CVPR_2024_paper.html": {
    "title": "Human Motion Prediction Under Unexpected Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangbei Yue",
      "Baiyi Li",
      "Julien Pettré",
      "Armin Seyfried",
      "He Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Text-to-3D_Generation_with_Bidirectional_Diffusion_using_both_2D_and_3D_CVPR_2024_paper.html": {
    "title": "Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lihe Ding",
      "Shaocong Dong",
      "Zhanpeng Huang",
      "Zibin Wang",
      "Yiyuan Zhang",
      "Kaixiong Gong",
      "Dan Xu",
      "Tianfan Xue"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_CLIP-Driven_Open-Vocabulary_3D_Scene_Graph_Generation_via_Cross-Modality_Contrastive_Learning_CVPR_2024_paper.html": {
    "title": "CLIP-Driven Open-Vocabulary 3D Scene Graph Generation via Cross-Modality Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lianggangxu Chen",
      "Xuejiao Wang",
      "Jiale Lu",
      "Shaohui Lin",
      "Changbo Wang",
      "Gaoqi He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pourkeshavarz_Adversarial_Backdoor_Attack_by_Naturalistic_Data_Poisoning_on_Trajectory_Prediction_CVPR_2024_paper.html": {
    "title": "Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mozhgan Pourkeshavarz",
      "Mohammad Sabokrou",
      "Amir Rasouli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Make-It-Vivid_Dressing_Your_Animatable_Biped_Cartoon_Characters_from_Text_CVPR_2024_paper.html": {
    "title": "Make-It-Vivid: Dressing Your Animatable Biped Cartoon Characters from Text",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junshu Tang",
      "Yanhong Zeng",
      "Ke Fan",
      "Xuheng Wang",
      "Bo Dai",
      "Kai Chen",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/de_Silva_Edirimuni_StraightPCF_Straight_Point_Cloud_Filtering_CVPR_2024_paper.html": {
    "title": "StraightPCF: Straight Point Cloud Filtering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dasith de Silva Edirimuni",
      "Xuequan Lu",
      "Gang Li",
      "Lei Wei",
      "Antonio Robles-Kelly",
      "Hongdong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Piergiovanni_Mirasol3B_A_Multimodal_Autoregressive_Model_for_Time-Aligned_and_Contextual_Modalities_CVPR_2024_paper.html": {
    "title": "Mirasol3B: A Multimodal Autoregressive Model for Time-Aligned and Contextual Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "AJ Piergiovanni",
      "Isaac Noble",
      "Dahun Kim",
      "Michael S. Ryoo",
      "Victor Gomes",
      "Anelia Angelova"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Baltatzis_Neural_Sign_Actors_A_Diffusion_Model_for_3D_Sign_Language_CVPR_2024_paper.html": {
    "title": "Neural Sign Actors: A Diffusion Model for 3D Sign Language Production from Text",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vasileios Baltatzis",
      "Rolandos Alexandros Potamias",
      "Evangelos Ververas",
      "Guanxiong Sun",
      "Jiankang Deng",
      "Stefanos Zafeiriou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_On_the_Diversity_and_Realism_of_Distilled_Dataset_An_Efficient_CVPR_2024_paper.html": {
    "title": "On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Sun",
      "Bei Shi",
      "Daiwei Yu",
      "Tao Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Semantics-aware_Motion_Retargeting_with_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Semantics-aware Motion Retargeting with Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haodong Zhang",
      "Zhike Chen",
      "Haocheng Xu",
      "Lei Hao",
      "Xiaofei Wu",
      "Songcen Xu",
      "Zhensong Zhang",
      "Yue Wang",
      "Rong Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Semantically-Shifted_Incremental_Adapter-Tuning_is_A_Continual_ViTransformer_CVPR_2024_paper.html": {
    "title": "Semantically-Shifted Incremental Adapter-Tuning is A Continual ViTransformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwen Tan",
      "Qinhao Zhou",
      "Xiang Xiang",
      "Ke Wang",
      "Yuchuan Wu",
      "Yongbin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Low-Rank_Approximation_for_Sparse_Attention_in_Multi-Modal_LLMs_CVPR_2024_paper.html": {
    "title": "Low-Rank Approximation for Sparse Attention in Multi-Modal LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Song",
      "Yukang Chen",
      "Shuai Yang",
      "Xiaohan Ding",
      "Yixiao Ge",
      "Ying-Cong Chen",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_TASeg_Temporal_Aggregation_Network_for_LiDAR_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "TASeg: Temporal Aggregation Network for LiDAR Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaopei Wu",
      "Yuenan Hou",
      "Xiaoshui Huang",
      "Binbin Lin",
      "Tong He",
      "Xinge Zhu",
      "Yuexin Ma",
      "Boxi Wu",
      "Haifeng Liu",
      "Deng Cai",
      "Wanli Ouyang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Bootstrapping_SparseFormers_from_Vision_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Bootstrapping SparseFormers from Vision Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziteng Gao",
      "Zhan Tong",
      "Kevin Qinghong Lin",
      "Joya Chen",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_EventPS_Real-Time_Photometric_Stereo_Using_an_Event_Camera_CVPR_2024_paper.html": {
    "title": "EventPS: Real-Time Photometric Stereo Using an Event Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bohan Yu",
      "Jieji Ren",
      "Jin Han",
      "Feishi Wang",
      "Jinxiu Liang",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sick_Unsupervised_Semantic_Segmentation_Through_Depth-Guided_Feature_Correlation_and_Sampling_CVPR_2024_paper.html": {
    "title": "Unsupervised Semantic Segmentation Through Depth-Guided Feature Correlation and Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leon Sick",
      "Dominik Engel",
      "Pedro Hermosilla",
      "Timo Ropinski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_On_the_Road_to_Portability_Compressing_End-to-End_Motion_Planner_for_CVPR_2024_paper.html": {
    "title": "On the Road to Portability: Compressing End-to-End Motion Planner for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaituo Feng",
      "Changsheng Li",
      "Dongchun Ren",
      "Ye Yuan",
      "Guoren Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kara_RAVE_Randomized_Noise_Shuffling_for_Fast_and_Consistent_Video_Editing_CVPR_2024_paper.html": {
    "title": "RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ozgur Kara",
      "Bariscan Kurtkaya",
      "Hidir Yesiltepe",
      "James M. Rehg",
      "Pinar Yanardag"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nie_PredToken_Predicting_Unknown_Tokens_and_Beyond_with_Coarse-to-Fine_Iterative_Decoding_CVPR_2024_paper.html": {
    "title": "PredToken: Predicting Unknown Tokens and Beyond with Coarse-to-Fine Iterative Decoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuesong Nie",
      "Haoyuan Jin",
      "Yunfeng Yan",
      "Xi Chen",
      "Zhihang Zhu",
      "Donglian Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Video-Based_Human_Pose_Regression_via_Decoupled_Space-Time_Aggregation_CVPR_2024_paper.html": {
    "title": "Video-Based Human Pose Regression via Decoupled Space-Time Aggregation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jijie He",
      "Wenwu Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_L-MAGIC_Language_Model_Assisted_Generation_of_Images_with_Coherence_CVPR_2024_paper.html": {
    "title": "L-MAGIC: Language Model Assisted Generation of Images with Coherence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhipeng Cai",
      "Matthias Mueller",
      "Reiner Birkl",
      "Diana Wofk",
      "Shao-Yen Tseng",
      "Junda Cheng",
      "Gabriela Ben-Melech Stan",
      "Vasudev Lai",
      "Michael Paulitsch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Taubner_3D_Face_Tracking_from_2D_Video_through_Iterative_Dense_UV_CVPR_2024_paper.html": {
    "title": "3D Face Tracking from 2D Video through Iterative Dense UV to Image Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Taubner",
      "Prashant Raina",
      "Mathieu Tuli",
      "Eu Wern Teh",
      "Chul Lee",
      "Jinmiao Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Carve3D_Improving_Multi-view_Reconstruction_Consistency_for_Diffusion_Models_with_RL_CVPR_2024_paper.html": {
    "title": "Carve3D: Improving Multi-view Reconstruction Consistency for Diffusion Models with RL Finetuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Desai Xie",
      "Jiahao Li",
      "Hao Tan",
      "Xin Sun",
      "Zhixin Shu",
      "Yi Zhou",
      "Sai Bi",
      "Sören Pirk",
      "Arie E. Kaufman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_Random_Entangled_Tokens_for_Adversarially_Robust_Vision_Transformer_CVPR_2024_paper.html": {
    "title": "Random Entangled Tokens for Adversarially Robust Vision Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huihui Gong",
      "Minjing Dong",
      "Siqi Ma",
      "Seyit Camtepe",
      "Surya Nepal",
      "Chang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Shadow_Generation_for_Composite_Image_Using_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "Shadow Generation for Composite Image Using Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyang Liu",
      "Junqi You",
      "Jianting Wang",
      "Xinhao Tao",
      "Bo Zhang",
      "Li Niu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_DisCo_Disentangled_Control_for_Realistic_Human_Dance_Generation_CVPR_2024_paper.html": {
    "title": "DisCo: Disentangled Control for Realistic Human Dance Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tan Wang",
      "Linjie Li",
      "Kevin Lin",
      "Yuanhao Zhai",
      "Chung-Ching Lin",
      "Zhengyuan Yang",
      "Hanwang Zhang",
      "Zicheng Liu",
      "Lijuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_L2B_Learning_to_Bootstrap_Robust_Models_for_Combating_Label_Noise_CVPR_2024_paper.html": {
    "title": "L2B: Learning to Bootstrap Robust Models for Combating Label Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyin Zhou",
      "Xianhang Li",
      "Fengze Liu",
      "Qingyue Wei",
      "Xuxi Chen",
      "Lequan Yu",
      "Cihang Xie",
      "Matthew P. Lungren",
      "Lei Xing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_GaussianShader_3D_Gaussian_Splatting_with_Shading_Functions_for_Reflective_Surfaces_CVPR_2024_paper.html": {
    "title": "GaussianShader: 3D Gaussian Splatting with Shading Functions for Reflective Surfaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingwenqi Jiang",
      "Jiadong Tu",
      "Yuan Liu",
      "Xifeng Gao",
      "Xiaoxiao Long",
      "Wenping Wang",
      "Yuexin Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dou_Tactile-Augmented_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "Tactile-Augmented Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Dou",
      "Fengyu Yang",
      "Yi Liu",
      "Antonio Loquercio",
      "Andrew Owens"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Su_Intensity-Robust_Autofocus_for_Spike_Camera_CVPR_2024_paper.html": {
    "title": "Intensity-Robust Autofocus for Spike Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changqing Su",
      "Zhiyuan Ye",
      "Yongsheng Xiao",
      "You Zhou",
      "Zhen Cheng",
      "Bo Xiong",
      "Zhaofei Yu",
      "Tiejun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_FairCLIP_Harnessing_Fairness_in_Vision-Language_Learning_CVPR_2024_paper.html": {
    "title": "FairCLIP: Harnessing Fairness in Vision-Language Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Luo",
      "Min Shi",
      "Muhammad Osama Khan",
      "Muhammad Muneeb Afzal",
      "Hao Huang",
      "Shuaihang Yuan",
      "Yu Tian",
      "Luo Song",
      "Ava Kouhana",
      "Tobias Elze",
      "Yi Fang",
      "Mengyu Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_StreamingFlow_Streaming_Occupancy_Forecasting_with_Asynchronous_Multi-modal_Data_Streams_via_CVPR_2024_paper.html": {
    "title": "StreamingFlow: Streaming Occupancy Forecasting with Asynchronous Multi-modal Data Streams via Neural Ordinary Differential Equation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yining Shi",
      "Kun Jiang",
      "Ke Wang",
      "Jiusi Li",
      "Yunlong Wang",
      "Mengmeng Yang",
      "Diange Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ozguroglu_pix2gestalt_Amodal_Segmentation_by_Synthesizing_Wholes_CVPR_2024_paper.html": {
    "title": "pix2gestalt: Amodal Segmentation by Synthesizing Wholes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ege Ozguroglu",
      "Ruoshi Liu",
      "Dídac Surís",
      "Dian Chen",
      "Achal Dave",
      "Pavel Tokmakov",
      "Carl Vondrick"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kweon_Weakly_Supervised_Point_Cloud_Semantic_Segmentation_via_Artificial_Oracle_CVPR_2024_paper.html": {
    "title": "Weakly Supervised Point Cloud Semantic Segmentation via Artificial Oracle",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeokjun Kweon",
      "Jihun Kim",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Language_Model_Guided_Interpretable_Video_Action_Reasoning_CVPR_2024_paper.html": {
    "title": "Language Model Guided Interpretable Video Action Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ning Wang",
      "Guangming Zhu",
      "HS Li",
      "Liang Zhang",
      "Syed Afaq Ali Shah",
      "Mohammed Bennamoun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Forecasting_of_3D_Whole-body_Human_Poses_with_Grasping_Objects_CVPR_2024_paper.html": {
    "title": "Forecasting of 3D Whole-body Human Poses with Grasping Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haitao Yan",
      "Qiongjie Cui",
      "Jiexin Xie",
      "Shijie Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_COTR_Compact_Occupancy_TRansformer_for_Vision-based_3D_Occupancy_Prediction_CVPR_2024_paper.html": {
    "title": "COTR: Compact Occupancy TRansformer for Vision-based 3D Occupancy Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihang Ma",
      "Xin Tan",
      "Yanyun Qu",
      "Lizhuang Ma",
      "Zhizhong Zhang",
      "Yuan Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_Accelerating_Diffusion_Sampling_with_Optimized_Time_Steps_CVPR_2024_paper.html": {
    "title": "Accelerating Diffusion Sampling with Optimized Time Steps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuchen Xue",
      "Zhaoqiang Liu",
      "Fei Chen",
      "Shifeng Zhang",
      "Tianyang Hu",
      "Enze Xie",
      "Zhenguo Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_See_Say_and_Segment_Teaching_LMMs_to_Overcome_False_Premises_CVPR_2024_paper.html": {
    "title": "See Say and Segment: Teaching LMMs to Overcome False Premises",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsung-Han Wu",
      "Giscard Biamby",
      "David Chan",
      "Lisa Dunlap",
      "Ritwik Gupta",
      "Xudong Wang",
      "Joseph E. Gonzalez",
      "Trevor Darrell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Is_Ego_Status_All_You_Need_for_Open-Loop_End-to-End_Autonomous_CVPR_2024_paper.html": {
    "title": "Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiqi Li",
      "Zhiding Yu",
      "Shiyi Lan",
      "Jiahan Li",
      "Jan Kautz",
      "Tong Lu",
      "Jose M. Alvarez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_Unsupervised_Template-assisted_Point_Cloud_Shape_Correspondence_Network_CVPR_2024_paper.html": {
    "title": "Unsupervised Template-assisted Point Cloud Shape Correspondence Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiacheng Deng",
      "Jiahao Lu",
      "Tianzhu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_CGI-DM_Digital_Copyright_Authentication_for_Diffusion_Models_via_Contrasting_Gradient_CVPR_2024_paper.html": {
    "title": "CGI-DM: Digital Copyright Authentication for Diffusion Models via Contrasting Gradient Inversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Wu",
      "Yang Hua",
      "Chumeng Liang",
      "Jiaru Zhang",
      "Hao Wang",
      "Tao Song",
      "Haibing Guan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qiao_Making_Visual_Sense_of_Oracle_Bones_for_You_and_Me_CVPR_2024_paper.html": {
    "title": "Making Visual Sense of Oracle Bones for You and Me",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runqi Qiao",
      "Lan Yang",
      "Kaiyue Pang",
      "Honggang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Weber_Finsler-Laplace-Beltrami_Operators_with_Application_to_Shape_Analysis_CVPR_2024_paper.html": {
    "title": "Finsler-Laplace-Beltrami Operators with Application to Shape Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Weber",
      "Thomas Dagès",
      "Maolin Gao",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dal_Cin_Minimal_Perspective_Autocalibration_CVPR_2024_paper.html": {
    "title": "Minimal Perspective Autocalibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Porfiri Dal Cin",
      "Timothy Duff",
      "Luca Magri",
      "Tomas Pajdla"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MOHO_Learning_Single-view_Hand-held_Object_Reconstruction_with_Multi-view_Occlusion-Aware_Supervision_CVPR_2024_paper.html": {
    "title": "MOHO: Learning Single-view Hand-held Object Reconstruction with Multi-view Occlusion-Aware Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyangguang Zhang",
      "Guanlong Jiao",
      "Yan Di",
      "Gu Wang",
      "Ziqin Huang",
      "Ruida Zhang",
      "Fabian Manhardt",
      "Bowen Fu",
      "Federico Tombari",
      "Xiangyang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shabanov_BANF_Band-Limited_Neural_Fields_for_Levels_of_Detail_Reconstruction_CVPR_2024_paper.html": {
    "title": "BANF: Band-Limited Neural Fields for Levels of Detail Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akhmedkhan Shabanov",
      "Shrisudhan Govindarajan",
      "Cody Reading",
      "Lily Goli",
      "Daniel Rebain",
      "Kwang Moo Yi",
      "Andrea Tagliasacchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mercea_Time-_Memory-_and_Parameter-Efficient_Visual_Adaptation_CVPR_2024_paper.html": {
    "title": "Time- Memory- and Parameter-Efficient Visual Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Otniel-Bogdan Mercea",
      "Alexey Gritsenko",
      "Cordelia Schmid",
      "Anurag Arnab"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SecondPose_SE3-Consistent_Dual-Stream_Feature_Fusion_for_Category-Level_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "SecondPose: SE(3)-Consistent Dual-Stream Feature Fusion for Category-Level Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yamei Chen",
      "Yan Di",
      "Guangyao Zhai",
      "Fabian Manhardt",
      "Chenyangguang Zhang",
      "Ruida Zhang",
      "Federico Tombari",
      "Nassir Navab",
      "Benjamin Busam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhai_Physical_Property_Understanding_from_Language-Embedded_Feature_Fields_CVPR_2024_paper.html": {
    "title": "Physical Property Understanding from Language-Embedded Feature Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Albert J. Zhai",
      "Yuan Shen",
      "Emily Y. Chen",
      "Gloria X. Wang",
      "Xinlei Wang",
      "Sheng Wang",
      "Kaiyu Guan",
      "Shenlong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_EgoGen_An_Egocentric_Synthetic_Data_Generator_CVPR_2024_paper.html": {
    "title": "EgoGen: An Egocentric Synthetic Data Generator",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gen Li",
      "Kaifeng Zhao",
      "Siwei Zhang",
      "Xiaozhong Lyu",
      "Mihai Dusmanu",
      "Yan Zhang",
      "Marc Pollefeys",
      "Siyu Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Suppress_and_Rebalance_Towards_Generalized_Multi-Modal_Face_Anti-Spoofing_CVPR_2024_paper.html": {
    "title": "Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xun Lin",
      "Shuai Wang",
      "Rizhao Cai",
      "Yizhong Liu",
      "Ying Fu",
      "Wenzhong Tang",
      "Zitong Yu",
      "Alex Kot"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_LEAD_Exploring_Logit_Space_Evolution_for_Model_Selection_CVPR_2024_paper.html": {
    "title": "LEAD: Exploring Logit Space Evolution for Model Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Hu",
      "Xiaotong Li",
      "Shixiang Tang",
      "Jun Liu",
      "Yichun Hu",
      "Ling-Yu Duan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Islam_Video_ReCap_Recursive_Captioning_of_Hour-Long_Videos_CVPR_2024_paper.html": {
    "title": "Video ReCap: Recursive Captioning of Hour-Long Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Mohaiminul Islam",
      "Ngan Ho",
      "Xitong Yang",
      "Tushar Nagarajan",
      "Lorenzo Torresani",
      "Gedas Bertasius"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ran_Towards_Realistic_Scene_Generation_with_LiDAR_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Towards Realistic Scene Generation with LiDAR Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxi Ran",
      "Vitor Guizilini",
      "Yue Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Enyo_Diffusion_Reflectance_Map_Single-Image_Stochastic_Inverse_Rendering_of_Illumination_and_CVPR_2024_paper.html": {
    "title": "Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of Illumination and Reflectance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuto Enyo",
      "Ko Nishino"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Universal_Segmentation_at_Arbitrary_Granularity_with_Language_Instruction_CVPR_2024_paper.html": {
    "title": "Universal Segmentation at Arbitrary Granularity with Language Instruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yong Liu",
      "Cairong Zhang",
      "Yitong Wang",
      "Jiahao Wang",
      "Yujiu Yang",
      "Yansong Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qian_GaussianAvatars_Photorealistic_Head_Avatars_with_Rigged_3D_Gaussians_CVPR_2024_paper.html": {
    "title": "GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenhan Qian",
      "Tobias Kirschstein",
      "Liam Schoneveld",
      "Davide Davoli",
      "Simon Giebenhain",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yue_MMMU_A_Massive_Multi-discipline_Multimodal_Understanding_and_Reasoning_Benchmark_for_CVPR_2024_paper.html": {
    "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Yue",
      "Yuansheng Ni",
      "Kai Zhang",
      "Tianyu Zheng",
      "Ruoqi Liu",
      "Ge Zhang",
      "Samuel Stevens",
      "Dongfu Jiang",
      "Weiming Ren",
      "Yuxuan Sun",
      "Cong Wei",
      "Botao Yu",
      "Ruibin Yuan",
      "Renliang Sun",
      "Ming Yin",
      "Boyuan Zheng",
      "Zhenzhu Yang",
      "Yibo Liu",
      "Wenhao Huang",
      "Huan Sun",
      "Yu Su",
      "Wenhu Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhangli_Layout-Agnostic_Scene_Text_Image_Synthesis_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Layout-Agnostic Scene Text Image Synthesis with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qilong Zhangli",
      "Jindong Jiang",
      "Di Liu",
      "Licheng Yu",
      "Xiaoliang Dai",
      "Ankit Ramchandani",
      "Guan Pang",
      "Dimitris N. Metaxas",
      "Praveen Krishnan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Berton_EarthLoc_Astronaut_Photography_Localization_by_Indexing_Earth_from_Space_CVPR_2024_paper.html": {
    "title": "EarthLoc: Astronaut Photography Localization by Indexing Earth from Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriele Berton",
      "Alex Stoken",
      "Barbara Caputo",
      "Carlo Masone"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Singh_SmartMask_Context_Aware_High-Fidelity_Mask_Generation_for_Fine-grained_Object_Insertion_CVPR_2024_paper.html": {
    "title": "SmartMask: Context Aware High-Fidelity Mask Generation for Fine-grained Object Insertion and Layout Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaskirat Singh",
      "Jianming Zhang",
      "Qing Liu",
      "Cameron Smith",
      "Zhe Lin",
      "Liang Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kondapaneni_Text-Image_Alignment_for_Diffusion-Based_Perception_CVPR_2024_paper.html": {
    "title": "Text-Image Alignment for Diffusion-Based Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neehar Kondapaneni",
      "Markus Marks",
      "Manuel Knott",
      "Rogerio Guimaraes",
      "Pietro Perona"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Customization_Assistant_for_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Customization Assistant for Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufan Zhou",
      "Ruiyi Zhang",
      "Jiuxiang Gu",
      "Tong Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_GaussianEditor_Editing_3D_Gaussians_Delicately_with_Text_Instructions_CVPR_2024_paper.html": {
    "title": "GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Wang",
      "Jiemin Fang",
      "Xiaopeng Zhang",
      "Lingxi Xie",
      "Qi Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_MemFlow_Optical_Flow_Estimation_and_Prediction_with_Memory_CVPR_2024_paper.html": {
    "title": "MemFlow: Optical Flow Estimation and Prediction with Memory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiaole Dong",
      "Yanwei Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Novel_Class_Discovery_for_Ultra-Fine-Grained_Visual_Categorization_CVPR_2024_paper.html": {
    "title": "Novel Class Discovery for Ultra-Fine-Grained Visual Categorization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Liu",
      "Yaqi Cai",
      "Qi Jia",
      "Binglin Qiu",
      "Weimin Wang",
      "Nan Pu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Souek_GenHowTo_Learning_to_Generate_Actions_and_State_Transformations_from_Instructional_CVPR_2024_paper.html": {
    "title": "GenHowTo: Learning to Generate Actions and State Transformations from Instructional Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tomáš Sou?ek",
      "Dima Damen",
      "Michael Wray",
      "Ivan Laptev",
      "Josef Sivic"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Youwang_Paint-it_Text-to-Texture_Synthesis_via_Deep_Convolutional_Texture_Map_Optimization_and_CVPR_2024_paper.html": {
    "title": "Paint-it: Text-to-Texture Synthesis via Deep Convolutional Texture Map Optimization and Physically-Based Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kim Youwang",
      "Tae-Hyun Oh",
      "Gerard Pons-Moll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_HiKER-SGG_Hierarchical_Knowledge_Enhanced_Robust_Scene_Graph_Generation_CVPR_2024_paper.html": {
    "title": "HiKER-SGG: Hierarchical Knowledge Enhanced Robust Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ce Zhang",
      "Simon Stepputtis",
      "Joseph Campbell",
      "Katia Sycara",
      "Yaqi Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lei_DiffusionGAN3D_Boosting_Text-guided_3D_Generation_and_Domain_Adaptation_by_Combining_CVPR_2024_paper.html": {
    "title": "DiffusionGAN3D: Boosting Text-guided 3D Generation and Domain Adaptation by Combining 3D GANs and Diffusion Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Biwen Lei",
      "Kai Yu",
      "Mengyang Feng",
      "Miaomiao Cui",
      "Xuansong Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Physics-Aware_Hand-Object_Interaction_Denoising_CVPR_2024_paper.html": {
    "title": "Physics-Aware Hand-Object Interaction Denoising",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haowen Luo",
      "Yunze Liu",
      "Li Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_VastGaussian_Vast_3D_Gaussians_for_Large_Scene_Reconstruction_CVPR_2024_paper.html": {
    "title": "VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Lin",
      "Zhihao Li",
      "Xiao Tang",
      "Jianzhuang Liu",
      "Shiyong Liu",
      "Jiayue Liu",
      "Yangdi Lu",
      "Xiaofei Wu",
      "Songcen Xu",
      "Youliang Yan",
      "Wenming Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_Edit_One_for_All_Interactive_Batch_Image_Editing_CVPR_2024_paper.html": {
    "title": "Edit One for All: Interactive Batch Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thao Nguyen",
      "Utkarsh Ojha",
      "Yuheng Li",
      "Haotian Liu",
      "Yong Jae Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Rethinking_Boundary_Discontinuity_Problem_for_Oriented_Object_Detection_CVPR_2024_paper.html": {
    "title": "Rethinking Boundary Discontinuity Problem for Oriented Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Xu",
      "Xinyuan Liu",
      "Haonan Xu",
      "Yike Ma",
      "Zunjie Zhu",
      "Chenggang Yan",
      "Feng Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Deformable_One-shot_Face_Stylization_via_DINO_Semantic_Guidance_CVPR_2024_paper.html": {
    "title": "Deformable One-shot Face Stylization via DINO Semantic Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhou",
      "Zichong Chen",
      "Hui Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Carter_SleepVST_Sleep_Staging_from_Near-Infrared_Video_Signals_using_Pre-Trained_Transformers_CVPR_2024_paper.html": {
    "title": "SleepVST: Sleep Staging from Near-Infrared Video Signals using Pre-Trained Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan F. Carter",
      "João Jorge",
      "Oliver Gibson",
      "Lionel Tarassenko"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Coarse-to-Fine_Latent_Diffusion_for_Pose-Guided_Person_Image_Synthesis_CVPR_2024_paper.html": {
    "title": "Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanzuo Lu",
      "Manlin Zhang",
      "Andy J Ma",
      "Xiaohua Xie",
      "Jianhuang Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Watermark-embedded_Adversarial_Examples_for_Copyright_Protection_against_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peifei Zhu",
      "Tsubasa Takahashi",
      "Hirokatsu Kataoka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yao_TCPTextual-based_Class-aware_Prompt_tuning_for_Visual-Language_Model_CVPR_2024_paper.html": {
    "title": "TCP:Textual-based Class-aware Prompt tuning for Visual-Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hantao Yao",
      "Rui Zhang",
      "Changsheng Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_OMG_Towards_Open-vocabulary_Motion_Generation_via_Mixture_of_Controllers_CVPR_2024_paper.html": {
    "title": "OMG: Towards Open-vocabulary Motion Generation via Mixture of Controllers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Liang",
      "Jiacheng Bao",
      "Ruichi Zhang",
      "Sihan Ren",
      "Yuecheng Xu",
      "Sibei Yang",
      "Xin Chen",
      "Jingyi Yu",
      "Lan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_TimeChat_A_Time-sensitive_Multimodal_Large_Language_Model_for_Long_Video_CVPR_2024_paper.html": {
    "title": "TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuhuai Ren",
      "Linli Yao",
      "Shicheng Li",
      "Xu Sun",
      "Lu Hou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ling_Align_Your_Gaussians_Text-to-4D_with_Dynamic_3D_Gaussians_and_Composed_CVPR_2024_paper.html": {
    "title": "Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huan Ling",
      "Seung Wook Kim",
      "Antonio Torralba",
      "Sanja Fidler",
      "Karsten Kreis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_PDF_A_Probability-Driven_Framework_for_Open_World_3D_Point_Cloud_CVPR_2024_paper.html": {
    "title": "PDF: A Probability-Driven Framework for Open World 3D Point Cloud Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinfeng Xu",
      "Siyuan Yang",
      "Xianzhi Li",
      "Yuan Tang",
      "Yixue Hao",
      "Long Hu",
      "Min Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Test-Time_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2024_paper.html": {
    "title": "Test-Time Domain Generalization for Face Anti-Spoofing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qianyu Zhou",
      "Ke-Yue Zhang",
      "Taiping Yao",
      "Xuequan Lu",
      "Shouhong Ding",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_DiffusionMTL_Learning_Multi-Task_Denoising_Diffusion_Model_from_Partially_Annotated_Data_CVPR_2024_paper.html": {
    "title": "DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanrong Ye",
      "Dan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Spike-guided_Motion_Deblurring_with_Unknown_Modal_Spatiotemporal_Alignment_CVPR_2024_paper.html": {
    "title": "Spike-guided Motion Deblurring with Unknown Modal Spatiotemporal Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiyuan Zhang",
      "Shiyan Chen",
      "Yajing Zheng",
      "Zhaofei Yu",
      "Tiejun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_VRP-SAM_SAM_with_Visual_Reference_Prompt_CVPR_2024_paper.html": {
    "title": "VRP-SAM: SAM with Visual Reference Prompt",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanpeng Sun",
      "Jiahui Chen",
      "Shan Zhang",
      "Xinyu Zhang",
      "Qiang Chen",
      "Gang Zhang",
      "Errui Ding",
      "Jingdong Wang",
      "Zechao Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Discriminability-Driven_Channel_Selection_for_Out-of-Distribution_Detection_CVPR_2024_paper.html": {
    "title": "Discriminability-Driven Channel Selection for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Yuan",
      "Rundong He",
      "Yicong Dong",
      "Zhongyi Han",
      "Yilong Yin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_ManiFPT_Defining_and_Analyzing_Fingerprints_of_Generative_Models_CVPR_2024_paper.html": {
    "title": "ManiFPT: Defining and Analyzing Fingerprints of Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hae Jin Song",
      "Mahyar Khayatkhoei",
      "Wael AbdAlmageed"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Real-time_3D-aware_Portrait_Video_Relighting_CVPR_2024_paper.html": {
    "title": "Real-time 3D-aware Portrait Video Relighting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqi Cai",
      "Kaiwen Jiang",
      "Shu-Yu Chen",
      "Yu-Kun Lai",
      "Hongbo Fu",
      "Boxin Shi",
      "Lin Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qian_3DGS-Avatar_Animatable_Avatars_via_Deformable_3D_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyin Qian",
      "Shaofei Wang",
      "Marko Mihajlovic",
      "Andreas Geiger",
      "Siyu Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Seyfioglu_Quilt-LLaVA_Visual_Instruction_Tuning_by_Extracting_Localized_Narratives_from_Open-Source_CVPR_2024_paper.html": {
    "title": "Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized Narratives from Open-Source Histopathology Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehmet Saygin Seyfioglu",
      "Wisdom O. Ikezogwo",
      "Fatemeh Ghezloo",
      "Ranjay Krishna",
      "Linda Shapiro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Traffic_Scene_Parsing_through_the_TSP6K_Dataset_CVPR_2024_paper.html": {
    "title": "Traffic Scene Parsing through the TSP6K Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng-Tao Jiang",
      "Yuqi Yang",
      "Yang Cao",
      "Qibin Hou",
      "Ming-Ming Cheng",
      "Chunhua Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hertz_Style_Aligned_Image_Generation_via_Shared_Attention_CVPR_2024_paper.html": {
    "title": "Style Aligned Image Generation via Shared Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Hertz",
      "Andrey Voynov",
      "Shlomi Fruchter",
      "Daniel Cohen-Or"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_E-GPS_Explainable_Geometry_Problem_Solving_via_Top-Down_Solver_and_Bottom-Up_CVPR_2024_paper.html": {
    "title": "E-GPS: Explainable Geometry Problem Solving via Top-Down Solver and Bottom-Up Generator",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjun Wu",
      "Lingling Zhang",
      "Jun Liu",
      "Xi Tang",
      "Yaxian Wang",
      "Shaowei Wang",
      "Qianying Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wimmer_Back_to_3D_Few-Shot_3D_Keypoint_Detection_with_Back-Projected_2D_CVPR_2024_paper.html": {
    "title": "Back to 3D: Few-Shot 3D Keypoint Detection with Back-Projected 2D Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Wimmer",
      "Peter Wonka",
      "Maks Ovsjanikov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lv_Fourier_Priors-Guided_Diffusion_for_Zero-Shot_Joint_Low-Light_Enhancement_and_Deblurring_CVPR_2024_paper.html": {
    "title": "Fourier Priors-Guided Diffusion for Zero-Shot Joint Low-Light Enhancement and Deblurring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqian Lv",
      "Shengping Zhang",
      "Chenyang Wang",
      "Yichen Zheng",
      "Bineng Zhong",
      "Chongyi Li",
      "Liqiang Nie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guan_Neural_Markov_Random_Field_for_Stereo_Matching_CVPR_2024_paper.html": {
    "title": "Neural Markov Random Field for Stereo Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongfan Guan",
      "Chen Wang",
      "Yun-Hui Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Driving_into_the_Future_Multiview_Visual_Forecasting_and_Planning_with_CVPR_2024_paper.html": {
    "title": "Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Wang",
      "Jiawei He",
      "Lue Fan",
      "Hongxin Li",
      "Yuntao Chen",
      "Zhaoxiang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kong_OpenESS_Event-based_Semantic_Scene_Understanding_with_Open_Vocabularies_CVPR_2024_paper.html": {
    "title": "OpenESS: Event-based Semantic Scene Understanding with Open Vocabularies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingdong Kong",
      "Youquan Liu",
      "Lai Xing Ng",
      "Benoit R. Cottereau",
      "Wei Tsang Ooi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Maniparambil_Do_Vision_and_Language_Encoders_Represent_the_World_Similarly_CVPR_2024_paper.html": {
    "title": "Do Vision and Language Encoders Represent the World Similarly?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mayug Maniparambil",
      "Raiymbek Akshulakov",
      "Yasser Abdelaziz Dahou Djilali",
      "Mohamed El Amine Seddik",
      "Sanath Narayan",
      "Karttikeya Mangalam",
      "Noel E. O'Connor"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_MGMap_Mask-Guided_Learning_for_Online_Vectorized_HD_Map_Construction_CVPR_2024_paper.html": {
    "title": "MGMap: Mask-Guided Learning for Online Vectorized HD Map Construction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaolu Liu",
      "Song Wang",
      "Wentong Li",
      "Ruizi Yang",
      "Junbo Chen",
      "Jianke Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Scaling_Up_to_Excellence_Practicing_Model_Scaling_for_Photo-Realistic_Image_CVPR_2024_paper.html": {
    "title": "Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fanghua Yu",
      "Jinjin Gu",
      "Zheyuan Li",
      "Jinfan Hu",
      "Xiangtao Kong",
      "Xintao Wang",
      "Jingwen He",
      "Yu Qiao",
      "Chao Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Q-Instruct_Improving_Low-level_Visual_Abilities_for_Multi-modality_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Q-Instruct: Improving Low-level Visual Abilities for Multi-modality Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoning Wu",
      "Zicheng Zhang",
      "Erli Zhang",
      "Chaofeng Chen",
      "Liang Liao",
      "Annan Wang",
      "Kaixin Xu",
      "Chunyi Li",
      "Jingwen Hou",
      "Guangtao Zhai",
      "Geng Xue",
      "Wenxiu Sun",
      "Qiong Yan",
      "Weisi Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_PoseIRM_Enhance_3D_Human_Pose_Estimation_on_Unseen_Camera_Settings_CVPR_2024_paper.html": {
    "title": "PoseIRM: Enhance 3D Human Pose Estimation on Unseen Camera Settings via Invariant Risk Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanlu Cai",
      "Weizhong Zhang",
      "Yuan Wu",
      "Cheng Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Zero-Shot_Structure-Preserving_Diffusion_Model_for_High_Dynamic_Range_Tone_Mapping_CVPR_2024_paper.html": {
    "title": "Zero-Shot Structure-Preserving Diffusion Model for High Dynamic Range Tone Mapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoxi Zhu",
      "Shusong Xu",
      "Peiye Liu",
      "Sicheng Li",
      "Yanheng Lu",
      "Dimin Niu",
      "Zihao Liu",
      "Zihao Meng",
      "Zhiyong Li",
      "Xinhua Chen",
      "Yibo Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rizve_VidLA_Video-Language_Alignment_at_Scale_CVPR_2024_paper.html": {
    "title": "VidLA: Video-Language Alignment at Scale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mamshad Nayeem Rizve",
      "Fan Fei",
      "Jayakrishnan Unnikrishnan",
      "Son Tran",
      "Benjamin Z. Yao",
      "Belinda Zeng",
      "Mubarak Shah",
      "Trishul Chilimbi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_VoCo_A_Simple-yet-Effective_Volume_Contrastive_Learning_Framework_for_3D_Medical_CVPR_2024_paper.html": {
    "title": "VoCo: A Simple-yet-Effective Volume Contrastive Learning Framework for 3D Medical Image Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linshan Wu",
      "Jiaxin Zhuang",
      "Hao Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_CCEdit_Creative_and_Controllable_Video_Editing_via_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "CCEdit: Creative and Controllable Video Editing via Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoyu Feng",
      "Wenming Weng",
      "Yanhui Wang",
      "Yuhui Yuan",
      "Jianmin Bao",
      "Chong Luo",
      "Zhibo Chen",
      "Baining Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_IPoD_Implicit_Field_Learning_with_Point_Diffusion_for_Generalizable_3D_CVPR_2024_paper.html": {
    "title": "IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yushuang Wu",
      "Luyue Shi",
      "Junhao Cai",
      "Weihao Yuan",
      "Lingteng Qiu",
      "Zilong Dong",
      "Liefeng Bo",
      "Shuguang Cui",
      "Xiaoguang Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_HAVE-FUN_Human_Avatar_Reconstruction_from_Few-Shot_Unconstrained_Images_CVPR_2024_paper.html": {
    "title": "HAVE-FUN: Human Avatar Reconstruction from Few-Shot Unconstrained Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xihe Yang",
      "Xingyu Chen",
      "Daiheng Gao",
      "Shaohui Wang",
      "Xiaoguang Han",
      "Baoyuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_ERMVP_Communication-Efficient_and_Collaboration-Robust_Multi-Vehicle_Perception_in_Challenging_Environments_CVPR_2024_paper.html": {
    "title": "ERMVP: Communication-Efficient and Collaboration-Robust Multi-Vehicle Perception in Challenging Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyu Zhang",
      "Kun Yang",
      "Yilei Wang",
      "Hanqi Wang",
      "Peng Sun",
      "Liang Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_DiffMorpher_Unleashing_the_Capability_of_Diffusion_Models_for_Image_Morphing_CVPR_2024_paper.html": {
    "title": "DiffMorpher: Unleashing the Capability of Diffusion Models for Image Morphing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiwen Zhang",
      "Yifan Zhou",
      "Xudong Xu",
      "Bo Dai",
      "Xingang Pan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shu_Towards_Real-World_HDR_Video_Reconstruction_A_Large-Scale_Benchmark_Dataset_and_CVPR_2024_paper.html": {
    "title": "Towards Real-World HDR Video Reconstruction: A Large-Scale Benchmark Dataset and A Two-Stage Alignment Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yong Shu",
      "Liquan Shen",
      "Xiangyu Hu",
      "Mengyao Li",
      "Zihao Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bai_Efficient_3D_Implicit_Head_Avatar_with_Mesh-anchored_Hash_Table_Blendshapes_CVPR_2024_paper.html": {
    "title": "Efficient 3D Implicit Head Avatar with Mesh-anchored Hash Table Blendshapes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqian Bai",
      "Feitong Tan",
      "Sean Fanello",
      "Rohit Pandey",
      "Mingsong Dou",
      "Shichen Liu",
      "Ping Tan",
      "Yinda Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Neseem_PikeLPN_Mitigating_Overlooked_Inefficiencies_of_Low-Precision_Neural_Networks_CVPR_2024_paper.html": {
    "title": "PikeLPN: Mitigating Overlooked Inefficiencies of Low-Precision Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marina Neseem",
      "Conor McCullough",
      "Randy Hsin",
      "Chas Leichner",
      "Shan Li",
      "In Suk Chong",
      "Andrew Howard",
      "Lukasz Lew",
      "Sherief Reda",
      "Ville-Mikko Rautio",
      "Daniele Moro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Stearns_CurveCloudNet_Processing_Point_Clouds_with_1D_Structure_CVPR_2024_paper.html": {
    "title": "CurveCloudNet: Processing Point Clouds with 1D Structure",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Colton Stearns",
      "Alex Fu",
      "Jiateng Liu",
      "Jeong Joon Park",
      "Davis Rempe",
      "Despoina Paschalidou",
      "Leonidas J. Guibas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_CAGE_Controllable_Articulation_GEneration_CVPR_2024_paper.html": {
    "title": "CAGE: Controllable Articulation GEneration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Liu",
      "Hou In Ivan Tam",
      "Ali Mahdavi-Amiri",
      "Manolis Savva"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_No_Time_to_Train_Empowering_Non-Parametric_Networks_for_Few-shot_3D_CVPR_2024_paper.html": {
    "title": "No Time to Train: Empowering Non-Parametric Networks for Few-shot 3D Scene Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyang Zhu",
      "Renrui Zhang",
      "Bowei He",
      "Ziyu Guo",
      "Jiaming Liu",
      "Han Xiao",
      "Chaoyou Fu",
      "Hao Dong",
      "Peng Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_PhysGaussian_Physics-Integrated_3D_Gaussians_for_Generative_Dynamics_CVPR_2024_paper.html": {
    "title": "PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Xie",
      "Zeshun Zong",
      "Yuxing Qiu",
      "Xuan Li",
      "Yutao Feng",
      "Yin Yang",
      "Chenfanfu Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Spatio-Temporal_Turbulence_Mitigation_A_Translational_Perspective_CVPR_2024_paper.html": {
    "title": "Spatio-Temporal Turbulence Mitigation: A Translational Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingguang Zhang",
      "Nicholas Chimitt",
      "Yiheng Chi",
      "Zhiyuan Mao",
      "Stanley H. Chan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Basu_FocusMAE_Gallbladder_Cancer_Detection_from_Ultrasound_Videos_with_Focused_Masked_CVPR_2024_paper.html": {
    "title": "FocusMAE: Gallbladder Cancer Detection from Ultrasound Videos with Focused Masked Autoencoders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumen Basu",
      "Mayuna Gupta",
      "Chetan Madan",
      "Pankaj Gupta",
      "Chetan Arora"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Phung_Grounded_Text-to-Image_Synthesis_with_Attention_Refocusing_CVPR_2024_paper.html": {
    "title": "Grounded Text-to-Image Synthesis with Attention Refocusing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quynh Phung",
      "Songwei Ge",
      "Jia-Bin Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Astruc_OpenStreetView-5M_The_Many_Roads_to_Global_Visual_Geolocation_CVPR_2024_paper.html": {
    "title": "OpenStreetView-5M: The Many Roads to Global Visual Geolocation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillaume Astruc",
      "Nicolas Dufour",
      "Ioannis Siglidis",
      "Constantin Aronssohn",
      "Nacim Bouia",
      "Stephanie Fu",
      "Romain Loiseau",
      "Van Nguyen Nguyen",
      "Charles Raude",
      "Elliot Vincent",
      "Lintao Xu",
      "Hongyu Zhou",
      "Loic Landrieu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kowal_Visual_Concept_Connectome_VCC_Open_World_Concept_Discovery_and_their_CVPR_2024_paper.html": {
    "title": "Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Kowal",
      "Richard P. Wildes",
      "Konstantinos G. Derpanis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mazzucchelli_IReNe_Instant_Recoloring_of_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "IReNe: Instant Recoloring of Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessio Mazzucchelli",
      "Adrian Garcia-Garcia",
      "Elena Garces",
      "Fernando Rivas-Manzaneque",
      "Francesc Moreno-Noguer",
      "Adrian Penate-Sanchez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yoon_Class_Tokens_Infusion_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Class Tokens Infusion for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sung-Hoon Yoon",
      "Hoyong Kwon",
      "Hyeonseong Kim",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_FedHCA2_Towards_Hetero-Client_Federated_Multi-Task_Learning_CVPR_2024_paper.html": {
    "title": "FedHCA2: Towards Hetero-Client Federated Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiang Lu",
      "Suizhi Huang",
      "Yuwen Yang",
      "Shalayiding Sirejiding",
      "Yue Ding",
      "Hongtao Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yi_Text-IF_Leveraging_Semantic_Text_Guidance_for_Degradation-Aware_and_Interactive_Image_CVPR_2024_paper.html": {
    "title": "Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunpeng Yi",
      "Han Xu",
      "Hao Zhang",
      "Linfeng Tang",
      "Jiayi Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Blau_GRAM_Global_Reasoning_for_Multi-Page_VQA_CVPR_2024_paper.html": {
    "title": "GRAM: Global Reasoning for Multi-Page VQA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsachi Blau",
      "Sharon Fogel",
      "Roi Ronen",
      "Alona Golts",
      "Roy Ganz",
      "Elad Ben Avraham",
      "Aviad Aberdam",
      "Shahar Tsiper",
      "Ron Litman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_MS-DETR_Efficient_DETR_Training_with_Mixed_Supervision_CVPR_2024_paper.html": {
    "title": "MS-DETR: Efficient DETR Training with Mixed Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuyang Zhao",
      "Yifan Sun",
      "Wenhao Wang",
      "Qiang Chen",
      "Errui Ding",
      "Yi Yang",
      "Jingdong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Giang_Learning_to_Produce_Semi-dense_Correspondences_for_Visual_Localization_CVPR_2024_paper.html": {
    "title": "Learning to Produce Semi-dense Correspondences for Visual Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khang Truong Giang",
      "Soohwan Song",
      "Sungho Jo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhan_Amodal_Ground_Truth_and_Completion_in_the_Wild_CVPR_2024_paper.html": {
    "title": "Amodal Ground Truth and Completion in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanqi Zhan",
      "Chuanxia Zheng",
      "Weidi Xie",
      "Andrew Zisserman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Motion_Diversification_Networks_CVPR_2024_paper.html": {
    "title": "Motion Diversification Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hee Jae Kim",
      "Eshed Ohn-Bar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Telling_Left_from_Right_Identifying_Geometry-Aware_Semantic_Correspondence_CVPR_2024_paper.html": {
    "title": "Telling Left from Right: Identifying Geometry-Aware Semantic Correspondence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Zhang",
      "Charles Herrmann",
      "Junhwa Hur",
      "Eric Chen",
      "Varun Jampani",
      "Deqing Sun",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_NECA_Neural_Customizable_Human_Avatar_CVPR_2024_paper.html": {
    "title": "NECA: Neural Customizable Human Avatar",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjin Xiao",
      "Qing Zhang",
      "Zhan Xu",
      "Wei-Shi Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_BEVSpread_Spread_Voxel_Pooling_for_Birds-Eye-View_Representation_in_Vision-based_Roadside_CVPR_2024_paper.html": {
    "title": "BEVSpread: Spread Voxel Pooling for Bird's-Eye-View Representation in Vision-based Roadside 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjie Wang",
      "Yehao Lu",
      "Guangcong Zheng",
      "Shuigen Zhan",
      "Xiaoqing Ye",
      "Zichang Tan",
      "Jingdong Wang",
      "Gaoang Wang",
      "Xi Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Real-IAD_A_Real-World_Multi-View_Dataset_for_Benchmarking_Versatile_Industrial_Anomaly_CVPR_2024_paper.html": {
    "title": "Real-IAD: A Real-World Multi-View Dataset for Benchmarking Versatile Industrial Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengjie Wang",
      "Wenbing Zhu",
      "Bin-Bin Gao",
      "Zhenye Gan",
      "Jiangning Zhang",
      "Zhihao Gu",
      "Shuguang Qian",
      "Mingang Chen",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Goel_PAIR_Diffusion_A_Comprehensive_Multimodal_Object-Level_Image_Editor_CVPR_2024_paper.html": {
    "title": "PAIR Diffusion: A Comprehensive Multimodal Object-Level Image Editor",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vidit Goel",
      "Elia Peruzzo",
      "Yifan Jiang",
      "Dejia Xu",
      "Xingqian Xu",
      "Nicu Sebe",
      "Trevor Darrell",
      "Zhangyang Wang",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Boosting_Adversarial_Transferability_by_Block_Shuffle_and_Rotation_CVPR_2024_paper.html": {
    "title": "Boosting Adversarial Transferability by Block Shuffle and Rotation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunyu Wang",
      "Xuanran He",
      "Wenxuan Wang",
      "Xiaosen Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Min_DriveWorld_4D_Pre-trained_Scene_Understanding_via_World_Models_for_Autonomous_CVPR_2024_paper.html": {
    "title": "DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Min",
      "Dawei Zhao",
      "Liang Xiao",
      "Jian Zhao",
      "Xinli Xu",
      "Zheng Zhu",
      "Lei Jin",
      "Jianshu Li",
      "Yulan Guo",
      "Junliang Xing",
      "Liping Jing",
      "Yiming Nie",
      "Bin Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Bridging_the_Gap_Between_End-to-End_and_Two-Step_Text_Spotting_CVPR_2024_paper.html": {
    "title": "Bridging the Gap Between End-to-End and Two-Step Text Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingxin Huang",
      "Hongliang Li",
      "Yuliang Liu",
      "Xiang Bai",
      "Lianwen Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_TokenCompose_Text-to-Image_Diffusion_with_Token-level_Supervision_CVPR_2024_paper.html": {
    "title": "TokenCompose: Text-to-Image Diffusion with Token-level Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zirui Wang",
      "Zhizhou Sha",
      "Zheng Ding",
      "Yilin Wang",
      "Zhuowen Tu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SUGAR_Pre-training_3D_Visual_Representations_for_Robotics_CVPR_2024_paper.html": {
    "title": "SUGAR: Pre-training 3D Visual Representations for Robotics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shizhe Chen",
      "Ricardo Garcia",
      "Ivan Laptev",
      "Cordelia Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_LidaRF_Delving_into_Lidar_for_Neural_Radiance_Field_on_Street_CVPR_2024_paper.html": {
    "title": "LidaRF: Delving into Lidar for Neural Radiance Field on Street Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanlin Sun",
      "Bingbing Zhuang",
      "Ziyu Jiang",
      "Buyu Liu",
      "Xiaohui Xie",
      "Manmohan Chandraker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_PairAug_What_Can_Augmented_Image-Text_Pairs_Do_for_Radiology_CVPR_2024_paper.html": {
    "title": "PairAug: What Can Augmented Image-Text Pairs Do for Radiology?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutong Xie",
      "Qi Chen",
      "Sinuo Wang",
      "Minh-Son To",
      "Iris Lee",
      "Ee Win Khoo",
      "Kerolos Hendy",
      "Daniel Koh",
      "Yong Xia",
      "Qi Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_FINER_Flexible_Spectral-bias_Tuning_in_Implicit_NEural_Representation_by_Variable-periodic_CVPR_2024_paper.html": {
    "title": "FINER: Flexible Spectral-bias Tuning in Implicit NEural Representation by Variable-periodic Activation Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Liu",
      "Hao Zhu",
      "Qi Zhang",
      "Jingde Fu",
      "Weibing Deng",
      "Zhan Ma",
      "Yanwen Guo",
      "Xun Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zanella_Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection_CVPR_2024_paper.html": {
    "title": "Harnessing Large Language Models for Training-free Video Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Zanella",
      "Willi Menapace",
      "Massimiliano Mancini",
      "Yiming Wang",
      "Elisa Ricci"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_TextCraftor_Your_Text_Encoder_Can_be_Image_Quality_Controller_CVPR_2024_paper.html": {
    "title": "TextCraftor: Your Text Encoder Can be Image Quality Controller",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanyu Li",
      "Xian Liu",
      "Anil Kag",
      "Ju Hu",
      "Yerlan Idelbayev",
      "Dhritiman Sagar",
      "Yanzhi Wang",
      "Sergey Tulyakov",
      "Jian Ren"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_FineParser_A_Fine-grained_Spatio-temporal_Action_Parser_for_Human-centric_Action_Quality_CVPR_2024_paper.html": {
    "title": "FineParser: A Fine-grained Spatio-temporal Action Parser for Human-centric Action Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinglin Xu",
      "Sibo Yin",
      "Guohao Zhao",
      "Zishuo Wang",
      "Yuxin Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_Video_Recognition_in_Portrait_Mode_CVPR_2024_paper.html": {
    "title": "Video Recognition in Portrait Mode",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingfei Han",
      "Linjie Yang",
      "Xiaojie Jin",
      "Jiashi Feng",
      "Xiaojun Chang",
      "Heng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Selective_Hourglass_Mapping_for_Universal_Image_Restoration_Based_on_Diffusion_CVPR_2024_paper.html": {
    "title": "Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dian Zheng",
      "Xiao-Ming Wu",
      "Shuzhou Yang",
      "Jian Zhang",
      "Jian-Fang Hu",
      "Wei-Shi Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Language_Models_as_Black-Box_Optimizers_for_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Language Models as Black-Box Optimizers for Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shihong Liu",
      "Samuel Yu",
      "Zhiqiu Lin",
      "Deepak Pathak",
      "Deva Ramanan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Exploring_Orthogonality_in_Open_World_Object_Detection_CVPR_2024_paper.html": {
    "title": "Exploring Orthogonality in Open World Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicheng Sun",
      "Jinghan Li",
      "Yadong Mu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Leng_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_through_Visual_Contrastive_CVPR_2024_paper.html": {
    "title": "Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sicong Leng",
      "Hang Zhang",
      "Guanzheng Chen",
      "Xin Li",
      "Shijian Lu",
      "Chunyan Miao",
      "Lidong Bing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_IMPRINT_Generative_Object_Compositing_by_Learning_Identity-Preserving_Representation_CVPR_2024_paper.html": {
    "title": "IMPRINT: Generative Object Compositing by Learning Identity-Preserving Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhi Song",
      "Zhifei Zhang",
      "Zhe Lin",
      "Scott Cohen",
      "Brian Price",
      "Jianming Zhang",
      "Soo Ye Kim",
      "He Zhang",
      "Wei Xiong",
      "Daniel Aliaga"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Audio-Visual_Segmentation_via_Unlabeled_Frame_Exploitation_CVPR_2024_paper.html": {
    "title": "Audio-Visual Segmentation via Unlabeled Frame Exploitation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinxiang Liu",
      "Yikun Liu",
      "Fei Zhang",
      "Chen Ju",
      "Ya Zhang",
      "Yanfeng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Balasingam_DriveTrack_A_Benchmark_for_Long-Range_Point_Tracking_in_Real-World_Videos_CVPR_2024_paper.html": {
    "title": "DriveTrack: A Benchmark for Long-Range Point Tracking in Real-World Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arjun Balasingam",
      "Joseph Chandler",
      "Chenning Li",
      "Zhoutong Zhang",
      "Hari Balakrishnan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Infrared_Adversarial_Car_Stickers_CVPR_2024_paper.html": {
    "title": "Infrared Adversarial Car Stickers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaopei Zhu",
      "Yuqiu Liu",
      "Zhanhao Hu",
      "Jianmin Li",
      "Xiaolin Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Sculpt3D_Multi-View_Consistent_Text-to-3D_Generation_with_Sparse_3D_Prior_CVPR_2024_paper.html": {
    "title": "Sculpt3D: Multi-View Consistent Text-to-3D Generation with Sparse 3D Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Chen",
      "Xiaofeng Yang",
      "Fan Yang",
      "Chengzeng Feng",
      "Zhoujie Fu",
      "Chuan-Sheng Foo",
      "Guosheng Lin",
      "Fayao Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_FreeMan_Towards_Benchmarking_3D_Human_Pose_Estimation_under_Real-World_Conditions_CVPR_2024_paper.html": {
    "title": "FreeMan: Towards Benchmarking 3D Human Pose Estimation under Real-World Conditions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiong Wang",
      "Fengyu Yang",
      "Bingliang Li",
      "Wenbo Gou",
      "Danqi Yan",
      "Ailing Zeng",
      "Yijun Gao",
      "Junle Wang",
      "Yanqing Jing",
      "Ruimao Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Su_ScanFormer_Referring_Expression_Comprehension_by_Iteratively_Scanning_CVPR_2024_paper.html": {
    "title": "ScanFormer: Referring Expression Comprehension by Iteratively Scanning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Su",
      "Peihan Miao",
      "Huanzhang Dou",
      "Xi Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ho_Model_Inversion_Robustness_Can_Transfer_Learning_Help_CVPR_2024_paper.html": {
    "title": "Model Inversion Robustness: Can Transfer Learning Help?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sy-Tuyen Ho",
      "Koh Jun Hao",
      "Keshigeyan Chandrasegaran",
      "Ngoc-Bao Nguyen",
      "Ngai-Man Cheung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_Portrait4D_Learning_One-Shot_4D_Head_Avatar_Synthesis_using_Synthetic_Data_CVPR_2024_paper.html": {
    "title": "Portrait4D: Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Deng",
      "Duomin Wang",
      "Xiaohang Ren",
      "Xingyu Chen",
      "Baoyuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_GP-NeRF_Generalized_Perception_NeRF_for_Context-Aware_3D_Scene_Understanding_CVPR_2024_paper.html": {
    "title": "GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Li",
      "Dingwen Zhang",
      "Yalun Dai",
      "Nian Liu",
      "Lechao Cheng",
      "Jingfeng Li",
      "Jingdong Wang",
      "Junwei Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Scheuble_Polarization_Wavefront_Lidar_Learning_Large_Scene_Reconstruction_from_Polarized_Wavefronts_CVPR_2024_paper.html": {
    "title": "Polarization Wavefront Lidar: Learning Large Scene Reconstruction from Polarized Wavefronts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dominik Scheuble",
      "Chenyang Lei",
      "Seung-Hwan Baek",
      "Mario Bijelic",
      "Felix Heide"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tsai_GDA_Generalized_Diffusion_for_Robust_Test-time_Adaptation_CVPR_2024_paper.html": {
    "title": "GDA: Generalized Diffusion for Robust Test-time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun-Yun Tsai",
      "Fu-Chen Chen",
      "Albert Y. C. Chen",
      "Junfeng Yang",
      "Che-Chun Su",
      "Min Sun",
      "Cheng-Hao Kuo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mughal_ConvoFusion_Multi-Modal_Conversational_Diffusion_for_Co-Speech_Gesture_Synthesis_CVPR_2024_paper.html": {
    "title": "ConvoFusion: Multi-Modal Conversational Diffusion for Co-Speech Gesture Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Hamza Mughal",
      "Rishabh Dabral",
      "Ikhsanul Habibie",
      "Lucia Donatelli",
      "Marc Habermann",
      "Christian Theobalt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_RLHF-V_Towards_Trustworthy_MLLMs_via_Behavior_Alignment_from_Fine-grained_Correctional_CVPR_2024_paper.html": {
    "title": "RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Yu",
      "Yuan Yao",
      "Haoye Zhang",
      "Taiwen He",
      "Yifeng Han",
      "Ganqu Cui",
      "Jinyi Hu",
      "Zhiyuan Liu",
      "Hai-Tao Zheng",
      "Maosong Sun",
      "Tat-Seng Chua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_ZeroShape_Regression-based_Zero-shot_Shape_Reconstruction_CVPR_2024_paper.html": {
    "title": "ZeroShape: Regression-based Zero-shot Shape Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Huang",
      "Stefan Stojanov",
      "Anh Thai",
      "Varun Jampani",
      "James M. Rehg"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Continual-MAE_Adaptive_Distribution_Masked_Autoencoders_for_Continual_Test-Time_Adaptation_CVPR_2024_paper.html": {
    "title": "Continual-MAE: Adaptive Distribution Masked Autoencoders for Continual Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Liu",
      "Ran Xu",
      "Senqiao Yang",
      "Renrui Zhang",
      "Qizhe Zhang",
      "Zehui Chen",
      "Yandong Guo",
      "Shanghang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_The_STVchrono_Dataset_Towards_Continuous_Change_Recognition_in_Time_CVPR_2024_paper.html": {
    "title": "The STVchrono Dataset: Towards Continuous Change Recognition in Time",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanjun Sun",
      "Yue Qiu",
      "Mariia Khan",
      "Fumiya Matsuzawa",
      "Kenji Iwata"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wong_SocialCircle_Learning_the_Angle-based_Social_Interaction_Representation_for_Pedestrian_Trajectory_CVPR_2024_paper.html": {
    "title": "SocialCircle: Learning the Angle-based Social Interaction Representation for Pedestrian Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Conghao Wong",
      "Beihao Xia",
      "Ziqian Zou",
      "Yulong Wang",
      "Xinge You"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Boosting_Neural_Representations_for_Videos_with_a_Conditional_Decoder_CVPR_2024_paper.html": {
    "title": "Boosting Neural Representations for Videos with a Conditional Decoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinjie Zhang",
      "Ren Yang",
      "Dailan He",
      "Xingtong Ge",
      "Tongda Xu",
      "Yan Wang",
      "Hongwei Qin",
      "Jun Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Dual-Enhanced_Coreset_Selection_with_Class-wise_Collaboration_for_Online_Blurry_Class_CVPR_2024_paper.html": {
    "title": "Dual-Enhanced Coreset Selection with Class-wise Collaboration for Online Blurry Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutian Luo",
      "Shiqi Zhao",
      "Haoran Wu",
      "Zhiwu Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ng_From_Audio_to_Photoreal_Embodiment_Synthesizing_Humans_in_Conversations_CVPR_2024_paper.html": {
    "title": "From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Evonne Ng",
      "Javier Romero",
      "Timur Bagautdinov",
      "Shaojie Bai",
      "Trevor Darrell",
      "Angjoo Kanazawa",
      "Alexander Richard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Single-View_Scene_Point_Cloud_Human_Grasp_Generation_CVPR_2024_paper.html": {
    "title": "Single-View Scene Point Cloud Human Grasp Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan-Kang Wang",
      "Chengyi Xing",
      "Yi-Lin Wei",
      "Xiao-Ming Wu",
      "Wei-Shi Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_One-step_Diffusion_with_Distribution_Matching_Distillation_CVPR_2024_paper.html": {
    "title": "One-step Diffusion with Distribution Matching Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianwei Yin",
      "Michaël Gharbi",
      "Richard Zhang",
      "Eli Shechtman",
      "Frédo Durand",
      "William T. Freeman",
      "Taesung Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Cyclic_Learning_for_Binaural_Audio_Generation_and_Localization_CVPR_2024_paper.html": {
    "title": "Cyclic Learning for Binaural Audio Generation and Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaojian Li",
      "Bin Zhao",
      "Yuan Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Neighbor_Relations_Matter_in_Video_Scene_Detection_CVPR_2024_paper.html": {
    "title": "Neighbor Relations Matter in Video Scene Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Tan",
      "Hongxing Wang",
      "Jiaxin Li",
      "Zhilong Ou",
      "Zhangbin Qian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Rethinking_Human_Motion_Prediction_with_Symplectic_Integral_CVPR_2024_paper.html": {
    "title": "Rethinking Human Motion Prediction with Symplectic Integral",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haipeng Chen",
      "Kedi Lyu",
      "Zhenguang Liu",
      "Yifang Yin",
      "Xun Yang",
      "Yingda Lyu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Koley_Text-to-Image_Diffusion_Models_are_Great_Sketch-Photo_Matchmakers_CVPR_2024_paper.html": {
    "title": "Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhadeep Koley",
      "Ayan Kumar Bhunia",
      "Aneeshan Sain",
      "Pinaki Nath Chowdhury",
      "Tao Xiang",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Mudslide_A_Universal_Nuclear_Instance_Segmentation_Method_CVPR_2024_paper.html": {
    "title": "Mudslide: A Universal Nuclear Instance Segmentation Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_CPGA_Coding_Priors-Guided_Aggregation_Network_for_Compressed_Video_Quality_Enhancement_CVPR_2024_paper.html": {
    "title": "CPGA: Coding Priors-Guided Aggregation Network for Compressed Video Quality Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiang Zhu",
      "Jinhua Hao",
      "Yukang Ding",
      "Yu Liu",
      "Qiao Mo",
      "Ming Sun",
      "Chao Zhou",
      "Shuyuan Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_MicroCinema_A_Divide-and-Conquer_Approach_for_Text-to-Video_Generation_CVPR_2024_paper.html": {
    "title": "MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhui Wang",
      "Jianmin Bao",
      "Wenming Weng",
      "Ruoyu Feng",
      "Dacheng Yin",
      "Tao Yang",
      "Jingxu Zhang",
      "Qi Dai",
      "Zhiyuan Zhao",
      "Chunyu Wang",
      "Kai Qiu",
      "Yuhui Yuan",
      "Xiaoyan Sun",
      "Chong Luo",
      "Baining Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Learning_Instance-Aware_Correspondences_for_Robust_Multi-Instance_Point_Cloud_Registration_in_CVPR_2024_paper.html": {
    "title": "Learning Instance-Aware Correspondences for Robust Multi-Instance Point Cloud Registration in Cluttered Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Yu",
      "Zheng Qin",
      "Lintao Zheng",
      "Kai Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Structure_Matters_Tackling_the_Semantic_Discrepancy_in_Diffusion_Models_for_CVPR_2024_paper.html": {
    "title": "Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models for Image Inpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haipeng Liu",
      "Yang Wang",
      "Biao Qian",
      "Meng Wang",
      "Yong Rui"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Modeling_Multimodal_Social_Interactions_New_Challenges_and_Baselines_with_Densely_CVPR_2024_paper.html": {
    "title": "Modeling Multimodal Social Interactions: New Challenges and Baselines with Densely Aligned Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangmin Lee",
      "Bolin Lai",
      "Fiona Ryan",
      "Bikram Boote",
      "James M. Rehg"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_COCONut_Modernizing_COCO_Segmentation_CVPR_2024_paper.html": {
    "title": "COCONut: Modernizing COCO Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xueqing Deng",
      "Qihang Yu",
      "Peng Wang",
      "Xiaohui Shen",
      "Liang-Chieh Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ko_Semantic_Line_Combination_Detector_CVPR_2024_paper.html": {
    "title": "Semantic Line Combination Detector",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinwon Ko",
      "Dongkwon Jin",
      "Chang-Su Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Prompt-Driven_Dynamic_Object-Centric_Learning_for_Single_Domain_Generalization_CVPR_2024_paper.html": {
    "title": "Prompt-Driven Dynamic Object-Centric Learning for Single Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Deng Li",
      "Aming Wu",
      "Yaowei Wang",
      "Yahong Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sarkar_Dual_Pose-invariant_Embeddings_Learning_Category_and_Object-specific_Discriminative_Representations_for_CVPR_2024_paper.html": {
    "title": "Dual Pose-invariant Embeddings: Learning Category and Object-specific Discriminative Representations for Recognition and Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rohan Sarkar",
      "Avinash Kak"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_vid-TLDR_Training_Free_Token_Merging_for_Light-weight_Video_Transformer_CVPR_2024_paper.html": {
    "title": "vid-TLDR: Training Free Token Merging for Light-weight Video Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joonmyung Choi",
      "Sanghyeok Lee",
      "Jaewon Chu",
      "Minhyuk Choi",
      "Hyunwoo J. Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_DRESS_Instructing_Large_Vision-Language_Models_to_Align_and_Interact_with_CVPR_2024_paper.html": {
    "title": "DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yangyi Chen",
      "Karan Sikka",
      "Michael Cogswell",
      "Heng Ji",
      "Ajay Divakaran"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Makeup_Prior_Models_for_3D_Facial_Makeup_Estimation_and_Applications_CVPR_2024_paper.html": {
    "title": "Makeup Prior Models for 3D Facial Makeup Estimation and Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingchao Yang",
      "Takafumi Taketomi",
      "Yuki Endo",
      "Yoshihiro Kanamori"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hou_Salience_DETR_Enhancing_Detection_Transformer_with_Hierarchical_Salience_Filtering_Refinement_CVPR_2024_paper.html": {
    "title": "Salience DETR: Enhancing Detection Transformer with Hierarchical Salience Filtering Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiuquan Hou",
      "Meiqin Liu",
      "Senlin Zhang",
      "Ping Wei",
      "Badong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sheng_Towards_More_Unified_In-context_Visual_Understanding_CVPR_2024_paper.html": {
    "title": "Towards More Unified In-context Visual Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dianmo Sheng",
      "Dongdong Chen",
      "Zhentao Tan",
      "Qiankun Liu",
      "Qi Chu",
      "Jianmin Bao",
      "Tao Gong",
      "Bin Liu",
      "Shengwei Xu",
      "Nenghai Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_F3Loc_Fusion_and_Filtering_for_Floorplan_Localization_CVPR_2024_paper.html": {
    "title": "F3Loc: Fusion and Filtering for Floorplan Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changan Chen",
      "Rui Wang",
      "Christoph Vogel",
      "Marc Pollefeys"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_ReconFusion_3D_Reconstruction_with_Diffusion_Priors_CVPR_2024_paper.html": {
    "title": "ReconFusion: 3D Reconstruction with Diffusion Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rundi Wu",
      "Ben Mildenhall",
      "Philipp Henzler",
      "Keunhong Park",
      "Ruiqi Gao",
      "Daniel Watson",
      "Pratul P. Srinivasan",
      "Dor Verbin",
      "Jonathan T. Barron",
      "Ben Poole",
      "Aleksander Ho?y?ski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_IM_HOI_Inertia-aware_Monocular_Capture_of_3D_Human-Object_Interactions_CVPR_2024_paper.html": {
    "title": "I'M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengfeng Zhao",
      "Juze Zhang",
      "Jiashen Du",
      "Ziwei Shan",
      "Junye Wang",
      "Jingyi Yu",
      "Jingya Wang",
      "Lan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Dynamic_Policy-Driven_Adaptive_Multi-Instance_Learning_for_Whole_Slide_Image_Classification_CVPR_2024_paper.html": {
    "title": "Dynamic Policy-Driven Adaptive Multi-Instance Learning for Whole Slide Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingting Zheng",
      "Kui Jiang",
      "Hongxun Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_InternVL_Scaling_up_Vision_Foundation_Models_and_Aligning_for_Generic_CVPR_2024_paper.html": {
    "title": "InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Chen",
      "Jiannan Wu",
      "Wenhai Wang",
      "Weijie Su",
      "Guo Chen",
      "Sen Xing",
      "Muyan Zhong",
      "Qinglong Zhang",
      "Xizhou Zhu",
      "Lewei Lu",
      "Bin Li",
      "Ping Luo",
      "Tong Lu",
      "Yu Qiao",
      "Jifeng Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Multi-View_Attentive_Contextualization_for_Multi-View_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "Multi-View Attentive Contextualization for Multi-View 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianpeng Liu",
      "Ce Zheng",
      "Ming Qian",
      "Nan Xue",
      "Chen Chen",
      "Zhebin Zhang",
      "Chen Li",
      "Tianfu Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_MemSAM_Taming_Segment_Anything_Model_for_Echocardiography_Video_Segmentation_CVPR_2024_paper.html": {
    "title": "MemSAM: Taming Segment Anything Model for Echocardiography Video Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaolong Deng",
      "Huisi Wu",
      "Runhao Zeng",
      "Jing Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_LiDAR4D_Dynamic_Neural_Fields_for_Novel_Space-time_View_LiDAR_Synthesis_CVPR_2024_paper.html": {
    "title": "LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehan Zheng",
      "Fan Lu",
      "Weiyi Xue",
      "Guang Chen",
      "Changjun Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Exploiting_Diffusion_Prior_for_Generalizable_Dense_Prediction_CVPR_2024_paper.html": {
    "title": "Exploiting Diffusion Prior for Generalizable Dense Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hsin-Ying Lee",
      "Hung-Yu Tseng",
      "Hsin-Ying Lee",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_PI3D_Efficient_Text-to-3D_Generation_with_Pseudo-Image_Diffusion_CVPR_2024_paper.html": {
    "title": "PI3D: Efficient Text-to-3D Generation with Pseudo-Image Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying-Tian Liu",
      "Yuan-Chen Guo",
      "Guan Luo",
      "Heyi Sun",
      "Wei Yin",
      "Song-Hai Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Po_Orthogonal_Adaptation_for_Modular_Customization_of_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Orthogonal Adaptation for Modular Customization of Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryan Po",
      "Guandao Yang",
      "Kfir Aberman",
      "Gordon Wetzstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Charatan_pixelSplat_3D_Gaussian_Splats_from_Image_Pairs_for_Scalable_Generalizable_CVPR_2024_paper.html": {
    "title": "pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Charatan",
      "Sizhe Lester Li",
      "Andrea Tagliasacchi",
      "Vincent Sitzmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_VBench_Comprehensive_Benchmark_Suite_for_Video_Generative_Models_CVPR_2024_paper.html": {
    "title": "VBench: Comprehensive Benchmark Suite for Video Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqi Huang",
      "Yinan He",
      "Jiashuo Yu",
      "Fan Zhang",
      "Chenyang Si",
      "Yuming Jiang",
      "Yuanhan Zhang",
      "Tianxing Wu",
      "Qingyang Jin",
      "Nattapol Chanpaisit",
      "Yaohui Wang",
      "Xinyuan Chen",
      "Limin Wang",
      "Dahua Lin",
      "Yu Qiao",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cho_Language-conditioned_Detection_Transformer_CVPR_2024_paper.html": {
    "title": "Language-conditioned Detection Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jang Hyun Cho",
      "Philipp Krähenbühl"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Karunratanakul_Optimizing_Diffusion_Noise_Can_Serve_As_Universal_Motion_Priors_CVPR_2024_paper.html": {
    "title": "Optimizing Diffusion Noise Can Serve As Universal Motion Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Korrawe Karunratanakul",
      "Konpat Preechakul",
      "Emre Aksan",
      "Thabo Beeler",
      "Supasorn Suwajanakorn",
      "Siyu Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_MAP_MAsk-Pruning_for_Source-Free_Model_Intellectual_Property_Protection_CVPR_2024_paper.html": {
    "title": "MAP: MAsk-Pruning for Source-Free Model Intellectual Property Protection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyang Peng",
      "Sanqing Qu",
      "Yong Wu",
      "Tianpei Zou",
      "Lianghua He",
      "Alois Knoll",
      "Guang Chen",
      "Changjun Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Danish_Improving_Single_Domain-Generalized_Object_Detection_A_Focus_on_Diversification_and_CVPR_2024_paper.html": {
    "title": "Improving Single Domain-Generalized Object Detection: A Focus on Diversification and Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Sohail Danish",
      "Muhammad Haris Khan",
      "Muhammad Akhtar Munir",
      "M. Saquib Sarfraz",
      "Mohsen Ali"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation_CVPR_2024_paper.html": {
    "title": "OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiongwei Wu",
      "Sicheng Yu",
      "Ee-Peng Lim",
      "Chong-Wah Ngo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Potje_XFeat_Accelerated_Features_for_Lightweight_Image_Matching_CVPR_2024_paper.html": {
    "title": "XFeat: Accelerated Features for Lightweight Image Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guilherme Potje",
      "Felipe Cadar",
      "André Araujo",
      "Renato Martins",
      "Erickson R. Nascimento"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hossain_Visual_Prompting_for_Generalized_Few-shot_Segmentation_A_Multi-scale_Approach_CVPR_2024_paper.html": {
    "title": "Visual Prompting for Generalized Few-shot Segmentation: A Multi-scale Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mir Rayat Imtiaz Hossain",
      "Mennatullah Siam",
      "Leonid Sigal",
      "James J. Little"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bai_ARTrackV2_Prompting_Autoregressive_Tracker_Where_to_Look_and_How_to_CVPR_2024_paper.html": {
    "title": "ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to Describe",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Bai",
      "Zeyang Zhao",
      "Yihong Gong",
      "Xing Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sharma_A_Vision_Check-up_for_Language_Models_CVPR_2024_paper.html": {
    "title": "A Vision Check-up for Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratyusha Sharma",
      "Tamar Rott Shaham",
      "Manel Baradad",
      "Stephanie Fu",
      "Adrian Rodriguez-Munoz",
      "Shivam Duggal",
      "Phillip Isola",
      "Antonio Torralba"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Memory-based_Adapters_for_Online_3D_Scene_Perception_CVPR_2024_paper.html": {
    "title": "Memory-based Adapters for Online 3D Scene Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiuwei Xu",
      "Chong Xia",
      "Ziwei Wang",
      "Linqing Zhao",
      "Yueqi Duan",
      "Jie Zhou",
      "Jiwen Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining_CVPR_2024_paper.html": {
    "title": "SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chull Hwan Song",
      "Taebaek Hwang",
      "Jooyoung Yoon",
      "Shunghyun Choi",
      "Yeong Hyeon Gu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dai_A_Study_of_Dropout-Induced_Modality_Bias_on_Robustness_to_Missing_CVPR_2024_paper.html": {
    "title": "A Study of Dropout-Induced Modality Bias on Robustness to Missing Video Frames for Audio-Visual Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusheng Dai",
      "Hang Chen",
      "Jun Du",
      "Ruoyu Wang",
      "Shihao Chen",
      "Haotian Wang",
      "Chin-Hui Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_A_Conditional_Denoising_Diffusion_Probabilistic_Model_for_Point_Cloud_Upsampling_CVPR_2024_paper.html": {
    "title": "A Conditional Denoising Diffusion Probabilistic Model for Point Cloud Upsampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentao Qu",
      "Yuantian Shao",
      "Lingwu Meng",
      "Xiaoshui Huang",
      "Liang Xiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_VideoRF_Rendering_Dynamic_Radiance_Fields_as_2D_Feature_Video_Streams_CVPR_2024_paper.html": {
    "title": "VideoRF: Rendering Dynamic Radiance Fields as 2D Feature Video Streams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liao Wang",
      "Kaixin Yao",
      "Chengcheng Guo",
      "Zhirui Zhang",
      "Qiang Hu",
      "Jingyi Yu",
      "Lan Xu",
      "Minye Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_DPHMs_Diffusion_Parametric_Head_Models_for_Depth-based_Tracking_CVPR_2024_paper.html": {
    "title": "DPHMs: Diffusion Parametric Head Models for Depth-based Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiapeng Tang",
      "Angela Dai",
      "Yinyu Nie",
      "Lev Markhasin",
      "Justus Thies",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_DetDiffusion_Synergizing_Generative_and_Perceptive_Models_for_Enhanced_Data_Generation_CVPR_2024_paper.html": {
    "title": "DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibo Wang",
      "Ruiyuan Gao",
      "Kai Chen",
      "Kaiqiang Zhou",
      "Yingjie Cai",
      "Lanqing Hong",
      "Zhenguo Li",
      "Lihui Jiang",
      "Dit-Yan Yeung",
      "Qiang Xu",
      "Kai Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_GAFusion_Adaptive_Fusing_LiDAR_and_Camera_with_Multiple_Guidance_for_CVPR_2024_paper.html": {
    "title": "GAFusion: Adaptive Fusing LiDAR and Camera with Multiple Guidance for 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotian Li",
      "Baojie Fan",
      "Jiandong Tian",
      "Huijie Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Perception-Oriented_Video_Frame_Interpolation_via_Asymmetric_Blending_CVPR_2024_paper.html": {
    "title": "Perception-Oriented Video Frame Interpolation via Asymmetric Blending",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyang Wu",
      "Xin Tao",
      "Changlin Li",
      "Wenyi Wang",
      "Xiaohong Liu",
      "Qingqing Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Countering_Personalized_Text-to-Image_Generation_with_Influence_Watermarks_CVPR_2024_paper.html": {
    "title": "Countering Personalized Text-to-Image Generation with Influence Watermarks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanwen Liu",
      "Zhicheng Sun",
      "Yadong Mu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fainstein_DUDF_Differentiable_Unsigned_Distance_Fields_with_Hyperbolic_Scaling_CVPR_2024_paper.html": {
    "title": "DUDF: Differentiable Unsigned Distance Fields with Hyperbolic Scaling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Fainstein",
      "Viviana Siless",
      "Emmanuel Iarussi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_PromptAD_Learning_Prompts_with_only_Normal_Samples_for_Few-Shot_Anomaly_CVPR_2024_paper.html": {
    "title": "PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofan Li",
      "Zhizhong Zhang",
      "Xin Tan",
      "Chengwei Chen",
      "Yanyun Qu",
      "Yuan Xie",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhuo_Improving_Graph_Contrastive_Learning_via_Adaptive_Positive_Sampling_CVPR_2024_paper.html": {
    "title": "Improving Graph Contrastive Learning via Adaptive Positive Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Zhuo",
      "Feiyang Qin",
      "Can Cui",
      "Kun Fu",
      "Bingxin Niu",
      "Mengzhu Wang",
      "Yuanfang Guo",
      "Chuan Wang",
      "Zhen Wang",
      "Xiaochun Cao",
      "Liang Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_UFC-Net_Unrolling_Fixed-point_Continuous_Network_for_Deep_Compressive_Sensing_CVPR_2024_paper.html": {
    "title": "UFC-Net: Unrolling Fixed-point Continuous Network for Deep Compressive Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Wang",
      "Hongping Gan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Patni_ECoDepth_Effective_Conditioning_of_Diffusion_Models_for_Monocular_Depth_Estimation_CVPR_2024_paper.html": {
    "title": "ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Suraj Patni",
      "Aradhye Agarwal",
      "Chetan Arora"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ling_DL3DV-10K_A_Large-Scale_Scene_Dataset_for_Deep_Learning-based_3D_Vision_CVPR_2024_paper.html": {
    "title": "DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lu Ling",
      "Yichen Sheng",
      "Zhi Tu",
      "Wentian Zhao",
      "Cheng Xin",
      "Kun Wan",
      "Lantao Yu",
      "Qianyu Guo",
      "Zixun Yu",
      "Yawen Lu",
      "Xuanmao Li",
      "Xingpeng Sun",
      "Rohan Ashok",
      "Aniruddha Mukherjee",
      "Hao Kang",
      "Xiangrui Kong",
      "Gang Hua",
      "Tianyi Zhang",
      "Bedrich Benes",
      "Aniket Bera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_2S-UDF_A_Novel_Two-stage_UDF_Learning_Method_for_Robust_Non-watertight_CVPR_2024_paper.html": {
    "title": "2S-UDF: A Novel Two-stage UDF Learning Method for Robust Non-watertight Model Reconstruction from Multi-view Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junkai Deng",
      "Fei Hou",
      "Xuhui Chen",
      "Wencheng Wang",
      "Ying He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_DETRs_Beat_YOLOs_on_Real-time_Object_Detection_CVPR_2024_paper.html": {
    "title": "DETRs Beat YOLOs on Real-time Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yian Zhao",
      "Wenyu Lv",
      "Shangliang Xu",
      "Jinman Wei",
      "Guanzhong Wang",
      "Qingqing Dang",
      "Yi Liu",
      "Jie Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_UniVS_Unified_and_Universal_Video_Segmentation_with_Prompts_as_Queries_CVPR_2024_paper.html": {
    "title": "UniVS: Unified and Universal Video Segmentation with Prompts as Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghan Li",
      "Shuai Li",
      "Xindong Zhang",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Bilateral_Adaptation_for_Human-Object_Interaction_Detection_with_Occlusion-Robustness_CVPR_2024_paper.html": {
    "title": "Bilateral Adaptation for Human-Object Interaction Detection with Occlusion-Robustness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangzhi Wang",
      "Yangyang Guo",
      "Ziwei Xu",
      "Mohan Kankanhalli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_An_Asymmetric_Augmented_Self-Supervised_Learning_Method_for_Unsupervised_Fine-Grained_Image_CVPR_2024_paper.html": {
    "title": "An Asymmetric Augmented Self-Supervised Learning Method for Unsupervised Fine-Grained Image Hashing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feiran Hu",
      "Chenlin Zhang",
      "Jiangliang Guo",
      "Xiu-Shen Wei",
      "Lin Zhao",
      "Anqi Xu",
      "Lingyan Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Le_Efficiently_Assemble_Normalization_Layers_and_Regularization_for_Federated_Domain_Generalization_CVPR_2024_paper.html": {
    "title": "Efficiently Assemble Normalization Layers and Regularization for Federated Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khiem Le",
      "Long Ho",
      "Cuong Do",
      "Danh Le-Phuoc",
      "Kok-Seng Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Exploring_Pose-Aware_Human-Object_Interaction_via_Hybrid_Learning_CVPR_2024_paper.html": {
    "title": "Exploring Pose-Aware Human-Object Interaction via Hybrid Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eastman Z Y Wu",
      "Yali Li",
      "Yuan Wang",
      "Shengjin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Depth_Information_Assisted_Collaborative_Mutual_Promotion_Network_for_Single_Image_CVPR_2024_paper.html": {
    "title": "Depth Information Assisted Collaborative Mutual Promotion Network for Single Image Dehazing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yafei Zhang",
      "Shen Zhou",
      "Huafeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wen_Density-Adaptive_Model_Based_on_Motif_Matrix_for_Multi-Agent_Trajectory_Prediction_CVPR_2024_paper.html": {
    "title": "Density-Adaptive Model Based on Motif Matrix for Multi-Agent Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Di Wen",
      "Haoran Xu",
      "Zhaocheng He",
      "Zhe Wu",
      "Guang Tan",
      "Peixi Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_Contrastive_Learning_for_DeepFake_Classification_and_Localization_via_Multi-Label_Ranking_CVPR_2024_paper.html": {
    "title": "Contrastive Learning for DeepFake Classification and Localization via Multi-Label Ranking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng-Yao Hong",
      "Yen-Chi Hsu",
      "Tyng-Luh Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Unlocking_the_Potential_of_Pre-trained_Vision_Transformers_for_Few-Shot_Semantic_CVPR_2024_paper.html": {
    "title": "Unlocking the Potential of Pre-trained Vision Transformers for Few-Shot Semantic Segmentation through Relationship Descriptors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqin Zhou",
      "Hai-Ming Xu",
      "Yangyang Shu",
      "Lingqiao Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_CustomListener_Text-guided_Responsive_Interaction_for_User-friendly_Listening_Head_Generation_CVPR_2024_paper.html": {
    "title": "CustomListener: Text-guided Responsive Interaction for User-friendly Listening Head Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Liu",
      "Ying Guo",
      "Cheng Zhen",
      "Tong Li",
      "Yingying Ao",
      "Pengfei Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sheinin_Projecting_Trackable_Thermal_Patterns_for_Dynamic_Computer_Vision_CVPR_2024_paper.html": {
    "title": "Projecting Trackable Thermal Patterns for Dynamic Computer Vision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mark Sheinin",
      "Aswin C. Sankaranarayanan",
      "Srinivasa G. Narasimhan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_SG-PGM_Partial_Graph_Matching_Network_with_Semantic_Geometric_Fusion_for_CVPR_2024_paper.html": {
    "title": "SG-PGM: Partial Graph Matching Network with Semantic Geometric Fusion for 3D Scene Graph Alignment and Its Downstream Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaxu Xie",
      "Alain Pagani",
      "Didier Stricker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mankovich_Fun_with_Flags_Robust_Principal_Directions_via_Flag_Manifolds_CVPR_2024_paper.html": {
    "title": "Fun with Flags: Robust Principal Directions via Flag Manifolds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Mankovich",
      "Gustau Camps-Valls",
      "Tolga Birdal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Generating_Non-Stationary_Textures_using_Self-Rectification_CVPR_2024_paper.html": {
    "title": "Generating Non-Stationary Textures using Self-Rectification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhou",
      "Rongjun Xiao",
      "Dani Lischinski",
      "Daniel Cohen-Or",
      "Hui Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_SPU-PMD_Self-Supervised_Point_Cloud_Upsampling_via_Progressive_Mesh_Deformation_CVPR_2024_paper.html": {
    "title": "SPU-PMD: Self-Supervised Point Cloud Upsampling via Progressive Mesh Deformation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanzhe Liu",
      "Rong Chen",
      "Yushi Li",
      "Yixi Li",
      "Xuehou Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_Advancing_Saliency_Ranking_with_Human_Fixations_Dataset_Models_and_Benchmarks_CVPR_2024_paper.html": {
    "title": "Advancing Saliency Ranking with Human Fixations: Dataset Models and Benchmarks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Deng",
      "Siyang Song",
      "Andrew P. French",
      "Denis Schluppeck",
      "Michael P. Pound"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Menapace_Snap_Video_Scaled_Spatiotemporal_Transformers_for_Text-to-Video_Synthesis_CVPR_2024_paper.html": {
    "title": "Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Willi Menapace",
      "Aliaksandr Siarohin",
      "Ivan Skorokhodov",
      "Ekaterina Deyneka",
      "Tsai-Shien Chen",
      "Anil Kag",
      "Yuwei Fang",
      "Aleksei Stoliar",
      "Elisa Ricci",
      "Jian Ren",
      "Sergey Tulyakov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Unsupervised_Deep_Unrolling_Networks_for_Phase_Unwrapping_CVPR_2024_paper.html": {
    "title": "Unsupervised Deep Unrolling Networks for Phase Unwrapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhile Chen",
      "Yuhui Quan",
      "Hui Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pu_Federated_Generalized_Category_Discovery_CVPR_2024_paper.html": {
    "title": "Federated Generalized Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Pu",
      "Wenjing Li",
      "Xingyuan Ji",
      "Yalan Qin",
      "Nicu Sebe",
      "Zhun Zhong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_JointSQ_Joint_Sparsification-Quantization_for_Distributed_Learning_CVPR_2024_paper.html": {
    "title": "JointSQ: Joint Sparsification-Quantization for Distributed Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiying Xie",
      "Haowei Li",
      "Jitao Ma",
      "Yunsong Li",
      "Jie Lei",
      "Donglai Liu",
      "Leyuan Fang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_A_Unified_Framework_for_Human-centric_Point_Cloud_Video_Understanding_CVPR_2024_paper.html": {
    "title": "A Unified Framework for Human-centric Point Cloud Video Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiteng Xu",
      "Kecheng Ye",
      "Xiao Han",
      "Yiming Ren",
      "Xinge Zhu",
      "Yuexin Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Roh_Edge-Aware_3D_Instance_Segmentation_Network_with_Intelligent_Semantic_Prior_CVPR_2024_paper.html": {
    "title": "Edge-Aware 3D Instance Segmentation Network with Intelligent Semantic Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonseok Roh",
      "Hwanhee Jung",
      "Giljoo Nam",
      "Jinseop Yeom",
      "Hyunje Park",
      "Sang Ho Yoon",
      "Sangpil Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Coherence_As_Texture_-_Passive_Textureless_3D_Reconstruction_by_Self-interference_CVPR_2024_paper.html": {
    "title": "Coherence As Texture - Passive Textureless 3D Reconstruction by Self-interference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Yu Chen",
      "Aswin C. Sankaranarayanan",
      "Anat Levin",
      "Matthew O'Toole"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_Enhancing_the_Power_of_OOD_Detection_via_Sample-Aware_Model_Selection_CVPR_2024_paper.html": {
    "title": "Enhancing the Power of OOD Detection via Sample-Aware Model Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Xue",
      "Zi He",
      "Yuan Zhang",
      "Chuanlong Xie",
      "Zhenguo Li",
      "Falong Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Collaborative_Semantic_Occupancy_Prediction_with_Hybrid_Feature_Fusion_in_Connected_CVPR_2024_paper.html": {
    "title": "Collaborative Semantic Occupancy Prediction with Hybrid Feature Fusion in Connected Automated Vehicles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Song",
      "Chenwei Liang",
      "Hu Cao",
      "Zhiran Yan",
      "Walter Zimmer",
      "Markus Gross",
      "Andreas Festag",
      "Alois Knoll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Generative_Multi-modal_Models_are_Good_Class_Incremental_Learners_CVPR_2024_paper.html": {
    "title": "Generative Multi-modal Models are Good Class Incremental Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xusheng Cao",
      "Haori Lu",
      "Linlan Huang",
      "Xialei Liu",
      "Ming-Ming Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Low-Resource_Vision_Challenges_for_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Low-Resource Vision Challenges for Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhua Zhang",
      "Hazel Doughty",
      "Cees G. M. Snoek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_RGBD_Objects_in_the_Wild_Scaling_Real-World_3D_Object_Learning_CVPR_2024_paper.html": {
    "title": "RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongchi Xia",
      "Yang Fu",
      "Sifei Liu",
      "Xiaolong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Shadow-Enlightened_Image_Outpainting_CVPR_2024_paper.html": {
    "title": "Shadow-Enlightened Image Outpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Yu",
      "Ruilin Li",
      "Shaorong Xie",
      "Jiayan Qiu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Towards_Generalizable_Tumor_Synthesis_CVPR_2024_paper.html": {
    "title": "Towards Generalizable Tumor Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Chen",
      "Xiaoxi Chen",
      "Haorui Song",
      "Zhiwei Xiong",
      "Alan Yuille",
      "Chen Wei",
      "Zongwei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Low-Res_Leads_the_Way_Improving_Generalization_for_Super-Resolution_by_Self-Supervised_CVPR_2024_paper.html": {
    "title": "Low-Res Leads the Way: Improving Generalization for Super-Resolution by Self-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Chen",
      "Wenbo Li",
      "Jinjin Gu",
      "Jingjing Ren",
      "Haoze Sun",
      "Xueyi Zou",
      "Zhensong Zhang",
      "Youliang Yan",
      "Lei Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_BOTH2Hands_Inferring_3D_Hands_from_Both_Text_Prompts_and_Body_CVPR_2024_paper.html": {
    "title": "BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqian Zhang",
      "Molin Huang",
      "Yuxuan Zhou",
      "Juze Zhang",
      "Jingyi Yu",
      "Jingya Wang",
      "Lan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_EpiDiff_Enhancing_Multi-View_Synthesis_via_Localized_Epipolar-Constrained_Diffusion_CVPR_2024_paper.html": {
    "title": "EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehuan Huang",
      "Hao Wen",
      "Junting Dong",
      "Yaohui Wang",
      "Yangguang Li",
      "Xinyuan Chen",
      "Yan-Pei Cao",
      "Ding Liang",
      "Yu Qiao",
      "Bo Dai",
      "Lu Sheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_On_the_Faithfulness_of_Vision_Transformer_Explanations_CVPR_2024_paper.html": {
    "title": "On the Faithfulness of Vision Transformer Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Wu",
      "Weitai Kang",
      "Hao Tang",
      "Yuan Hong",
      "Yan Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Pixel-level_Semantic_Correspondence_through_Layout-aware_Representation_Learning_and_Multi-scale_Matching_CVPR_2024_paper.html": {
    "title": "Pixel-level Semantic Correspondence through Layout-aware Representation Learning and Multi-scale Matching Integration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixuan Sun",
      "Zhangyue Yin",
      "Haibo Wang",
      "Yan Wang",
      "Xipeng Qiu",
      "Weifeng Ge",
      "Wenqiang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Majumder_Learning_Spatial_Features_from_Audio-Visual_Correspondence_in_Egocentric_Videos_CVPR_2024_paper.html": {
    "title": "Learning Spatial Features from Audio-Visual Correspondence in Egocentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sagnik Majumder",
      "Ziad Al-Halah",
      "Kristen Grauman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_DreamAvatar_Text-and-Shape_Guided_3D_Human_Avatar_Generation_via_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "DreamAvatar: Text-and-Shape Guided 3D Human Avatar Generation via Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yukang Cao",
      "Yan-Pei Cao",
      "Kai Han",
      "Ying Shan",
      "Kwan-Yee K. Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Dynamic_Graph_Representation_with_Knowledge-aware_Attention_for_Histopathology_Whole_Slide_CVPR_2024_paper.html": {
    "title": "Dynamic Graph Representation with Knowledge-aware Attention for Histopathology Whole Slide Image Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawen Li",
      "Yuxuan Chen",
      "Hongbo Chu",
      "Qiehe Sun",
      "Tian Guan",
      "Anjia Han",
      "Yonghong He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Brain_Decodes_Deep_Nets_CVPR_2024_paper.html": {
    "title": "Brain Decodes Deep Nets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huzheng Yang",
      "James Gee",
      "Jianbo Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Semantics_Distortion_and_Style_Matter_Towards_Source-free_UDA_for_Panoramic_CVPR_2024_paper.html": {
    "title": "Semantics Distortion and Style Matter: Towards Source-free UDA for Panoramic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Zheng",
      "Pengyuan Zhou",
      "Athanasios V. Vasilakos",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Bidirectional_Autoregessive_Diffusion_Model_for_Dance_Generation_CVPR_2024_paper.html": {
    "title": "Bidirectional Autoregessive Diffusion Model for Dance Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Canyu Zhang",
      "Youbao Tang",
      "Ning Zhang",
      "Ruei-Sung Lin",
      "Mei Han",
      "Jing Xiao",
      "Song Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Align_Before_Adapt_Leveraging_Entity-to-Region_Alignments_for_Generalizable_Video_Action_CVPR_2024_paper.html": {
    "title": "Align Before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Chen",
      "Dapeng Chen",
      "Ruijin Liu",
      "Sai Zhou",
      "Wenyuan Xue",
      "Wei Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_GOV-NeSF_Generalizable_Open-Vocabulary_Neural_Semantic_Fields_CVPR_2024_paper.html": {
    "title": "GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunsong Wang",
      "Hanlin Chen",
      "Gim Hee Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_FRESCO_Spatial-Temporal_Correspondence_for_Zero-Shot_Video_Translation_CVPR_2024_paper.html": {
    "title": "FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Yang",
      "Yifan Zhou",
      "Ziwei Liu",
      "Chen Change Loy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_Dual-Scale_Transformer_for_Large-Scale_Single-Pixel_Imaging_CVPR_2024_paper.html": {
    "title": "Dual-Scale Transformer for Large-Scale Single-Pixel Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gang Qu",
      "Ping Wang",
      "Xin Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chae_Towards_Robust_3D_Object_Detection_with_LiDAR_and_4D_Radar_CVPR_2024_paper.html": {
    "title": "Towards Robust 3D Object Detection with LiDAR and 4D Radar Fusion in Various Weather Conditions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujeong Chae",
      "Hyeonseong Kim",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Enhancing_3D_Fidelity_of_Text-to-3D_using_Cross-View_Correspondences_CVPR_2024_paper.html": {
    "title": "Enhancing 3D Fidelity of Text-to-3D using Cross-View Correspondences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungwook Kim",
      "Kejie Li",
      "Xueqing Deng",
      "Yichun Shi",
      "Minsu Cho",
      "Peng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Blayney_Bezier_Everywhere_All_at_Once_Learning_Drivable_Lanes_as_Bezier_CVPR_2024_paper.html": {
    "title": "Bezier Everywhere All at Once: Learning Drivable Lanes as Bezier Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hugh Blayney",
      "Hanlin Tian",
      "Hamish Scott",
      "Nils Goldbeck",
      "Chess Stetson",
      "Panagiotis Angeloudis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shao_SplattingAvatar_Realistic_Real-Time_Human_Avatars_with_Mesh-Embedded_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhijing Shao",
      "Zhaolong Wang",
      "Zhuang Li",
      "Duotun Wang",
      "Xiangru Lin",
      "Yu Zhang",
      "Mingming Fan",
      "Zeyu Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dib_MoSAR_Monocular_Semi-Supervised_Model_for_Avatar_Reconstruction_using_Differentiable_Shading_CVPR_2024_paper.html": {
    "title": "MoSAR: Monocular Semi-Supervised Model for Avatar Reconstruction using Differentiable Shading",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdallah Dib",
      "Luiz Gustavo Hafemann",
      "Emeline Got",
      "Trevor Anderson",
      "Amin Fadaeinejad",
      "Rafael M. O. Cruz",
      "Marc-André Carbonneau"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_Bridging_Remote_Sensors_with_Multisensor_Geospatial_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Bridging Remote Sensors with Multisensor Geospatial Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boran Han",
      "Shuai Zhang",
      "Xingjian Shi",
      "Markus Reichstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Can_I_Trust_Your_Answer_Visually_Grounded_Video_Question_Answering_CVPR_2024_paper.html": {
    "title": "Can I Trust Your Answer? Visually Grounded Video Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junbin Xiao",
      "Angela Yao",
      "Yicong Li",
      "Tat-Seng Chua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cetinkaya_RankED_Addressing_Imbalance_and_Uncertainty_in_Edge_Detection_Using_Ranking-based_CVPR_2024_paper.html": {
    "title": "RankED: Addressing Imbalance and Uncertainty in Edge Detection Using Ranking-based Losses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bedrettin Cetinkaya",
      "Sinan Kalkan",
      "Emre Akbas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sengupta_DiffHuman_Probabilistic_Photorealistic_3D_Reconstruction_of_Humans_CVPR_2024_paper.html": {
    "title": "DiffHuman: Probabilistic Photorealistic 3D Reconstruction of Humans",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akash Sengupta",
      "Thiemo Alldieck",
      "Nikos Kolotouros",
      "Enric Corona",
      "Andrei Zanfir",
      "Cristian Sminchisescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_SeeSR_Towards_Semantics-Aware_Real-World_Image_Super-Resolution_CVPR_2024_paper.html": {
    "title": "SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongyuan Wu",
      "Tao Yang",
      "Lingchen Sun",
      "Zhengqiang Zhang",
      "Shuai Li",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Permutation_Equivariance_of_Transformers_and_Its_Applications_CVPR_2024_paper.html": {
    "title": "Permutation Equivariance of Transformers and Its Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hengyuan Xu",
      "Liyao Xiang",
      "Hangyu Ye",
      "Dixi Yao",
      "Pengzhi Chu",
      "Baochun Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wada_Polos_Multimodal_Metric_Learning_from_Human_Feedback_for_Image_Captioning_CVPR_2024_paper.html": {
    "title": "Polos: Multimodal Metric Learning from Human Feedback for Image Captioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuiga Wada",
      "Kanta Kaneda",
      "Daichi Saito",
      "Komei Sugiura"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ashutosh_Detours_for_Navigating_Instructional_Videos_CVPR_2024_paper.html": {
    "title": "Detours for Navigating Instructional Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kumar Ashutosh",
      "Zihui Xue",
      "Tushar Nagarajan",
      "Kristen Grauman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Discontinuity-preserving_Normal_Integration_with_Auxiliary_Edges_CVPR_2024_paper.html": {
    "title": "Discontinuity-preserving Normal Integration with Auxiliary Edges",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyomin Kim",
      "Yucheol Jung",
      "Seungyong Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_DrivingGaussian_Composite_Gaussian_Splatting_for_Surrounding_Dynamic_Autonomous_Driving_Scenes_CVPR_2024_paper.html": {
    "title": "DrivingGaussian: Composite Gaussian Splatting for Surrounding Dynamic Autonomous Driving Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Zhou",
      "Zhiwei Lin",
      "Xiaojun Shan",
      "Yongtao Wang",
      "Deqing Sun",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Self-Supervised_Multi-Object_Tracking_with_Path_Consistency_CVPR_2024_paper.html": {
    "title": "Self-Supervised Multi-Object Tracking with Path Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijia Lu",
      "Bing Shuai",
      "Yanbei Chen",
      "Zhenlin Xu",
      "Davide Modolo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hedlin_Unsupervised_Keypoints_from_Pretrained_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Unsupervised Keypoints from Pretrained Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eric Hedlin",
      "Gopal Sharma",
      "Shweta Mahajan",
      "Xingzhe He",
      "Hossam Isack",
      "Abhishek Kar",
      "Helge Rhodin",
      "Andrea Tagliasacchi",
      "Kwang Moo Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chan_Resolution_Limit_of_Single-Photon_LiDAR_CVPR_2024_paper.html": {
    "title": "Resolution Limit of Single-Photon LiDAR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stanley H. Chan",
      "Hashan K. Weerasooriya",
      "Weijian Zhang",
      "Pamela Abshire",
      "Istvan Gyongy",
      "Robert K. Henderson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zou_Flatten_Long-Range_Loss_Landscapes_for_Cross-Domain_Few-Shot_Learning_CVPR_2024_paper.html": {
    "title": "Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixiong Zou",
      "Yicong Liu",
      "Yiman Hu",
      "Yuhua Li",
      "Ruixuan Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Improving_Distant_3D_Object_Detection_Using_2D_Box_Supervision_CVPR_2024_paper.html": {
    "title": "Improving Distant 3D Object Detection Using 2D Box Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zetong Yang",
      "Zhiding Yu",
      "Chris Choy",
      "Renhao Wang",
      "Anima Anandkumar",
      "Jose M. Alvarez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Poduval_HDQMF_Holographic_Feature_Decomposition_Using_Quantum_Algorithms_CVPR_2024_paper.html": {
    "title": "HDQMF: Holographic Feature Decomposition Using Quantum Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prathyush Prasanth Poduval",
      "Zhuowen Zou",
      "Mohsen Imani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Diffusion-based_Blind_Text_Image_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Diffusion-based Blind Text Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhe Zhang",
      "Jiawei Zhang",
      "Hao Li",
      "Zhouxia Wang",
      "Luwei Hou",
      "Dongqing Zou",
      "Liheng Bian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Consistent_Prompting_for_Rehearsal-Free_Continual_Learning_CVPR_2024_paper.html": {
    "title": "Consistent Prompting for Rehearsal-Free Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhanxin Gao",
      "Jun Cen",
      "Xiaobin Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_UniPAD_A_Universal_Pre-training_Paradigm_for_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "UniPAD: A Universal Pre-training Paradigm for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honghui Yang",
      "Sha Zhang",
      "Di Huang",
      "Xiaoyang Wu",
      "Haoyi Zhu",
      "Tong He",
      "Shixiang Tang",
      "Hengshuang Zhao",
      "Qibo Qiu",
      "Binbin Lin",
      "Xiaofei He",
      "Wanli Ouyang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SeD_Semantic-Aware_Discriminator_for_Image_Super-Resolution_CVPR_2024_paper.html": {
    "title": "SeD: Semantic-Aware Discriminator for Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingchen Li",
      "Xin Li",
      "Hanxin Zhu",
      "Yeying Jin",
      "Ruoyu Feng",
      "Zhizheng Zhang",
      "Zhibo Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Howard_SocialCounterfactuals_Probing_and_Mitigating_Intersectional_Social_Biases_in_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "SocialCounterfactuals: Probing and Mitigating Intersectional Social Biases in Vision-Language Models with Counterfactual Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phillip Howard",
      "Avinash Madasu",
      "Tiep Le",
      "Gustavo Lujan Moreno",
      "Anahita Bhiwandiwalla",
      "Vasudev Lal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SVDTree_Semantic_Voxel_Diffusion_for_Single_Image_Tree_Reconstruction_CVPR_2024_paper.html": {
    "title": "SVDTree: Semantic Voxel Diffusion for Single Image Tree Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Li",
      "Zhihao Liu",
      "Bedrich Benes",
      "Xiaopeng Zhang",
      "Jianwei Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jayasumana_Rethinking_FID_Towards_a_Better_Evaluation_Metric_for_Image_Generation_CVPR_2024_paper.html": {
    "title": "Rethinking FID: Towards a Better Evaluation Metric for Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sadeep Jayasumana",
      "Srikumar Ramalingam",
      "Andreas Veit",
      "Daniel Glasner",
      "Ayan Chakrabarti",
      "Sanjiv Kumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Moon_Efficient_Privacy-Preserving_Visual_Localization_Using_3D_Ray_Clouds_CVPR_2024_paper.html": {
    "title": "Efficient Privacy-Preserving Visual Localization Using 3D Ray Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heejoon Moon",
      "Chunghwan Lee",
      "Je Hyeong Hong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mazur_SuperPrimitive_Scene_Reconstruction_at_a_Primitive_Level_CVPR_2024_paper.html": {
    "title": "SuperPrimitive: Scene Reconstruction at a Primitive Level",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kirill Mazur",
      "Gwangbin Bae",
      "Andrew J. Davison"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Poudel_ReCoRe_Regularized_Contrastive_Representation_Learning_of_World_Model_CVPR_2024_paper.html": {
    "title": "ReCoRe: Regularized Contrastive Representation Learning of World Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rudra P.K. Poudel",
      "Harit Pandya",
      "Stephan Liwicki",
      "Roberto Cipolla"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_TFMQ-DM_Temporal_Feature_Maintenance_Quantization_for_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yushi Huang",
      "Ruihao Gong",
      "Jing Liu",
      "Tianlong Chen",
      "Xianglong Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yavartanoo_CNC-Net_Self-Supervised_Learning_for_CNC_Machining_Operations_CVPR_2024_paper.html": {
    "title": "CNC-Net: Self-Supervised Learning for CNC Machining Operations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohsen Yavartanoo",
      "Sangmin Hong",
      "Reyhaneh Neshatavar",
      "Kyoung Mu Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Le_JRDB-PanoTrack_An_Open-world_Panoptic_Segmentation_and_Tracking_Robotic_Dataset_in_CVPR_2024_paper.html": {
    "title": "JRDB-PanoTrack: An Open-world Panoptic Segmentation and Tracking Robotic Dataset in Crowded Human Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Duy Tho Le",
      "Chenhui Gou",
      "Stavya Datta",
      "Hengcan Shi",
      "Ian Reid",
      "Jianfei Cai",
      "Hamid Rezatofighi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Meral_CONFORM_Contrast_is_All_You_Need_for_High-Fidelity_Text-to-Image_Diffusion_CVPR_2024_paper.html": {
    "title": "CONFORM: Contrast is All You Need for High-Fidelity Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuna Han Salih Meral",
      "Enis Simsar",
      "Federico Tombari",
      "Pinar Yanardag"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Self-Supervised_Facial_Representation_Learning_with_Facial_Region_Awareness_CVPR_2024_paper.html": {
    "title": "Self-Supervised Facial Representation Learning with Facial Region Awareness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Gao",
      "Ioannis Patras"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yi_GaussianDreamer_Fast_Generation_from_Text_to_3D_Gaussians_by_Bridging_CVPR_2024_paper.html": {
    "title": "GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taoran Yi",
      "Jiemin Fang",
      "Junjie Wang",
      "Guanjun Wu",
      "Lingxi Xie",
      "Xiaopeng Zhang",
      "Wenyu Liu",
      "Qi Tian",
      "Xinggang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Marcos-Manchon_Open-Vocabulary_Attention_Maps_with_Token_Optimization_for_Semantic_Segmentation_in_CVPR_2024_paper.html": {
    "title": "Open-Vocabulary Attention Maps with Token Optimization for Semantic Segmentation in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pablo Marcos-Manchón",
      "Roberto Alcover-Couso",
      "Juan C. SanMiguel",
      "José M. Martínez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_OPERA_Alleviating_Hallucination_in_Multi-Modal_Large_Language_Models_via_Over-Trust_CVPR_2024_paper.html": {
    "title": "OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qidong Huang",
      "Xiaoyi Dong",
      "Pan Zhang",
      "Bin Wang",
      "Conghui He",
      "Jiaqi Wang",
      "Dahua Lin",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Volumetric_Environment_Representation_for_Vision-Language_Navigation_CVPR_2024_paper.html": {
    "title": "Volumetric Environment Representation for Vision-Language Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Liu",
      "Wenguan Wang",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_DreamComposer_Controllable_3D_Object_Generation_via_Multi-View_Conditions_CVPR_2024_paper.html": {
    "title": "DreamComposer: Controllable 3D Object Generation via Multi-View Conditions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhan Yang",
      "Yukun Huang",
      "Xiaoyang Wu",
      "Yuan-Chen Guo",
      "Song-Hai Zhang",
      "Hengshuang Zhao",
      "Tong He",
      "Xihui Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Self-Calibrating_Vicinal_Risk_Minimisation_for_Model_Calibration_CVPR_2024_paper.html": {
    "title": "Self-Calibrating Vicinal Risk Minimisation for Model Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Liu",
      "Changkun Ye",
      "Ruikai Cui",
      "Nick Barnes"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_NeRFDeformer_NeRF_Transformation_from_a_Single_View_via_3D_Scene_CVPR_2024_paper.html": {
    "title": "NeRFDeformer: NeRF Transformation from a Single View via 3D Scene Flows",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenggang Tang",
      "Zhongzheng Ren",
      "Xiaoming Zhao",
      "Bowen Wen",
      "Jonathan Tremblay",
      "Stan Birchfield",
      "Alexander Schwing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ge_LPSNet_End-to-End_Human_Pose_and_Shape_Estimation_with_Lensless_Imaging_CVPR_2024_paper.html": {
    "title": "LPSNet: End-to-End Human Pose and Shape Estimation with Lensless Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Ge",
      "Qiao Feng",
      "Hailong Jia",
      "Xiongzheng Li",
      "Xiangjun Yin",
      "You Zhou",
      "Jingyu Yang",
      "Kun Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Embracing_Unimodal_Aleatoric_Uncertainty_for_Robust_Multimodal_Fusion_CVPR_2024_paper.html": {
    "title": "Embracing Unimodal Aleatoric Uncertainty for Robust Multimodal Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixian Gao",
      "Xun Jiang",
      "Xing Xu",
      "Fumin Shen",
      "Yujie Li",
      "Heng Tao Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_Unifying_Correspondence_Pose_and_NeRF_for_Generalized_Pose-Free_Novel_View_CVPR_2024_paper.html": {
    "title": "Unifying Correspondence Pose and NeRF for Generalized Pose-Free Novel View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sunghwan Hong",
      "Jaewoo Jung",
      "Heeseong Shin",
      "Jiaolong Yang",
      "Seungryong Kim",
      "Chong Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Draw_Step_by_Step_Reconstructing_CAD_Construction_Sequences_from_Point_CVPR_2024_paper.html": {
    "title": "Draw Step by Step: Reconstructing CAD Construction Sequences from Point Clouds via Multimodal Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijian Ma",
      "Shuaiqi Chen",
      "Yunzhong Lou",
      "Xueyang Li",
      "Xiangdong Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_DiffusionTrack_Point_Set_Diffusion_Model_for_Visual_Object_Tracking_CVPR_2024_paper.html": {
    "title": "DiffusionTrack: Point Set Diffusion Model for Visual Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Xie",
      "Zhongdao Wang",
      "Chao Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Towards_a_Simultaneous_and_Granular_Identity-Expression_Control_in_Personalized_Face_CVPR_2024_paper.html": {
    "title": "Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renshuai Liu",
      "Bowen Ma",
      "Wei Zhang",
      "Zhipeng Hu",
      "Changjie Fan",
      "Tangjie Lv",
      "Yu Ding",
      "Xuan Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jain_PEEKABOO_Interactive_Video_Generation_via_Masked-Diffusion_CVPR_2024_paper.html": {
    "title": "PEEKABOO: Interactive Video Generation via Masked-Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yash Jain",
      "Anshul Nasery",
      "Vibhav Vineet",
      "Harkirat Behl"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nunes_Scaling_Diffusion_Models_to_Real-World_3D_LiDAR_Scene_Completion_CVPR_2024_paper.html": {
    "title": "Scaling Diffusion Models to Real-World 3D LiDAR Scene Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas Nunes",
      "Rodrigo Marcuzzi",
      "Benedikt Mersch",
      "Jens Behley",
      "Cyrill Stachniss"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_Discriminative_Pattern_Calibration_Mechanism_for_Source-Free_Domain_Adaptation_CVPR_2024_paper.html": {
    "title": "Discriminative Pattern Calibration Mechanism for Source-Free Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haifeng Xia",
      "Siyu Xia",
      "Zhengming Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_Deep_Generative_Model_based_Rate-Distortion_for_Image_Downscaling_Assessment_CVPR_2024_paper.html": {
    "title": "Deep Generative Model based Rate-Distortion for Image Downscaling Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanbang Liang",
      "Bhavesh Garg",
      "Paul Rosin",
      "Yipeng Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_Physical_Backdoor_Towards_Temperature-based_Backdoor_Attacks_in_the_Physical_World_CVPR_2024_paper.html": {
    "title": "Physical Backdoor: Towards Temperature-based Backdoor Attacks in the Physical World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wen Yin",
      "Jian Lou",
      "Pan Zhou",
      "Yulai Xie",
      "Dan Feng",
      "Yuhua Sun",
      "Tailai Zhang",
      "Lichao Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Franchi_Make_Me_a_BNN_A_Simple_Strategy_for_Estimating_Bayesian_CVPR_2024_paper.html": {
    "title": "Make Me a BNN: A Simple Strategy for Estimating Bayesian Uncertainty from Pre-trained Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gianni Franchi",
      "Olivier Laurent",
      "Maxence Leguery",
      "Andrei Bursuc",
      "Andrea Pilzer",
      "Angela Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_Language-only_Training_of_Zero-shot_Composed_Image_Retrieval_CVPR_2024_paper.html": {
    "title": "Language-only Training of Zero-shot Composed Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geonmo Gu",
      "Sanghyuk Chun",
      "Wonjae Kim",
      "Yoohoon Kang",
      "Sangdoo Yun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dao_EFHQ_Multi-purpose_ExtremePose-Face-HQ_dataset_CVPR_2024_paper.html": {
    "title": "EFHQ: Multi-purpose ExtremePose-Face-HQ dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Trung Tuan Dao",
      "Duc Hong Vu",
      "Cuong Pham",
      "Anh Tran"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Dynamic_Cues-Assisted_Transformer_for_Robust_Point_Cloud_Registration_CVPR_2024_paper.html": {
    "title": "Dynamic Cues-Assisted Transformer for Robust Point Cloud Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Chen",
      "Pei Yan",
      "Sihe Xiang",
      "Yihua Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fadnavis_Patch2Self2_Self-supervised_Denoising_on_Coresets_via_Matrix_Sketching_CVPR_2024_paper.html": {
    "title": "Patch2Self2: Self-supervised Denoising on Coresets via Matrix Sketching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shreyas Fadnavis",
      "Agniva Chowdhury",
      "Joshua Batson",
      "Petros Drineas",
      "Eleftherios Garyfallidis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_High-fidelity_Person-centric_Subject-to-Image_Synthesis_CVPR_2024_paper.html": {
    "title": "High-fidelity Person-centric Subject-to-Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yibin Wang",
      "Weizhong Zhang",
      "Jianwei Zheng",
      "Cheng Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bianchi_The_Devil_is_in_the_Fine-Grained_Details_Evaluating_Open-Vocabulary_Object_CVPR_2024_paper.html": {
    "title": "The Devil is in the Fine-Grained Details: Evaluating Open-Vocabulary Object Detectors for Fine-Grained Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Bianchi",
      "Fabio Carrara",
      "Nicola Messina",
      "Claudio Gennaro",
      "Fabrizio Falchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Efficient_and_Effective_Weakly-Supervised_Action_Segmentation_via_Action-Transition-Aware_Boundary_Alignment_CVPR_2024_paper.html": {
    "title": "Efficient and Effective Weakly-Supervised Action Segmentation via Action-Transition-Aware Boundary Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angchi Xu",
      "Wei-Shi Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tai_Link-Context_Learning_for_Multimodal_LLMs_CVPR_2024_paper.html": {
    "title": "Link-Context Learning for Multimodal LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Tai",
      "Weichen Fan",
      "Zhao Zhang",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Pixel-Aligned_Language_Model_CVPR_2024_paper.html": {
    "title": "Pixel-Aligned Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiarui Xu",
      "Xingyi Zhou",
      "Shen Yan",
      "Xiuye Gu",
      "Anurag Arnab",
      "Chen Sun",
      "Xiaolong Wang",
      "Cordelia Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_JeDi_Joint-Image_Diffusion_Models_for_Finetuning-Free_Personalized_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "JeDi: Joint-Image Diffusion Models for Finetuning-Free Personalized Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zeng",
      "Vishal M. Patel",
      "Haochen Wang",
      "Xun Huang",
      "Ting-Chun Wang",
      "Ming-Yu Liu",
      "Yogesh Balaji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_ConsistDreamer_3D-Consistent_2D_Diffusion_for_High-Fidelity_Scene_Editing_CVPR_2024_paper.html": {
    "title": "ConsistDreamer: 3D-Consistent 2D Diffusion for High-Fidelity Scene Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun-Kun Chen",
      "Samuel Rota Bulò",
      "Norman Müller",
      "Lorenzo Porzi",
      "Peter Kontschieder",
      "Yu-Xiong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_HandDiff_3D_Hand_Pose_Estimation_with_Diffusion_on_Image-Point_Cloud_CVPR_2024_paper.html": {
    "title": "HandDiff: 3D Hand Pose Estimation with Diffusion on Image-Point Cloud",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wencan Cheng",
      "Hao Tang",
      "Luc Van Gool",
      "Jong Hwan Ko"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_SNIDA_Unlocking_Few-Shot_Object_Detection_with_Non-linear_Semantic_Decoupling_Augmentation_CVPR_2024_paper.html": {
    "title": "SNIDA: Unlocking Few-Shot Object Detection with Non-linear Semantic Decoupling Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanjie Wang",
      "Xu Zou",
      "Luxin Yan",
      "Sheng Zhong",
      "Jiahuan Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cui_On_the_Robustness_of_Large_Multimodal_Models_Against_Image_Adversarial_CVPR_2024_paper.html": {
    "title": "On the Robustness of Large Multimodal Models Against Image Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanming Cui",
      "Alejandro Aparcedo",
      "Young Kyun Jang",
      "Ser-Nam Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SoundingActions_Learning_How_Actions_Sound_from_Narrated_Egocentric_Videos_CVPR_2024_paper.html": {
    "title": "SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changan Chen",
      "Kumar Ashutosh",
      "Rohit Girdhar",
      "David Harwath",
      "Kristen Grauman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Not_All_Voxels_Are_Equal_Hardness-Aware_Semantic_Scene_Completion_with_CVPR_2024_paper.html": {
    "title": "Not All Voxels Are Equal: Hardness-Aware Semantic Scene Completion with Self-Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Song Wang",
      "Jiawei Yu",
      "Wentong Li",
      "Wenyu Liu",
      "Xiaolu Liu",
      "Junbo Chen",
      "Jianke Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dabhi_3D-LFM_Lifting_Foundation_Model_CVPR_2024_paper.html": {
    "title": "3D-LFM: Lifting Foundation Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mosam Dabhi",
      "László A. Jeni",
      "Simon Lucey"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_VP3D_Unleashing_2D_Visual_Prompt_for_Text-to-3D_Generation_CVPR_2024_paper.html": {
    "title": "VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Chen",
      "Yingwei Pan",
      "Haibo Yang",
      "Ting Yao",
      "Tao Mei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_MonoHair_High-Fidelity_Hair_Modeling_from_a_Monocular_Video_CVPR_2024_paper.html": {
    "title": "MonoHair: High-Fidelity Hair Modeling from a Monocular Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyu Wu",
      "Lingchen Yang",
      "Zhiyi Kuang",
      "Yao Feng",
      "Xutao Han",
      "Yuefan Shen",
      "Hongbo Fu",
      "Kun Zhou",
      "Youyi Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Content-Style_Decoupling_for_Unsupervised_Makeup_Transfer_without_Generating_Pseudo_Ground_CVPR_2024_paper.html": {
    "title": "Content-Style Decoupling for Unsupervised Makeup Transfer without Generating Pseudo Ground Truth",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Sun",
      "Shengwu Xiong",
      "Yaxiong Chen",
      "Yi Rong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_CVPR_2024_paper.html": {
    "title": "One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Li",
      "Haoyan Guan",
      "Jianing Qiu",
      "Michael Spratling"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_A_Versatile_Framework_for_Continual_Test-Time_Domain_Adaptation_Balancing_Discriminability_CVPR_2024_paper.html": {
    "title": "A Versatile Framework for Continual Test-Time Domain Adaptation: Balancing Discriminability and Generalizability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Yang",
      "Xuan Chen",
      "Moqi Li",
      "Kun Wei",
      "Cheng Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Quantifying_Uncertainty_in_Motion_Prediction_with_Variational_Bayesian_Mixture_CVPR_2024_paper.html": {
    "title": "Quantifying Uncertainty in Motion Prediction with Variational Bayesian Mixture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juanwu Lu",
      "Can Cui",
      "Yunsheng Ma",
      "Aniket Bera",
      "Ziran Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_You_Only_Need_Less_Attention_at_Each_Stage_in_Vision_CVPR_2024_paper.html": {
    "title": "You Only Need Less Attention at Each Stage in Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuoxi Zhang",
      "Hanpeng Liu",
      "Stephen Lin",
      "Kun He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mahmoud_Sieve_Multimodal_Dataset_Pruning_using_Image_Captioning_Models_CVPR_2024_paper.html": {
    "title": "Sieve: Multimodal Dataset Pruning using Image Captioning Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anas Mahmoud",
      "Mostafa Elhoushi",
      "Amro Abbas",
      "Yu Yang",
      "Newsha Ardalani",
      "Hugh Leather",
      "Ari S. Morcos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Generalizable_Novel-View_Synthesis_using_a_Stereo_Camera_CVPR_2024_paper.html": {
    "title": "Generalizable Novel-View Synthesis using a Stereo Camera",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haechan Lee",
      "Wonjoon Jin",
      "Seung-Hwan Baek",
      "Sunghyun Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Dynamic_LiDAR_Re-simulation_using_Compositional_Neural_Fields_CVPR_2024_paper.html": {
    "title": "Dynamic LiDAR Re-simulation using Compositional Neural Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanfeng Wu",
      "Xingxing Zuo",
      "Stefan Leutenegger",
      "Or Litany",
      "Konrad Schindler",
      "Shengyu Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Massiceti_Explaining_CLIPs_Performance_Disparities_on_Data_from_BlindLow_Vision_Users_CVPR_2024_paper.html": {
    "title": "Explaining CLIP's Performance Disparities on Data from Blind/Low Vision Users",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniela Massiceti",
      "Camilla Longden",
      "Agnieszka Slowik",
      "Samuel Wills",
      "Martin Grayson",
      "Cecily Morrison"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_AETTA_Label-Free_Accuracy_Estimation_for_Test-Time_Adaptation_CVPR_2024_paper.html": {
    "title": "AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeckyung Lee",
      "Sorn Chottananurak",
      "Taesik Gong",
      "Sung-Ju Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Digital_Life_Project_Autonomous_3D_Characters_with_Social_Intelligence_CVPR_2024_paper.html": {
    "title": "Digital Life Project: Autonomous 3D Characters with Social Intelligence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongang Cai",
      "Jianping Jiang",
      "Zhongfei Qing",
      "Xinying Guo",
      "Mingyuan Zhang",
      "Zhengyu Lin",
      "Haiyi Mei",
      "Chen Wei",
      "Ruisi Wang",
      "Wanqi Yin",
      "Liang Pan",
      "Xiangyu Fan",
      "Han Du",
      "Peng Gao",
      "Zhitao Yang",
      "Yang Gao",
      "Jiaqi Li",
      "Tianxiang Ren",
      "Yukun Wei",
      "Xiaogang Wang",
      "Chen Change Loy",
      "Lei Yang",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Eskandar_An_Empirical_Study_of_the_Generalization_Ability_of_Lidar_3D_CVPR_2024_paper.html": {
    "title": "An Empirical Study of the Generalization Ability of Lidar 3D Object Detectors to Unseen Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George Eskandar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Niu_Unsupervised_Universal_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Unsupervised Universal Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dantong Niu",
      "Xudong Wang",
      "Xinyang Han",
      "Long Lian",
      "Roei Herzig",
      "Trevor Darrell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Rethinking_Prior_Information_Generation_with_CLIP_for_Few-Shot_Segmentation_CVPR_2024_paper.html": {
    "title": "Rethinking Prior Information Generation with CLIP for Few-Shot Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Wang",
      "Bingfeng Zhang",
      "Jian Pang",
      "Honglong Chen",
      "Weifeng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bae_SingularTrajectory_Universal_Trajectory_Predictor_Using_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Inhwan Bae",
      "Young-Jae Park",
      "Hae-Gon Jeon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Generating_Handwritten_Mathematical_Expressions_From_Symbol_Graphs_An_End-to-End_Pipeline_CVPR_2024_paper.html": {
    "title": "Generating Handwritten Mathematical Expressions From Symbol Graphs: An End-to-End Pipeline",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Chen",
      "Fei Gao",
      "Yanguang Zhang",
      "Maoying Qiao",
      "Nannan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Silva-Rodriguez_A_Closer_Look_at_the_Few-Shot_Adaptation_of_Large_Vision-Language_CVPR_2024_paper.html": {
    "title": "A Closer Look at the Few-Shot Adaptation of Large Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julio Silva-Rodríguez",
      "Sina Hajimiri",
      "Ismail Ben Ayed",
      "Jose Dolz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Generative_Rendering_Controllable_4D-Guided_Video_Generation_with_2D_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengqu Cai",
      "Duygu Ceylan",
      "Matheus Gadelha",
      "Chun-Hao Paul Huang",
      "Tuanfeng Yang Wang",
      "Gordon Wetzstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saito_Relightable_Gaussian_Codec_Avatars_CVPR_2024_paper.html": {
    "title": "Relightable Gaussian Codec Avatars",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shunsuke Saito",
      "Gabriel Schwartz",
      "Tomas Simon",
      "Junxuan Li",
      "Giljoo Nam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nagasinghe_Why_Not_Use_Your_Textbook_Knowledge-Enhanced_Procedure_Planning_of_Instructional_CVPR_2024_paper.html": {
    "title": "Why Not Use Your Textbook? Knowledge-Enhanced Procedure Planning of Instructional Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kumaranage Ravindu Yasas Nagasinghe",
      "Honglu Zhou",
      "Malitha Gunawardhana",
      "Martin Renqiang Min",
      "Daniel Harari",
      "Muhammad Haris Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Global_and_Hierarchical_Geometry_Consistency_Priors_for_Few-shot_NeRFs_in_CVPR_2024_paper.html": {
    "title": "Global and Hierarchical Geometry Consistency Priors for Few-shot NeRFs in Indoor Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaotian Sun",
      "Qingshan Xu",
      "Xinjie Yang",
      "Yu Zang",
      "Cheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_FreeKD_Knowledge_Distillation_via_Semantic_Frequency_Prompt_CVPR_2024_paper.html": {
    "title": "FreeKD: Knowledge Distillation via Semantic Frequency Prompt",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Zhang",
      "Tao Huang",
      "Jiaming Liu",
      "Tao Jiang",
      "Kuan Cheng",
      "Shanghang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mittal_Cant_Make_an_Omelette_Without_Breaking_Some_Eggs_Plausible_Action_CVPR_2024_paper.html": {
    "title": "Can't Make an Omelette Without Breaking Some Eggs: Plausible Action Anticipation Using Large Video-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Himangi Mittal",
      "Nakul Agarwal",
      "Shao-Yuan Lo",
      "Kwonjoon Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zaffar_On_the_Estimation_of_Image-matching_Uncertainty_in_Visual_Place_Recognition_CVPR_2024_paper.html": {
    "title": "On the Estimation of Image-matching Uncertainty in Visual Place Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mubariz Zaffar",
      "Liangliang Nan",
      "Julian F. P. Kooij"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chng_Mask_Grounding_for_Referring_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Mask Grounding for Referring Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yong Xien Chng",
      "Henry Zheng",
      "Yizeng Han",
      "Xuchong Qiu",
      "Gao Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Single-to-Dual-View_Adaptation_for_Egocentric_3D_Hand_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "Single-to-Dual-View Adaptation for Egocentric 3D Hand Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruicong Liu",
      "Takehiko Ohkawa",
      "Mingfang Zhang",
      "Yoichi Sato"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Habuchi_Time-Efficient_Light-Field_Acquisition_Using_Coded_Aperture_and_Events_CVPR_2024_paper.html": {
    "title": "Time-Efficient Light-Field Acquisition Using Coded Aperture and Events",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuji Habuchi",
      "Keita Takahashi",
      "Chihiro Tsutake",
      "Toshiaki Fujii",
      "Hajime Nagahara"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_EVS-assisted_Joint_Deblurring_Rolling-Shutter_Correction_and_Video_Frame_Interpolation_through_CVPR_2024_paper.html": {
    "title": "EVS-assisted Joint Deblurring Rolling-Shutter Correction and Video Frame Interpolation through Sensor Inverse Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Jiang",
      "Fangwen Tu",
      "Yixuan Long",
      "Aabhaas Vaish",
      "Bowen Zhou",
      "Qinyi Wang",
      "Wei Zhang",
      "Yuntan Fang",
      "Luis Eduardo Garcia Capel",
      "Bo Mu",
      "Tiejun Dai",
      "Andreas Suess"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Prompt-Enhanced_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_Detection_CVPR_2024_paper.html": {
    "title": "Prompt-Enhanced Multiple Instance Learning for Weakly Supervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junxi Chen",
      "Liang Li",
      "Li Su",
      "Zheng-jun Zha",
      "Qingming Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Animate_Anyone_Consistent_and_Controllable_Image-to-Video_Synthesis_for_Character_Animation_CVPR_2024_paper.html": {
    "title": "Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_FreeCustom_Tuning-Free_Customized_Image_Generation_for_Multi-Concept_Composition_CVPR_2024_paper.html": {
    "title": "FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ganggui Ding",
      "Canyu Zhao",
      "Wen Wang",
      "Zhen Yang",
      "Zide Liu",
      "Hao Chen",
      "Chunhua Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_Non-autoregressive_Sequence-to-Sequence_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "Non-autoregressive Sequence-to-Sequence Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunyu Shi",
      "Qi Dong",
      "Luis Goncalves",
      "Zhuowen Tu",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_MaskINT_Video_Editing_via_Interpolative_Non-autoregressive_Masked_Transformers_CVPR_2024_paper.html": {
    "title": "MaskINT: Video Editing via Interpolative Non-autoregressive Masked Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Ma",
      "Shahin Mahdizadehaghdam",
      "Bichen Wu",
      "Zhipeng Fan",
      "Yuchao Gu",
      "Wenliang Zhao",
      "Lior Shapira",
      "Xiaohui Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bang_Active_Prompt_Learning_in_Vision_Language_Models_CVPR_2024_paper.html": {
    "title": "Active Prompt Learning in Vision Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihwan Bang",
      "Sumyeong Ahn",
      "Jae-Gil Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Learning_Multi-Dimensional_Human_Preference_for_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Learning Multi-Dimensional Human Preference for Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sixian Zhang",
      "Bohan Wang",
      "Junqiang Wu",
      "Yan Li",
      "Tingting Gao",
      "Di Zhang",
      "Zhongyuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kwak_ViVid-1-to-3_Novel_View_Synthesis_with_Video_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeong-gi Kwak",
      "Erqun Dong",
      "Yuhe Jin",
      "Hanseok Ko",
      "Shweta Mahajan",
      "Kwang Moo Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Active_Object_Detection_with_Knowledge_Aggregation_and_Distillation_from_Large_CVPR_2024_paper.html": {
    "title": "Active Object Detection with Knowledge Aggregation and Distillation from Large Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dejie Yang",
      "Yang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gurbuz_NICE_Neurogenesis_Inspired_Contextual_Encoding_for_Replay-free_Class_Incremental_Learning_CVPR_2024_paper.html": {
    "title": "NICE: Neurogenesis Inspired Contextual Encoding for Replay-free Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mustafa Burak Gurbuz",
      "Jean Michael Moorman",
      "Constantine Dovrolis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cen_Generating_Human_Motion_in_3D_Scenes_from_Text_Descriptions_CVPR_2024_paper.html": {
    "title": "Generating Human Motion in 3D Scenes from Text Descriptions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Cen",
      "Huaijin Pi",
      "Sida Peng",
      "Zehong Shen",
      "Minghui Yang",
      "Shuai Zhu",
      "Hujun Bao",
      "Xiaowei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gambashidze_Weak-to-Strong_3D_Object_Detection_with_X-Ray_Distillation_CVPR_2024_paper.html": {
    "title": "Weak-to-Strong 3D Object Detection with X-Ray Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Gambashidze",
      "Aleksandr Dadukin",
      "Maxim Golyadkin",
      "Maria Razzhivina",
      "Ilya Makarov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_QDFormer_Towards_Robust_Audiovisual_Segmentation_in_Complex_Environments_with_Quantization-based_CVPR_2024_paper.html": {
    "title": "QDFormer: Towards Robust Audiovisual Segmentation in Complex Environments with Quantization-based Semantic Decomposition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Li",
      "Jinglu Wang",
      "Xiaohao Xu",
      "Xiulian Peng",
      "Rita Singh",
      "Yan Lu",
      "Bhiksha Raj"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Active_Open-Vocabulary_Recognition_Let_Intelligent_Moving_Mitigate_CLIP_Limitations_CVPR_2024_paper.html": {
    "title": "Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP Limitations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Fan",
      "Jianxiong Zhou",
      "Xiaoying Xing",
      "Ying Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guan_Backdoor_Defense_via_Test-Time_Detecting_and_Repairing_CVPR_2024_paper.html": {
    "title": "Backdoor Defense via Test-Time Detecting and Repairing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiyang Guan",
      "Jian Liang",
      "Ran He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Fast_Adaptation_for_Human_Pose_Estimation_via_Meta-Optimization_CVPR_2024_paper.html": {
    "title": "Fast Adaptation for Human Pose Estimation via Meta-Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengxiang Hu",
      "Huaijiang Sun",
      "Bin Li",
      "Dong Wei",
      "Weiqing Li",
      "Jianfeng Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Efficient_Meshflow_and_Optical_Flow_Estimation_from_Event_Cameras_CVPR_2024_paper.html": {
    "title": "Efficient Meshflow and Optical Flow Estimation from Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinglong Luo",
      "Ao Luo",
      "Zhengning Wang",
      "Chunyu Lin",
      "Bing Zeng",
      "Shuaicheng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Visual_Program_Distillation_Distilling_Tools_and_Programmatic_Reasoning_into_Vision-Language_CVPR_2024_paper.html": {
    "title": "Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yushi Hu",
      "Otilia Stretcu",
      "Chun-Ta Lu",
      "Krishnamurthy Viswanathan",
      "Kenji Hata",
      "Enming Luo",
      "Ranjay Krishna",
      "Ariel Fuxman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kolodiazhnyi_OneFormer3D_One_Transformer_for_Unified_Point_Cloud_Segmentation_CVPR_2024_paper.html": {
    "title": "OneFormer3D: One Transformer for Unified Point Cloud Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxim Kolodiazhnyi",
      "Anna Vorontsova",
      "Anton Konushin",
      "Danila Rukhovich"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jahangard_JRDB-Social_A_Multifaceted_Robotic_Dataset_for_Understanding_of_Context_and_CVPR_2024_paper.html": {
    "title": "JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions Within Social Groups",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simindokht Jahangard",
      "Zhixi Cai",
      "Shiki Wen",
      "Hamid Rezatofighi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peirone_A_Backpack_Full_of_Skills_Egocentric_Video_Understanding_with_Diverse_CVPR_2024_paper.html": {
    "title": "A Backpack Full of Skills: Egocentric Video Understanding with Diverse Task Perspectives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simone Alberto Peirone",
      "Francesca Pistilli",
      "Antonio Alliegro",
      "Giuseppe Averta"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_WOUAF_Weight_Modulation_for_User_Attribution_and_Fingerprinting_in_Text-to-Image_CVPR_2024_paper.html": {
    "title": "WOUAF: Weight Modulation for User Attribution and Fingerprinting in Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changhoon Kim",
      "Kyle Min",
      "Maitreya Patel",
      "Sheng Cheng",
      "Yezhou Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Visual_In-Context_Prompting_CVPR_2024_paper.html": {
    "title": "Visual In-Context Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Li",
      "Qing Jiang",
      "Hao Zhang",
      "Tianhe Ren",
      "Shilong Liu",
      "Xueyan Zou",
      "Huaizhe Xu",
      "Hongyang Li",
      "Jianwei Yang",
      "Chunyuan Li",
      "Lei Zhang",
      "Jianfeng Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sklyarova_Text-Conditioned_Generative_Model_of_3D_Strand-based_Human_Hairstyles_CVPR_2024_paper.html": {
    "title": "Text-Conditioned Generative Model of 3D Strand-based Human Hairstyles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vanessa Sklyarova",
      "Egor Zakharov",
      "Otmar Hilliges",
      "Michael J. Black",
      "Justus Thies"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_GPT-4Vision_is_a_Human-Aligned_Evaluator_for_Text-to-3D_Generation_CVPR_2024_paper.html": {
    "title": "GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Wu",
      "Guandao Yang",
      "Zhibing Li",
      "Kai Zhang",
      "Ziwei Liu",
      "Leonidas Guibas",
      "Dahua Lin",
      "Gordon Wetzstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_NTO3D_Neural_Target_Object_3D_Reconstruction_with_Segment_Anything_CVPR_2024_paper.html": {
    "title": "NTO3D: Neural Target Object 3D Reconstruction with Segment Anything",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaobao Wei",
      "Renrui Zhang",
      "Jiarui Wu",
      "Jiaming Liu",
      "Ming Lu",
      "Yandong Guo",
      "Shanghang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Instruct-ReID_A_Multi-purpose_Person_Re-identification_Task_with_Instructions_CVPR_2024_paper.html": {
    "title": "Instruct-ReID: A Multi-purpose Person Re-identification Task with Instructions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weizhen He",
      "Yiheng Deng",
      "Shixiang Tang",
      "Qihao Chen",
      "Qingsong Xie",
      "Yizhou Wang",
      "Lei Bai",
      "Feng Zhu",
      "Rui Zhao",
      "Wanli Ouyang",
      "Donglian Qi",
      "Yunfeng Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_OmniMedVQA_A_New_Large-Scale_Comprehensive_Evaluation_Benchmark_for_Medical_LVLM_CVPR_2024_paper.html": {
    "title": "OmniMedVQA: A New Large-Scale Comprehensive Evaluation Benchmark for Medical LVLM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutao Hu",
      "Tianbin Li",
      "Quanfeng Lu",
      "Wenqi Shao",
      "Junjun He",
      "Yu Qiao",
      "Ping Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Skeleton-in-Context_Unified_Skeleton_Sequence_Modeling_with_In-Context_Learning_CVPR_2024_paper.html": {
    "title": "Skeleton-in-Context: Unified Skeleton Sequence Modeling with In-Context Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinshun Wang",
      "Zhongbin Fang",
      "Xia Li",
      "Xiangtai Li",
      "Chen Chen",
      "Mengyuan Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Du_DemoFusion_Democratising_High-Resolution_Image_Generation_With_No__CVPR_2024_paper.html": {
    "title": "DemoFusion: Democratising High-Resolution Image Generation With No $$$",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoyi Du",
      "Dongliang Chang",
      "Timothy Hospedales",
      "Yi-Zhe Song",
      "Zhanyu Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_IBD-SLAM_Learning_Image-Based_Depth_Fusion_for_Generalizable_SLAM_CVPR_2024_paper.html": {
    "title": "IBD-SLAM: Learning Image-Based Depth Fusion for Generalizable SLAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghao Yin",
      "Shangzhe Wu",
      "Kai Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Javed_CPLIP_Zero-Shot_Learning_for_Histopathology_with_Comprehensive_Vision-Language_Alignment_CVPR_2024_paper.html": {
    "title": "CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sajid Javed",
      "Arif Mahmood",
      "Iyyakutti Iyappan Ganapathi",
      "Fayaz Ali Dharejo",
      "Naoufel Werghi",
      "Mohammed Bennamoun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Total_Selfie_Generating_Full-Body_Selfies_CVPR_2024_paper.html": {
    "title": "Total Selfie: Generating Full-Body Selfies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowei Chen",
      "Brian Curless",
      "Ira Kemelmacher-Shlizerman",
      "Steven M. Seitz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Visual_Programming_for_Zero-shot_Open-Vocabulary_3D_Visual_Grounding_CVPR_2024_paper.html": {
    "title": "Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Yuan",
      "Jinke Ren",
      "Chun-Mei Feng",
      "Hengshuang Zhao",
      "Shuguang Cui",
      "Zhen Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Brynte_Learning_Structure-from-Motion_with_Graph_Attention_Networks_CVPR_2024_paper.html": {
    "title": "Learning Structure-from-Motion with Graph Attention Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas Brynte",
      "José Pedro Iglesias",
      "Carl Olsson",
      "Fredrik Kahl"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jung_Geometry_Transfer_for_Stylizing_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "Geometry Transfer for Stylizing Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunyoung Jung",
      "Seonghyeon Nam",
      "Nikolaos Sarafianos",
      "Sungjoo Yoo",
      "Alexander Sorkine-Hornung",
      "Rakesh Ranjan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shetty_Holoported_Characters_Real-time_Free-viewpoint_Rendering_of_Humans_from_Sparse_RGB_CVPR_2024_paper.html": {
    "title": "Holoported Characters: Real-time Free-viewpoint Rendering of Humans from Sparse RGB Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashwath Shetty",
      "Marc Habermann",
      "Guoxing Sun",
      "Diogo Luvizon",
      "Vladislav Golyanik",
      "Christian Theobalt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_SEAS_ShapE-Aligned_Supervision_for_Person_Re-Identification_CVPR_2024_paper.html": {
    "title": "SEAS: ShapE-Aligned Supervision for Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haidong Zhu",
      "Pranav Budhwant",
      "Zhaoheng Zheng",
      "Ram Nevatia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wen_Class_Incremental_Learning_with_Multi-Teacher_Distillation_CVPR_2024_paper.html": {
    "title": "Class Incremental Learning with Multi-Teacher Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haitao Wen",
      "Lili Pan",
      "Yu Dai",
      "Heqian Qiu",
      "Lanxiao Wang",
      "Qingbo Wu",
      "Hongliang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Reg-PTQ_Regression-specialized_Post-training_Quantization_for_Fully_Quantized_Object_Detector_CVPR_2024_paper.html": {
    "title": "Reg-PTQ: Regression-specialized Post-training Quantization for Fully Quantized Object Detector",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifu Ding",
      "Weilun Feng",
      "Chuyan Chen",
      "Jinyang Guo",
      "Xianglong Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_AMU-Tuning_Effective_Logit_Bias_for_CLIP-based_Few-shot_Learning_CVPR_2024_paper.html": {
    "title": "AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwei Tang",
      "Zhenyi Lin",
      "Qilong Wang",
      "Pengfei Zhu",
      "Qinghua Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Flepp_Real-World_Mobile_Image_Denoising_Dataset_with_Efficient_Baselines_CVPR_2024_paper.html": {
    "title": "Real-World Mobile Image Denoising Dataset with Efficient Baselines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roman Flepp",
      "Andrey Ignatov",
      "Radu Timofte",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rojas-Gomez_Making_Vision_Transformers_Truly_Shift-Equivariant_CVPR_2024_paper.html": {
    "title": "Making Vision Transformers Truly Shift-Equivariant",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renan A. Rojas-Gomez",
      "Teck-Yian Lim",
      "Minh N. Do",
      "Raymond A. Yeh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_SpikeNeRF_Learning_Neural_Radiance_Fields_from_Continuous_Spike_Stream_CVPR_2024_paper.html": {
    "title": "SpikeNeRF: Learning Neural Radiance Fields from Continuous Spike Stream",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Zhu",
      "Kangmin Jia",
      "Yifan Zhao",
      "Yunshan Qi",
      "Lizhi Wang",
      "Hua Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rodin_Action_Scene_Graphs_for_Long-Form_Understanding_of_Egocentric_Videos_CVPR_2024_paper.html": {
    "title": "Action Scene Graphs for Long-Form Understanding of Egocentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Rodin",
      "Antonino Furnari",
      "Kyle Min",
      "Subarna Tripathi",
      "Giovanni Maria Farinella"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cong_A_Semi-supervised_Nighttime_Dehazing_Baseline_with_Spatial-Frequency_Aware_and_Realistic_CVPR_2024_paper.html": {
    "title": "A Semi-supervised Nighttime Dehazing Baseline with Spatial-Frequency Aware and Realistic Brightness Constraint",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaofeng Cong",
      "Jie Gui",
      "Jing Zhang",
      "Junming Hou",
      "Hao Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_De-confounded_Data-free_Knowledge_Distillation_for_Handling_Distribution_Shifts_CVPR_2024_paper.html": {
    "title": "De-confounded Data-free Knowledge Distillation for Handling Distribution Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzheng Wang",
      "Dingkang Yang",
      "Zhaoyu Chen",
      "Yang Liu",
      "Siao Liu",
      "Wenqiang Zhang",
      "Lihua Zhang",
      "Lizhe Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_Fine-Grained_Bipartite_Concept_Factorization_for_Clustering_CVPR_2024_paper.html": {
    "title": "Fine-Grained Bipartite Concept Factorization for Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Peng",
      "Pengfei Zhang",
      "Yongyong Chen",
      "Zhao Kang",
      "Chenglizhao Chen",
      "Qiang Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Siamese_Learning_with_Joint_Alignment_and_Regression_for_Weakly-Supervised_Video_CVPR_2024_paper.html": {
    "title": "Siamese Learning with Joint Alignment and Regression for Weakly-Supervised Video Paragraph Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaolei Tan",
      "Jianhuang Lai",
      "Wei-Shi Zheng",
      "Jian-Fang Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Language-Driven_Anchors_for_Zero-Shot_Adversarial_Robustness_CVPR_2024_paper.html": {
    "title": "Language-Driven Anchors for Zero-Shot Adversarial Robustness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Li",
      "Wei Zhang",
      "Yining Liu",
      "Zhanhao Hu",
      "Bo Zhang",
      "Xiaolin Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Deep_Equilibrium_Diffusion_Restoration_with_Parallel_Sampling_CVPR_2024_paper.html": {
    "title": "Deep Equilibrium Diffusion Restoration with Parallel Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiezhang Cao",
      "Yue Shi",
      "Kai Zhang",
      "Yulun Zhang",
      "Radu Timofte",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_LEOD_Label-Efficient_Object_Detection_for_Event_Cameras_CVPR_2024_paper.html": {
    "title": "LEOD: Label-Efficient Object Detection for Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Wu",
      "Mathias Gehrig",
      "Qing Lyu",
      "Xudong Liu",
      "Igor Gilitschenski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Morphological_Prototyping_for_Unsupervised_Slide_Representation_Learning_in_Computational_Pathology_CVPR_2024_paper.html": {
    "title": "Morphological Prototyping for Unsupervised Slide Representation Learning in Computational Pathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrew H. Song",
      "Richard J. Chen",
      "Tong Ding",
      "Drew F.K. Williamson",
      "Guillaume Jaume",
      "Faisal Mahmood"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Fooling_Polarization-Based_Vision_using_Locally_Controllable_Polarizing_Projection_CVPR_2024_paper.html": {
    "title": "Fooling Polarization-Based Vision using Locally Controllable Polarizing Projection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuoxiao Li",
      "Zhihang Zhong",
      "Shohei Nobuhara",
      "Ko Nishino",
      "Yinqiang Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Le_Moing_Dense_Optical_Tracking_Connecting_the_Dots_CVPR_2024_paper.html": {
    "title": "Dense Optical Tracking: Connecting the Dots",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillaume Le Moing",
      "Jean Ponce",
      "Cordelia Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_A_Stealthy_Wrongdoer_Feature-Oriented_Reconstruction_Attack_against_Split_Learning_CVPR_2024_paper.html": {
    "title": "A Stealthy Wrongdoer: Feature-Oriented Reconstruction Attack against Split Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Xu",
      "Mengda Yang",
      "Wenzhe Yi",
      "Ziang Li",
      "Juan Wang",
      "Hongxin Hu",
      "Yong Zhuang",
      "Yaxin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_DiffAM_Diffusion-based_Adversarial_Makeup_Transfer_for_Facial_Privacy_Protection_CVPR_2024_paper.html": {
    "title": "DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Sun",
      "Lingyun Yu",
      "Hongtao Xie",
      "Jiaming Li",
      "Yongdong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Navaneet_SlowFormer_Adversarial_Attack_on_Compute_and_Energy_Consumption_of_Efficient_CVPR_2024_paper.html": {
    "title": "SlowFormer: Adversarial Attack on Compute and Energy Consumption of Efficient Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "K L Navaneet",
      "Soroush Abbasi Koohpayegani",
      "Essam Sleiman",
      "Hamed Pirsiavash"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_TULIP_Transformer_for_Upsampling_of_LiDAR_Point_Clouds_CVPR_2024_paper.html": {
    "title": "TULIP: Transformer for Upsampling of LiDAR Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Yang",
      "Patrick Pfreundschuh",
      "Roland Siegwart",
      "Marco Hutter",
      "Peyman Moghadam",
      "Vaishakh Patil"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_How_to_Configure_Good_In-Context_Sequence_for_Visual_Question_Answering_CVPR_2024_paper.html": {
    "title": "How to Configure Good In-Context Sequence for Visual Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Li",
      "Jiawei Peng",
      "Huiyi Chen",
      "Chongyang Gao",
      "Xu Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Abdal_Gaussian_Shell_Maps_for_Efficient_3D_Human_Generation_CVPR_2024_paper.html": {
    "title": "Gaussian Shell Maps for Efficient 3D Human Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rameen Abdal",
      "Wang Yifan",
      "Zifan Shi",
      "Yinghao Xu",
      "Ryan Po",
      "Zhengfei Kuang",
      "Qifeng Chen",
      "Dit-Yan Yeung",
      "Gordon Wetzstein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Defense_Against_Adversarial_Attacks_on_No-Reference_Image_Quality_Models_with_CVPR_2024_paper.html": {
    "title": "Defense Against Adversarial Attacks on No-Reference Image Quality Models with Gradient Norm Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujia Liu",
      "Chenxi Yang",
      "Dingquan Li",
      "Jianhao Ding",
      "Tingting Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_TACO_Benchmarking_Generalizable_Bimanual_Tool-ACtion-Object_Understanding_CVPR_2024_paper.html": {
    "title": "TACO: Benchmarking Generalizable Bimanual Tool-ACtion-Object Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Liu",
      "Haolin Yang",
      "Xu Si",
      "Ling Liu",
      "Zipeng Li",
      "Yuxiang Zhang",
      "Yebin Liu",
      "Li Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_MoST_Motion_Style_Transformer_Between_Diverse_Action_Contents_CVPR_2024_paper.html": {
    "title": "MoST: Motion Style Transformer Between Diverse Action Contents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boeun Kim",
      "Jungho Kim",
      "Hyung Jin Chang",
      "Jin Young Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mahajan_Prompting_Hard_or_Hardly_Prompting_Prompt_Inversion_for_Text-to-Image_Diffusion_CVPR_2024_paper.html": {
    "title": "Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shweta Mahajan",
      "Tanzila Rahman",
      "Kwang Moo Yi",
      "Leonid Sigal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Unmixing_Before_Fusion_A_Generalized_Paradigm_for_Multi-Source-based_Hyperspectral_Image_CVPR_2024_paper.html": {
    "title": "Unmixing Before Fusion: A Generalized Paradigm for Multi-Source-based Hyperspectral Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Yu",
      "Erting Pan",
      "Xinya Wang",
      "Yuheng Wu",
      "Xiaoguang Mei",
      "Jiayi Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tao_AlignMiF_Geometry-Aligned_Multimodal_Implicit_Field_for_LiDAR-Camera_Joint_Synthesis_CVPR_2024_paper.html": {
    "title": "AlignMiF: Geometry-Aligned Multimodal Implicit Field for LiDAR-Camera Joint Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tang Tao",
      "Guangrun Wang",
      "Yixing Lao",
      "Peng Chen",
      "Jie Liu",
      "Liang Lin",
      "Kaicheng Yu",
      "Xiaodan Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mei_CoDi_Conditional_Diffusion_Distillation_for_Higher-Fidelity_and_Faster_Image_Generation_CVPR_2024_paper.html": {
    "title": "CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangfu Mei",
      "Mauricio Delbracio",
      "Hossein Talebi",
      "Zhengzhong Tu",
      "Vishal M. Patel",
      "Peyman Milanfar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/An_Improving_Unsupervised_Hierarchical_Representation_with_Reinforcement_Learning_CVPR_2024_paper.html": {
    "title": "Improving Unsupervised Hierarchical Representation with Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruyi An",
      "Yewen Li",
      "Xu He",
      "Pengjie Gu",
      "Mengchen Zhao",
      "Dong Li",
      "Jianye Hao",
      "Chaojie Wang",
      "Bo An",
      "Mingyuan Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jing_HPL-ESS_Hybrid_Pseudo-Labeling_for_Unsupervised_Event-based_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "HPL-ESS: Hybrid Pseudo-Labeling for Unsupervised Event-based Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linglin Jing",
      "Yiming Ding",
      "Yunpeng Gao",
      "Zhigang Wang",
      "Xu Yan",
      "Dong Wang",
      "Gerald Schaefer",
      "Hui Fang",
      "Bin Zhao",
      "Xuelong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ran_X-Adapter_Adding_Universal_Compatibility_of_Plugins_for_Upgraded_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "X-Adapter: Adding Universal Compatibility of Plugins for Upgraded Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingmin Ran",
      "Xiaodong Cun",
      "Jia-Wei Liu",
      "Rui Zhao",
      "Song Zijie",
      "Xintao Wang",
      "Jussi Keppo",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Towards_General_Robustness_Verification_of_MaxPool-based_Convolutional_Neural_Networks_via_CVPR_2024_paper.html": {
    "title": "Towards General Robustness Verification of MaxPool-based Convolutional Neural Networks via Tightening Linear Approximation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Xiao",
      "Shiqing Ma",
      "Juan Zhai",
      "Chunrong Fang",
      "Jinyuan Jia",
      "Zhenyu Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_BT-Adapter_Video_Conversation_is_Feasible_Without_Video_Instruction_Tuning_CVPR_2024_paper.html": {
    "title": "BT-Adapter: Video Conversation is Feasible Without Video Instruction Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruyang Liu",
      "Chen Li",
      "Yixiao Ge",
      "Thomas H. Li",
      "Ying Shan",
      "Ge Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_CADTalk_An_Algorithm_and_Benchmark_for_Semantic_Commenting_of_CAD_CVPR_2024_paper.html": {
    "title": "CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haocheng Yuan",
      "Jing Xu",
      "Hao Pan",
      "Adrien Bousseau",
      "Niloy J. Mitra",
      "Changjian Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_Learning_to_Rematch_Mismatched_Pairs_for_Robust_Cross-Modal_Retrieval_CVPR_2024_paper.html": {
    "title": "Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haochen Han",
      "Qinghua Zheng",
      "Guang Dai",
      "Minnan Luo",
      "Jingdong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ni_Generate_Subgoal_Images_before_Act_Unlocking_the_Chain-of-Thought_Reasoning_in_CVPR_2024_paper.html": {
    "title": "Generate Subgoal Images before Act: Unlocking the Chain-of-Thought Reasoning in Diffusion Model for Robot Manipulation with Multimodal Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Ni",
      "Jianye Hao",
      "Shiguang Wu",
      "Longxin Kou",
      "Jiashun Liu",
      "Yan Zheng",
      "Bin Wang",
      "Yuzheng Zhuang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Asymmetric_Masked_Distillation_for_Pre-Training_Small_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Asymmetric Masked Distillation for Pre-Training Small Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyu Zhao",
      "Bingkun Huang",
      "Sen Xing",
      "Gangshan Wu",
      "Yu Qiao",
      "Limin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Inversion-Free_Image_Editing_with_Language-Guided_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Inversion-Free Image Editing with Language-Guided Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihan Xu",
      "Yidong Huang",
      "Jiayi Pan",
      "Ziqiao Ma",
      "Joyce Chai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mondal_HumMUSS_Human_Motion_Understanding_using_State_Space_Models_CVPR_2024_paper.html": {
    "title": "HumMUSS: Human Motion Understanding using State Space Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnab Mondal",
      "Stefano Alletto",
      "Denis Tome"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qin_MP5_A_Multi-modal_Open-ended_Embodied_System_in_Minecraft_via_Active_CVPR_2024_paper.html": {
    "title": "MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiran Qin",
      "Enshen Zhou",
      "Qichang Liu",
      "Zhenfei Yin",
      "Lu Sheng",
      "Ruimao Zhang",
      "Yu Qiao",
      "Jing Shao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Du_Uncovering_What_Why_and_How_A_Comprehensive_Benchmark_for_Causation_CVPR_2024_paper.html": {
    "title": "Uncovering What Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Du",
      "Sicheng Zhang",
      "Binzhu Xie",
      "Guoshun Nan",
      "Jiayang Zhang",
      "Junrui Xu",
      "Hangyu Liu",
      "Sicong Leng",
      "Jiangming Liu",
      "Hehe Fan",
      "Dajiu Huang",
      "Jing Feng",
      "Linli Chen",
      "Can Zhang",
      "Xuhuan Li",
      "Hao Zhang",
      "Jianhang Chen",
      "Qimei Cui",
      "Xiaofeng Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chang_MiKASA_Multi-Key-Anchor__Scene-Aware_Transformer_for_3D_Visual_Grounding_CVPR_2024_paper.html": {
    "title": "MiKASA: Multi-Key-Anchor & Scene-Aware Transformer for 3D Visual Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chun-Peng Chang",
      "Shaoxiang Wang",
      "Alain Pagani",
      "Didier Stricker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_ZePT_Zero-Shot_Pan-Tumor_Segmentation_via_Query-Disentangling_and_Self-Prompting_CVPR_2024_paper.html": {
    "title": "ZePT: Zero-Shot Pan-Tumor Segmentation via Query-Disentangling and Self-Prompting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yankai Jiang",
      "Zhongzhen Huang",
      "Rongzhao Zhang",
      "Xiaofan Zhang",
      "Shaoting Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Task-Driven_Exploration_Decoupling_and_Inter-Task_Feedback_for_Joint_Moment_Retrieval_CVPR_2024_paper.html": {
    "title": "Task-Driven Exploration: Decoupling and Inter-Task Feedback for Joint Moment Retrieval and Highlight Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Yang",
      "Ping Wei",
      "Huan Li",
      "Ziyang Ren"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vasu_MobileCLIP_Fast_Image-Text_Models_through_Multi-Modal_Reinforced_Training_CVPR_2024_paper.html": {
    "title": "MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pavan Kumar Anasosalu Vasu",
      "Hadi Pouransari",
      "Fartash Faghri",
      "Raviteja Vemulapalli",
      "Oncel Tuzel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Drag_Your_Noise_Interactive_Point-based_Editing_via_Diffusion_Semantic_Propagation_CVPR_2024_paper.html": {
    "title": "Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haofeng Liu",
      "Chenshu Xu",
      "Yifei Yang",
      "Lihua Zeng",
      "Shengfeng He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_CDMAD_Class-Distribution-Mismatch-Aware_Debiasing_for_Class-Imbalanced_Semi-Supervised_Learning_CVPR_2024_paper.html": {
    "title": "CDMAD: Class-Distribution-Mismatch-Aware Debiasing for Class-Imbalanced Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyuck Lee",
      "Heeyoung Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bansal_VideoCon_Robust_Video-Language_Alignment_via_Contrast_Captions_CVPR_2024_paper.html": {
    "title": "VideoCon: Robust Video-Language Alignment via Contrast Captions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hritik Bansal",
      "Yonatan Bitton",
      "Idan Szpektor",
      "Kai-Wei Chang",
      "Aditya Grover"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tu_PanoPose_Self-supervised_Relative_Pose_Estimation_for_Panoramic_Images_CVPR_2024_paper.html": {
    "title": "PanoPose: Self-supervised Relative Pose Estimation for Panoramic Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diantao Tu",
      "Hainan Cui",
      "Xianwei Zheng",
      "Shuhan Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_ContextSeg_Sketch_Semantic_Segmentation_by_Querying_the_Context_with_Attention_CVPR_2024_paper.html": {
    "title": "ContextSeg: Sketch Semantic Segmentation by Querying the Context with Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Wang",
      "Changjian Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dunlap_Describing_Differences_in_Image_Sets_with_Natural_Language_CVPR_2024_paper.html": {
    "title": "Describing Differences in Image Sets with Natural Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lisa Dunlap",
      "Yuhui Zhang",
      "Xiaohan Wang",
      "Ruiqi Zhong",
      "Trevor Darrell",
      "Jacob Steinhardt",
      "Joseph E. Gonzalez",
      "Serena Yeung-Levy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Discovering_and_Mitigating_Visual_Biases_through_Keyword_Explanation_CVPR_2024_paper.html": {
    "title": "Discovering and Mitigating Visual Biases through Keyword Explanation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Younghyun Kim",
      "Sangwoo Mo",
      "Minkyu Kim",
      "Kyungmin Lee",
      "Jaeho Lee",
      "Jinwoo Shin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Robust_Emotion_Recognition_in_Context_Debiasing_CVPR_2024_paper.html": {
    "title": "Robust Emotion Recognition in Context Debiasing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dingkang Yang",
      "Kun Yang",
      "Mingcheng Li",
      "Shunli Wang",
      "Shuaibing Wang",
      "Lihua Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Fully_Geometric_Panoramic_Localization_CVPR_2024_paper.html": {
    "title": "Fully Geometric Panoramic Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junho Kim",
      "Jiwon Jeong",
      "Young Min Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chowdhury_CAPE_CAM_as_a_Probabilistic_Ensemble_for_Enhanced_DNN_Interpretation_CVPR_2024_paper.html": {
    "title": "CAPE: CAM as a Probabilistic Ensemble for Enhanced DNN Interpretation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Townim Faisal Chowdhury",
      "Kewen Liao",
      "Vu Minh Hieu Phan",
      "Minh-Son To",
      "Yutong Xie",
      "Kevin Hung",
      "David Ross",
      "Anton van den Hengel",
      "Johan W. Verjans",
      "Zhibin Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_NeRF_Director_Revisiting_View_Selection_in_Neural_Volume_Rendering_CVPR_2024_paper.html": {
    "title": "NeRF Director: Revisiting View Selection in Neural Volume Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhui Xiao",
      "Rodrigo Santa Cruz",
      "David Ahmedt-Aristizabal",
      "Olivier Salvado",
      "Clinton Fookes",
      "Leo Lebrat"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Khorram_Taming_the_Tail_in_Class-Conditional_GANs_Knowledge_Sharing_via_Unconditional_CVPR_2024_paper.html": {
    "title": "Taming the Tail in Class-Conditional GANs: Knowledge Sharing via Unconditional Training at Lower Resolutions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saeed Khorram",
      "Mingqi Jiang",
      "Mohamad Shahbazi",
      "Mohamad H. Danesh",
      "Li Fuxin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_VideoSwap_Customized_Video_Subject_Swapping_with_Interactive_Semantic_Point_Correspondence_CVPR_2024_paper.html": {
    "title": "VideoSwap: Customized Video Subject Swapping with Interactive Semantic Point Correspondence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchao Gu",
      "Yipin Zhou",
      "Bichen Wu",
      "Licheng Yu",
      "Jia-Wei Liu",
      "Rui Zhao",
      "Jay Zhangjie Wu",
      "David Junhao Zhang",
      "Mike Zheng Shou",
      "Kevin Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_SonicVisionLM_Playing_Sound_with_Vision_Language_Models_CVPR_2024_paper.html": {
    "title": "SonicVisionLM: Playing Sound with Vision Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhifeng Xie",
      "Shengye Yu",
      "Qile He",
      "Mengtian Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Multi-Space_Alignments_Towards_Universal_LiDAR_Segmentation_CVPR_2024_paper.html": {
    "title": "Multi-Space Alignments Towards Universal LiDAR Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youquan Liu",
      "Lingdong Kong",
      "Xiaoyang Wu",
      "Runnan Chen",
      "Xin Li",
      "Liang Pan",
      "Ziwei Liu",
      "Yuexin Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_DiffuScene_Denoising_Diffusion_Models_for_Generative_Indoor_Scene_Synthesis_CVPR_2024_paper.html": {
    "title": "DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiapeng Tang",
      "Yinyu Nie",
      "Lev Markhasin",
      "Angela Dai",
      "Justus Thies",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chang_Hierarchical_Histogram_Threshold_Segmentation_-_Auto-terminating_High-detail_Oversegmentation_CVPR_2024_paper.html": {
    "title": "Hierarchical Histogram Threshold Segmentation - Auto-terminating High-detail Oversegmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas V. Chang",
      "Simon Seibt",
      "Bartosz von Rymon Lipinski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Once_for_Both_Single_Stage_of_Importance_and_Sparsity_Search_CVPR_2024_paper.html": {
    "title": "Once for Both: Single Stage of Importance and Sparsity Search for Vision Transformer Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hancheng Ye",
      "Chong Yu",
      "Peng Ye",
      "Renqiu Xia",
      "Yansong Tang",
      "Jiwen Lu",
      "Tao Chen",
      "Bo Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yoo_As-Plausible-As-Possible_Plausibility-Aware_Mesh_Deformation_Using_2D_Diffusion_Priors_CVPR_2024_paper.html": {
    "title": "As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungwoo Yoo",
      "Kunho Kim",
      "Vladimir G. Kim",
      "Minhyuk Sung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_MCNet_Rethinking_the_Core_Ingredients_for_Accurate_and_Efficient_Homography_CVPR_2024_paper.html": {
    "title": "MCNet: Rethinking the Core Ingredients for Accurate and Efficient Homography Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haokai Zhu",
      "Si-Yuan Cao",
      "Jianxin Hu",
      "Sitong Zuo",
      "Beinan Yu",
      "Jiacheng Ying",
      "Junwei Li",
      "Hui-Liang Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_ECLIPSE_Efficient_Continual_Learning_in_Panoptic_Segmentation_with_Visual_Prompt_CVPR_2024_paper.html": {
    "title": "ECLIPSE: Efficient Continual Learning in Panoptic Segmentation with Visual Prompt Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beomyoung Kim",
      "Joonsang Yu",
      "Sung Ju Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Boosting_Continual_Learning_of_Vision-Language_Models_via_Mixture-of-Experts_Adapters_CVPR_2024_paper.html": {
    "title": "Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiazuo Yu",
      "Yunzhi Zhuge",
      "Lu Zhang",
      "Ping Hu",
      "Dong Wang",
      "Huchuan Lu",
      "You He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huynh_MaGGIe_Masked_Guided_Gradual_Human_Instance_Matting_CVPR_2024_paper.html": {
    "title": "MaGGIe: Masked Guided Gradual Human Instance Matting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuong Huynh",
      "Seoung Wug Oh",
      "Abhinav Shrivastava",
      "Joon-Young Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_FlowDiffuser_Advancing_Optical_Flow_Estimation_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "FlowDiffuser: Advancing Optical Flow Estimation with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ao Luo",
      "Xin Li",
      "Fan Yang",
      "Jiangyu Liu",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hua_Benchmarking_Implicit_Neural_Representation_and_Geometric_Rendering_in_Real-Time_RGB-D_CVPR_2024_paper.html": {
    "title": "Benchmarking Implicit Neural Representation and Geometric Rendering in Real-Time RGB-D SLAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongyan Hua",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Free3D_Consistent_Novel_View_Synthesis_without_3D_Representation_CVPR_2024_paper.html": {
    "title": "Free3D: Consistent Novel View Synthesis without 3D Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuanxia Zheng",
      "Andrea Vedaldi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_SuperSVG_Superpixel-based_Scalable_Vector_Graphics_Synthesis_CVPR_2024_paper.html": {
    "title": "SuperSVG: Superpixel-based Scalable Vector Graphics Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Teng Hu",
      "Ran Yi",
      "Baihong Qian",
      "Jiangning Zhang",
      "Paul L. Rosin",
      "Yu-Kun Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_AV2AV_Direct_Audio-Visual_Speech_to_Audio-Visual_Speech_Translation_with_Unified_CVPR_2024_paper.html": {
    "title": "AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation with Unified Audio-Visual Speech Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeongsoo Choi",
      "Se Jin Park",
      "Minsu Kim",
      "Yong Man Ro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Towards_the_Uncharted_Density-Descending_Feature_Perturbation_for_Semi-supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Towards the Uncharted: Density-Descending Feature Perturbation for Semi-supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Wang",
      "Huihui Bai",
      "Limin Yu",
      "Yao Zhao",
      "Jimin Xiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vuong_WALT3D_Generating_Realistic_Training_Data_from_Time-Lapse_Imagery_for_Reconstructing_CVPR_2024_paper.html": {
    "title": "WALT3D: Generating Realistic Training Data from Time-Lapse Imagery for Reconstructing Dynamic Objects Under Occlusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khiem Vuong",
      "N Dinesh Reddy",
      "Robert Tamburo",
      "Srinivasa G. Narasimhan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_RTMO_Towards_High-Performance_One-Stage_Real-Time_Multi-Person_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "RTMO: Towards High-Performance One-Stage Real-Time Multi-Person Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Lu",
      "Tao Jiang",
      "Yining Li",
      "Xiangtai Li",
      "Kai Chen",
      "Wenming Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_Contrastive_Mean-Shift_Learning_for_Generalized_Category_Discovery_CVPR_2024_paper.html": {
    "title": "Contrastive Mean-Shift Learning for Generalized Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sua Choi",
      "Dahyun Kang",
      "Minsu Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Towards_Language-Driven_Video_Inpainting_via_Multimodal_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "Towards Language-Driven Video Inpainting via Multimodal Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianzong Wu",
      "Xiangtai Li",
      "Chenyang Si",
      "Shangchen Zhou",
      "Jingkang Yang",
      "Jiangning Zhang",
      "Yining Li",
      "Kai Chen",
      "Yunhai Tong",
      "Ziwei Liu",
      "Chen Change Loy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Miao_WaveFace_Authentic_Face_Restoration_with_Efficient_Frequency_Recovery_CVPR_2024_paper.html": {
    "title": "WaveFace: Authentic Face Restoration with Efficient Frequency Recovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunqi Miao",
      "Jiankang Deng",
      "Jungong Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_CLIP-KD_An_Empirical_Study_of_CLIP_Model_Distillation_CVPR_2024_paper.html": {
    "title": "CLIP-KD: An Empirical Study of CLIP Model Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuanguang Yang",
      "Zhulin An",
      "Libo Huang",
      "Junyu Bi",
      "Xinqiang Yu",
      "Han Yang",
      "Boyu Diao",
      "Yongjun Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_UltrAvatar_A_Realistic_Animatable_3D_Avatar_Diffusion_Model_with_Authenticity_CVPR_2024_paper.html": {
    "title": "UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyuan Zhou",
      "Rakib Hyder",
      "Ziwei Xuan",
      "Guojun Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_OneTracker_Unifying_Visual_Object_Tracking_with_Foundation_Models_and_Efficient_CVPR_2024_paper.html": {
    "title": "OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingyi Hong",
      "Shilin Yan",
      "Renrui Zhang",
      "Wanyun Li",
      "Xinyu Zhou",
      "Pinxue Guo",
      "Kaixun Jiang",
      "Yiting Chen",
      "Jinglun Li",
      "Zhaoyu Chen",
      "Wenqiang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yue_SC-Tune_Unleashing_Self-Consistent_Referential_Comprehension_in_Large_Vision_Language_Models_CVPR_2024_paper.html": {
    "title": "SC-Tune: Unleashing Self-Consistent Referential Comprehension in Large Vision Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongtian Yue",
      "Jie Cheng",
      "Longteng Guo",
      "Xingyuan Dai",
      "Zijia Zhao",
      "Xingjian He",
      "Gang Xiong",
      "Yisheng Lv",
      "Jing Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Improving_Depth_Completion_via_Depth_Feature_Upsampling_CVPR_2024_paper.html": {
    "title": "Improving Depth Completion via Depth Feature Upsampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Wang",
      "Ge Zhang",
      "Shaoqian Wang",
      "Bo Li",
      "Qi Liu",
      "Le Hui",
      "Yuchao Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_NeRSP_Neural_3D_Reconstruction_for_Reflective_Objects_with_Sparse_Polarized_CVPR_2024_paper.html": {
    "title": "NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse Polarized Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Han",
      "Heng Guo",
      "Koki Fukai",
      "Hiroaki Santo",
      "Boxin Shi",
      "Fumio Okura",
      "Zhanyu Ma",
      "Yunpeng Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Retrieval-Augmented_Embodied_Agents_CVPR_2024_paper.html": {
    "title": "Retrieval-Augmented Embodied Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Zhu",
      "Zhicai Ou",
      "Xiaofeng Mou",
      "Jian Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_SAFDNet_A_Simple_and_Effective_Network_for_Fully_Sparse_3D_CVPR_2024_paper.html": {
    "title": "SAFDNet: A Simple and Effective Network for Fully Sparse 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gang Zhang",
      "Junnan Chen",
      "Guohuan Gao",
      "Jianmin Li",
      "Si Liu",
      "Xiaolin Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kang_Attention-Propagation_Network_for_Egocentric_Heatmap_to_3D_Pose_Lifting_CVPR_2024_paper.html": {
    "title": "Attention-Propagation Network for Egocentric Heatmap to 3D Pose Lifting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeho Kang",
      "Youngki Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_OmniMotionGPT_Animal_Motion_Generation_with_Limited_Data_CVPR_2024_paper.html": {
    "title": "OmniMotionGPT: Animal Motion Generation with Limited Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangsihao Yang",
      "Mingyuan Zhou",
      "Mengyi Shan",
      "Bingbing Wen",
      "Ziwei Xuan",
      "Mitch Hill",
      "Junjie Bai",
      "Guo-Jun Qi",
      "Yalin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_SNI-SLAM_Semantic_Neural_Implicit_SLAM_CVPR_2024_paper.html": {
    "title": "SNI-SLAM: Semantic Neural Implicit SLAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siting Zhu",
      "Guangming Wang",
      "Hermann Blum",
      "Jiuming Liu",
      "Liang Song",
      "Marc Pollefeys",
      "Hesheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_InstanceDiffusion_Instance-level_Control_for_Image_Generation_CVPR_2024_paper.html": {
    "title": "InstanceDiffusion: Instance-level Control for Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xudong Wang",
      "Trevor Darrell",
      "Sai Saketh Rambhatla",
      "Rohit Girdhar",
      "Ishan Misra"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Unifying_Top-down_and_Bottom-up_Scanpath_Prediction_Using_Transformers_CVPR_2024_paper.html": {
    "title": "Unifying Top-down and Bottom-up Scanpath Prediction Using Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhibo Yang",
      "Sounak Mondal",
      "Seoyoung Ahn",
      "Ruoyu Xue",
      "Gregory Zelinsky",
      "Minh Hoai",
      "Dimitris Samaras"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_HINTED_Hard_Instance_Enhanced_Detector_with_Mixed-Density_Feature_Fusion_for_CVPR_2024_paper.html": {
    "title": "HINTED: Hard Instance Enhanced Detector with Mixed-Density Feature Fusion for Sparsely-Supervised 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiming Xia",
      "Wei Ye",
      "Hai Wu",
      "Shijia Zhao",
      "Leyuan Xing",
      "Xun Huang",
      "Jinhao Deng",
      "Xin Li",
      "Chenglu Wen",
      "Cheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_Structured_Gradient-based_Interpretations_via_Norm-Regularized_Adversarial_Training_CVPR_2024_paper.html": {
    "title": "Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shizhan Gong",
      "Qi Dou",
      "Farzan Farnia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Building_a_Strong_Pre-Training_Baseline_for_Universal_3D_Large-Scale_Perception_CVPR_2024_paper.html": {
    "title": "Building a Strong Pre-Training Baseline for Universal 3D Large-Scale Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoming Chen",
      "Zhizhong Zhang",
      "Yanyun Qu",
      "Ruixin Zhang",
      "Xin Tan",
      "Yuan Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_DS-NeRV_Implicit_Neural_Video_Representation_with_Decomposed_Static_and_Dynamic_CVPR_2024_paper.html": {
    "title": "DS-NeRV: Implicit Neural Video Representation with Decomposed Static and Dynamic Codes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Yan",
      "Zhihui Ke",
      "Xiaobo Zhou",
      "Tie Qiu",
      "Xidong Shi",
      "Dadong Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_3D-Aware_Face_Editing_via_Warping-Guided_Latent_Direction_Learning_CVPR_2024_paper.html": {
    "title": "3D-Aware Face Editing via Warping-Guided Latent Direction Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Cheng",
      "Zhuo Chen",
      "Xingyu Ren",
      "Wenhan Zhu",
      "Zhengqin Xu",
      "Di Xu",
      "Changpeng Yang",
      "Yichao Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jin_3DFIRES_Few_Image_3D_REconstruction_for_Scenes_with_Hidden_Surfaces_CVPR_2024_paper.html": {
    "title": "3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surfaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linyi Jin",
      "Nilesh Kulkarni",
      "David F. Fouhey"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cho_CAT-Seg_Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seokju Cho",
      "Heeseong Shin",
      "Sunghwan Hong",
      "Anurag Arnab",
      "Paul Hongsuck Seo",
      "Seungryong Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Focus_on_Your_Instruction_Fine-grained_and_Multi-instruction_Image_Editing_by_CVPR_2024_paper.html": {
    "title": "Focus on Your Instruction: Fine-grained and Multi-instruction Image Editing by Attention Modulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qin Guo",
      "Tianwei Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hou_SDSTrack_Self-Distillation_Symmetric_Adapter_Learning_for_Multi-Modal_Visual_Object_Tracking_CVPR_2024_paper.html": {
    "title": "SDSTrack: Self-Distillation Symmetric Adapter Learning for Multi-Modal Visual Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaojun Hou",
      "Jiazheng Xing",
      "Yijie Qian",
      "Yaowei Guo",
      "Shuo Xin",
      "Junhao Chen",
      "Kai Tang",
      "Mengmeng Wang",
      "Zhengkai Jiang",
      "Liang Liu",
      "Yong Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_MCPNet_An_Interpretable_Classifier_via_Multi-Level_Concept_Prototypes_CVPR_2024_paper.html": {
    "title": "MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bor-Shiun Wang",
      "Chien-Yi Wang",
      "Wei-Chen Chiu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ishmam_Semantic_Shield_Defending_Vision-Language_Models_Against_Backdooring_and_Poisoning_via_CVPR_2024_paper.html": {
    "title": "Semantic Shield: Defending Vision-Language Models Against Backdooring and Poisoning via Fine-grained Knowledge Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alvi Md Ishmam",
      "Christopher Thomas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_AvatarGPT_All-in-One_Framework_for_Motion_Understanding_Planning_Generation_and_Beyond_CVPR_2024_paper.html": {
    "title": "AvatarGPT: All-in-One Framework for Motion Understanding Planning Generation and Beyond",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixiang Zhou",
      "Yu Wan",
      "Baoyuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Rethinking_the_Up-Sampling_Operations_in_CNN-based_Generative_Network_for_Generalizable_CVPR_2024_paper.html": {
    "title": "Rethinking the Up-Sampling Operations in CNN-based Generative Network for Generalizable Deepfake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuangchuang Tan",
      "Yao Zhao",
      "Shikui Wei",
      "Guanghua Gu",
      "Ping Liu",
      "Yunchao Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Co-Speech_Gesture_Video_Generation_via_Motion-Decoupled_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "Co-Speech Gesture Video Generation via Motion-Decoupled Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu He",
      "Qiaochu Huang",
      "Zhensong Zhang",
      "Zhiwei Lin",
      "Zhiyong Wu",
      "Sicheng Yang",
      "Minglei Li",
      "Zhiyi Chen",
      "Songcen Xu",
      "Xiaofei Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_CDFormer_When_Degradation_Prediction_Embraces_Diffusion_Model_for_Blind_Image_CVPR_2024_paper.html": {
    "title": "CDFormer: When Degradation Prediction Embraces Diffusion Model for Blind Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingguo Liu",
      "Chenyi Zhuang",
      "Pan Gao",
      "Jie Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_HumanRef_Single_Image_to_3D_Human_Generation_via_Reference-Guided_Diffusion_CVPR_2024_paper.html": {
    "title": "HumanRef: Single Image to 3D Human Generation via Reference-Guided Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingbo Zhang",
      "Xiaoyu Li",
      "Qi Zhang",
      "Yanpei Cao",
      "Ying Shan",
      "Jing Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Taesiri_GlitchBench_Can_Large_Multimodal_Models_Detect_Video_Game_Glitches_CVPR_2024_paper.html": {
    "title": "GlitchBench: Can Large Multimodal Models Detect Video Game Glitches?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Reza Taesiri",
      "Tianjun Feng",
      "Cor-Paul Bezemer",
      "Anh Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Rethinking_Interactive_Image_Segmentation_with_Low_Latency_High_Quality_and_CVPR_2024_paper.html": {
    "title": "Rethinking Interactive Image Segmentation with Low Latency High Quality and Diverse Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qin Liu",
      "Jaemin Cho",
      "Mohit Bansal",
      "Marc Niethammer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Norouzi_ALGM_Adaptive_Local-then-Global_Token_Merging_for_Efficient_Semantic_Segmentation_with_CVPR_2024_paper.html": {
    "title": "ALGM: Adaptive Local-then-Global Token Merging for Efficient Semantic Segmentation with Plain Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Narges Norouzi",
      "Svetlana Orlova",
      "Daan de Geus",
      "Gijs Dubbelman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shim_DITTO_Dual_and_Integrated_Latent_Topologies_for_Implicit_3D_Reconstruction_CVPR_2024_paper.html": {
    "title": "DITTO: Dual and Integrated Latent Topologies for Implicit 3D Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaehyeok Shim",
      "Kyungdon Joo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Single-Model_and_Any-Modality_for_Video_Object_Tracking_CVPR_2024_paper.html": {
    "title": "Single-Model and Any-Modality for Video Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongwei Wu",
      "Jilai Zheng",
      "Xiangxuan Ren",
      "Florin-Alexandru Vasluianu",
      "Chao Ma",
      "Danda Pani Paudel",
      "Luc Van Gool",
      "Radu Timofte"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cho_FlowTrack_Revisiting_Optical_Flow_for_Long-Range_Dense_Tracking_CVPR_2024_paper.html": {
    "title": "FlowTrack: Revisiting Optical Flow for Long-Range Dense Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seokju Cho",
      "Jiahui Huang",
      "Seungryong Kim",
      "Joon-Young Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Keller_HIT_Estimating_Internal_Human_Implicit_Tissues_from_the_Body_Surface_CVPR_2024_paper.html": {
    "title": "HIT: Estimating Internal Human Implicit Tissues from the Body Surface",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marilyn Keller",
      "Vaibhav Arora",
      "Abdelmouttaleb Dakri",
      "Shivam Chandhok",
      "Jürgen Machann",
      "Andreas Fritsche",
      "Michael J. Black",
      "Sergi Pujades"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_DanceCamera3D_3D_Camera_Movement_Synthesis_with_Music_and_Dance_CVPR_2024_paper.html": {
    "title": "DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Wang",
      "Jia Jia",
      "Shikun Sun",
      "Haozhe Wu",
      "Rong Han",
      "Zhenyu Li",
      "Di Tang",
      "Jiaqing Zhou",
      "Jiebo Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_Synthesize_Diagnose_and_Optimize_Towards_Fine-Grained_Vision-Language_Understanding_CVPR_2024_paper.html": {
    "title": "Synthesize Diagnose and Optimize: Towards Fine-Grained Vision-Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wujian Peng",
      "Sicheng Xie",
      "Zuyao You",
      "Shiyi Lan",
      "Zuxuan Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Density-guided_Translator_Boosts_Synthetic-to-Real_Unsupervised_Domain_Adaptive_Segmentation_of_3D_CVPR_2024_paper.html": {
    "title": "Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain Adaptive Segmentation of 3D Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhimin Yuan",
      "Wankang Zeng",
      "Yanfei Su",
      "Weiquan Liu",
      "Ming Cheng",
      "Yulan Guo",
      "Cheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pang_Cross_Initialization_for_Face_Personalization_of_Text-to-Image_Models_CVPR_2024_paper.html": {
    "title": "Cross Initialization for Face Personalization of Text-to-Image Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lianyu Pang",
      "Jian Yin",
      "Haoran Xie",
      "Qiping Wang",
      "Qing Li",
      "Xudong Mao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Brack_LEDITS_Limitless_Image_Editing_using_Text-to-Image_Models_CVPR_2024_paper.html": {
    "title": "LEDITS++: Limitless Image Editing using Text-to-Image Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manuel Brack",
      "Felix Friedrich",
      "Katharia Kornmeier",
      "Linoy Tsaban",
      "Patrick Schramowski",
      "Kristian Kersting",
      "Apolinario Passos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jain_Video_Interpolation_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Video Interpolation with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddhant Jain",
      "Daniel Watson",
      "Eric Tabellion",
      "Aleksander Ho?ynski",
      "Ben Poole",
      "Janne Kontkanen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kumar_WildlifeMapper_Aerial_Image_Analysis_for_Multi-Species_Detection_and_Identification_CVPR_2024_paper.html": {
    "title": "WildlifeMapper: Aerial Image Analysis for Multi-Species Detection and Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Satish Kumar",
      "Bowen Zhang",
      "Chandrakanth Gudavalli",
      "Connor Levenson",
      "Lacey Hughey",
      "Jared A. Stabach",
      "Irene Amoke",
      "Gordon Ojwang",
      "Joseph Mukeka",
      "Stephen Mwiu",
      "Joseph Ogutu",
      "Howard Frederick",
      "B.S. Manjunath"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Learning_Adaptive_Spatial_Coherent_Correlations_for_Speech-Preserving_Facial_Expression_Manipulation_CVPR_2024_paper.html": {
    "title": "Learning Adaptive Spatial Coherent Correlations for Speech-Preserving Facial Expression Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianshui Chen",
      "Jianman Lin",
      "Zhijing Yang",
      "Chunmei Qing",
      "Liang Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Tune-An-Ellipse_CLIP_Has_Potential_to_Find_What_You_Want_CVPR_2024_paper.html": {
    "title": "Tune-An-Ellipse: CLIP Has Potential to Find What You Want",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinheng Xie",
      "Songhe Deng",
      "Bing Li",
      "Haozhe Liu",
      "Yawen Huang",
      "Yefeng Zheng",
      "Jurgen Schmidhuber",
      "Bernard Ghanem",
      "Linlin Shen",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chugunov_Neural_Spline_Fields_for_Burst_Image_Fusion_and_Layer_Separation_CVPR_2024_paper.html": {
    "title": "Neural Spline Fields for Burst Image Fusion and Layer Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilya Chugunov",
      "David Shustin",
      "Ruyu Yan",
      "Chenyang Lei",
      "Felix Heide"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shin_WHAM_Reconstructing_World-grounded_Humans_with_Accurate_3D_Motion_CVPR_2024_paper.html": {
    "title": "WHAM: Reconstructing World-grounded Humans with Accurate 3D Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soyong Shin",
      "Juyong Kim",
      "Eni Halilaj",
      "Michael J. Black"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_NAPGuard_Towards_Detecting_Naturalistic_Adversarial_Patches_CVPR_2024_paper.html": {
    "title": "NAPGuard: Towards Detecting Naturalistic Adversarial Patches",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyang Wu",
      "Jiakai Wang",
      "Jiejie Zhao",
      "Yazhe Wang",
      "Xianglong Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_DiffPerformer_Iterative_Learning_of_Consistent_Latent_Guidance_for_Diffusion-based_Human_CVPR_2024_paper.html": {
    "title": "DiffPerformer: Iterative Learning of Consistent Latent Guidance for Diffusion-based Human Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyang Wang",
      "Zerong Zheng",
      "Tao Yu",
      "Xiaoqian Lv",
      "Bineng Zhong",
      "Shengping Zhang",
      "Liqiang Nie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Unified_Language-driven_Zero-shot_Domain_Adaptation_CVPR_2024_paper.html": {
    "title": "Unified Language-driven Zero-shot Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Senqiao Yang",
      "Zhuotao Tian",
      "Li Jiang",
      "Jiaya Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Category-Level_Multi-Part_Multi-Joint_3D_Shape_Assembly_CVPR_2024_paper.html": {
    "title": "Category-Level Multi-Part Multi-Joint 3D Shape Assembly",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Li",
      "Kaichun Mo",
      "Yueqi Duan",
      "He Wang",
      "Jiequan Zhang",
      "Lin Shao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Equivariant_Multi-Modality_Image_Fusion_CVPR_2024_paper.html": {
    "title": "Equivariant Multi-Modality Image Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixiang Zhao",
      "Haowen Bai",
      "Jiangshe Zhang",
      "Yulun Zhang",
      "Kai Zhang",
      "Shuang Xu",
      "Dongdong Chen",
      "Radu Timofte",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/You_NeLF-Pro_Neural_Light_Field_Probes_for_Multi-Scale_Novel_View_Synthesis_CVPR_2024_paper.html": {
    "title": "NeLF-Pro: Neural Light Field Probes for Multi-Scale Novel View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zinuo You",
      "Andreas Geiger",
      "Anpei Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_One-Shot_Open_Affordance_Learning_with_Foundation_Models_CVPR_2024_paper.html": {
    "title": "One-Shot Open Affordance Learning with Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gen Li",
      "Deqing Sun",
      "Laura Sevilla-Lara",
      "Varun Jampani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Dont_Look_into_the_Dark_Latent_Codes_for_Pluralistic_Image_CVPR_2024_paper.html": {
    "title": "Don't Look into the Dark: Latent Codes for Pluralistic Image Inpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiwei Chen",
      "Yajie Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Incremental_Nuclei_Segmentation_from_Histopathological_Images_via_Future-class_Awareness_and_CVPR_2024_paper.html": {
    "title": "Incremental Nuclei Segmentation from Histopathological Images via Future-class Awareness and Compatibility-inspired Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huyong Wang",
      "Huisi Wu",
      "Jing Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mou_DiffEditor_Boosting_Accuracy_and_Flexibility_on_Diffusion-based_Image_Editing_CVPR_2024_paper.html": {
    "title": "DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Mou",
      "Xintao Wang",
      "Jiechong Song",
      "Ying Shan",
      "Jian Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Solving_Masked_Jigsaw_Puzzles_with_Diffusion_Vision_Transformers_CVPR_2024_paper.html": {
    "title": "Solving Masked Jigsaw Puzzles with Diffusion Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyang Liu",
      "Wondmgezahu Teshome",
      "Sandesh Ghimire",
      "Mario Sznaier",
      "Octavia Camps"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_InstructVideo_Instructing_Video_Diffusion_Models_with_Human_Feedback_CVPR_2024_paper.html": {
    "title": "InstructVideo: Instructing Video Diffusion Models with Human Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hangjie Yuan",
      "Shiwei Zhang",
      "Xiang Wang",
      "Yujie Wei",
      "Tao Feng",
      "Yining Pan",
      "Yingya Zhang",
      "Ziwei Liu",
      "Samuel Albanie",
      "Dong Ni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Fully_Exploiting_Every_Real_Sample_SuperPixel_Sample_Gradient_Model_Stealing_CVPR_2024_paper.html": {
    "title": "Fully Exploiting Every Real Sample: SuperPixel Sample Gradient Model Stealing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunlong Zhao",
      "Xiaoheng Deng",
      "Yijing Liu",
      "Xinjun Pei",
      "Jiazhi Xia",
      "Wei Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Progressive_Divide-and-Conquer_via_Subsampling_Decomposition_for_Accelerated_MRI_CVPR_2024_paper.html": {
    "title": "Progressive Divide-and-Conquer via Subsampling Decomposition for Accelerated MRI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Wang",
      "Lanqing Guo",
      "Yufei Wang",
      "Hao Cheng",
      "Yi Yu",
      "Bihan Wen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lv_DiffMOT_A_Real-time_Diffusion-based_Multiple_Object_Tracker_with_Non-linear_Prediction_CVPR_2024_paper.html": {
    "title": "DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyi Lv",
      "Yuhang Huang",
      "Ning Zhang",
      "Ruei-Sung Lin",
      "Mei Han",
      "Dan Zeng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jin_MV-Adapter_Multimodal_Video_Transfer_Learning_for_Video_Text_Retrieval_CVPR_2024_paper.html": {
    "title": "MV-Adapter: Multimodal Video Transfer Learning for Video Text Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaojie Jin",
      "Bowen Zhang",
      "Weibo Gong",
      "Kai Xu",
      "Xueqing Deng",
      "Peng Wang",
      "Zhao Zhang",
      "Xiaohui Shen",
      "Jiashi Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ke_Rethinking_Multi-view_Representation_Learning_via_Distilled_Disentangling_CVPR_2024_paper.html": {
    "title": "Rethinking Multi-view Representation Learning via Distilled Disentangling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanzhou Ke",
      "Bo Wang",
      "Xiaoli Wang",
      "Shengfeng He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Reilly_Just_Add__Pose_Induced_Video_Transformers_for_Understanding_Activities_CVPR_2024_paper.html": {
    "title": "Just Add ?! Pose Induced Video Transformers for Understanding Activities of Daily Living",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dominick Reilly",
      "Srijan Das"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_ViLa-MIL_Dual-scale_Vision-Language_Multiple_Instance_Learning_for_Whole_Slide_Image_CVPR_2024_paper.html": {
    "title": "ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiangbo Shi",
      "Chen Li",
      "Tieliang Gong",
      "Yefeng Zheng",
      "Huazhu Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Targeted_Representation_Alignment_for_Open-World_Semi-Supervised_Learning_CVPR_2024_paper.html": {
    "title": "Targeted Representation Alignment for Open-World Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruixuan Xiao",
      "Lei Feng",
      "Kai Tang",
      "Junbo Zhao",
      "Yixuan Li",
      "Gang Chen",
      "Haobo Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hruby_Efficient_Solution_of_Point-Line_Absolute_Pose_CVPR_2024_paper.html": {
    "title": "Efficient Solution of Point-Line Absolute Pose",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Petr Hruby",
      "Timothy Duff",
      "Marc Pollefeys"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Text-to-3D_using_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "Text-to-3D using Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zilong Chen",
      "Feng Wang",
      "Yikai Wang",
      "Huaping Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_CapsFusion_Rethinking_Image-Text_Data_at_Scale_CVPR_2024_paper.html": {
    "title": "CapsFusion: Rethinking Image-Text Data at Scale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiying Yu",
      "Quan Sun",
      "Xiaosong Zhang",
      "Yufeng Cui",
      "Fan Zhang",
      "Yue Cao",
      "Xinlong Wang",
      "Jingjing Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ge_On_the_Content_Bias_in_Frechet_Video_Distance_CVPR_2024_paper.html": {
    "title": "On the Content Bias in Frechet Video Distance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Songwei Ge",
      "Aniruddha Mahapatra",
      "Gaurav Parmar",
      "Jun-Yan Zhu",
      "Jia-Bin Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shao_Tumor_Micro-environment_Interactions_Guided_Graph_Learning_for_Survival_Analysis_of_CVPR_2024_paper.html": {
    "title": "Tumor Micro-environment Interactions Guided Graph Learning for Survival Analysis of Human Cancers from Whole-slide Pathological Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Shao",
      "YangYang Shi",
      "Daoqiang Zhang",
      "JunJie Zhou",
      "Peng Wan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qin_Towards_Generalizable_Multi-Object_Tracking_CVPR_2024_paper.html": {
    "title": "Towards Generalizable Multi-Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Qin",
      "Le Wang",
      "Sanping Zhou",
      "Panpan Fu",
      "Gang Hua",
      "Wei Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_POPDG_Popular_3D_Dance_Generation_with_PopDanceSet_CVPR_2024_paper.html": {
    "title": "POPDG: Popular 3D Dance Generation with PopDanceSet",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenye Luo",
      "Min Ren",
      "Xuecai Hu",
      "Yongzhen Huang",
      "Li Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Image_Neural_Field_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Image Neural Field Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinbo Chen",
      "Oliver Wang",
      "Richard Zhang",
      "Eli Shechtman",
      "Xiaolong Wang",
      "Michael Gharbi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Discriminative Probing and Tuning for Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leigang Qu",
      "Wenjie Wang",
      "Yongqi Li",
      "Hanwang Zhang",
      "Liqiang Nie",
      "Tat-Seng Chua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Slice3D_Multi-Slice_Occlusion-Revealing_Single_View_3D_Reconstruction_CVPR_2024_paper.html": {
    "title": "Slice3D: Multi-Slice Occlusion-Revealing Single View 3D Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizhi Wang",
      "Wallace Lira",
      "Wenqi Wang",
      "Ali Mahdavi-Amiri",
      "Hao Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_Towards_More_Accurate_Diffusion_Model_Acceleration_with_A_Timestep_Tuner_CVPR_2024_paper.html": {
    "title": "Towards More Accurate Diffusion Model Acceleration with A Timestep Tuner",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengfei Xia",
      "Yujun Shen",
      "Changsong Lei",
      "Yu Zhou",
      "Deli Zhao",
      "Ran Yi",
      "Wenping Wang",
      "Yong-Jin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Rethinking_Generalizable_Face_Anti-spoofing_via_Hierarchical_Prototype-guided_Distribution_Refinement_in_CVPR_2024_paper.html": {
    "title": "Rethinking Generalizable Face Anti-spoofing via Hierarchical Prototype-guided Distribution Refinement in Hyperbolic Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyang Hu",
      "Ke-Yue Zhang",
      "Taiping Yao",
      "Shouhong Ding",
      "Lizhuang Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_IIRP-Net_Iterative_Inference_Residual_Pyramid_Network_for_Enhanced_Image_Registration_CVPR_2024_paper.html": {
    "title": "IIRP-Net: Iterative Inference Residual Pyramid Network for Enhanced Image Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tai Ma",
      "Suwei Zhang",
      "Jiafeng Li",
      "Ying Wen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Learning_without_Exact_Guidance_Updating_Large-scale_High-resolution_Land_Cover_Maps_CVPR_2024_paper.html": {
    "title": "Learning without Exact Guidance: Updating Large-scale High-resolution Land Cover Maps from Low-resolution Historical Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuohong Li",
      "Wei He",
      "Jiepan Li",
      "Fangxiao Lu",
      "Hongyan Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_GenesisTex_Adapting_Image_Denoising_Diffusion_to_Texture_Space_CVPR_2024_paper.html": {
    "title": "GenesisTex: Adapting Image Denoising Diffusion to Texture Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenjian Gao",
      "Boyan Jiang",
      "Xinghui Li",
      "Yingpeng Zhang",
      "Qian Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cho_TTA-EVF_Test-Time_Adaptation_for_Event-based_Video_Frame_Interpolation_via_Reliable_CVPR_2024_paper.html": {
    "title": "TTA-EVF: Test-Time Adaptation for Event-based Video Frame Interpolation via Reliable Pixel and Sample Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoonhee Cho",
      "Taewoo Kim",
      "Yuhwan Jeong",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Image-to-Image_Matching_via_Foundation_Models_A_New_Perspective_for_Open-Vocabulary_CVPR_2024_paper.html": {
    "title": "Image-to-Image Matching via Foundation Models: A New Perspective for Open-Vocabulary Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Wang",
      "Rui Sun",
      "Naisong Luo",
      "Yuwen Pan",
      "Tianzhu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_BigGait_Learning_Gait_Representation_You_Want_by_Large_Vision_Models_CVPR_2024_paper.html": {
    "title": "BigGait: Learning Gait Representation You Want by Large Vision Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dingqiang Ye",
      "Chao Fan",
      "Jingzhe Ma",
      "Xiaoming Liu",
      "Shiqi Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_BEVNeXt_Reviving_Dense_BEV_Frameworks_for_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenxin Li",
      "Shiyi Lan",
      "Jose M. Alvarez",
      "Zuxuan Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection_CVPR_2024_paper.html": {
    "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Qi",
      "Zehong Yan",
      "Wynne Hsu",
      "Mong Li Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saini_Beyond_Seen_Primitive_Concepts_and_Attribute-Object_Compositional_Learning_CVPR_2024_paper.html": {
    "title": "Beyond Seen Primitive Concepts and Attribute-Object Compositional Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nirat Saini",
      "Khoi Pham",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Unleashing_Network_Potentials_for_Semantic_Scene_Completion_CVPR_2024_paper.html": {
    "title": "Unleashing Network Potentials for Semantic Scene Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengyun Wang",
      "Qianru Sun",
      "Dong Zhang",
      "Jinhui Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Narasimhaswamy_HOIST-Former_Hand-held_Objects_Identification_Segmentation_and_Tracking_in_the_Wild_CVPR_2024_paper.html": {
    "title": "HOIST-Former: Hand-held Objects Identification Segmentation and Tracking in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Supreeth Narasimhaswamy",
      "Huy Anh Nguyen",
      "Lihan Huang",
      "Minh Hoai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sung_Contextrast_Contextual_Contrastive_Learning_for_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Contextrast: Contextual Contrastive Learning for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changki Sung",
      "Wanhee Kim",
      "Jungho An",
      "Wooju Lee",
      "Hyungtae Lim",
      "Hyun Myung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_Learning_Occupancy_for_Monocular_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "Learning Occupancy for Monocular 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Peng",
      "Junkai Xu",
      "Haoran Cheng",
      "Zheng Yang",
      "Xiaopei Wu",
      "Wei Qian",
      "Wenxiao Wang",
      "Boxi Wu",
      "Deng Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_LAA-Net_Localized_Artifact_Attention_Network_for_Quality-Agnostic_and_Generalizable_Deepfake_CVPR_2024_paper.html": {
    "title": "LAA-Net: Localized Artifact Attention Network for Quality-Agnostic and Generalizable Deepfake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dat Nguyen",
      "Nesryne Mejri",
      "Inder Pal Singh",
      "Polina Kuleshova",
      "Marcella Astrid",
      "Anis Kacem",
      "Enjie Ghorbel",
      "Djamila Aouada"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qu_LEAD_Learning_Decomposition_for_Source-free_Universal_Domain_Adaptation_CVPR_2024_paper.html": {
    "title": "LEAD: Learning Decomposition for Source-free Universal Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanqing Qu",
      "Tianpei Zou",
      "Lianghua He",
      "Florian Röhrbein",
      "Alois Knoll",
      "Guang Chen",
      "Changjun Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jin_AUEditNet_Dual-Branch_Facial_Action_Unit_Intensity_Manipulation_with_Implicit_Disentanglement_CVPR_2024_paper.html": {
    "title": "AUEditNet: Dual-Branch Facial Action Unit Intensity Manipulation with Implicit Disentanglement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiwei Jin",
      "Zhen Wang",
      "Lei Wang",
      "Peng Liu",
      "Ning Bi",
      "Truong Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tandon_BodyMAP_-_Jointly_Predicting_Body_Mesh_and_3D_Applied_Pressure_CVPR_2024_paper.html": {
    "title": "BodyMAP - Jointly Predicting Body Mesh and 3D Applied Pressure Map for People in Bed",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhishek Tandon",
      "Anujraaj Goyal",
      "Henry M. Clever",
      "Zackory Erickson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_OneLLM_One_Framework_to_Align_All_Modalities_with_Language_CVPR_2024_paper.html": {
    "title": "OneLLM: One Framework to Align All Modalities with Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Han",
      "Kaixiong Gong",
      "Yiyuan Zhang",
      "Jiaqi Wang",
      "Kaipeng Zhang",
      "Dahua Lin",
      "Yu Qiao",
      "Peng Gao",
      "Xiangyu Yue"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jing_PAD_Patch-Agnostic_Defense_against_Adversarial_Patch_Attacks_CVPR_2024_paper.html": {
    "title": "PAD: Patch-Agnostic Defense against Adversarial Patch Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lihua Jing",
      "Rui Wang",
      "Wenqi Ren",
      "Xin Dong",
      "Cong Zou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tudosiu_MULAN_A_Multi_Layer_Annotated_Dataset_for_Controllable_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "MULAN: A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Petru-Daniel Tudosiu",
      "Yongxin Yang",
      "Shifeng Zhang",
      "Fei Chen",
      "Steven McDonagh",
      "Gerasimos Lampouras",
      "Ignacio Iacobacci",
      "Sarah Parisot"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Alfasly_Rotation-Agnostic_Image_Representation_Learning_for_Digital_Pathology_CVPR_2024_paper.html": {
    "title": "Rotation-Agnostic Image Representation Learning for Digital Pathology",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saghir Alfasly",
      "Abubakr Shafique",
      "Peyman Nejat",
      "Jibran Khan",
      "Areej Alsaafin",
      "Ghazal Alabtah",
      "H.R. Tizhoosh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Unbiased_Faster_R-CNN_for_Single-source_Domain_Generalized_Object_Detection_CVPR_2024_paper.html": {
    "title": "Unbiased Faster R-CNN for Single-source Domain Generalized Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yajing Liu",
      "Shijun Zhou",
      "Xiyao Liu",
      "Chunhui Hao",
      "Baojie Fan",
      "Jiandong Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_Super-Resolution_Reconstruction_from_Bayer-Pattern_Spike_Streams_CVPR_2024_paper.html": {
    "title": "Super-Resolution Reconstruction from Bayer-Pattern Spike Streams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanchen Dong",
      "Ruiqin Xiong",
      "Jian Zhang",
      "Zhaofei Yu",
      "Xiaopeng Fan",
      "Shuyuan Zhu",
      "Tiejun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_EASE-DETR_Easing_the_Competition_among_Object_Queries_CVPR_2024_paper.html": {
    "title": "EASE-DETR: Easing the Competition among Object Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yulu Gao",
      "Yifan Sun",
      "Xudong Ding",
      "Chuyang Zhao",
      "Si Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Thomas_KPConvX_Modernizing_Kernel_Point_Convolution_with_Kernel_Attention_CVPR_2024_paper.html": {
    "title": "KPConvX: Modernizing Kernel Point Convolution with Kernel Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hugues Thomas",
      "Yao-Hung Hubert Tsai",
      "Timothy D. Barfoot",
      "Jian Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Habibian_Clockwork_Diffusion_Efficient_Generation_With_Model-Step_Distillation_CVPR_2024_paper.html": {
    "title": "Clockwork Diffusion: Efficient Generation With Model-Step Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirhossein Habibian",
      "Amir Ghodrati",
      "Noor Fathima",
      "Guillaume Sautiere",
      "Risheek Garrepalli",
      "Fatih Porikli",
      "Jens Petersen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kumar_Pick-or-Mix_Dynamic_Channel_Sampling_for_ConvNets_CVPR_2024_paper.html": {
    "title": "Pick-or-Mix: Dynamic Channel Sampling for ConvNets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashish Kumar",
      "Daneul Kim",
      "Jaesik Park",
      "Laxmidhar Behera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Self-Discovering_Interpretable_Diffusion_Latent_Directions_for_Responsible_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Li",
      "Chengzhi Shen",
      "Philip Torr",
      "Volker Tresp",
      "Jindong Gu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_HiLo_Detailed_and_Robust_3D_Clothed_Human_Reconstruction_with_High-and_CVPR_2024_paper.html": {
    "title": "HiLo: Detailed and Robust 3D Clothed Human Reconstruction with High-and Low-Frequency Information of Parametric Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Yang",
      "Dong Liu",
      "Shuhai Zhang",
      "Zeshuai Deng",
      "Zixiong Huang",
      "Mingkui Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hwang_Promptable_Behaviors_Personalizing_Multi-Objective_Rewards_from_Human_Preferences_CVPR_2024_paper.html": {
    "title": "Promptable Behaviors: Personalizing Multi-Objective Rewards from Human Preferences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minyoung Hwang",
      "Luca Weihs",
      "Chanwoo Park",
      "Kimin Lee",
      "Aniruddha Kembhavi",
      "Kiana Ehsani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Biondi_Stationary_Representations_Optimally_Approximating_Compatibility_and_Implications_for_Improved_Model_CVPR_2024_paper.html": {
    "title": "Stationary Representations: Optimally Approximating Compatibility and Implications for Improved Model Replacements",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niccolò Biondi",
      "Federico Pernici",
      "Simone Ricci",
      "Alberto Del Bimbo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Towards_Calibrated_Multi-label_Deep_Neural_Networks_CVPR_2024_paper.html": {
    "title": "Towards Calibrated Multi-label Deep Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiacheng Cheng",
      "Nuno Vasconcelos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SceneTex_High-Quality_Texture_Synthesis_for_Indoor_Scenes_via_Diffusion_Priors_CVPR_2024_paper.html": {
    "title": "SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dave Zhenyu Chen",
      "Haoxuan Li",
      "Hsin-Ying Lee",
      "Sergey Tulyakov",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Neural_Underwater_Scene_Representation_CVPR_2024_paper.html": {
    "title": "Neural Underwater Scene Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunkai Tang",
      "Chengxuan Zhu",
      "Renjie Wan",
      "Chao Xu",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_Progress-Aware_Online_Action_Segmentation_for_Egocentric_Procedural_Task_Videos_CVPR_2024_paper.html": {
    "title": "Progress-Aware Online Action Segmentation for Egocentric Procedural Task Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Shen",
      "Ehsan Elhamifar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zimmer_TUMTraf_V2X_Cooperative_Perception_Dataset_CVPR_2024_paper.html": {
    "title": "TUMTraf V2X Cooperative Perception Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Walter Zimmer",
      "Gerhard Arya Wardana",
      "Suren Sritharan",
      "Xingcheng Zhou",
      "Rui Song",
      "Alois C. Knoll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dupty_Constrained_Layout_Generation_with_Factor_Graphs_CVPR_2024_paper.html": {
    "title": "Constrained Layout Generation with Factor Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Haroon Dupty",
      "Yanfei Dong",
      "Sicong Leng",
      "Guoji Fu",
      "Yong Liang Goh",
      "Wei Lu",
      "Wee Sun Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bora_SLICE_Stabilized_LIME_for_Consistent_Explanations_for_Image_Classification_CVPR_2024_paper.html": {
    "title": "SLICE: Stabilized LIME for Consistent Explanations for Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Revoti Prasad Bora",
      "Philipp Terhörst",
      "Raymond Veldhuis",
      "Raghavendra Ramachandra",
      "Kiran Raja"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Anomaly_Heterogeneity_Learning_for_Open-set_Supervised_Anomaly_Detection_CVPR_2024_paper.html": {
    "title": "Anomaly Heterogeneity Learning for Open-set Supervised Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawen Zhu",
      "Choubo Ding",
      "Yu Tian",
      "Guansong Pang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yao_SPECAT_SPatial-spEctral_Cumulative-Attention_Transformer_for_High-Resolution_Hyperspectral_Image_Reconstruction_CVPR_2024_paper.html": {
    "title": "SPECAT: SPatial-spEctral Cumulative-Attention Transformer for High-Resolution Hyperspectral Image Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyang Yao",
      "Shuyang Liu",
      "Xiaoyun Yuan",
      "Lu Fang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Attentive_Illumination_Decomposition_Model_for_Multi-Illuminant_White_Balancing_CVPR_2024_paper.html": {
    "title": "Attentive Illumination Decomposition Model for Multi-Illuminant White Balancing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyoung Kim",
      "Jinwoo Kim",
      "Junsang Yu",
      "Seon Joo Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Efficient_Stitchable_Task_Adaptation_CVPR_2024_paper.html": {
    "title": "Efficient Stitchable Task Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu He",
      "Zizheng Pan",
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tian_Image_Processing_GNN_Breaking_Rigidity_in_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Image Processing GNN: Breaking Rigidity in Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchuan Tian",
      "Hanting Chen",
      "Chao Xu",
      "Yunhe Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Revisiting_Counterfactual_Problems_in_Referring_Expression_Comprehension_CVPR_2024_paper.html": {
    "title": "Revisiting Counterfactual Problems in Referring Expression Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihan Yu",
      "Ruifan Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_DyBluRF_Dynamic_Neural_Radiance_Fields_from_Blurry_Monocular_Video_CVPR_2024_paper.html": {
    "title": "DyBluRF: Dynamic Neural Radiance Fields from Blurry Monocular Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huiqiang Sun",
      "Xingyi Li",
      "Liao Shen",
      "Xinyi Ye",
      "Ke Xian",
      "Zhiguo Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Niedermayr_Compressed_3D_Gaussian_Splatting_for_Accelerated_Novel_View_Synthesis_CVPR_2024_paper.html": {
    "title": "Compressed 3D Gaussian Splatting for Accelerated Novel View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Niedermayr",
      "Josef Stumpfegger",
      "Rüdiger Westermann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hamilton_Separating_the_Chirp_from_the_Chat_Self-supervised_Visual_Grounding_of_CVPR_2024_paper.html": {
    "title": "Separating the \"Chirp\" from the \"Chat\": Self-supervised Visual Grounding of Sound and Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mark Hamilton",
      "Andrew Zisserman",
      "John R. Hershey",
      "William T. Freeman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Galappaththige_Towards_Generalizing_to_Unseen_Domains_with_Few_Labels_CVPR_2024_paper.html": {
    "title": "Towards Generalizing to Unseen Domains with Few Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chamuditha Jayanga Galappaththige",
      "Sanoojan Baliah",
      "Malitha Gunawardhana",
      "Muhammad Haris Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_MA-LMM_Memory-Augmented_Large_Multimodal_Model_for_Long-Term_Video_Understanding_CVPR_2024_paper.html": {
    "title": "MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo He",
      "Hengduo Li",
      "Young Kyun Jang",
      "Menglin Jia",
      "Xuefei Cao",
      "Ashish Shah",
      "Abhinav Shrivastava",
      "Ser-Nam Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_AAMDM_Accelerated_Auto-regressive_Motion_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "AAMDM: Accelerated Auto-regressive Motion Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Li",
      "Calvin Qiao",
      "Guanqiao Ren",
      "KangKang Yin",
      "Sehoon Ha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Towards_Understanding_Cross_and_Self-Attention_in_Stable_Diffusion_for_Text-Guided_CVPR_2024_paper.html": {
    "title": "Towards Understanding Cross and Self-Attention in Stable Diffusion for Text-Guided Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingyan Liu",
      "Chengyu Wang",
      "Tingfeng Cao",
      "Kui Jia",
      "Jun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Dr2Net_Dynamic_Reversible_Dual-Residual_Networks_for_Memory-Efficient_Finetuning_CVPR_2024_paper.html": {
    "title": "Dr2Net: Dynamic Reversible Dual-Residual Networks for Memory-Efficient Finetuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhao",
      "Shuming Liu",
      "Karttikeya Mangalam",
      "Guocheng Qian",
      "Fatimah Zohra",
      "Abdulmohsen Alghannam",
      "Jitendra Malik",
      "Bernard Ghanem"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_PNeRV_Enhancing_Spatial_Consistency_via_Pyramidal_Neural_Representation_for_Videos_CVPR_2024_paper.html": {
    "title": "PNeRV: Enhancing Spatial Consistency via Pyramidal Neural Representation for Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Zhao",
      "M. Salman Asif",
      "Zhan Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_LTGC_Long-tail_Recognition_via_Leveraging_LLMs-driven_Generated_Content_CVPR_2024_paper.html": {
    "title": "LTGC: Long-tail Recognition via Leveraging LLMs-driven Generated Content",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihao Zhao",
      "Yalun Dai",
      "Hao Li",
      "Wei Hu",
      "Fan Zhang",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_DiverGen_Improving_Instance_Segmentation_by_Learning_Wider_Data_Distribution_with_CVPR_2024_paper.html": {
    "title": "DiverGen: Improving Instance Segmentation by Learning Wider Data Distribution with More Diverse Generative Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengxiang Fan",
      "Muzhi Zhu",
      "Hao Chen",
      "Yang Liu",
      "Weijia Wu",
      "Huaqi Zhang",
      "Chunhua Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Neural_Refinement_for_Absolute_Pose_Regression_with_Feature_Synthesis_CVPR_2024_paper.html": {
    "title": "Neural Refinement for Absolute Pose Regression with Feature Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Chen",
      "Yash Bhalgat",
      "Xinghui Li",
      "Jia-Wang Bian",
      "Kejie Li",
      "Zirui Wang",
      "Victor Adrian Prisacariu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Learning_Disentangled_Identifiers_for_Action-Customized_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Learning Disentangled Identifiers for Action-Customized Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siteng Huang",
      "Biao Gong",
      "Yutong Feng",
      "Xi Chen",
      "Yuqian Fu",
      "Yu Liu",
      "Donglin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cong_Automatic_Controllable_Colorization_via_Imagination_CVPR_2024_paper.html": {
    "title": "Automatic Controllable Colorization via Imagination",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyan Cong",
      "Yue Wu",
      "Qifeng Chen",
      "Chenyang Lei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Point_Transformer_V3_Simpler_Faster_Stronger_CVPR_2024_paper.html": {
    "title": "Point Transformer V3: Simpler Faster Stronger",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Wu",
      "Li Jiang",
      "Peng-Shuai Wang",
      "Zhijian Liu",
      "Xihui Liu",
      "Yu Qiao",
      "Wanli Ouyang",
      "Tong He",
      "Hengshuang Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_DiffCast_A_Unified_Framework_via_Residual_Diffusion_for_Precipitation_Nowcasting_CVPR_2024_paper.html": {
    "title": "DiffCast: A Unified Framework via Residual Diffusion for Precipitation Nowcasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Demin Yu",
      "Xutao Li",
      "Yunming Ye",
      "Baoquan Zhang",
      "Chuyao Luo",
      "Kuai Dai",
      "Rui Wang",
      "Xunlai Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Grauman_Ego-Exo4D_Understanding_Skilled_Human_Activity_from_First-_and_Third-Person_Perspectives_CVPR_2024_paper.html": {
    "title": "Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kristen Grauman",
      "Andrew Westbury",
      "Lorenzo Torresani",
      "Kris Kitani",
      "Jitendra Malik",
      "Triantafyllos Afouras",
      "Kumar Ashutosh",
      "Vijay Baiyya",
      "Siddhant Bansal",
      "Bikram Boote",
      "Eugene Byrne",
      "Zach Chavis",
      "Joya Chen",
      "Feng Cheng",
      "Fu-Jen Chu",
      "Sean Crane",
      "Avijit Dasgupta",
      "Jing Dong",
      "Maria Escobar",
      "Cristhian Forigua",
      "Abrham Gebreselasie",
      "Sanjay Haresh",
      "Jing Huang",
      "Md Mohaiminul Islam",
      "Suyog Jain",
      "Rawal Khirodkar",
      "Devansh Kukreja",
      "Kevin J Liang",
      "Jia-Wei Liu",
      "Sagnik Majumder",
      "Yongsen Mao",
      "Miguel Martin",
      "Effrosyni Mavroudi",
      "Tushar Nagarajan",
      "Francesco Ragusa",
      "Santhosh Kumar Ramakrishnan",
      "Luigi Seminara",
      "Arjun Somayazulu",
      "Yale Song",
      "Shan Su",
      "Zihui Xue",
      "Edward Zhang",
      "Jinxu Zhang",
      "Angela Castillo",
      "Changan Chen",
      "Xinzhu Fu",
      "Ryosuke Furuta",
      "Cristina Gonzalez",
      "Prince Gupta",
      "Jiabo Hu",
      "Yifei Huang",
      "Yiming Huang",
      "Weslie Khoo",
      "Anush Kumar",
      "Robert Kuo",
      "Sach Lakhavani",
      "Miao Liu",
      "Mi Luo",
      "Zhengyi Luo",
      "Brighid Meredith",
      "Austin Miller",
      "Oluwatumininu Oguntola",
      "Xiaqing Pan",
      "Penny Peng",
      "Shraman Pramanick",
      "Merey Ramazanova",
      "Fiona Ryan",
      "Wei Shan",
      "Kiran Somasundaram",
      "Chenan Song",
      "Audrey Southerland",
      "Masatoshi Tateno",
      "Huiyu Wang",
      "Yuchen Wang",
      "Takuma Yagi",
      "Mingfei Yan",
      "Xitong Yang",
      "Zecheng Yu",
      "Shengxin Cindy Zha",
      "Chen Zhao",
      "Ziwei Zhao",
      "Zhifan Zhu",
      "Jeff Zhuo",
      "Pablo Arbelaez",
      "Gedas Bertasius",
      "Dima Damen",
      "Jakob Engel",
      "Giovanni Maria Farinella",
      "Antonino Furnari",
      "Bernard Ghanem",
      "Judy Hoffman",
      "C.V. Jawahar",
      "Richard Newcombe",
      "Hyun Soo Park",
      "James M. Rehg",
      "Yoichi Sato",
      "Manolis Savva",
      "Jianbo Shi",
      "Mike Zheng Shou",
      "Michael Wray"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Point_Cloud_Pre-training_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Point Cloud Pre-training with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Zheng",
      "Xiaoshui Huang",
      "Guofeng Mei",
      "Yuenan Hou",
      "Zhaoyang Lyu",
      "Bo Dai",
      "Wanli Ouyang",
      "Yongshun Gong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Mask4Align_Aligned_Entity_Prompting_with_Color_Masks_for_Multi-Entity_Localization_CVPR_2024_paper.html": {
    "title": "Mask4Align: Aligned Entity Prompting with Color Masks for Multi-Entity Localization Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoquan Zhang",
      "Ronggang Huang",
      "Yi Xie",
      "Huaidong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_RCL_Reliable_Continual_Learning_for_Unified_Failure_Detection_CVPR_2024_paper.html": {
    "title": "RCL: Reliable Continual Learning for Unified Failure Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Zhu",
      "Zhen Cheng",
      "Xu-Yao Zhang",
      "Cheng-Lin Liu",
      "Zhaoxiang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Referring_Image_Editing_Object-level_Image_Editing_via_Referring_Expressions_CVPR_2024_paper.html": {
    "title": "Referring Image Editing: Object-level Image Editing via Referring Expressions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chang Liu",
      "Xiangtai Li",
      "Henghui Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_CAMixerSR_Only_Details_Need_More_Attention_CVPR_2024_paper.html": {
    "title": "CAMixerSR: Only Details Need More \"Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Wang",
      "Yi Liu",
      "Shijie Zhao",
      "Junlin Li",
      "Li Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Duan_Towards_Backward-Compatible_Continual_Learning_of_Image_Compression_CVPR_2024_paper.html": {
    "title": "Towards Backward-Compatible Continual Learning of Image Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Duan",
      "Ming Lu",
      "Justin Yang",
      "Jiangpeng He",
      "Zhan Ma",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Latent_Modulated_Function_for_Computational_Optimal_Continuous_Image_Representation_CVPR_2024_paper.html": {
    "title": "Latent Modulated Function for Computational Optimal Continuous Image Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongyao He",
      "Zhi Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Reddy_Unsupervised_Video_Domain_Adaptation_with_Masked_Pre-Training_and_Collaborative_Self-Training_CVPR_2024_paper.html": {
    "title": "Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arun Reddy",
      "William Paul",
      "Corban Rivera",
      "Ketul Shah",
      "Celso M. de Melo",
      "Rama Chellappa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Piccinelli_UniDepth_Universal_Monocular_Metric_Depth_Estimation_CVPR_2024_paper.html": {
    "title": "UniDepth: Universal Monocular Metric Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luigi Piccinelli",
      "Yung-Hsu Yang",
      "Christos Sakaridis",
      "Mattia Segu",
      "Siyuan Li",
      "Luc Van Gool",
      "Fisher Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Drobyshev_EMOPortraits_Emotion-enhanced_Multimodal_One-shot_Head_Avatars_CVPR_2024_paper.html": {
    "title": "EMOPortraits: Emotion-enhanced Multimodal One-shot Head Avatars",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Drobyshev",
      "Antoni Bigata Casademunt",
      "Konstantinos Vougioukas",
      "Zoe Landgraf",
      "Stavros Petridis",
      "Maja Pantic"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tonderski_NeuRAD_Neural_Rendering_for_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "NeuRAD: Neural Rendering for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adam Tonderski",
      "Carl Lindström",
      "Georg Hess",
      "William Ljungbergh",
      "Lennart Svensson",
      "Christoffer Petersson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_VideoCutLER_Surprisingly_Simple_Unsupervised_Video_Instance_Segmentation_CVPR_2024_paper.html": {
    "title": "VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xudong Wang",
      "Ishan Misra",
      "Ziyun Zeng",
      "Rohit Girdhar",
      "Trevor Darrell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Bootstrapping_Chest_CT_Image_Understanding_by_Distilling_Knowledge_from_X-ray_CVPR_2024_paper.html": {
    "title": "Bootstrapping Chest CT Image Understanding by Distilling Knowledge from X-ray Expert Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiwei Cao",
      "Jianpeng Zhang",
      "Yingda Xia",
      "Tony C. W. Mok",
      "Zi Li",
      "Xianghua Ye",
      "Le Lu",
      "Jian Zheng",
      "Yuxing Tang",
      "Ling Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Magic_Tokens_Select_Diverse_Tokens_for_Multi-modal_Object_Re-Identification_CVPR_2024_paper.html": {
    "title": "Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pingping Zhang",
      "Yuhao Wang",
      "Yang Liu",
      "Zhengzheng Tu",
      "Huchuan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_Open3DIS_Open-Vocabulary_3D_Instance_Segmentation_with_2D_Mask_Guidance_CVPR_2024_paper.html": {
    "title": "Open3DIS: Open-Vocabulary 3D Instance Segmentation with 2D Mask Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phuc Nguyen",
      "Tuan Duc Ngo",
      "Evangelos Kalogerakis",
      "Chuang Gan",
      "Anh Tran",
      "Cuong Pham",
      "Khoi Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gan_SignGraph_A_Sign_Sequence_is_Worth_Graphs_of_Nodes_CVPR_2024_paper.html": {
    "title": "SignGraph: A Sign Sequence is Worth Graphs of Nodes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiwei Gan",
      "Yafeng Yin",
      "Zhiwei Jiang",
      "Hongkai Wen",
      "Lei Xie",
      "Sanglu Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Schult_ControlRoom3D_Room_Generation_using_Semantic_Proxy_Rooms_CVPR_2024_paper.html": {
    "title": "ControlRoom3D: Room Generation using Semantic Proxy Rooms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas Schult",
      "Sam Tsai",
      "Lukas Höllein",
      "Bichen Wu",
      "Jialiang Wang",
      "Chih-Yao Ma",
      "Kunpeng Li",
      "Xiaofang Wang",
      "Felix Wimbauer",
      "Zijian He",
      "Peizhao Zhang",
      "Bastian Leibe",
      "Peter Vajda",
      "Ji Hou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_DeconfuseTrack_Dealing_with_Confusion_for_Multi-Object_Tracking_CVPR_2024_paper.html": {
    "title": "DeconfuseTrack: Dealing with Confusion for Multi-Object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Huang",
      "Shoudong Han",
      "Mengyu He",
      "Wenbo Zheng",
      "Yuhao Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_PAPR_in_Motion_Seamless_Point-level_3D_Scene_Interpolation_CVPR_2024_paper.html": {
    "title": "PAPR in Motion: Seamless Point-level 3D Scene Interpolation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shichong Peng",
      "Yanshu Zhang",
      "Ke Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Causal_Mode_Multiplexer_A_Novel_Framework_for_Unbiased_Multispectral_Pedestrian_CVPR_2024_paper.html": {
    "title": "Causal Mode Multiplexer: A Novel Framework for Unbiased Multispectral Pedestrian Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeheon Kim",
      "Sebin Shin",
      "Youngjoon Yu",
      "Hak Gu Kim",
      "Yong Man Ro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_HIMap_HybrId_Representation_Learning_for_End-to-end_Vectorized_HD_Map_Construction_CVPR_2024_paper.html": {
    "title": "HIMap: HybrId Representation Learning for End-to-end Vectorized HD Map Construction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Zhou",
      "Hui Zhang",
      "Jiaqian Yu",
      "Yifan Yang",
      "Sangil Jung",
      "Seung-In Park",
      "ByungIn Yoo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_LTA-PCS_Learnable_Task-Agnostic_Point_Cloud_Sampling_CVPR_2024_paper.html": {
    "title": "LTA-PCS: Learnable Task-Agnostic Point Cloud Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaheng Liu",
      "Jianhao Li",
      "Kaisiyuan Wang",
      "Hongcheng Guo",
      "Jian Yang",
      "Junran Peng",
      "Ke Xu",
      "Xianglong Liu",
      "Jinyang Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_Non-Rigid_Structure-from-Motion_Temporally-Smooth_Procrustean_Alignment_and_Spatially-Variant_Deformation_Modeling_CVPR_2024_paper.html": {
    "title": "Non-Rigid Structure-from-Motion: Temporally-Smooth Procrustean Alignment and Spatially-Variant Deformation Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Shi",
      "Hui Deng",
      "Yuchao Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Di_ShapeMatcher_Self-Supervised_Joint_Shape_Canonicalization_Segmentation_Retrieval_and_Deformation_CVPR_2024_paper.html": {
    "title": "ShapeMatcher: Self-Supervised Joint Shape Canonicalization Segmentation Retrieval and Deformation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Di",
      "Chenyangguang Zhang",
      "Chaowei Wang",
      "Ruida Zhang",
      "Guangyao Zhai",
      "Yanyan Li",
      "Bowen Fu",
      "Xiangyang Ji",
      "Shan Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_UniPTS_A_Unified_Framework_for_Proficient_Post-Training_Sparsity_CVPR_2024_paper.html": {
    "title": "UniPTS: A Unified Framework for Proficient Post-Training Sparsity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingjing Xie",
      "Yuxin Zhang",
      "Mingbao Lin",
      "Liujuan Cao",
      "Rongrong Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_HumanNorm_Learning_Normal_Diffusion_Model_for_High-quality_and_Realistic_3D_CVPR_2024_paper.html": {
    "title": "HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Huang",
      "Ruizhi Shao",
      "Qi Zhang",
      "Hongwen Zhang",
      "Ying Feng",
      "Yebin Liu",
      "Qing Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Unleashing_Unlabeled_Data_A_Paradigm_for_Cross-View_Geo-Localization_CVPR_2024_paper.html": {
    "title": "Unleashing Unlabeled Data: A Paradigm for Cross-View Geo-Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guopeng Li",
      "Ming Qian",
      "Gui-Song Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tanay_Global_Latent_Neural_Rendering_CVPR_2024_paper.html": {
    "title": "Global Latent Neural Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Tanay",
      "Matteo Maggioni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_PanoOcc_Unified_Occupancy_Representation_for_Camera-based_3D_Panoptic_Segmentation_CVPR_2024_paper.html": {
    "title": "PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqi Wang",
      "Yuntao Chen",
      "Xingyu Liao",
      "Lue Fan",
      "Zhaoxiang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Brahimi_Sparse_Views_Near_Light_A_Practical_Paradigm_for_Uncalibrated_Point-light_CVPR_2024_paper.html": {
    "title": "Sparse Views Near Light: A Practical Paradigm for Uncalibrated Point-light Photometric Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Brahimi",
      "Bjoern Haefner",
      "Zhenzhang Ye",
      "Bastian Goldluecke",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Meta-Point_Learning_and_Refining_for_Category-Agnostic_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "Meta-Point Learning and Refining for Category-Agnostic Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Chen",
      "Jiebin Yan",
      "Yuming Fang",
      "Li Niu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Armando_Cross-view_and_Cross-pose_Completion_for_3D_Human_Understanding_CVPR_2024_paper.html": {
    "title": "Cross-view and Cross-pose Completion for 3D Human Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthieu Armando",
      "Salma Galaaoui",
      "Fabien Baradel",
      "Thomas Lucas",
      "Vincent Leroy",
      "Romain Brégier",
      "Philippe Weinzaepfel",
      "Grégory Rogez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Batch_Normalization_Alleviates_the_Spectral_Bias_in_Coordinate_Networks_CVPR_2024_paper.html": {
    "title": "Batch Normalization Alleviates the Spectral Bias in Coordinate Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicheng Cai",
      "Hao Zhu",
      "Qiu Shen",
      "Xinran Wang",
      "Xun Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Efficient_Scene_Recovery_Using_Luminous_Flux_Prior_CVPR_2024_paper.html": {
    "title": "Efficient Scene Recovery Using Luminous Flux Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongyu Li",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shah_LQMFormer_Language-aware_Query_Mask_Transformer_for_Referring_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "LQMFormer: Language-aware Query Mask Transformer for Referring Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nisarg A. Shah",
      "Vibashan VS",
      "Vishal M. Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Customize_your_NeRF_Adaptive_Source_Driven_3D_Scene_Editing_via_CVPR_2024_paper.html": {
    "title": "Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runze He",
      "Shaofei Huang",
      "Xuecheng Nie",
      "Tianrui Hui",
      "Luoqi Liu",
      "Jiao Dai",
      "Jizhong Han",
      "Guanbin Li",
      "Si Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Keetha_SplaTAM_Splat_Track__Map_3D_Gaussians_for_Dense_RGB-D_CVPR_2024_paper.html": {
    "title": "SplaTAM: Splat Track & Map 3D Gaussians for Dense RGB-D SLAM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikhil Keetha",
      "Jay Karhade",
      "Krishna Murthy Jatavallabhula",
      "Gengshan Yang",
      "Sebastian Scherer",
      "Deva Ramanan",
      "Jonathon Luiten"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Instance-based_Max-margin_for_Practical_Few-shot_Recognition_CVPR_2024_paper.html": {
    "title": "Instance-based Max-margin for Practical Few-shot Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghao Fu",
      "Ke Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shin_Spherical_Mask_Coarse-to-Fine_3D_Point_Cloud_Instance_Segmentation_with_Spherical_CVPR_2024_paper.html": {
    "title": "Spherical Mask: Coarse-to-Fine 3D Point Cloud Instance Segmentation with Spherical Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangyun Shin",
      "Kaichen Zhou",
      "Madhu Vankadari",
      "Andrew Markham",
      "Niki Trigoni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Omni-Q_Omni-Directional_Scene_Understanding_for_Unsupervised_Visual_Grounding_CVPR_2024_paper.html": {
    "title": "Omni-Q: Omni-Directional Scene Understanding for Unsupervised Visual Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Wang",
      "Yutian Lin",
      "Yu Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_VISTA-LLAMA_Reducing_Hallucination_in_Video_Language_Models_via_Equal_Distance_CVPR_2024_paper.html": {
    "title": "VISTA-LLAMA: Reducing Hallucination in Video Language Models via Equal Distance to Visual Tokens",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Ma",
      "Xiaojie Jin",
      "Heng Wang",
      "Yuchen Xian",
      "Jiashi Feng",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rochow_FSRT_Facial_Scene_Representation_Transformer_for_Face_Reenactment_from_Factorized_CVPR_2024_paper.html": {
    "title": "FSRT: Facial Scene Representation Transformer for Face Reenactment from Factorized Appearance Head-pose and Facial Expression Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andre Rochow",
      "Max Schwarz",
      "Sven Behnke"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shang_Efficient_Multitask_Dense_Predictor_via_Binarization_CVPR_2024_paper.html": {
    "title": "Efficient Multitask Dense Predictor via Binarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhang Shang",
      "Dan Xu",
      "Gaowen Liu",
      "Ramana Rao Kompella",
      "Yan Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Melnyk_TetraSphere_A_Neural_Descriptor_for_O3-Invariant_Point_Cloud_Analysis_CVPR_2024_paper.html": {
    "title": "TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pavlo Melnyk",
      "Andreas Robinson",
      "Michael Felsberg",
      "Mårten Wadenbäck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_ZeroRF_Fast_Sparse_View_360deg_Reconstruction_with_Zero_Pretraining_CVPR_2024_paper.html": {
    "title": "ZeroRF: Fast Sparse View 360deg Reconstruction with Zero Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoxi Shi",
      "Xinyue Wei",
      "Cheng Wang",
      "Hao Su"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hao_RCooper_A_Real-world_Large-scale_Dataset_for_Roadside_Cooperative_Perception_CVPR_2024_paper.html": {
    "title": "RCooper: A Real-world Large-scale Dataset for Roadside Cooperative Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiyang Hao",
      "Siqi Fan",
      "Yingru Dai",
      "Zhenlin Zhang",
      "Chenxi Li",
      "Yuntian Wang",
      "Haibao Yu",
      "Wenxian Yang",
      "Jirui Yuan",
      "Zaiqing Nie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_TutteNet_Injective_3D_Deformations_by_Composition_of_2D_Mesh_Deformations_CVPR_2024_paper.html": {
    "title": "TutteNet: Injective 3D Deformations by Composition of 2D Mesh Deformations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Sun",
      "Thibault Groueix",
      "Chen Song",
      "Qixing Huang",
      "Noam Aigerman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Diomataris_WANDR_Intention-guided_Human_Motion_Generation_CVPR_2024_paper.html": {
    "title": "WANDR: Intention-guided Human Motion Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Markos Diomataris",
      "Nikos Athanasiou",
      "Omid Taheri",
      "Xi Wang",
      "Otmar Hilliges",
      "Michael J. Black"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ganjdanesh_Jointly_Training_and_Pruning_CNNs_via_Learnable_Agent_Guidance_and_CVPR_2024_paper.html": {
    "title": "Jointly Training and Pruning CNNs via Learnable Agent Guidance and Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alireza Ganjdanesh",
      "Shangqian Gao",
      "Heng Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Estimating_Noisy_Class_Posterior_with_Part-level_Labels_for_Noisy_Label_CVPR_2024_paper.html": {
    "title": "Estimating Noisy Class Posterior with Part-level Labels for Noisy Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Zhao",
      "Bin Shi",
      "Jianfei Ruan",
      "Tianze Pan",
      "Bo Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Addepalli_Leveraging_Vision-Language_Models_for_Improving_Domain_Generalization_in_Image_Classification_CVPR_2024_paper.html": {
    "title": "Leveraging Vision-Language Models for Improving Domain Generalization in Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sravanti Addepalli",
      "Ashish Ramayee Asokan",
      "Lakshay Sharma",
      "R. Venkatesh Babu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ryu_Diffusion-EDFs_Bi-equivariant_Denoising_Generative_Modeling_on_SE3_for_Visual_Robotic_CVPR_2024_paper.html": {
    "title": "Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunwoo Ryu",
      "Jiwoo Kim",
      "Hyunseok An",
      "Junwoo Chang",
      "Joohwan Seo",
      "Taehan Kim",
      "Yubin Kim",
      "Chaewon Hwang",
      "Jongeun Choi",
      "Roberto Horowitz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Prompt_Learning_via_Meta-Regularization_CVPR_2024_paper.html": {
    "title": "Prompt Learning via Meta-Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyoung Park",
      "Juyeon Ko",
      "Hyunwoo J. Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Contrasting_Intra-Modal_and_Ranking_Cross-Modal_Hard_Negatives_to_Enhance_Visio-Linguistic_CVPR_2024_paper.html": {
    "title": "Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Compositional Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Le Zhang",
      "Rabiul Awal",
      "Aishwarya Agrawal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_CMA_A_Chromaticity_Map_Adapter_for_Robust_Detection_of_Screen-Recapture_CVPR_2024_paper.html": {
    "title": "CMA: A Chromaticity Map Adapter for Robust Detection of Screen-Recapture Document Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changsheng Chen",
      "Liangwei Lin",
      "Yongqi Chen",
      "Bin Li",
      "Jishen Zeng",
      "Jiwu Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Embodied_Multi-Modal_Agent_trained_by_an_LLM_from_a_Parallel_CVPR_2024_paper.html": {
    "title": "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijun Yang",
      "Tianyi Zhou",
      "Kanxue Li",
      "Dapeng Tao",
      "Lusong Li",
      "Li Shen",
      "Xiaodong He",
      "Jing Jiang",
      "Yuhui Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_VA3_Virtually_Assured_Amplification_Attack_on_Probabilistic_Copyright_Protection_for_CVPR_2024_paper.html": {
    "title": "VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Li",
      "Qianli Shen",
      "Kenji Kawaguchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mahadevan_Point-VOS_Pointing_Up_Video_Object_Segmentation_CVPR_2024_paper.html": {
    "title": "Point-VOS: Pointing Up Video Object Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sabarinath Mahadevan",
      "Idil Esen Zulfikar",
      "Paul Voigtlaender",
      "Bastian Leibe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sato_Intriguing_Properties_of_Diffusion_Models_An_Empirical_Study_of_the_CVPR_2024_paper.html": {
    "title": "Intriguing Properties of Diffusion Models: An Empirical Study of the Natural Attack Capability in Text-to-Image Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takami Sato",
      "Justin Yue",
      "Nanze Chen",
      "Ningfei Wang",
      "Qi Alfred Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_GroupContrast_Semantic-aware_Self-supervised_Representation_Learning_for_3D_Understanding_CVPR_2024_paper.html": {
    "title": "GroupContrast: Semantic-aware Self-supervised Representation Learning for 3D Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyao Wang",
      "Li Jiang",
      "Xiaoyang Wu",
      "Zhuotao Tian",
      "Bohao Peng",
      "Hengshuang Zhao",
      "Jiaya Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jung_HouseCat6D_-_A_Large-Scale_Multi-Modal_Category_Level_6D_Object_Perception_CVPR_2024_paper.html": {
    "title": "HouseCat6D - A Large-Scale Multi-Modal Category Level 6D Object Perception Dataset with Household Objects in Realistic Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "HyunJun Jung",
      "Shun-Cheng Wu",
      "Patrick Ruhkamp",
      "Guangyao Zhai",
      "Hannah Schieber",
      "Giulia Rizzoli",
      "Pengyuan Wang",
      "Hongcheng Zhao",
      "Lorenzo Garattoni",
      "Sven Meier",
      "Daniel Roth",
      "Nassir Navab",
      "Benjamin Busam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mi_Privacy-Preserving_Face_Recognition_Using_Trainable_Feature_Subtraction_CVPR_2024_paper.html": {
    "title": "Privacy-Preserving Face Recognition Using Trainable Feature Subtraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxi Mi",
      "Zhizhou Zhong",
      "Yuge Huang",
      "Jiazhen Ji",
      "Jianqing Xu",
      "Jun Wang",
      "Shaoming Wang",
      "Shouhong Ding",
      "Shuigeng Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kalra_Towards_Co-Evaluation_of_Cameras_HDR_and_Algorithms_for_Industrial-Grade_6DoF_CVPR_2024_paper.html": {
    "title": "Towards Co-Evaluation of Cameras HDR and Algorithms for Industrial-Grade 6DoF Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Agastya Kalra",
      "Guy Stoppi",
      "Dmitrii Marin",
      "Vage Taamazyan",
      "Aarrushi Shandilya",
      "Rishav Agarwal",
      "Anton Boykov",
      "Tze Hao Chong",
      "Michael Stark"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Learning_Visual_Prompt_for_Gait_Recognition_CVPR_2024_paper.html": {
    "title": "Learning Visual Prompt for Gait Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kang Ma",
      "Ying Fu",
      "Chunshui Cao",
      "Saihui Hou",
      "Yongzhen Huang",
      "Dezhi Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_MLP_Can_Be_A_Good_Transformer_Learner_CVPR_2024_paper.html": {
    "title": "MLP Can Be A Good Transformer Learner",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sihao Lin",
      "Pumeng Lyu",
      "Dongrui Liu",
      "Tao Tang",
      "Xiaodan Liang",
      "Andy Song",
      "Xiaojun Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_GraphDreamer_Compositional_3D_Scene_Synthesis_from_Scene_Graphs_CVPR_2024_paper.html": {
    "title": "GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gege Gao",
      "Weiyang Liu",
      "Anpei Chen",
      "Andreas Geiger",
      "Bernhard Schölkopf"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hou_Visual-Augmented_Dynamic_Semantic_Prototype_for_Generative_Zero-Shot_Learning_CVPR_2024_paper.html": {
    "title": "Visual-Augmented Dynamic Semantic Prototype for Generative Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjin Hou",
      "Shiming Chen",
      "Shuhuang Chen",
      "Ziming Hong",
      "Yan Wang",
      "Xuetao Feng",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Xinge You"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mo_Dynamic_Prompt_Optimizing_for_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Dynamic Prompt Optimizing for Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyi Mo",
      "Tianyu Zhang",
      "Yalong Bai",
      "Bing Su",
      "Ji-Rong Wen",
      "Qing Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_SC-GS_Sparse-Controlled_Gaussian_Splatting_for_Editable_Dynamic_Scenes_CVPR_2024_paper.html": {
    "title": "SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi-Hua Huang",
      "Yang-Tian Sun",
      "Ziyi Yang",
      "Xiaoyang Lyu",
      "Yan-Pei Cao",
      "Xiaojuan Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_360Loc_A_Dataset_and_Benchmark_for_Omnidirectional_Visual_Localization_with_CVPR_2024_paper.html": {
    "title": "360Loc: A Dataset and Benchmark for Omnidirectional Visual Localization with Cross-device Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huajian Huang",
      "Changkun Liu",
      "Yipeng Zhu",
      "Hui Cheng",
      "Tristan Braud",
      "Sai-Kit Yeung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Domain_Gap_Embeddings_for_Generative_Dataset_Augmentation_CVPR_2024_paper.html": {
    "title": "Domain Gap Embeddings for Generative Dataset Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinong Oliver Wang",
      "Younjoon Chung",
      "Chen Henry Wu",
      "Fernando De la Torre"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mei_Geometrically-driven_Aggregation_for_Zero-shot_3D_Point_Cloud_Understanding_CVPR_2024_paper.html": {
    "title": "Geometrically-driven Aggregation for Zero-shot 3D Point Cloud Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guofeng Mei",
      "Luigi Riz",
      "Yiming Wang",
      "Fabio Poiesi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_Learning_to_Rank_Patches_for_Unbiased_Image_Redundancy_Reduction_CVPR_2024_paper.html": {
    "title": "Learning to Rank Patches for Unbiased Image Redundancy Reduction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Luo",
      "Zhineng Chen",
      "Peng Zhou",
      "Zuxuan Wu",
      "Xieping Gao",
      "Yu-Gang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Going_Beyond_Multi-Task_Dense_Prediction_with_Synergy_Embedding_Models_CVPR_2024_paper.html": {
    "title": "Going Beyond Multi-Task Dense Prediction with Synergy Embedding Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huimin Huang",
      "Yawen Huang",
      "Lanfen Lin",
      "Ruofeng Tong",
      "Yen-Wei Chen",
      "Hao Zheng",
      "Yuexiang Li",
      "Yefeng Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Disentangled_Pre-training_for_Human-Object_Interaction_Detection_CVPR_2024_paper.html": {
    "title": "Disentangled Pre-training for Human-Object Interaction Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuolong Li",
      "Xingao Li",
      "Changxing Ding",
      "Xiangmin Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Light_the_Night_A_Multi-Condition_Diffusion_Framework_for_Unpaired_Low-Light_CVPR_2024_paper.html": {
    "title": "Light the Night: A Multi-Condition Diffusion Framework for Unpaired Low-Light Enhancement in Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinlong Li",
      "Baolu Li",
      "Zhengzhong Tu",
      "Xinyu Liu",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Runsheng Xu",
      "Hongkai Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_MetaCloak_Preventing_Unauthorized_Subject-driven_Text-to-image_Diffusion-based_Synthesis_via_Meta-learning_CVPR_2024_paper.html": {
    "title": "MetaCloak: Preventing Unauthorized Subject-driven Text-to-image Diffusion-based Synthesis via Meta-learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Liu",
      "Chenrui Fan",
      "Yutong Dai",
      "Xun Chen",
      "Pan Zhou",
      "Lichao Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Neural_Modes_Self-supervised_Learning_of_Nonlinear_Modal_Subspaces_CVPR_2024_paper.html": {
    "title": "Neural Modes: Self-supervised Learning of Nonlinear Modal Subspaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahong Wang",
      "Yinwei Du",
      "Stelian Coros",
      "Bernhard Thomaszewski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Papa_How_to_Train_Neural_Field_Representations_A_Comprehensive_Study_and_CVPR_2024_paper.html": {
    "title": "How to Train Neural Field Representations: A Comprehensive Study and Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuele Papa",
      "Riccardo Valperga",
      "David Knigge",
      "Miltiadis Kofinas",
      "Phillip Lippe",
      "Jan-Jakob Sonke",
      "Efstratios Gavves"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Delving_into_the_Trajectory_Long-tail_Distribution_for_Muti-object_Tracking_CVPR_2024_paper.html": {
    "title": "Delving into the Trajectory Long-tail Distribution for Muti-object Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijia Chen",
      "En Yu",
      "Jinyang Li",
      "Wenbing Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_Tri-Modal_Motion_Retrieval_by_Learning_a_Joint_Embedding_Space_CVPR_2024_paper.html": {
    "title": "Tri-Modal Motion Retrieval by Learning a Joint Embedding Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangning Yin",
      "Shihao Zou",
      "Yuxuan Ge",
      "Zheng Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Seg2Reg_Differentiable_2D_Segmentation_to_1D_Regression_Rendering_for_360_CVPR_2024_paper.html": {
    "title": "Seg2Reg: Differentiable 2D Segmentation to 1D Regression Rendering for 360 Room Layout Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Sun",
      "Wei-En Tai",
      "Yu-Lin Shih",
      "Kuan-Wei Chen",
      "Yong-Jing Syu",
      "Kent Selwyn The",
      "Yu-Chiang Frank Wang",
      "Hwann-Tzong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Strong_Transferable_Adversarial_Attacks_via_Ensembled_Asymptotically_Normal_Distribution_Learning_CVPR_2024_paper.html": {
    "title": "Strong Transferable Adversarial Attacks via Ensembled Asymptotically Normal Distribution Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengwei Fang",
      "Rui Wang",
      "Tao Huang",
      "Liping Jing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Spanning_Training_Progress_Temporal_Dual-Depth_Scoring_TDDS_for_Enhanced_Dataset_CVPR_2024_paper.html": {
    "title": "Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for Enhanced Dataset Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Zhang",
      "Jiawei Du",
      "Yunsong Li",
      "Weiying Xie",
      "Joey Tianyi Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_UniMix_Towards_Domain_Adaptive_and_Generalizable_LiDAR_Semantic_Segmentation_in_CVPR_2024_paper.html": {
    "title": "UniMix: Towards Domain Adaptive and Generalizable LiDAR Semantic Segmentation in Adverse Weather",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haimei Zhao",
      "Jing Zhang",
      "Zhuo Chen",
      "Shanshan Zhao",
      "Dacheng Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jang_Visual_Delta_Generator_with_Large_Multi-modal_Models_for_Semi-supervised_Composed_CVPR_2024_paper.html": {
    "title": "Visual Delta Generator with Large Multi-modal Models for Semi-supervised Composed Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Young Kyun Jang",
      "Donghyun Kim",
      "Zihang Meng",
      "Dat Huynh",
      "Ser-Nam Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ilic_Selective_Interpretable_and_Motion_Consistent_Privacy_Attribute_Obfuscation_for_Action_CVPR_2024_paper.html": {
    "title": "Selective Interpretable and Motion Consistent Privacy Attribute Obfuscation for Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filip Ilic",
      "He Zhao",
      "Thomas Pock",
      "Richard P. Wildes"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_HiPose_Hierarchical_Binary_Surface_Encoding_and_Correspondence_Pruning_for_RGB-D_CVPR_2024_paper.html": {
    "title": "HiPose: Hierarchical Binary Surface Encoding and Correspondence Pruning for RGB-D 6DoF Object Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongliang Lin",
      "Yongzhi Su",
      "Praveen Nathan",
      "Sandeep Inuganti",
      "Yan Di",
      "Martin Sundermeyer",
      "Fabian Manhardt",
      "Didier Stricker",
      "Jason Rambach",
      "Yu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_DiffForensics_Leveraging_Diffusion_Prior_to_Image_Forgery_Detection_and_Localization_CVPR_2024_paper.html": {
    "title": "DiffForensics: Leveraging Diffusion Prior to Image Forgery Detection and Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeqin Yu",
      "Jiangqun Ni",
      "Yuzhen Lin",
      "Haoyi Deng",
      "Bin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_CoSeR_Bridging_Image_and_Language_for_Cognitive_Super-Resolution_CVPR_2024_paper.html": {
    "title": "CoSeR: Bridging Image and Language for Cognitive Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoze Sun",
      "Wenbo Li",
      "Jianzhuang Liu",
      "Haoyu Chen",
      "Renjing Pei",
      "Xueyi Zou",
      "Youliang Yan",
      "Yujiu Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Geometry-aware_Reconstruction_and_Fusion-refined_Rendering_for_Generalizable_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "Geometry-aware Reconstruction and Fusion-refined Rendering for Generalizable Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianqi Liu",
      "Xinyi Ye",
      "Min Shi",
      "Zihao Huang",
      "Zhiyu Pan",
      "Zhan Peng",
      "Zhiguo Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_Boosting_Self-Supervision_for_Single-View_Scene_Completion_via_Knowledge_Distillation_CVPR_2024_paper.html": {
    "title": "Boosting Self-Supervision for Single-View Scene Completion via Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keonhee Han",
      "Dominik Muhle",
      "Felix Wimbauer",
      "Daniel Cremers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "PromptKD: Unsupervised Prompt Distillation for Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Li",
      "Xiang Li",
      "Xinyi Fu",
      "Xin Zhang",
      "Weiqiang Wang",
      "Shuo Chen",
      "Jian Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_VideoBooth_Diffusion-based_Video_Generation_with_Image_Prompts_CVPR_2024_paper.html": {
    "title": "VideoBooth: Diffusion-based Video Generation with Image Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuming Jiang",
      "Tianxing Wu",
      "Shuai Yang",
      "Chenyang Si",
      "Dahua Lin",
      "Yu Qiao",
      "Chen Change Loy",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Robust_Overfitting_Does_Matter_Test-Time_Adversarial_Purification_With_FGSM_CVPR_2024_paper.html": {
    "title": "Robust Overfitting Does Matter: Test-Time Adversarial Purification With FGSM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linyu Tang",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Sparse_Global_Matching_for_Video_Frame_Interpolation_with_Large_Motion_CVPR_2024_paper.html": {
    "title": "Sparse Global Matching for Video Frame Interpolation with Large Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunxu Liu",
      "Guozhen Zhang",
      "Rui Zhao",
      "Limin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_ExtDM_Distribution_Extrapolation_Diffusion_Model_for_Video_Prediction_CVPR_2024_paper.html": {
    "title": "ExtDM: Distribution Extrapolation Diffusion Model for Video Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicheng Zhang",
      "Junyao Hu",
      "Wentao Cheng",
      "Danda Paudel",
      "Jufeng Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiong_Modality-Collaborative_Test-Time_Adaptation_for_Action_Recognition_CVPR_2024_paper.html": {
    "title": "Modality-Collaborative Test-Time Adaptation for Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baochen Xiong",
      "Xiaoshan Yang",
      "Yaguang Song",
      "Yaowei Wang",
      "Changsheng Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sanyal_SCULPT_Shape-Conditioned_Unpaired_Learning_of_Pose-dependent_Clothed_and_Textured_Human_CVPR_2024_paper.html": {
    "title": "SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soubhik Sanyal",
      "Partha Ghosh",
      "Jinlong Yang",
      "Michael J. Black",
      "Justus Thies",
      "Timo Bolkart"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Point_Segment_and_Count_A_Generalized_Framework_for_Object_Counting_CVPR_2024_paper.html": {
    "title": "Point Segment and Count: A Generalized Framework for Object Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhizhong Huang",
      "Mingliang Dai",
      "Yi Zhang",
      "Junping Zhang",
      "Hongming Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Koneputugodage_Small_Steps_and_Level_Sets_Fitting_Neural_Surface_Models_with_CVPR_2024_paper.html": {
    "title": "Small Steps and Level Sets: Fitting Neural Surface Models with Point Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chamin Hewa Koneputugodage",
      "Yizhak Ben-Shabat",
      "Dylan Campbell",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Du_Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation_CVPR_2024_paper.html": {
    "title": "Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhekai Du",
      "Xinyao Li",
      "Fengling Li",
      "Ke Lu",
      "Lei Zhu",
      "Jingjing Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_PTT_Point-Trajectory_Transformer_for_Efficient_Temporal_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kuan-Chih Huang",
      "Weijie Lyu",
      "Ming-Hsuan Yang",
      "Yi-Hsuan Tsai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Muller_Generative_Proxemics_A_Prior_for_3D_Social_Interaction_from_Images_CVPR_2024_paper.html": {
    "title": "Generative Proxemics: A Prior for 3D Social Interaction from Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lea Müller",
      "Vickie Ye",
      "Georgios Pavlakos",
      "Michael Black",
      "Angjoo Kanazawa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_A_Simple_and_Effective_Point-based_Network_for_Event_Camera_6-DOFs_CVPR_2024_paper.html": {
    "title": "A Simple and Effective Point-based Network for Event Camera 6-DOFs Pose Relocalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongwei Ren",
      "Jiadong Zhu",
      "Yue Zhou",
      "Haotian Fu",
      "Yulong Huang",
      "Bojun Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mahmood_Semantic-Aware_Multi-Label_Adversarial_Attacks_CVPR_2024_paper.html": {
    "title": "Semantic-Aware Multi-Label Adversarial Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hassan Mahmood",
      "Ehsan Elhamifar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hou_EasyDrag_Efficient_Point-based_Manipulation_on_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "EasyDrag: Efficient Point-based Manipulation on Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingzhong Hou",
      "Boxiao Liu",
      "Yi Zhang",
      "Jihao Liu",
      "Yu Liu",
      "Haihang You"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shlapentokh-Rothman_Region-Based_Representations_Revisited_CVPR_2024_paper.html": {
    "title": "Region-Based Representations Revisited",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michal Shlapentokh-Rothman",
      "Ansel Blume",
      "Yao Xiao",
      "Yuqun Wu",
      "Sethuraman TV",
      "Heyi Tao",
      "Jae Yong Lee",
      "Wilfredo Torres",
      "Yu-Xiong Wang",
      "Derek Hoiem"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_GenH2R_Learning_Generalizable_Human-to-Robot_Handover_via_Scalable_Simulation_Demonstration_and_CVPR_2024_paper.html": {
    "title": "GenH2R: Learning Generalizable Human-to-Robot Handover via Scalable Simulation Demonstration and Imitation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zifan Wang",
      "Junyu Chen",
      "Ziqing Chen",
      "Pengwei Xie",
      "Rui Chen",
      "Li Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mok_Modality-Agnostic_Structural_Image_Representation_Learning_for_Deformable_Multi-Modality_Medical_Image_CVPR_2024_paper.html": {
    "title": "Modality-Agnostic Structural Image Representation Learning for Deformable Multi-Modality Medical Image Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tony C. W. Mok",
      "Zi Li",
      "Yunhao Bai",
      "Jianpeng Zhang",
      "Wei Liu",
      "Yan-Jie Zhou",
      "Ke Yan",
      "Dakai Jin",
      "Yu Shi",
      "Xiaoli Yin",
      "Le Lu",
      "Ling Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Any-Shift_Prompting_for_Generalization_over_Distributions_CVPR_2024_paper.html": {
    "title": "Any-Shift Prompting for Generalization over Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehao Xiao",
      "Jiayi Shen",
      "Mohammad Mahdi Derakhshani",
      "Shengcai Liao",
      "Cees G. M. Snoek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_InterHandGen_Two-Hand_Interaction_Generation_via_Cascaded_Reverse_Diffusion_CVPR_2024_paper.html": {
    "title": "InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyun Lee",
      "Shunsuke Saito",
      "Giljoo Nam",
      "Minhyuk Sung",
      "Tae-Kyun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_CPR-Coach_Recognizing_Composite_Error_Actions_based_on_Single-class_Training_CVPR_2024_paper.html": {
    "title": "CPR-Coach: Recognizing Composite Error Actions based on Single-class Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shunli Wang",
      "Shuaibing Wang",
      "Dingkang Yang",
      "Mingcheng Li",
      "Haopeng Kuang",
      "Xiao Zhao",
      "Liuzhen Su",
      "Peng Zhai",
      "Lihua Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_Video2Game_Real-time_Interactive_Realistic_and_Browser-Compatible_Environment_from_a_Single_CVPR_2024_paper.html": {
    "title": "Video2Game: Real-time Interactive Realistic and Browser-Compatible Environment from a Single Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongchi Xia",
      "Zhi-Hao Lin",
      "Wei-Chiu Ma",
      "Shenlong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Tackling_the_Singularities_at_the_Endpoints_of_Time_Intervals_in_CVPR_2024_paper.html": {
    "title": "Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengze Zhang",
      "Hubery Yin",
      "Chen Li",
      "Xiaohua Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vecchio_MatSynth_A_Modern_PBR_Materials_Dataset_CVPR_2024_paper.html": {
    "title": "MatSynth: A Modern PBR Materials Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuseppe Vecchio",
      "Valentin Deschaintre"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ni_CHAIN_Enhancing_Generalization_in_Data-Efficient_GANs_via_lipsCHitz_continuity_constrAIned_CVPR_2024_paper.html": {
    "title": "CHAIN: Enhancing Generalization in Data-Efficient GANs via lipsCHitz continuity constrAIned Normalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Ni",
      "Piotr Koniusz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_RTracker_Recoverable_Tracking_via_PN_Tree_Structured_Memory_CVPR_2024_paper.html": {
    "title": "RTracker: Recoverable Tracking via PN Tree Structured Memory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqing Huang",
      "Xin Li",
      "Zikun Zhou",
      "Yaowei Wang",
      "Zhenyu He",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_High-Quality_Facial_Geometry_and_Appearance_Capture_at_Home_CVPR_2024_paper.html": {
    "title": "High-Quality Facial Geometry and Appearance Capture at Home",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Han",
      "Junfeng Lyu",
      "Feng Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Doll_DualAD_Disentangling_the_Dynamic_and_Static_World_for_End-to-End_Driving_CVPR_2024_paper.html": {
    "title": "DualAD: Disentangling the Dynamic and Static World for End-to-End Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Doll",
      "Niklas Hanselmann",
      "Lukas Schneider",
      "Richard Schulz",
      "Marius Cordts",
      "Markus Enzweiler",
      "Hendrik P. A. Lensch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_OTE_Exploring_Accurate_Scene_Text_Recognition_Using_One_Token_CVPR_2024_paper.html": {
    "title": "OTE: Exploring Accurate Scene Text Recognition Using One Token",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianjun Xu",
      "Yuxin Wang",
      "Hongtao Xie",
      "Yongdong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Micorek_MULDE_Multiscale_Log-Density_Estimation_via_Denoising_Score_Matching_for_Video_CVPR_2024_paper.html": {
    "title": "MULDE: Multiscale Log-Density Estimation via Denoising Score Matching for Video Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jakub Micorek",
      "Horst Possegger",
      "Dominik Narnhofer",
      "Horst Bischof",
      "Mateusz Kozinski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Casarin_Your_Image_is_My_Video_Reshaping_the_Receptive_Field_via_CVPR_2024_paper.html": {
    "title": "Your Image is My Video: Reshaping the Receptive Field via Image-To-Video Differentiable AutoAugmentation and Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sofia Casarin",
      "Cynthia I. Ugwu",
      "Sergio Escalera",
      "Oswald Lanz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lv_PTQ4SAM_Post-Training_Quantization_for_Segment_Anything_CVPR_2024_paper.html": {
    "title": "PTQ4SAM: Post-Training Quantization for Segment Anything",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengtao Lv",
      "Hong Chen",
      "Jinyang Guo",
      "Yifu Ding",
      "Xianglong Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Improving_Birds_Eye_View_Semantic_Segmentation_by_Task_Decomposition_CVPR_2024_paper.html": {
    "title": "Improving Bird's Eye View Semantic Segmentation by Task Decomposition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhao Zhao",
      "Yongcan Chen",
      "Yu Wu",
      "Tianyang Liu",
      "Bo Du",
      "Peilun Xiao",
      "Shi Qiu",
      "Hongda Yang",
      "Guozhen Li",
      "Yi Yang",
      "Yutian Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_SpikingResformer_Bridging_ResNet_and_Vision_Transformer_in_Spiking_Neural_Networks_CVPR_2024_paper.html": {
    "title": "SpikingResformer: Bridging ResNet and Vision Transformer in Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Shi",
      "Zecheng Hao",
      "Zhaofei Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_Scene_Adaptive_Sparse_Transformer_for_Event-based_Object_Detection_CVPR_2024_paper.html": {
    "title": "Scene Adaptive Sparse Transformer for Event-based Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yansong Peng",
      "Hebei Li",
      "Yueyi Zhang",
      "Xiaoyan Sun",
      "Feng Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bolanos_Gaussian_Shadow_Casting_for_Neural_Characters_CVPR_2024_paper.html": {
    "title": "Gaussian Shadow Casting for Neural Characters",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luis Bolanos",
      "Shih-Yang Su",
      "Helge Rhodin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_CURSOR_Scalable_Mixed-Order_Hypergraph_Matching_with_CUR_Decomposition_CVPR_2024_paper.html": {
    "title": "CURSOR: Scalable Mixed-Order Hypergraph Matching with CUR Decomposition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qixuan Zheng",
      "Ming Zhang",
      "Hong Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Poggi_Federated_Online_Adaptation_for_Deep_Stereo_CVPR_2024_paper.html": {
    "title": "Federated Online Adaptation for Deep Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matteo Poggi",
      "Fabio Tosi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bai_Sequential_Modeling_Enables_Scalable_Learning_for_Large_Vision_Models_CVPR_2024_paper.html": {
    "title": "Sequential Modeling Enables Scalable Learning for Large Vision Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutong Bai",
      "Xinyang Geng",
      "Karttikeya Mangalam",
      "Amir Bar",
      "Alan L. Yuille",
      "Trevor Darrell",
      "Jitendra Malik",
      "Alexei A. Efros"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sundararaman_Self-Supervised_Dual_Contouring_CVPR_2024_paper.html": {
    "title": "Self-Supervised Dual Contouring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramana Sundararaman",
      "Roman Klokov",
      "Maks Ovsjanikov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Moure_Regularized_Parameter_Uncertainty_for_Improving_Generalization_in_Reinforcement_Learning_CVPR_2024_paper.html": {
    "title": "Regularized Parameter Uncertainty for Improving Generalization in Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pehuen Moure",
      "Longbiao Cheng",
      "Joachim Ott",
      "Zuowen Wang",
      "Shih-Chii Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_GigaTraj_Predicting_Long-term_Trajectories_of_Hundreds_of_Pedestrians_in_Gigapixel_CVPR_2024_paper.html": {
    "title": "GigaTraj: Predicting Long-term Trajectories of Hundreds of Pedestrians in Gigapixel Complex Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haozhe Lin",
      "Chunyu Wei",
      "Li He",
      "Yuchen Guo",
      "Yunqi Zhao",
      "Shanglong Li",
      "Lu Fang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_GSVA_Generalized_Segmentation_via_Multimodal_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "GSVA: Generalized Segmentation via Multimodal Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuofan Xia",
      "Dongchen Han",
      "Yizeng Han",
      "Xuran Pan",
      "Shiji Song",
      "Gao Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_AdaBM_On-the-Fly_Adaptive_Bit_Mapping_for_Image_Super-Resolution_CVPR_2024_paper.html": {
    "title": "AdaBM: On-the-Fly Adaptive Bit Mapping for Image Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheeun Hong",
      "Kyoung Mu Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_CoralSCOP_Segment_any_COral_Image_on_this_Planet_CVPR_2024_paper.html": {
    "title": "CoralSCOP: Segment any COral Image on this Planet",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqiang Zheng",
      "Haixin Liang",
      "Binh-Son Hua",
      "Yue Him Wong",
      "Put Ang Jr",
      "Apple Pui Yi Chui",
      "Sai-Kit Yeung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xing_SVGDreamer_Text_Guided_SVG_Generation_with_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "SVGDreamer: Text Guided SVG Generation with Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ximing Xing",
      "Haitao Zhou",
      "Chuang Wang",
      "Jing Zhang",
      "Dong Xu",
      "Qian Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_BlockGCN_Redefine_Topology_Awareness_for_Skeleton-Based_Action_Recognition_CVPR_2024_paper.html": {
    "title": "BlockGCN: Redefine Topology Awareness for Skeleton-Based Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Zhou",
      "Xudong Yan",
      "Zhi-Qi Cheng",
      "Yan Yan",
      "Qi Dai",
      "Xian-Sheng Hua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Improved_Baselines_with_Visual_Instruction_Tuning_CVPR_2024_paper.html": {
    "title": "Improved Baselines with Visual Instruction Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haotian Liu",
      "Chunyuan Li",
      "Yuheng Li",
      "Yong Jae Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Structure-Guided_Adversarial_Training_of_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Structure-Guided Adversarial Training of Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ling Yang",
      "Haotian Qian",
      "Zhilong Zhang",
      "Jingwei Liu",
      "Bin Cui"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kulkarni_NIFTY_Neural_Object_Interaction_Fields_for_Guided_Human_Motion_Synthesis_CVPR_2024_paper.html": {
    "title": "NIFTY: Neural Object Interaction Fields for Guided Human Motion Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nilesh Kulkarni",
      "Davis Rempe",
      "Kyle Genova",
      "Abhijit Kundu",
      "Justin Johnson",
      "David Fouhey",
      "Leonidas Guibas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huo_C2KD_Bridging_the_Modality_Gap_for_Cross-Modal_Knowledge_Distillation_CVPR_2024_paper.html": {
    "title": "C2KD: Bridging the Modality Gap for Cross-Modal Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fushuo Huo",
      "Wenchao Xu",
      "Jingcai Guo",
      "Haozhao Wang",
      "Song Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Traceable_Federated_Continual_Learning_CVPR_2024_paper.html": {
    "title": "Traceable Federated Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiang Wang",
      "Bingyan Liu",
      "Yawen Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bae_Can_Language_Beat_Numerical_Regression_Language-Based_Multimodal_Trajectory_Prediction_CVPR_2024_paper.html": {
    "title": "Can Language Beat Numerical Regression? Language-Based Multimodal Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Inhwan Bae",
      "Junoh Lee",
      "Hae-Gon Jeon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mills_Building_Optimal_Neural_Architectures_using_Interpretable_Knowledge_CVPR_2024_paper.html": {
    "title": "Building Optimal Neural Architectures using Interpretable Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keith G. Mills",
      "Fred X. Han",
      "Mohammad Salameh",
      "Shengyao Lu",
      "Chunhua Zhou",
      "Jiao He",
      "Fengyu Sun",
      "Di Niu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_V_Guided_Visual_Search_as_a_Core_Mechanism_in_Multimodal_CVPR_2024_paper.html": {
    "title": "V?: Guided Visual Search as a Core Mechanism in Multimodal LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Penghao Wu",
      "Saining Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Baek_Unexplored_Faces_of_Robustness_and_Out-of-Distribution_Covariate_Shifts_in_Environment_CVPR_2024_paper.html": {
    "title": "Unexplored Faces of Robustness and Out-of-Distribution: Covariate Shifts in Environment and Sensor Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunsu Baek",
      "Keondo Park",
      "Jiyoon Kim",
      "Hyung-Sin Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yair_Uncertainty_Visualization_via_Low-Dimensional_Posterior_Projections_CVPR_2024_paper.html": {
    "title": "Uncertainty Visualization via Low-Dimensional Posterior Projections",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omer Yair",
      "Elias Nehme",
      "Tomer Michaeli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_VSCode_General_Visual_Salient_and_Camouflaged_Object_Detection_with_2D_CVPR_2024_paper.html": {
    "title": "VSCode: General Visual Salient and Camouflaged Object Detection with 2D Prompt Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Luo",
      "Nian Liu",
      "Wangbo Zhao",
      "Xuguang Yang",
      "Dingwen Zhang",
      "Deng-Ping Fan",
      "Fahad Khan",
      "Junwei Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_GaussianEditor_Swift_and_Controllable_3D_Editing_with_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwen Chen",
      "Zilong Chen",
      "Chi Zhang",
      "Feng Wang",
      "Xiaofeng Yang",
      "Yikai Wang",
      "Zhongang Cai",
      "Lei Yang",
      "Huaping Liu",
      "Guosheng Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mei_Holo-Relighting_Controllable_Volumetric_Portrait_Relighting_from_a_Single_Image_CVPR_2024_paper.html": {
    "title": "Holo-Relighting: Controllable Volumetric Portrait Relighting from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqun Mei",
      "Yu Zeng",
      "He Zhang",
      "Zhixin Shu",
      "Xuaner Zhang",
      "Sai Bi",
      "Jianming Zhang",
      "HyunJoon Jung",
      "Vishal M. Patel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Noisy_One-point_Homographies_are_Surprisingly_Good_CVPR_2024_paper.html": {
    "title": "Noisy One-point Homographies are Surprisingly Good",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaqing Ding",
      "Jonathan Astermark",
      "Magnus Oskarsson",
      "Viktor Larsson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_PointInfinity_Resolution-Invariant_Point_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "PointInfinity: Resolution-Invariant Point Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Huang",
      "Justin Johnson",
      "Shoubhik Debnath",
      "James M. Rehg",
      "Chao-Yuan Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wen_Panacea_Panoramic_and_Controllable_Video_Generation_for_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "Panacea: Panoramic and Controllable Video Generation for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqing Wen",
      "Yucheng Zhao",
      "Yingfei Liu",
      "Fan Jia",
      "Yanhui Wang",
      "Chong Luo",
      "Chi Zhang",
      "Tiancai Wang",
      "Xiaoyan Sun",
      "Xiangyu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shan_Open-Vocabulary_Semantic_Segmentation_with_Image_Embedding_Balancing_CVPR_2024_paper.html": {
    "title": "Open-Vocabulary Semantic Segmentation with Image Embedding Balancing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangheng Shan",
      "Dongyue Wu",
      "Guilin Zhu",
      "Yuanjie Shao",
      "Nong Sang",
      "Changxin Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Structured_Model_Probing_Empowering_Efficient_Transfer_Learning_by_Structured_Regularization_CVPR_2024_paper.html": {
    "title": "Structured Model Probing: Empowering Efficient Transfer Learning by Structured Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi-Fan Wu",
      "Chaojie Mao",
      "Wue Wang",
      "Jianwen Jiang",
      "Yiliang Lv",
      "Rong Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yao_Multi-Modal_Proxy_Learning_Towards_Personalized_Visual_Multiple_Clustering_CVPR_2024_paper.html": {
    "title": "Multi-Modal Proxy Learning Towards Personalized Visual Multiple Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Yao",
      "Qi Qian",
      "Juhua Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nam_DreamMatcher_Appearance_Matching_Self-Attention_for_Semantically-Consistent_Text-to-Image_Personalization_CVPR_2024_paper.html": {
    "title": "DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jisu Nam",
      "Heesu Kim",
      "DongJae Lee",
      "Siyoon Jin",
      "Seungryong Kim",
      "Seunggyu Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_Stronger_Fewer__Superior_Harnessing_Vision_Foundation_Models_for_Domain_CVPR_2024_paper.html": {
    "title": "Stronger Fewer & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixiang Wei",
      "Lin Chen",
      "Yi Jin",
      "Xiaoxiao Ma",
      "Tianle Liu",
      "Pengyang Ling",
      "Ben Wang",
      "Huaian Chen",
      "Jinjin Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Enomoto_PolarMatte_Fully_Computational_Ground-Truth-Quality_Alpha_Matte_Extraction_for_Images_and_CVPR_2024_paper.html": {
    "title": "PolarMatte: Fully Computational Ground-Truth-Quality Alpha Matte Extraction for Images and Video using Polarized Screen Matting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kenji Enomoto",
      "TJ Rhodes",
      "Brian Price",
      "Gavin Miller"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bourriez_ChAda-ViT__Channel_Adaptive_Attention_for_Joint_Representation_Learning_of_CVPR_2024_paper.html": {
    "title": "ChAda-ViT : Channel Adaptive Attention for Joint Representation Learning of Heterogeneous Microscopy Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Bourriez",
      "Ihab Bendidi",
      "Ethan Cohen",
      "Gabriel Watkinson",
      "Maxime Sanchez",
      "Guillaume Bollot",
      "Auguste Genovesio"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lai_CARZero_Cross-Attention_Alignment_for_Radiology_Zero-Shot_Classification_CVPR_2024_paper.html": {
    "title": "CARZero: Cross-Attention Alignment for Radiology Zero-Shot Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Lai",
      "Qingsong Yao",
      "Zihang Jiang",
      "Rongsheng Wang",
      "Zhiyang He",
      "Xiaodong Tao",
      "S. Kevin Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_HOIDiffusion_Generating_Realistic_3D_Hand-Object_Interaction_Data_CVPR_2024_paper.html": {
    "title": "HOIDiffusion: Generating Realistic 3D Hand-Object Interaction Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengqi Zhang",
      "Yang Fu",
      "Zheng Ding",
      "Sifei Liu",
      "Zhuowen Tu",
      "Xiaolong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Thamizharasan_VecFusion_Vector_Font_Generation_with_Diffusion_CVPR_2024_paper.html": {
    "title": "VecFusion: Vector Font Generation with Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vikas Thamizharasan",
      "Difan Liu",
      "Shantanu Agarwal",
      "Matthew Fisher",
      "Michael Gharbi",
      "Oliver Wang",
      "Alec Jacobson",
      "Evangelos Kalogerakis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Favero_Multi-Modal_Hallucination_Control_by_Visual_Information_Grounding_CVPR_2024_paper.html": {
    "title": "Multi-Modal Hallucination Control by Visual Information Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessandro Favero",
      "Luca Zancato",
      "Matthew Trager",
      "Siddharth Choudhary",
      "Pramuditha Perera",
      "Alessandro Achille",
      "Ashwin Swaminathan",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Towards_Text-guided_3D_Scene_Composition_CVPR_2024_paper.html": {
    "title": "Towards Text-guided 3D Scene Composition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihang Zhang",
      "Chaoyang Wang",
      "Aliaksandr Siarohin",
      "Peiye Zhuang",
      "Yinghao Xu",
      "Ceyuan Yang",
      "Dahua Lin",
      "Bolei Zhou",
      "Sergey Tulyakov",
      "Hsin-Ying Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_EMAGE_Towards_Unified_Holistic_Co-Speech_Gesture_Generation_via_Expressive_Masked_CVPR_2024_paper.html": {
    "title": "EMAGE: Towards Unified Holistic Co-Speech Gesture Generation via Expressive Masked Audio Gesture Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiyang Liu",
      "Zihao Zhu",
      "Giorgio Becherini",
      "Yichen Peng",
      "Mingyang Su",
      "You Zhou",
      "Xuefei Zhe",
      "Naoya Iwamoto",
      "Bo Zheng",
      "Michael J. Black"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Haydarov_Adversarial_Text_to_Continuous_Image_Generation_CVPR_2024_paper.html": {
    "title": "Adversarial Text to Continuous Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kilichbek Haydarov",
      "Aashiq Muhamed",
      "Xiaoqian Shen",
      "Jovana Lazarevic",
      "Ivan Skorokhodov",
      "Chamuditha Jayanga Galappaththige",
      "Mohamed Elhoseiny"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Parashar_The_Neglected_Tails_in_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "The Neglected Tails in Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shubham Parashar",
      "Zhiqiu Lin",
      "Tian Liu",
      "Xiangjue Dong",
      "Yanan Li",
      "Deva Ramanan",
      "James Caverlee",
      "Shu Kong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Learning_Background_Prompts_to_Discover_Implicit_Knowledge_for_Open_Vocabulary_CVPR_2024_paper.html": {
    "title": "Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Li",
      "Jiacheng Zhang",
      "Jichang Li",
      "Ge Li",
      "Si Liu",
      "Liang Lin",
      "Guanbin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_HumanNeRF-SE_A_Simple_yet_Effective_Approach_to_Animate_HumanNeRF_with_CVPR_2024_paper.html": {
    "title": "HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Caoyuan Ma",
      "Yu-Lun Liu",
      "Zhixiang Wang",
      "Wu Liu",
      "Xinchen Liu",
      "Zheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_HOLD_Category-agnostic_3D_Reconstruction_of_Interacting_Hands_and_Objects_from_CVPR_2024_paper.html": {
    "title": "HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and Objects from Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zicong Fan",
      "Maria Parelli",
      "Maria Eleni Kadoglou",
      "Xu Chen",
      "Muhammed Kocabas",
      "Michael J. Black",
      "Otmar Hilliges"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_Continual_Segmentation_with_Disentangled_Objectness_Learning_and_Class_Recognition_CVPR_2024_paper.html": {
    "title": "Continual Segmentation with Disentangled Objectness Learning and Class Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yizheng Gong",
      "Siyue Yu",
      "Xiaoyang Wang",
      "Jimin Xiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Towards_Accurate_Post-training_Quantization_for_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Towards Accurate Post-training Quantization for Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changyuan Wang",
      "Ziwei Wang",
      "Xiuwei Xu",
      "Yansong Tang",
      "Jie Zhou",
      "Jiwen Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_ASAM_Boosting_Segment_Anything_Model_with_Adversarial_Tuning_CVPR_2024_paper.html": {
    "title": "ASAM: Boosting Segment Anything Model with Adversarial Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Li",
      "Haoke Xiao",
      "Lv Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lyu_UniBind_LLM-Augmented_Unified_and_Balanced_Representation_Space_to_Bind_Them_CVPR_2024_paper.html": {
    "title": "UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanhuiyi Lyu",
      "Xu Zheng",
      "Jiazhou Zhou",
      "Lin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_Dynamic_Support_Information_Mining_for_Category-Agnostic_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "Dynamic Support Information Mining for Category-Agnostic Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Ren",
      "Yuanyuan Gao",
      "Haifeng Sun",
      "Qi Qi",
      "Jingyu Wang",
      "Jianxin Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Test-Time_Adaptation_for_Depth_Completion_CVPR_2024_paper.html": {
    "title": "Test-Time Adaptation for Depth Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyoungseob Park",
      "Anjali Gupta",
      "Alex Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Khanna_GOAT-Bench_A_Benchmark_for_Multi-Modal_Lifelong_Navigation_CVPR_2024_paper.html": {
    "title": "GOAT-Bench: A Benchmark for Multi-Modal Lifelong Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mukul Khanna",
      "Ram Ramrakhya",
      "Gunjan Chhablani",
      "Sriram Yenamandra",
      "Theophile Gervet",
      "Matthew Chang",
      "Zsolt Kira",
      "Devendra Singh Chaplot",
      "Dhruv Batra",
      "Roozbeh Mottaghi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Taming_Mode_Collapse_in_Score_Distillation_for_Text-to-3D_Generation_CVPR_2024_paper.html": {
    "title": "Taming Mode Collapse in Score Distillation for Text-to-3D Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peihao Wang",
      "Dejia Xu",
      "Zhiwen Fan",
      "Dilin Wang",
      "Sreyas Mohan",
      "Forrest Iandola",
      "Rakesh Ranjan",
      "Yilei Li",
      "Qiang Liu",
      "Zhangyang Wang",
      "Vikas Chandra"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Binarized_Low-light_Raw_Video_Enhancement_CVPR_2024_paper.html": {
    "title": "Binarized Low-light Raw Video Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gengchen Zhang",
      "Yulun Zhang",
      "Xin Yuan",
      "Ying Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_MorpheuS_Neural_Dynamic_360deg_Surface_Reconstruction_from_Monocular_RGB-D_Video_CVPR_2024_paper.html": {
    "title": "MorpheuS: Neural Dynamic 360deg Surface Reconstruction from Monocular RGB-D Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hengyi Wang",
      "Jingwen Wang",
      "Lourdes Agapito"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Decoupling_Static_and_Hierarchical_Motion_Perception_for_Referring_Video_Segmentation_CVPR_2024_paper.html": {
    "title": "Decoupling Static and Hierarchical Motion Perception for Referring Video Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuting He",
      "Henghui Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_MagicAnimate_Temporally_Consistent_Human_Image_Animation_using_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongcong Xu",
      "Jianfeng Zhang",
      "Jun Hao Liew",
      "Hanshu Yan",
      "Jia-Wei Liu",
      "Chenxu Zhang",
      "Jiashi Feng",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Dense_Vision_Transformer_Compression_with_Few_Samples_CVPR_2024_paper.html": {
    "title": "Dense Vision Transformer Compression with Few Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanxiao Zhang",
      "Yifan Zhou",
      "Guo-Hua Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qiu_Masked_AutoDecoder_is_Effective_Multi-Task_Vision_Generalist_CVPR_2024_paper.html": {
    "title": "Masked AutoDecoder is Effective Multi-Task Vision Generalist",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Qiu",
      "Jiaxing Huang",
      "Peng Gao",
      "Lewei Lu",
      "Xiaoqin Zhang",
      "Shijian Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Weakly_Misalignment-free_Adaptive_Feature_Alignment_for_UAVs-based_Multimodal_Object_Detection_CVPR_2024_paper.html": {
    "title": "Weakly Misalignment-free Adaptive Feature Alignment for UAVs-based Multimodal Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Chen",
      "Jiahao Qi",
      "Xingyue Liu",
      "Kangcheng Bin",
      "Ruigang Fu",
      "Xikun Hu",
      "Ping Zhong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tirado-Garin_From_Correspondences_to_Pose_Non-minimal_Certifiably_Optimal_Relative_Pose_without_CVPR_2024_paper.html": {
    "title": "From Correspondences to Pose: Non-minimal Certifiably Optimal Relative Pose without Disambiguation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Javier Tirado-Garín",
      "Javier Civera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ghanekar_Passive_Snapshot_Coded_Aperture_Dual-Pixel_RGB-D_Imaging_CVPR_2024_paper.html": {
    "title": "Passive Snapshot Coded Aperture Dual-Pixel RGB-D Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bhargav Ghanekar",
      "Salman Siddique Khan",
      "Pranav Sharma",
      "Shreyas Singh",
      "Vivek Boominathan",
      "Kaushik Mitra",
      "Ashok Veeraraghavan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zuo_Loose_Inertial_Poser_Motion_Capture_with_IMU-attached_Loose-Wear_Jacket_CVPR_2024_paper.html": {
    "title": "Loose Inertial Poser: Motion Capture with IMU-attached Loose-Wear Jacket",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengxu Zuo",
      "Yiming Wang",
      "Lishuang Zhan",
      "Shihui Guo",
      "Xinyu Yi",
      "Feng Xu",
      "Yipeng Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Instance_Tracking_in_3D_Scenes_from_Egocentric_Videos_CVPR_2024_paper.html": {
    "title": "Instance Tracking in 3D Scenes from Egocentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhan Zhao",
      "Haoyu Ma",
      "Shu Kong",
      "Charless Fowlkes"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Meng_Correlation-aware_Coarse-to-fine_MLPs_for_Deformable_Medical_Image_Registration_CVPR_2024_paper.html": {
    "title": "Correlation-aware Coarse-to-fine MLPs for Deformable Medical Image Registration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyuan Meng",
      "Dagan Feng",
      "Lei Bi",
      "Jinman Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Toward_Generalist_Anomaly_Detection_via_In-context_Residual_Learning_with_Few-shot_CVPR_2024_paper.html": {
    "title": "Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawen Zhu",
      "Guansong Pang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vaish_Fourier-basis_Functions_to_Bridge_Augmentation_Gap_Rethinking_Frequency_Augmentation_in_CVPR_2024_paper.html": {
    "title": "Fourier-basis Functions to Bridge Augmentation Gap: Rethinking Frequency Augmentation in Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Puru Vaish",
      "Shunxin Wang",
      "Nicola Strisciuglio"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Learning_to_Transform_Dynamically_for_Better_Adversarial_Transferability_CVPR_2024_paper.html": {
    "title": "Learning to Transform Dynamically for Better Adversarial Transferability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongyi Zhu",
      "Zeliang Zhang",
      "Susan Liang",
      "Zhuo Liu",
      "Chenliang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Klinghoffer_PlatoNeRF_3D_Reconstruction_in_Platos_Cave_via_Single-View_Two-Bounce_Lidar_CVPR_2024_paper.html": {
    "title": "PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tzofi Klinghoffer",
      "Xiaoyu Xiang",
      "Siddharth Somasundaram",
      "Yuchen Fan",
      "Christian Richardt",
      "Ramesh Raskar",
      "Rakesh Ranjan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_PanoContext-Former_Panoramic_Total_Scene_Understanding_with_a_Transformer_CVPR_2024_paper.html": {
    "title": "PanoContext-Former: Panoramic Total Scene Understanding with a Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Dong",
      "Chuan Fang",
      "Liefeng Bo",
      "Zilong Dong",
      "Ping Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Training-Free_Pretrained_Model_Merging_CVPR_2024_paper.html": {
    "title": "Training-Free Pretrained Model Merging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengqi Xu",
      "Ke Yuan",
      "Huiqiong Wang",
      "Yong Wang",
      "Mingli Song",
      "Jie Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_NC-SDF_Enhancing_Indoor_Scene_Reconstruction_Using_Neural_SDFs_with_View-Dependent_CVPR_2024_paper.html": {
    "title": "NC-SDF: Enhancing Indoor Scene Reconstruction Using Neural SDFs with View-Dependent Normal Compensation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Chen",
      "Xiaolong Wu",
      "Yu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_An_Interactive_Navigation_Method_with_Effect-oriented_Affordance_CVPR_2024_paper.html": {
    "title": "An Interactive Navigation Method with Effect-oriented Affordance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohan Wang",
      "Yuehu Liu",
      "Xinhang Song",
      "Yuyi Liu",
      "Sixian Zhang",
      "Shuqiang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Person_in_Place_Generating_Associative_Skeleton-Guidance_Maps_for_Human-Object_Interaction_CVPR_2024_paper.html": {
    "title": "Person in Place: Generating Associative Skeleton-Guidance Maps for Human-Object Interaction Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "ChangHee Yang",
      "ChanHee Kang",
      "Kyeongbo Kong",
      "Hanni Oh",
      "Suk-Ju Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Flaborea_PREGO_Online_Mistake_Detection_in_PRocedural_EGOcentric_Videos_CVPR_2024_paper.html": {
    "title": "PREGO: Online Mistake Detection in PRocedural EGOcentric Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessandro Flaborea",
      "Guido Maria D'Amely di Melendugno",
      "Leonardo Plini",
      "Luca Scofano",
      "Edoardo De Matteis",
      "Antonino Furnari",
      "Giovanni Maria Farinella",
      "Fabio Galasso"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_ChatPose_Chatting_about_3D_Human_Pose_CVPR_2024_paper.html": {
    "title": "ChatPose: Chatting about 3D Human Pose",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Feng",
      "Jing Lin",
      "Sai Kumar Dwivedi",
      "Yu Sun",
      "Priyanka Patel",
      "Michael J. Black"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Prompt3D_Random_Prompt_Assisted_Weakly-Supervised_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "Prompt3D: Random Prompt Assisted Weakly-Supervised 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohong Zhang",
      "Huisheng Ye",
      "Jingwen Li",
      "Qinyu Tang",
      "Yuanqi Li",
      "Yanwen Guo",
      "Jie Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Logit_Standardization_in_Knowledge_Distillation_CVPR_2024_paper.html": {
    "title": "Logit Standardization in Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangquan Sun",
      "Wenqi Ren",
      "Jingzhi Li",
      "Rui Wang",
      "Xiaochun Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Fine-grained_Prototypical_Voting_with_Heterogeneous_Mixup_for_Semi-supervised_2D-3D_Cross-modal_CVPR_2024_paper.html": {
    "title": "Fine-grained Prototypical Voting with Heterogeneous Mixup for Semi-supervised 2D-3D Cross-modal Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Zhang",
      "Xian-Sheng Hua",
      "Chong Chen",
      "Xiao Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Leak_and_Learn_An_Attackers_Cookbook_to_Train_Using_Leaked_CVPR_2024_paper.html": {
    "title": "Leak and Learn: An Attacker's Cookbook to Train Using Leaked Data from Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua C. Zhao",
      "Ahaan Dabholkar",
      "Atul Sharma",
      "Saurabh Bagchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jeong_OCAI_Improving_Optical_Flow_Estimation_by_Occlusion_and_Consistency_Aware_CVPR_2024_paper.html": {
    "title": "OCAI: Improving Optical Flow Estimation by Occlusion and Consistency Aware Interpolation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jisoo Jeong",
      "Hong Cai",
      "Risheek Garrepalli",
      "Jamie Menjay Lin",
      "Munawar Hayat",
      "Fatih Porikli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Distilling_ODE_Solvers_of_Diffusion_Models_into_Smaller_Steps_CVPR_2024_paper.html": {
    "title": "Distilling ODE Solvers of Diffusion Models into Smaller Steps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanghwan Kim",
      "Hao Tang",
      "Fisher Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Navigating_Beyond_Dropout_An_Intriguing_Solution_towards_Generalizable_Image_Super_CVPR_2024_paper.html": {
    "title": "Navigating Beyond Dropout: An Intriguing Solution towards Generalizable Image Super Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Yinqiang Zheng",
      "Tieyong Zeng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bandyopadhyay_Doodle_Your_3D_From_Abstract_Freehand_Sketches_to_Precise_3D_CVPR_2024_paper.html": {
    "title": "Doodle Your 3D: From Abstract Freehand Sketches to Precise 3D Shapes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hmrishav Bandyopadhyay",
      "Subhadeep Koley",
      "Ayan Das",
      "Ayan Kumar Bhunia",
      "Aneeshan Sain",
      "Pinaki Nath Chowdhury",
      "Tao Xiang",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kocsis_LightIt_Illumination_Modeling_and_Control_for_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "LightIt: Illumination Modeling and Control for Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peter Kocsis",
      "Julien Philip",
      "Kalyan Sunkavalli",
      "Matthias Nießner",
      "Yannick Hold-Geoffroy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Single_View_Refractive_Index_Tomography_with_Neural_Fields_CVPR_2024_paper.html": {
    "title": "Single View Refractive Index Tomography with Neural Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brandon Zhao",
      "Aviad Levis",
      "Liam Connor",
      "Pratul P. Srinivasan",
      "Katherine L. Bouman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Neural_Lineage_CVPR_2024_paper.html": {
    "title": "Neural Lineage",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runpeng Yu",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shabani_Visual_Layout_Composer_Image-Vector_Dual_Diffusion_Model_for_Design_Layout_CVPR_2024_paper.html": {
    "title": "Visual Layout Composer: Image-Vector Dual Diffusion Model for Design Layout Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Amin Shabani",
      "Zhaowen Wang",
      "Difan Liu",
      "Nanxuan Zhao",
      "Jimei Yang",
      "Yasutaka Furukawa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_FC-GNN_Recovering_Reliable_and_Accurate_Correspondences_from_Interferences_CVPR_2024_paper.html": {
    "title": "FC-GNN: Recovering Reliable and Accurate Correspondences from Interferences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haobo Xu",
      "Jun Zhou",
      "Hua Yang",
      "Renjie Pan",
      "Cunyan Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saha_Turb-Seg-Res_A_Segment-then-Restore_Pipeline_for_Dynamic_Videos_with_Atmospheric_Turbulence_CVPR_2024_paper.html": {
    "title": "Turb-Seg-Res: A Segment-then-Restore Pipeline for Dynamic Videos with Atmospheric Turbulence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ripon Kumar Saha",
      "Dehao Qin",
      "Nianyi Li",
      "Jinwei Ye",
      "Suren Jayasuriya"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_Real-time_Acquisition_and_Reconstruction_of_Dynamic_Volumes_with_Neural_Structured_CVPR_2024_paper.html": {
    "title": "Real-time Acquisition and Reconstruction of Dynamic Volumes with Neural Structured Illumination",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Zeng",
      "Zoubin Bi",
      "Mingrui Yin",
      "Xiang Feng",
      "Kun Zhou",
      "Hongzhi Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_3D_Multi-frame_Fusion_for_Video_Stabilization_CVPR_2024_paper.html": {
    "title": "3D Multi-frame Fusion for Video Stabilization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhan Peng",
      "Xinyi Ye",
      "Weiyue Zhao",
      "Tianqi Liu",
      "Huiqiang Sun",
      "Baopu Li",
      "Zhiguo Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Local-consistent_Transformation_Learning_for_Rotation-invariant_Point_Cloud_Analysis_CVPR_2024_paper.html": {
    "title": "Local-consistent Transformation Learning for Rotation-invariant Point Cloud Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyang Chen",
      "Lunhao Duan",
      "Shanshan Zhao",
      "Changxing Ding",
      "Dacheng Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Tailored_Visions_Enhancing_Text-to-Image_Generation_with_Personalized_Prompt_Rewriting_CVPR_2024_paper.html": {
    "title": "Tailored Visions: Enhancing Text-to-Image Generation with Personalized Prompt Rewriting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijie Chen",
      "Lichao Zhang",
      "Fangsheng Weng",
      "Lili Pan",
      "Zhenzhong Lan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiong_Efficient_Deformable_ConvNets_Rethinking_Dynamic_and_Sparse_Operator_for_Vision_CVPR_2024_paper.html": {
    "title": "Efficient Deformable ConvNets: Rethinking Dynamic and Sparse Operator for Vision Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwen Xiong",
      "Zhiqi Li",
      "Yuntao Chen",
      "Feng Wang",
      "Xizhou Zhu",
      "Jiapeng Luo",
      "Wenhai Wang",
      "Tong Lu",
      "Hongsheng Li",
      "Yu Qiao",
      "Lewei Lu",
      "Jie Zhou",
      "Jifeng Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_CoDe_An_Explicit_Content_Decoupling_Framework_for_Image_Restoration_CVPR_2024_paper.html": {
    "title": "CoDe: An Explicit Content Decoupling Framework for Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enxuan Gu",
      "Hongwei Ge",
      "Yong Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_XFibrosis_Explicit_Vessel-Fiber_Modeling_for_Fibrosis_Staging_from_Liver_Pathology_CVPR_2024_paper.html": {
    "title": "XFibrosis: Explicit Vessel-Fiber Modeling for Fibrosis Staging from Liver Pathology Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Yin",
      "Siqi Liu",
      "Fei Lyu",
      "Jiahao Lu",
      "Sune Darkner",
      "Vincent Wai-Sun Wong",
      "Pong C. Yuen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Agro_UnO_Unsupervised_Occupancy_Fields_for_Perception_and_Forecasting_CVPR_2024_paper.html": {
    "title": "UnO: Unsupervised Occupancy Fields for Perception and Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Agro",
      "Quinlan Sykora",
      "Sergio Casas",
      "Thomas Gilles",
      "Raquel Urtasun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SpatialVLM_Endowing_Vision-Language_Models_with_Spatial_Reasoning_Capabilities_CVPR_2024_paper.html": {
    "title": "SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyuan Chen",
      "Zhuo Xu",
      "Sean Kirmani",
      "Brain Ichter",
      "Dorsa Sadigh",
      "Leonidas Guibas",
      "Fei Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Geng_InstructDiffusion_A_Generalist_Modeling_Interface_for_Vision_Tasks_CVPR_2024_paper.html": {
    "title": "InstructDiffusion: A Generalist Modeling Interface for Vision Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zigang Geng",
      "Binxin Yang",
      "Tiankai Hang",
      "Chen Li",
      "Shuyang Gu",
      "Ting Zhang",
      "Jianmin Bao",
      "Zheng Zhang",
      "Houqiang Li",
      "Han Hu",
      "Dong Chen",
      "Baining Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_DreamVideo_Composing_Your_Dream_Videos_with_Customized_Subject_and_Motion_CVPR_2024_paper.html": {
    "title": "DreamVideo: Composing Your Dream Videos with Customized Subject and Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujie Wei",
      "Shiwei Zhang",
      "Zhiwu Qing",
      "Hangjie Yuan",
      "Zhiheng Liu",
      "Yu Liu",
      "Yingya Zhang",
      "Jingren Zhou",
      "Hongming Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ramazzina_Gated_Fields_Learning_Scene_Reconstruction_from_Gated_Videos_CVPR_2024_paper.html": {
    "title": "Gated Fields: Learning Scene Reconstruction from Gated Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Ramazzina",
      "Stefanie Walz",
      "Pragyan Dahal",
      "Mario Bijelic",
      "Felix Heide"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bang_RadarDistill_Boosting_Radar-based_Object_Detection_Performance_via_Knowledge_Distillation_from_CVPR_2024_paper.html": {
    "title": "RadarDistill: Boosting Radar-based Object Detection Performance via Knowledge Distillation from LiDAR Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geonho Bang",
      "Kwangjin Choi",
      "Jisong Kim",
      "Dongsuk Kum",
      "Jun Won Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zaech_Probabilistic_Sampling_of_Balanced_K-Means_using_Adiabatic_Quantum_Computing_CVPR_2024_paper.html": {
    "title": "Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan-Nico Zaech",
      "Martin Danelljan",
      "Tolga Birdal",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Diao_UniPT_Universal_Parallel_Tuning_for_Transfer_Learning_with_Efficient_Parameter_CVPR_2024_paper.html": {
    "title": "UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiwen Diao",
      "Bo Wan",
      "Ying Zhang",
      "Xu Jia",
      "Huchuan Lu",
      "Long Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Thawakar_Composed_Video_Retrieval_via_Enriched_Context_and_Discriminative_Embeddings_CVPR_2024_paper.html": {
    "title": "Composed Video Retrieval via Enriched Context and Discriminative Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omkar Thawakar",
      "Muzammal Naseer",
      "Rao Muhammad Anwer",
      "Salman Khan",
      "Michael Felsberg",
      "Mubarak Shah",
      "Fahad Shahbaz Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Using_Human_Feedback_to_Fine-tune_Diffusion_Models_without_Any_Reward_CVPR_2024_paper.html": {
    "title": "Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Yang",
      "Jian Tao",
      "Jiafei Lyu",
      "Chunjiang Ge",
      "Jiaxin Chen",
      "Weihan Shen",
      "Xiaolong Zhu",
      "Xiu Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Perceptual_Assessment_and_Optimization_of_HDR_Image_Rendering_CVPR_2024_paper.html": {
    "title": "Perceptual Assessment and Optimization of HDR Image Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peibei Cao",
      "Rafal K. Mantiuk",
      "Kede Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dutta_Multiview_Aerial_Visual_RECognition_MAVREC_Can_Multi-view_Improve_Aerial_Visual_CVPR_2024_paper.html": {
    "title": "Multiview Aerial Visual RECognition (MAVREC): Can Multi-view Improve Aerial Visual Perception?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aritra Dutta",
      "Srijan Das",
      "Jacob Nielsen",
      "Rajatsubhra Chakraborty",
      "Mubarak Shah"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Diffusion-driven_GAN_Inversion_for_Multi-Modal_Face_Image_Generation_CVPR_2024_paper.html": {
    "title": "Diffusion-driven GAN Inversion for Multi-Modal Face Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihyun Kim",
      "Changjae Oh",
      "Hoseok Do",
      "Soohyun Kim",
      "Kwanghoon Sohn"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Low-Rank_Knowledge_Decomposition_for_Medical_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Low-Rank Knowledge Decomposition for Medical Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang Zhou",
      "Haolin Li",
      "Siyuan Du",
      "Jiangchao Yao",
      "Ya Zhang",
      "Yanfeng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_SaCo_Loss_Sample-wise_Affinity_Consistency_for_Vision-Language_Pre-training_CVPR_2024_paper.html": {
    "title": "SaCo Loss: Sample-wise Affinity Consistency for Vision-Language Pre-training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sitong Wu",
      "Haoru Tan",
      "Zhuotao Tian",
      "Yukang Chen",
      "Xiaojuan Qi",
      "Jiaya Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cui_Steganographic_Passport_An_Owner_and_User_Verifiable_Credential_for_Deep_CVPR_2024_paper.html": {
    "title": "Steganographic Passport: An Owner and User Verifiable Credential for Deep Model IP Protection Without Retraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Cui",
      "Ruohan Meng",
      "Chaohui Xu",
      "Chip-Hong Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Stable_Neighbor_Denoising_for_Source-free_Domain_Adaptive_Segmentation_CVPR_2024_paper.html": {
    "title": "Stable Neighbor Denoising for Source-free Domain Adaptive Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Zhao",
      "Shuang Wang",
      "Qi Zang",
      "Licheng Jiao",
      "Nicu Sebe",
      "Zhun Zhong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_SynSP_Synergy_of_Smoothness_and_Precision_in_Pose_Sequences_Refinement_CVPR_2024_paper.html": {
    "title": "SynSP: Synergy of Smoothness and Precision in Pose Sequences Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wang",
      "Lei Jin",
      "Zheng Wang",
      "Jianshu Li",
      "Liang Li",
      "Fang Zhao",
      "Yu Cheng",
      "Li Yuan",
      "Li Zhou",
      "Junliang Xing",
      "Jian Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Men_En3D_An_Enhanced_Generative_Model_for_Sculpting_3D_Humans_from_CVPR_2024_paper.html": {
    "title": "En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifang Men",
      "Biwen Lei",
      "Yuan Yao",
      "Miaomiao Cui",
      "Zhouhui Lian",
      "Xuansong Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_Neural_Visibility_Field_for_Uncertainty-Driven_Active_Mapping_CVPR_2024_paper.html": {
    "title": "Neural Visibility Field for Uncertainty-Driven Active Mapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangjie Xue",
      "Jesse Dill",
      "Pranay Mathur",
      "Frank Dellaert",
      "Panagiotis Tsiotra",
      "Danfei Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Tri-Perspective_View_Decomposition_for_Geometry-Aware_Depth_Completion_CVPR_2024_paper.html": {
    "title": "Tri-Perspective View Decomposition for Geometry-Aware Depth Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiqiang Yan",
      "Yuankai Lin",
      "Kun Wang",
      "Yupeng Zheng",
      "Yufei Wang",
      "Zhenyu Zhang",
      "Jun Li",
      "Jian Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_Boosting_Adversarial_Training_via_Fisher-Rao_Norm-based_Regularization_CVPR_2024_paper.html": {
    "title": "Boosting Adversarial Training via Fisher-Rao Norm-based Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Yin",
      "Wenjie Ruan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Graikos_Learned_Representation-Guided_Diffusion_Models_for_Large-Image_Generation_CVPR_2024_paper.html": {
    "title": "Learned Representation-Guided Diffusion Models for Large-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandros Graikos",
      "Srikar Yellapragada",
      "Minh-Quan Le",
      "Saarthak Kapse",
      "Prateek Prasanna",
      "Joel Saltz",
      "Dimitris Samaras"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pelhan_DAVE_-_A_Detect-and-Verify_Paradigm_for_Low-Shot_Counting_CVPR_2024_paper.html": {
    "title": "DAVE - A Detect-and-Verify Paradigm for Low-Shot Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jer Pelhan",
      "Alan Lukeži?",
      "Vitjan Zavrtanik",
      "Matej Kristan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_Ranni_Taming_Text-to-Image_Diffusion_for_Accurate_Instruction_Following_CVPR_2024_paper.html": {
    "title": "Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutong Feng",
      "Biao Gong",
      "Di Chen",
      "Yujun Shen",
      "Yu Liu",
      "Jingren Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Seo_Relaxed_Contrastive_Learning_for_Federated_Learning_CVPR_2024_paper.html": {
    "title": "Relaxed Contrastive Learning for Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seonguk Seo",
      "Jinkyu Kim",
      "Geeho Kim",
      "Bohyung Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Direct2.5_Diverse_Text-to-3D_Generation_via_Multi-view_2.5D_Diffusion_CVPR_2024_paper.html": {
    "title": "Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanxun Lu",
      "Jingyang Zhang",
      "Shiwei Li",
      "Tian Fang",
      "David McKinnon",
      "Yanghai Tsin",
      "Long Quan",
      "Xun Cao",
      "Yao Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Efficient_LoFTR_Semi-Dense_Local_Feature_Matching_with_Sparse-Like_Speed_CVPR_2024_paper.html": {
    "title": "Efficient LoFTR: Semi-Dense Local Feature Matching with Sparse-Like Speed",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Wang",
      "Xingyi He",
      "Sida Peng",
      "Dongli Tan",
      "Xiaowei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_Contextual_Augmented_Global_Contrast_for_Multimodal_Intent_Recognition_CVPR_2024_paper.html": {
    "title": "Contextual Augmented Global Contrast for Multimodal Intent Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaili Sun",
      "Zhiwen Xie",
      "Mang Ye",
      "Huyin Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Pre-trained_Model_Guided_Fine-Tuning_for_Zero-Shot_Adversarial_Robustness_CVPR_2024_paper.html": {
    "title": "Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial Robustness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sibo Wang",
      "Jie Zhang",
      "Zheng Yuan",
      "Shiguang Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vecchio_MatFuse_Controllable_Material_Generation_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "MatFuse: Controllable Material Generation with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuseppe Vecchio",
      "Renato Sortino",
      "Simone Palazzo",
      "Concetto Spampinato"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_CoGS_Controllable_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "CoGS: Controllable Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heng Yu",
      "Joel Julin",
      "Zoltán A. Milacski",
      "Koichiro Niinuma",
      "László A. Jeni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ehm_Partial-to-Partial_Shape_Matching_with_Geometric_Consistency_CVPR_2024_paper.html": {
    "title": "Partial-to-Partial Shape Matching with Geometric Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Viktoria Ehm",
      "Maolin Gao",
      "Paul Roetzer",
      "Marvin Eisenberger",
      "Daniel Cremers",
      "Florian Bernard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liao_Descriptor_and_Word_Soups_Overcoming_the_Parameter_Efficiency_Accuracy_Tradeoff_CVPR_2024_paper.html": {
    "title": "Descriptor and Word Soups: Overcoming the Parameter Efficiency Accuracy Tradeoff for Out-of-Distribution Few-shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christopher Liao",
      "Theodoros Tsiligkaridis",
      "Brian Kulis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Harnessing_the_Power_of_MLLMs_for_Transferable_Text-to-Image_Person_ReID_CVPR_2024_paper.html": {
    "title": "Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentan Tan",
      "Changxing Ding",
      "Jiayu Jiang",
      "Fei Wang",
      "Yibing Zhan",
      "Dapeng Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_360x_A_Panoptic_Multi-modal_Scene_Understanding_Dataset_CVPR_2024_paper.html": {
    "title": "360+x: A Panoptic Multi-modal Scene Understanding Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Chen",
      "Yuqi Hou",
      "Chenyuan Qu",
      "Irene Testini",
      "Xiaohan Hong",
      "Jianbo Jiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Weakly_Supervised_Video_Individual_Counting_CVPR_2024_paper.html": {
    "title": "Weakly Supervised Video Individual Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyan Liu",
      "Guorong Li",
      "Yuankai Qi",
      "Ziheng Yan",
      "Zhenjun Han",
      "Anton van den Hengel",
      "Ming-Hsuan Yang",
      "Qingming Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Gaussian_Shading_Provable_Performance-Lossless_Image_Watermarking_for_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijin Yang",
      "Kai Zeng",
      "Kejiang Chen",
      "Han Fang",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sundar_Generalized_Event_Cameras_CVPR_2024_paper.html": {
    "title": "Generalized Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Varun Sundar",
      "Matthew Dutson",
      "Andrei Ardelean",
      "Claudio Bruschini",
      "Edoardo Charbon",
      "Mohit Gupta"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_3D_Neural_Edge_Reconstruction_CVPR_2024_paper.html": {
    "title": "3D Neural Edge Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Li",
      "Songyou Peng",
      "Zehao Yu",
      "Shaohui Liu",
      "Rémi Pautrat",
      "Xiaochuan Yin",
      "Marc Pollefeys"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_DocRes_A_Generalist_Model_Toward_Unifying_Document_Image_Restoration_Tasks_CVPR_2024_paper.html": {
    "title": "DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Zhang",
      "Dezhi Peng",
      "Chongyu Liu",
      "Peirong Zhang",
      "Lianwen Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cha_Honeybee_Locality-enhanced_Projector_for_Multimodal_LLM_CVPR_2024_paper.html": {
    "title": "Honeybee: Locality-enhanced Projector for Multimodal LLM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junbum Cha",
      "Wooyoung Kang",
      "Jonghwan Mun",
      "Byungseok Roh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lochman_Learned_Trajectory_Embedding_for_Subspace_Clustering_CVPR_2024_paper.html": {
    "title": "Learned Trajectory Embedding for Subspace Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaroslava Lochman",
      "Carl Olsson",
      "Christopher Zach"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Training_Vision_Transformers_for_Semi-Supervised_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Training Vision Transformers for Semi-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinting Hu",
      "Li Jiang",
      "Bernt Schiele"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Woo_HarmonyView_Harmonizing_Consistency_and_Diversity_in_One-Image-to-3D_CVPR_2024_paper.html": {
    "title": "HarmonyView: Harmonizing Consistency and Diversity in One-Image-to-3D",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangmin Woo",
      "Byeongjun Park",
      "Hyojun Go",
      "Jin-Young Kim",
      "Changick Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_DGC-GNN_Leveraging_Geometry_and_Color_Cues_for_Visual_Descriptor-Free_2D-3D_CVPR_2024_paper.html": {
    "title": "DGC-GNN: Leveraging Geometry and Color Cues for Visual Descriptor-Free 2D-3D Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuzhe Wang",
      "Juho Kannala",
      "Daniel Barath"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Arica_CuVLER_Enhanced_Unsupervised_Object_Discoveries_through_Exhaustive_Self-Supervised_Transformers_CVPR_2024_paper.html": {
    "title": "CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shahaf Arica",
      "Or Rubin",
      "Sapir Gershov",
      "Shlomi Laufer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jeong_Quantifying_Task_Priority_for_Multi-Task_Optimization_CVPR_2024_paper.html": {
    "title": "Quantifying Task Priority for Multi-Task Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wooseong Jeong",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_UnSAMFlow_Unsupervised_Optical_Flow_Guided_by_Segment_Anything_Model_CVPR_2024_paper.html": {
    "title": "UnSAMFlow: Unsupervised Optical Flow Guided by Segment Anything Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Yuan",
      "Lei Luo",
      "Zhuo Hui",
      "Can Pu",
      "Xiaoyu Xiang",
      "Rakesh Ranjan",
      "Denis Demandolx"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_Exploiting_Inter-sample_and_Inter-feature_Relations_in_Dataset_Distillation_CVPR_2024_paper.html": {
    "title": "Exploiting Inter-sample and Inter-feature Relations in Dataset Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxiao Deng",
      "Wenbin Li",
      "Tianyu Ding",
      "Lei Wang",
      "Hongguang Zhang",
      "Kuihua Huang",
      "Jing Huo",
      "Yang Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_On_the_Scalability_of_Diffusion-based_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "On the Scalability of Diffusion-based Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Li",
      "Yang Zou",
      "Ying Wang",
      "Orchid Majumder",
      "Yusheng Xie",
      "R. Manmatha",
      "Ashwin Swaminathan",
      "Zhuowen Tu",
      "Stefano Ermon",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Otonari_Entity-NeRF_Detecting_and_Removing_Moving_Entities_in_Urban_Scenes_CVPR_2024_paper.html": {
    "title": "Entity-NeRF: Detecting and Removing Moving Entities in Urban Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takashi Otonari",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_TAMM_TriAdapter_Multi-Modal_Learning_for_3D_Shape_Understanding_CVPR_2024_paper.html": {
    "title": "TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Zhang",
      "Shengcao Cao",
      "Yu-Xiong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_GauHuman_Articulated_Gaussian_Splatting_from_Monocular_Human_Videos_CVPR_2024_paper.html": {
    "title": "GauHuman: Articulated Gaussian Splatting from Monocular Human Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shoukang Hu",
      "Tao Hu",
      "Ziwei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cui_AnySkill_Learning_Open-Vocabulary_Physical_Skill_for_Interactive_Agents_CVPR_2024_paper.html": {
    "title": "AnySkill: Learning Open-Vocabulary Physical Skill for Interactive Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jieming Cui",
      "Tengyu Liu",
      "Nian Liu",
      "Yaodong Yang",
      "Yixin Zhu",
      "Siyuan Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Im_EGTR_Extracting_Graph_from_Transformer_for_Scene_Graph_Generation_CVPR_2024_paper.html": {
    "title": "EGTR: Extracting Graph from Transformer for Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinbae Im",
      "JeongYeon Nam",
      "Nokyung Park",
      "Hyungmin Lee",
      "Seunghyun Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Seo_Generative_Unlearning_for_Any_Identity_CVPR_2024_paper.html": {
    "title": "Generative Unlearning for Any Identity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juwon Seo",
      "Sung-Hoon Lee",
      "Tae-Young Lee",
      "Seungjun Moon",
      "Gyeong-Moon Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Context-based_and_Diversity-driven_Specificity_in_Compositional_Zero-Shot_Learning_CVPR_2024_paper.html": {
    "title": "Context-based and Diversity-driven Specificity in Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun Li",
      "Zhe Liu",
      "Hang Chen",
      "Lina Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_FlowVid_Taming_Imperfect_Optical_Flows_for_Consistent_Video-to-Video_Synthesis_CVPR_2024_paper.html": {
    "title": "FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Liang",
      "Bichen Wu",
      "Jialiang Wang",
      "Licheng Yu",
      "Kunpeng Li",
      "Yinan Zhao",
      "Ishan Misra",
      "Jia-Bin Huang",
      "Peizhao Zhang",
      "Peter Vajda",
      "Diana Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Choi_StyleCineGAN_Landscape_Cinemagraph_Generation_using_a_Pre-trained_StyleGAN_CVPR_2024_paper.html": {
    "title": "StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongwoo Choi",
      "Kwanggyoon Seo",
      "Amirsaman Ashtari",
      "Junyong Noh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_Rethinking_Multi-domain_Generalization_with_A_General_Learning_Objective_CVPR_2024_paper.html": {
    "title": "Rethinking Multi-domain Generalization with A General Learning Objective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaorui Tan",
      "Xi Yang",
      "Kaizhu Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Khoshkhahtinat_Laplacian-guided_Entropy_Model_in_Neural_Codec_with_Blur-dissipated_Synthesis_CVPR_2024_paper.html": {
    "title": "Laplacian-guided Entropy Model in Neural Codec with Blur-dissipated Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atefeh Khoshkhahtinat",
      "Ali Zafari",
      "Piyush M. Mehta",
      "Nasser M. Nasrabadi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mirzaei_Universal_Novelty_Detection_Through_Adaptive_Contrastive_Learning_CVPR_2024_paper.html": {
    "title": "Universal Novelty Detection Through Adaptive Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hossein Mirzaei",
      "Mojtaba Nafez",
      "Mohammad Jafari",
      "Mohammad Bagher Soltani",
      "Mohammad Azizmalayeri",
      "Jafar Habibi",
      "Mohammad Sabokrou",
      "Mohammad Hossein Rohban"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Rethinking_Diffusion_Model_for_Multi-Contrast_MRI_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Rethinking Diffusion Model for Multi-Contrast MRI Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyuan Li",
      "Chen Rao",
      "Juncheng Mo",
      "Zhanjie Zhang",
      "Wei Xing",
      "Lei Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Goswami_Resurrecting_Old_Classes_with_New_Data_for_Exemplar-Free_Continual_Learning_CVPR_2024_paper.html": {
    "title": "Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dipam Goswami",
      "Albin Soutif-Cormerais",
      "Yuyang Liu",
      "Sandesh Kamath",
      "Bart?omiej Twardowski",
      "Joost van de Weijer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Singha_Unknown_Prompt_the_only_Lacuna_Unveiling_CLIPs_Potential_for_Open_CVPR_2024_paper.html": {
    "title": "Unknown Prompt the only Lacuna: Unveiling CLIP's Potential for Open Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mainak Singha",
      "Ankit Jha",
      "Shirsha Bose",
      "Ashwin Nair",
      "Moloud Abdar",
      "Biplab Banerjee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Poly_Kernel_Inception_Network_for_Remote_Sensing_Detection_CVPR_2024_paper.html": {
    "title": "Poly Kernel Inception Network for Remote Sensing Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinhao Cai",
      "Qiuxia Lai",
      "Yuwei Wang",
      "Wenguan Wang",
      "Zeren Sun",
      "Yazhou Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_RMT_Retentive_Networks_Meet_Vision_Transformers_CVPR_2024_paper.html": {
    "title": "RMT: Retentive Networks Meet Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qihang Fan",
      "Huaibo Huang",
      "Mingrui Chen",
      "Hongmin Liu",
      "Ran He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lang_From_Coarse_to_Fine-Grained_Open-Set_Recognition_CVPR_2024_paper.html": {
    "title": "From Coarse to Fine-Grained Open-Set Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nico Lang",
      "Vésteinn Snæbjarnarson",
      "Elijah Cole",
      "Oisin Mac Aodha",
      "Christian Igel",
      "Serge Belongie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Multimodal_Pathway_Improve_Transformers_with_Irrelevant_Data_from_Other_Modalities_CVPR_2024_paper.html": {
    "title": "Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyuan Zhang",
      "Xiaohan Ding",
      "Kaixiong Gong",
      "Yixiao Ge",
      "Ying Shan",
      "Xiangyu Yue"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_FaceChain-ImagineID_Freely_Crafting_High-Fidelity_Diverse_Talking_Faces_from_Disentangled_Audio_CVPR_2024_paper.html": {
    "title": "FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces from Disentangled Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chao Xu",
      "Yang Liu",
      "Jiazheng Xing",
      "Weida Wang",
      "Mingze Sun",
      "Jun Dan",
      "Tianxin Huang",
      "Siyuan Li",
      "Zhi-Qi Cheng",
      "Ying Tai",
      "Baigui Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_OmniViD_A_Generative_Framework_for_Universal_Video_Understanding_CVPR_2024_paper.html": {
    "title": "OmniViD: A Generative Framework for Universal Video Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junke Wang",
      "Dongdong Chen",
      "Chong Luo",
      "Bo He",
      "Lu Yuan",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_Naturally_Supervised_3D_Visual_Grounding_with_Language-Regularized_Concept_Learners_CVPR_2024_paper.html": {
    "title": "Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chun Feng",
      "Joy Hsu",
      "Weiyu Liu",
      "Jiajun Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_SSR-Encoder_Encoding_Selective_Subject_Representation_for_Subject-Driven_Generation_CVPR_2024_paper.html": {
    "title": "SSR-Encoder: Encoding Selective Subject Representation for Subject-Driven Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Zhang",
      "Yiren Song",
      "Jiaming Liu",
      "Rui Wang",
      "Jinpeng Yu",
      "Hao Tang",
      "Huaxia Li",
      "Xu Tang",
      "Yao Hu",
      "Han Pan",
      "Zhongliang Jing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_CA-Jaccard_Camera-aware_Jaccard_Distance_for_Person_Re-identification_CVPR_2024_paper.html": {
    "title": "CA-Jaccard: Camera-aware Jaccard Distance for Person Re-identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyu Chen",
      "Zheyi Fan",
      "Zhaoru Chen",
      "Yixuan Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Dual_Prior_Unfolding_for_Snapshot_Compressive_Imaging_CVPR_2024_paper.html": {
    "title": "Dual Prior Unfolding for Snapshot Compressive Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiancheng Zhang",
      "Haijin Zeng",
      "Jiezhang Cao",
      "Yongyong Chen",
      "Dengxiu Yu",
      "Yin-Ping Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fu_COLMAP-Free_3D_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "COLMAP-Free 3D Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Fu",
      "Sifei Liu",
      "Amey Kulkarni",
      "Jan Kautz",
      "Alexei A. Efros",
      "Xiaolong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_MVIP-NeRF_Multi-view_3D_Inpainting_on_NeRF_Scenes_via_Diffusion_Prior_CVPR_2024_paper.html": {
    "title": "MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via Diffusion Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Honghua Chen",
      "Chen Change Loy",
      "Xingang Pan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_StegoGAN_Leveraging_Steganography_for_Non-Bijective_Image-to-Image_Translation_CVPR_2024_paper.html": {
    "title": "StegoGAN: Leveraging Steganography for Non-Bijective Image-to-Image Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sidi Wu",
      "Yizi Chen",
      "Samuel Mermet",
      "Lorenz Hurni",
      "Konrad Schindler",
      "Nicolas Gonthier",
      "Loic Landrieu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_MM_VTO_Multi-Garment_Virtual_Try-On_and_Editing_CVPR_2024_paper.html": {
    "title": "M&M VTO: Multi-Garment Virtual Try-On and Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luyang Zhu",
      "Yingwei Li",
      "Nan Liu",
      "Hao Peng",
      "Dawei Yang",
      "Ira Kemelmacher-Shlizerman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_AutoAD_III_The_Prequel_-_Back_to_the_Pixels_CVPR_2024_paper.html": {
    "title": "AutoAD III: The Prequel - Back to the Pixels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tengda Han",
      "Max Bain",
      "Arsha Nagrani",
      "Gül Varol",
      "Weidi Xie",
      "Andrew Zisserman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Characteristics_Matching_Based_Hash_Codes_Generation_for_Efficient_Fine-grained_Image_CVPR_2024_paper.html": {
    "title": "Characteristics Matching Based Hash Codes Generation for Efficient Fine-grained Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen-Duo Chen",
      "Li-Jun Zhao",
      "Zi-Chao Zhang",
      "Xin Luo",
      "Xin-Shun Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_BadCLIP_Dual-Embedding_Guided_Backdoor_Attack_on_Multimodal_Contrastive_Learning_CVPR_2024_paper.html": {
    "title": "BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Liang",
      "Mingli Zhu",
      "Aishan Liu",
      "Baoyuan Wu",
      "Xiaochun Cao",
      "Ee-Chien Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Dynamic_Inertial_Poser_DynaIP_Part-Based_Motion_Dynamics_Learning_for_Enhanced_CVPR_2024_paper.html": {
    "title": "Dynamic Inertial Poser (DynaIP): Part-Based Motion Dynamics Learning for Enhanced Human Pose Estimation with Sparse Inertial Sensors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Zhang",
      "Songpengcheng Xia",
      "Lei Chu",
      "Jiarui Yang",
      "Qi Wu",
      "Ling Pei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Barroso-Laguna_Matching_2D_Images_in_3D_Metric_Relative_Pose_from_Metric_CVPR_2024_paper.html": {
    "title": "Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Axel Barroso-Laguna",
      "Sowmya Munukutla",
      "Victor Adrian Prisacariu",
      "Eric Brachmann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_Efficient_Vision-Language_Pre-training_by_Cluster_Masking_CVPR_2024_paper.html": {
    "title": "Efficient Vision-Language Pre-training by Cluster Masking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Wei",
      "Zixuan Pan",
      "Andrew Owens"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_GraCo_Granularity-Controllable_Interactive_Segmentation_CVPR_2024_paper.html": {
    "title": "GraCo: Granularity-Controllable Interactive Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yian Zhao",
      "Kehan Li",
      "Zesen Cheng",
      "Pengchong Qiao",
      "Xiawu Zheng",
      "Rongrong Ji",
      "Chang Liu",
      "Li Yuan",
      "Jie Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pu_M3-UDA_A_New_Benchmark_for_Unsupervised_Domain_Adaptive_Fetal_Cardiac_CVPR_2024_paper.html": {
    "title": "M3-UDA: A New Benchmark for Unsupervised Domain Adaptive Fetal Cardiac Structure Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Pu",
      "Liwen Wang",
      "Jiewen Yang",
      "Guannan He",
      "Xingbo Dong",
      "Shengli Li",
      "Ying Tan",
      "Ming Chen",
      "Zhe Jin",
      "Kenli Li",
      "Xiaomeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_GPS-Gaussian_Generalizable_Pixel-wise_3D_Gaussian_Splatting_for_Real-time_Human_Novel_CVPR_2024_paper.html": {
    "title": "GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shunyuan Zheng",
      "Boyao Zhou",
      "Ruizhi Shao",
      "Boning Liu",
      "Shengping Zhang",
      "Liqiang Nie",
      "Yebin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jin_Chat-UniVi_Unified_Visual_Representation_Empowers_Large_Language_Models_with_Image_CVPR_2024_paper.html": {
    "title": "Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Jin",
      "Ryuichi Takanobu",
      "Wancai Zhang",
      "Xiaochun Cao",
      "Li Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Burgert_MAGICK_A_Large-scale_Captioned_Dataset_from_Matting_Generated_Images_using_CVPR_2024_paper.html": {
    "title": "MAGICK: A Large-scale Captioned Dataset from Matting Generated Images using Chroma Keying",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryan D. Burgert",
      "Brian L. Price",
      "Jason Kuen",
      "Yijun Li",
      "Michael S. Ryoo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Video_Super-Resolution_Transformer_with_Masked_InterIntra-Frame_Attention_CVPR_2024_paper.html": {
    "title": "Video Super-Resolution Transformer with Masked Inter&Intra-Frame Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyu Zhou",
      "Leheng Zhang",
      "Xiaorui Zhao",
      "Keze Wang",
      "Leida Li",
      "Shuhang Gu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Token_Transformation_Matters_Towards_Faithful_Post-hoc_Explanation_for_Vision_Transformer_CVPR_2024_paper.html": {
    "title": "Token Transformation Matters: Towards Faithful Post-hoc Explanation for Vision Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Wu",
      "Bin Duan",
      "Weitai Kang",
      "Hao Tang",
      "Yan Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_Bayesian_Differentiable_Physics_for_Cloth_Digitalization_CVPR_2024_paper.html": {
    "title": "Bayesian Differentiable Physics for Cloth Digitalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Deshan Gong",
      "Ningtao Mao",
      "He Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_G-HOP_Generative_Hand-Object_Prior_for_Interaction_Reconstruction_and_Grasp_Synthesis_CVPR_2024_paper.html": {
    "title": "G-HOP: Generative Hand-Object Prior for Interaction Reconstruction and Grasp Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Ye",
      "Abhinav Gupta",
      "Kris Kitani",
      "Shubham Tulsiani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Higher-order_Relational_Reasoning_for_Pedestrian_Trajectory_Prediction_CVPR_2024_paper.html": {
    "title": "Higher-order Relational Reasoning for Pedestrian Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungjune Kim",
      "Hyung-gun Chi",
      "Hyerin Lim",
      "Karthik Ramani",
      "Jinkyu Kim",
      "Sangpil Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_SurroundSDF_Implicit_3D_Scene_Understanding_Based_on_Signed_Distance_Field_CVPR_2024_paper.html": {
    "title": "SurroundSDF: Implicit 3D Scene Understanding Based on Signed Distance Field",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lizhe Liu",
      "Bohua Wang",
      "Hongwei Xie",
      "Daqi Liu",
      "Li Liu",
      "Zhiqiang Tian",
      "Kuiyuan Yang",
      "Bing Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nam_Contrastive_Denoising_Score_for_Text-guided_Latent_Diffusion_Image_Editing_CVPR_2024_paper.html": {
    "title": "Contrastive Denoising Score for Text-guided Latent Diffusion Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyelin Nam",
      "Gihyun Kwon",
      "Geon Yeong Park",
      "Jong Chul Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Schroppel_Neural_Point_Cloud_Diffusion_for_Disentangled_3D_Shape_and_Appearance_CVPR_2024_paper.html": {
    "title": "Neural Point Cloud Diffusion for Disentangled 3D Shape and Appearance Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp Schröppel",
      "Christopher Wewer",
      "Jan Eric Lenssen",
      "Eddy Ilg",
      "Thomas Brox"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_RealNet_A_Feature_Selection_Network_with_Realistic_Synthetic_Anomaly_for_CVPR_2024_paper.html": {
    "title": "RealNet: A Feature Selection Network with Realistic Synthetic Anomaly for Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ximiao Zhang",
      "Min Xu",
      "Xiuzhuang Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Outdoor_Scene_Extrapolation_with_Hierarchical_Generative_Cellular_Automata_CVPR_2024_paper.html": {
    "title": "Outdoor Scene Extrapolation with Hierarchical Generative Cellular Automata",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongsu Zhang",
      "Francis Williams",
      "Zan Gojcic",
      "Karsten Kreis",
      "Sanja Fidler",
      "Young Min Kim",
      "Amlan Kar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mou_Instruct_4D-to-4D_Editing_4D_Scenes_as_Pseudo-3D_Scenes_Using_2D_CVPR_2024_paper.html": {
    "title": "Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linzhan Mou",
      "Jun-Kun Chen",
      "Yu-Xiong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zuffi_VAREN_Very_Accurate_and_Realistic_Equine_Network_CVPR_2024_paper.html": {
    "title": "VAREN: Very Accurate and Realistic Equine Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Silvia Zuffi",
      "Ylva Mellbin",
      "Ci Li",
      "Markus Hoeschle",
      "Hedvig Kjellström",
      "Senya Polikovsky",
      "Elin Hernlund",
      "Michael J. Black"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Photo-SLAM_Real-time_Simultaneous_Localization_and_Photorealistic_Mapping_for_Monocular_Stereo_CVPR_2024_paper.html": {
    "title": "Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular Stereo and RGB-D Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huajian Huang",
      "Longwei Li",
      "Hui Cheng",
      "Sai-Kit Yeung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_SD-DiT_Unleashing_the_Power_of_Self-supervised_Discrimination_in_Diffusion_Transformer_CVPR_2024_paper.html": {
    "title": "SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rui Zhu",
      "Yingwei Pan",
      "Yehao Li",
      "Ting Yao",
      "Zhenglong Sun",
      "Tao Mei",
      "Chang Wen Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Multi-modal_Instruction_Tuned_LLMs_with_Fine-grained_Visual_Perception_CVPR_2024_paper.html": {
    "title": "Multi-modal Instruction Tuned LLMs with Fine-grained Visual Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwen He",
      "Yifan Wang",
      "Lijun Wang",
      "Huchuan Lu",
      "Jun-Yan He",
      "Jin-Peng Lan",
      "Bin Luo",
      "Xuansong Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_ProMotion_Prototypes_As_Motion_Learners_CVPR_2024_paper.html": {
    "title": "ProMotion: Prototypes As Motion Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yawen Lu",
      "Dongfang Liu",
      "Qifan Wang",
      "Cheng Han",
      "Yiming Cui",
      "Zhiwen Cao",
      "Xueling Zhang",
      "Yingjie Victor Chen",
      "Heng Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_SpatialTracker_Tracking_Any_2D_Pixels_in_3D_Space_CVPR_2024_paper.html": {
    "title": "SpatialTracker: Tracking Any 2D Pixels in 3D Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxi Xiao",
      "Qianqian Wang",
      "Shangzhan Zhang",
      "Nan Xue",
      "Sida Peng",
      "Yujun Shen",
      "Xiaowei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_LaMPilot_An_Open_Benchmark_Dataset_for_Autonomous_Driving_with_Language_CVPR_2024_paper.html": {
    "title": "LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunsheng Ma",
      "Can Cui",
      "Xu Cao",
      "Wenqian Ye",
      "Peiran Liu",
      "Juanwu Lu",
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Kyungtae Han",
      "Aniket Bera",
      "James M. Rehg",
      "Ziran Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_MedBN_Robust_Test-Time_Adaptation_against_Malicious_Test_Samples_CVPR_2024_paper.html": {
    "title": "MedBN: Robust Test-Time Adaptation against Malicious Test Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyejin Park",
      "Jeongyeon Hwang",
      "Sunung Mun",
      "Sangdon Park",
      "Jungseul Ok"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bao_Unsupervised_Gaze_Representation_Learning_from_Multi-view_Face_Images_CVPR_2024_paper.html": {
    "title": "Unsupervised Gaze Representation Learning from Multi-view Face Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Bao",
      "Feng Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Slyman_FairDeDup_Detecting_and_Mitigating_Vision-Language_Fairness_Disparities_in_Semantic_Dataset_CVPR_2024_paper.html": {
    "title": "FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eric Slyman",
      "Stefan Lee",
      "Scott Cohen",
      "Kushal Kafle"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_CrossMAE_Cross-Modality_Masked_Autoencoders_for_Region-Aware_Audio-Visual_Pre-Training_CVPR_2024_paper.html": {
    "title": "CrossMAE: Cross-Modality Masked Autoencoders for Region-Aware Audio-Visual Pre-Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Guo",
      "Siyang Sun",
      "Shuailei Ma",
      "Kecheng Zheng",
      "Xiaoyi Bao",
      "Shijie Ma",
      "Wei Zou",
      "Yun Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Osprey_Pixel_Understanding_with_Visual_Instruction_Tuning_CVPR_2024_paper.html": {
    "title": "Osprey: Pixel Understanding with Visual Instruction Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqian Yuan",
      "Wentong Li",
      "Jian Liu",
      "Dongqi Tang",
      "Xinjie Luo",
      "Chi Qin",
      "Lei Zhang",
      "Jianke Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nam_Modality-agnostic_Domain_Generalizable_Medical_Image_Segmentation_by_Multi-Frequency_in_Multi-Scale_CVPR_2024_paper.html": {
    "title": "Modality-agnostic Domain Generalizable Medical Image Segmentation by Multi-Frequency in Multi-Scale Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ju-Hyeon Nam",
      "Nur Suriza Syazwany",
      "Su Jung Kim",
      "Sang-Chul Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yue_Few-shot_Learner_Parameterization_by_Diffusion_Time-steps_CVPR_2024_paper.html": {
    "title": "Few-shot Learner Parameterization by Diffusion Time-steps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongqi Yue",
      "Pan Zhou",
      "Richang Hong",
      "Hanwang Zhang",
      "Qianru Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Auto_MC-Reward_Automated_Dense_Reward_Design_with_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Li",
      "Xue Yang",
      "Zhaokai Wang",
      "Xizhou Zhu",
      "Jie Zhou",
      "Yu Qiao",
      "Xiaogang Wang",
      "Hongsheng Li",
      "Lewei Lu",
      "Jifeng Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Moon_GenFlow_Generalizable_Recurrent_Flow_for_6D_Pose_Refinement_of_Novel_CVPR_2024_paper.html": {
    "title": "GenFlow: Generalizable Recurrent Flow for 6D Pose Refinement of Novel Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungphill Moon",
      "Hyeontae Son",
      "Dongcheol Hur",
      "Sangwook Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ahmed_OrCo_Towards_Better_Generalization_via_Orthogonality_and_Contrast_for_Few-Shot_CVPR_2024_paper.html": {
    "title": "OrCo: Towards Better Generalization via Orthogonality and Contrast for Few-Shot Class-Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Noor Ahmed",
      "Anna Kukleva",
      "Bernt Schiele"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_MuGE_Multiple_Granularity_Edge_Detection_CVPR_2024_paper.html": {
    "title": "MuGE: Multiple Granularity Edge Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Caixia Zhou",
      "Yaping Huang",
      "Mengyang Pu",
      "Qingji Guan",
      "Ruoxi Deng",
      "Haibin Ling"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Real-World_Efficient_Blind_Motion_Deblurring_via_Blur_Pixel_Discretization_CVPR_2024_paper.html": {
    "title": "Real-World Efficient Blind Motion Deblurring via Blur Pixel Discretization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Insoo Kim",
      "Jae Seok Choi",
      "Geonseok Seo",
      "Kinam Kwon",
      "Jinwoo Shin",
      "Hyong-Euk Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_EmoVIT_Revolutionizing_Emotion_Insights_with_Visual_Instruction_Tuning_CVPR_2024_paper.html": {
    "title": "EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongxia Xie",
      "Chu-Jun Peng",
      "Yu-Wen Tseng",
      "Hung-Jen Chen",
      "Chan-Feng Hsu",
      "Hong-Han Shuai",
      "Wen-Huang Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Knobel_Learning_to_Count_without_Annotations_CVPR_2024_paper.html": {
    "title": "Learning to Count without Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Knobel",
      "Tengda Han",
      "Yuki M. Asano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Maxwell_Logarithmic_Lenses_Exploring_Log_RGB_Data_for_Image_Classification_CVPR_2024_paper.html": {
    "title": "Logarithmic Lenses: Exploring Log RGB Data for Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bruce A. Maxwell",
      "Sumegha Singhania",
      "Avnish Patel",
      "Rahul Kumar",
      "Heather Fryling",
      "Sihan Li",
      "Haonan Sun",
      "Ping He",
      "Zewen Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ricker_AEROBLADE_Training-Free_Detection_of_Latent_Diffusion_Images_Using_Autoencoder_Reconstruction_CVPR_2024_paper.html": {
    "title": "AEROBLADE: Training-Free Detection of Latent Diffusion Images Using Autoencoder Reconstruction Error",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas Ricker",
      "Denis Lukovnikov",
      "Asja Fischer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_Scaled_Decoupled_Distillation_CVPR_2024_paper.html": {
    "title": "Scaled Decoupled Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shicai Wei",
      "Chunbo Luo",
      "Yang Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_NARUTO_Neural_Active_Reconstruction_from_Uncertain_Target_Observations_CVPR_2024_paper.html": {
    "title": "NARUTO: Neural Active Reconstruction from Uncertain Target Observations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyue Feng",
      "Huangying Zhan",
      "Zheng Chen",
      "Qingan Yan",
      "Xiangyu Xu",
      "Changjiang Cai",
      "Bing Li",
      "Qilun Zhu",
      "Yi Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Point2CAD_Reverse_Engineering_CAD_Models_from_3D_Point_Clouds_CVPR_2024_paper.html": {
    "title": "Point2CAD: Reverse Engineering CAD Models from 3D Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujia Liu",
      "Anton Obukhov",
      "Jan Dirk Wegner",
      "Konrad Schindler"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Loiseau_Learnable_Earth_Parser_Discovering_3D_Prototypes_in_Aerial_Scans_CVPR_2024_paper.html": {
    "title": "Learnable Earth Parser: Discovering 3D Prototypes in Aerial Scans",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Romain Loiseau",
      "Elliot Vincent",
      "Mathieu Aubry",
      "Loic Landrieu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Weber_NeRFiller_Completing_Scenes_via_Generative_3D_Inpainting_CVPR_2024_paper.html": {
    "title": "NeRFiller: Completing Scenes via Generative 3D Inpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ethan Weber",
      "Aleksander Holynski",
      "Varun Jampani",
      "Saurabh Saxena",
      "Noah Snavely",
      "Abhishek Kar",
      "Angjoo Kanazawa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Cloud-Device_Collaborative_Learning_for_Multimodal_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "Cloud-Device Collaborative Learning for Multimodal Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanqun Wang",
      "Jiaming Liu",
      "Chenxuan Li",
      "Yuan Zhang",
      "Junpeng Ma",
      "Xinyu Wei",
      "Kevin Zhang",
      "Maurice Chong",
      "Renrui Zhang",
      "Yijiang Liu",
      "Shanghang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_KD-DETR_Knowledge_Distillation_for_Detection_Transformer_with_Consistent_Distillation_Points_CVPR_2024_paper.html": {
    "title": "KD-DETR: Knowledge Distillation for Detection Transformer with Consistent Distillation Points Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Wang",
      "Xin Li",
      "Shengzhao Weng",
      "Gang Zhang",
      "Haixiao Yue",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ventura_Absolute_Pose_from_One_or_Two_Scaled_and_Oriented_Features_CVPR_2024_paper.html": {
    "title": "Absolute Pose from One or Two Scaled and Oriented Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Ventura",
      "Zuzana Kukelova",
      "Torsten Sattler",
      "Dániel Baráth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Source-Free_Domain_Adaptation_with_Frozen_Multimodal_Foundation_Model_CVPR_2024_paper.html": {
    "title": "Source-Free Domain Adaptation with Frozen Multimodal Foundation Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Song Tang",
      "Wenxin Su",
      "Mao Ye",
      "Xiatian Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_LocLLM_Exploiting_Generalizable_Human_Keypoint_Localization_via_Large_Language_Model_CVPR_2024_paper.html": {
    "title": "LocLLM: Exploiting Generalizable Human Keypoint Localization via Large Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongkai Wang",
      "Shiyu Xuan",
      "Shiliang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_MMA-Diffusion_MultiModal_Attack_on_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "MMA-Diffusion: MultiModal Attack on Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijun Yang",
      "Ruiyuan Gao",
      "Xiaosen Wang",
      "Tsung-Yi Ho",
      "Nan Xu",
      "Qiang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Benchmarking_Audio_Visual_Segmentation_for_Long-Untrimmed_Videos_CVPR_2024_paper.html": {
    "title": "Benchmarking Audio Visual Segmentation for Long-Untrimmed Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Liu",
      "Peike Patrick Li",
      "Qingtao Yu",
      "Hongwei Sheng",
      "Dadong Wang",
      "Lincheng Li",
      "Xin Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rahman_EMCAD_Efficient_Multi-scale_Convolutional_Attention_Decoding_for_Medical_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "EMCAD: Efficient Multi-scale Convolutional Attention Decoding for Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Mostafijur Rahman",
      "Mustafa Munir",
      "Radu Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_VTQA_Visual_Text_Question_Answering_via_Entity_Alignment_and_Cross-Media_CVPR_2024_paper.html": {
    "title": "VTQA: Visual Text Question Answering via Entity Alignment and Cross-Media Reasoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kang Chen",
      "Xiangqian Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ayad_QN-Mixer_A_Quasi-Newton_MLP-Mixer_Model_for_Sparse-View_CT_Reconstruction_CVPR_2024_paper.html": {
    "title": "QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ishak Ayad",
      "Nicolas Larue",
      "Mai K. Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ngo_Learning_CNN_on_ViT_A_Hybrid_Model_to_Explicitly_Class-specific_CVPR_2024_paper.html": {
    "title": "Learning CNN on ViT: A Hybrid Model to Explicitly Class-specific Boundaries for Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ba Hung Ngo",
      "Nhat-Tuong Do-Tran",
      "Tuan-Ngoc Nguyen",
      "Hae-Gon Jeon",
      "Tae Jong Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Urbanek_A_Picture_is_Worth_More_Than_77_Text_Tokens_Evaluating_CVPR_2024_paper.html": {
    "title": "A Picture is Worth More Than 77 Text Tokens: Evaluating CLIP-Style Models on Dense Captions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jack Urbanek",
      "Florian Bordes",
      "Pietro Astolfi",
      "Mary Williamson",
      "Vasu Sharma",
      "Adriana Romero-Soriano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Narasimhaswamy_HanDiffuser_Text-to-Image_Generation_With_Realistic_Hand_Appearances_CVPR_2024_paper.html": {
    "title": "HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Supreeth Narasimhaswamy",
      "Uttaran Bhattacharya",
      "Xiang Chen",
      "Ishita Dasgupta",
      "Saayan Mitra",
      "Minh Hoai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Raistrick_Infinigen_Indoors_Photorealistic_Indoor_Scenes_using_Procedural_Generation_CVPR_2024_paper.html": {
    "title": "Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Raistrick",
      "Lingjie Mei",
      "Karhan Kayan",
      "David Yan",
      "Yiming Zuo",
      "Beining Han",
      "Hongyu Wen",
      "Meenal Parakh",
      "Stamatis Alexandropoulos",
      "Lahav Lipson",
      "Zeyu Ma",
      "Jia Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MART_Masked_Affective_RepresenTation_Learning_via_Masked_Temporal_Distribution_Distillation_CVPR_2024_paper.html": {
    "title": "MART: Masked Affective RepresenTation Learning via Masked Temporal Distribution Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhicheng Zhang",
      "Pancheng Zhao",
      "Eunil Park",
      "Jufeng Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Agiza_MTLoRA_Low-Rank_Adaptation_Approach_for_Efficient_Multi-Task_Learning_CVPR_2024_paper.html": {
    "title": "MTLoRA: Low-Rank Adaptation Approach for Efficient Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Agiza",
      "Marina Neseem",
      "Sherief Reda"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Skorokhodov_Hierarchical_Patch_Diffusion_Models_for_High-Resolution_Video_Generation_CVPR_2024_paper.html": {
    "title": "Hierarchical Patch Diffusion Models for High-Resolution Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Skorokhodov",
      "Willi Menapace",
      "Aliaksandr Siarohin",
      "Sergey Tulyakov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ji_Motion_Blur_Decomposition_with_Cross-shutter_Guidance_CVPR_2024_paper.html": {
    "title": "Motion Blur Decomposition with Cross-shutter Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Ji",
      "Haiyang Jiang",
      "Yinqiang Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Scene-adaptive_and_Region-aware_Multi-modal_Prompt_for_Open_Vocabulary_Object_Detection_CVPR_2024_paper.html": {
    "title": "Scene-adaptive and Region-aware Multi-modal Prompt for Open Vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaowei Zhao",
      "Xianglong Liu",
      "Duorui Wang",
      "Yajun Gao",
      "Zhide Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_MimicDiffusion_Purifying_Adversarial_Perturbation_via_Mimicking_Clean_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiyu Song",
      "Hanjiang Lai",
      "Yan Pan",
      "Jian Yin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Schardong_Neural_Implicit_Morphing_of_Face_Images_CVPR_2024_paper.html": {
    "title": "Neural Implicit Morphing of Face Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guilherme Schardong",
      "Tiago Novello",
      "Hallison Paz",
      "Iurii Medvedev",
      "Vinícius da Silva",
      "Luiz Velho",
      "Nuno Gonçalves"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_UniGS_Unified_Representation_for_Image_Generation_and_Segmentation_CVPR_2024_paper.html": {
    "title": "UniGS: Unified Representation for Image Generation and Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lu Qi",
      "Lehan Yang",
      "Weidong Guo",
      "Yu Xu",
      "Bo Du",
      "Varun Jampani",
      "Ming-Hsuan Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Robust_Synthetic-to-Real_Transfer_for_Stereo_Matching_CVPR_2024_paper.html": {
    "title": "Robust Synthetic-to-Real Transfer for Stereo Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Zhang",
      "Jiahe Li",
      "Lei Huang",
      "Xiaohan Yu",
      "Lin Gu",
      "Jin Zheng",
      "Xiao Bai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Moon_Instance-Aware_Group_Quantization_for_Vision_Transformers_CVPR_2024_paper.html": {
    "title": "Instance-Aware Group Quantization for Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaehyeon Moon",
      "Dohyung Kim",
      "Junyong Cheon",
      "Bumsub Ham"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_A_General_and_Efficient_Training_for_Transformer_via_Token_Expansion_CVPR_2024_paper.html": {
    "title": "A General and Efficient Training for Transformer via Token Expansion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Huang",
      "Yunhang Shen",
      "Jiao Xie",
      "Baochang Zhang",
      "Gaoqi He",
      "Ke Li",
      "Xing Sun",
      "Shaohui Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_GenZI_Zero-Shot_3D_Human-Scene_Interaction_Generation_CVPR_2024_paper.html": {
    "title": "GenZI: Zero-Shot 3D Human-Scene Interaction Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Li",
      "Angela Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rakic_Tyche_Stochastic_In-Context_Learning_for_Medical_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Tyche: Stochastic In-Context Learning for Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marianne Rakic",
      "Hallee E. Wong",
      "Jose Javier Gonzalez Ortiz",
      "Beth A. Cimini",
      "John V. Guttag",
      "Adrian V. Dalca"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Scarpellini_DiffAssemble_A_Unified_Graph-Diffusion_Model_for_2D_and_3D_Reassembly_CVPR_2024_paper.html": {
    "title": "DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gianluca Scarpellini",
      "Stefano Fiorini",
      "Francesco Giuliari",
      "Pietro Moreiro",
      "Alessio Del Bue"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_NeISF_Neural_Incident_Stokes_Field_for_Geometry_and_Material_Estimation_CVPR_2024_paper.html": {
    "title": "NeISF: Neural Incident Stokes Field for Geometry and Material Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenhao Li",
      "Taishi Ono",
      "Takeshi Uemori",
      "Hajime Mihara",
      "Alexander Gatto",
      "Hajime Nagahara",
      "Yusuke Moriuchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Barsellotti_Training-Free_Open-Vocabulary_Segmentation_with_Offline_Diffusion-Augmented_Prototype_Generation_CVPR_2024_paper.html": {
    "title": "Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Barsellotti",
      "Roberto Amoroso",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_YOLO-World_Real-Time_Open-Vocabulary_Object_Detection_CVPR_2024_paper.html": {
    "title": "YOLO-World: Real-Time Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianheng Cheng",
      "Lin Song",
      "Yixiao Ge",
      "Wenyu Liu",
      "Xinggang Wang",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lei_ViT-Lens_Towards_Omni-modal_Representations_CVPR_2024_paper.html": {
    "title": "ViT-Lens: Towards Omni-modal Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weixian Lei",
      "Yixiao Ge",
      "Kun Yi",
      "Jianfeng Zhang",
      "Difei Gao",
      "Dylan Sun",
      "Yuying Ge",
      "Ying Shan",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Cross-Dimension_Affinity_Distillation_for_3D_EM_Neuron_Segmentation_CVPR_2024_paper.html": {
    "title": "Cross-Dimension Affinity Distillation for 3D EM Neuron Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Liu",
      "Miaomiao Cai",
      "Yinda Chen",
      "Yueyi Zhang",
      "Te Shi",
      "Ruobing Zhang",
      "Xuejin Chen",
      "Zhiwei Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kocabas_HUGS_Human_Gaussian_Splats_CVPR_2024_paper.html": {
    "title": "HUGS: Human Gaussian Splats",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammed Kocabas",
      "Jen-Hao Rick Chang",
      "James Gabriel",
      "Oncel Tuzel",
      "Anurag Ranjan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kuckreja_GeoChat_Grounded_Large_Vision-Language_Model_for_Remote_Sensing_CVPR_2024_paper.html": {
    "title": "GeoChat: Grounded Large Vision-Language Model for Remote Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kartik Kuckreja",
      "Muhammad Sohail Danish",
      "Muzammal Naseer",
      "Abhijit Das",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_PhysPT_Physics-aware_Pretrained_Transformer_for_Estimating_Human_Dynamics_from_Monocular_CVPR_2024_paper.html": {
    "title": "PhysPT: Physics-aware Pretrained Transformer for Estimating Human Dynamics from Monocular Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufei Zhang",
      "Jeffrey O. Kephart",
      "Zijun Cui",
      "Qiang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gu_Producing_and_Leveraging_Online_Map_Uncertainty_in_Trajectory_Prediction_CVPR_2024_paper.html": {
    "title": "Producing and Leveraging Online Map Uncertainty in Trajectory Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunjiang Gu",
      "Guanyu Song",
      "Igor Gilitschenski",
      "Marco Pavone",
      "Boris Ivanovic"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pi_PerceptionGPT_Effectively_Fusing_Visual_Perception_into_LLM_CVPR_2024_paper.html": {
    "title": "PerceptionGPT: Effectively Fusing Visual Perception into LLM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Renjie Pi",
      "Lewei Yao",
      "Jiahui Gao",
      "Jipeng Zhang",
      "Tong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Probabilistic_Speech-Driven_3D_Facial_Motion_Synthesis_New_Benchmarks_Methods_and_CVPR_2024_paper.html": {
    "title": "Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks Methods and Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karren D. Yang",
      "Anurag Ranjan",
      "Jen-Hao Rick Chang",
      "Raviteja Vemulapalli",
      "Oncel Tuzel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_LASO_Language-guided_Affordance_Segmentation_on_3D_Object_CVPR_2024_paper.html": {
    "title": "LASO: Language-guided Affordance Segmentation on 3D Object",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yicong Li",
      "Na Zhao",
      "Junbin Xiao",
      "Chun Feng",
      "Xiang Wang",
      "Tat-seng Chua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Riemannian_Multinomial_Logistics_Regression_for_SPD_Neural_Networks_CVPR_2024_paper.html": {
    "title": "Riemannian Multinomial Logistics Regression for SPD Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziheng Chen",
      "Yue Song",
      "Gaowen Liu",
      "Ramana Rao Kompella",
      "Xiao-Jun Wu",
      "Nicu Sebe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_FreGS_3D_Gaussian_Splatting_with_Progressive_Frequency_Regularization_CVPR_2024_paper.html": {
    "title": "FreGS: 3D Gaussian Splatting with Progressive Frequency Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahui Zhang",
      "Fangneng Zhan",
      "Muyu Xu",
      "Shijian Lu",
      "Eric Xing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Perera_Discriminative_Sample-Guided_and_Parameter-Efficient_Feature_Space_Adaptation_for_Cross-Domain_Few-Shot_CVPR_2024_paper.html": {
    "title": "Discriminative Sample-Guided and Parameter-Efficient Feature Space Adaptation for Cross-Domain Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rashindrie Perera",
      "Saman Halgamuge"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bandyopadhyay_What_Sketch_Explainability_Really_Means_for_Downstream_Tasks_CVPR_2024_paper.html": {
    "title": "What Sketch Explainability Really Means for Downstream Tasks?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hmrishav Bandyopadhyay",
      "Pinaki Nath Chowdhury",
      "Ayan Kumar Bhunia",
      "Aneeshan Sain",
      "Tao Xiang",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Onzon_Neural_Exposure_Fusion_for_High-Dynamic_Range_Object_Detection_CVPR_2024_paper.html": {
    "title": "Neural Exposure Fusion for High-Dynamic Range Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emmanuel Onzon",
      "Maximilian Bömer",
      "Fahim Mannan",
      "Felix Heide"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_EfficientDreamer_High-Fidelity_and_Robust_3D_Creation_via_Orthogonal-view_Diffusion_Priors_CVPR_2024_paper.html": {
    "title": "EfficientDreamer: High-Fidelity and Robust 3D Creation via Orthogonal-view Diffusion Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhipeng Hu",
      "Minda Zhao",
      "Chaoyi Zhao",
      "Xinyue Liang",
      "Lincheng Li",
      "Zeng Zhao",
      "Changjie Fan",
      "Xiaowei Zhou",
      "Xin Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_HOIAnimator_Generating_Text-prompt_Human-object_Animations_using_Novel_Perceptive_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "HOIAnimator: Generating Text-prompt Human-object Animations using Novel Perceptive Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenfeng Song",
      "Xinyu Zhang",
      "Shuai Li",
      "Yang Gao",
      "Aimin Hao",
      "Xia Hou",
      "Chenglizhao Chen",
      "Ning Li",
      "Hong Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_SyncTalk_The_Devil_is_in_the_Synchronization_for_Talking_Head_CVPR_2024_paper.html": {
    "title": "SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziqiao Peng",
      "Wentao Hu",
      "Yue Shi",
      "Xiangyu Zhu",
      "Xiaomei Zhang",
      "Hao Zhao",
      "Jun He",
      "Hongyan Liu",
      "Zhaoxin Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_SFOD_Spiking_Fusion_Object_Detector_CVPR_2024_paper.html": {
    "title": "SFOD: Spiking Fusion Object Detector",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yimeng Fan",
      "Wei Zhang",
      "Changsong Liu",
      "Mingyang Li",
      "Wenrui Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_Detector-Free_Structure_from_Motion_CVPR_2024_paper.html": {
    "title": "Detector-Free Structure from Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingyi He",
      "Jiaming Sun",
      "Yifan Wang",
      "Sida Peng",
      "Qixing Huang",
      "Hujun Bao",
      "Xiaowei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Diller_CG-HOI_Contact-Guided_3D_Human-Object_Interaction_Generation_CVPR_2024_paper.html": {
    "title": "CG-HOI: Contact-Guided 3D Human-Object Interaction Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christian Diller",
      "Angela Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_Towards_Surveillance_Video-and-Language_Understanding_New_Dataset_Baselines_and_Challenges_CVPR_2024_paper.html": {
    "title": "Towards Surveillance Video-and-Language Understanding: New Dataset Baselines and Challenges",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tongtong Yuan",
      "Xuange Zhang",
      "Kun Liu",
      "Bo Liu",
      "Chen Chen",
      "Jian Jin",
      "Zhenzhen Jiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mao_AdaRevD_Adaptive_Patch_Exiting_Reversible_Decoder_Pushes_the_Limit_of_CVPR_2024_paper.html": {
    "title": "AdaRevD: Adaptive Patch Exiting Reversible Decoder Pushes the Limit of Image Deblurring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xintian Mao",
      "Qingli Li",
      "Yan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Learning_to_Remove_Wrinkled_Transparent_Film_with_Polarized_Prior_CVPR_2024_paper.html": {
    "title": "Learning to Remove Wrinkled Transparent Film with Polarized Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Tang",
      "Ruizheng Wu",
      "Xiaogang Xu",
      "Sixing Hu",
      "Ying-Cong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Majumdar_OpenEQA_Embodied_Question_Answering_in_the_Era_of_Foundation_Models_CVPR_2024_paper.html": {
    "title": "OpenEQA: Embodied Question Answering in the Era of Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arjun Majumdar",
      "Anurag Ajay",
      "Xiaohan Zhang",
      "Pranav Putta",
      "Sriram Yenamandra",
      "Mikael Henaff",
      "Sneha Silwal",
      "Paul Mcvay",
      "Oleksandr Maksymets",
      "Sergio Arnaud",
      "Karmesh Yadav",
      "Qiyang Li",
      "Ben Newman",
      "Mohit Sharma",
      "Vincent Berges",
      "Shiqi Zhang",
      "Pulkit Agrawal",
      "Yonatan Bisk",
      "Dhruv Batra",
      "Mrinal Kalakrishnan",
      "Franziska Meier",
      "Chris Paxton",
      "Alexander Sax",
      "Aravind Rajeswaran"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_DreamSalon_A_Staged_Diffusion_Framework_for_Preserving_Identity-Context_in_Editable_CVPR_2024_paper.html": {
    "title": "DreamSalon: A Staged Diffusion Framework for Preserving Identity-Context in Editable Face Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haonan Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Dispel_Darkness_for_Better_Fusion_A_Controllable_Visual_Enhancer_based_CVPR_2024_paper.html": {
    "title": "Dispel Darkness for Better Fusion: A Controllable Visual Enhancer based on Cross-modal Conditional Adversarial Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Zhang",
      "Linfeng Tang",
      "Xinyu Xiang",
      "Xuhui Zuo",
      "Jiayi Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_Querying_as_Prompt_Parameter-Efficient_Learning_for_Multimodal_Language_Model_CVPR_2024_paper.html": {
    "title": "Querying as Prompt: Parameter-Efficient Learning for Multimodal Language Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tian Liang",
      "Jing Huang",
      "Ming Kong",
      "Luyuan Chen",
      "Qiang Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_DePT_Decoupled_Prompt_Tuning_CVPR_2024_paper.html": {
    "title": "DePT: Decoupled Prompt Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ji Zhang",
      "Shihan Wu",
      "Lianli Gao",
      "Heng Tao Shen",
      "Jingkuan Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Super-Resolution_for_Real-time_Rendering_with_Radiance_Demodulation_CVPR_2024_paper.html": {
    "title": "Neural Super-Resolution for Real-time Rendering with Radiance Demodulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia Li",
      "Ziling Chen",
      "Xiaolong Wu",
      "Lu Wang",
      "Beibei Wang",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Deformable_3D_Gaussians_for_High-Fidelity_Monocular_Dynamic_Scene_Reconstruction_CVPR_2024_paper.html": {
    "title": "Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyi Yang",
      "Xinyu Gao",
      "Wen Zhou",
      "Shaohui Jiao",
      "Yuqing Zhang",
      "Xiaogang Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ji_Enhancing_3D_Object_Detection_with_2D_Detection-Guided_Query_Anchors_CVPR_2024_paper.html": {
    "title": "Enhancing 3D Object Detection with 2D Detection-Guided Query Anchors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxuanye Ji",
      "Pengpeng Liang",
      "Erkang Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Continual_Forgetting_for_Pre-trained_Vision_Models_CVPR_2024_paper.html": {
    "title": "Continual Forgetting for Pre-trained Vision Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongbo Zhao",
      "Bolin Ni",
      "Junsong Fan",
      "Yuxi Wang",
      "Yuntao Chen",
      "Gaofeng Meng",
      "Zhaoxiang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Real_Acoustic_Fields_An_Audio-Visual_Room_Acoustics_Dataset_and_Benchmark_CVPR_2024_paper.html": {
    "title": "Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Chen",
      "Israel D. Gebru",
      "Christian Richardt",
      "Anurag Kumar",
      "William Laney",
      "Andrew Owens",
      "Alexander Richard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Caron_A_Generative_Approach_for_Wikipedia-Scale_Visual_Entity_Recognition_CVPR_2024_paper.html": {
    "title": "A Generative Approach for Wikipedia-Scale Visual Entity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mathilde Caron",
      "Ahmet Iscen",
      "Alireza Fathi",
      "Cordelia Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gong_A_Physics-informed_Low-rank_Deep_Neural_Network_for_Blind_and_Universal_CVPR_2024_paper.html": {
    "title": "A Physics-informed Low-rank Deep Neural Network for Blind and Universal Lens Aberration Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Gong",
      "Runzhao Yang",
      "Weihang Zhang",
      "Jinli Suo",
      "Qionghai Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Corsetti_Open-Vocabulary_Object_6D_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "Open-Vocabulary Object 6D Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaime Corsetti",
      "Davide Boscaini",
      "Changjae Oh",
      "Andrea Cavallaro",
      "Fabio Poiesi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Plug_and_Play_Active_Learning_for_Object_Detection_CVPR_2024_paper.html": {
    "title": "Plug and Play Active Learning for Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenhongyi Yang",
      "Lichao Huang",
      "Elliot J. Crowley"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/You_Calibrating_Multi-modal_Representations_A_Pursuit_of_Group_Robustness_without_Annotations_CVPR_2024_paper.html": {
    "title": "Calibrating Multi-modal Representations: A Pursuit of Group Robustness without Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenyu You",
      "Yifei Min",
      "Weicheng Dai",
      "Jasjeet S. Sekhon",
      "Lawrence Staib",
      "James S. Duncan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_LiSA_LiDAR_Localization_with_Semantic_Awareness_CVPR_2024_paper.html": {
    "title": "LiSA: LiDAR Localization with Semantic Awareness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bochun Yang",
      "Zijun Li",
      "Wen Li",
      "Zhipeng Cai",
      "Chenglu Wen",
      "Yu Zang",
      "Matthias Muller",
      "Cheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pinyoanuntapong_MMM_Generative_Masked_Motion_Model_CVPR_2024_paper.html": {
    "title": "MMM: Generative Masked Motion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ekkasit Pinyoanuntapong",
      "Pu Wang",
      "Minwoo Lee",
      "Chen Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cha_PEGASUS_Personalized_Generative_3D_Avatars_with_Composable_Attributes_CVPR_2024_paper.html": {
    "title": "PEGASUS: Personalized Generative 3D Avatars with Composable Attributes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunsoo Cha",
      "Byungjun Kim",
      "Hanbyul Joo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shao_LMDrive_Closed-Loop_End-to-End_Driving_with_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "LMDrive: Closed-Loop End-to-End Driving with Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Shao",
      "Yuxuan Hu",
      "Letian Wang",
      "Guanglu Song",
      "Steven L. Waslander",
      "Yu Liu",
      "Hongsheng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_MCD_Diverse_Large-Scale_Multi-Campus_Dataset_for_Robot_Perception_CVPR_2024_paper.html": {
    "title": "MCD: Diverse Large-Scale Multi-Campus Dataset for Robot Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thien-Minh Nguyen",
      "Shenghai Yuan",
      "Thien Hoang Nguyen",
      "Pengyu Yin",
      "Haozhi Cao",
      "Lihua Xie",
      "Maciej Wozniak",
      "Patric Jensfelt",
      "Marko Thiel",
      "Justin Ziegenbein",
      "Noel Blunder"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Diff-Plugin_Revitalizing_Details_for_Diffusion-based_Low-level_Tasks_CVPR_2024_paper.html": {
    "title": "Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Liu",
      "Zhanghan Ke",
      "Fang Liu",
      "Nanxuan Zhao",
      "Rynson W.H. Lau"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_AHIVE_Anatomy-aware_Hierarchical_Vision_Encoding_for_Interactive_Radiology_Report_Retrieval_CVPR_2024_paper.html": {
    "title": "AHIVE: Anatomy-aware Hierarchical Vision Encoding for Interactive Radiology Report Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sixing Yan",
      "William K. Cheung",
      "Ivor W. Tsang",
      "Keith Chiu",
      "Terence M. Tong",
      "Ka Chun Cheung",
      "Simon See"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_CyberDemo_Augmenting_Simulated_Human_Demonstration_for_Real-World_Dexterous_Manipulation_CVPR_2024_paper.html": {
    "title": "CyberDemo: Augmenting Simulated Human Demonstration for Real-World Dexterous Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Wang",
      "Yuzhe Qin",
      "Kaiming Kuang",
      "Yigit Korkmaz",
      "Akhilan Gurumoorthy",
      "Hao Su",
      "Xiaolong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Abdelfattah_MaskCLR_Attention-Guided_Contrastive_Learning_for_Robust_Action_Representation_Learning_CVPR_2024_paper.html": {
    "title": "MaskCLR: Attention-Guided Contrastive Learning for Robust Action Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohamed Abdelfattah",
      "Mariam Hassan",
      "Alexandre Alahi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Narrative_Action_Evaluation_with_Prompt-Guided_Multimodal_Interaction_CVPR_2024_paper.html": {
    "title": "Narrative Action Evaluation with Prompt-Guided Multimodal Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyi Zhang",
      "Sule Bai",
      "Guangyi Chen",
      "Lei Chen",
      "Jiwen Lu",
      "Junle Wang",
      "Yansong Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chan_R-Cyclic_Diffuser_Reductive_and_Cyclic_Latent_Diffusion_for_3D_Clothed_CVPR_2024_paper.html": {
    "title": "R-Cyclic Diffuser: Reductive and Cyclic Latent Diffusion for 3D Clothed Human Digitalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kennard Yanting Chan",
      "Fayao Liu",
      "Guosheng Lin",
      "Chuan Sheng Foo",
      "Weisi Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Intelligent_Grimm_-_Open-ended_Visual_Storytelling_via_Latent_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Intelligent Grimm - Open-ended Visual Storytelling via Latent Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chang Liu",
      "Haoning Wu",
      "Yujie Zhong",
      "Xiaoyun Zhang",
      "Yanfeng Wang",
      "Weidi Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Validating_Privacy-Preserving_Face_Recognition_under_a_Minimum_Assumption_CVPR_2024_paper.html": {
    "title": "Validating Privacy-Preserving Face Recognition under a Minimum Assumption",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Zhang",
      "Xingbo Dong",
      "YenLung Lai",
      "Ying Zhou",
      "Xiaoyan Zhang",
      "Xingguo Lv",
      "Zhe Jin",
      "Xuejun Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ho_Long-Tailed_Anomaly_Detection_with_Learnable_Class_Names_CVPR_2024_paper.html": {
    "title": "Long-Tailed Anomaly Detection with Learnable Class Names",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chih-Hui Ho",
      "Kuan-Chuan Peng",
      "Nuno Vasconcelos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tian_ArGue_Attribute-Guided_Prompt_Tuning_for_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Tian",
      "Shu Zou",
      "Zhaoyuan Yang",
      "Jing Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Rapid_3D_Model_Generation_with_Intuitive_3D_Input_CVPR_2024_paper.html": {
    "title": "Rapid 3D Model Generation with Intuitive 3D Input",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianrun Chen",
      "Chaotao Ding",
      "Shangzhan Zhang",
      "Chunan Yu",
      "Ying Zang",
      "Zejian Li",
      "Sida Peng",
      "Lingyun Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_GenTron_Diffusion_Transformers_for_Image_and_Video_Generation_CVPR_2024_paper.html": {
    "title": "GenTron: Diffusion Transformers for Image and Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shoufa Chen",
      "Mengmeng Xu",
      "Jiawei Ren",
      "Yuren Cong",
      "Sen He",
      "Yanping Xie",
      "Animesh Sinha",
      "Ping Luo",
      "Tao Xiang",
      "Juan-Manuel Perez-Rua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shin_Close_Imitation_of_Expert_Retouching_for_Black-and-White_Photography_CVPR_2024_paper.html": {
    "title": "Close Imitation of Expert Retouching for Black-and-White Photography",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seunghyun Shin",
      "Jisu Shin",
      "Jihwan Bae",
      "Inwook Shim",
      "Hae-Gon Jeon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_TRIP_Temporal_Residual_Learning_with_Image_Noise_Prior_for_Image-to-Video_CVPR_2024_paper.html": {
    "title": "TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongwei Zhang",
      "Fuchen Long",
      "Yingwei Pan",
      "Zhaofan Qiu",
      "Ting Yao",
      "Yang Cao",
      "Tao Mei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_TexVocab_Texture_Vocabulary-conditioned_Human_Avatars_CVPR_2024_paper.html": {
    "title": "TexVocab: Texture Vocabulary-conditioned Human Avatars",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiao Liu",
      "Zhe Li",
      "Yebin Liu",
      "Haoqian Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_KITRO_Refining_Human_Mesh_by_2D_Clues_and_Kinematic-tree_Rotation_CVPR_2024_paper.html": {
    "title": "KITRO: Refining Human Mesh by 2D Clues and Kinematic-tree Rotation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengyuan Yang",
      "Kerui Gu",
      "Angela Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ali-bey_BoQ_A_Place_is_Worth_a_Bag_of_Learnable_Queries_CVPR_2024_paper.html": {
    "title": "BoQ: A Place is Worth a Bag of Learnable Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amar Ali-bey",
      "Brahim Chaib-draa",
      "Philippe Giguère"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guedon_SuGaR_Surface-Aligned_Gaussian_Splatting_for_Efficient_3D_Mesh_Reconstruction_and_CVPR_2024_paper.html": {
    "title": "SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Antoine Guédon",
      "Vincent Lepetit"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mitsuzumi_Understanding_and_Improving_Source-free_Domain_Adaptation_from_a_Theoretical_Perspective_CVPR_2024_paper.html": {
    "title": "Understanding and Improving Source-free Domain Adaptation from a Theoretical Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Mitsuzumi",
      "Akisato Kimura",
      "Hisashi Kashima"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Learning_SO3-Invariant_Semantic_Correspondence_via_Local_Shape_Transform_CVPR_2024_paper.html": {
    "title": "Learning SO(3)-Invariant Semantic Correspondence via Local Shape Transform",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunghyun Park",
      "Seungwook Kim",
      "Jaesik Park",
      "Minsu Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_GigaPose_Fast_and_Robust_Novel_Object_Pose_Estimation_via_One_CVPR_2024_paper.html": {
    "title": "GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Van Nguyen Nguyen",
      "Thibault Groueix",
      "Mathieu Salzmann",
      "Vincent Lepetit"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Imagine_Before_Go_Self-Supervised_Generative_Map_for_Object_Goal_Navigation_CVPR_2024_paper.html": {
    "title": "Imagine Before Go: Self-Supervised Generative Map for Object Goal Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sixian Zhang",
      "Xinyao Yu",
      "Xinhang Song",
      "Xiaohan Wang",
      "Shuqiang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Towards_Effective_Usage_of_Human-Centric_Priors_in_Diffusion_Models_for_CVPR_2024_paper.html": {
    "title": "Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyan Wang",
      "Zhenhong Sun",
      "Zhiyu Tan",
      "Xuanbai Chen",
      "Weihua Chen",
      "Hao Li",
      "Cheng Zhang",
      "Yang Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_A_Video_is_Worth_256_Bases_Spatial-Temporal_Expectation-Maximization_Inversion_for_CVPR_2024_paper.html": {
    "title": "A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization Inversion for Zero-Shot Video Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maomao Li",
      "Yu Li",
      "Tianyu Yang",
      "Yunfei Liu",
      "Dongxu Yue",
      "Zhihui Lin",
      "Dong Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_HIPTrack_Visual_Tracking_with_Historical_Prompts_CVPR_2024_paper.html": {
    "title": "HIPTrack: Visual Tracking with Historical Prompts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenrui Cai",
      "Qingjie Liu",
      "Yunhong Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_URHand_Universal_Relightable_Hands_CVPR_2024_paper.html": {
    "title": "URHand: Universal Relightable Hands",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoxi Chen",
      "Gyeongsik Moon",
      "Kaiwen Guo",
      "Chen Cao",
      "Stanislav Pidhorskyi",
      "Tomas Simon",
      "Rohan Joshi",
      "Yuan Dong",
      "Yichen Xu",
      "Bernardo Pires",
      "He Wen",
      "Lucas Evans",
      "Bo Peng",
      "Julia Buffalini",
      "Autumn Trimble",
      "Kevyn McPhail",
      "Melissa Schoeller",
      "Shoou-I Yu",
      "Javier Romero",
      "Michael Zollhofer",
      "Yaser Sheikh",
      "Ziwei Liu",
      "Shunsuke Saito"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_An_N-Point_Linear_Solver_for_Line_and_Motion_Estimation_with_CVPR_2024_paper.html": {
    "title": "An N-Point Linear Solver for Line and Motion Estimation with Event Cameras",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ling Gao",
      "Daniel Gehrig",
      "Hang Su",
      "Davide Scaramuzza",
      "Laurent Kneip"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_GenNBV_Generalizable_Next-Best-View_Policy_for_Active_3D_Reconstruction_CVPR_2024_paper.html": {
    "title": "GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Chen",
      "Quanyi Li",
      "Tai Wang",
      "Tianfan Xue",
      "Jiangmiao Pang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ahmed_Deep-TROJ_An_Inference_Stage_Trojan_Insertion_Algorithm_through_Efficient_Weight_CVPR_2024_paper.html": {
    "title": "Deep-TROJ: An Inference Stage Trojan Insertion Algorithm through Efficient Weight Replacement Attack",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sabbir Ahmed",
      "Ranyang Zhou",
      "Shaahin Angizi",
      "Adnan Siraj Rakin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Investigating_and_Mitigating_the_Side_Effects_of_Noisy_Views_for_CVPR_2024_paper.html": {
    "title": "Investigating and Mitigating the Side Effects of Noisy Views for Self-Supervised Clustering Algorithms in Practical Multi-View Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Xu",
      "Yazhou Ren",
      "Xiaolong Wang",
      "Lei Feng",
      "Zheng Zhang",
      "Gang Niu",
      "Xiaofeng Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_EvalCrafter_Benchmarking_and_Evaluating_Large_Video_Generation_Models_CVPR_2024_paper.html": {
    "title": "EvalCrafter: Benchmarking and Evaluating Large Video Generation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaofang Liu",
      "Xiaodong Cun",
      "Xuebo Liu",
      "Xintao Wang",
      "Yong Zhang",
      "Haoxin Chen",
      "Yang Liu",
      "Tieyong Zeng",
      "Raymond Chan",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_SelfOcc_Self-Supervised_Vision-Based_3D_Occupancy_Prediction_CVPR_2024_paper.html": {
    "title": "SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuanhui Huang",
      "Wenzhao Zheng",
      "Borui Zhang",
      "Jie Zhou",
      "Jiwen Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_SubT-MRS_Dataset_Pushing_SLAM_Towards_All-weather_Environments_CVPR_2024_paper.html": {
    "title": "SubT-MRS Dataset: Pushing SLAM Towards All-weather Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shibo Zhao",
      "Yuanjun Gao",
      "Tianhao Wu",
      "Damanpreet Singh",
      "Rushan Jiang",
      "Haoxiang Sun",
      "Mansi Sarawata",
      "Yuheng Qiu",
      "Warren Whittaker",
      "Ian Higgins",
      "Yi Du",
      "Shaoshu Su",
      "Can Xu",
      "John Keller",
      "Jay Karhade",
      "Lucas Nogueira",
      "Sourojit Saha",
      "Ji Zhang",
      "Wenshan Wang",
      "Chen Wang",
      "Sebastian Scherer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Feng_Named_Entity_Driven_Zero-Shot_Image_Manipulation_CVPR_2024_paper.html": {
    "title": "Named Entity Driven Zero-Shot Image Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhida Feng",
      "Li Chen",
      "Jing Tian",
      "JiaXiang Liu",
      "Shikun Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Relational_Matching_for_Weakly_Semi-Supervised_Oriented_Object_Detection_CVPR_2024_paper.html": {
    "title": "Relational Matching for Weakly Semi-Supervised Oriented Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Wu",
      "Hau-San Wong",
      "Si Wu",
      "Tianyou Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liao_Rethinking_the_Representation_in_Federated_Unsupervised_Learning_with_Non-IID_Data_CVPR_2024_paper.html": {
    "title": "Rethinking the Representation in Federated Unsupervised Learning with Non-IID Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinting Liao",
      "Weiming Liu",
      "Chaochao Chen",
      "Pengyang Zhou",
      "Fengyuan Yu",
      "Huabin Zhu",
      "Binhui Yao",
      "Tao Wang",
      "Xiaolin Zheng",
      "Yanchao Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lo_Distraction_is_All_You_Need_Memory-Efficient_Image_Immunization_against_Diffusion-Based_CVPR_2024_paper.html": {
    "title": "Distraction is All You Need: Memory-Efficient Image Immunization against Diffusion-Based Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ling Lo",
      "Cheng Yu Yeo",
      "Hong-Han Shuai",
      "Wen-Huang Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Suo_Knowledge-Enhanced_Dual-stream_Zero-shot_Composed_Image_Retrieval_CVPR_2024_paper.html": {
    "title": "Knowledge-Enhanced Dual-stream Zero-shot Composed Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yucheng Suo",
      "Fan Ma",
      "Linchao Zhu",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Taming_Self-Training_for_Open-Vocabulary_Object_Detection_CVPR_2024_paper.html": {
    "title": "Taming Self-Training for Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Zhao",
      "Samuel Schulter",
      "Long Zhao",
      "Zhixing Zhang",
      "Vijay Kumar B G",
      "Yumin Suh",
      "Manmohan Chandraker",
      "Dimitris N. Metaxas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Grounding_and_Enhancing_Grid-based_Models_for_Neural_Fields_CVPR_2024_paper.html": {
    "title": "Grounding and Enhancing Grid-based Models for Neural Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zelin Zhao",
      "Fenglei Fan",
      "Wenlong Liao",
      "Junchi Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Bilateral_Propagation_Network_for_Depth_Completion_CVPR_2024_paper.html": {
    "title": "Bilateral Propagation Network for Depth Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Tang",
      "Fei-Peng Tian",
      "Boshi An",
      "Jian Li",
      "Ping Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jeong_ESR-NeRF_Emissive_Source_Reconstruction_Using_LDR_Multi-view_Images_CVPR_2024_paper.html": {
    "title": "ESR-NeRF: Emissive Source Reconstruction Using LDR Multi-view Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinseo Jeong",
      "Junseo Koo",
      "Qimeng Zhang",
      "Gunhee Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhuang_Infer_from_What_You_Have_Seen_Before_Temporally-dependent_Classifier_for_CVPR_2024_paper.html": {
    "title": "Infer from What You Have Seen Before: Temporally-dependent Classifier for Semi-supervised Video Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiafan Zhuang",
      "Zilei Wang",
      "Yixin Zhang",
      "Zhun Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Unleashing_Channel_Potential_Space-Frequency_Selection_Convolution_for_SAR_Object_Detection_CVPR_2024_paper.html": {
    "title": "Unleashing Channel Potential: Space-Frequency Selection Convolution for SAR Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Li",
      "Di Wang",
      "Zhangyuan Hu",
      "Wenxuan Zhu",
      "Shaofeng Li",
      "Quan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Oba_READ_Retrieval-Enhanced_Asymmetric_Diffusion_for_Motion_Planning_CVPR_2024_paper.html": {
    "title": "READ: Retrieval-Enhanced Asymmetric Diffusion for Motion Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takeru Oba",
      "Matthew Walter",
      "Norimichi Ukita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Video_Frame_Interpolation_via_Direct_Synthesis_with_the_Event-based_Reference_CVPR_2024_paper.html": {
    "title": "Video Frame Interpolation via Direct Synthesis with the Event-based Reference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Liu",
      "Yongjian Deng",
      "Hao Chen",
      "Zhen Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_DSL-FIQA_Assessing_Facial_Image_Quality_via_Dual-Set_Degradation_Learning_and_CVPR_2024_paper.html": {
    "title": "DSL-FIQA: Assessing Facial Image Quality via Dual-Set Degradation Learning and Landmark-Guided Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Ting Chen",
      "Gurunandan Krishnan",
      "Qiang Gao",
      "Sy-Yen Kuo",
      "Sizhou Ma",
      "Jian Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Youk_FMA-Net_Flow-Guided_Dynamic_Filtering_and_Iterative_Feature_Refinement_with_Multi-Attention_CVPR_2024_paper.html": {
    "title": "FMA-Net: Flow-Guided Dynamic Filtering and Iterative Feature Refinement with Multi-Attention for Joint Video Super-Resolution and Deblurring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geunhyuk Youk",
      "Jihyong Oh",
      "Munchurl Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_OVMR_Open-Vocabulary_Recognition_with_Multi-Modal_References_CVPR_2024_paper.html": {
    "title": "OVMR: Open-Vocabulary Recognition with Multi-Modal References",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zehong Ma",
      "Shiliang Zhang",
      "Longhui Wei",
      "Qi Tian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Hourglass_Tokenizer_for_Efficient_Transformer-Based_3D_Human_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhao Li",
      "Mengyuan Liu",
      "Hong Liu",
      "Pichao Wang",
      "Jialun Cai",
      "Nicu Sebe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qian_Boosting_Diffusion_Models_with_Moving_Average_Sampling_in_Frequency_Domain_CVPR_2024_paper.html": {
    "title": "Boosting Diffusion Models with Moving Average Sampling in Frequency Domain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yurui Qian",
      "Qi Cai",
      "Yingwei Pan",
      "Yehao Li",
      "Ting Yao",
      "Qibin Sun",
      "Tao Mei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lei_GART_Gaussian_Articulated_Template_Models_CVPR_2024_paper.html": {
    "title": "GART: Gaussian Articulated Template Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahui Lei",
      "Yufu Wang",
      "Georgios Pavlakos",
      "Lingjie Liu",
      "Kostas Daniilidis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Global_and_Local_Prompts_Cooperation_via_Optimal_Transport_for_Federated_CVPR_2024_paper.html": {
    "title": "Global and Local Prompts Cooperation via Optimal Transport for Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongxia Li",
      "Wei Huang",
      "Jingya Wang",
      "Ye Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Bi-Causal_Group_Activity_Recognition_via_Bidirectional_Causality_CVPR_2024_paper.html": {
    "title": "Bi-Causal: Group Activity Recognition via Bidirectional Causality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youliang Zhang",
      "Wenxuan Liu",
      "Danni Xu",
      "Zhuo Zhou",
      "Zheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yatim_Space-Time_Diffusion_Features_for_Zero-Shot_Text-Driven_Motion_Transfer_CVPR_2024_paper.html": {
    "title": "Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Danah Yatim",
      "Rafail Fridman",
      "Omer Bar-Tal",
      "Yoni Kasten",
      "Tali Dekel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_KP-RED_Exploiting_Semantic_Keypoints_for_Joint_3D_Shape_Retrieval_and_CVPR_2024_paper.html": {
    "title": "KP-RED: Exploiting Semantic Keypoints for Joint 3D Shape Retrieval and Deformation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruida Zhang",
      "Chenyangguang Zhang",
      "Yan Di",
      "Fabian Manhardt",
      "Xingyu Liu",
      "Federico Tombari",
      "Xiangyang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Carreira_Learning_from_One_Continuous_Video_Stream_CVPR_2024_paper.html": {
    "title": "Learning from One Continuous Video Stream",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "João Carreira",
      "Michael King",
      "Viorica Patraucean",
      "Dilara Gokay",
      "Catalin Ionescu",
      "Yi Yang",
      "Daniel Zoran",
      "Joseph Heyward",
      "Carl Doersch",
      "Yusuf Aytar",
      "Dima Damen",
      "Andrew Zisserman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_VGGSfM_Visual_Geometry_Grounded_Deep_Structure_From_Motion_CVPR_2024_paper.html": {
    "title": "VGGSfM: Visual Geometry Grounded Deep Structure From Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianyuan Wang",
      "Nikita Karaev",
      "Christian Rupprecht",
      "David Novotny"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_MIGC_Multi-Instance_Generation_Controller_for_Text-to-Image_Synthesis_CVPR_2024_paper.html": {
    "title": "MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dewei Zhou",
      "You Li",
      "Fan Ma",
      "Xiaoting Zhang",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Distilling_CLIP_with_Dual_Guidance_for_Learning_Discriminative_Human_Body_CVPR_2024_paper.html": {
    "title": "Distilling CLIP with Dual Guidance for Learning Discriminative Human Body Shape Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Liu",
      "Minchul Kim",
      "Zhiyuan Ren",
      "Xiaoming Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Retrieval-Augmented_Open-Vocabulary_Object_Detection_CVPR_2024_paper.html": {
    "title": "Retrieval-Augmented Open-Vocabulary Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jooyeon Kim",
      "Eulrang Cho",
      "Sehyung Kim",
      "Hyunwoo J. Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Farina_MULTIFLOW_Shifting_Towards_Task-Agnostic_Vision-Language_Pruning_CVPR_2024_paper.html": {
    "title": "MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matteo Farina",
      "Massimiliano Mancini",
      "Elia Cunegatti",
      "Gaowen Liu",
      "Giovanni Iacca",
      "Elisa Ricci"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Spin-UP_Spin_Light_for_Natural_Light_Uncalibrated_Photometric_Stereo_CVPR_2024_paper.html": {
    "title": "Spin-UP: Spin Light for Natural Light Uncalibrated Photometric Stereo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongrui Li",
      "Zhan Lu",
      "Haojie Yan",
      "Boxin Shi",
      "Gang Pan",
      "Qian Zheng",
      "Xudong Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_LLaFS_When_Large_Language_Models_Meet_Few-Shot_Segmentation_CVPR_2024_paper.html": {
    "title": "LLaFS: When Large Language Models Meet Few-Shot Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lanyun Zhu",
      "Tianrun Chen",
      "Deyi Ji",
      "Jieping Ye",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Kernel_Adaptive_Convolution_for_Scene_Text_Detection_via_Distance_Map_CVPR_2024_paper.html": {
    "title": "Kernel Adaptive Convolution for Scene Text Detection via Distance Map Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinzhi Zheng",
      "Heng Fan",
      "Libo Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_PixelLM_Pixel_Reasoning_with_Large_Multimodal_Model_CVPR_2024_paper.html": {
    "title": "PixelLM: Pixel Reasoning with Large Multimodal Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongwei Ren",
      "Zhicheng Huang",
      "Yunchao Wei",
      "Yao Zhao",
      "Dongmei Fu",
      "Jiashi Feng",
      "Xiaojie Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MRFS_Mutually_Reinforcing_Image_Fusion_and_Segmentation_CVPR_2024_paper.html": {
    "title": "MRFS: Mutually Reinforcing Image Fusion and Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Zhang",
      "Xuhui Zuo",
      "Jie Jiang",
      "Chunchao Guo",
      "Jiayi Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_MemoNav_Working_Memory_Model_for_Visual_Navigation_CVPR_2024_paper.html": {
    "title": "MemoNav: Working Memory Model for Visual Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongxin Li",
      "Zeyu Wang",
      "Xu Yang",
      "Yuran Yang",
      "Shuqi Mei",
      "Zhaoxiang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ikemura_Robust_Depth_Enhancement_via_Polarization_Prompt_Fusion_Tuning_CVPR_2024_paper.html": {
    "title": "Robust Depth Enhancement via Polarization Prompt Fusion Tuning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kei Ikemura",
      "Yiming Huang",
      "Felix Heide",
      "Zhaoxiang Zhang",
      "Qifeng Chen",
      "Chenyang Lei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_AssistGUI_Task-Oriented_PC_Graphical_User_Interface_Automation_CVPR_2024_paper.html": {
    "title": "AssistGUI: Task-Oriented PC Graphical User Interface Automation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Difei Gao",
      "Lei Ji",
      "Zechen Bai",
      "Mingyu Ouyang",
      "Peiran Li",
      "Dongxing Mao",
      "Qinchen Wu",
      "Weichen Zhang",
      "Peiyi Wang",
      "Xiangwu Guo",
      "Hengxu Wang",
      "Luowei Zhou",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Adaptive_Multi-Modal_Cross-Entropy_Loss_for_Stereo_Matching_CVPR_2024_paper.html": {
    "title": "Adaptive Multi-Modal Cross-Entropy Loss for Stereo Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peng Xu",
      "Zhiyu Xiang",
      "Chengyu Qiao",
      "Jingyun Fu",
      "Tianyu Pu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_Unlocking_the_Potential_of_Prompt-Tuning_in_Bridging_Generalized_and_Personalized_CVPR_2024_paper.html": {
    "title": "Unlocking the Potential of Prompt-Tuning in Bridging Generalized and Personalized Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenlong Deng",
      "Christos Thrampoulidis",
      "Xiaoxiao Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Compact_3D_Gaussian_Representation_for_Radiance_Field_CVPR_2024_paper.html": {
    "title": "Compact 3D Gaussian Representation for Radiance Field",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joo Chan Lee",
      "Daniel Rho",
      "Xiangyu Sun",
      "Jong Hwan Ko",
      "Eunbyung Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_PaSCo_Urban_3D_Panoptic_Scene_Completion_with_Uncertainty_Awareness_CVPR_2024_paper.html": {
    "title": "PaSCo: Urban 3D Panoptic Scene Completion with Uncertainty Awareness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anh-Quan Cao",
      "Angela Dai",
      "Raoul de Charette"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_GALA_Generating_Animatable_Layered_Assets_from_a_Single_Scan_CVPR_2024_paper.html": {
    "title": "GALA: Generating Animatable Layered Assets from a Single Scan",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeksoo Kim",
      "Byungjun Kim",
      "Shunsuke Saito",
      "Hanbyul Joo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yoon_LeGO_Leveraging_a_Surface_Deformation_Network_for_Animatable_Stylized_Face_CVPR_2024_paper.html": {
    "title": "LeGO: Leveraging a Surface Deformation Network for Animatable Stylized Face Generation with One Example",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soyeon Yoon",
      "Kwan Yun",
      "Kwanggyoon Seo",
      "Sihun Cha",
      "Jung Eun Yoo",
      "Junyong Noh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Frequency-Adaptive_Dilated_Convolution_for_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Frequency-Adaptive Dilated Convolution for Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linwei Chen",
      "Lin Gu",
      "Dezhi Zheng",
      "Ying Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_3D_Building_Reconstruction_from_Monocular_Remote_Sensing_Images_with_Multi-level_CVPR_2024_paper.html": {
    "title": "3D Building Reconstruction from Monocular Remote Sensing Images with Multi-level Supervisions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijia Li",
      "Haote Yang",
      "Zhenghao Hu",
      "Juepeng Zheng",
      "Gui-Song Xia",
      "Conghui He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_PhyScene_Physically_Interactable_3D_Scene_Synthesis_for_Embodied_AI_CVPR_2024_paper.html": {
    "title": "PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yandan Yang",
      "Baoxiong Jia",
      "Peiyuan Zhi",
      "Siyuan Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jia_Generative_Latent_Coding_for_Ultra-Low_Bitrate_Image_Compression_CVPR_2024_paper.html": {
    "title": "Generative Latent Coding for Ultra-Low Bitrate Image Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Jia",
      "Jiahao Li",
      "Bin Li",
      "Houqiang Li",
      "Yan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liao_Multiple_View_Geometry_Transformers_for_3D_Human_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "Multiple View Geometry Transformers for 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziwei Liao",
      "Jialiang Zhu",
      "Chunyu Wang",
      "Han Hu",
      "Steven L. Waslander"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ho_SiTH_Single-view_Textured_Human_Reconstruction_with_Image-Conditioned_Diffusion_CVPR_2024_paper.html": {
    "title": "SiTH: Single-view Textured Human Reconstruction with Image-Conditioned Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hsuan- I Ho",
      "Jie Song",
      "Otmar Hilliges"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Distributionally_Generative_Augmentation_for_Fair_Facial_Attribute_Classification_CVPR_2024_paper.html": {
    "title": "Distributionally Generative Augmentation for Fair Facial Attribute Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fengda Zhang",
      "Qianpei He",
      "Kun Kuang",
      "Jiashuo Liu",
      "Long Chen",
      "Chao Wu",
      "Jun Xiao",
      "Hanwang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_DynVideo-E_Harnessing_Dynamic_NeRF_for_Large-Scale_Motion-_and_View-Change_Human-Centric_CVPR_2024_paper.html": {
    "title": "DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and View-Change Human-Centric Video Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia-Wei Liu",
      "Yan-Pei Cao",
      "Jay Zhangjie Wu",
      "Weijia Mao",
      "Yuchao Gu",
      "Rui Zhao",
      "Jussi Keppo",
      "Ying Shan",
      "Mike Zheng Shou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dou_Real-Time_Neural_BRDF_with_Spherically_Distributed_Primitives_CVPR_2024_paper.html": {
    "title": "Real-Time Neural BRDF with Spherically Distributed Primitives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yishun Dou",
      "Zhong Zheng",
      "Qiaoqiao Jin",
      "Bingbing Ni",
      "Yugang Chen",
      "Junxiang Ke"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ali_Harnessing_Meta-Learning_for_Improving_Full-Frame_Video_Stabilization_CVPR_2024_paper.html": {
    "title": "Harnessing Meta-Learning for Improving Full-Frame Video Stabilization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Kashif Ali",
      "Eun Woo Im",
      "Dongjin Kim",
      "Tae Hyun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_VideoCrafter2_Overcoming_Data_Limitations_for_High-Quality_Video_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxin Chen",
      "Yong Zhang",
      "Xiaodong Cun",
      "Menghan Xia",
      "Xintao Wang",
      "Chao Weng",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kweon_From_SAM_to_CAMs_Exploring_Segment_Anything_Model_for_Weakly_CVPR_2024_paper.html": {
    "title": "From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeokjun Kweon",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tsao_Boosting_Flow-based_Generative_Super-Resolution_Models_via_Learned_Prior_CVPR_2024_paper.html": {
    "title": "Boosting Flow-based Generative Super-Resolution Models via Learned Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li-Yuan Tsao",
      "Yi-Chen Lo",
      "Chia-Che Chang",
      "Hao-Wei Chen",
      "Roy Tseng",
      "Chien Feng",
      "Chun-Yi Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Koley_How_to_Handle_Sketch-Abstraction_in_Sketch-Based_Image_Retrieval_CVPR_2024_paper.html": {
    "title": "How to Handle Sketch-Abstraction in Sketch-Based Image Retrieval?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhadeep Koley",
      "Ayan Kumar Bhunia",
      "Aneeshan Sain",
      "Pinaki Nath Chowdhury",
      "Tao Xiang",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Trevithick_What_You_See_is_What_You_GAN_Rendering_Every_Pixel_CVPR_2024_paper.html": {
    "title": "What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Trevithick",
      "Matthew Chan",
      "Towaki Takikawa",
      "Umar Iqbal",
      "Shalini De Mello",
      "Manmohan Chandraker",
      "Ravi Ramamoorthi",
      "Koki Nagano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chung_Style_Injection_in_Diffusion_A_Training-free_Approach_for_Adapting_Large-scale_CVPR_2024_paper.html": {
    "title": "Style Injection in Diffusion: A Training-free Approach for Adapting Large-scale Diffusion Models for Style Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiwoo Chung",
      "Sangeek Hyun",
      "Jae-Pil Heo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Towards_Robust_Learning_to_Optimize_with_Theoretical_Guarantees_CVPR_2024_paper.html": {
    "title": "Towards Robust Learning to Optimize with Theoretical Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingyu Song",
      "Wei Lin",
      "Juncheng Wang",
      "Hong Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Deng_Differentiable_Neural_Surface_Refinement_for_Modeling_Transparent_Objects_CVPR_2024_paper.html": {
    "title": "Differentiable Neural Surface Refinement for Modeling Transparent Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weijian Deng",
      "Dylan Campbell",
      "Chunyi Sun",
      "Shubham Kanitkar",
      "Matthew E. Shaffer",
      "Stephen Gould"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Geng_OrthCaps_An_Orthogonal_CapsNet_with_Sparse_Attention_Routing_and_Pruning_CVPR_2024_paper.html": {
    "title": "OrthCaps: An Orthogonal CapsNet with Sparse Attention Routing and Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Geng",
      "Jiaming Wang",
      "Jiawei Gong",
      "Yuerong Xue",
      "Jun Xu",
      "Fanglin Chen",
      "Xiaolin Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fang_ProS_Prompting-to-simulate_Generalized_knowledge_for_Universal_Cross-Domain_Retrieval_CVPR_2024_paper.html": {
    "title": "ProS: Prompting-to-simulate Generalized knowledge for Universal Cross-Domain Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaipeng Fang",
      "Jingkuan Song",
      "Lianli Gao",
      "Pengpeng Zeng",
      "Zhi-Qi Cheng",
      "Xiyao Li",
      "Heng Tao Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Florence-2_Advancing_a_Unified_Representation_for_a_Variety_of_Vision_CVPR_2024_paper.html": {
    "title": "Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Xiao",
      "Haiping Wu",
      "Weijian Xu",
      "Xiyang Dai",
      "Houdong Hu",
      "Yumao Lu",
      "Michael Zeng",
      "Ce Liu",
      "Lu Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_NeRF_On-the-go_Exploiting_Uncertainty_for_Distractor-free_NeRFs_in_the_Wild_CVPR_2024_paper.html": {
    "title": "NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weining Ren",
      "Zihan Zhu",
      "Boyang Sun",
      "Jiaqi Chen",
      "Marc Pollefeys",
      "Songyou Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Akada_3D_Human_Pose_Perception_from_Egocentric_Stereo_Videos_CVPR_2024_paper.html": {
    "title": "3D Human Pose Perception from Egocentric Stereo Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hiroyasu Akada",
      "Jian Wang",
      "Vladislav Golyanik",
      "Christian Theobalt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Grid_Diffusion_Models_for_Text-to-Video_Generation_CVPR_2024_paper.html": {
    "title": "Grid Diffusion Models for Text-to-Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taegyeong Lee",
      "Soyeong Kwon",
      "Taehwan Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Du_Boosting_Object_Detection_with_Zero-Shot_Day-Night_Domain_Adaptation_CVPR_2024_paper.html": {
    "title": "Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhipeng Du",
      "Miaojing Shi",
      "Jiankang Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_LucidDreamer_Towards_High-Fidelity_Text-to-3D_Generation_via_Interval_Score_Matching_CVPR_2024_paper.html": {
    "title": "LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixun Liang",
      "Xin Yang",
      "Jiantao Lin",
      "Haodong Li",
      "Xiaogang Xu",
      "Yingcong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_PTM-VQA_Efficient_Video_Quality_Assessment_Leveraging_Diverse_PreTrained_Models_from_CVPR_2024_paper.html": {
    "title": "PTM-VQA: Efficient Video Quality Assessment Leveraging Diverse PreTrained Models from the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Yuan",
      "Hongbo Liu",
      "Mading Li",
      "Muyi Sun",
      "Ming Sun",
      "Jiachao Gong",
      "Jinhua Hao",
      "Chao Zhou",
      "Yansong Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Versatile_Medical_Image_Segmentation_Learned_from_Multi-Source_Datasets_via_Model_CVPR_2024_paper.html": {
    "title": "Versatile Medical Image Segmentation Learned from Multi-Source Datasets via Model Self-Disambiguation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Chen",
      "Hao Zheng",
      "Yuemeng Li",
      "Yuncong Ma",
      "Liang Ma",
      "Hongming Li",
      "Yong Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jain_Improving_Generalization_via_Meta-Learning_on_Hard_Samples_CVPR_2024_paper.html": {
    "title": "Improving Generalization via Meta-Learning on Hard Samples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nishant Jain",
      "Arun S. Suggala",
      "Pradeep Shenoy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liao_Align_and_Aggregate_Compositional_Reasoning_with_Video_Alignment_and_Answer_CVPR_2024_paper.html": {
    "title": "Align and Aggregate: Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaohe Liao",
      "Jiangtong Li",
      "Li Niu",
      "Liqing Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_REACTO_Reconstructing_Articulated_Objects_from_a_Single_Video_CVPR_2024_paper.html": {
    "title": "REACTO: Reconstructing Articulated Objects from a Single Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoyue Song",
      "Jiacheng Wei",
      "Chuan Sheng Foo",
      "Guosheng Lin",
      "Fayao Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Egocentric_Whole-Body_Motion_Capture_with_FisheyeViT_and_Diffusion-Based_Motion_Refinement_CVPR_2024_paper.html": {
    "title": "Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based Motion Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jian Wang",
      "Zhe Cao",
      "Diogo Luvizon",
      "Lingjie Liu",
      "Kripasindhu Sarkar",
      "Danhang Tang",
      "Thabo Beeler",
      "Christian Theobalt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_Language_Embedded_3D_Gaussians_for_Open-Vocabulary_Scene_Understanding_CVPR_2024_paper.html": {
    "title": "Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin-Chuan Shi",
      "Miao Wang",
      "Hao-Bin Duan",
      "Shao-Hua Guan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Argaw_Towards_Automated_Movie_Trailer_Generation_CVPR_2024_paper.html": {
    "title": "Towards Automated Movie Trailer Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dawit Mureja Argaw",
      "Mattia Soldan",
      "Alejandro Pardo",
      "Chen Zhao",
      "Fabian Caba Heilbron",
      "Joon Son Chung",
      "Bernard Ghanem"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Differentiable_Information_Bottleneck_for_Deterministic_Multi-view_Clustering_CVPR_2024_paper.html": {
    "title": "Differentiable Information Bottleneck for Deterministic Multi-view Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqiang Yan",
      "Zhixiang Jin",
      "Fengshou Han",
      "Yangdong Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Sheared_Backpropagation_for_Fine-tuning_Foundation_Models_CVPR_2024_paper.html": {
    "title": "Sheared Backpropagation for Fine-tuning Foundation Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiyuan Yu",
      "Li Shen",
      "Liang Ding",
      "Xinmei Tian",
      "Yixin Chen",
      "Dacheng Tao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kung_Action-slot_Visual_Action-centric_Representations_for_Multi-label_Atomic_Activity_Recognition_in_CVPR_2024_paper.html": {
    "title": "Action-slot: Visual Action-centric Representations for Multi-label Atomic Activity Recognition in Traffic Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi-Hsi Kung",
      "Shu-Wei Lu",
      "Yi-Hsuan Tsai",
      "Yi-Ting Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Animatable_Gaussians_Learning_Pose-dependent_Gaussian_Maps_for_High-fidelity_Human_Avatar_CVPR_2024_paper.html": {
    "title": "Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhe Li",
      "Zerong Zheng",
      "Lizhen Wang",
      "Yebin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Latency_Correction_for_Event-guided_Deblurring_and_Frame_Interpolation_CVPR_2024_paper.html": {
    "title": "Latency Correction for Event-guided Deblurring and Frame Interpolation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Yang",
      "Jinxiu Liang",
      "Bohan Yu",
      "Yan Chen",
      "Jimmy S. Ren",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Retraining-Free_Model_Quantization_via_One-Shot_Weight-Coupling_Learning_CVPR_2024_paper.html": {
    "title": "Retraining-Free Model Quantization via One-Shot Weight-Coupling Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Tang",
      "Yuan Meng",
      "Jiacheng Jiang",
      "Shuzhao Xie",
      "Rongwei Lu",
      "Xinzhu Ma",
      "Zhi Wang",
      "Wenwu Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_EVCap_Retrieval-Augmented_Image_Captioning_with_External_Visual-Name_Memory_for_Open-World_CVPR_2024_paper.html": {
    "title": "EVCap: Retrieval-Augmented Image Captioning with External Visual-Name Memory for Open-World Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxuan Li",
      "Duc Minh Vo",
      "Akihiro Sugimoto",
      "Hideki Nakayama"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_SIFU_Side-view_Conditioned_Implicit_Function_for_Real-world_Usable_Clothed_Human_CVPR_2024_paper.html": {
    "title": "SIFU: Side-view Conditioned Implicit Function for Real-world Usable Clothed Human Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zechuan Zhang",
      "Zongxin Yang",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kelly_WinSyn__A_High_Resolution_Testbed_for_Synthetic_Data_CVPR_2024_paper.html": {
    "title": "WinSyn: : A High Resolution Testbed for Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Kelly",
      "John Femiani",
      "Peter Wonka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Autoregressive_Queries_for_Adaptive_Tracking_with_Spatio-Temporal_Transformers_CVPR_2024_paper.html": {
    "title": "Autoregressive Queries for Adaptive Tracking with Spatio-Temporal Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinxia Xie",
      "Bineng Zhong",
      "Zhiyi Mo",
      "Shengping Zhang",
      "Liangtao Shi",
      "Shuxiang Song",
      "Rongrong Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ni_Misalignment-Robust_Frequency_Distribution_Loss_for_Image_Transformation_CVPR_2024_paper.html": {
    "title": "Misalignment-Robust Frequency Distribution Loss for Image Transformation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhangkai Ni",
      "Juncheng Wu",
      "Zian Wang",
      "Wenhan Yang",
      "Hanli Wang",
      "Lin Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zou_Language-aware_Visual_Semantic_Distillation_for_Video_Question_Answering_CVPR_2024_paper.html": {
    "title": "Language-aware Visual Semantic Distillation for Video Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bo Zou",
      "Chao Yang",
      "Yu Qiao",
      "Chengbin Quan",
      "Youjian Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Lane2Seq_Towards_Unified_Lane_Detection_via_Sequence_Generation_CVPR_2024_paper.html": {
    "title": "Lane2Seq: Towards Unified Lane Detection via Sequence Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kunyang Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Disentangled_Prompt_Representation_for_Domain_Generalization_CVPR_2024_paper.html": {
    "title": "Disentangled Prompt Representation for Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "De Cheng",
      "Zhipeng Xu",
      "Xinyang Jiang",
      "Nannan Wang",
      "Dongsheng Li",
      "Xinbo Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fang_Abductive_Ego-View_Accident_Video_Understanding_for_Safe_Driving_Perception_CVPR_2024_paper.html": {
    "title": "Abductive Ego-View Accident Video Understanding for Safe Driving Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianwu Fang",
      "Lei-lei Li",
      "Junfei Zhou",
      "Junbin Xiao",
      "Hongkai Yu",
      "Chen Lv",
      "Jianru Xue",
      "Tat-Seng Chua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Brucker_Cross-spectral_Gated-RGB_Stereo_Depth_Estimation_CVPR_2024_paper.html": {
    "title": "Cross-spectral Gated-RGB Stereo Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Brucker",
      "Stefanie Walz",
      "Mario Bijelic",
      "Felix Heide"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_KVQ_Kwai_Video_Quality_Assessment_for_Short-form_Videos_CVPR_2024_paper.html": {
    "title": "KVQ: Kwai Video Quality Assessment for Short-form Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiting Lu",
      "Xin Li",
      "Yajing Pei",
      "Kun Yuan",
      "Qizhi Xie",
      "Yunpeng Qu",
      "Ming Sun",
      "Chao Zhou",
      "Zhibo Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Degrees_of_Freedom_Matter_Inferring_Dynamics_from_Point_Trajectories_CVPR_2024_paper.html": {
    "title": "Degrees of Freedom Matter: Inferring Dynamics from Point Trajectories",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Zhang",
      "Sergey Prokudin",
      "Marko Mihajlovic",
      "Qianli Ma",
      "Siyu Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_LEMON_Learning_3D_Human-Object_Interaction_Relation_from_2D_Images_CVPR_2024_paper.html": {
    "title": "LEMON: Learning 3D Human-Object Interaction Relation from 2D Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang Yang",
      "Wei Zhai",
      "Hongchen Luo",
      "Yang Cao",
      "Zheng-Jun Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hou_Low-Latency_Neural_Stereo_Streaming_CVPR_2024_paper.html": {
    "title": "Low-Latency Neural Stereo Streaming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiqi Hou",
      "Farzad Farhadzadeh",
      "Amir Said",
      "Guillaume Sautiere",
      "Hoang Le"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kowal_Understanding_Video_Transformers_via_Universal_Concept_Discovery_CVPR_2024_paper.html": {
    "title": "Understanding Video Transformers via Universal Concept Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Kowal",
      "Achal Dave",
      "Rares Ambrus",
      "Adrien Gaidon",
      "Konstantinos G. Derpanis",
      "Pavel Tokmakov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Exploring_the_Transferability_of_Visual_Prompting_for_Multimodal_Large_Language_CVPR_2024_paper.html": {
    "title": "Exploring the Transferability of Visual Prompting for Multimodal Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichi Zhang",
      "Yinpeng Dong",
      "Siyuan Zhang",
      "Tianzan Min",
      "Hang Su",
      "Jun Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luo_PointOBB_Learning_Oriented_Object_Detection_via_Single_Point_Supervision_CVPR_2024_paper.html": {
    "title": "PointOBB: Learning Oriented Object Detection via Single Point Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junwei Luo",
      "Xue Yang",
      "Yi Yu",
      "Qingyun Li",
      "Junchi Yan",
      "Yansheng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kocsis_Intrinsic_Image_Diffusion_for_Indoor_Single-view_Material_Estimation_CVPR_2024_paper.html": {
    "title": "Intrinsic Image Diffusion for Indoor Single-view Material Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peter Kocsis",
      "Vincent Sitzmann",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_SHAP-EDITOR_Instruction-Guided_Latent_3D_Editing_in_Seconds_CVPR_2024_paper.html": {
    "title": "SHAP-EDITOR: Instruction-Guided Latent 3D Editing in Seconds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghao Chen",
      "Junyu Xie",
      "Iro Laina",
      "Andrea Vedaldi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Leng_HyperSDFusion_Bridging_Hierarchical_Structures_in_Language_and_Geometry_for_Enhanced_CVPR_2024_paper.html": {
    "title": "HyperSDFusion: Bridging Hierarchical Structures in Language and Geometry for Enhanced 3D Text2Shape Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiying Leng",
      "Tolga Birdal",
      "Xiaohui Liang",
      "Federico Tombari"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wan_OmniParser_A_Unified_Framework_for_Text_Spotting_Key_Information_Extraction_CVPR_2024_paper.html": {
    "title": "OmniParser: A Unified Framework for Text Spotting Key Information Extraction and Table Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianqiang Wan",
      "Sibo Song",
      "Wenwen Yu",
      "Yuliang Liu",
      "Wenqing Cheng",
      "Fei Huang",
      "Xiang Bai",
      "Cong Yao",
      "Zhibo Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_Are_Conventional_SNNs_Really_Efficient_A_Perspective_from_Network_Quantization_CVPR_2024_paper.html": {
    "title": "Are Conventional SNNs Really Efficient? A Perspective from Network Quantization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Tenglong Li",
      "Jindong Li",
      "Yi Zeng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Training_Like_a_Medical_Resident_Context-Prior_Learning_Toward_Universal_Medical_CVPR_2024_paper.html": {
    "title": "Training Like a Medical Resident: Context-Prior Learning Toward Universal Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhe Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lopes_Material_Palette_Extraction_of_Materials_from_a_Single_Image_CVPR_2024_paper.html": {
    "title": "Material Palette: Extraction of Materials from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Lopes",
      "Fabio Pizzati",
      "Raoul de Charette"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hua_Initialization_Matters_for_Adversarial_Transfer_Learning_CVPR_2024_paper.html": {
    "title": "Initialization Matters for Adversarial Transfer Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andong Hua",
      "Jindong Gu",
      "Zhiyu Xue",
      "Nicholas Carlini",
      "Eric Wong",
      "Yao Qin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_RealCustom_Narrowing_Real_Text_Word_for_Real-Time_Open-Domain_Text-to-Image_Customization_CVPR_2024_paper.html": {
    "title": "RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengqi Huang",
      "Zhendong Mao",
      "Mingcong Liu",
      "Qian He",
      "Yongdong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hui_MicroDiffusion_Implicit_Representation-Guided_Diffusion_for_3D_Reconstruction_from_Limited_2D_CVPR_2024_paper.html": {
    "title": "MicroDiffusion: Implicit Representation-Guided Diffusion for 3D Reconstruction from Limited 2D Microscopy Projections",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mude Hui",
      "Zihao Wei",
      "Hongru Zhu",
      "Fei Xia",
      "Yuyin Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Marza_Task-Conditioned_Adaptation_of_Visual_Features_in_Multi-Task_Policy_Learning_CVPR_2024_paper.html": {
    "title": "Task-Conditioned Adaptation of Visual Features in Multi-Task Policy Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pierre Marza",
      "Laetitia Matignon",
      "Olivier Simonin",
      "Christian Wolf"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_L0-Sampler_An_L0_Model_Guided_Volume_Sampling_for_NeRF_CVPR_2024_paper.html": {
    "title": "L0-Sampler: An L0 Model Guided Volume Sampling for NeRF",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liangchen Li",
      "Juyong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Hybrid_Proposal_Refiner_Revisiting_DETR_Series_from_the_Faster_R-CNN_CVPR_2024_paper.html": {
    "title": "Hybrid Proposal Refiner: Revisiting DETR Series from the Faster R-CNN Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinjing Zhao",
      "Fangyun Wei",
      "Chang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Practical_Measurements_of_Translucent_Materials_with_Inter-Pixel_Translucency_Prior_CVPR_2024_paper.html": {
    "title": "Practical Measurements of Translucent Materials with Inter-Pixel Translucency Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Chen",
      "Jie Guo",
      "Shuichang Lai",
      "Ruoyu Fu",
      "Mengxun Kong",
      "Chen Wang",
      "Hongyu Sun",
      "Zhebin Zhang",
      "Chen Li",
      "Yanwen Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mirdehghan_TurboSL_Dense_Accurate_and_Fast_3D_by_Neural_Inverse_Structured_CVPR_2024_paper.html": {
    "title": "TurboSL: Dense Accurate and Fast 3D by Neural Inverse Structured Light",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parsa Mirdehghan",
      "Maxx Wu",
      "Wenzheng Chen",
      "David B. Lindell",
      "Kiriakos N. Kutulakos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Text2QR_Harmonizing_Aesthetic_Customization_and_Scanning_Robustness_for_Text-Guided_QR_CVPR_2024_paper.html": {
    "title": "Text2QR: Harmonizing Aesthetic Customization and Scanning Robustness for Text-Guided QR Code Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyang Wu",
      "Xiaohong Liu",
      "Jun Jia",
      "Xuehao Cui",
      "Guangtao Zhai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_GS-IR_3D_Gaussian_Splatting_for_Inverse_Rendering_CVPR_2024_paper.html": {
    "title": "GS-IR: 3D Gaussian Splatting for Inverse Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Liang",
      "Qi Zhang",
      "Ying Feng",
      "Ying Shan",
      "Kui Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_SynFog_A_Photo-realistic_Synthetic_Fog_Dataset_based_on_End-to-end_Imaging_CVPR_2024_paper.html": {
    "title": "SynFog: A Photo-realistic Synthetic Fog Dataset based on End-to-end Imaging Simulation for Advancing Real-World Defogging in Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Xie",
      "Henglu Wei",
      "Zhenyi Liu",
      "Xiaoyu Wang",
      "Xiangyang Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Video_Harmonization_with_Triplet_Spatio-Temporal_Variation_Patterns_CVPR_2024_paper.html": {
    "title": "Video Harmonization with Triplet Spatio-Temporal Variation Patterns",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zonghui Guo",
      "Xinyu Han",
      "Jie Zhang",
      "Shiguang Shan",
      "Haiyong Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_TRINS_Towards_Multimodal_Language_Models_that_Can_Read_CVPR_2024_paper.html": {
    "title": "TRINS: Towards Multimodal Language Models that Can Read",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiyi Zhang",
      "Yanzhe Zhang",
      "Jian Chen",
      "Yufan Zhou",
      "Jiuxiang Gu",
      "Changyou Chen",
      "Tong Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Self-Supervised_Representation_Learning_from_Arbitrary_Scenarios_CVPR_2024_paper.html": {
    "title": "Self-Supervised Representation Learning from Arbitrary Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaowen Li",
      "Yousong Zhu",
      "Zhiyang Chen",
      "Zongxin Gao",
      "Rui Zhao",
      "Chaoyang Zhao",
      "Ming Tang",
      "Jinqiao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saha_Improved_Zero-Shot_Classification_by_Adapting_VLMs_with_Text_Descriptions_CVPR_2024_paper.html": {
    "title": "Improved Zero-Shot Classification by Adapting VLMs with Text Descriptions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oindrila Saha",
      "Grant Van Horn",
      "Subhransu Maji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Living_Scenes_Multi-object_Relocalization_and_Reconstruction_in_Changing_3D_Environments_CVPR_2024_paper.html": {
    "title": "Living Scenes: Multi-object Relocalization and Reconstruction in Changing 3D Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liyuan Zhu",
      "Shengyu Huang",
      "Konrad Schindler",
      "Iro Armeni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_CricaVPR_Cross-image_Correlation-aware_Representation_Learning_for_Visual_Place_Recognition_CVPR_2024_paper.html": {
    "title": "CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Lu",
      "Xiangyuan Lan",
      "Lijun Zhang",
      "Dongmei Jiang",
      "Yaowei Wang",
      "Chun Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Patel_ECLIPSE_A_Resource-Efficient_Text-to-Image_Prior_for_Image_Generations_CVPR_2024_paper.html": {
    "title": "ECLIPSE: A Resource-Efficient Text-to-Image Prior for Image Generations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maitreya Patel",
      "Changhoon Kim",
      "Sheng Cheng",
      "Chitta Baral",
      "Yezhou Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chi_Adaptive_Bidirectional_Displacement_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanyang Chi",
      "Jian Pang",
      "Bingfeng Zhang",
      "Weifeng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kalble_Accurate_Training_Data_for_Occupancy_Map_Prediction_in_Automated_Driving_CVPR_2024_paper.html": {
    "title": "Accurate Training Data for Occupancy Map Prediction in Automated Driving Using Evidence Theory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas Kälble",
      "Sascha Wirges",
      "Maxim Tatarchenko",
      "Eddy Ilg"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Phongthawee_DiffusionLight_Light_Probes_for_Free_by_Painting_a_Chrome_Ball_CVPR_2024_paper.html": {
    "title": "DiffusionLight: Light Probes for Free by Painting a Chrome Ball",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pakkapon Phongthawee",
      "Worameth Chinchuthakun",
      "Nontaphat Sinsunthithet",
      "Varun Jampani",
      "Amit Raj",
      "Pramook Khungurn",
      "Supasorn Suwajanakorn"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bu_Instance-level_Expert_Knowledge_and_Aggregate_Discriminative_Attention_for_Radiology_Report_CVPR_2024_paper.html": {
    "title": "Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shenshen Bu",
      "Taiji Li",
      "Yuedong Yang",
      "Zhiming Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Task-Adaptive_Saliency_Guidance_for_Exemplar-free_Class_Incremental_Learning_CVPR_2024_paper.html": {
    "title": "Task-Adaptive Saliency Guidance for Exemplar-free Class Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xialei Liu",
      "Jiang-Tian Zhai",
      "Andrew D. Bagdanov",
      "Ke Li",
      "Ming-Ming Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_Rethinking_the_Spatial_Inconsistency_in_Classifier-Free_Diffusion_Guidance_CVPR_2024_paper.html": {
    "title": "Rethinking the Spatial Inconsistency in Classifier-Free Diffusion Guidance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dazhong Shen",
      "Guanglu Song",
      "Zeyue Xue",
      "Fu-Yun Wang",
      "Yu Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Language-driven_All-in-one_Adverse_Weather_Removal_CVPR_2024_paper.html": {
    "title": "Language-driven All-in-one Adverse Weather Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Yang",
      "Liyuan Pan",
      "Yan Yang",
      "Wei Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Each_Test_Image_Deserves_A_Specific_Prompt_Continual_Test-Time_Adaptation_CVPR_2024_paper.html": {
    "title": "Each Test Image Deserves A Specific Prompt: Continual Test-Time Adaptation for 2D Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyang Chen",
      "Yongsheng Pan",
      "Yiwen Ye",
      "Mengkang Lu",
      "Yong Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_KTPFormer_Kinematics_and_Trajectory_Prior_Knowledge-Enhanced_Transformer_for_3D_Human_CVPR_2024_paper.html": {
    "title": "KTPFormer: Kinematics and Trajectory Prior Knowledge-Enhanced Transformer for 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jihua Peng",
      "Yanghong Zhou",
      "P. Y. Mok"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_MAPLM_A_Real-World_Large-Scale_Vision-Language_Benchmark_for_Map_and_Traffic_CVPR_2024_paper.html": {
    "title": "MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Cao",
      "Tong Zhou",
      "Yunsheng Ma",
      "Wenqian Ye",
      "Can Cui",
      "Kun Tang",
      "Zhipeng Cao",
      "Kaizhao Liang",
      "Ziran Wang",
      "James M. Rehg",
      "Chao Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_EgoExoLearn_A_Dataset_for_Bridging_Asynchronous_Ego-_and_Exo-centric_View_CVPR_2024_paper.html": {
    "title": "EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Huang",
      "Guo Chen",
      "Jilan Xu",
      "Mingfang Zhang",
      "Lijin Yang",
      "Baoqi Pei",
      "Hongjie Zhang",
      "Lu Dong",
      "Yali Wang",
      "Limin Wang",
      "Yu Qiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dou_Differentiable_Micro-Mesh_Construction_CVPR_2024_paper.html": {
    "title": "Differentiable Micro-Mesh Construction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yishun Dou",
      "Zhong Zheng",
      "Qiaoqiao Jin",
      "Rui Shi",
      "Yuhan Li",
      "Bingbing Ni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_Improved_Implicit_Neural_Representation_with_Fourier_Reparameterized_Training_CVPR_2024_paper.html": {
    "title": "Improved Implicit Neural Representation with Fourier Reparameterized Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kexuan Shi",
      "Xingyu Zhou",
      "Shuhang Gu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SNED_Superposition_Network_Architecture_Search_for_Efficient_Video_Diffusion_Model_CVPR_2024_paper.html": {
    "title": "SNED: Superposition Network Architecture Search for Efficient Video Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengang Li",
      "Yan Kang",
      "Yuchen Liu",
      "Difan Liu",
      "Tobias Hinz",
      "Feng Liu",
      "Yanzhi Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Groupwise_Query_Specialization_and_Quality-Aware_Multi-Assignment_for_Transformer-based_Visual_Relationship_CVPR_2024_paper.html": {
    "title": "Groupwise Query Specialization and Quality-Aware Multi-Assignment for Transformer-based Visual Relationship Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jongha Kim",
      "Jihwan Park",
      "Jinyoung Park",
      "Jinyoung Kim",
      "Sehyung Kim",
      "Hyunwoo J. Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_LeftRefill_Filling_Right_Canvas_based_on_Left_Reference_through_Generalized_CVPR_2024_paper.html": {
    "title": "LeftRefill: Filling Right Canvas based on Left Reference through Generalized Text-to-Image Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenjie Cao",
      "Yunuo Cai",
      "Qiaole Dong",
      "Yikai Wang",
      "Yanwei Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ham_Personalized_Residuals_for_Concept-Driven_Text-to-Image_Generation_CVPR_2024_paper.html": {
    "title": "Personalized Residuals for Concept-Driven Text-to-Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cusuh Ham",
      "Matthew Fisher",
      "James Hays",
      "Nicholas Kolkin",
      "Yuchen Liu",
      "Richard Zhang",
      "Tobias Hinz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Condition-Aware_Neural_Network_for_Controlled_Image_Generation_CVPR_2024_paper.html": {
    "title": "Condition-Aware Neural Network for Controlled Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Han Cai",
      "Muyang Li",
      "Qinsheng Zhang",
      "Ming-Yu Liu",
      "Song Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Versatile_Navigation_Under_Partial_Observability_via_Value-guided_Diffusion_Policy_CVPR_2024_paper.html": {
    "title": "Versatile Navigation Under Partial Observability via Value-guided Diffusion Policy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gengyu Zhang",
      "Hao Tang",
      "Yan Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_All_in_One_Framework_for_Multimodal_Re-identification_in_the_Wild_CVPR_2024_paper.html": {
    "title": "All in One Framework for Multimodal Re-identification in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Li",
      "Mang Ye",
      "Ming Zhang",
      "Bo Du"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bhunia_Looking_3D_Anomaly_Detection_with_2D-3D_Alignment_CVPR_2024_paper.html": {
    "title": "Looking 3D: Anomaly Detection with 2D-3D Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ankan Bhunia",
      "Changjian Li",
      "Hakan Bilen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Purified_and_Unified_Steganographic_Network_CVPR_2024_paper.html": {
    "title": "Purified and Unified Steganographic Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guobiao Li",
      "Sheng Li",
      "Zicong Luo",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_VS_Reconstructing_Clothed_3D_Human_from_Single_Image_via_Vertex_CVPR_2024_paper.html": {
    "title": "VS: Reconstructing Clothed 3D Human from Single Image via Vertex Shift",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leyuan Liu",
      "Yuhan Li",
      "Yunqi Gao",
      "Changxin Gao",
      "Yuanyuan Liu",
      "Jingying Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Weng_PARA-Drive_Parallelized_Architecture_for_Real-time_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "PARA-Drive: Parallelized Architecture for Real-time Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinshuo Weng",
      "Boris Ivanovic",
      "Yan Wang",
      "Yue Wang",
      "Marco Pavone"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_TEA_Test-time_Energy_Adaptation_CVPR_2024_paper.html": {
    "title": "TEA: Test-time Energy Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yige Yuan",
      "Bingbing Xu",
      "Liang Hou",
      "Fei Sun",
      "Huawei Shen",
      "Xueqi Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xue_NEAT_Distilling_3D_Wireframes_from_Neural_Attraction_Fields_CVPR_2024_paper.html": {
    "title": "NEAT: Distilling 3D Wireframes from Neural Attraction Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nan Xue",
      "Bin Tan",
      "Yuxi Xiao",
      "Liang Dong",
      "Gui-Song Xia",
      "Tianfu Wu",
      "Yujun Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bodur_Prompt_Augmentation_for_Self-supervised_Text-guided_Image_Manipulation_CVPR_2024_paper.html": {
    "title": "Prompt Augmentation for Self-supervised Text-guided Image Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rumeysa Bodur",
      "Binod Bhattarai",
      "Tae-Kyun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xuan_Pink_Unveiling_the_Power_of_Referential_Comprehension_for_Multi-modal_LLMs_CVPR_2024_paper.html": {
    "title": "Pink: Unveiling the Power of Referential Comprehension for Multi-modal LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Xuan",
      "Qingpei Guo",
      "Ming Yang",
      "Shiliang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_LDP_Language-driven_Dual-Pixel_Image_Defocus_Deblurring_Network_CVPR_2024_paper.html": {
    "title": "LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Yang",
      "Liyuan Pan",
      "Yan Yang",
      "Richard Hartley",
      "Miaomiao Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qiu_MMSum_A_Dataset_for_Multimodal_Summarization_and_Thumbnail_Generation_of_CVPR_2024_paper.html": {
    "title": "MMSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jielin Qiu",
      "Jiacheng Zhu",
      "William Han",
      "Aditesh Kumar",
      "Karthik Mittal",
      "Claire Jin",
      "Zhengyuan Yang",
      "Linjie Li",
      "Jianfeng Wang",
      "Ding Zhao",
      "Bo Li",
      "Lijuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_HalluciDoctor_Mitigating_Hallucinatory_Toxicity_in_Visual_Instruction_Data_CVPR_2024_paper.html": {
    "title": "HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qifan Yu",
      "Juncheng Li",
      "Longhui Wei",
      "Liang Pang",
      "Wentao Ye",
      "Bosheng Qin",
      "Siliang Tang",
      "Qi Tian",
      "Yueting Zhuang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Pre-trained_Vision_and_Language_Transformers_Are_Few-Shot_Incremental_Learners_CVPR_2024_paper.html": {
    "title": "Pre-trained Vision and Language Transformers Are Few-Shot Incremental Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keon-Hee Park",
      "Kyungwoo Song",
      "Gyeong-Moon Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Guess_The_Unseen_Dynamic_3D_Scene_Reconstruction_from_Partial_2D_CVPR_2024_paper.html": {
    "title": "Guess The Unseen: Dynamic 3D Scene Reconstruction from Partial 2D Glimpses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Inhee Lee",
      "Byungjun Kim",
      "Hanbyul Joo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_C2RV_Cross-Regional_and_Cross-View_Learning_for_Sparse-View_CBCT_Reconstruction_CVPR_2024_paper.html": {
    "title": "C^2RV: Cross-Regional and Cross-View Learning for Sparse-View CBCT Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiqun Lin",
      "Jiewen Yang",
      "Hualiang Wang",
      "Xinpeng Ding",
      "Wei Zhao",
      "Xiaomeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ruiz_HyperDreamBooth_HyperNetworks_for_Fast_Personalization_of_Text-to-Image_Models_CVPR_2024_paper.html": {
    "title": "HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nataniel Ruiz",
      "Yuanzhen Li",
      "Varun Jampani",
      "Wei Wei",
      "Tingbo Hou",
      "Yael Pritch",
      "Neal Wadhwa",
      "Michael Rubinstein",
      "Kfir Aberman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhong_Language-guided_Image_Reflection_Separation_CVPR_2024_paper.html": {
    "title": "Language-guided Image Reflection Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haofeng Zhong",
      "Yuchen Hong",
      "Shuchen Weng",
      "Jinxiu Liang",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liao_HardMo_A_Large-Scale_Hardcase_Dataset_for_Motion_Capture_CVPR_2024_paper.html": {
    "title": "HardMo: A Large-Scale Hardcase Dataset for Motion Capture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Liao",
      "Chuanchen Luo",
      "Yinuo Du",
      "Yuxi Wang",
      "Xucheng Yin",
      "Man Zhang",
      "Zhaoxiang Zhang",
      "Junran Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ou_View-Category_Interactive_Sharing_Transformer_for_Incomplete_Multi-View_Multi-Label_Learning_CVPR_2024_paper.html": {
    "title": "View-Category Interactive Sharing Transformer for Incomplete Multi-View Multi-Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shilong Ou",
      "Zhe Xue",
      "Yawen Li",
      "Meiyu Liang",
      "Yuanqiang Cai",
      "Junjiang Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Han_The_More_You_See_in_2D_the_More_You_Perceive_CVPR_2024_paper.html": {
    "title": "The More You See in 2D the More You Perceive in 3D",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyang Han",
      "Zelin Gao",
      "Angjoo Kanazawa",
      "Shubham Goel",
      "Yossi Gandelsman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kumar_GLiDR_Topologically_Regularized_Graph_Generative_Network_for_Sparse_LiDAR_Point_CVPR_2024_paper.html": {
    "title": "GLiDR: Topologically Regularized Graph Generative Network for Sparse LiDAR Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prashant Kumar",
      "Kshitij Madhav Bhat",
      "Vedang Bhupesh Shenvi Nadkarni",
      "Prem Kalra"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Separate_and_Conquer_Decoupling_Co-occurrence_via_Decomposition_and_Representation_for_CVPR_2024_paper.html": {
    "title": "Separate and Conquer: Decoupling Co-occurrence via Decomposition and Representation for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwei Yang",
      "Kexue Fu",
      "Minghong Duan",
      "Linhao Qu",
      "Shuo Wang",
      "Zhijian Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Vargas_BiPer_Binary_Neural_Networks_using_a_Periodic_Function_CVPR_2024_paper.html": {
    "title": "BiPer: Binary Neural Networks using a Periodic Function",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Edwin Vargas",
      "Claudia V. Correa",
      "Carlos Hinojosa",
      "Henry Arguello"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Unifying_Automatic_and_Interactive_Matting_with_Pretrained_ViTs_CVPR_2024_paper.html": {
    "title": "Unifying Automatic and Interactive Matting with Pretrained ViTs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixuan Ye",
      "Wenze Liu",
      "He Guo",
      "Yujia Liang",
      "Chaoyi Hong",
      "Hao Lu",
      "Zhiguo Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Segment_Any_Event_Streams_via_Weighted_Adaptation_of_Pivotal_Tokens_CVPR_2024_paper.html": {
    "title": "Segment Any Event Streams via Weighted Adaptation of Pivotal Tokens",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwen Chen",
      "Zhiyu Zhu",
      "Yifan Zhang",
      "Junhui Hou",
      "Guangming Shi",
      "Jinjian Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_AnyDoor_Zero-shot_Object-level_Image_Customization_CVPR_2024_paper.html": {
    "title": "AnyDoor: Zero-shot Object-level Image Customization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Chen",
      "Lianghua Huang",
      "Yu Liu",
      "Yujun Shen",
      "Deli Zhao",
      "Hengshuang Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Commonsense_Prototype_for_Outdoor_Unsupervised_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "Commonsense Prototype for Outdoor Unsupervised 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hai Wu",
      "Shijia Zhao",
      "Xun Huang",
      "Chenglu Wen",
      "Xin Li",
      "Cheng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Lookahead_Exploration_with_Neural_Radiance_Representation_for_Continuous_Vision-Language_Navigation_CVPR_2024_paper.html": {
    "title": "Lookahead Exploration with Neural Radiance Representation for Continuous Vision-Language Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Wang",
      "Xiangyang Li",
      "Jiahao Yang",
      "Yeqi Liu",
      "Junjie Hu",
      "Ming Jiang",
      "Shuqiang Jiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_Clustering_Propagation_for_Universal_Medical_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "Clustering Propagation for Universal Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang Ding",
      "Liulei Li",
      "Wenguan Wang",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_MoPE-CLIP_Structured_Pruning_for_Efficient_Vision-Language_Models_with_Module-wise_Pruning_CVPR_2024_paper.html": {
    "title": "MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haokun Lin",
      "Haoli Bai",
      "Zhili Liu",
      "Lu Hou",
      "Muyi Sun",
      "Linqi Song",
      "Ying Wei",
      "Zhenan Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tian_Learning_Vision_from_Models_Rivals_Learning_Vision_from_Data_CVPR_2024_paper.html": {
    "title": "Learning Vision from Models Rivals Learning Vision from Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yonglong Tian",
      "Lijie Fan",
      "Kaifeng Chen",
      "Dina Katabi",
      "Dilip Krishnan",
      "Phillip Isola"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Leveraging_Frame_Affinity_for_sRGB-to-RAW_Video_De-rendering_CVPR_2024_paper.html": {
    "title": "Leveraging Frame Affinity for sRGB-to-RAW Video De-rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhang",
      "Wencheng Han",
      "Yang Zhou",
      "Jianbing Shen",
      "Cheng-zhong Xu",
      "Wentao Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Adapting_Short-Term_Transformers_for_Action_Detection_in_Untrimmed_Videos_CVPR_2024_paper.html": {
    "title": "Adapting Short-Term Transformers for Action Detection in Untrimmed Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Yang",
      "Huan Gao",
      "Ping Guo",
      "Limin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ko_The_Mirrored_Influence_Hypothesis_Efficient_Data_Influence_Estimation_by_Harnessing_CVPR_2024_paper.html": {
    "title": "The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Myeongseob Ko",
      "Feiyang Kang",
      "Weiyan Shi",
      "Ming Jin",
      "Zhou Yu",
      "Ruoxi Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Herau_SOAC_Spatio-Temporal_Overlap-Aware_Multi-Sensor_Calibration_using_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quentin Herau",
      "Nathan Piasco",
      "Moussab Bennehar",
      "Luis Roldao",
      "Dzmitry Tsishkou",
      "Cyrille Migniot",
      "Pascal Vasseur",
      "Cédric Demonceaux"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_G3-LQ_Marrying_Hyperbolic_Alignment_with_Explicit_Semantic-Geometric_Modeling_for_3D_CVPR_2024_paper.html": {
    "title": "G^3-LQ: Marrying Hyperbolic Alignment with Explicit Semantic-Geometric Modeling for 3D Visual Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Wang",
      "Yali Li",
      "Shengjin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Garment_Recovery_with_Shape_and_Deformation_Priors_CVPR_2024_paper.html": {
    "title": "Garment Recovery with Shape and Deformation Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ren Li",
      "Corentin Dumery",
      "Benoît Guillard",
      "Pascal Fua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Quan_Psychometry_An_Omnifit_Model_for_Image_Reconstruction_from_Human_Brain_CVPR_2024_paper.html": {
    "title": "Psychometry: An Omnifit Model for Image Reconstruction from Human Brain Activity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruijie Quan",
      "Wenguan Wang",
      "Zhibo Tian",
      "Fan Ma",
      "Yi Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Exploring_Regional_Clues_in_CLIP_for_Zero-Shot_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Exploring Regional Clues in CLIP for Zero-Shot Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Zhang",
      "Meng-Hao Guo",
      "Miao Wang",
      "Shi-Min Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Move_as_You_Say_Interact_as_You_Can_Language-guided_Human_CVPR_2024_paper.html": {
    "title": "Move as You Say Interact as You Can: Language-guided Human Motion Generation with Scene Affordance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zan Wang",
      "Yixin Chen",
      "Baoxiong Jia",
      "Puhao Li",
      "Jinlu Zhang",
      "Jingze Zhang",
      "Tengyu Liu",
      "Yixin Zhu",
      "Wei Liang",
      "Siyuan Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Choose_What_You_Need_Disentangled_Representation_Learning_for_Scene_Text_CVPR_2024_paper.html": {
    "title": "Choose What You Need: Disentangled Representation Learning for Scene Text Recognition Removal and Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boqiang Zhang",
      "Hongtao Xie",
      "Zuan Gao",
      "Yuxin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_Generalizable_Face_Landmarking_Guided_by_Conditional_Face_Warping_CVPR_2024_paper.html": {
    "title": "Generalizable Face Landmarking Guided by Conditional Face Warping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Liang",
      "Haotian Liu",
      "Hongteng Xu",
      "Dixin Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Sat2Scene_3D_Urban_Scene_Generation_from_Satellite_Images_with_Diffusion_CVPR_2024_paper.html": {
    "title": "Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zuoyue Li",
      "Zhenqiang Li",
      "Zhaopeng Cui",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shao_Control4D_Efficient_4D_Portrait_Editing_with_Text_CVPR_2024_paper.html": {
    "title": "Control4D: Efficient 4D Portrait Editing with Text",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruizhi Shao",
      "Jingxiang Sun",
      "Cheng Peng",
      "Zerong Zheng",
      "Boyao Zhou",
      "Hongwen Zhang",
      "Yebin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Symphonize_3D_Semantic_Scene_Completion_with_Contextual_Instance_Queries_CVPR_2024_paper.html": {
    "title": "Symphonize 3D Semantic Scene Completion with Contextual Instance Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyi Jiang",
      "Tianheng Cheng",
      "Naiyu Gao",
      "Haoyang Zhang",
      "Tianwei Lin",
      "Wenyu Liu",
      "Xinggang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liso_Loopy-SLAM_Dense_Neural_SLAM_with_Loop_Closures_CVPR_2024_paper.html": {
    "title": "Loopy-SLAM: Dense Neural SLAM with Loop Closures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Liso",
      "Erik Sandström",
      "Vladimir Yugay",
      "Luc Van Gool",
      "Martin R. Oswald"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_CLIPtone_Unsupervised_Learning_for_Text-based_Image_Tone_Adjustment_CVPR_2024_paper.html": {
    "title": "CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeongmin Lee",
      "Kyoungkook Kang",
      "Jungseul Ok",
      "Sunghyun Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Thakral_ToonerGAN_Reinforcing_GANs_for_Obfuscating_Automated_Facial_Indexing_CVPR_2024_paper.html": {
    "title": "ToonerGAN: Reinforcing GANs for Obfuscating Automated Facial Indexing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kartik Thakral",
      "Shashikant Prasad",
      "Stuti Aswani",
      "Mayank Vatsa",
      "Richa Singh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Duan_Content-Adaptive_Non-Local_Convolution_for_Remote_Sensing_Pansharpening_CVPR_2024_paper.html": {
    "title": "Content-Adaptive Non-Local Convolution for Remote Sensing Pansharpening",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yule Duan",
      "Xiao Wu",
      "Haoyu Deng",
      "Liang-Jian Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Codebook_Transfer_with_Part-of-Speech_for_Vector-Quantized_Image_Modeling_CVPR_2024_paper.html": {
    "title": "Codebook Transfer with Part-of-Speech for Vector-Quantized Image Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baoquan Zhang",
      "Huaibin Wang",
      "Chuyao Luo",
      "Xutao Li",
      "Guotao Liang",
      "Yunming Ye",
      "Xiaochen Qi",
      "Yao He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dai_Learning_Inclusion_Matching_for_Animation_Paint_Bucket_Colorization_CVPR_2024_paper.html": {
    "title": "Learning Inclusion Matching for Animation Paint Bucket Colorization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuekun Dai",
      "Shangchen Zhou",
      "Qinyue Li",
      "Chongyi Li",
      "Chen Change Loy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_Editable_Scene_Simulation_for_Autonomous_Driving_via_Collaborative_LLM-Agents_CVPR_2024_paper.html": {
    "title": "Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxi Wei",
      "Zi Wang",
      "Yifan Lu",
      "Chenxin Xu",
      "Changxing Liu",
      "Hao Zhao",
      "Siheng Chen",
      "Yanfeng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_SAM-6D_Segment_Anything_Model_Meets_Zero-Shot_6D_Object_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiehong Lin",
      "Lihua Liu",
      "Dekun Lu",
      "Kui Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_InceptionNeXt_When_Inception_Meets_ConvNeXt_CVPR_2024_paper.html": {
    "title": "InceptionNeXt: When Inception Meets ConvNeXt",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weihao Yu",
      "Pan Zhou",
      "Shuicheng Yan",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mu_SnAG_Scalable_and_Accurate_Video_Grounding_CVPR_2024_paper.html": {
    "title": "SnAG: Scalable and Accurate Video Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fangzhou Mu",
      "Sicheng Mo",
      "Yin Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kakogeorgiou_SPOT_Self-Training_with_Patch-Order_Permutation_for_Object-Centric_Learning_with_Autoregressive_CVPR_2024_paper.html": {
    "title": "SPOT: Self-Training with Patch-Order Permutation for Object-Centric Learning with Autoregressive Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ioannis Kakogeorgiou",
      "Spyros Gidaris",
      "Konstantinos Karantzalos",
      "Nikos Komodakis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_LiveHPS_LiDAR-based_Scene-level_Human_Pose_and_Shape_Estimation_in_Free_CVPR_2024_paper.html": {
    "title": "LiveHPS: LiDAR-based Scene-level Human Pose and Shape Estimation in Free Environment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Ren",
      "Xiao Han",
      "Chengfeng Zhao",
      "Jingya Wang",
      "Lan Xu",
      "Jingyi Yu",
      "Yuexin Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Segment_Every_Out-of-Distribution_Object_CVPR_2024_paper.html": {
    "title": "Segment Every Out-of-Distribution Object",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjie Zhao",
      "Jia Li",
      "Xin Dong",
      "Yu Xiang",
      "Yunhui Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sameni_Building_Vision-Language_Models_on_Solid_Foundations_with_Masked_Distillation_CVPR_2024_paper.html": {
    "title": "Building Vision-Language Models on Solid Foundations with Masked Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sepehr Sameni",
      "Kushal Kafle",
      "Hao Tan",
      "Simon Jenni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Wavelet-based_Fourier_Information_Interaction_with_Frequency_Diffusion_Adjustment_for_Underwater_CVPR_2024_paper.html": {
    "title": "Wavelet-based Fourier Information Interaction with Frequency Diffusion Adjustment for Underwater Image Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Zhao",
      "Weiling Cai",
      "Chenyu Dong",
      "Chengwei Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tian_CroSel_Cross_Selection_of_Confident_Pseudo_Labels_for_Partial-Label_Learning_CVPR_2024_paper.html": {
    "title": "CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyu Tian",
      "Hongxin Wei",
      "Yiqun Wang",
      "Lei Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Maruani_PoNQ_a_Neural_QEM-based_Mesh_Representation_CVPR_2024_paper.html": {
    "title": "PoNQ: a Neural QEM-based Mesh Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nissim Maruani",
      "Maks Ovsjanikov",
      "Pierre Alliez",
      "Mathieu Desbrun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_ModaVerse_Efficiently_Transforming_Modalities_with_LLMs_CVPR_2024_paper.html": {
    "title": "ModaVerse: Efficiently Transforming Modalities with LLMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Wang",
      "Bohan Zhuang",
      "Qi Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_TransLoc4D_Transformer-based_4D_Radar_Place_Recognition_CVPR_2024_paper.html": {
    "title": "TransLoc4D: Transformer-based 4D Radar Place Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guohao Peng",
      "Heshan Li",
      "Yangyang Zhao",
      "Jun Zhang",
      "Zhenyu Wu",
      "Pengyu Zheng",
      "Danwei Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Frequency-aware_Event-based_Video_Deblurring_for_Real-World_Motion_Blur_CVPR_2024_paper.html": {
    "title": "Frequency-aware Event-based Video Deblurring for Real-World Motion Blur",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taewoo Kim",
      "Hoonhee Cho",
      "Kuk-Jin Yoon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ntinou_Multiscale_Vision_Transformers_Meet_Bipartite_Matching_for_Efficient_Single-stage_Action_CVPR_2024_paper.html": {
    "title": "Multiscale Vision Transformers Meet Bipartite Matching for Efficient Single-stage Action Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ioanna Ntinou",
      "Enrique Sanchez",
      "Georgios Tzimiropoulos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Boosting_Order-Preserving_and_Transferability_for_Neural_Architecture_Search_a_Joint_CVPR_2024_paper.html": {
    "title": "Boosting Order-Preserving and Transferability for Neural Architecture Search: a Joint Architecture Refined Search and Fine-tuning Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Beichen Zhang",
      "Xiaoxing Wang",
      "Xiaohan Qin",
      "Junchi Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sheng_Dr._Bokeh_DiffeRentiable_Occlusion-aware_Bokeh_Rendering_CVPR_2024_paper.html": {
    "title": "Dr. Bokeh: DiffeRentiable Occlusion-aware Bokeh Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Sheng",
      "Zixun Yu",
      "Lu Ling",
      "Zhiwen Cao",
      "Xuaner Zhang",
      "Xin Lu",
      "Ke Xian",
      "Haiting Lin",
      "Bedrich Benes"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Unsegment_Anything_by_Simulating_Deformation_CVPR_2024_paper.html": {
    "title": "Unsegment Anything by Simulating Deformation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Lu",
      "Xingyi Yang",
      "Xinchao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Martin_Transductive_Zero-Shot_and_Few-Shot_CLIP_CVPR_2024_paper.html": {
    "title": "Transductive Zero-Shot and Few-Shot CLIP",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ségolène Martin",
      "Yunshi Huang",
      "Fereshteh Shakeri",
      "Jean-Christophe Pesquet",
      "Ismail Ben Ayed"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wakai_Deep_Single_Image_Camera_Calibration_by_Heatmap_Regression_to_Recover_CVPR_2024_paper.html": {
    "title": "Deep Single Image Camera Calibration by Heatmap Regression to Recover Fisheye Images Under Manhattan World Assumption",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nobuhiko Wakai",
      "Satoshi Sato",
      "Yasunori Ishii",
      "Takayoshi Yamashita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_ID-Blau_Image_Deblurring_by_Implicit_Diffusion-based_reBLurring_AUgmentation_CVPR_2024_paper.html": {
    "title": "ID-Blau: Image Deblurring by Implicit Diffusion-based reBLurring AUgmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia-Hao Wu",
      "Fu-Jen Tsai",
      "Yan-Tsung Peng",
      "Chung-Chi Tsai",
      "Chia-Wen Lin",
      "Yen-Yu Lin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Radl_LAENeRF_Local_Appearance_Editing_for_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "LAENeRF: Local Appearance Editing for Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Radl",
      "Michael Steiner",
      "Andreas Kurz",
      "Markus Steinberger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Son_CSTA_CNN-based_Spatiotemporal_Attention_for_Video_Summarization_CVPR_2024_paper.html": {
    "title": "CSTA: CNN-based Spatiotemporal Attention for Video Summarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaewon Son",
      "Jaehun Park",
      "Kwangsu Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_Adversarial_Score_Distillation_When_score_distillation_meets_GAN_CVPR_2024_paper.html": {
    "title": "Adversarial Score Distillation: When score distillation meets GAN",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Wei",
      "Jingkai Zhou",
      "Junyao Sun",
      "Xuesong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Decentralized_Directed_Collaboration_for_Personalized_Federated_Learning_CVPR_2024_paper.html": {
    "title": "Decentralized Directed Collaboration for Personalized Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingqi Liu",
      "Yifan Shi",
      "Qinglun Li",
      "Baoyuan Wu",
      "Xueqian Wang",
      "Li Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Vector_Graphics_Generation_via_Mutually_Impulsed_Dual-domain_Diffusion_CVPR_2024_paper.html": {
    "title": "Vector Graphics Generation via Mutually Impulsed Dual-domain Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongyin Zhao",
      "Ye Chen",
      "Zhangli Hu",
      "Xuanhong Chen",
      "Bingbing Ni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cavagnero_PEM_Prototype-based_Efficient_MaskFormer_for_Image_Segmentation_CVPR_2024_paper.html": {
    "title": "PEM: Prototype-based Efficient MaskFormer for Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niccolò Cavagnero",
      "Gabriele Rosi",
      "Claudia Cuttano",
      "Francesca Pistilli",
      "Marco Ciccone",
      "Giuseppe Averta",
      "Fabio Cermelli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dai_Referring_Expression_Counting_CVPR_2024_paper.html": {
    "title": "Referring Expression Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyang Dai",
      "Jun Liu",
      "Ngai-Man Cheung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_ScoreHypo_Probabilistic_Human_Mesh_Estimation_with_Hypothesis_Scoring_CVPR_2024_paper.html": {
    "title": "ScoreHypo: Probabilistic Human Mesh Estimation with Hypothesis Scoring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuan Xu",
      "Xiaoxuan Ma",
      "Jiajun Su",
      "Wentao Zhu",
      "Yu Qiao",
      "Yizhou Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hamdi_GES__Generalized_Exponential_Splatting_for_Efficient_Radiance_Field_Rendering_CVPR_2024_paper.html": {
    "title": "GES : Generalized Exponential Splatting for Efficient Radiance Field Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdullah Hamdi",
      "Luke Melas-Kyriazi",
      "Jinjie Mai",
      "Guocheng Qian",
      "Ruoshi Liu",
      "Carl Vondrick",
      "Bernard Ghanem",
      "Andrea Vedaldi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Donahue_Learning_to_Predict_Activity_Progress_by_Self-Supervised_Video_Alignment_CVPR_2024_paper.html": {
    "title": "Learning to Predict Activity Progress by Self-Supervised Video Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gerard Donahue",
      "Ehsan Elhamifar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kahatapitiya_VicTR_Video-conditioned_Text_Representations_for_Activity_Recognition_CVPR_2024_paper.html": {
    "title": "VicTR: Video-conditioned Text Representations for Activity Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kumara Kahatapitiya",
      "Anurag Arnab",
      "Arsha Nagrani",
      "Michael S. Ryoo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Label-Efficient_Group_Robustness_via_Out-of-Distribution_Concept_Curation_CVPR_2024_paper.html": {
    "title": "Label-Efficient Group Robustness via Out-of-Distribution Concept Curation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwei Yang",
      "Anthony Z. Liu",
      "Robert Wolfe",
      "Aylin Caliskan",
      "Bill Howe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_MMCert_Provable_Defense_against_Adversarial_Attacks_to_Multi-modal_Models_CVPR_2024_paper.html": {
    "title": "MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanting Wang",
      "Hongye Fu",
      "Wei Zou",
      "Jinyuan Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Men_3DToonify_Creating_Your_High-Fidelity_3D_Stylized_Avatar_Easily_from_2D_CVPR_2024_paper.html": {
    "title": "3DToonify: Creating Your High-Fidelity 3D Stylized Avatar Easily from 2D Portrait Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifang Men",
      "Hanxi Liu",
      "Yuan Yao",
      "Miaomiao Cui",
      "Xuansong Xie",
      "Zhouhui Lian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tran_NAYER_Noisy_Layer_Data_Generation_for_Efficient_and_Effective_Data-free_CVPR_2024_paper.html": {
    "title": "NAYER: Noisy Layer Data Generation for Efficient and Effective Data-free Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minh-Tuan Tran",
      "Trung Le",
      "Xuan-May Le",
      "Mehrtash Harandi",
      "Quan Hung Tran",
      "Dinh Phung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Srivastava_OmniVec2_-_A_Novel_Transformer_based_Network_for_Large_Scale_CVPR_2024_paper.html": {
    "title": "OmniVec2 - A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Srivastava",
      "Gaurav Sharma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_Investigating_Compositional_Challenges_in_Vision-Language_Models_for_Visual_Grounding_CVPR_2024_paper.html": {
    "title": "Investigating Compositional Challenges in Vision-Language Models for Visual Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunan Zeng",
      "Yan Huang",
      "Jinjin Zhang",
      "Zequn Jie",
      "Zhenhua Chai",
      "Liang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_6D-Diff_A_Keypoint_Diffusion_Framework_for_6D_Object_Pose_Estimation_CVPR_2024_paper.html": {
    "title": "6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Xu",
      "Haoxuan Qu",
      "Yujun Cai",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Generative_Region-Language_Pretraining_for_Open-Ended_Object_Detection_CVPR_2024_paper.html": {
    "title": "Generative Region-Language Pretraining for Open-Ended Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuang Lin",
      "Yi Jiang",
      "Lizhen Qu",
      "Zehuan Yuan",
      "Jianfei Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shang_Enhancing_Post-training_Quantization_Calibration_through_Contrastive_Learning_CVPR_2024_paper.html": {
    "title": "Enhancing Post-training Quantization Calibration through Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhang Shang",
      "Gaowen Liu",
      "Ramana Rao Kompella",
      "Yan Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Efficient_Model_Stealing_Defense_with_Noise_Transition_Matrix_CVPR_2024_paper.html": {
    "title": "Efficient Model Stealing Defense with Noise Transition Matrix",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong-Dong Wu",
      "Chilin Fu",
      "Weichang Wu",
      "Wenwen Xia",
      "Xiaolu Zhang",
      "Jun Zhou",
      "Min-Ling Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Le_MeshPose_Unifying_DensePose_and_3D_Body_Mesh_Reconstruction_CVPR_2024_paper.html": {
    "title": "MeshPose: Unifying DensePose and 3D Body Mesh Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eric-Tuan Le",
      "Antonis Kakolyris",
      "Petros Koutras",
      "Himmy Tam",
      "Efstratios Skordos",
      "George Papandreou",
      "Riza Alp Güler",
      "Iasonas Kokkinos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tian_Unsupervised_Salient_Instance_Detection_CVPR_2024_paper.html": {
    "title": "Unsupervised Salient Instance Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Tian",
      "Ke Xu",
      "Rynson Lau"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Enhancing_Visual_Document_Understanding_with_Contrastive_Learning_in_Large_Visual-Language_CVPR_2024_paper.html": {
    "title": "Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Li",
      "Yunfei Wu",
      "Xinghua Jiang",
      "Zhihao Guo",
      "Mingming Gong",
      "Haoyu Cao",
      "Yinsong Liu",
      "Deqiang Jiang",
      "Xing Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_Move_Anything_with_Layered_Scene_Diffusion_CVPR_2024_paper.html": {
    "title": "Move Anything with Layered Scene Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiawei Ren",
      "Mengmeng Xu",
      "Jui-Chieh Wu",
      "Ziwei Liu",
      "Tao Xiang",
      "Antoine Toisoul"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_GS-SLAM_Dense_Visual_SLAM_with_3D_Gaussian_Splatting_CVPR_2024_paper.html": {
    "title": "GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi Yan",
      "Delin Qu",
      "Dan Xu",
      "Bin Zhao",
      "Zhigang Wang",
      "Dong Wang",
      "Xuelong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Scaffold-GS_Structured_3D_Gaussians_for_View-Adaptive_Rendering_CVPR_2024_paper.html": {
    "title": "Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Lu",
      "Mulin Yu",
      "Linning Xu",
      "Yuanbo Xiangli",
      "Limin Wang",
      "Dahua Lin",
      "Bo Dai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Data_Valuation_and_Detections_in_Federated_Learning_CVPR_2024_paper.html": {
    "title": "Data Valuation and Detections in Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenqian Li",
      "Shuran Fu",
      "Fengrui Zhang",
      "Yan Pang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cui_Classes_Are_Not_Equal_An_Empirical_Study_on_Image_Recognition_CVPR_2024_paper.html": {
    "title": "Classes Are Not Equal: An Empirical Study on Image Recognition Fairness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiequan Cui",
      "Beier Zhu",
      "Xin Wen",
      "Xiaojuan Qi",
      "Bei Yu",
      "Hanwang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Moreau_Human_Gaussian_Splatting_Real-time_Rendering_of_Animatable_Avatars_CVPR_2024_paper.html": {
    "title": "Human Gaussian Splatting: Real-time Rendering of Animatable Avatars",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arthur Moreau",
      "Jifei Song",
      "Helisa Dhamo",
      "Richard Shaw",
      "Yiren Zhou",
      "Eduardo Pérez-Pellitero"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yan_Multi-Scale_3D_Gaussian_Splatting_for_Anti-Aliased_Rendering_CVPR_2024_paper.html": {
    "title": "Multi-Scale 3D Gaussian Splatting for Anti-Aliased Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwen Yan",
      "Weng Fei Low",
      "Yu Chen",
      "Gim Hee Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kaushik_A_Bayesian_Approach_to_OOD_Robustness_in_Image_Classification_CVPR_2024_paper.html": {
    "title": "A Bayesian Approach to OOD Robustness in Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prakhar Kaushik",
      "Adam Kortylewski",
      "Alan Yuille"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Unified-IO_2_Scaling_Autoregressive_Multimodal_Models_with_Vision_Language_Audio_CVPR_2024_paper.html": {
    "title": "Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision Language Audio and Action",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiasen Lu",
      "Christopher Clark",
      "Sangho Lee",
      "Zichen Zhang",
      "Savya Khosla",
      "Ryan Marten",
      "Derek Hoiem",
      "Aniruddha Kembhavi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nam_Joint_Reconstruction_of_3D_Human_and_Object_via_Contact-Based_Refinement_CVPR_2024_paper.html": {
    "title": "Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeongjin Nam",
      "Daniel Sungho Jung",
      "Gyeongsik Moon",
      "Kyoung Mu Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chalk_TIM_A_Time_Interval_Machine_for_Audio-Visual_Action_Recognition_CVPR_2024_paper.html": {
    "title": "TIM: A Time Interval Machine for Audio-Visual Action Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob Chalk",
      "Jaesung Huh",
      "Evangelos Kazakos",
      "Andrew Zisserman",
      "Dima Damen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bobkov_The_Devil_is_in_the_Details_StyleFeatureEditor_for_Detail-Rich_StyleGAN_CVPR_2024_paper.html": {
    "title": "The Devil is in the Details: StyleFeatureEditor for Detail-Rich StyleGAN Inversion and High Quality Image Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Denis Bobkov",
      "Vadim Titov",
      "Aibek Alanov",
      "Dmitry Vetrov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Song_Unbiased_Estimator_for_Distorted_Conics_in_Camera_Calibration_CVPR_2024_paper.html": {
    "title": "Unbiased Estimator for Distorted Conics in Camera Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaehyeon Song",
      "Jaeho Shin",
      "Myung-Hwan Jeon",
      "Jongwoo Lim",
      "Ayoung Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ugrinovic_MultiPhys_Multi-Person_Physics-aware_3D_Motion_Estimation_CVPR_2024_paper.html": {
    "title": "MultiPhys: Multi-Person Physics-aware 3D Motion Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Ugrinovic",
      "Boxiao Pan",
      "Georgios Pavlakos",
      "Despoina Paschalidou",
      "Bokui Shen",
      "Jordi Sanchez-Riera",
      "Francesc Moreno-Noguer",
      "Leonidas Guibas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fischer_Multi-Level_Neural_Scene_Graphs_for_Dynamic_Urban_Environments_CVPR_2024_paper.html": {
    "title": "Multi-Level Neural Scene Graphs for Dynamic Urban Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias Fischer",
      "Lorenzo Porzi",
      "Samuel Rota Bulo",
      "Marc Pollefeys",
      "Peter Kontschieder"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Would_Deep_Generative_Models_Amplify_Bias_in_Future_Models_CVPR_2024_paper.html": {
    "title": "Would Deep Generative Models Amplify Bias in Future Models?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianwei Chen",
      "Yusuke Hirota",
      "Mayu Otani",
      "Noa Garcia",
      "Yuta Nakashima"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Goli_Bayes_Rays_Uncertainty_Quantification_for_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lily Goli",
      "Cody Reading",
      "Silvia Sellán",
      "Alec Jacobson",
      "Andrea Tagliasacchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Thamizharasan_NIVeL_Neural_Implicit_Vector_Layers_for_Text-to-Vector_Generation_CVPR_2024_paper.html": {
    "title": "NIVeL: Neural Implicit Vector Layers for Text-to-Vector Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vikas Thamizharasan",
      "Difan Liu",
      "Matthew Fisher",
      "Nanxuan Zhao",
      "Evangelos Kalogerakis",
      "Michal Lukac"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Driving-Video_Dehazing_with_Non-Aligned_Regularization_for_Safety_Assistance_CVPR_2024_paper.html": {
    "title": "Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junkai Fan",
      "Jiangwei Weng",
      "Kun Wang",
      "Yijun Yang",
      "Jianjun Qian",
      "Jun Li",
      "Jian Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhu_Is_Vanilla_MLP_in_Neural_Radiance_Field_Enough_for_Few-shot_CVPR_2024_paper.html": {
    "title": "Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View Synthesis?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanxin Zhu",
      "Tianyu He",
      "Xin Li",
      "Bingchen Li",
      "Zhibo Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhong_CVT-xRF_Contrastive_In-Voxel_Transformer_for_3D_Consistent_Radiance_Fields_from_CVPR_2024_paper.html": {
    "title": "CVT-xRF: Contrastive In-Voxel Transformer for 3D Consistent Radiance Fields from Sparse Inputs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingji Zhong",
      "Lanqing Hong",
      "Zhenguo Li",
      "Dan Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhan_OAKINK2_A_Dataset_of_Bimanual_Hands-Object_Manipulation_in_Complex_Task_CVPR_2024_paper.html": {
    "title": "OAKINK2: A Dataset of Bimanual Hands-Object Manipulation in Complex Task Completion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhan",
      "Lixin Yang",
      "Yifei Zhao",
      "Kangrui Mao",
      "Hanlin Xu",
      "Zenan Lin",
      "Kailin Li",
      "Cewu Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hong_CogAgent_A_Visual_Language_Model_for_GUI_Agents_CVPR_2024_paper.html": {
    "title": "CogAgent: A Visual Language Model for GUI Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyi Hong",
      "Weihan Wang",
      "Qingsong Lv",
      "Jiazheng Xu",
      "Wenmeng Yu",
      "Junhui Ji",
      "Yan Wang",
      "Zihan Wang",
      "Yuxiao Dong",
      "Ming Ding",
      "Jie Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_Text-Guided_3D_Face_Synthesis_-_From_Generation_to_Editing_CVPR_2024_paper.html": {
    "title": "Text-Guided 3D Face Synthesis - From Generation to Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunjie Wu",
      "Yapeng Meng",
      "Zhipeng Hu",
      "Lincheng Li",
      "Haoqian Wu",
      "Kun Zhou",
      "Weiwei Xu",
      "Xin Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_AIDE_An_Automatic_Data_Engine_for_Object_Detection_in_Autonomous_CVPR_2024_paper.html": {
    "title": "AIDE: An Automatic Data Engine for Object Detection in Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingfu Liang",
      "Jong-Chyi Su",
      "Samuel Schulter",
      "Sparsh Garg",
      "Shiyu Zhao",
      "Ying Wu",
      "Manmohan Chandraker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_Multiplane_Prior_Guided_Few-Shot_Aerial_Scene_Rendering_CVPR_2024_paper.html": {
    "title": "Multiplane Prior Guided Few-Shot Aerial Scene Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihan Gao",
      "Licheng Jiao",
      "Lingling Li",
      "Xu Liu",
      "Fang Liu",
      "Puhua Chen",
      "Yuwei Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kapon_MAS_Multi-view_Ancestral_Sampling_for_3D_Motion_Generation_Using_2D_CVPR_2024_paper.html": {
    "title": "MAS: Multi-view Ancestral Sampling for 3D Motion Generation Using 2D Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roy Kapon",
      "Guy Tevet",
      "Daniel Cohen-Or",
      "Amit H. Bermano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Smart_Help_Strategic_Opponent_Modeling_for_Proactive_and_Adaptive_Robot_CVPR_2024_paper.html": {
    "title": "Smart Help: Strategic Opponent Modeling for Proactive and Adaptive Robot Assistance in Households",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihao Cao",
      "Zidong Wang",
      "Siwen Xie",
      "Anji Liu",
      "Lifeng Fan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Bilateral_Event_Mining_and_Complementary_for_Event_Stream_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Bilateral Event Mining and Complementary for Event Stream Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhilin Huang",
      "Quanmin Liang",
      "Yijie Yu",
      "Chujun Qin",
      "Xiawu Zheng",
      "Kai Huang",
      "Zikun Zhou",
      "Wenming Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Online_Task-Free_Continual_Generative_and_Discriminative_Learning_via_Dynamic_Cluster_CVPR_2024_paper.html": {
    "title": "Online Task-Free Continual Generative and Discriminative Learning via Dynamic Cluster Memory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Ye",
      "Adrian G. Bors"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liang_Rapid_Motor_Adaptation_for_Robotic_Manipulator_Arms_CVPR_2024_paper.html": {
    "title": "Rapid Motor Adaptation for Robotic Manipulator Arms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichao Liang",
      "Kevin Ellis",
      "João Henriques"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_SANeRF-HQ_Segment_Anything_for_NeRF_in_High_Quality_CVPR_2024_paper.html": {
    "title": "SANeRF-HQ: Segment Anything for NeRF in High Quality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Liu",
      "Benran Hu",
      "Chi-Keung Tang",
      "Yu-Wing Tai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hayder_DSGG_Dense_Relation_Transformer_for_an_End-to-end_Scene_Graph_Generation_CVPR_2024_paper.html": {
    "title": "DSGG: Dense Relation Transformer for an End-to-end Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeeshan Hayder",
      "Xuming He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Transcending_the_Limit_of_Local_Window_Advanced_Super-Resolution_Transformer_with_CVPR_2024_paper.html": {
    "title": "Transcending the Limit of Local Window: Advanced Super-Resolution Transformer with Adaptive Token Dictionary",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leheng Zhang",
      "Yawei Li",
      "Xingyu Zhou",
      "Xiaorui Zhao",
      "Shuhang Gu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kim_Object_Dynamics_Modeling_with_Hierarchical_Point_Cloud-based_Representations_CVPR_2024_paper.html": {
    "title": "Object Dynamics Modeling with Hierarchical Point Cloud-based Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chanho Kim",
      "Li Fuxin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ahn_WWW_A_Unified_Framework_for_Explaining_What_Where_and_Why_CVPR_2024_paper.html": {
    "title": "WWW: A Unified Framework for Explaining What Where and Why of Neural Networks by Interpretation of Neuron Concepts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yong Hyun Ahn",
      "Hyeon Bae Kim",
      "Seong Tae Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_SkySense_A_Multi-Modal_Remote_Sensing_Foundation_Model_Towards_Universal_Interpretation_CVPR_2024_paper.html": {
    "title": "SkySense: A Multi-Modal Remote Sensing Foundation Model Towards Universal Interpretation for Earth Observation Imagery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Guo",
      "Jiangwei Lao",
      "Bo Dang",
      "Yingying Zhang",
      "Lei Yu",
      "Lixiang Ru",
      "Liheng Zhong",
      "Ziyuan Huang",
      "Kang Wu",
      "Dingxiang Hu",
      "Huimei He",
      "Jian Wang",
      "Jingdong Chen",
      "Ming Yang",
      "Yongjun Zhang",
      "Yansheng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_CaKDP_Category-aware_Knowledge_Distillation_and_Pruning_Framework_for_Lightweight_3D_CVPR_2024_paper.html": {
    "title": "CaKDP: Category-aware Knowledge Distillation and Pruning Framework for Lightweight 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haonan Zhang",
      "Longjun Liu",
      "Yuqi Huang",
      "Zhao Yang",
      "Xinyu Lei",
      "Bihan Wen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Mixed-Precision_Quantization_for_Federated_Learning_on_Resource-Constrained_Heterogeneous_Devices_CVPR_2024_paper.html": {
    "title": "Mixed-Precision Quantization for Federated Learning on Resource-Constrained Heterogeneous Devices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huancheng Chen",
      "Haris Vikalo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ray_CFAT_Unleashing_Triangular_Windows_for_Image_Super-resolution_CVPR_2024_paper.html": {
    "title": "CFAT: Unleashing Triangular Windows for Image Super-resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhisek Ray",
      "Gaurav Kumar",
      "Maheshkumar H. Kolekar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_ICP-Flow_LiDAR_Scene_Flow_Estimation_with_ICP_CVPR_2024_paper.html": {
    "title": "ICP-Flow: LiDAR Scene Flow Estimation with ICP",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yancong Lin",
      "Holger Caesar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer_CVPR_2024_paper.html": {
    "title": "MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianjian Cao",
      "Peng Ye",
      "Shengze Li",
      "Chong Yu",
      "Yansong Tang",
      "Jiwen Lu",
      "Tao Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_G-NeRF_Geometry-enhanced_Novel_View_Synthesis_from_Single-View_Images_CVPR_2024_paper.html": {
    "title": "G-NeRF: Geometry-enhanced Novel View Synthesis from Single-View Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixiong Huang",
      "Qi Chen",
      "Libo Sun",
      "Yifan Yang",
      "Naizhou Wang",
      "Qi Wu",
      "Mingkui Tan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Rebain_Neural_Fields_as_Distributions_Signal_Processing_Beyond_Euclidean_Space_CVPR_2024_paper.html": {
    "title": "Neural Fields as Distributions: Signal Processing Beyond Euclidean Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Rebain",
      "Soroosh Yazdani",
      "Kwang Moo Yi",
      "Andrea Tagliasacchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Rolling_Shutter_Correction_with_Intermediate_Distortion_Flow_Estimation_CVPR_2024_paper.html": {
    "title": "Rolling Shutter Correction with Intermediate Distortion Flow Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingdeng Cao",
      "Sidi Yang",
      "Yujiu Yang",
      "Yinqiang Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ahn_Style_Blind_Domain_Generalized_Semantic_Segmentation_via_Covariance_Alignment_and_CVPR_2024_paper.html": {
    "title": "Style Blind Domain Generalized Semantic Segmentation via Covariance Alignment and Semantic Consistence Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Woo-Jin Ahn",
      "Geun-Yeong Yang",
      "Hyun-Duck Choi",
      "Myo-Taeg Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fares_Attack_To_Defend_Exploiting_Adversarial_Attacks_for_Detecting_Poisoned_Models_CVPR_2024_paper.html": {
    "title": "Attack To Defend: Exploiting Adversarial Attacks for Detecting Poisoned Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samar Fares",
      "Karthik Nandakumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_X-3D_Explicit_3D_Structure_Modeling_for_Point_Cloud_Recognition_CVPR_2024_paper.html": {
    "title": "X-3D: Explicit 3D Structure Modeling for Point Cloud Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuofeng Sun",
      "Yongming Rao",
      "Jiwen Lu",
      "Haibin Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Roetzer_SpiderMatch_3D_Shape_Matching_with_Global_Optimality_and_Geometric_Consistency_CVPR_2024_paper.html": {
    "title": "SpiderMatch: 3D Shape Matching with Global Optimality and Geometric Consistency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paul Roetzer",
      "Florian Bernard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Troika_Multi-Path_Cross-Modal_Traction_for_Compositional_Zero-Shot_Learning_CVPR_2024_paper.html": {
    "title": "Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siteng Huang",
      "Biao Gong",
      "Yutong Feng",
      "Min Zhang",
      "Yiliang Lv",
      "Donglin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_One_More_Step_A_Versatile_Plug-and-Play_Module_for_Rectifying_Diffusion_CVPR_2024_paper.html": {
    "title": "One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion Schedule Flaws and Enhancing Low-Frequency Controls",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minghui Hu",
      "Jianbin Zheng",
      "Chuanxia Zheng",
      "Chaoyue Wang",
      "Dacheng Tao",
      "Tat-Jen Cham"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_Enhancing_Multimodal_Cooperation_via_Sample-level_Modality_Valuation_CVPR_2024_paper.html": {
    "title": "Enhancing Multimodal Cooperation via Sample-level Modality Valuation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yake Wei",
      "Ruoxuan Feng",
      "Zihe Wang",
      "Di Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fan_Evidential_Active_Recognition_Intelligent_and_Prudent_Open-World_Embodied_Perception_CVPR_2024_paper.html": {
    "title": "Evidential Active Recognition: Intelligent and Prudent Open-World Embodied Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lei Fan",
      "Mingfu Liang",
      "Yunxuan Li",
      "Gang Hua",
      "Ying Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Toker_SatSynth_Augmenting_Image-Mask_Pairs_through_Diffusion_Models_for_Aerial_Semantic_CVPR_2024_paper.html": {
    "title": "SatSynth: Augmenting Image-Mask Pairs through Diffusion Models for Aerial Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aysim Toker",
      "Marvin Eisenberger",
      "Daniel Cremers",
      "Laura Leal-Taixé"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_XScale-NVS_Cross-Scale_Novel_View_Synthesis_with_Hash_Featurized_Manifold_CVPR_2024_paper.html": {
    "title": "XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangyu Wang",
      "Jinzhi Zhang",
      "Fan Wang",
      "Ruqi Huang",
      "Lu Fang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_Ink_Dot-Oriented_Differentiable_Optimization_for_Neural_Image_Halftoning_CVPR_2024_paper.html": {
    "title": "Ink Dot-Oriented Differentiable Optimization for Neural Image Halftoning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Jiang",
      "Bingfeng Zhou",
      "Yadong Mu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Trivigno_The_Unreasonable_Effectiveness_of_Pre-Trained_Features_for_Camera_Pose_Refinement_CVPR_2024_paper.html": {
    "title": "The Unreasonable Effectiveness of Pre-Trained Features for Camera Pose Refinement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriele Trivigno",
      "Carlo Masone",
      "Barbara Caputo",
      "Torsten Sattler"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Scalable_3D_Registration_via_Truncated_Entry-wise_Absolute_Residuals_CVPR_2024_paper.html": {
    "title": "Scalable 3D Registration via Truncated Entry-wise Absolute Residuals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Huang",
      "Liangzu Peng",
      "Rene Vidal",
      "Yun-Hui Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shih_ExtraNeRF_Visibility-Aware_View_Extrapolation_of_Neural_Radiance_Fields_with_Diffusion_CVPR_2024_paper.html": {
    "title": "ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Meng-Li Shih",
      "Wei-Chiu Ma",
      "Lorenzo Boyice",
      "Aleksander Holynski",
      "Forrester Cole",
      "Brian Curless",
      "Janne Kontkanen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Terris_Equivariant_Plug-and-Play_Image_Reconstruction_CVPR_2024_paper.html": {
    "title": "Equivariant Plug-and-Play Image Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthieu Terris",
      "Thomas Moreau",
      "Nelly Pustelnik",
      "Julian Tachella"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sun_CLIP_as_RNN_Segment_Countless_Visual_Concepts_without_Training_Endeavor_CVPR_2024_paper.html": {
    "title": "CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuyang Sun",
      "Runjia Li",
      "Philip Torr",
      "Xiuye Gu",
      "Siyang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_LP_A_Surprisingly_Strong_Linear_Probe_for_Few-Shot_CLIP_CVPR_2024_paper.html": {
    "title": "LP++: A Surprisingly Strong Linear Probe for Few-Shot CLIP",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunshi Huang",
      "Fereshteh Shakeri",
      "Jose Dolz",
      "Malik Boudiaf",
      "Houda Bahig",
      "Ismail Ben Ayed"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ma_Active_Generalized_Category_Discovery_CVPR_2024_paper.html": {
    "title": "Active Generalized Category Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shijie Ma",
      "Fei Zhu",
      "Zhun Zhong",
      "Xu-Yao Zhang",
      "Cheng-Lin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_HIVE_Harnessing_Human_Feedback_for_Instructional_Visual_Editing_CVPR_2024_paper.html": {
    "title": "HIVE: Harnessing Human Feedback for Instructional Visual Editing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shu Zhang",
      "Xinyi Yang",
      "Yihao Feng",
      "Can Qin",
      "Chia-Chih Chen",
      "Ning Yu",
      "Zeyuan Chen",
      "Huan Wang",
      "Silvio Savarese",
      "Stefano Ermon",
      "Caiming Xiong",
      "Ran Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_StrokeFaceNeRF_Stroke-based_Facial_Appearance_Editing_in_Neural_Radiance_Field_CVPR_2024_paper.html": {
    "title": "StrokeFaceNeRF: Stroke-based Facial Appearance Editing in Neural Radiance Field",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao-Juan Li",
      "Dingxi Zhang",
      "Shu-Yu Chen",
      "Feng-Lin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tan_FlowVQTalker_High-Quality_Emotional_Talking_Face_Generation_through_Normalizing_Flow_and_CVPR_2024_paper.html": {
    "title": "FlowVQTalker: High-Quality Emotional Talking Face Generation through Normalizing Flow and Quantization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Tan",
      "Bin Ji",
      "Ye Pan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Learning_from_Observer_Gaze_Zero-Shot_Attention_Prediction_Oriented_by_Human-Object_CVPR_2024_paper.html": {
    "title": "Learning from Observer Gaze: Zero-Shot Attention Prediction Oriented by Human-Object Interaction Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen Zhou",
      "Linkai Liu",
      "Chao Gou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_ProxyCap_Real-time_Monocular_Full-body_Capture_in_World_Space_via_Human-Centric_CVPR_2024_paper.html": {
    "title": "ProxyCap: Real-time Monocular Full-body Capture in World Space via Human-Centric Proxy-to-Motion Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiang Zhang",
      "Hongwen Zhang",
      "Liangxiao Hu",
      "Jiajun Zhang",
      "Hongwei Yi",
      "Shengping Zhang",
      "Yebin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/DInca_OpenBias_Open-set_Bias_Detection_in_Text-to-Image_Generative_Models_CVPR_2024_paper.html": {
    "title": "OpenBias: Open-set Bias Detection in Text-to-Image Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moreno D'Incà",
      "Elia Peruzzo",
      "Massimiliano Mancini",
      "Dejia Xu",
      "Vidit Goel",
      "Xingqian Xu",
      "Zhangyang Wang",
      "Humphrey Shi",
      "Nicu Sebe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chatterjee_On_the_Robustness_of_Language_Guidance_for_Low-Level_Vision_Tasks_CVPR_2024_paper.html": {
    "title": "On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Agneet Chatterjee",
      "Tejas Gokhale",
      "Chitta Baral",
      "Yezhou Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_UFOGen_You_Forward_Once_Large_Scale_Text-to-Image_Generation_via_Diffusion_CVPR_2024_paper.html": {
    "title": "UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanwu Xu",
      "Yang Zhao",
      "Zhisheng Xiao",
      "Tingbo Hou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_3DiffTection_3D_Object_Detection_with_Geometry-Aware_Diffusion_Features_CVPR_2024_paper.html": {
    "title": "3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenfeng Xu",
      "Huan Ling",
      "Sanja Fidler",
      "Or Litany"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/T_Lift3D_Zero-Shot_Lifting_of_Any_2D_Vision_Model_to_3D_CVPR_2024_paper.html": {
    "title": "Lift3D: Zero-Shot Lifting of Any 2D Vision Model to 3D",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mukund Varma T",
      "Peihao Wang",
      "Zhiwen Fan",
      "Zhangyang Wang",
      "Hao Su",
      "Ravi Ramamoorthi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_LowRankOcc_Tensor_Decomposition_and_Low-Rank_Recovery_for_Vision-based_3D_Semantic_CVPR_2024_paper.html": {
    "title": "LowRankOcc: Tensor Decomposition and Low-Rank Recovery for Vision-based 3D Semantic Occupancy Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Linqing Zhao",
      "Xiuwei Xu",
      "Ziwei Wang",
      "Yunpeng Zhang",
      "Borui Zhang",
      "Wenzhao Zheng",
      "Dalong Du",
      "Jie Zhou",
      "Jiwen Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jin_Multiway_Point_Cloud_Mosaicking_with_Diffusion_and_Global_Optimization_CVPR_2024_paper.html": {
    "title": "Multiway Point Cloud Mosaicking with Diffusion and Global Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengze Jin",
      "Iro Armeni",
      "Marc Pollefeys",
      "Daniel Barath"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Bello_Novel_View_Synthesis_with_View-Dependent_Effects_from_a_Single_Image_CVPR_2024_paper.html": {
    "title": "Novel View Synthesis with View-Dependent Effects from a Single Image",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juan Luis Gonzalez Bello",
      "Munchurl Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yu_Point2RBox_Combine_Knowledge_from_Synthetic_Visual_Patterns_for_End-to-end_Oriented_CVPR_2024_paper.html": {
    "title": "Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Yu",
      "Xue Yang",
      "Qingyun Li",
      "Feipeng Da",
      "Jifeng Dai",
      "Yu Qiao",
      "Junchi Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_PBWR_Parametric-Building-Wireframe_Reconstruction_from_Aerial_LiDAR_Point_Clouds_CVPR_2024_paper.html": {
    "title": "PBWR: Parametric-Building-Wireframe Reconstruction from Aerial LiDAR Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangfeng Huang",
      "Ruisheng Wang",
      "Bo Guo",
      "Hongxin Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Luan_Spectrum_AUC_Difference_SAUCD_Human-aligned_3D_Shape_Evaluation_CVPR_2024_paper.html": {
    "title": "Spectrum AUC Difference (SAUCD): Human-aligned 3D Shape Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Luan",
      "Zhong Li",
      "Lele Chen",
      "Xuan Gong",
      "Lichang Chen",
      "Yi Xu",
      "Junsong Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_HRVDA_High-Resolution_Visual_Document_Assistant_CVPR_2024_paper.html": {
    "title": "HRVDA: High-Resolution Visual Document Assistant",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaohu Liu",
      "Kun Yin",
      "Haoyu Cao",
      "Xinghua Jiang",
      "Xin Li",
      "Yinsong Liu",
      "Deqiang Jiang",
      "Xing Sun",
      "Linli Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Learning_for_Transductive_Threshold_Calibration_in_Open-World_Recognition_CVPR_2024_paper.html": {
    "title": "Learning for Transductive Threshold Calibration in Open-World Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qin Zhang",
      "Dongsheng An",
      "Tianjun Xiao",
      "Tong He",
      "Qingming Tang",
      "Ying Nian Wu",
      "Joseph Tighe",
      "Yifan Xing"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_Weakly-Supervised_Emotion_Transition_Learning_for_Diverse_3D_Co-speech_Gesture_Generation_CVPR_2024_paper.html": {
    "title": "Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech Gesture Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingqun Qi",
      "Jiahao Pan",
      "Peng Li",
      "Ruibin Yuan",
      "Xiaowei Chi",
      "Mengfei Li",
      "Wenhan Luo",
      "Wei Xue",
      "Shanghang Zhang",
      "Qifeng Liu",
      "Yike Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lipson_Multi-Session_SLAM_with_Differentiable_Wide-Baseline_Pose_Optimization_CVPR_2024_paper.html": {
    "title": "Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lahav Lipson",
      "Jia Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Peng_A_Dual-Augmentor_Framework_for_Domain_Generalization_in_3D_Human_Pose_CVPR_2024_paper.html": {
    "title": "A Dual-Augmentor Framework for Domain Generalization in 3D Human Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qucheng Peng",
      "Ce Zheng",
      "Chen Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Piao_Improving_Out-of-Distribution_Generalization_in_Graphs_via_Hierarchical_Semantic_Environments_CVPR_2024_paper.html": {
    "title": "Improving Out-of-Distribution Generalization in Graphs via Hierarchical Semantic Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinhua Piao",
      "Sangseon Lee",
      "Yijingxiu Lu",
      "Sun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shen_CN-RMA_Combined_Network_with_Ray_Marching_Aggregation_for_3D_Indoor_CVPR_2024_paper.html": {
    "title": "CN-RMA: Combined Network with Ray Marching Aggregation for 3D Indoor Object Detection from Multi-view Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guanlin Shen",
      "Jingwei Huang",
      "Zhihua Hu",
      "Bin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kong_ACT-Diffusion_Efficient_Adversarial_Consistency_Training_for_One-step_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Kong",
      "Jinhao Duan",
      "Lichao Sun",
      "Hao Cheng",
      "Renjing Xu",
      "Hengtao Shen",
      "Xiaofeng Zhu",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Spectral_Meets_Spatial_Harmonising_3D_Shape_Matching_and_Interpolation_CVPR_2024_paper.html": {
    "title": "Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongliang Cao",
      "Marvin Eisenberger",
      "Nafie El Amrani",
      "Daniel Cremers",
      "Florian Bernard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Sheynin_Emu_Edit_Precise_Image_Editing_via_Recognition_and_Generation_Tasks_CVPR_2024_paper.html": {
    "title": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shelly Sheynin",
      "Adam Polyak",
      "Uriel Singer",
      "Yuval Kirstain",
      "Amit Zohar",
      "Oron Ashual",
      "Devi Parikh",
      "Yaniv Taigman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shiohara_Face2Diffusion_for_Fast_and_Editable_Face_Personalization_CVPR_2024_paper.html": {
    "title": "Face2Diffusion for Fast and Editable Face Personalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaede Shiohara",
      "Toshihiko Yamasaki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Causal-CoG_A_Causal-Effect_Look_at_Context_Generation_for_Boosting_Multi-modal_CVPR_2024_paper.html": {
    "title": "Causal-CoG: A Causal-Effect Look at Context Generation for Boosting Multi-modal Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shitian Zhao",
      "Zhuowan Li",
      "Yadong Lu",
      "Alan Yuille",
      "Yan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lou_Hide_in_Thicket_Generating_Imperceptible_and_Rational_Adversarial_Perturbations_on_CVPR_2024_paper.html": {
    "title": "Hide in Thicket: Generating Imperceptible and Rational Adversarial Perturbations on 3D Point Clouds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianrui Lou",
      "Xiaojun Jia",
      "Jindong Gu",
      "Li Liu",
      "Siyuan Liang",
      "Bangyan He",
      "Xiaochun Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_SG-BEV_Satellite-Guided_BEV_Fusion_for_Cross-View_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "SG-BEV: Satellite-Guided BEV Fusion for Cross-View Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyan Ye",
      "Qiyan Luo",
      "Jinhua Yu",
      "Huaping Zhong",
      "Zhimeng Zheng",
      "Conghui He",
      "Weijia Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chiu_Brush2Prompt_Contextual_Prompt_Generator_for_Object_Inpainting_CVPR_2024_paper.html": {
    "title": "Brush2Prompt: Contextual Prompt Generator for Object Inpainting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mang Tik Chiu",
      "Yuqian Zhou",
      "Lingzhi Zhang",
      "Zhe Lin",
      "Connelly Barnes",
      "Sohrab Amirghodsi",
      "Eli Shechtman",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nishi_Joint-Task_Regularization_for_Partially_Labeled_Multi-Task_Learning_CVPR_2024_paper.html": {
    "title": "Joint-Task Regularization for Partially Labeled Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kento Nishi",
      "Junsik Kim",
      "Wanhua Li",
      "Hanspeter Pfister"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Shallow-Deep_Collaborative_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_CVPR_2024_paper.html": {
    "title": "Shallow-Deep Collaborative Learning for Unsupervised Visible-Infrared Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Yang",
      "Jun Chen",
      "Mang Ye"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Dancing_with_Still_Images_Video_Distillation_via_Static-Dynamic_Disentanglement_CVPR_2024_paper.html": {
    "title": "Dancing with Still Images: Video Distillation via Static-Dynamic Disentanglement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Wang",
      "Yue Xu",
      "Cewu Lu",
      "Yong-Lu Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shao_Context-Aware_Integration_of_Language_and_Visual_References_for_Natural_Language_CVPR_2024_paper.html": {
    "title": "Context-Aware Integration of Language and Visual References for Natural Language Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanyan Shao",
      "Shuting He",
      "Qi Ye",
      "Yuchao Feng",
      "Wenhan Luo",
      "Jiming Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huberman-Spiegelglas_An_Edit_Friendly_DDPM_Noise_Space_Inversion_and_Manipulations_CVPR_2024_paper.html": {
    "title": "An Edit Friendly DDPM Noise Space: Inversion and Manipulations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Inbar Huberman-Spiegelglas",
      "Vladimir Kulikov",
      "Tomer Michaeli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_LEAP-VO_Long-term_Effective_Any_Point_Tracking_for_Visual_Odometry_CVPR_2024_paper.html": {
    "title": "LEAP-VO: Long-term Effective Any Point Tracking for Visual Odometry",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weirong Chen",
      "Le Chen",
      "Rui Wang",
      "Marc Pollefeys"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_RoDLA_Benchmarking_the_Robustness_of_Document_Layout_Analysis_Models_CVPR_2024_paper.html": {
    "title": "RoDLA: Benchmarking the Robustness of Document Layout Analysis Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yufan Chen",
      "Jiaming Zhang",
      "Kunyu Peng",
      "Junwei Zheng",
      "Ruiping Liu",
      "Philip Torr",
      "Rainer Stiefelhagen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ding_UniRepLKNet_A_Universal_Perception_Large-Kernel_ConvNet_for_Audio_Video_Point_CVPR_2024_paper.html": {
    "title": "UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio Video Point Cloud Time-Series and Image Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohan Ding",
      "Yiyuan Zhang",
      "Yixiao Ge",
      "Sijie Zhao",
      "Lin Song",
      "Xiangyu Yue",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wan_Unveiling_the_Unknown_Unleashing_the_Power_of_Unknown_to_Known_CVPR_2024_paper.html": {
    "title": "Unveiling the Unknown: Unleashing the Power of Unknown to Known in Open-Set Source-Free Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fuli Wan",
      "Han Zhao",
      "Xu Yang",
      "Cheng Deng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gao_BilevelPruning_Unified_Dynamic_and_Static_Channel_Pruning_for_Convolutional_Neural_CVPR_2024_paper.html": {
    "title": "BilevelPruning: Unified Dynamic and Static Channel Pruning for Convolutional Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangqian Gao",
      "Yanfu Zhang",
      "Feihu Huang",
      "Heng Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dai_IDGuard_Robust_General_Identity-centric_POI_Proactive_Defense_Against_Face_Editing_CVPR_2024_paper.html": {
    "title": "IDGuard: Robust General Identity-centric POI Proactive Defense Against Face Editing Abuse",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunshu Dai",
      "Jianwei Fei",
      "Fangjun Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_SwiftBrush_One-Step_Text-to-Image_Diffusion_Model_with_Variational_Score_Distillation_CVPR_2024_paper.html": {
    "title": "SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational Score Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thuan Hoang Nguyen",
      "Anh Tran"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.html": {
    "title": "DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhao Qi",
      "Shancheng Fang",
      "Yanze Wu",
      "Hongtao Xie",
      "Jiawei Liu",
      "Lang Chen",
      "Qian He",
      "Yongdong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Instance-Adaptive_and_Geometric-Aware_Keypoint_Learning_for_Category-Level_6D_Object_Pose_CVPR_2024_paper.html": {
    "title": "Instance-Adaptive and Geometric-Aware Keypoint Learning for Category-Level 6D Object Pose Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiao Lin",
      "Wenfei Yang",
      "Yuan Gao",
      "Tianzhu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Universal_Semi-Supervised_Domain_Adaptation_by_Mitigating_Common-Class_Bias_CVPR_2024_paper.html": {
    "title": "Universal Semi-Supervised Domain Adaptation by Mitigating Common-Class Bias",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyu Zhang",
      "Qingmu Liu",
      "Felix Ong Wei Cong",
      "Mohamed Ragab",
      "Chuan-Sheng Foo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Exact_Fusion_via_Feature_Distribution_Matching_for_Few-shot_Image_Generation_CVPR_2024_paper.html": {
    "title": "Exact Fusion via Feature Distribution Matching for Few-shot Image Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingbo Zhou",
      "Yutong Ye",
      "Pengyu Zhang",
      "Xian Wei",
      "Mingsong Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ouyang_CoDeF_Content_Deformation_Fields_for_Temporally_Consistent_Video_Processing_CVPR_2024_paper.html": {
    "title": "CoDeF: Content Deformation Fields for Temporally Consistent Video Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Ouyang",
      "Qiuyu Wang",
      "Yuxi Xiao",
      "Qingyan Bai",
      "Juntao Zhang",
      "Kecheng Zheng",
      "Xiaowei Zhou",
      "Qifeng Chen",
      "Yujun Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fruhauf_QUADify_Extracting_Meshes_with_Pixel-level_Details_and_Materials_from_Images_CVPR_2024_paper.html": {
    "title": "QUADify: Extracting Meshes with Pixel-level Details and Materials from Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Frühauf",
      "Hayko Riemenschneider",
      "Markus Gross",
      "Christopher Schroers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_RecDiffusion_Rectangling_for_Image_Stitching_with_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "RecDiffusion: Rectangling for Image Stitching with Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianhao Zhou",
      "Haipeng Li",
      "Ziyi Wang",
      "Ao Luo",
      "Chen-Lin Zhang",
      "Jiajun Li",
      "Bing Zeng",
      "Shuaicheng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Verbin_Eclipse_Disambiguating_Illumination_and_Materials_using_Unintended_Shadows_CVPR_2024_paper.html": {
    "title": "Eclipse: Disambiguating Illumination and Materials using Unintended Shadows",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dor Verbin",
      "Ben Mildenhall",
      "Peter Hedman",
      "Jonathan T. Barron",
      "Todd Zickler",
      "Pratul P. Srinivasan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Feature_3DGS_Supercharging_3D_Gaussian_Splatting_to_Enable_Distilled_Feature_CVPR_2024_paper.html": {
    "title": "Feature 3DGS: Supercharging 3D Gaussian Splatting to Enable Distilled Feature Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shijie Zhou",
      "Haoran Chang",
      "Sicheng Jiang",
      "Zhiwen Fan",
      "Zehao Zhu",
      "Dejia Xu",
      "Pradyumna Chari",
      "Suya You",
      "Zhangyang Wang",
      "Achuta Kadambi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Parihar_Balancing_Act_Distribution-Guided_Debiasing_in_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Balancing Act: Distribution-Guided Debiasing in Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rishubh Parihar",
      "Abhijnya Bhat",
      "Abhipsa Basu",
      "Saswat Mallick",
      "Jogendra Nath Kundu",
      "R. Venkatesh Babu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_Viewpoint-Aware_Visual_Grounding_in_3D_Scenes_CVPR_2024_paper.html": {
    "title": "Viewpoint-Aware Visual Grounding in 3D Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangxi Shi",
      "Zhonghua Wu",
      "Stefan Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_4K4D_Real-Time_4D_View_Synthesis_at_4K_Resolution_CVPR_2024_paper.html": {
    "title": "4K4D: Real-Time 4D View Synthesis at 4K Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Xu",
      "Sida Peng",
      "Haotong Lin",
      "Guangzhao He",
      "Jiaming Sun",
      "Yujun Shen",
      "Hujun Bao",
      "Xiaowei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_View-decoupled_Transformer_for_Person_Re-identification_under_Aerial-ground_Camera_Network_CVPR_2024_paper.html": {
    "title": "View-decoupled Transformer for Person Re-identification under Aerial-ground Camera Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Zhang",
      "Lei Wang",
      "Vishal M. Patel",
      "Xiaohua Xie",
      "Jianhaung Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_CRKD_Enhanced_Camera-Radar_Object_Detection_with_Cross-modality_Knowledge_Distillation_CVPR_2024_paper.html": {
    "title": "CRKD: Enhanced Camera-Radar Object Detection with Cross-modality Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingjun Zhao",
      "Jingyu Song",
      "Katherine A. Skinner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chung_Differentiable_Point-based_Inverse_Rendering_CVPR_2024_paper.html": {
    "title": "Differentiable Point-based Inverse Rendering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoon-Gyu Chung",
      "Seokjun Choi",
      "Seung-Hwan Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_OED_Towards_One-stage_End-to-End_Dynamic_Scene_Graph_Generation_CVPR_2024_paper.html": {
    "title": "OED: Towards One-stage End-to-End Dynamic Scene Graph Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guan Wang",
      "Zhimin Li",
      "Qingchao Chen",
      "Yang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_CoG-DQA_Chain-of-Guiding_Learning_with_Large_Language_Models_for_Diagram_Question_CVPR_2024_paper.html": {
    "title": "CoG-DQA: Chain-of-Guiding Learning with Large Language Models for Diagram Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shaowei Wang",
      "Lingling Zhang",
      "Longji Zhu",
      "Tao Qin",
      "Kim-Hui Yap",
      "Xinyu Zhang",
      "Jun Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Transferable_and_Principled_Efficiency_for_Open-Vocabulary_Segmentation_CVPR_2024_paper.html": {
    "title": "Transferable and Principled Efficiency for Open-Vocabulary Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingxuan Xu",
      "Wuyang Chen",
      "Yao Zhao",
      "Yunchao Wei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Paskaleva_A_Unified_and_Interpretable_Emotion_Representation_and_Expression_Generation_CVPR_2024_paper.html": {
    "title": "A Unified and Interpretable Emotion Representation and Expression Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reni Paskaleva",
      "Mykyta Holubakha",
      "Andela Ilic",
      "Saman Motamed",
      "Luc Van Gool",
      "Danda Paudel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_Upscale-A-Video_Temporal-Consistent_Diffusion_Model_for_Real-World_Video_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shangchen Zhou",
      "Peiqing Yang",
      "Jianyi Wang",
      "Yihang Luo",
      "Chen Change Loy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_EvDiG_Event-guided_Direct_and_Global_Components_Separation_CVPR_2024_paper.html": {
    "title": "EvDiG: Event-guided Direct and Global Components Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyu Zhou",
      "Peiqi Duan",
      "Boyu Li",
      "Chu Zhou",
      "Chao Xu",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shao_DeIL_Direct-and-Inverse_CLIP_for_Open-World_Few-Shot_Learning_CVPR_2024_paper.html": {
    "title": "DeIL: Direct-and-Inverse CLIP for Open-World Few-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuai Shao",
      "Yu Bai",
      "Yan Wang",
      "Baodi Liu",
      "Yicong Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_4D-DRESS_A_4D_Dataset_of_Real-World_Human_Clothing_With_Semantic_CVPR_2024_paper.html": {
    "title": "4D-DRESS: A 4D Dataset of Real-World Human Clothing With Semantic Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbo Wang",
      "Hsuan-I Ho",
      "Chen Guo",
      "Boxiang Rong",
      "Artur Grigorev",
      "Jie Song",
      "Juan Jose Zarate",
      "Otmar Hilliges"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Feedback-Guided_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "Feedback-Guided Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jimuyang Zhang",
      "Zanming Huang",
      "Arijit Ray",
      "Eshed Ohn-Bar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Large_Language_Models_are_Good_Prompt_Learners_for_Low-Shot_Image_CVPR_2024_paper.html": {
    "title": "Large Language Models are Good Prompt Learners for Low-Shot Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoheng Zheng",
      "Jingmin Wei",
      "Xuefeng Hu",
      "Haidong Zhu",
      "Ram Nevatia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saini_Specularity_Factorization_for_Low-Light_Enhancement_CVPR_2024_paper.html": {
    "title": "Specularity Factorization for Low-Light Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saurabh Saini",
      "P J Narayanan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zeng_Paint3D_Paint_Anything_3D_with_Lighting-Less_Texture_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianfang Zeng",
      "Xin Chen",
      "Zhongqi Qi",
      "Wen Liu",
      "Zibo Zhao",
      "Zhibin Wang",
      "Bin Fu",
      "Yong Liu",
      "Gang Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lin_VILA_On_Pre-training_for_Visual_Language_Models_CVPR_2024_paper.html": {
    "title": "VILA: On Pre-training for Visual Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ji Lin",
      "Hongxu Yin",
      "Wei Ping",
      "Pavlo Molchanov",
      "Mohammad Shoeybi",
      "Song Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_DiLiGenRT_A_Photometric_Stereo_Dataset_with_Quantified_Roughness_and_Translucency_CVPR_2024_paper.html": {
    "title": "DiLiGenRT: A Photometric Stereo Dataset with Quantified Roughness and Translucency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heng Guo",
      "Jieji Ren",
      "Feishi Wang",
      "Boxin Shi",
      "Mingjun Ren",
      "Yasuyuki Matsushita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wei_De-Diffusion_Makes_Text_a_Strong_Cross-Modal_Interface_CVPR_2024_paper.html": {
    "title": "De-Diffusion Makes Text a Strong Cross-Modal Interface",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Wei",
      "Chenxi Liu",
      "Siyuan Qiao",
      "Zhishuai Zhang",
      "Alan Yuille",
      "Jiahui Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gritsenko_End-to-End_Spatio-Temporal_Action_Localisation_with_Video_Transformers_CVPR_2024_paper.html": {
    "title": "End-to-End Spatio-Temporal Action Localisation with Video Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexey A. Gritsenko",
      "Xuehan Xiong",
      "Josip Djolonga",
      "Mostafa Dehghani",
      "Chen Sun",
      "Mario Lucic",
      "Cordelia Schmid",
      "Anurag Arnab"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lee_Text-Guided_Variational_Image_Generation_for_Industrial_Anomaly_Detection_and_Segmentation_CVPR_2024_paper.html": {
    "title": "Text-Guided Variational Image Generation for Industrial Anomaly Detection and Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyu Lee",
      "Jongwon Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Self-Adaptive_Reality-Guided_Diffusion_for_Artifact-Free_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Self-Adaptive Reality-Guided Diffusion for Artifact-Free Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingping Zheng",
      "Ling Zheng",
      "Yuanfan Guo",
      "Ying Li",
      "Songcen Xu",
      "Jiankang Deng",
      "Hang Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_End-to-End_Temporal_Action_Detection_with_1B_Parameters_Across_1000_Frames_CVPR_2024_paper.html": {
    "title": "End-to-End Temporal Action Detection with 1B Parameters Across 1000 Frames",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuming Liu",
      "Chen-Lin Zhang",
      "Chen Zhao",
      "Bernard Ghanem"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Multimodal_Representation_Learning_by_Alternating_Unimodal_Adaptation_CVPR_2024_paper.html": {
    "title": "Multimodal Representation Learning by Alternating Unimodal Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohui Zhang",
      "Jaehong Yoon",
      "Mohit Bansal",
      "Huaxiu Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xie_MS-MANO_Enabling_Hand_Pose_Tracking_with_Biomechanical_Constraints_CVPR_2024_paper.html": {
    "title": "MS-MANO: Enabling Hand Pose Tracking with Biomechanical Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengfei Xie",
      "Wenqiang Xu",
      "Tutian Tang",
      "Zhenjun Yu",
      "Cewu Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Generate_Like_Experts_Multi-Stage_Font_Generation_by_Incorporating_Font_Transfer_CVPR_2024_paper.html": {
    "title": "Generate Like Experts: Multi-Stage Font Generation by Incorporating Font Transfer Process into Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Fu",
      "Fanghua Yu",
      "Anran Liu",
      "Zixuan Wang",
      "Jie Wen",
      "Junjun He",
      "Yu Qiao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chiche_Pre-training_Vision_Models_with_Mandelbulb_Variations_CVPR_2024_paper.html": {
    "title": "Pre-training Vision Models with Mandelbulb Variations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Naoto Chiche",
      "Yuto Horikawa",
      "Ryo Fujita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tian_Diffuse_Attend_and_Segment_Unsupervised_Zero-Shot_Segmentation_using_Stable_Diffusion_CVPR_2024_paper.html": {
    "title": "Diffuse Attend and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjiao Tian",
      "Lavisha Aggarwal",
      "Andrea Colaco",
      "Zsolt Kira",
      "Mar Gonzalez-Franco"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shi_TransNeXt_Robust_Foveal_Visual_Perception_for_Vision_Transformers_CVPR_2024_paper.html": {
    "title": "TransNeXt: Robust Foveal Visual Perception for Vision Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dai Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ren_Implicit_Discriminative_Knowledge_Learning_for_Visible-Infrared_Person_Re-Identification_CVPR_2024_paper.html": {
    "title": "Implicit Discriminative Knowledge Learning for Visible-Infrared Person Re-Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaijie Ren",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jaume_Modeling_Dense_Multimodal_Interactions_Between_Biological_Pathways_and_Histology_for_CVPR_2024_paper.html": {
    "title": "Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillaume Jaume",
      "Anurag Vaidya",
      "Richard J. Chen",
      "Drew F.K. Williamson",
      "Paul Pu Liang",
      "Faisal Mahmood"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Nguyen_Mining_Supervision_for_Dynamic_Regions_in_Self-Supervised_Monocular_Depth_Estimation_CVPR_2024_paper.html": {
    "title": "Mining Supervision for Dynamic Regions in Self-Supervised Monocular Depth Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoang Chuong Nguyen",
      "Tianyu Wang",
      "Jose M. Alvarez",
      "Miaomiao Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Le_Gradient_Alignment_for_Cross-Domain_Face_Anti-Spoofing_CVPR_2024_paper.html": {
    "title": "Gradient Alignment for Cross-Domain Face Anti-Spoofing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Binh M. Le",
      "Simon S. Woo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Stotko_Physics-guided_Shape-from-Template_Monocular_Video_Perception_through_Neural_Surrogate_Models_CVPR_2024_paper.html": {
    "title": "Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Stotko",
      "Nils Wandel",
      "Reinhard Klein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Long_S2MVTC_a_Simple_yet_Efficient_Scalable_Multi-View_Tensor_Clustering_CVPR_2024_paper.html": {
    "title": "S2MVTC: a Simple yet Efficient Scalable Multi-View Tensor Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Long",
      "Qiyuan Wang",
      "Yazhou Ren",
      "Yipeng Liu",
      "Ce Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pan_OpticalDR_A_Deep_Optical_Imaging_Model_for_Privacy-Protective_Depression_Recognition_CVPR_2024_paper.html": {
    "title": "OpticalDR: A Deep Optical Imaging Model for Privacy-Protective Depression Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuchen Pan",
      "Junjun Jiang",
      "Kui Jiang",
      "Zhihao Wu",
      "Keyuan Yu",
      "Xianming Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kang_Observation-Guided_Diffusion_Probabilistic_Models_CVPR_2024_paper.html": {
    "title": "Observation-Guided Diffusion Probabilistic Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junoh Kang",
      "Jinyoung Choi",
      "Sungik Choi",
      "Bohyung Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Koley_Youll_Never_Walk_Alone_A_Sketch_and_Text_Duet_for_CVPR_2024_paper.html": {
    "title": "You'll Never Walk Alone: A Sketch and Text Duet for Fine-Grained Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhadeep Koley",
      "Ayan Kumar Bhunia",
      "Aneeshan Sain",
      "Pinaki Nath Chowdhury",
      "Tao Xiang",
      "Yi-Zhe Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Spatial-Aware_Regression_for_Keypoint_Localization_CVPR_2024_paper.html": {
    "title": "Spatial-Aware Regression for Keypoint Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongkai Wang",
      "Shiliang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_S2MAE_A_Spatial-Spectral_Pretraining_Foundation_Model_for_Spectral_Remote_Sensing_CVPR_2024_paper.html": {
    "title": "S2MAE: A Spatial-Spectral Pretraining Foundation Model for Spectral Remote Sensing Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuyang Li",
      "Danfeng Hong",
      "Jocelyn Chanussot"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_EFormer_Enhanced_Transformer_towards_Semantic-Contour_Features_of_Foreground_for_Portraits_CVPR_2024_paper.html": {
    "title": "EFormer: Enhanced Transformer towards Semantic-Contour Features of Foreground for Portraits Matting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zitao Wang",
      "Qiguang Miao",
      "Yue Xi",
      "Peipei Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jiang_MultiPly_Reconstruction_of_Multiple_People_from_Monocular_Video_in_the_CVPR_2024_paper.html": {
    "title": "MultiPly: Reconstruction of Multiple People from Monocular Video in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeren Jiang",
      "Chen Guo",
      "Manuel Kaufmann",
      "Tianjian Jiang",
      "Julien Valentin",
      "Otmar Hilliges",
      "Jie Song"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Unsupervised_3D_Structure_Inference_from_Category-Specific_Image_Collections_CVPR_2024_paper.html": {
    "title": "Unsupervised 3D Structure Inference from Category-Specific Image Collections",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weikang Wang",
      "Dongliang Cao",
      "Florian Bernard"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Augustin_DiG-IN_Diffusion_Guidance_for_Investigating_Networks_-_Uncovering_Classifier_Differences_CVPR_2024_paper.html": {
    "title": "DiG-IN: Diffusion Guidance for Investigating Networks - Uncovering Classifier Differences Neuron Visualisations and Visual Counterfactual Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Augustin",
      "Yannic Neuhaus",
      "Matthias Hein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_RepViT_Revisiting_Mobile_CNN_From_ViT_Perspective_CVPR_2024_paper.html": {
    "title": "RepViT: Revisiting Mobile CNN From ViT Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ao Wang",
      "Hui Chen",
      "Zijia Lin",
      "Jungong Han",
      "Guiguang Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Giebenhain_MonoNPHM_Dynamic_Head_Reconstruction_from_Monocular_Videos_CVPR_2024_paper.html": {
    "title": "MonoNPHM: Dynamic Head Reconstruction from Monocular Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Markos Georgopoulos",
      "Martin Rünz",
      "Lourdes Agapito",
      "Matthias Nießner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_Realigning_Confidence_with_Temporal_Saliency_Information_for_Point-Level_Weakly-Supervised_Temporal_CVPR_2024_paper.html": {
    "title": "Realigning Confidence with Temporal Saliency Information for Point-Level Weakly-Supervised Temporal Action Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziying Xia",
      "Jian Cheng",
      "Siyu Liu",
      "Yongxiang Hu",
      "Shiguang Wang",
      "Yijie Zhang",
      "Liwan Dang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_ConsistNet_Enforcing_3D_Consistency_for_Multi-view_Images_Diffusion_CVPR_2024_paper.html": {
    "title": "ConsistNet: Enforcing 3D Consistency for Multi-view Images Diffusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayu Yang",
      "Ziang Cheng",
      "Yunfei Duan",
      "Pan Ji",
      "Hongdong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_GenN2N_Generative_NeRF2NeRF_Translation_CVPR_2024_paper.html": {
    "title": "GenN2N: Generative NeRF2NeRF Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyue Liu",
      "Han Xue",
      "Kunming Luo",
      "Ping Tan",
      "Li Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiao_Theoretically_Achieving_Continuous_Representation_of_Oriented_Bounding_Boxes_CVPR_2024_paper.html": {
    "title": "Theoretically Achieving Continuous Representation of Oriented Bounding Boxes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zikai Xiao",
      "Guoye Yang",
      "Xue Yang",
      "Taijiang Mu",
      "Junchi Yan",
      "Shimin Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chaouai_Universal_Robustness_via_Median_Randomized_Smoothing_for_Real-World_Super-Resolution_CVPR_2024_paper.html": {
    "title": "Universal Robustness via Median Randomized Smoothing for Real-World Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zakariya Chaouai",
      "Mohamed Tamaazousti"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lyu_One-dimensional_Adapter_to_Rule_Them_All_Concepts_Diffusion_Models_and_CVPR_2024_paper.html": {
    "title": "One-dimensional Adapter to Rule Them All: Concepts Diffusion Models and Erasing Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengyao Lyu",
      "Yuhong Yang",
      "Haiwen Hong",
      "Hui Chen",
      "Xuan Jin",
      "Yuan He",
      "Hui Xue",
      "Jungong Han",
      "Guiguang Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shou_Learning_Large-Factor_EM_Image_Super-Resolution_with_Generative_Priors_CVPR_2024_paper.html": {
    "title": "Learning Large-Factor EM Image Super-Resolution with Generative Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiateng Shou",
      "Zeyu Xiao",
      "Shiyu Deng",
      "Wei Huang",
      "Peiyao Shi",
      "Ruobing Zhang",
      "Zhiwei Xiong",
      "Feng Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Saadati_DIMAT_Decentralized_Iterative_Merging-And-Training_for_Deep_Learning_Models_CVPR_2024_paper.html": {
    "title": "DIMAT: Decentralized Iterative Merging-And-Training for Deep Learning Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nastaran Saadati",
      "Minh Pham",
      "Nasla Saleem",
      "Joshua R. Waite",
      "Aditya Balu",
      "Zhanong Jiang",
      "Chinmay Hegde",
      "Soumik Sarkar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_MMA_Multi-Modal_Adapter_for_Vision-Language_Models_CVPR_2024_paper.html": {
    "title": "MMA: Multi-Modal Adapter for Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingxiao Yang",
      "Ru-Yuan Zhang",
      "Yanchen Wang",
      "Xiaohua Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Brunekreef_Kandinsky_Conformal_Prediction_Efficient_Calibration_of_Image_Segmentation_Algorithms_CVPR_2024_paper.html": {
    "title": "Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joren Brunekreef",
      "Eric Marcus",
      "Ray Sheombarsing",
      "Jan-Jakob Sonke",
      "Jonas Teuwen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chung_Diversity-aware_Channel_Pruning_for_StyleGAN_Compression_CVPR_2024_paper.html": {
    "title": "Diversity-aware Channel Pruning for StyleGAN Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiwoo Chung",
      "Sangeek Hyun",
      "Sang-Heon Shim",
      "Jae-Pil Heo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Stevens_BioCLIP_A_Vision_Foundation_Model_for_the_Tree_of_Life_CVPR_2024_paper.html": {
    "title": "BioCLIP: A Vision Foundation Model for the Tree of Life",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Stevens",
      "Jiaman Wu",
      "Matthew J Thompson",
      "Elizabeth G Campolongo",
      "Chan Hee Song",
      "David Edward Carlyn",
      "Li Dong",
      "Wasila M Dahdul",
      "Charles Stewart",
      "Tanya Berger-Wolf",
      "Wei-Lun Chao",
      "Yu Su"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_From_Pixels_to_Graphs_Open-Vocabulary_Scene_Graph_Generation_with_Vision-Language_CVPR_2024_paper.html": {
    "title": "From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with Vision-Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rongjie Li",
      "Songyang Zhang",
      "Dahua Lin",
      "Kai Chen",
      "Xuming He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiong_Deep_Imbalanced_Regression_via_Hierarchical_Classification_Adjustment_CVPR_2024_paper.html": {
    "title": "Deep Imbalanced Regression via Hierarchical Classification Adjustment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haipeng Xiong",
      "Angela Yao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_Adaptive_Fusion_of_Single-View_and_Multi-View_Depth_for_Autonomous_Driving_CVPR_2024_paper.html": {
    "title": "Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junda Cheng",
      "Wei Yin",
      "Kaixuan Wang",
      "Xiaozhi Chen",
      "Shijie Wang",
      "Xin Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Neural_Clustering_based_Visual_Representation_Learning_CVPR_2024_paper.html": {
    "title": "Neural Clustering based Visual Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guikun Chen",
      "Xia Li",
      "Yi Yang",
      "Wenguan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Continual_Self-supervised_Learning_Towards_Universal_Multi-modal_Medical_Data_Representation_Learning_CVPR_2024_paper.html": {
    "title": "Continual Self-supervised Learning: Towards Universal Multi-modal Medical Data Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiwen Ye",
      "Yutong Xie",
      "Jianpeng Zhang",
      "Ziyang Chen",
      "Qi Wu",
      "Yong Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shehzadi_Sparse_Semi-DETR_Sparse_Learnable_Queries_for_Semi-Supervised_Object_Detection_CVPR_2024_paper.html": {
    "title": "Sparse Semi-DETR: Sparse Learnable Queries for Semi-Supervised Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tahira Shehzadi",
      "Khurram Azeem Hashmi",
      "Didier Stricker",
      "Muhammad Zeshan Afzal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Towards_Efficient_Replay_in_Federated_Incremental_Learning_CVPR_2024_paper.html": {
    "title": "Towards Efficient Replay in Federated Incremental Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yichen Li",
      "Qunwei Li",
      "Haozhao Wang",
      "Ruixuan Li",
      "Wenliang Zhong",
      "Guannan Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_SimAC_A_Simple_Anti-Customization_Method_for_Protecting_Face_Privacy_against_CVPR_2024_paper.html": {
    "title": "SimAC: A Simple Anti-Customization Method for Protecting Face Privacy against Text-to-Image Synthesis of Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feifei Wang",
      "Zhentao Tan",
      "Tianyi Wei",
      "Yue Wu",
      "Qidong Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lyu_Total-Decom_Decomposed_3D_Scene_Reconstruction_with_Minimal_Interaction_CVPR_2024_paper.html": {
    "title": "Total-Decom: Decomposed 3D Scene Reconstruction with Minimal Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Lyu",
      "Chirui Chang",
      "Peng Dai",
      "Yang-Tian Sun",
      "Xiaojuan Qi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Kheradmand_Accelerating_Neural_Field_Training_via_Soft_Mining_CVPR_2024_paper.html": {
    "title": "Accelerating Neural Field Training via Soft Mining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shakiba Kheradmand",
      "Daniel Rebain",
      "Gopal Sharma",
      "Hossam Isack",
      "Abhishek Kar",
      "Andrea Tagliasacchi",
      "Kwang Moo Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Tang_Ensemble_Diversity_Facilitates_Adversarial_Transferability_CVPR_2024_paper.html": {
    "title": "Ensemble Diversity Facilitates Adversarial Transferability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Tang",
      "Zheng Wang",
      "Yi Bin",
      "Qi Dou",
      "Yang Yang",
      "Heng Tao Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Fair-VPT_Fair_Visual_Prompt_Tuning_for_Image_Classification_CVPR_2024_paper.html": {
    "title": "Fair-VPT: Fair Visual Prompt Tuning for Image Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sungho Park",
      "Hyeran Byun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Ai_Uncertainty-Aware_Source-Free_Adaptive_Image_Super-Resolution_with_Wavelet_Augmentation_Transformer_CVPR_2024_paper.html": {
    "title": "Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuang Ai",
      "Xiaoqiang Zhou",
      "Huaibo Huang",
      "Lei Zhang",
      "Ran He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Gear-NeRF_Free-Viewpoint_Rendering_and_Tracking_with_Motion-aware_Spatio-Temporal_Sampling_CVPR_2024_paper.html": {
    "title": "Gear-NeRF: Free-Viewpoint Rendering and Tracking with Motion-aware Spatio-Temporal Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinhang Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang",
      "Pedro Miraldo",
      "Suhas Lohit",
      "Moitreya Chatterjee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Pourkeshavarz_CaDeT_a_Causal_Disentanglement_Approach_for_Robust_Trajectory_Prediction_in_CVPR_2024_paper.html": {
    "title": "CaDeT: a Causal Disentanglement Approach for Robust Trajectory Prediction in Autonomous Driving",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mozhgan Pourkeshavarz",
      "Junrui Zhang",
      "Amir Rasouli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Spacetime_Gaussian_Feature_Splatting_for_Real-Time_Dynamic_View_Synthesis_CVPR_2024_paper.html": {
    "title": "Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhan Li",
      "Zhang Chen",
      "Zhong Li",
      "Yi Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.html": {
    "title": "Instruct-Imagen: Image Generation with Multi-modal Instruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hexiang Hu",
      "Kelvin C.K. Chan",
      "Yu-Chuan Su",
      "Wenhu Chen",
      "Yandong Li",
      "Kihyuk Sohn",
      "Yang Zhao",
      "Xue Ben",
      "Boqing Gong",
      "William Cohen",
      "Ming-Wei Chang",
      "Xuhui Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_Prompting_Vision_Foundation_Models_for_Pathology_Image_Analysis_CVPR_2024_paper.html": {
    "title": "Prompting Vision Foundation Models for Pathology Image Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chong Yin",
      "Siqi Liu",
      "Kaiyang Zhou",
      "Vincent Wai-Sun Wong",
      "Pong C. Yuen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/An_Rethinking_Few-shot_3D_Point_Cloud_Semantic_Segmentation_CVPR_2024_paper.html": {
    "title": "Rethinking Few-shot 3D Point Cloud Semantic Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaochong An",
      "Guolei Sun",
      "Yun Liu",
      "Fayao Liu",
      "Zongwei Wu",
      "Dan Wang",
      "Luc Van Gool",
      "Serge Belongie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SEED-Bench_Benchmarking_Multimodal_Large_Language_Models_CVPR_2024_paper.html": {
    "title": "SEED-Bench: Benchmarking Multimodal Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bohao Li",
      "Yuying Ge",
      "Yixiao Ge",
      "Guangzhi Wang",
      "Rui Wang",
      "Ruimao Zhang",
      "Ying Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Abbasi_BrainWash_A_Poisoning_Attack_to_Forget_in_Continual_Learning_CVPR_2024_paper.html": {
    "title": "BrainWash: A Poisoning Attack to Forget in Continual Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ali Abbasi",
      "Parsa Nooralinejad",
      "Hamed Pirsiavash",
      "Soheil Kolouri"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Munir_GreedyViG_Dynamic_Axial_Graph_Construction_for_Efficient_Vision_GNNs_CVPR_2024_paper.html": {
    "title": "GreedyViG: Dynamic Axial Graph Construction for Efficient Vision GNNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mustafa Munir",
      "William Avery",
      "Md Mostafijur Rahman",
      "Radu Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Relightable_and_Animatable_Neural_Avatar_from_Sparse-View_Video_CVPR_2024_paper.html": {
    "title": "Relightable and Animatable Neural Avatar from Sparse-View Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Xu",
      "Sida Peng",
      "Chen Geng",
      "Linzhan Mou",
      "Zihan Yan",
      "Jiaming Sun",
      "Hujun Bao",
      "Xiaowei Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_FreePoint_Unsupervised_Point_Cloud_Instance_Segmentation_CVPR_2024_paper.html": {
    "title": "FreePoint: Unsupervised Point Cloud Instance Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhikai Zhang",
      "Jian Ding",
      "Li Jiang",
      "Dengxin Dai",
      "Guisong Xia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hsu_Pose_Adapted_Shape_Learning_for_Large-Pose_Face_Reenactment_CVPR_2024_paper.html": {
    "title": "Pose Adapted Shape Learning for Large-Pose Face Reenactment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gee-Sern Jison Hsu",
      "Jie-Ying Zhang",
      "Huang Yu Hsiang",
      "Wei-Jie Hong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Object_Pose_Estimation_via_the_Aggregation_of_Diffusion_Features_CVPR_2024_paper.html": {
    "title": "Object Pose Estimation via the Aggregation of Diffusion Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianfu Wang",
      "Guosheng Hu",
      "Hongguang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xiong_Circuit_Design_and_Efficient_Simulation_of_Quantum_Inner_Product_and_CVPR_2024_paper.html": {
    "title": "Circuit Design and Efficient Simulation of Quantum Inner Product and Empirical Studies of Its Effect on Near-Term Hybrid Quantum-Classic Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Xiong",
      "Yehui Tang",
      "Xinyu Ye",
      "Junchi Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_How_to_Make_Cross_Encoder_a_Good_Teacher_for_Efficient_CVPR_2024_paper.html": {
    "title": "How to Make Cross Encoder a Good Teacher for Efficient Image-Text Retrieval?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Chen",
      "Zongyang Ma",
      "Ziqi Zhang",
      "Zhongang Qi",
      "Chunfeng Yuan",
      "Bing Li",
      "Junfu Pu",
      "Ying Shan",
      "Xiaojuan Qi",
      "Weiming Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lao_Diffeomorphic_Template_Registration_for_Atmospheric_Turbulence_Mitigation_CVPR_2024_paper.html": {
    "title": "Diffeomorphic Template Registration for Atmospheric Turbulence Mitigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Lao",
      "Congli Wang",
      "Alex Wong",
      "Stefano Soatto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Maliszewski_Selective_Nonlinearities_Removal_from_Digital_Signals_CVPR_2024_paper.html": {
    "title": "Selective Nonlinearities Removal from Digital Signals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Krzysztof A. Maliszewski",
      "Magdalena A. Urba?ska",
      "Varvara Vetrova",
      "Sylwia M. Kolenderska"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Xia_NB-GTR_Narrow-Band_Guided_Turbulence_Removal_CVPR_2024_paper.html": {
    "title": "NB-GTR: Narrow-Band Guided Turbulence Removal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifei Xia",
      "Chu Zhou",
      "Chengxuan Zhu",
      "Minggui Teng",
      "Chao Xu",
      "Boxin Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Gavrikov_Can_Biases_in_ImageNet_Models_Explain_Generalization_CVPR_2024_paper.html": {
    "title": "Can Biases in ImageNet Models Explain Generalization?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/He_NRDF_Neural_Riemannian_Distance_Fields_for_Learning_Articulated_Pose_Priors_CVPR_2024_paper.html": {
    "title": "NRDF: Neural Riemannian Distance Fields for Learning Articulated Pose Priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yannan He",
      "Garvita Tiwari",
      "Tolga Birdal",
      "Jan Eric Lenssen",
      "Gerard Pons-Moll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Fei_RepAn_Enhanced_Annealing_through_Re-parameterization_CVPR_2024_paper.html": {
    "title": "RepAn: Enhanced Annealing through Re-parameterization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Fei",
      "Xiawu Zheng",
      "Yan Wang",
      "Fei Chao",
      "Chenglin Wu",
      "Liujuan Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Purohit_Generative_Quanta_Color_Imaging_CVPR_2024_paper.html": {
    "title": "Generative Quanta Color Imaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vishal Purohit",
      "Junjie Luo",
      "Yiheng Chi",
      "Qi Guo",
      "Stanley H. Chan",
      "Qiang Qiu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Panda-70M_Captioning_70M_Videos_with_Multiple_Cross-Modality_Teachers_CVPR_2024_paper.html": {
    "title": "Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tsai-Shien Chen",
      "Aliaksandr Siarohin",
      "Willi Menapace",
      "Ekaterina Deyneka",
      "Hsiang-wei Chao",
      "Byung Eun Jeon",
      "Yuwei Fang",
      "Hsin-Ying Lee",
      "Jian Ren",
      "Ming-Hsuan Yang",
      "Sergey Tulyakov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Overload_Latency_Attacks_on_Object_Detection_for_Edge_Devices_CVPR_2024_paper.html": {
    "title": "Overload: Latency Attacks on Object Detection for Edge Devices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Erh-Chung Chen",
      "Pin-Yu Chen",
      "I-Hsin Chung",
      "Che-Rung Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Huang_DreamControl_Control-Based_Text-to-3D_Generation_with_3D_Self-Prior_CVPR_2024_paper.html": {
    "title": "DreamControl: Control-Based Text-to-3D Generation with 3D Self-Prior",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyu Huang",
      "Yihan Zeng",
      "Zhilu Zhang",
      "Wan Xu",
      "Hang Xu",
      "Songcen Xu",
      "Rynson W.H. Lau",
      "Wangmeng Zuo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Infrared_Small_Target_Detection_with_Scale_and_Location_Sensitivity_CVPR_2024_paper.html": {
    "title": "Infrared Small Target Detection with Scale and Location Sensitivity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiankun Liu",
      "Rui Liu",
      "Bolun Zheng",
      "Hongkui Wang",
      "Ying Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Self-supervised_Debiasing_Using_Low_Rank_Regularization_CVPR_2024_paper.html": {
    "title": "Self-supervised Debiasing Using Low Rank Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Geon Yeong Park",
      "Chanyong Jung",
      "Sangmin Lee",
      "Jong Chul Ye",
      "Sang Wan Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Jain_ODIN_A_Single_Model_for_2D_and_3D_Segmentation_CVPR_2024_paper.html": {
    "title": "ODIN: A Single Model for 2D and 3D Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayush Jain",
      "Pushkal Katara",
      "Nikolaos Gkanatsios",
      "Adam W. Harley",
      "Gabriel Sarch",
      "Kriti Aggarwal",
      "Vishrav Chaudhary",
      "Katerina Fragkiadaki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_SD4Match_Learning_to_Prompt_Stable_Diffusion_Model_for_Semantic_Matching_CVPR_2024_paper.html": {
    "title": "SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinghui Li",
      "Jingyi Lu",
      "Kai Han",
      "Victor Adrian Prisacariu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_InitNO_Boosting_Text-to-Image_Diffusion_Models_via_Initial_Noise_Optimization_CVPR_2024_paper.html": {
    "title": "InitNO: Boosting Text-to-Image Diffusion Models via Initial Noise Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiefan Guo",
      "Jinlin Liu",
      "Miaomiao Cui",
      "Jiankai Li",
      "Hongyu Yang",
      "Di Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html": {
    "title": "Neural Video Compression with Feature Modulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Li",
      "Bin Li",
      "Yan Lu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_Data_Poisoning_based_Backdoor_Attacks_to_Contrastive_Learning_CVPR_2024_paper.html": {
    "title": "Data Poisoning based Backdoor Attacks to Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinghuai Zhang",
      "Hongbin Liu",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lou_Multimodal_Sense-Informed_Forecasting_of_3D_Human_Motions_CVPR_2024_paper.html": {
    "title": "Multimodal Sense-Informed Forecasting of 3D Human Motions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Lou",
      "Qiongjie Cui",
      "Haofan Wang",
      "Xu Tang",
      "Hong Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Hwang_FlowerFormer_Empowering_Neural_Architecture_Encoding_using_a_Flow-aware_Graph_Transformer_CVPR_2024_paper.html": {
    "title": "FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongyeong Hwang",
      "Hyunju Kim",
      "Sunwoo Kim",
      "Kijung Shin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_EmoGen_Emotional_Image_Content_Generation_with_Text-to-Image_Diffusion_Models_CVPR_2024_paper.html": {
    "title": "EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingyuan Yang",
      "Jiawei Feng",
      "Hui Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Iurada_Finding_Lottery_Tickets_in_Vision_Models_via_Data-driven_Spectral_Foresight_CVPR_2024_paper.html": {
    "title": "Finding Lottery Tickets in Vision Models via Data-driven Spectral Foresight Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Leonardo Iurada",
      "Marco Ciccone",
      "Tatiana Tommasi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_InNeRF360_Text-Guided_3D-Consistent_Object_Inpainting_on_360-degree_Neural_Radiance_Fields_CVPR_2024_paper.html": {
    "title": "InNeRF360: Text-Guided 3D-Consistent Object Inpainting on 360-degree Neural Radiance Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongqing Wang",
      "Tong Zhang",
      "Alaa Abboud",
      "Sabine Süsstrunk"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Weng_Neural_Implicit_Representation_for_Building_Digital_Twins_of_Unknown_Articulated_CVPR_2024_paper.html": {
    "title": "Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yijia Weng",
      "Bowen Wen",
      "Jonathan Tremblay",
      "Valts Blukis",
      "Dieter Fox",
      "Leonidas Guibas",
      "Stan Birchfield"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Progressive_Semantic-Guided_Vision_Transformer_for_Zero-Shot_Learning_CVPR_2024_paper.html": {
    "title": "Progressive Semantic-Guided Vision Transformer for Zero-Shot Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiming Chen",
      "Wenjin Hou",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yin_IS-Fusion_Instance-Scene_Collaborative_Fusion_for_Multimodal_3D_Object_Detection_CVPR_2024_paper.html": {
    "title": "IS-Fusion: Instance-Scene Collaborative Fusion for Multimodal 3D Object Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junbo Yin",
      "Jianbing Shen",
      "Runnan Chen",
      "Wei Li",
      "Ruigang Yang",
      "Pascal Frossard",
      "Wenguan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Dong_Building_Bridges_across_Spatial_and_Temporal_Resolutions_Reference-Based_Super-Resolution_via_CVPR_2024_paper.html": {
    "title": "Building Bridges across Spatial and Temporal Resolutions: Reference-Based Super-Resolution via Change Priors and Conditional Diffusion Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runmin Dong",
      "Shuai Yuan",
      "Bin Luo",
      "Mengxuan Chen",
      "Jinxiao Zhang",
      "Lixian Zhang",
      "Weijia Li",
      "Juepeng Zheng",
      "Haohuan Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Vanishing-Point-Guided_Video_Semantic_Segmentation_of_Driving_Scenes_CVPR_2024_paper.html": {
    "title": "Vanishing-Point-Guided Video Semantic Segmentation of Driving Scenes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diandian Guo",
      "Deng-Ping Fan",
      "Tongyu Lu",
      "Christos Sakaridis",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Park_Enhancing_Intrinsic_Features_for_Debiasing_via_Investigating_Class-Discerning_Common_Attributes_CVPR_2024_paper.html": {
    "title": "Enhancing Intrinsic Features for Debiasing via Investigating Class-Discerning Common Attributes in Bias-Contrastive Pair",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeonghoon Park",
      "Chaeyeon Chung",
      "Jaegul Choo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Wu_LAMP_Learn_A_Motion_Pattern_for_Few-Shot_Video_Generation_CVPR_2024_paper.html": {
    "title": "LAMP: Learn A Motion Pattern for Few-Shot Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiqi Wu",
      "Liangyu Chen",
      "Tong Yang",
      "Chunle Guo",
      "Chongyi Li",
      "Xiangyu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Mitra_Compositional_Chain-of-Thought_Prompting_for_Large_Multimodal_Models_CVPR_2024_paper.html": {
    "title": "Compositional Chain-of-Thought Prompting for Large Multimodal Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chancharik Mitra",
      "Brandon Huang",
      "Trevor Darrell",
      "Roei Herzig"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Yi_Diffusion_Time-step_Curriculum_for_One_Image_to_3D_Generation_CVPR_2024_paper.html": {
    "title": "Diffusion Time-step Curriculum for One Image to 3D Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuanyu Yi",
      "Zike Wu",
      "Qingshan Xu",
      "Pan Zhou",
      "Joo-Hwee Lim",
      "Hanwang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Shum_Language-driven_Object_Fusion_into_Neural_Radiance_Fields_with_Pose-Conditioned_Dataset_CVPR_2024_paper.html": {
    "title": "Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ka Chun Shum",
      "Jaeyeon Kim",
      "Binh-Son Hua",
      "Duc Thanh Nguyen",
      "Sai-Kit Yeung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Qi_Adaptive_Hyper-graph_Aggregation_for_Modality-Agnostic_Federated_Learning_CVPR_2024_paper.html": {
    "title": "Adaptive Hyper-graph Aggregation for Modality-Agnostic Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Qi",
      "Shuai Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Uppal_SPIN_Simultaneous_Perception_Interaction_and_Navigation_CVPR_2024_paper.html": {
    "title": "SPIN: Simultaneous Perception Interaction and Navigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shagun Uppal",
      "Ananye Agarwal",
      "Haoyu Xiong",
      "Kenneth Shaw",
      "Deepak Pathak"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Zhou_DREAM_Diffusion_Rectification_and_Estimation-Adaptive_Models_CVPR_2024_paper.html": {
    "title": "DREAM: Diffusion Rectification and Estimation-Adaptive Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinxin Zhou",
      "Tianyu Ding",
      "Tianyi Chen",
      "Jiachen Jiang",
      "Ilya Zharkov",
      "Zhihui Zhu",
      "Luming Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024/html/Lei_Exploring_the_Potential_of_Large_Foundation_Models_for_Open-Vocabulary_HOI_CVPR_2024_paper.html": {
    "title": "Exploring the Potential of Large Foundation Models for Open-Vocabulary HOI Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ting Lei",
      "Shaofeng Yin",
      "Yang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MDEC/html/Spencer_The_Third_Monocular_Depth_Estimation_Challenge_CVPRW_2024_paper.html": {
    "title": "The Third Monocular Depth Estimation Challenge",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaime Spencer",
      "Fabio Tosi",
      "Matteo Poggi",
      "Ripudaman Singh Arora",
      "Chris Russell",
      "Simon Hadfield",
      "Richard Bowden",
      "Guangyuan Zhou",
      "Zhengxin Li",
      "Qiang Rao",
      "Yiping Bao",
      "Xiao Liu",
      "Dohyeong Kim",
      "Jinseong Kim",
      "Myunghyun Kim",
      "Mykola Lavreniuk",
      "Rui Li",
      "Qing Mao",
      "Jiang Wu",
      "Yu Zhu",
      "Jinqiu Sun",
      "Yanning Zhang",
      "Suraj Patni",
      "Aradhye Agarwal",
      "Chetan Arora",
      "Pihai Sun",
      "Kui Jiang",
      "Gang Wu",
      "Jian Liu",
      "Xianming Liu",
      "Junjun Jiang",
      "Xidan Zhang",
      "Jianing Wei",
      "Fangjun Wang",
      "Zhiming Tan",
      "Jiabao Wang",
      "Albert Luginov",
      "Muhammad Shahzad",
      "Seyed Hosseini",
      "Aleksander Trajcevski",
      "James H. Elder"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/UG2/html/Guichemerre_Source-Free_Domain_Adaptation_of_Weakly-Supervised_Object_Localization_Models_for_Histology_CVPRW_2024_paper.html": {
    "title": "Source-Free Domain Adaptation of Weakly-Supervised Object Localization Models for Histology",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexis Guichemerre",
      "Soufiane Belharbi",
      "Tsiry Mayet",
      "Shakeeb Murtaza",
      "Pourya Shamsolmoali",
      "Luke Mccaffrey",
      "Eric Granger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/UG2/html/Chang_UAV-Rain1k_A_Benchmark_for_Raindrop_Removal_from_UAV_Aerial_Imagery_CVPRW_2024_paper.html": {
    "title": "UAV-Rain1k: A Benchmark for Raindrop Removal from UAV Aerial Imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhui Chang",
      "Hongming Chen",
      "Xin He",
      "Xiang Chen",
      "Liangduo Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/UG2/html/Madhusudana_Mobile_Aware_Denoiser_Network_MADNet_for_Quad_Bayer_Images_CVPRW_2024_paper.html": {
    "title": "Mobile Aware Denoiser Network (MADNet) for Quad Bayer Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pavan C. Madhusudana",
      "Jing Li",
      "Zeeshan Nadir",
      "Hamid R. Sheikh",
      "Seok-Jun Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/UG2/html/Wei_Feature_Corrective_Transfer_Learning_End-to-End_Solutions_to_Object_Detection_in_CVPRW_2024_paper.html": {
    "title": "Feature Corrective Transfer Learning: End-to-End Solutions to Object Detection in Non-Ideal Visual Conditions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuheng Wei",
      "Guoyuan Wu",
      "Matthew J. Barth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MS/html/Banerjee_Damage_Detection_and_Localization_by_Learning_Deep_Features_of_Elastic_CVPRW_2024_paper.html": {
    "title": "Damage Detection and Localization by Learning Deep Features of Elastic Waves in Piezoelectric Ceramic Using Point Contact Method",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pragyan Banerjee",
      "Pranjal Saxena",
      "Nur M M Kalimullah",
      "Amit Shelke",
      "Anowarul Habib"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MS/html/Kazimi_Self-Supervised_Learning_with_Generative_Adversarial_Networks_for_Electron_Microscopy_CVPRW_2024_paper.html": {
    "title": "Self-Supervised Learning with Generative Adversarial Networks for Electron Microscopy",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bashir Kazimi",
      "Karina Ruzaeva",
      "Stefan Sandfeld"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MS/html/Wong_VolRAFT_Volumetric_Optical_Flow_Network_for_Digital_Volume_Correlation_of_CVPRW_2024_paper.html": {
    "title": "VolRAFT: Volumetric Optical Flow Network for Digital Volume Correlation of Synchrotron Radiation-based Micro-CT Images of Bone-Implant Interfaces",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tak Ming Wong",
      "Julian Moosmann",
      "Berit Zeller-Plumhoff"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Nayak_Data-free_Defense_of_Black_Box_Models_Against_Adversarial_Attacks_CVPRW_2024_paper.html": {
    "title": "Data-free Defense of Black Box Models Against Adversarial Attacks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaurav Kumar Nayak",
      "Inder Khatri",
      "Ruchit Rawal",
      "Anirban Chakraborty"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Hoang_Improving_the_Robustness_of_3D_Human_Pose_Estimation_A_Benchmark_CVPRW_2024_paper.html": {
    "title": "Improving the Robustness of 3D Human Pose Estimation: A Benchmark and Learning from Noisy Input",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Trung-Hieu Hoang",
      "Mona Zehni",
      "Huy Phan",
      "Duc Minh Vo",
      "Minh N. Do"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Shen_Practical_Region-level_Attack_against_Segment_Anything_Models_CVPRW_2024_paper.html": {
    "title": "Practical Region-level Attack against Segment Anything Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifan Shen",
      "Zhengyuan Li",
      "Gang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Doula_AR-CP_Uncertainty-Aware_Perception_in_Adverse_Conditions_with_Conformal_Prediction_and_CVPRW_2024_paper.html": {
    "title": "AR-CP: Uncertainty-Aware Perception in Adverse Conditions with Conformal Prediction and Augmented Reality For Assisted Driving",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Achref Doula",
      "Max Mühlhäuser",
      "Alejandro Sanchez Guinea"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Regmi_T2FNorm_Train-time_Feature_Normalization_for_OOD_Detection_in_Image_Classification_CVPRW_2024_paper.html": {
    "title": "T2FNorm: Train-time Feature Normalization for OOD Detection in Image Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sudarshan Regmi",
      "Bibek Panthi",
      "Sakar Dotel",
      "Prashnna K Gyawali",
      "Danail Stoyanov",
      "Binod Bhattarai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Mehri_SkipPLUS_Skip_the_First_Few_Layers_to_Better_Explain_Vision_CVPRW_2024_paper.html": {
    "title": "SkipPLUS: Skip the First Few Layers to Better Explain Vision Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Faridoun Mehri",
      "Mohsen Fayyaz",
      "Mahdieh Soleymani Baghshah",
      "Mohammad Taher Pilehvar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Li_Fast-NTK_Parameter-Efficient_Unlearning_for_Large-Scale_Models_CVPRW_2024_paper.html": {
    "title": "Fast-NTK: Parameter-Efficient Unlearning for Large-Scale Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guihong Li",
      "Hsiang Hsu",
      "Chun-Fu Chen",
      "Radu Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Zuo_Robust_and_Explainable_Fine-Grained_Visual_Classification_with_Transfer_Learning_A_CVPRW_2024_paper.html": {
    "title": "Robust and Explainable Fine-Grained Visual Classification with Transfer Learning: A Dual-Carriageway Framework",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheming Zuo",
      "Joseph Smith",
      "Jonathan Stonehouse",
      "Boguslaw Obara"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Chen_DIA_Diffusion_based_Inverse_Network_Attack_on_Collaborative_Inference_CVPRW_2024_paper.html": {
    "title": "DIA: Diffusion based Inverse Network Attack on Collaborative Inference",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dake Chen",
      "Shiduo Li",
      "Yuke Zhang",
      "Chenghao Li",
      "Souvik Kundu",
      "Peter A. Beerel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Bhatta_Our_Deep_CNN_Face_Matchers_Have_Developed_Achromatopsia_CVPRW_2024_paper.html": {
    "title": "Our Deep CNN Face Matchers Have Developed Achromatopsia",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aman Bhatta",
      "Domingo Mery",
      "Haiyu Wu",
      "Joyce Annan",
      "Michael C. King",
      "Kevin W. Bowyer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/De_Coninck_Mitigating_Bias_Using_Model-Agnostic_Data_Attribution_CVPRW_2024_paper.html": {
    "title": "Mitigating Bias Using Model-Agnostic Data Attribution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sander De Coninck",
      "Sam Leroux",
      "Pieter Simoens"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Ugwu_Fractals_as_Pre-training_Datasets_for_Anomaly_Detection_and_Localization_CVPRW_2024_paper.html": {
    "title": "Fractals as Pre-training Datasets for Anomaly Detection and Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cynthia I. Ugwu",
      "Sofia Casarin",
      "Oswald Lanz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Hwa_Enforcing_Conditional_Independence_for_Fair_Representation_Learning_and_Causal_Image_CVPRW_2024_paper.html": {
    "title": "Enforcing Conditional Independence for Fair Representation Learning and Causal Image Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jensen Hwa",
      "Qingyu Zhao",
      "Aditya Lahiri",
      "Adnan Masood",
      "Babak Salimi",
      "Ehsan Adeli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Mehra_Test-time_Assessment_of_a_Models_Performance_on_Unseen_Domains_via_CVPRW_2024_paper.html": {
    "title": "Test-time Assessment of a Model's Performance on Unseen Domains via Optimal Transport",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshay Mehra",
      "Yunbei Zhang",
      "Jihun Hamm"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Karus_Towards_Explainable_Visual_Vessel_Recognition_Using_Fine-Grained_Classification_and_Image_CVPRW_2024_paper.html": {
    "title": "Towards Explainable Visual Vessel Recognition Using Fine-Grained Classification and Image Retrieval",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heiko Karus",
      "Friedhelm Schwenker",
      "Michael Munz",
      "Michael Teutsch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Choi_Towards_Efficient_Machine_Unlearning_with_Data_Augmentation_Guided_Loss-Increasing_GLI_CVPRW_2024_paper.html": {
    "title": "Towards Efficient Machine Unlearning with Data Augmentation: Guided Loss-Increasing (GLI) to Prevent the Catastrophic Model Utility Drop",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dasol Choi",
      "Soora Choi",
      "Eunsun Lee",
      "Jinwoo Seo",
      "Dongbin Na"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Regmi_ReweightOOD_Loss_Reweighting_for_Distance-based_OOD_Detection_CVPRW_2024_paper.html": {
    "title": "ReweightOOD: Loss Reweighting for Distance-based OOD Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sudarshan Regmi",
      "Bibek Panthi",
      "Yifei Ming",
      "Prashnna K Gyawali",
      "Danail Stoyanov",
      "Binod Bhattarai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/html/Sarkar_RLNet_Robust_Linearized_Networks_for_Efficient_Private_Inference_CVPRW_2024_paper.html": {
    "title": "RLNet: Robust Linearized Networks for Efficient Private Inference",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sreetama Sarkar",
      "Souvik Kundu",
      "Peter A. Beerel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LXCV/html/Lima_ST-Gait_Leveraging_Spatio-temporal_Convolutions_for_Gait-based_Emotion_Recognition_on_Videos_CVPRW_2024_paper.html": {
    "title": "ST-Gait++: Leveraging Spatio-temporal Convolutions for Gait-based Emotion Recognition on Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maria Luísa Lima",
      "Willams De Lima Costa",
      "Estefania Talavera Martínez",
      "Veronica Teichrieb"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LXCV/html/Reyes-Amezcua_Enhancing_Image_Classification_Robustness_through_Adversarial_Sampling_with_Delta_Data_CVPRW_2024_paper.html": {
    "title": "Enhancing Image Classification Robustness through Adversarial Sampling with Delta Data Augmentation (DDA)",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Reyes-Amezcua",
      "Gilberto Ochoa-Ruiz",
      "Andres Mendez-Vazquez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LXCV/html/Perez_Beyond_Appearances_Material_Segmentation_with_Embedded_Spectral_Information_from_RGB-D_CVPRW_2024_paper.html": {
    "title": "Beyond Appearances: Material Segmentation with Embedded Spectral Information from RGB-D imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fabian Perez",
      "Hoover Rueda-Chacón"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LXCV/html/Izquierdo-Cordova_The_Myth_of_the_Pyramid_CVPRW_2024_paper.html": {
    "title": "The Myth of the Pyramid",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramon Izquierdo-Cordova",
      "Walterio Mayol-Cuevas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LXCV/html/Castro_An_End-to-End_Approach_for_Handwriting_Recognition_From_Handwritten_Text_Lines_CVPRW_2024_paper.html": {
    "title": "An End-to-End Approach for Handwriting Recognition: From Handwritten Text Lines to Complete Pages",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dayvid Castro",
      "Byron Leite Dantas Bezerra",
      "Cleber Zanchettin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LXCV/html/Schirmer_High-Resolution_Detection_of_Earth_Structural_Heterogeneities_from_Seismic_Amplitudes_using_CVPRW_2024_paper.html": {
    "title": "High-Resolution Detection of Earth Structural Heterogeneities from Seismic Amplitudes using Convolutional Neural Networks with Attention layers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luiz Schirmer",
      "Guilherme Schardong",
      "Vinícius Da Silva",
      "Rogério Santos",
      "Hélio Lopes"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Lu_GPT_as_Psychologist___Preliminary_Evaluations_for_GPT-4V_on_CVPRW_2024_paper.html": {
    "title": "GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Lu",
      "Xuesong Niu",
      "Jiyao Wang",
      "Yin Wang",
      "Qingyong Hu",
      "Jiaqi Tang",
      "Yuting Zhang",
      "Kaishen Yuan",
      "Bin Huang",
      "Zitong Yu",
      "Dengbo He",
      "Shuiguang Deng",
      "Hao Chen",
      "Yingcong Chen",
      "Shiguang Shan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Braun_How_Suboptimal_is_Training_rPPG_Models_with_Videos_and_Targets_CVPRW_2024_paper.html": {
    "title": "How Suboptimal is Training rPPG Models with Videos and Targets from Different Body Sites?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Björn Braun",
      "Daniel Mcduff",
      "Christian Holz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Cantrill_Orientation-conditioned_Facial_Texture_Mapping_for_Video-based_Facial_Remote_Photoplethysmography_Estimation_CVPRW_2024_paper.html": {
    "title": "Orientation-conditioned Facial Texture Mapping for Video-based Facial Remote Photoplethysmography Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sam Cantrill",
      "David Ahmedt-Aristizabal",
      "Lars Petersson",
      "Hanna Suominen",
      "Mohammad Ali Armin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Parodi_Vision-language_Models_for_Decoding_Provider_Attention_During_Neonatal_Resuscitation_CVPRW_2024_paper.html": {
    "title": "Vision-language Models for Decoding Provider Attention During Neonatal Resuscitation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felipe Parodi",
      "Jordan K. Matelsky",
      "Alejandra Regla-Vargas",
      "Elizabeth E. Foglia",
      "Charis Lim",
      "Danielle Weinberg",
      "Konrad P. Kording",
      "Heidi M. Herrick",
      "Michael L. Platt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Dong_DECNet_A_Non-Contacting_Dual-Modality_Emotion_Classification_Network_for_Driver_Health_CVPRW_2024_paper.html": {
    "title": "DECNet: A Non-Contacting Dual-Modality Emotion Classification Network for Driver Health Monitoring",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhekang Dong",
      "Chenhao Hu",
      "Shiqi Zhou",
      "Liyan Zhu",
      "Junfan Wang",
      "Yi Chen",
      "Xudong Lv",
      "Xiaoyue Ji"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Vance_Refining_Remote_Photoplethysmography_Architectures_using_CKA_and_Empirical_Methods_CVPRW_2024_paper.html": {
    "title": "Refining Remote Photoplethysmography Architectures using CKA and Empirical Methods",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Vance",
      "Patrick Flynn"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Singh_Video_Based_Computational_Coding_of_Movement_Anomalies_in_ASD_Children_CVPRW_2024_paper.html": {
    "title": "Video Based Computational Coding of Movement Anomalies in ASD Children",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Priya Singh",
      "Abhishek Pathak",
      "Umer Jon Ganai",
      "Braj Bhushan",
      "Venkatesh K. Subramanian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Vedernikov_Analyzing_Participants_Engagement_during_Online_Meetings_Using_Unsupervised_Remote_Photoplethysmography_CVPRW_2024_paper.html": {
    "title": "Analyzing Participants' Engagement during Online Meetings Using Unsupervised Remote Photoplethysmography with Behavioral Features",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Vedernikov",
      "Zhaodong Sun",
      "Virpi-Liisa Kykyri",
      "Mikko Pohjola",
      "Miriam Nokia",
      "Xiaobai Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Khandelwal_NurtureNet_A_Multi-task_Video-based_Approach_for_Newborn_Anthropometry_CVPRW_2024_paper.html": {
    "title": "NurtureNet: A Multi-task Video-based Approach for Newborn Anthropometry",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yash Khandelwal",
      "Mayur Arvind",
      "Sriram Kumar",
      "Ashish Gupta",
      "Sachin Kumar Danisetty",
      "Piyush Bagad",
      "Anish Madan",
      "Mayank Lunayach",
      "Aditya Annavajjala",
      "Abhishek Maiti",
      "Sansiddh Jain",
      "Aman Dalmia",
      "Namrata Deka",
      "Jerome White",
      "Jigar Doshi",
      "Angjoo Kanazawa",
      "Rahul Panicker",
      "Alpan Raval",
      "Srinivas Rana",
      "Makarand Tapaswi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPM/html/Wegerif_Paediatric_Pulse_Rate_Measurements_a_Comparison_of_Methods_using_Remote_CVPRW_2024_paper.html": {
    "title": "Paediatric Pulse Rate Measurements: a Comparison of Methods using Remote Photoplethysmography",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Wegerif",
      "Ivan Veleslavov",
      "Lieke Dorine Van Putten",
      "Kate Emily Bamford",
      "Gauri Misra",
      "Niall Mullen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Khairi_Efficient_Local_Correlation_Volume_for_Unsupervised_Optical_Flow_Estimation_on_CVPRW_2024_paper.html": {
    "title": "Efficient Local Correlation Volume for Unsupervised Optical Flow Estimation on Small Moving Objects in Large Satellite Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sarra Khairi",
      "Etienne Meunier",
      "Renaud Fraisse",
      "Patrick Bouthemy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Sastry_GeoSynth_Contextually-Aware_High-Resolution_Satellite_Image_Synthesis_CVPRW_2024_paper.html": {
    "title": "GeoSynth: Contextually-Aware High-Resolution Satellite Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Srikumar Sastry",
      "Subash Khanal",
      "Aayush Dhakal",
      "Nathan Jacobs"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Obadic_Contrastive_Pretraining_for_Visual_Concept_Explanations_of_Socioeconomic_Outcomes_CVPRW_2024_paper.html": {
    "title": "Contrastive Pretraining for Visual Concept Explanations of Socioeconomic Outcomes",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivica Obadic",
      "Alex Levering",
      "Lars Pennig",
      "Dario Oliveira",
      "Diego Marcos",
      "Xiaoxiang Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Le_Bellier_Detecting_Out-Of-Distribution_Earth_Observation_Images_with_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "Detecting Out-Of-Distribution Earth Observation Images with Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georges Le Bellier",
      "Nicolas Audebert"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Nair_Let_Me_Show_You_How_Its_Done_-_Cross-modal_Knowledge_CVPRW_2024_paper.html": {
    "title": "Let Me Show You How It's Done - Cross-modal Knowledge Distillation as Pretext Task for Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rudhishna Narayanan Nair",
      "Ronny Hänsch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Roberts_Charting_New_Territories_Exploring_the_Geographic_and_Geospatial_Capabilities_of_CVPRW_2024_paper.html": {
    "title": "Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Roberts",
      "Timo Lüddecke",
      "Rehan Sheikh",
      "Kai Han",
      "Samuel Albanie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Venkatesan_SyntStereo2Real_Edge-Aware_GAN_for_Remote_Sensing_Image-to-Image_Translation_while_Maintaining_CVPRW_2024_paper.html": {
    "title": "SyntStereo2Real: Edge-Aware GAN for Remote Sensing Image-to-Image Translation while Maintaining Stereo Constraint",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vasudha Venkatesan",
      "Daniel Panangian",
      "Mario Fuentes Reyes",
      "Ksenia Bittner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Dhakal_Sat2Cap_Mapping_Fine-Grained_Textual_Descriptions_from_Satellite_Images_CVPRW_2024_paper.html": {
    "title": "Sat2Cap: Mapping Fine-Grained Textual Descriptions from Satellite Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aayush Dhakal",
      "Adeel Ahmad",
      "Subash Khanal",
      "Srikumar Sastry",
      "Hannah Kerner",
      "Nathan Jacobs"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Broni-Bediako_Unsupervised_Domain_Adaptation_Architecture_Search_with_Self-Training_for_Land_Cover_CVPRW_2024_paper.html": {
    "title": "Unsupervised Domain Adaptation Architecture Search with Self-Training for Land Cover Mapping",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Clifford Broni-Bediako",
      "Junshi Xia",
      "Naoto Yokoya"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Ebel_Implicit_Assimilation_of_Sparse_In_Situ_Data_for_Dense__CVPRW_2024_paper.html": {
    "title": "Implicit Assimilation of Sparse In Situ Data for Dense & Global Storm Surge Forecasting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Ebel",
      "Brandon Victor",
      "Peter Naylor",
      "Gabriele Meoni",
      "Federico Serva",
      "Rochelle Schneider"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Behari_SUNDIAL_3D_Satellite_Understanding_through_Direct_Ambient_and_Complex_Lighting_CVPRW_2024_paper.html": {
    "title": "SUNDIAL: 3D Satellite Understanding through Direct Ambient and Complex Lighting Decomposition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikhil Behari",
      "Akshat Dave",
      "Kushagra Tiwary",
      "William Yang",
      "Ramesh Raskar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Bou_Exploring_Robust_Features_for_Few-Shot_Object_Detection_in_Satellite_Imagery_CVPRW_2024_paper.html": {
    "title": "Exploring Robust Features for Few-Shot Object Detection in Satellite Imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xavier Bou",
      "Gabriele Facciolo",
      "Rafael Grompone Von Gioi",
      "Jean-Michel Morel",
      "Thibaud Ehret"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Okabayashi_Cross-sensor_super-resolution_of_irregularly_sampled_Sentinel-2_time_series_CVPRW_2024_paper.html": {
    "title": "Cross-sensor super-resolution of irregularly sampled Sentinel-2 time series",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aimi Okabayashi",
      "Nicolas Audebert",
      "Simon Donike",
      "Charlotte Pelletier"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Stoken_Street_Lights_Will_Guide_You_Georeferencing_Nighttime_Astronaut_Photography_of_CVPRW_2024_paper.html": {
    "title": "(Street) Lights Will Guide You: Georeferencing Nighttime Astronaut Photography of Earth",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Stoken",
      "Peter Ilhardt",
      "Mark Lambert",
      "Kenton Fisher"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Ehret_Radar_Fields_An_Extension_of_Radiance_Fields_to_SAR_CVPRW_2024_paper.html": {
    "title": "Radar Fields: An Extension of Radiance Fields to SAR",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thibaud Ehret",
      "Roger Mari",
      "Dawa Derksen",
      "Nicolas Gasnier",
      "Gabriele Facciolo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Qu_Deep_Generative_Data_Assimilation_in_Multimodal_Setting_CVPRW_2024_paper.html": {
    "title": "Deep Generative Data Assimilation in Multimodal Setting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongquan Qu",
      "Juan Nathaniel",
      "Shuolin Li",
      "Pierre Gentine"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Singh_GeoLLM-Engine_A_Realistic_Environment_for_Building_Geospatial_Copilots_CVPRW_2024_paper.html": {
    "title": "GeoLLM-Engine: A Realistic Environment for Building Geospatial Copilots",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simranjit Singh",
      "Michael Fore",
      "Dimitrios Stamoulis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/html/Zhao_UrbanSARFloods_Sentinel-1_SLC-Based_Benchmark_Dataset_for_Urban_and_Open-Area_Flood_CVPRW_2024_paper.html": {
    "title": "UrbanSARFloods: Sentinel-1 SLC-Based Benchmark Dataset for Urban and Open-Area Flood Mapping",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Zhao",
      "Zhitong Xiong",
      "Xiao Xiang Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GAZE/html/Jindal_Spatio-Temporal_Attention_and_Gaussian_Processes_for_Personalized_Video_Gaze_Estimation_CVPRW_2024_paper.html": {
    "title": "Spatio-Temporal Attention and Gaussian Processes for Personalized Video Gaze Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Swati Jindal",
      "Mohit Yadav",
      "Roberto Manduchi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GAZE/html/Nishiyasu_Gaze_Scanpath_Transformer_Predicting_Visual_Search_Target_by_Spatiotemporal_Semantic_CVPRW_2024_paper.html": {
    "title": "Gaze Scanpath Transformer: Predicting Visual Search Target by Spatiotemporal Semantic Modeling of Gaze Scanpath",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takumi Nishiyasu",
      "Yoichi Sato"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GAZE/html/Gupta_Exploring_the_Zero-Shot_Capabilities_of_Vision-Language_Models_for_Improving_Gaze_CVPRW_2024_paper.html": {
    "title": "Exploring the Zero-Shot Capabilities of Vision-Language Models for Improving Gaze Following",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anshul Gupta",
      "Pierre Vuillecard",
      "Arya Farkhondeh",
      "Jean-Marc Odobez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GAZE/html/Mathew_GESCAM__A_Dataset_and_Method_on_Gaze_Estimation_for_CVPRW_2024_paper.html": {
    "title": "GESCAM : A Dataset and Method on Gaze Estimation for Classroom Attention Measurement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Athul M. Mathew",
      "Arshad Ali Khan",
      "Thariq Khalid",
      "Riad Souissi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Pang_Sparse_Multi-view_Hand-object_Reconstruction_for_Unseen_Environments_CVPRW_2024_paper.html": {
    "title": "Sparse Multi-view Hand-object Reconstruction for Unseen Environments",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yik Lung Pang",
      "Changjae Oh",
      "Andrea Cavallaro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Marathe_MIMIC_Masked_Image_Modeling_with_Image_Correspondences_CVPRW_2024_paper.html": {
    "title": "MIMIC: Masked Image Modeling with Image Correspondences",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kalyani Marathe",
      "Mahtab Bigverdi",
      "Nishat Khan",
      "Tuhin Kundu",
      "Patrick Howe",
      "Sharan Ranjit S",
      "Anand Bhattad",
      "Aniruddha Kembhavi",
      "Linda G. Shapiro",
      "Ranjay Krishna"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Chung_Depth-Regularized_Optimization_for_3D_Gaussian_Splatting_in_Few-Shot_Images_CVPRW_2024_paper.html": {
    "title": "Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaeyoung Chung",
      "Jeongtaek Oh",
      "Kyoung Mu Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Oh_From_2D_Portraits_to_3D_Realities_Advancing_GAN_Inversion_for_CVPRW_2024_paper.html": {
    "title": "From 2D Portraits to 3D Realities: Advancing GAN Inversion for Enhanced Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonseok Oh",
      "Youngjoo Jo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Hong_3D_Clothed_Human_Reconstruction_from_Sparse_Multi-view_Images_CVPRW_2024_paper.html": {
    "title": "3D Clothed Human Reconstruction from Sparse Multi-view Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jin Gyu Hong",
      "Seung Young Noh",
      "Hee Kyung Lee",
      "Won Sik Cheong",
      "Ju Yong Chang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Li_MonoSelfRecon_Purely_Self-Supervised_Explicit_Generalizable_3D_Reconstruction_of_Indoor_Scenes_CVPRW_2024_paper.html": {
    "title": "MonoSelfRecon: Purely Self-Supervised Explicit Generalizable 3D Reconstruction of Indoor Scenes from Monocular RGB Views",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runfa Li",
      "Upal Mahbub",
      "Vasudev Bhaskaran",
      "Truong Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Dharmasiri_Cross-Modal_Self-Training_Aligning_Images_and_Pointclouds_to_learn_Classification_without_CVPRW_2024_paper.html": {
    "title": "Cross-Modal Self-Training: Aligning Images and Pointclouds to learn Classification without Labels",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amaya Dharmasiri",
      "Muzammal Naseer",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Alzahrani_Selective_Multi-View_Deep_Model_for_3D_Object_Classification_CVPRW_2024_paper.html": {
    "title": "Selective Multi-View Deep Model for 3D Object Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mona Alzahrani",
      "Muhammad Usman",
      "Saeed Anwar",
      "Tarek Helmy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Zhu_DepthVoting_A_Few-Shot_Point_Cloud_Classification_Model_Incorporating_a_Projection-Based_CVPRW_2024_paper.html": {
    "title": "DepthVoting: A Few-Shot Point Cloud Classification Model Incorporating a Projection-Based Voting Mechanism",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunhui Zhu",
      "Jiajing Chen",
      "Senem Velipasalar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Kim_Color-cued_Efficient_Densification_Method_for_3D_Gaussian_Splatting_CVPRW_2024_paper.html": {
    "title": "Color-cued Efficient Densification Method for 3D Gaussian Splatting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sieun Kim",
      "Kyungjin Lee",
      "Youngki Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Lee_OGRMPI_An_Efficient_Multiview_Integrated_Multiplane_Image_based_on_Occlusion_CVPRW_2024_paper.html": {
    "title": "OGRMPI: An Efficient Multiview Integrated Multiplane Image based on Occlusion Guided Residuals",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dae Yeol Lee",
      "Guan-Ming Su",
      "Peng Yin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Revaud_SACReg_Scene-Agnostic_Coordinate_Regression_for_Visual_Localization_CVPRW_2024_paper.html": {
    "title": "SACReg: Scene-Agnostic Coordinate Regression for Visual Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jerome Revaud",
      "Yohann Cabon",
      "Romain Brégier",
      "Jongmin Lee",
      "Philippe Weinzaepfel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Teepe_Lifting_Multi-View_Detection_and_Tracking_to_the_Birds_Eye_View_CVPRW_2024_paper.html": {
    "title": "Lifting Multi-View Detection and Tracking to the Bird's Eye View",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Torben Teepe",
      "Philipp Wolters",
      "Johannes Gilg",
      "Fabian Herzog",
      "Gerhard Rigoll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Song_AgileGAN3D_Few-Shot_3D_Portrait_Stylization_by_Augmented_Transfer_Learning_CVPRW_2024_paper.html": {
    "title": "AgileGAN3D: Few-Shot 3D Portrait Stylization by Augmented Transfer Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guoxian Song",
      "Hongyi Xu",
      "Jing Liu",
      "Tiancheng Zhi",
      "Yichun Shi",
      "Jianfeng Zhang",
      "Zihang Jiang",
      "Jiashi Feng",
      "Shen Sang",
      "Linjie Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Sharma_2T-UNET_A_Two-Tower_UNet_with_Depth_Clues_for_Robust_Stereo_CVPRW_2024_paper.html": {
    "title": "2T-UNET: A Two-Tower UNet with Depth Clues for Robust Stereo Depth Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mansi Sharma",
      "Rohit Choudhary",
      "Rithvik Anil"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Margaryan_DGBD_Depth_Guided_Branched_Diffusion_for_Comprehensive_Controllability_in_Multi-View_CVPRW_2024_paper.html": {
    "title": "DGBD: Depth Guided Branched Diffusion for Comprehensive Controllability in Multi-View Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hovhannes Margaryan",
      "Daniil Hayrapetyan",
      "Wenyan Cong",
      "Zhangyang Wang",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Yue_Semi-Stereo_A_Universal_Stereo_Matching_Framework_for_Imperfect_Data_via_CVPRW_2024_paper.html": {
    "title": "Semi-Stereo: A Universal Stereo Matching Framework for Imperfect Data via Semi-supervised Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Yue",
      "Zongqing Lu",
      "Xiangru Lin",
      "Wenjia Ren",
      "Zhijing Shao",
      "Haonan Hu",
      "Yu Zhang",
      "Qingmin Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/html/Ren_PointOfView_A_Multi-modal_Network_for_Few-shot_3D_Point_Cloud_Classification_CVPRW_2024_paper.html": {
    "title": "PointOfView: A Multi-modal Network for Few-shot 3D Point Cloud Classification Fusing Point and Multi-view Image Features",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huantao Ren",
      "Jiyang Wang",
      "Minmin Yang",
      "Senem Velipasalar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EDGE/html/Castells_LD-Pruner_Efficient_Pruning_of_Latent_Diffusion_Models_using_Task-Agnostic_Insights_CVPRW_2024_paper.html": {
    "title": "LD-Pruner: Efficient Pruning of Latent Diffusion Models using Task-Agnostic Insights",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thibault Castells",
      "Hyoung-Kyu Song",
      "Bo-Kyeong Kim",
      "Shinkook Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EDGE/html/Lin_EdgeRelight360_Text-Conditioned_360-Degree_HDR_Image_Generation_for_Real-Time_On-Device_Video_CVPRW_2024_paper.html": {
    "title": "EdgeRelight360: Text-Conditioned 360-Degree HDR Image Generation for Real-Time On-Device Video Portrait Relighting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min-Hui Lin",
      "Mahesh Reddy",
      "Guillaume Berger",
      "Michel Sarkis",
      "Fatih Porikli",
      "Ning Bi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VISOD/html/Cerezo_Camera_Motion_Estimation_from_RGB-D-Inertial_Scene_Flow_CVPRW_2024_paper.html": {
    "title": "Camera Motion Estimation from RGB-D-Inertial Scene Flow",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Cerezo",
      "Javier Civera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VISOD/html/Liu_BAA-NGP_Bundle-Adjusting_Accelerated_Neural_Graphics_Primitives_CVPRW_2024_paper.html": {
    "title": "BAA-NGP: Bundle-Adjusting Accelerated Neural Graphics Primitives",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sainan Liu",
      "Shan Lin",
      "Jingpei Lu",
      "Alexey Supikov",
      "Michael Yip"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VISOD/html/Abouee_Weakly_Supervised_End2End_Deep_Visual_Odometry_CVPRW_2024_paper.html": {
    "title": "Weakly Supervised End2End Deep Visual Odometry",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amin Abouee",
      "Ashwanth Ravi",
      "Lars Hinneburg",
      "Mateusz Dziwulski",
      "Florian Ölsner",
      "Jürgen Hess",
      "Stefan Milz",
      "Patrik Mäder"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/INRV/html/Biswal_StegaNeRV_Video_Steganography_using_Implicit_Neural_Representation_CVPRW_2024_paper.html": {
    "title": "StegaNeRV: Video Steganography using Implicit Neural Representation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Monsij Biswal",
      "Tong Shao",
      "Kenneth Rose",
      "Peng Yin",
      "Sean Mccarthy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/INRV/html/Ballerini_Connecting_NeRFs_Images_and_Text_CVPRW_2024_paper.html": {
    "title": "Connecting NeRFs Images and Text",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Ballerini",
      "Pierluigi Zama Ramirez",
      "Roberto Mirabella",
      "Samuele Salti",
      "Luigi Di Stefano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/INRV/html/Feng_ImplicitTerrain_a_Continuous_Surface_Model_for_Terrain_Data_Analysis_CVPRW_2024_paper.html": {
    "title": "ImplicitTerrain: a Continuous Surface Model for Terrain Data Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoan Feng",
      "Xin Xu",
      "Leila De Floriani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/INRV/html/Costain_Contextualising_Implicit_Representations_for_Semantic_Tasks_CVPRW_2024_paper.html": {
    "title": "Contextualising Implicit Representations for Semantic Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Theo W. Costain",
      "Kejie Li",
      "Victor A. Prisacariu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GDUG/html/Wang_Reference-based_GAN_Evaluation_by_Adaptive_Inversion_CVPRW_2024_paper.html": {
    "title": "Reference-based GAN Evaluation by Adaptive Inversion",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianbo Wang",
      "Heliang Zheng",
      "Toshihiko Yamasaki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Cui_IDAdapter_Learning_Mixed_Features_for_Tuning-Free_Personalization_of_Text-to-Image_Models_CVPRW_2024_paper.html": {
    "title": "IDAdapter: Learning Mixed Features for Tuning-Free Personalization of Text-to-Image Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siying Cui",
      "Jia Guo",
      "Xiang An",
      "Jiankang Deng",
      "Yongle Zhao",
      "Xinyu Wei",
      "Ziyong Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Tarasiou_Rethinking_the_Domain_Gap_in_Near-infrared_Face_Recognition_CVPRW_2024_paper.html": {
    "title": "Rethinking the Domain Gap in Near-infrared Face Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michail Tarasiou",
      "Jiankang Deng",
      "Stefanos Zafeiriou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Huang_A_Visualization_Method_for_Data_Domain_Changes_in_CNN_Networks_CVPRW_2024_paper.html": {
    "title": "A Visualization Method for Data Domain Changes in CNN Networks and the Optimization Method for Selecting Thresholds in Classification Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minzhe Huang",
      "Changwei Nie",
      "Weihong Zhong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Luevano_Assessing_the_Performance_of_Efficient_Face_Anti-Spoofing_Detection_Against_Physical_CVPRW_2024_paper.html": {
    "title": "Assessing the Performance of Efficient Face Anti-Spoofing Detection Against Physical and Digital Presentation Attacks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luis S. Luevano",
      "Yoanna Martínez-Díaz",
      "Heydi Méndez-Vázquez",
      "Miguel González-Mendoza",
      "Davide Frey"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Zou_Multi-angle_Consistent_Generative_NeRF_with_Additive_Angular_Margin_Momentum_Contrastive_CVPRW_2024_paper.html": {
    "title": "Multi-angle Consistent Generative NeRF with Additive Angular Margin Momentum Contrastive Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hang Zou",
      "Hui Zhang",
      "Yuan Zhang",
      "Hui Ma",
      "Dexin Zhao",
      "Qi Zhang",
      "Qi Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Yu_Unified_Face_Attack_Detection_with_Micro_Disturbance_and_a_Two-Stage_CVPRW_2024_paper.html": {
    "title": "Unified Face Attack Detection with Micro Disturbance and a Two-Stage Training Strategy",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaruo Yu",
      "Dagong Lu",
      "Xingyue Shi",
      "Chenfan Qu",
      "Fengjun Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/He_Joint_Physical-Digital_Facial_Attack_Detection_Via_Simulating_Spoofing_Clues_CVPRW_2024_paper.html": {
    "title": "Joint Physical-Digital Facial Attack Detection Via Simulating Spoofing Clues",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianhua He",
      "Dashuang Liang",
      "Song Yang",
      "Zhanlong Hao",
      "Hui Ma",
      "Binjie Mao",
      "Xi Li",
      "Yao Wang",
      "Pengfei Yan",
      "Ajian Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Kim_Advancing_Cross-Domain_Generalizability_in_Face_Anti-Spoofing_Insights_Design_and_Metrics_CVPRW_2024_paper.html": {
    "title": "Advancing Cross-Domain Generalizability in Face Anti-Spoofing: Insights Design and Metrics",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyojin Kim",
      "Jiyoon Lee",
      "Yonghyun Jeong",
      "Haneol Jang",
      "Youngjoon Yoo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Nathan_Multiattention-Net_A_Novel_Approach_to_Face_Anti-Spoofing_with_Modified_Squeezed_CVPRW_2024_paper.html": {
    "title": "Multiattention-Net: A Novel Approach to Face Anti-Spoofing with Modified Squeezed Residual Blocks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sabari Nathan",
      "M.Parisa Beham",
      "A Nagaraj",
      "S. Mohamed Mansoor Roomi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Song_Supervised_Contrastive_Learning_for_Snapshot_Spectral_Imaging_Face_Anti-Spoofing_CVPRW_2024_paper.html": {
    "title": "Supervised Contrastive Learning for Snapshot Spectral Imaging Face Anti-Spoofing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuanbiao Song",
      "Yan Hong",
      "Jun Lan",
      "Huijia Zhu",
      "Weiqiang Wang",
      "Jianfu Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Yuan_Unified_Physical-Digital_Attack_Detection_Challenge_CVPRW_2024_paper.html": {
    "title": "Unified Physical-Digital Attack Detection Challenge",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haocheng Yuan",
      "Ajian Liu",
      "Junze Zheng",
      "Jun Wan",
      "Jiankang Deng",
      "Sergio Escalera",
      "Hugo Jair Escalante",
      "Isabelle Guyon",
      "Zhen Lei"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FAS2024/html/Li_Snapshot_Spectral_Imaging_for_Face_Anti-Spoofing_Addressing_Data_Challenges_with_CVPRW_2024_paper.html": {
    "title": "Snapshot Spectral Imaging for Face Anti-Spoofing: Addressing Data Challenges with Advanced Processing and Training",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Li",
      "Yaowen Xu",
      "Zhaofan Zou",
      "Zhixiang He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAT/html/Yamashita_MixStyle-Based_Contrastive_Test-Time_Adaptation_Pathway_to_Domain_Generalization_CVPRW_2024_paper.html": {
    "title": "MixStyle-Based Contrastive Test-Time Adaptation: Pathway to Domain Generalization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kota Yamashita",
      "Kazuhiro Hotta"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAT/html/Jahan_Unknown_Sample_Discovery_for_Source_Free_Open_Set_Domain_Adaptation_CVPRW_2024_paper.html": {
    "title": "Unknown Sample Discovery for Source Free Open Set Domain Adaptation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chowdhury Sadman Jahan",
      "Andreas Savakis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAT/html/Fahim_ST2ST_Self-Supervised_Test-time_Adaptation_for_Video_Action_Recognition_CVPRW_2024_paper.html": {
    "title": "ST2ST: Self-Supervised Test-time Adaptation for Video Action Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masud An-Nur Islam Fahim",
      "Mohammed Innat",
      "Jani Boutellier"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAT/html/Leroux_Test-time_Specialization_of_Dynamic_Neural_Networks_CVPRW_2024_paper.html": {
    "title": "Test-time Specialization of Dynamic Neural Networks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sam Leroux",
      "Dewant Katare",
      "Aaron Yi Ding",
      "Pieter Simoens"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAT/html/Ruan_Fully_Test-time_Adaptation_for_Object_Detection_CVPRW_2024_paper.html": {
    "title": "Fully Test-time Adaptation for Object Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoqian Ruan",
      "Wei Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Xu_DemosaicFormer_Coarse-to-Fine_Demosaicing_Network_for_HybridEVS_Camera_CVPRW_2024_paper.html": {
    "title": "DemosaicFormer: Coarse-to-Fine Demosaicing Network for HybridEVS Camera",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Senyan Xu",
      "Zhijing Sun",
      "Jiaying Zhu",
      "Yurui Zhu",
      "Xueyang Fu",
      "Zheng-Jun Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Li_From_Synthetic_to_Real_A_Calibration-free_Pipeline_for_Few-shot_Raw_CVPRW_2024_paper.html": {
    "title": "From Synthetic to Real: A Calibration-free Pipeline for Few-shot Raw Image Denoising",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruoqi Li",
      "Chang Liu",
      "Ziyi Wang",
      "Yao Du",
      "Jingjing Yang",
      "Long Bao",
      "Heng Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Jin_MIPI_2024_Challenge_on_Few-shot_RAW_Image_Denoising_Methods_and_CVPRW_2024_paper.html": {
    "title": "MIPI 2024 Challenge on Few-shot RAW Image Denoising: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Jin",
      "Chunle Guo",
      "Xiaoming Li",
      "Zongsheng Yue",
      "Chongyi Li",
      "Shangchen Zhou",
      "Ruicheng Feng",
      "Yuekun Dai",
      "Peiqing Yang",
      "Chen Change Loy",
      "Ruoqi Li",
      "Chang Liu",
      "Ziyi Wang",
      "Yao Du",
      "Jingjing Yang",
      "Long Bao",
      "Heng Sun",
      "Xiangyu Kong",
      "Xiaoxia Xing",
      "Jinlong Wu",
      "Yuanyang Xue",
      "Hyunhee Park",
      "Sejun Song",
      "Changho Kim",
      "Jingfan Tan",
      "Wenhan Luo",
      "Zikun Liu",
      "Mingde Qiao",
      "Junjun Jiang",
      "Kui Jiang",
      "Yao Xiao",
      "Chuyang Sun",
      "Jinhui Hu",
      "Weijian Ruan",
      "Yubo Dong",
      "Kai Chen",
      "Hyejeong Jo",
      "Jiahao Qin",
      "Bingjie Han",
      "Pinle Qin",
      "Rui Chai",
      "Pengyuan Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Lu_Event_Camera_Demosaicing_via_Swin_Transformer_and_Pixel-focus_Loss_CVPRW_2024_paper.html": {
    "title": "Event Camera Demosaicing via Swin Transformer and Pixel-focus Loss",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunfan Lu",
      "Yijie Xu",
      "Wenzong Ma",
      "Weiyu Guo",
      "Hui Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Wang_UDAC_Under-Display_Array_Cameras_CVPRW_2024_paper.html": {
    "title": "UDAC: Under-Display Array Cameras",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chengyu Wang",
      "Jing Li",
      "Pavan C. Madhusudanarao",
      "Jinhan Hu",
      "Jitesh K. Singh",
      "Woojhon Choi",
      "Seok-Jun Lee",
      "Hamid R. Sheikh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Liu_LaDiffGAN_Training_GANs_with_Diffusion_Supervision_in_Latent_Spaces_CVPRW_2024_paper.html": {
    "title": "LaDiffGAN: Training GANs with Diffusion Supervision in Latent Spaces",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuhui Liu",
      "Bohan Zeng",
      "Sicheng Gao",
      "Shanglin Li",
      "Yutang Feng",
      "Hong Li",
      "Boyu Liu",
      "Jianzhuang Liu",
      "Baochang Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Dai_MIPI_2024_Challenge_on_Nighttime_Flare_Removal_Methods_and_Results_CVPRW_2024_paper.html": {
    "title": "MIPI 2024 Challenge on Nighttime Flare Removal: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuekun Dai",
      "Dafeng Zhang",
      "Xiaoming Li",
      "Zongsheng Yue",
      "Chongyi Li",
      "Shangchen Zhou",
      "Ruicheng Feng",
      "Peiqing Yang",
      "Zhezhu Jin",
      "Guanqun Liu",
      "Chen Change Loy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Qin_EL2NM_Extremely_Low-light_Noise_Modeling_Through_Diffusion_Iteration_CVPRW_2024_paper.html": {
    "title": "EL2NM: Extremely Low-light Noise Modeling Through Diffusion Iteration",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahao Qin",
      "Pinle Qin",
      "Rui Chai",
      "Jia Qin",
      "Zanxia Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MIPI/html/Wu_MIPI_2024_Challenge_on_Demosaic_for_Hybridevs_Camera_Methods_and_CVPRW_2024_paper.html": {
    "title": "MIPI 2024 Challenge on Demosaic for Hybridevs Camera: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yaqi Wu",
      "Zhihao Fan",
      "Xiaofeng Chu",
      "Jimmy S. Ren",
      "Xiaoming Li",
      "Zongsheng Yue",
      "Chongyi Li",
      "Shangcheng Zhou",
      "Ruicheng Feng",
      "Yuekun Dai",
      "Peiqing Yang",
      "Chen Change Loy",
      "Senyan Xu",
      "Zhijing Sun",
      "Jiaying Zhu",
      "Yurui Zhu",
      "Xueyang Fu",
      "Zheng-Jun Zha",
      "Jun Cao",
      "Cheng Li",
      "Shu Chen",
      "Liang Ma",
      "Shiyang Zhou",
      "Haijin Zeng",
      "Kai Feng",
      "Yongyong Chen",
      "Jingyong Su",
      "Xianyu Guan",
      "Hongyuan Yu",
      "Cheng Wan",
      "Jiamin Lin",
      "Binnan Han",
      "Yajun Zou",
      "Zhuoyuan Wu",
      "Yuan Huang",
      "Yongsheng Yu",
      "Daoan Zhang",
      "Jizhe Li",
      "Xuanwu Yin",
      "Kunlong Zuo",
      "Yunfan Lu",
      "Yijie Xu",
      "Wenzong Ma",
      "Weiyu Guo",
      "Hui Xiong",
      "Wei Yu",
      "Bingchun Luo",
      "Sabari Nathan",
      "Priya Kansal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/2WFM/html/Englert_Exploring_the_Benefits_of_Vision_Foundation_Models_for_Unsupervised_Domain_CVPRW_2024_paper.html": {
    "title": "Exploring the Benefits of Vision Foundation Models for Unsupervised Domain Adaptation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Brunó B. Englert",
      "Fabrizio J. Piva",
      "Tommie Kerssies",
      "Daan De Geus",
      "Gijs Dubbelman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/2WFM/html/Kerssies_How_to_Benchmark_Vision_Foundation_Models_for_Semantic_Segmentation_CVPRW_2024_paper.html": {
    "title": "How to Benchmark Vision Foundation Models for Semantic Segmentation?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tommie Kerssies",
      "Daan De Geus",
      "Gijs Dubbelman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FGVC11/html/Ng_ConceptHash_Interpretable_Fine-Grained_Hashing_via_Concept_Discovery_CVPRW_2024_paper.html": {
    "title": "ConceptHash: Interpretable Fine-Grained Hashing via Concept Discovery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kam Woh Ng",
      "Xiatian Zhu",
      "Yi-Zhe Song",
      "Tao Xiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FGVC11/html/Dondera_Towards_Learning_Image_Similarity_from_General_Triplet_Labels_CVPRW_2024_paper.html": {
    "title": "Towards Learning Image Similarity from General Triplet Labels",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Radu Dondera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FGVC11/html/Sharma_Monitoring_Social_Insect_Activity_with_Minimal_Human_Supervision_CVPRW_2024_paper.html": {
    "title": "Monitoring Social Insect Activity with Minimal Human Supervision",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarun Sharma",
      "Julian M. Wagner",
      "Sara Beery",
      "William B. Dickson",
      "Michael H. Dickinson",
      "Joseph Parker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FGVC11/html/Barbany_Leveraging_Large_Language_Models_for_Multimodal_Search_CVPRW_2024_paper.html": {
    "title": "Leveraging Large Language Models for Multimodal Search",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oriol Barbany",
      "Michael Huang",
      "Xinliang Zhu",
      "Arnab Dhua"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FGVC11/html/Laprade_HyperLeaf2024_-_A_Hyperspectral_Imaging_Dataset_for_Classification_and_Regression_CVPRW_2024_paper.html": {
    "title": "HyperLeaf2024 - A Hyperspectral Imaging Dataset for Classification and Regression of Wheat Leaves",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Michael Laprade",
      "Pawel Pieta",
      "Svetlana Kutuzova",
      "Jesper Cairo Westergaard",
      "Mads Nielsen",
      "Svend Christensen",
      "Anders Bjorholm Dahl"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FGVC11/html/Moltisanti_Coarse_or_Fine_Recognising_Action_End_States_without_Labels_CVPRW_2024_paper.html": {
    "title": "Coarse or Fine? Recognising Action End States without Labels",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davide Moltisanti",
      "Hakan Bilen",
      "Laura Sevilla-Lara",
      "Frank Keller"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FGVC11/html/Sharma_Making_Use_of_Unlabeled_Data_Comparing_Strategies_for_Marine_Animal_CVPRW_2024_paper.html": {
    "title": "Making Use of Unlabeled Data: Comparing Strategies for Marine Animal Detection in Long-tailed Datasets Using Self-supervised and Semi-supervised Pre-training",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarun Sharma",
      "Danelle E. Cline",
      "Duane Edgington"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Reichert_Sensor_Equivariance_A_Framework_for_Semantic_Segmentation_with_Diverse_Camera_CVPRW_2024_paper.html": {
    "title": "Sensor Equivariance: A Framework for Semantic Segmentation with Diverse Camera Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hannes Reichert",
      "Manuel Hetzel",
      "Andreas Hubert",
      "Konrad Doll",
      "Bernhard Sick"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Liu_Estimating_Depth_of_Monocular_Panoramic_Image_with_Teacher-Student_Model_Fusing_CVPRW_2024_paper.html": {
    "title": "Estimating Depth of Monocular Panoramic Image with Teacher-Student Model Fusing Equirectangular and Spherical Representations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingguo Liu",
      "Yijun Xu",
      "Shigang Li",
      "Jianfeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Bhanushali_Cross-Domain_Synthetic-to-Real_In-the-Wild_Depth_and_Normal_Estimation_for_3D_Scene_CVPRW_2024_paper.html": {
    "title": "Cross-Domain Synthetic-to-Real In-the-Wild Depth and Normal Estimation for 3D Scene Understanding",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jay Bhanushali",
      "Manivannan Muniyandi",
      "Praneeth Chakravarthula"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Yogamani_FisheyeBEVSeg_Surround_View_Fisheye_Cameras_based_Birds-Eye_View_Segmentation_for_CVPRW_2024_paper.html": {
    "title": "FisheyeBEVSeg: Surround View Fisheye Cameras based Bird's-Eye View Segmentation for Autonomous Driving",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Senthil Yogamani",
      "David Unger",
      "Venkatraman Narayanan",
      "Varun Ravi Kumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Shah_MultiPanoWise_Holistic_Deep_Architecture_for_Multi-task_Dense_Prediction_from_a_CVPRW_2024_paper.html": {
    "title": "MultiPanoWise: Holistic Deep Architecture for Multi-task Dense Prediction from a Single Panoramic Image",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Uzair Shah",
      "Muhammad Tukur",
      "Mahmood Alzubaidi",
      "Giovanni Pintore",
      "Enrico Gobbetti",
      "Mowafa Househ",
      "Jens Schneider",
      "Marco Agus"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Shan_Multi-scale_Attention-Based_Inclination_Angles_Estimation_for_Panoramic_Camera_CVPRW_2024_paper.html": {
    "title": "Multi-scale Attention-Based Inclination Angles Estimation for Panoramic Camera",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Shan",
      "Heyu Chen",
      "Jiaying Zhang",
      "Shigang Li",
      "Jianfeng Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Slezak_Exploring_the_Limits_Applying_State-of-the-Art_Stereo_Matching_Algorithms_to_Rectified_CVPRW_2024_paper.html": {
    "title": "Exploring the Limits: Applying State-of-the-Art Stereo Matching Algorithms to Rectified Ultra-Wide Stereo",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filip Slezák",
      "Morten S. Laursen",
      "Thomas B. Moeslund"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Lin_DQ-HorizonNet_Enhancing_Door_Detection_Accuracy_in_Panoramic_Images_via_Dynamic_CVPRW_2024_paper.html": {
    "title": "DQ-HorizonNet: Enhancing Door Detection Accuracy in Panoramic Images via Dynamic Quantization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cing-Jia Lin",
      "Jheng-Wei Su",
      "Kai-Wen Hsiao",
      "Ting-Yu Yen",
      "Chih-Yuan Yao",
      "Hung-Kuo Chu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Sakthi_Impact_of_Video_Compression_Artifacts_on_Fisheye_Camera_Visual_Perception_CVPRW_2024_paper.html": {
    "title": "Impact of Video Compression Artifacts on Fisheye Camera Visual Perception Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Madhumitha Sakthi",
      "Louis Kerofsky",
      "Varun Ravi Kumar",
      "Senthil Yogamani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OmniCV2024/html/Chen_BGDNet_Background-guided_Indoor_Panorama_Depth_Estimation_CVPRW_2024_paper.html": {
    "title": "BGDNet: Background-guided Indoor Panorama Depth Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiajing Chen",
      "Zhiqiang Wan",
      "Manjunath Narayana",
      "Yuguang Li",
      "Will Hutchcroft",
      "Senem Velipasalar",
      "Sing Bing Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Mao_Generating_Material-Aware_3D_Models_from_Sparse_Views_CVPRW_2024_paper.html": {
    "title": "Generating Material-Aware 3D Models from Sparse Views",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shi Mao",
      "Chenming Wu",
      "Ran Yi",
      "Zhelun Shen",
      "Liangjun Zhang",
      "Wolfgang Heidrich"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Bi_Generalized_Foggy-Scene_Semantic_Segmentation_by_Frequency_Decoupling_CVPRW_2024_paper.html": {
    "title": "Generalized Foggy-Scene Semantic Segmentation by Frequency Decoupling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qi Bi",
      "Shaodi You",
      "Theo Gevers"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Dufraisse_Physics_Based_Camera_Privacy_Lens_and_Network_Co-Design_to_the_CVPRW_2024_paper.html": {
    "title": "Physics Based Camera Privacy: Lens and Network Co-Design to the Rescue",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marius Dufraisse",
      "Marcela Carvalho",
      "Pauline Trouvé-Peloux",
      "Frédéric Champagnat"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Lv_GPT4Motion_Scripting_Physical_Motions_in_Text-to-Video_Generation_via_Blender-Oriented_GPT_CVPRW_2024_paper.html": {
    "title": "GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via Blender-Oriented GPT Planning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxi Lv",
      "Yi Huang",
      "Mingfu Yan",
      "Jiancheng Huang",
      "Jianzhuang Liu",
      "Yifan Liu",
      "Yafei Wen",
      "Xiaoxin Chen",
      "Shifeng Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Liu_Computational_Spectral_Imaging_with_Unified_Encoding_Model_and_Beyond_CVPRW_2024_paper.html": {
    "title": "Computational Spectral Imaging with Unified Encoding Model and Beyond",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinyuan Liu",
      "Lingen Li",
      "Lin Zhu",
      "Lizhi Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Chen_Imaging_Signal_Recovery_Using_Neural_Network_Priors_Under_Uncertain_Forward_CVPRW_2024_paper.html": {
    "title": "Imaging Signal Recovery Using Neural Network Priors Under Uncertain Forward Model Parameters",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiwen Chen",
      "Wenhui Zhu",
      "Peijie Qiu",
      "Abolfazl Razi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Yang_ViTKD_Feature-based_Knowledge_Distillation_for_Vision_Transformers_CVPRW_2024_paper.html": {
    "title": "ViTKD: Feature-based Knowledge Distillation for Vision Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhendong Yang",
      "Zhe Li",
      "Ailing Zeng",
      "Zexian Li",
      "Chun Yuan",
      "Yu Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Ren_Point-Supervised_Semantic_Segmentation_of_Natural_Scenes_via_Hyperspectral_Imaging_CVPRW_2024_paper.html": {
    "title": "Point-Supervised Semantic Segmentation of Natural Scenes via Hyperspectral Imaging",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianqi Ren",
      "Qiu Shen",
      "Ying Fu",
      "Shaodi You"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/html/Jiang_Gain-first_or_Exposure-first_Benchmark_for_Better_Low-light_Video_Photography_and_CVPRW_2024_paper.html": {
    "title": "Gain-first or Exposure-first: Benchmark for Better Low-light Video Photography and Enhancement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haiyang Jiang",
      "Zhihang Zhong",
      "Yinqiang Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Lin_3D_Kinematics_Estimation_from_Video_with_a_Biomechanical_Model_and_CVPRW_2024_paper.html": {
    "title": "3D Kinematics Estimation from Video with a Biomechanical Model and Synthetic Training Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi-Yi Lin",
      "Bofan Lyu",
      "Judith Cueto Fernandez",
      "Eline Van Der Kruk",
      "Ajay Seth",
      "Xucong Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Kolf_GraFIQs_Face_Image_Quality_Assessment_Using_Gradient_Magnitudes_CVPRW_2024_paper.html": {
    "title": "GraFIQs: Face Image Quality Assessment Using Gradient Magnitudes",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan Niklas Kolf",
      "Naser Damer",
      "Fadi Boutros"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Zhang_Generalized_Single-Image-Based_Morphing_Attack_Detection_Using_Deep_Representations_from_Vision_CVPRW_2024_paper.html": {
    "title": "Generalized Single-Image-Based Morphing Attack Detection Using Deep Representations from Vision Transformer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Zhang",
      "Raghavendra Ramachandra",
      "Kiran Raja",
      "Christoph Busch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Ozturk_Can_the_Accuracy_Bias_by_Facial_Hairstyle_be_Reduced_Through_CVPRW_2024_paper.html": {
    "title": "Can the Accuracy Bias by Facial Hairstyle be Reduced Through Balancing the Training Data?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kagan Ozturk",
      "Haiyu Wu",
      "Kevin W. Bowyer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Gonzalez-Soler_TattTRN_Template_Reconstruction_Network_for_Tattoo_Retrieval_CVPRW_2024_paper.html": {
    "title": "TattTRN: Template Reconstruction Network for Tattoo Retrieval",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lazaro Janier Gonzalez-Soler",
      "Maciej Salwowski",
      "Christian Rathgeb",
      "Daniel Fischer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Liang_FIQA-FAS_Face_Image_Quality_Assessment_Based_Face_Anti-Spoofing_CVPRW_2024_paper.html": {
    "title": "FIQA-FAS: Face Image Quality Assessment Based Face Anti-Spoofing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ya-Chi Liang",
      "Min-Xuan Qiu",
      "Shang-Hong Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Ogino_Outsmarting_Biometric_Imposters_Enhancing_Iris-Recognition_System_Security_through_Physical_Adversarial_CVPRW_2024_paper.html": {
    "title": "Outsmarting Biometric Imposters: Enhancing Iris-Recognition System Security through Physical Adversarial Example Generation and PAD Fine-Tuning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuka Ogino",
      "Kazuya Kakizaki",
      "Takahiro Toizumi",
      "Atsushi Ito"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Mirabet-Herranz_One_Embedding_to_Predict_Them_All_Visible_and_Thermal_Universal_CVPRW_2024_paper.html": {
    "title": "One Embedding to Predict Them All: Visible and Thermal Universal Face Representations for Soft Biometric Estimation via Vision Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nelida Mirabet-Herranz",
      "Chiara Galdi",
      "Jean-Luc Dugelay"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Chen_Confidence-Aware_RGB-D_Face_Recognition_via_Virtual_Depth_Synthesis_CVPRW_2024_paper.html": {
    "title": "Confidence-Aware RGB-D Face Recognition via Virtual Depth Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zijian Chen",
      "Mei Wang",
      "Weihong Deng",
      "Hongzhi Shi",
      "Dongchao Wen",
      "Yingjie Zhang",
      "Xingchen Cui",
      "Jian Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/BIOMET/html/Tarollo_Adversarial_Identity_Injection_for_Semantic_Face_Image_Synthesis_CVPRW_2024_paper.html": {
    "title": "Adversarial Identity Injection for Semantic Face Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giuseppe Tarollo",
      "Tomaso Fontanini",
      "Claudio Ferrari",
      "Guido Borghi",
      "Andrea Prati"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Misra_Uncovering_the_Hidden_Cost_of_Model_Compression_CVPRW_2024_paper.html": {
    "title": "Uncovering the Hidden Cost of Model Compression",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diganta Misra",
      "Muawiz Chaudhary",
      "Agam Goyal",
      "Bharat Runwal",
      "Pin Yu Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Kim_AAPL_Adding_Attributes_to_Prompt_Learning_for_Vision-Language_Models_CVPRW_2024_paper.html": {
    "title": "AAPL: Adding Attributes to Prompt Learning for Vision-Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gahyeon Kim",
      "Sohee Kim",
      "Seokju Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Baldassini_What_Makes_Multimodal_In-Context_Learning_Work_CVPRW_2024_paper.html": {
    "title": "What Makes Multimodal In-Context Learning Work?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Folco Bertini Baldassini",
      "Mustafa Shukor",
      "Matthieu Cord",
      "Laure Soulier",
      "Benjamin Piwowarski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Zanella_Low-Rank_Few-Shot_Adaptation_of_Vision-Language_Models_CVPRW_2024_paper.html": {
    "title": "Low-Rank Few-Shot Adaptation of Vision-Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maxime Zanella",
      "Ismail Ben Ayed"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Das_Prompting_Foundational_Models_for_Omni-supervised_Instance_Segmentation_CVPRW_2024_paper.html": {
    "title": "Prompting Foundational Models for Omni-supervised Instance Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnav M. Das",
      "Ritwick Chaudhry",
      "Kaustav Kundu",
      "Davide Modolo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Chen_Conv-Adapter_Exploring_Parameter_Efficient_Transfer_Learning_for_ConvNets_CVPRW_2024_paper.html": {
    "title": "Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Chen",
      "Ran Tao",
      "Han Zhang",
      "Yidong Wang",
      "Xiang Li",
      "Wei Ye",
      "Jindong Wang",
      "Guosheng Hu",
      "Marios Savvides"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Ozdemir_Enhancing_Visual_Question_Answering_through_Question-Driven_Image_Captions_as_Prompts_CVPRW_2024_paper.html": {
    "title": "Enhancing Visual Question Answering through Question-Driven Image Captions as Prompts",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Övgü Özdemir",
      "Erdem Akagündüz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Quesada_PointPrompt_A_Multi-modal_Prompting_Dataset_for_Segment_Anything_Model_CVPRW_2024_paper.html": {
    "title": "PointPrompt: A Multi-modal Prompting Dataset for Segment Anything Model",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jorge Quesada",
      "Mohammad Alotaibi",
      "Mohit Prabhushankar",
      "Ghassan Alregib"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Rhobin/html/Azam_A_Survey_on_3D_Egocentric_Human_Pose_Estimation_CVPRW_2024_paper.html": {
    "title": "A Survey on 3D Egocentric Human Pose Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Mushfiqur Azam",
      "Kevin Desai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Rhobin/html/Levy_V-VIPE_Variational_View_Invariant_Pose_Embedding_CVPRW_2024_paper.html": {
    "title": "V-VIPE: Variational View Invariant Pose Embedding",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mara Levy",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Rhobin/html/Uguz_MoCap-to-Visual_Domain_Adaptation_for_Efficient_Human_Mesh_Estimation_from_2D_CVPRW_2024_paper.html": {
    "title": "MoCap-to-Visual Domain Adaptation for Efficient Human Mesh Estimation from 2D Keypoints",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bedirhan Uguz",
      "Ozhan Suat",
      "Batuhan Karagoz",
      "Emre Akbas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPR-NAS/html/An_CycleGANAS_Differentiable_Neural_Architecture_Search_for_CycleGAN_CVPRW_2024_paper.html": {
    "title": "CycleGANAS: Differentiable Neural Architecture Search for CycleGAN",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taegun An",
      "Changhee Joo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPR-NAS/html/Huang_UP-NAS_Unified_Proxy_for_Neural_Architecture_Search_CVPRW_2024_paper.html": {
    "title": "UP-NAS: Unified Proxy for Neural Architecture Search",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi-Cheng Huang",
      "Wei-Hua Li",
      "Chih-Han Tsou",
      "Jun-Cheng Chen",
      "Chu-Song Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPR-NAS/html/Zhang_CSCO_Connectivity_Search_of_Convolutional_Operators_CVPRW_2024_paper.html": {
    "title": "CSCO: Connectivity Search of Convolutional Operators",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tunhou Zhang",
      "Shiyu Li",
      "Hsin-Pai Cheng",
      "Feng Yan",
      "Hai Li",
      "Yiran Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPR-NAS/html/Subbotko_The_Devil_is_in_Discretization_Discrepancy._Robustifying_Differentiable_NAS_with_CVPRW_2024_paper.html": {
    "title": "The Devil is in Discretization Discrepancy. Robustifying Differentiable NAS with Single-Stage Searching Protocol",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konstanty Subbotko",
      "Wojciech Jablonski",
      "Piotr Bilinski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPR-NAS/html/Gao_QuantNAS_Quantization-aware_Neural_Architecture_Search_For_Efficient_Deployment_On_Mobile_CVPRW_2024_paper.html": {
    "title": "QuantNAS: Quantization-aware Neural Architecture Search For Efficient Deployment On Mobile Device",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianxiao Gao",
      "Li Guo",
      "Shanwei Zhao",
      "Peihan Xu",
      "Yukun Yang",
      "Xionghao Liu",
      "Shihao Wang",
      "Shiai Zhu",
      "Dajiang Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVPR-NAS/html/Casarin_GRASP-GCN_Graph-Shape_Prioritization_for_Neural_Architecture_Search_Under_Distribution_Shifts_CVPRW_2024_paper.html": {
    "title": "GRASP-GCN: Graph-Shape Prioritization for Neural Architecture Search Under Distribution Shifts",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sofia Casarin",
      "Oswald Lanz",
      "Sergio Escalera"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Madasu_ICSVR_Investigating_Compositional_and_Syntactic_Understanding_in_Video_Retrieval_Models_CVPRW_2024_paper.html": {
    "title": "ICSVR: Investigating Compositional and Syntactic Understanding in Video Retrieval Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Avinash Madasu",
      "Vasudev Lal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Kim_Show_Think_and_Tell_Thought-Augmented_Fine-Tuning_of_Large_Language_Models_CVPRW_2024_paper.html": {
    "title": "Show Think and Tell: Thought-Augmented Fine-Tuning of Large Language Models for Video Captioning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Byoungjip Kim",
      "Dasol Hwang",
      "Sungjun Cho",
      "Youngsoo Jang",
      "Honglak Lee",
      "Moontae Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Wang_LLM-Seg_Bridging_Image_Segmentation_and_Large_Language_Model_Reasoning_CVPRW_2024_paper.html": {
    "title": "LLM-Seg: Bridging Image Segmentation and Large Language Model Reasoning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junchi Wang",
      "Lei Ke"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Caffagni_Wiki-LLaVA_Hierarchical_Retrieval-Augmented_Generation_for_Multimodal_LLMs_CVPRW_2024_paper.html": {
    "title": "Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davide Caffagni",
      "Federico Cocchi",
      "Nicholas Moratelli",
      "Sara Sarto",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Schiappa_Probing_Conceptual_Understanding_of_Large_Visual-Language_Models_CVPRW_2024_paper.html": {
    "title": "Probing Conceptual Understanding of Large Visual-Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Madeline Schiappa",
      "Raiyaan Abdullah",
      "Shehreen Azad",
      "Jared Claypoole",
      "Michael Cogswell",
      "Ajay Divakaran",
      "Yogesh Rawat"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Li_Matting_Anything_CVPRW_2024_paper.html": {
    "title": "Matting Anything",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen Li",
      "Jitesh Jain",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Smith_Continual_Diffusion_with_STAMINA_STack-And-Mask_INcremental_Adapters_CVPRW_2024_paper.html": {
    "title": "Continual Diffusion with STAMINA: STack-And-Mask INcremental Adapters",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Seale Smith",
      "Yen-Chang Hsu",
      "Zsolt Kira",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Xu_Benchmarking_Zero-Shot_Recognition_with_Vision-Language_Models_Challenges_on_Granularity_and_CVPRW_2024_paper.html": {
    "title": "Benchmarking Zero-Shot Recognition with Vision-Language Models: Challenges on Granularity and Specificity",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenlin Xu",
      "Yi Zhu",
      "Siqi Deng",
      "Abhay Mittal",
      "Yanbei Chen",
      "Manchen Wang",
      "Paolo Favaro",
      "Joseph Tighe",
      "Davide Modolo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Zhang_Recognize_Anything_A_Strong_Image_Tagging_Model_CVPRW_2024_paper.html": {
    "title": "Recognize Anything: A Strong Image Tagging Model",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youcai Zhang",
      "Xinyu Huang",
      "Jinyu Ma",
      "Zhaoyang Li",
      "Zhaochuan Luo",
      "Yanchun Xie",
      "Yuzhuo Qin",
      "Tong Luo",
      "Yaqian Li",
      "Shilong Liu",
      "Yandong Guo",
      "Lei Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Wang_Towards_Efficient_Audio-Visual_Learners_via_Empowering_Pre-trained_Vision_Transformers_with_CVPRW_2024_paper.html": {
    "title": "Towards Efficient Audio-Visual Learners via Empowering Pre-trained Vision Transformers with Cross-Modal Adaptation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Wang",
      "Yapeng Tian",
      "Dimitrios Hatzinakos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Zhang_Forget-Me-Not_Learning_to_Forget_in_Text-to-Image_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gong Zhang",
      "Kai Wang",
      "Xingqian Xu",
      "Zhangyang Wang",
      "Humphrey Shi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Rai_Strategies_to_Leverage_Foundational_Model_Knowledge_in_Object_Affordance_Grounding_CVPRW_2024_paper.html": {
    "title": "Strategies to Leverage Foundational Model Knowledge in Object Affordance Grounding",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arushi Rai",
      "Kyle Buettner",
      "Adriana Kovashka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMFM/html/Schiappa_Robustness_Analysis_on_Foundational_Segmentation_Models_CVPRW_2024_paper.html": {
    "title": "Robustness Analysis on Foundational Segmentation Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Madeline Chantry Schiappa",
      "Shehreen Azad",
      "Sachidanand Vs",
      "Yunhao Ge",
      "Ondrej Miksik",
      "Yogesh S Rawat",
      "Vibhav Vineet"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PVUW/html/Meeran_SAM-PM_Enhancing_Video_Camouflaged_Object_Detection_using_Spatio-Temporal_Attention_CVPRW_2024_paper.html": {
    "title": "SAM-PM: Enhancing Video Camouflaged Object Detection using Spatio-Temporal Attention",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Nawfal Meeran",
      "Gokul Adethya T",
      "Bhanu Pratyush Mantha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PVUW/html/Qu_ChatVTG_Video_Temporal_Grounding_via_Chat_with_Video_Dialogue_Large_CVPRW_2024_paper.html": {
    "title": "ChatVTG: Video Temporal Grounding via Chat with Video Dialogue Large Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengxue Qu",
      "Xiaodong Chen",
      "Wu Liu",
      "Alicia Li",
      "Yao Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Mehta_Fake_It_to_Make_It_Using_Synthetic_Data_to_Remedy_CVPRW_2024_paper.html": {
    "title": "Fake It to Make It: Using Synthetic Data to Remedy the Data Shortage in Joint Multimodal Speech-and-Gesture Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivam Mehta",
      "Anna Deichler",
      "Jim O'regan",
      "Birger Moëll",
      "Jonas Beskow",
      "Gustav Eje Henter",
      "Simon Alexanderson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Bensabath_A_Cross-Dataset_Study_for_Text-based_3D_Human_Motion_Retrieval_CVPRW_2024_paper.html": {
    "title": "A Cross-Dataset Study for Text-based 3D Human Motion Retrieval",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Léore Bensabath",
      "Mathis Petrovich",
      "Gul Varol"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Bhattacharya_Speech2UnifiedExpressions_Synchronous_Synthesis_of_Co-Speech_Affective_Face_and_Body_Expressions_CVPRW_2024_paper.html": {
    "title": "Speech2UnifiedExpressions: Synchronous Synthesis of Co-Speech Affective Face and Body Expressions from Affordable Inputs",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Uttaran Bhattacharya",
      "Aniket Bera",
      "Dinesh Manocha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Ruiz-Ponce_in2IN_Leveraging_Individual_Information_to_Generate_Human_INteractions_CVPRW_2024_paper.html": {
    "title": "in2IN: Leveraging Individual Information to Generate Human INteractions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pablo Ruiz-Ponce",
      "German Barquero",
      "Cristina Palmero",
      "Sergio Escalera",
      "José García-Rodríguez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Lee_T2LM_Long-Term_3D_Human_Motion_Generation_from_Multiple_Sentences_CVPRW_2024_paper.html": {
    "title": "T2LM: Long-Term 3D Human Motion Generation from Multiple Sentences",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taeryung Lee",
      "Fabien Baradel",
      "Thomas Lucas",
      "Kyoung Mu Lee",
      "Grègory Rogez"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Petrovich_Multi-Track_Timeline_Control_for_Text-Driven_3D_Human_Motion_Generation_CVPRW_2024_paper.html": {
    "title": "Multi-Track Timeline Control for Text-Driven 3D Human Motion Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mathis Petrovich",
      "Or Litany",
      "Umar Iqbal",
      "Michael J. Black",
      "Gul Varol",
      "Xue Bin Peng",
      "Davis Rempe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Hogue_DiffTED_One-shot_Audio-driven_TED_Talk_Video_Generation_with_Diffusion-based_Co-speech_CVPRW_2024_paper.html": {
    "title": "DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Steven Hogue",
      "Chenxu Zhang",
      "Hamza Daruger",
      "Yapeng Tian",
      "Xiaohu Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Li_Two-Person_Interaction_Augmentation_with_Skeleton_Priors_CVPRW_2024_paper.html": {
    "title": "Two-Person Interaction Augmentation with Skeleton Priors",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baiyi Li",
      "Edmond S. L. Ho",
      "Hubert P. H. Shum",
      "He Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/HuMoGen/html/Sheng_Exploring_Text-to-Motion_Generation_with_Human_Preference_CVPRW_2024_paper.html": {
    "title": "Exploring Text-to-Motion Generation with Human Preference",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jenny Sheng",
      "Matthieu Lin",
      "Andrew Zhao",
      "Kevin Pruvost",
      "Yu-Hui Wen",
      "Yangguang Li",
      "Gao Huang",
      "Yong-Jin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Deria_InVERGe_Intelligent_Visual_Encoder_for_Bridging_Modalities_in_Report_Generation_CVPRW_2024_paper.html": {
    "title": "InVERGe: Intelligent Visual Encoder for Bridging Modalities in Report Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ankan Deria",
      "Komal Kumar",
      "Snehashis Chakraborty",
      "Dwarikanath Mahapatra",
      "Sudipta Roy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Deb_ZInD-Tell_Towards_Translating_Indoor_Panoramas_into_Descriptions_CVPRW_2024_paper.html": {
    "title": "ZInD-Tell: Towards Translating Indoor Panoramas into Descriptions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tonmoay Deb",
      "Lichen Wang",
      "Zachary Bessinger",
      "Naji Khosravan",
      "Eric Penner",
      "Sing Bing Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Hu_De-noised_Vision-language_Fusion_Guided_by_Visual_Cues_for_E-commerce_Product_CVPRW_2024_paper.html": {
    "title": "De-noised Vision-language Fusion Guided by Visual Cues for E-commerce Product Search",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhizhang Hu",
      "Shasha Li",
      "Ming Du",
      "Arnab Dhua",
      "Douglas Gray"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Lee_VMCML_Video_and_Music_Matching_via_Cross-Modality_Lifting_CVPRW_2024_paper.html": {
    "title": "VMCML: Video and Music Matching via Cross-Modality Lifting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi-Shan Lee",
      "Wei-Cheng Tseng",
      "Fu-En Wang",
      "Min Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Agrawal_Listen_Then_See_Video_Alignment_with_Speaker_Attention_CVPRW_2024_paper.html": {
    "title": "Listen Then See: Video Alignment with Speaker Attention",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aviral Agrawal",
      "Carlos Mateo Samudio Lezcano",
      "Iqui Balam Heredia-Marin",
      "Prabhdeep Singh Sethi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Devulapally_Multi-Modal_Fusion_of_Event_and_RGB_for_Monocular_Depth_Estimation_CVPRW_2024_paper.html": {
    "title": "Multi-Modal Fusion of Event and RGB for Monocular Depth Estimation Using a Unified Transformer-based Architecture",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anusha Devulapally",
      "Md Fahim Faysal Khan",
      "Siddharth Advani",
      "Vijaykrishnan Narayanan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Liu_LAformer_Trajectory_Prediction_for_Autonomous_Driving_with_Lane-Aware_Scene_Constraints_CVPRW_2024_paper.html": {
    "title": "LAformer: Trajectory Prediction for Autonomous Driving with Lane-Aware Scene Constraints",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengmeng Liu",
      "Hao Cheng",
      "Lin Chen",
      "Hellward Broszio",
      "Jiangtao Li",
      "Runjiang Zhao",
      "Monika Sester",
      "Michael Ying Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Ghadiya_Cross-Modal_Fusion_and_Attention_Mechanism_for_Weakly_Supervised_Video_Anomaly_CVPRW_2024_paper.html": {
    "title": "Cross-Modal Fusion and Attention Mechanism for Weakly Supervised Video Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayush Ghadiya",
      "Purbayan Kar",
      "Vishal Chudasama",
      "Pankaj Wasnik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Shen_Exploring_the_Role_of_Audio_in_Video_Captioning_CVPRW_2024_paper.html": {
    "title": "Exploring the Role of Audio in Video Captioning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhan Shen",
      "Linjie Yang",
      "Longyin Wen",
      "Haichao Yu",
      "Ehsan Elhamifar",
      "Heng Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Rawal_AIGeN_An_Adversarial_Approach_for_Instruction_Generation_in_VLN_CVPRW_2024_paper.html": {
    "title": "AIGeN: An Adversarial Approach for Instruction Generation in VLN",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niyati Rawal",
      "Roberto Bigazzi",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Zhong_Multimodal_Understanding_of_Memes_with_Fair_Explanations_CVPRW_2024_paper.html": {
    "title": "Multimodal Understanding of Memes with Fair Explanations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Zhong",
      "Bhiman Kumar Baghel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Piekenbrinck_RGB-D_Cube_R-CNN_3D_Object_Detection_with_Selective_Modality_Dropout_CVPRW_2024_paper.html": {
    "title": "RGB-D Cube R-CNN: 3D Object Detection with Selective Modality Dropout",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jens Piekenbrinck",
      "Alexander Hermans",
      "Narunas Vaskevicius",
      "Timm Linder",
      "Bastian Leibe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Ibn_Abdul_Hakim_Leveraging_Generative_Language_Models_for_Weakly_Supervised_Sentence_Component_Analysis_CVPRW_2024_paper.html": {
    "title": "Leveraging Generative Language Models for Weakly Supervised Sentence Component Analysis in Video-Language Joint Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zaber Ibn Abdul Hakim",
      "Najibul Haque Sarker",
      "Rahul Pratap Singh",
      "Bishmoy Paul",
      "Ali Dabouei",
      "Min Xu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Jha_RAVN_Reinforcement_Aided_Adaptive_Vector_Quantization_of_Deep_Neural_Networks_CVPRW_2024_paper.html": {
    "title": "RAVN: Reinforcement Aided Adaptive Vector Quantization of Deep Neural Networks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anamika Jha",
      "Aratrik Chattopadhyay",
      "Mrinal Banerji",
      "Disha Jain"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Dampfhoffer_Neuromorphic_Lip-Reading_with_Signed_Spiking_Gated_Recurrent_Units_CVPRW_2024_paper.html": {
    "title": "Neuromorphic Lip-Reading with Signed Spiking Gated Recurrent Units",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manon Dampfhoffer",
      "Thomas Mesquida"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Lin_SciFlow_Empowering_Lightweight_Optical_Flow_Models_with_Self-Cleaning_Iterations_CVPRW_2024_paper.html": {
    "title": "SciFlow: Empowering Lightweight Optical Flow Models with Self-Cleaning Iterations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jamie Menjay Lin",
      "Jisoo Jeong",
      "Hong Cai",
      "Risheek Garrepalli",
      "Kai Wang",
      "Fatih Porikli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Paissan_Structured_Sparse_Back-propagation_for_Lightweight_On-Device_Continual_Learning_on_Microcontroller_CVPRW_2024_paper.html": {
    "title": "Structured Sparse Back-propagation for Lightweight On-Device Continual Learning on Microcontroller Units",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Paissan",
      "Davide Nadalini",
      "Manuele Rusci",
      "Alberto Ancilotto",
      "Francesco Conti",
      "Luca Benini",
      "Elisabetta Farella"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Ramon_ED-DCFNet_An_Unsupervised_Encoder-decoder_Neural_Model_for_Event-driven_Feature_Extraction_CVPRW_2024_paper.html": {
    "title": "ED-DCFNet: An Unsupervised Encoder-decoder Neural Model for Event-driven Feature Extraction and Object Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raz Ramon",
      "Hadar Cohen-Duwek",
      "Elishai Ezra Tsur"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Bompani_Multi-resolution_Rescored_ByteTrack_for_Video_Object_Detection_on_Ultra-low-power_Embedded_CVPRW_2024_paper.html": {
    "title": "Multi-resolution Rescored ByteTrack for Video Object Detection on Ultra-low-power Embedded Systems",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Bompani",
      "Manuele Rusci",
      "Daniele Palossi",
      "Francesco Conti",
      "Luca Benini"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Padeiro_Lightweight_Maize_Disease_Detection_through_Post-Training_Quantization_with_Similarity_Preservation_CVPRW_2024_paper.html": {
    "title": "Lightweight Maize Disease Detection through Post-Training Quantization with Similarity Preservation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carlos Victorino Padeiro",
      "Tse-Wei Chen",
      "Takahiro Komamizu",
      "Ichiro Ide"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Chen_Dedicated_Inference_Engine_and_Binary-Weight_Neural_Networks_for_Lightweight_Instance_CVPRW_2024_paper.html": {
    "title": "Dedicated Inference Engine and Binary-Weight Neural Networks for Lightweight Instance Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tse-Wei Chen",
      "Wei Tao",
      "Dongyue Zhao",
      "Kazuhiro Mima",
      "Tadayuki Ito",
      "Kinya Osa",
      "Masami Kato"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Prabhune_Content-aware_Input_Scaling_and_Deep_Learning_Computation_Offloading_for_Low-Latency_CVPRW_2024_paper.html": {
    "title": "Content-aware Input Scaling and Deep Learning Computation Offloading for Low-Latency Embedded Vision",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Omkar Prabhune",
      "Tianen Chen",
      "Younghyun Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Cigla_Efficient_Video_Stabilization_via_Partial_Block_Phase_Correlation_on_Edge_CVPRW_2024_paper.html": {
    "title": "Efficient Video Stabilization via Partial Block Phase Correlation on Edge GPUs",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cevahir Çığla"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Leroux_Multi-bit_Black-box_Watermarking_of_Deep_Neural_Networks_in_Embedded_Applications_CVPRW_2024_paper.html": {
    "title": "Multi-bit Black-box Watermarking of Deep Neural Networks in Embedded Applications",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sam Leroux",
      "Stijn Vanassche",
      "Pieter Simoens"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Frickenstein_Pruning_as_a_Binarization_Technique_CVPRW_2024_paper.html": {
    "title": "Pruning as a Binarization Technique",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Frickenstein",
      "Pierpaolo Mori",
      "Shambhavi Balamuthu Sampath",
      "Moritz Thoma",
      "Nael Fasfous",
      "Manoj Rohit Vemparala",
      "Alexander Frickenstein",
      "Christian Unger",
      "Claudio Passerone",
      "Walter Stechele"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EVW/html/Agarwal_Prune_Efficiently_by_Soft_Pruning_CVPRW_2024_paper.html": {
    "title": "Prune Efficiently by Soft Pruning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Parakh Agarwal",
      "Manu Mathew",
      "Kunal Ranjan Patel",
      "Varun Tripathi",
      "Pramod Swami"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAR/html/Maidment_Using_Language-Aligned_Gesture_Embeddings_for_Understanding_Gestures_Accompanying_Math_Terms_CVPRW_2024_paper.html": {
    "title": "Using Language-Aligned Gesture Embeddings for Understanding Gestures Accompanying Math Terms",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tristan Maidment",
      "Purav J Patel",
      "Erin Walker",
      "Adriana Kovashka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAR/html/Ma_Task_Navigator_Decomposing_Complex_Tasks_for_Multimodal_Large_Language_Models_CVPRW_2024_paper.html": {
    "title": "Task Navigator: Decomposing Complex Tasks for Multimodal Large Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feipeng Ma",
      "Yizhou Zhou",
      "Yueyi Zhang",
      "Siying Wu",
      "Zheyu Zhang",
      "Zilong He",
      "Fengyun Rao",
      "Xiaoyan Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAR/html/Cuttano_What_Does_CLIP_Know_About_Peeling_a_Banana_CVPRW_2024_paper.html": {
    "title": "What Does CLIP Know About Peeling a Banana?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Claudia Cuttano",
      "Gabriele Rosi",
      "Gabriele Trivigno",
      "Giuseppe Averta"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAR/html/Zafar_Multi-Explainable_TemporalNet_An_Interpretable_Multimodal_Approach_using_Temporal_Convolutional_Network_CVPRW_2024_paper.html": {
    "title": "Multi-Explainable TemporalNet: An Interpretable Multimodal Approach using Temporal Convolutional Network for User-level Depression Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anas Zafar",
      "Danyal Aftab",
      "Rizwan Qureshi",
      "Yaofeng Wang",
      "Hong Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAR/html/Arefeen_ViTA_An_Efficient_Video-to-Text_Algorithm__using_VLM_for_RAG-based_CVPRW_2024_paper.html": {
    "title": "ViTA: An Efficient Video-to-Text Algorithm using VLM for RAG-based Video Analysis System",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Adnan Arefeen",
      "Biplob Debnath",
      "Md Yusuf Sarwar Uddin",
      "Srimat Chakradhar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Kolbinger_Strategies_to_Improve_Real-World_Applicability_of_Laparoscopic_Anatomy_Segmentation_Models_CVPRW_2024_paper.html": {
    "title": "Strategies to Improve Real-World Applicability of Laparoscopic Anatomy Segmentation Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fiona R. Kolbinger",
      "Jiangpeng He",
      "Jinge Ma",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Reddy_Advancing_Brain_Tumor_Analysis_Curating_a_High-Quality_MRI_Dataset_for_CVPRW_2024_paper.html": {
    "title": "Advancing Brain Tumor Analysis: Curating a High-Quality MRI Dataset for Deep Learning-Based Molecular Marker Profiling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divya D. Reddy",
      "Niloufar Saadat",
      "James M. Holcomb",
      "Benjamin C. Wagner",
      "Nghi C. Truong",
      "Jason Bowerman",
      "Kimmo J. Hatanpaa",
      "Toral R Patel",
      "Marco C. Pinho",
      "Ananth J Madhuranthakam",
      "Chandan Ganesh Bangalore Yogananda",
      "Joseph A. Maldjian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Sharma_ControlPolypNet_Towards_Controlled_Colon_Polyp_Synthesis_for_Improved_Polyp_Segmentation_CVPRW_2024_paper.html": {
    "title": "ControlPolypNet: Towards Controlled Colon Polyp Synthesis for Improved Polyp Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vanshali Sharma",
      "Abhishek Kumar",
      "Debesh Jha",
      "M.K. Bhuyan",
      "Pradip K. Das",
      "Ulas Bagci"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Go_Generation_of_Structurally_Realistic_Retinal_Fundus_Images_with_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "Generation of Structurally Realistic Retinal Fundus Images with Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sojung Go",
      "Younghoon Ji",
      "Sang Jun Park",
      "Soochahn Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Ihler_Distribution-Aware_Multi-Label_FixMatch_for_Semi-Supervised_Learning_on_CheXpert._CVPRW_2024_paper.html": {
    "title": "Distribution-Aware Multi-Label FixMatch for Semi-Supervised Learning on CheXpert",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sontje Ihler",
      "Felix Kuhnke",
      "Timo Kuhlgatz",
      "Thomas Seel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Hasan_A_Comparative_Analysis_of_Implicit_Augmentation_Techniques_for_Breast_Cancer_CVPRW_2024_paper.html": {
    "title": "A Comparative Analysis of Implicit Augmentation Techniques for Breast Cancer Diagnosis Using Multiple Views",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yumnah Hasan",
      "Talhat Khan",
      "Darian Reyes Fernandez De Bulnes",
      "Juan F H Albarracin",
      "Conor Ryan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Lecomte_Beyond_Respiratory_Models_A_Physics-enhanced_Synthetic_Data_Generation_Method_for_CVPRW_2024_paper.html": {
    "title": "Beyond Respiratory Models: A Physics-enhanced Synthetic Data Generation Method for 2D-3D Deformable Registration",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "François Lecomte",
      "Pablo Alvarez",
      "Stéphane Cotin",
      "Jean-Louis Dillenseger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Fischer_Hairy_Ground_Truth_Enhancement_for_Semantic_Segmentation_CVPRW_2024_paper.html": {
    "title": "Hairy Ground Truth Enhancement for Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sophie Fischer",
      "Irina Voiculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Corona-Figueroa_Repeat_and_Concatenate_2D_to_3D_Image_Translation_with_3D_CVPRW_2024_paper.html": {
    "title": "Repeat and Concatenate: 2D to 3D Image Translation with 3D to 3D Generative Modeling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abril Corona-Figueroa",
      "Hubert P. H. Shum",
      "Chris G. Willcocks"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Ramakers_UltraAugment_Fan-shape_and_Artifact-based_Data_Augmentation_for_2D_Ultrasound_Images_CVPRW_2024_paper.html": {
    "title": "UltraAugment: Fan-shape and Artifact-based Data Augmentation for 2D Ultrasound Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Ramakers",
      "Tom Vercauteren",
      "Jan Deprest",
      "Helena Williams"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Soberanis-Mukul_GSAMCutie_Text-Promptable_Tool_Mask_Annotation_for_Endoscopic_Video_CVPRW_2024_paper.html": {
    "title": "GSAM+Cutie: Text-Promptable Tool Mask Annotation for Endoscopic Video",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roger D. Soberanis-Mukul",
      "Jiahuan Cheng",
      "Jan Emily Mangulabnan",
      "S. Swaroop Vedula",
      "Masaru Ishii",
      "Gregory Hager",
      "Russell H. Taylor",
      "Mathias Unberath"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Kanhere_Privacy-Preserving_Collaboration_for_Multi-Organ_Segmentation_via_Federated_Learning_from_Sites_CVPRW_2024_paper.html": {
    "title": "Privacy-Preserving Collaboration for Multi-Organ Segmentation via Federated Learning from Sites with Partial Labels",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adway Kanhere",
      "Pranav Kulkarni",
      "Paul H. Yi",
      "Vishwa S. Parekh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Redekop_Codebook_VQ-VAE_Approach_for_Prostate_Cancer_Diagnosis_using_Multiparametric_MRI_CVPRW_2024_paper.html": {
    "title": "Codebook VQ-VAE Approach for Prostate Cancer Diagnosis using Multiparametric MRI",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ekaterina Redekop",
      "Mara Pleasure",
      "Zichen Wang",
      "Karthik V Sarma",
      "Adam Kinnaird",
      "William Speier",
      "Corey W Arnold"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Zhu_nnMobileNet_Rethinking_CNN_for_Retinopathy_Research_CVPRW_2024_paper.html": {
    "title": "nnMobileNet: Rethinking CNN for Retinopathy Research",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenhui Zhu",
      "Peijie Qiu",
      "Xiwen Chen",
      "Xin Li",
      "Natasha Lepore",
      "Oana M. Dumitrascu",
      "Yalin Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Poles_Repurposing_the_Image_Generative_Potential_Exploiting_GANs_to_Grade_Diabetic_CVPRW_2024_paper.html": {
    "title": "Repurposing the Image Generative Potential: Exploiting GANs to Grade Diabetic Retinopathy",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Isabella Poles",
      "Eleonora D'arnese",
      "Luca G. Cellamare",
      "Marco D. Santambrogio",
      "Darvin Yi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Mota_MMIST-ccRCC_A_Real_World_Medical_Dataset_for_the_Development_of_CVPRW_2024_paper.html": {
    "title": "MMIST-ccRCC: A Real World Medical Dataset for the Development of Multi-Modal Systems",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiago Mota",
      "M. Rita Verdelho",
      "Diogo J. Araújo",
      "Alceu Bissoto",
      "Carlos Santiago",
      "Catarina Barata"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DCAMI/html/Hein_Creating_a_Digital_Twin_of_Spinal_Surgery_A_Proof_of_CVPRW_2024_paper.html": {
    "title": "Creating a Digital Twin of Spinal Surgery: A Proof of Concept",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas Hein",
      "Frédéric Giraud",
      "Lilian Calvet",
      "Alexander Schwarz",
      "Nicola Alessandro Cavalcanti",
      "Sergey Prokudin",
      "Mazda Farshad",
      "Siyu Tang",
      "Marc Pollefeys",
      "Fabio Carrillo",
      "Philipp Fürnstahl"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WiCV/html/Huang_Unsupervised_Domain_Adaptation_for_Weed_Segmentation_Using_Greedy_Pseudo-labelling_CVPRW_2024_paper.html": {
    "title": "Unsupervised Domain Adaptation for Weed Segmentation Using Greedy Pseudo-labelling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingchao Huang",
      "Abdul Bais"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WiCV/html/Tarres_PARASOL_Parametric_Style_Control_for_Diffusion_Image_Synthesis_CVPRW_2024_paper.html": {
    "title": "PARASOL: Parametric Style Control for Diffusion Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gemma Canet Tarrés",
      "Dan Ruta",
      "Tu Bui",
      "John Collomosse"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WiCV/html/Wanyan_Extending_Global-local_View_Alignment_for_Self-supervised_Learning_with_Remote_Sensing_CVPRW_2024_paper.html": {
    "title": "Extending Global-local View Alignment for Self-supervised Learning with Remote Sensing Imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinye Wanyan",
      "Sachith Seneviratne",
      "Shuchang Shen",
      "Michael Kirley"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WiCV/html/Wani_ABC-CapsNet_Attention_based_Cascaded_Capsule_Network_for_Audio_Deepfake_Detection_CVPRW_2024_paper.html": {
    "title": "ABC-CapsNet: Attention based Cascaded Capsule Network for Audio Deepfake Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taiba Majid Wani",
      "Reeva Gulzar",
      "Irene Amerini"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WiCV/html/Garg_GestFormer_Multiscale_Wavelet_Pooling_Transformer_Network_for_Dynamic_Hand_Gesture_CVPRW_2024_paper.html": {
    "title": "GestFormer: Multiscale Wavelet Pooling Transformer Network for Dynamic Hand Gesture Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mallika Garg",
      "Debashis Ghosh",
      "Pyari Mohan Pradhan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WiCV/html/Mehmood_RetinaLiteNet_A_Lightweight_Transformer_based_CNN_for_Retinal_Feature_Segmentation_CVPRW_2024_paper.html": {
    "title": "RetinaLiteNet: A Lightweight Transformer based CNN for Retinal Feature Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehwish Mehmood",
      "Majed Alsharari",
      "Shahzaib Iqbal",
      "Ivor Spence",
      "Muhammad Fahim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SyntaGen/html/Singh_Is_Synthetic_Data_all_We_Need_Benchmarking_the_Robustness_of_CVPRW_2024_paper.html": {
    "title": "Is Synthetic Data all We Need? Benchmarking the Robustness of Models Trained with Synthetic Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Krishnakant Singh",
      "Thanush Navaratnam",
      "Jannik Holmer",
      "Simone Schaub-Meyer",
      "Stefan Roth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SyntaGen/html/Khandelwal_RePoseDM_Recurrent_Pose_Alignment_and_Gradient_Guidance_for_Pose_Guided_CVPRW_2024_paper.html": {
    "title": "RePoseDM: Recurrent Pose Alignment and Gradient Guidance for Pose Guided Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anant Khandelwal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/html/Hetang_Segment_Anything_Model_for_Road_Network_Graph_Extraction_CVPRW_2024_paper.html": {
    "title": "Segment Anything Model for Road Network Graph Extraction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Congrui Hetang",
      "Haoru Xue",
      "Cindy Le",
      "Tianwei Yue",
      "Wenping Wang",
      "Yihui He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/html/Khandelwal_FloCoDe_Unbiased_Dynamic_Scene_Graph_Generation_with_Temporal_Consistency_and_CVPRW_2024_paper.html": {
    "title": "FloCoDe: Unbiased Dynamic Scene Graph Generation with Temporal Consistency and Correlation Debiasing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anant Khandelwal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/html/Chaves_VideoSAGE_Video_Summarization_with_Graph_Representation_Learning_CVPRW_2024_paper.html": {
    "title": "VideoSAGE: Video Summarization with Graph Representation Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jose M. Rojas Chaves",
      "Subarna Tripathi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/html/Zhang_EgoSG_Learning_3D_Scene_Graphs_from_Egocentric_RGB-D_Sequences_CVPRW_2024_paper.html": {
    "title": "EgoSG: Learning 3D Scene Graphs from Egocentric RGB-D Sequences",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoyi Zhang",
      "Xitong Yang",
      "Ji Hou",
      "Kris Kitani",
      "Weidong Cai",
      "Fu-Jen Chu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/html/Lorenz_A_Review_and_Efficient_Implementation_of_Scene_Graph_Generation_Metrics_CVPRW_2024_paper.html": {
    "title": "A Review and Efficient Implementation of Scene Graph Generation Metrics",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julian Lorenz",
      "Robin Schön",
      "Katja Ludwig",
      "Rainer Lienhart"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/html/Cheng_Efflex_Efficient_and_Flexible_Pipeline_for_Spatio-Temporal_Trajectory_Graph_Modeling_CVPRW_2024_paper.html": {
    "title": "Efflex: Efficient and Flexible Pipeline for Spatio-Temporal Trajectory Graph Modeling and Representation Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ming Cheng",
      "Ziyi Zhou",
      "Bowen Zhang",
      "Ziyu Wang",
      "Jiaqi Gan",
      "Ziang Ren",
      "Weiqi Feng",
      "Yi Lyu",
      "Hefan Zhang",
      "Xingjian Diao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Kalluri_Open-world_Instance_Segmentation_Top-down_Learning_with_Bottom-up_Supervision_CVPRW_2024_paper.html": {
    "title": "Open-world Instance Segmentation: Top-down Learning with Bottom-up Supervision",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarun Kalluri",
      "Weiyao Wang",
      "Heng Wang",
      "Manmohan Chandraker",
      "Lorenzo Torresani",
      "Du Tran"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Raine_Human-in-the-Loop_Segmentation_of_Multi-species_Coral_Imagery__CVPRW_2024_paper.html": {
    "title": "Human-in-the-Loop Segmentation of Multi-species Coral Imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Scarlett Raine",
      "Ross Marchant",
      "Brano Kusy",
      "Frederic Maire",
      "Niko Sunderhauf",
      "Tobias Fischer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Immanuel_Learnable_Prompt_for_Few-Shot_Semantic_Segmentation_in_Remote_Sensing_Domain_CVPRW_2024_paper.html": {
    "title": "Learnable Prompt for Few-Shot Semantic Segmentation in Remote Sensing Domain",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Steve Andreas Immanuel",
      "Hagai Raja Sinulingga"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Huang_Zero-Shot_Monocular_Motion_Segmentation_in_the_Wild_by_Combining_Deep_CVPRW_2024_paper.html": {
    "title": "Zero-Shot Monocular Motion Segmentation in the Wild by Combining Deep Learning with Geometric Motion Model Fusion",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxiang Huang",
      "Yuhao Chen",
      "John Zelek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Hu_Weakly-Supervised_Temporal_Action_Localization_with_Multi-Modal_Plateau_Transformers_CVPRW_2024_paper.html": {
    "title": "Weakly-Supervised Temporal Action Localization with Multi-Modal Plateau Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Hu",
      "Kai Li",
      "Deep Patel",
      "Erik Kruus",
      "Martin Renqiang Min",
      "Zhengming Ding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Huang_UVIS_Unsupervised_Video_Instance_Segmentation_CVPRW_2024_paper.html": {
    "title": "UVIS: Unsupervised Video Instance Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuaiyi Huang",
      "Saksham Suri",
      "Kamal Gupta",
      "Sai Saketh Rambhatla",
      "Ser-Nam Lim",
      "Abhinav Shrivastava"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Guirguis_Uncertainty-based_Forgetting_Mitigation_for_Generalized_Few-Shot_Object_Detection_CVPRW_2024_paper.html": {
    "title": "Uncertainty-based Forgetting Mitigation for Generalized Few-Shot Object Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karim Guirguis",
      "George Eskandar",
      "Mingyang Wang",
      "Matthias Kayser",
      "Eduardo Monari",
      "Bin Yang",
      "Jürgen Beyerer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Menta_Active_Transferability_Estimation_CVPRW_2024_paper.html": {
    "title": "Active Transferability Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarun Ram Menta",
      "Surgan Jandial",
      "Akash Patil",
      "Saketh Bachu",
      "Vimal K.B",
      "Balaji Krishnamurthy",
      "Vineeth N. Balasubramanian",
      "Mausoom Sarkar",
      "Chirag Agarwal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Li_Generalized_Few-Shot_Meets_Remote_Sensing_Discovering_Novel_Classes_in_Land_CVPRW_2024_paper.html": {
    "title": "Generalized Few-Shot Meets Remote Sensing: Discovering Novel Classes in Land Cover Mapping via Hybrid Semantic Segmentation Framework",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuohong Li",
      "Fangxiao Lu",
      "Jiaqi Zou",
      "Lei Hu",
      "Hongyan Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Lemkhenter_SemiGPC_Distribution-Aware_Label_Refinement_for_Imbalanced_Semi-Supervised_Learning_Using_Gaussian_CVPRW_2024_paper.html": {
    "title": "SemiGPC: Distribution-Aware Label Refinement for Imbalanced Semi-Supervised Learning Using Gaussian Processes",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdelhak Lemkhenter",
      "Manchen Wang",
      "Luca Zancato",
      "Gurumurthy Swaminathan",
      "Paolo Favaro",
      "Davide Modolo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Gao_Enrich_Distill_and_Fuse_Generalized_Few-Shot_Semantic_Segmentation_in_Remote_CVPRW_2024_paper.html": {
    "title": "Enrich Distill and Fuse: Generalized Few-Shot Semantic Segmentation in Remote Sensing Leveraging Foundation Model's Assistance",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tianyi Gao",
      "Wei Ao",
      "Xing-Ao Wang",
      "Yuanhao Zhao",
      "Ping Ma",
      "Mengjie Xie",
      "Hang Fu",
      "Jinchang Ren",
      "Zhi Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Tong_Dynamic_Knowledge_Adapter_with_Probabilistic_Calibration_for_Generalized_Few-Shot_Semantic_CVPRW_2024_paper.html": {
    "title": "Dynamic Knowledge Adapter with Probabilistic Calibration for Generalized Few-Shot Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jintao Tong",
      "Haichen Zhou",
      "Yicong Liu",
      "Yiman Hu",
      "Yixiong Zou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Nebbia_Image-caption_Difficulty_for_Efficient_Weakly-supervised_Object_Detection_from_In-the-wild_Data_CVPRW_2024_paper.html": {
    "title": "Image-caption Difficulty for Efficient Weakly-supervised Object Detection from In-the-wild Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giacomo Nebbia",
      "Adriana Kovashka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Pan_MoDA_Leveraging_Motion_Priors_from_Videos_for_Advancing_Unsupervised_Domain_CVPRW_2024_paper.html": {
    "title": "MoDA: Leveraging Motion Priors from Videos for Advancing Unsupervised Domain Adaptation in Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Pan",
      "Xu Yin",
      "Seokju Lee",
      "Axi Niu",
      "Sungeui Yoon",
      "In So Kweon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Huang_What_is_Point_Supervision_Worth_in_Video_Instance_Segmentation_CVPRW_2024_paper.html": {
    "title": "What is Point Supervision Worth in Video Instance Segmentation?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuaiyi Huang",
      "De-An Huang",
      "Zhiding Yu",
      "Shiyi Lan",
      "Subhashree Radhakrishnan",
      "Jose M. Alvarez",
      "Abhinav Shrivastava",
      "Anima Anandkumar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Han_Latent-based_Diffusion_Model_for_Long-tailed_Recognition_CVPRW_2024_paper.html": {
    "title": "Latent-based Diffusion Model for Long-tailed Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengxiao Han",
      "Changkun Ye",
      "Jieming Zhou",
      "Jing Zhang",
      "Jie Hong",
      "Xuesong Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Wu_Learning_Tracking_Representations_from_Single_Point_Annotations_CVPRW_2024_paper.html": {
    "title": "Learning Tracking Representations from Single Point Annotations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiangqiang Wu",
      "Antoni B. Chan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Myers_On_Accuracy_and_Speed_of_Geodesic_Regression_Do_Geometric_Priors_CVPRW_2024_paper.html": {
    "title": "On Accuracy and Speed of Geodesic Regression: Do Geometric Priors Improve Learning on Small Datasets?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adele Myers",
      "Nina Miolane"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Rongali_CDAD-Net_Bridging_Domain_Gaps_in_Generalized_Category_Discovery_CVPRW_2024_paper.html": {
    "title": "CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Bhargav Rongali",
      "Sarthak Mehrotra",
      "Ankit Jha",
      "Mohamad Hassan N C",
      "Shirsha Bose",
      "Tanisha Gupta",
      "Mainak Singha",
      "Biplab Banerjee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/html/Kurzendorfer_Audio-Visual_Generalized_Zero-Shot_Learning_using_Pre-Trained_Large_Multi-Modal_Models_CVPRW_2024_paper.html": {
    "title": "Audio-Visual Generalized Zero-Shot Learning using Pre-Trained Large Multi-Modal Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Kurzendörfer",
      "Otniel-Bogdan Mercea",
      "A. Sophia Koepke",
      "Zeynep Akata"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/L3DIVU/html/Wang_Class_Similarity_Transition_Decoupling_Class_Similarities_and_Imbalance_from_Generalized_CVPRW_2024_paper.html": {
    "title": "Class Similarity Transition: Decoupling Class Similarities and Imbalance from Generalized Few-shot Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shihong Wang",
      "Ruixun Liu",
      "Kaiyu Li",
      "Jiawei Jiang",
      "Xiangyong Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Chen_Recon3D_High_Quality_3D_Reconstruction_from_a_Single_Image_Using_CVPRW_2024_paper.html": {
    "title": "Recon3D: High Quality 3D Reconstruction from a Single Image Using Generated Back-View Explicit Priors",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruiyang Chen",
      "Mohan Yin",
      "Jiawei Shen",
      "Wei Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Kouros_Unveiling_the_Ambiguity_in_Neural_Inverse_Rendering_A_Parameter_Compensation_CVPRW_2024_paper.html": {
    "title": "Unveiling the Ambiguity in Neural Inverse Rendering: A Parameter Compensation Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georgios Kouros",
      "Minye Wu",
      "Sushruth Nagesh",
      "Xianling Zhang",
      "Tinne Tuytelaars"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Kung_SAD-GS_Shape-aligned_Depth-supervised_Gaussian_Splatting_CVPRW_2024_paper.html": {
    "title": "SAD-GS: Shape-aligned Depth-supervised Gaussian Splatting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pou-Chun Kung",
      "Seth Isaacson",
      "Ram Vasudevan",
      "Katherine A. Skinner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Campbell_Neural_Fields_for_Co-Reconstructing_3D_Objects_from_Incidental_2D_Data_CVPRW_2024_paper.html": {
    "title": "Neural Fields for Co-Reconstructing 3D Objects from Incidental 2D Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dylan Campbell",
      "Eldar Insafutdinov",
      "Joao F. Henriques",
      "Andrea Vedaldi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Cong_NeRF_as_Pretraining_at_Scale_Generalizable_3D-Aware_Semantic_Representation_Learning_CVPRW_2024_paper.html": {
    "title": "NeRF as Pretraining at Scale: Generalizable 3D-Aware Semantic Representation Learning from View Prediction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyan Cong",
      "Hanxue Liang",
      "Zhiwen Fan",
      "Peihao Wang",
      "Yifan Jiang",
      "Dejia Xu",
      "A. Cengiz Oztireli",
      "Zhangyang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Radl_Analyzing_the_Internals_of_Neural_Radiance_Fields_CVPRW_2024_paper.html": {
    "title": "Analyzing the Internals of Neural Radiance Fields",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukas Radl",
      "Andreas Kurz",
      "Michael Steiner",
      "Markus Steinberger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Dey_GHNeRF_Learning_Generalizable_Human_Features_with_Efficient_Neural_Radiance_Fields_CVPRW_2024_paper.html": {
    "title": "GHNeRF: Learning Generalizable Human Features with Efficient Neural Radiance Fields",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnab Dey",
      "Di Yang",
      "Rohith Agaram",
      "Antitza Dantcheva",
      "Andrew I. Comport",
      "Srinath Sridhar",
      "Jean Martinet"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Cartillier_SLAIM_Robust_Dense_Neural_SLAM_for_Online_Tracking_and_Mapping_CVPRW_2024_paper.html": {
    "title": "SLAIM: Robust Dense Neural SLAM for Online Tracking and Mapping",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Cartillier",
      "Grant Schindler",
      "Irfan Essa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Dey_CoLa-SDF_Controllable_Latent_StyleSDF_for_Disentangled_3D_Face_Generation_CVPRW_2024_paper.html": {
    "title": "CoLa-SDF: Controllable Latent StyleSDF for Disentangled 3D Face Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rahul Dey",
      "Bernhard Egger",
      "Vishnu Naresh Boddeti",
      "Ye Wang",
      "Tim K. Marks"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NRI/html/Selvaratnam_Localised-NeRF_Specular_Highlights_and_Colour_Gradient_Localising_in_NeRF_CVPRW_2024_paper.html": {
    "title": "Localised-NeRF: Specular Highlights and Colour Gradient Localising in NeRF",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dharmendra Selvaratnam",
      "Dena Bazazian"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Hong_Learning_to_Schedule_Resistant_to_Adversarial_Attacks_in_Diffusion_Probabilistic_CVPRW_2024_paper.html": {
    "title": "Learning to Schedule Resistant to Adversarial Attacks in Diffusion Probabilistic Models Under the Threat of Lipschitz Singularities",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanghwa Hong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Wang_Enhancing_Targeted_Attack_Transferability_via_Diversified_Weight_Pruning_CVPRW_2024_paper.html": {
    "title": "Enhancing Targeted Attack Transferability via Diversified Weight Pruning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hung-Jui Wang",
      "Yu-Yu Wu",
      "Shang-Tse Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Mumcu_Multimodal_Attack_Detection_for_Action_Recognition_Models_CVPRW_2024_paper.html": {
    "title": "Multimodal Attack Detection for Action Recognition Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Furkan Mumcu",
      "Yasin Yilmaz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Chen_Large_Language_Models_in_Wargaming_Methodology_Application_and_Robustness_CVPRW_2024_paper.html": {
    "title": "Large Language Models in Wargaming: Methodology Application and Robustness",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuwei Chen",
      "Shiyong Chu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Ye_Sharpness-Aware_Optimization_for_Real-World_Adversarial_Attacks_for_Diverse_Compute_Platforms_CVPRW_2024_paper.html": {
    "title": "Sharpness-Aware Optimization for Real-World Adversarial Attacks for Diverse Compute Platforms with Enhanced Transferability",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muchao Ye",
      "Xiang Xu",
      "Qin Zhang",
      "Jonathan Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Wang_Benchmarking_Robustness_in_Neural_Radiance_Fields_CVPRW_2024_paper.html": {
    "title": "Benchmarking Robustness in Neural Radiance Fields",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Wang",
      "Angtian Wang",
      "Junbo Li",
      "Alan Yuille",
      "Cihang Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Zhang_Enhancing_the_Transferability_of_Adversarial_Attacks_with_Stealth_Preservation_CVPRW_2024_paper.html": {
    "title": "Enhancing the Transferability of Adversarial Attacks with Stealth Preservation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinwei Zhang",
      "Tianyuan Zhang",
      "Yitong Zhang",
      "Shuangcheng Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Jankowski_Red-Teaming_Segment_Anything_Model_CVPRW_2024_paper.html": {
    "title": "Red-Teaming Segment Anything Model",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Krzysztof Jankowski",
      "Bartlomiej Sobieski",
      "Mateusz Kwiatkowski",
      "Jakub Szulc",
      "Michał Janik",
      "Hubert Baniecki",
      "Przemysław Biecek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Althoupety_DaFF_Dual_Attentive_Feature_Fusion_for_Multispectral_Pedestrian_Detection_CVPRW_2024_paper.html": {
    "title": "DaFF: Dual Attentive Feature Fusion for Multispectral Pedestrian Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Afnan Althoupety",
      "Li-Yun Wang",
      "Wu-Chi Feng",
      "Banafsheh Rekabdar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Sheppard_Learning_Surface_Terrain_Classifications_from_Ground_Penetrating_Radar_CVPRW_2024_paper.html": {
    "title": "Learning Surface Terrain Classifications from Ground Penetrating Radar",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anja Sheppard",
      "Jason Brown",
      "Nilton Renno",
      "Katherine A. Skinner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Mayr_Narrowing_the_Synthetic-to-Real_Gap_for_Thermal_Infrared_Semantic_Image_Segmentation_CVPRW_2024_paper.html": {
    "title": "Narrowing the Synthetic-to-Real Gap for Thermal Infrared Semantic Image Segmentation Using Diffusion-based Conditional Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christian Mayr",
      "Christian Kubler",
      "Norbert Haala",
      "Michael Teutsch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Kukushkin_BiMAE_-_A_Bimodal_Masked_Autoencoder_Architecture_for_Single-Label_Hyperspectral_CVPRW_2024_paper.html": {
    "title": "BiMAE - A Bimodal Masked Autoencoder Architecture for Single-Label Hyperspectral Image Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maksim Kukushkin",
      "Martin Bogdan",
      "Thomas Schmid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Helvig_CAFF-DINO_Multi-spectral_Object_Detection_Transformers_with_Cross-attention_Features_Fusion_CVPRW_2024_paper.html": {
    "title": "CAFF-DINO: Multi-spectral Object Detection Transformers with Cross-attention Features Fusion",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Helvig",
      "Baptiste Abeloos",
      "Pauline Trouvé-Peloux"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Corley_Revisiting_Pre-trained_Remote_Sensing_Model_Benchmarks_Resizing_and_Normalization_Matters_CVPRW_2024_paper.html": {
    "title": "Revisiting Pre-trained Remote Sensing Model Benchmarks: Resizing and Normalization Matters",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Isaac Corley",
      "Caleb Robinson",
      "Rahul Dodhia",
      "Juan M. Lavista Ferres",
      "Peyman Najafirad"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Senjaliya_Deep_Learning-Based_Identification_of_Arctic_Ocean_Boundaries_and_Near-Surface_Phenomena_CVPRW_2024_paper.html": {
    "title": "Deep Learning-Based Identification of Arctic Ocean Boundaries and Near-Surface Phenomena in Underwater Echograms",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Femina Senjaliya",
      "Melissa Cote",
      "Amanda Dash",
      "Alexandra Branzan Albu",
      "Andrea Niemi",
      "Stéphane Gauthier",
      "Julek Chawarski",
      "Steve Pearce",
      "Kaan Ersahin",
      "Keath Borg"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Cortes-Mendez_Exploring_the_Usage_of_Diffusion_Models_for_Thermal_Image_Super-resolution_CVPRW_2024_paper.html": {
    "title": "Exploring the Usage of Diffusion Models for Thermal Image Super-resolution: A Generic Uncertainty-aware Approach for Guided and Non-guided Schemes",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carlos Cortés-Mendez",
      "Jean-Bernard Hayet"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Puttagunta_Multi-Scale_Feature_Fusion_using_Channel_Transformers_for_Guided_Thermal_Image_CVPRW_2024_paper.html": {
    "title": "Multi-Scale Feature Fusion using Channel Transformers for Guided Thermal Image Super Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raghunath Sai Puttagunta",
      "Birendra Kathariya",
      "Zhu Li",
      "George York"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Guo_Scattering_Prompt_Tuning_A_Fine-tuned_Foundation_Model_for_SAR_Object_CVPRW_2024_paper.html": {
    "title": "Scattering Prompt Tuning: A Fine-tuned Foundation Model for SAR Object Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weilong Guo",
      "Shengyang Li",
      "Jian Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Jiang_Flexible_Window-based_Self-attention_Transformer_in_Thermal_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Flexible Window-based Self-attention Transformer in Thermal Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongcheng Jiang",
      "Zhiqiang Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Yu_MvAV-pix2pixHD_Multi-view_Aerial_View_Image_Translation_CVPRW_2024_paper.html": {
    "title": "MvAV-pix2pixHD: Multi-view Aerial View Image Translation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yu",
      "Keda Lu",
      "Shenshen Du",
      "Lin Xu",
      "Peng Chang",
      "Houde Liu",
      "Bin Lan",
      "Tianyu Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Rivadeneira_Thermal_Image_Super-Resolution_Challenge_Results_-_PBVS_2024_CVPRW_2024_paper.html": {
    "title": "Thermal Image Super-Resolution Challenge Results - PBVS 2024",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rafael E. Rivadeneira",
      "Angel D. Sappa",
      "Chenyang Wang",
      "Junjun Jiang",
      "Zhiwei Zhong",
      "Peilin Chen",
      "Shiqi Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Reyes-Angulo_Forward-Forward_Algorithm_for_Hyperspectral_Image_Classification_CVPRW_2024_paper.html": {
    "title": "Forward-Forward Algorithm for Hyperspectral Image Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abel A. Reyes-Angulo",
      "Sidike Paheding"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Low_Multi-modal_Aerial_View_Image_Challenge_Sensor_Domain_Translation_CVPRW_2024_paper.html": {
    "title": "Multi-modal Aerial View Image Challenge: Sensor Domain Translation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Spencer Low",
      "Oliver Nina",
      "Dylan Bowald",
      "Angel D. Sappa",
      "Nathan Inkawhich",
      "Peter Bruns"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Low_Multi-modal_Aerial_View_Image_Challenge_SAR_Classification_CVPRW_2024_paper.html": {
    "title": "Multi-modal Aerial View Image Challenge: SAR Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Spencer Low",
      "Oliver Nina",
      "Dylan Bowald",
      "Angel D. Sappa",
      "Nathan Inkawhich",
      "Peter Bruns"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Gaus_Performance_Evaluation_of_Segment_Anything_Model_with_Variational_Prompting_for_CVPRW_2024_paper.html": {
    "title": "Performance Evaluation of Segment Anything Model with Variational Prompting for Application to Non-Visible Spectrum Imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yona Falinie A. Gaus",
      "Neelanjan Bhowmik",
      "Brian K. S. Isaac-Medina",
      "Toby P. Breckon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Arnold_SwinFuSR_An_Image_Fusion-inspired_Model_for_RGB-guided_Thermal_Image_Super-resolution_CVPRW_2024_paper.html": {
    "title": "SwinFuSR: An Image Fusion-inspired Model for RGB-guided Thermal Image Super-resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cyprien Arnold",
      "Philippe Jouvet",
      "Lama Seoud"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Jiang_Seeing_the_Vibration_from_Fiber-Optic_Cables_Rain_Intensity_Monitoring_using_CVPRW_2024_paper.html": {
    "title": "Seeing the Vibration from Fiber-Optic Cables: Rain Intensity Monitoring using Deep Frequency Filtering",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhuocheng Jiang",
      "Yangmin Ding",
      "Junhui Zhao",
      "Yue Tian",
      "Shaobo Han",
      "Sarper Ozharar",
      "Ting Wang",
      "James M. Moore"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Joshi_HNN_Hierarchical_Noise-Deinterlace_Net_Towards_Image_Denoising_CVPRW_2024_paper.html": {
    "title": "HNN: Hierarchical Noise-Deinterlace Net Towards Image Denoising",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amogh Joshi",
      "Nikhil Akalwadi",
      "Chinmayee Mandi",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Ujwala Patil",
      "Uma Mudenagudi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FRCSyn/html/Deandres-Tame_Second_Edition_FRCSyn_Challenge_at_CVPR_2024_Face_Recognition_Challenge_CVPRW_2024_paper.html": {
    "title": "Second Edition FRCSyn Challenge at CVPR 2024: Face Recognition Challenge in the Era of Synthetic Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Deandres-Tame",
      "Ruben Tolosana",
      "Pietro Melzi",
      "Ruben Vera-Rodriguez",
      "Minchul Kim",
      "Christian Rathgeb",
      "Xiaoming Liu",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia",
      "Zhizhou Zhong",
      "Yuge Huang",
      "Yuxi Mi",
      "Shouhong Ding",
      "Shuigeng Zhou",
      "Shuai He",
      "Lingzhi Fu",
      "Heng Cong",
      "Rongyu Zhang",
      "Zhihong Xiao",
      "Evgeny Smirnov",
      "Anton Pimenov",
      "Aleksei Grigorev",
      "Denis Timoshenko",
      "Kaleb Mesfin Asfaw",
      "Cheng Yaw Low",
      "Hao Liu",
      "Chuyi Wang",
      "Qing Zuo",
      "Zhixiang He",
      "Hatef Otroshi Shahreza",
      "Anjith George",
      "Alexander Unnervik",
      "Parsa Rahimi",
      "Sébastien Marcel",
      "Pedro C. Neto",
      "Marco Huber",
      "Jan Niklas Kolf",
      "Naser Damer",
      "Fadi Boutros",
      "Jaime S. Cardoso",
      "Ana F. Sequeira",
      "Andrea Atzori",
      "Gianni Fenu",
      "Mirko Marras",
      "Vitomir Štruc",
      "Jiang Yu",
      "Zhangjie Li",
      "Jichun Li",
      "Weisong Zhao",
      "Zhen Lei",
      "Xiangyu Zhu",
      "Xiao-Yu Zhang",
      "Bernardo Biesseck",
      "Pedro Vidal",
      "Luiz Coelho",
      "Roger Granada",
      "David Menotti"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Gutierrez-Perez_No_Bells_Just_Whistles_Sports_Field_Registration_by_Leveraging_Geometric_CVPRW_2024_paper.html": {
    "title": "No Bells Just Whistles: Sports Field Registration by Leveraging Geometric Properties",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marc Gutiérrez-Pérez",
      "Antonio Agudo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Askari_Video_Interaction_Recognition_using_an_Attention_Augmented_Relational_Network_and_CVPRW_2024_paper.html": {
    "title": "Video Interaction Recognition using an Attention Augmented Relational Network and Skeleton Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Farzaneh Askari",
      "Cyril Yared",
      "Rohit Ramaprasad",
      "Devin Garg",
      "Anjun Hu",
      "James J. Clark"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Yeung_AutoSoccerPose_Automated_3D_Posture_Analysis_of_Soccer_Shot_Movements_CVPRW_2024_paper.html": {
    "title": "AutoSoccerPose: Automated 3D Posture Analysis of Soccer Shot Movements",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Calvin Yeung",
      "Kenjiro Ide",
      "Keisuke Fujii"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Suzuki_Pseudo-label_Based_Unsupervised_Fine-tuning_of_a_Monocular_3D_Pose_Estimation_CVPRW_2024_paper.html": {
    "title": "Pseudo-label Based Unsupervised Fine-tuning of a Monocular 3D Pose Estimation Model for Sports Motions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tomohiro Suzuki",
      "Ryota Tanaka",
      "Kazuya Takeda",
      "Keisuke Fujii"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Li_FineRehab_A_Multi-modality_and_Multi-task_Dataset_for_Rehabilitation_Analysis_CVPRW_2024_paper.html": {
    "title": "FineRehab: A Multi-modality and Multi-task Dataset for Rehabilitation Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianwei Li",
      "Jun Xue",
      "Rui Cao",
      "Xiaoxia Du",
      "Siyu Mo",
      "Kehao Ran",
      "Zeyan Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Cabado_Beyond_the_Premier_Assessing_Action_Spotting_Transfer_Capability_Across_Diverse_CVPRW_2024_paper.html": {
    "title": "Beyond the Premier: Assessing Action Spotting Transfer Capability Across Diverse Domains",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bruno Cabado",
      "Anthony Cioppa",
      "Silvio Giancola",
      "Andrés Villa",
      "Bertha Guijarro-Berdiñas",
      "Emilio J. Padrón",
      "Bernard Ghanem",
      "Marc Van Droogenbroeck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Nakabayashi_Event-based_Ball_Spin_Estimation_in_Sports_CVPRW_2024_paper.html": {
    "title": "Event-based Ball Spin Estimation in Sports",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takuya Nakabayashi",
      "Kyota Higa",
      "Masahiro Yamaguchi",
      "Ryo Fujiwara",
      "Hideo Saito"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Qazi_ExerAIde_AI-assisted_Multimodal_Diagnosis_for_Enhanced_Sports_Performance_and_Personalised_CVPRW_2024_paper.html": {
    "title": "ExerAIde: AI-assisted Multimodal Diagnosis for Enhanced Sports Performance and Personalised Rehabilitation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmed Qazi",
      "Asim Iqbal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Decorte_Multi-Modal_Hit_Detection_and_Positional_Analysis_in_Padel_Competitions_CVPRW_2024_paper.html": {
    "title": "Multi-Modal Hit Detection and Positional Analysis in Padel Competitions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robbe Decorte",
      "Martin Paré",
      "Jelle Vanhaeverbeke",
      "Joachim Taelman",
      "Maarten Slembrouck",
      "Steven Verstockt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Gossard_Table_Tennis_Ball_Spin_Estimation_with_an_Event_Camera_CVPRW_2024_paper.html": {
    "title": "Table Tennis Ball Spin Estimation with an Event Camera",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Gossard",
      "Julian Krismer",
      "Andreas Ziegler",
      "Jonas Tebbe",
      "Andreas Zell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Bright_PitcherNet_Powering_the_Moneyball_Evolution_in_Baseball_Video_Analytics_CVPRW_2024_paper.html": {
    "title": "PitcherNet: Powering the Moneyball Evolution in Baseball Video Analytics",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jerrin Bright",
      "Bavesh Balaji",
      "Yuhao Chen",
      "David A Clausi",
      "John S Zelek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Hussain_Medium_Scale_Benchmark_for_Cricket_Excited_Actions_Understanding_CVPRW_2024_paper.html": {
    "title": "Medium Scale Benchmark for Cricket Excited Actions Understanding",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Altaf Hussain",
      "Noman Khan",
      "Muhammad Munsif",
      "Min Je Kim",
      "Sung Wook Baik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Koshkina_A_General_Framework_for_Jersey_Number_Recognition_in_Sports_Video_CVPRW_2024_paper.html": {
    "title": "A General Framework for Jersey Number Recognition in Sports Video",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maria Koshkina",
      "James H. Elder"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Nonaka_Rugby_Scene_Classification_Enhanced_by_Vision_Language_Model_CVPRW_2024_paper.html": {
    "title": "Rugby Scene Classification Enhanced by Vision Language Model",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naoki Nonaka",
      "Ryo Fujihira",
      "Toshiki Koshiba",
      "Akira Maeda",
      "Jun Seita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Leduc_SoccerNet-Depth_a_Scalable_Dataset_for_Monocular_Depth_Estimation_in_Sports_CVPRW_2024_paper.html": {
    "title": "SoccerNet-Depth: a Scalable Dataset for Monocular Depth Estimation in Sports Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnaud Leduc",
      "Anthony Cioppa",
      "Silvio Giancola",
      "Bernard Ghanem",
      "Marc Van Droogenbroeck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Held_X-VARS_Introducing_Explainability_in_Football_Refereeing_with_Multi-Modal_Large_Language_CVPRW_2024_paper.html": {
    "title": "X-VARS: Introducing Explainability in Football Refereeing with Multi-Modal Large Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan Held",
      "Hani Itani",
      "Anthony Cioppa",
      "Silvio Giancola",
      "Bernard Ghanem",
      "Marc Van Droogenbroeck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Okamoto_Hierarchical_NeuroSymbolic_Approach_for_Comprehensive_and_Explainable_Action_Quality_Assessment_CVPRW_2024_paper.html": {
    "title": "Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lauren Okamoto",
      "Paritosh Parmar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Magera_A_Universal_Protocol_to_Benchmark_Camera_Calibration_for_Sports_CVPRW_2024_paper.html": {
    "title": "A Universal Protocol to Benchmark Camera Calibration for Sports",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Floriane Magera",
      "Thomas Hoyoux",
      "Olivier Barnich",
      "Marc Van Droogenbroeck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Scott_TeamTrack_A_Dataset_for_Multi-Sport_Multi-Object_Tracking_in_Full-pitch_Videos_CVPRW_2024_paper.html": {
    "title": "TeamTrack: A Dataset for Multi-Sport Multi-Object Tracking in Full-pitch Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atom Scott",
      "Ikuma Uchida",
      "Ning Ding",
      "Rikuhei Umemoto",
      "Rory Bunker",
      "Ren Kobayashi",
      "Takeshi Koyama",
      "Masaki Onishi",
      "Yoshinari Kameda",
      "Keisuke Fujii"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Xarles_T-DEED_Temporal-Discriminability_Enhancer_Encoder-Decoder_for_Precise_Event_Spotting_in_Sports_CVPRW_2024_paper.html": {
    "title": "T-DEED: Temporal-Discriminability Enhancer Encoder-Decoder for Precise Event Spotting in Sports Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Artur Xarles",
      "Sergio Escalera",
      "Thomas B. Moeslund",
      "Albert Clapés"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Kaneko_Augmenting_Pass_Prediction_via_Imitation_Learning_in_Soccer_Simulations_CVPRW_2024_paper.html": {
    "title": "Augmenting Pass Prediction via Imitation Learning in Soccer Simulations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takeshi Kaneko",
      "Rei Kawakami",
      "Takeshi Naemura",
      "Nakamasa Inoue"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Ibh_A_Stroke_of_Genius_Predicting_the_Next_Move_in_Badminton_CVPRW_2024_paper.html": {
    "title": "A Stroke of Genius: Predicting the Next Move in Badminton",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Magnus Ibh",
      "Stella Graßhof",
      "Dan Witzner Hansen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Somers_SoccerNet_Game_State_Reconstruction_End-to-End_Athlete_Tracking_and_Identification_on_CVPRW_2024_paper.html": {
    "title": "SoccerNet Game State Reconstruction: End-to-End Athlete Tracking and Identification on a Minimap",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vladimir Somers",
      "Victor Joos",
      "Anthony Cioppa",
      "Silvio Giancola",
      "Seyed Abolfazl Ghasemzadeh",
      "Floriane Magera",
      "Baptiste Standaert",
      "Amir M. Mansourian",
      "Xin Zhou",
      "Shohreh Kasaei",
      "Bernard Ghanem",
      "Alexandre Alahi",
      "Marc Van Droogenbroeck",
      "Christophe De Vleeschouwer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Majeed_MV-Soccer_Motion-Vector_Augmented_Instance_Segmentation_for_Soccer_Player_Tracking_CVPRW_2024_paper.html": {
    "title": "MV-Soccer: Motion-Vector Augmented Instance Segmentation for Soccer Player Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fahad Majeed",
      "Nauman Ullah Gilal",
      "Khaled Al-Thelaya",
      "Yin Yang",
      "Marco Agus",
      "Jens Schneider"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Dreyer_Understanding_the_Extra-Ordinary_Validating_Deep_Model_Decisions_with_Prototypical_Concept-based_CVPRW_2024_paper.html": {
    "title": "Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with Prototypical Concept-based Explanations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maximilian Dreyer",
      "Reduan Achtibat",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Franco_Understanding_ReLU_Network_Robustness_Through_Test_Set_Certification_Performance_CVPRW_2024_paper.html": {
    "title": "Understanding ReLU Network Robustness Through Test Set Certification Performance",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicola Franco",
      "Jeanette Miriam Lorenz",
      "Karsten Roscher",
      "Stephan Günnemann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Bareeva_Reactive_Model_Correction_Mitigating_Harm_to_Task-Relevant_Features_via_Conditional_CVPRW_2024_paper.html": {
    "title": "Reactive Model Correction: Mitigating Harm to Task-Relevant Features via Conditional Bias Suppression",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dilyara Bareeva",
      "Maximilian Dreyer",
      "Frederik Pahde",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Xiong_Hinge-Wasserstein_Estimating_Multimodal_Aleatoric_Uncertainty_in_Regression_Tasks_CVPRW_2024_paper.html": {
    "title": "Hinge-Wasserstein: Estimating Multimodal Aleatoric Uncertainty in Regression Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziliang Xiong",
      "Arvi Jonnarth",
      "Abdelrahman Eldesokey",
      "Joakim Johnander",
      "Bastian Wandt",
      "Per-Erik Forssén"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Li_AdvDenoise_Fast_Generation_Framework_of_Universal_and_Robust_Adversarial_Patches_CVPRW_2024_paper.html": {
    "title": "AdvDenoise: Fast Generation Framework of Universal and Robust Adversarial Patches Using Denoise",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Li",
      "Zigan Wang",
      "Jinliang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Mossina_Conformal_Semantic_Image_Segmentation_Post-hoc_Quantification_of_Predictive_Uncertainty_CVPRW_2024_paper.html": {
    "title": "Conformal Semantic Image Segmentation: Post-hoc Quantification of Predictive Uncertainty",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Mossina",
      "Joseba Dalmau",
      "Léo Andéol"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Neumeier_Reliable_Trajectory_Prediction_and_Uncertainty_Quantification_with_Conditioned_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "Reliable Trajectory Prediction and Uncertainty Quantification with Conditioned Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marion Neumeier",
      "Sebastian Dorn",
      "Michael Botsch",
      "Wolfgang Utschick"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Al_Kader_Hammoud_Look_Listen_and_Attack_Backdoor_Attacks_Against_Video_Action_Recognition_CVPRW_2024_paper.html": {
    "title": "Look Listen and Attack: Backdoor Attacks Against Video Action Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hasan Abed Al Kader Hammoud",
      "Shuming Liu",
      "Mohammed Alkhrashi",
      "Fahad Albalawi",
      "Bernard Ghanem"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Yatbaz_Run-time_Monitoring_of_3D_Object_Detection_in_Automated_Driving_Systems_CVPRW_2024_paper.html": {
    "title": "Run-time Monitoring of 3D Object Detection in Automated Driving Systems Using Early Layer Neural Activation Patterns",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hakan Yekta Yatbaz",
      "Mehrdad Dianati",
      "Konstantinos Koufos",
      "Roger Woodman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Mitra_Investigating_Calibration_and_Corruption_Robustness_of_Post-hoc_Pruned_Perception_CNNs_CVPRW_2024_paper.html": {
    "title": "Investigating Calibration and Corruption Robustness of Post-hoc Pruned Perception CNNs: An Image Classification Benchmark Study",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pallavi Mitra",
      "Gesina Schwalbe",
      "Nadja Klein"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Heidemann_Towards_Engineered_Safe_AI_with_Modular_Concept_Models_CVPRW_2024_paper.html": {
    "title": "Towards Engineered Safe AI with Modular Concept Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lena Heidemann",
      "Iwo Kurzidem",
      "Maureen Monnet",
      "Karsten Roscher",
      "Stephan Günnemann"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Dealcala_A_Comprehensive_Analysis_of_Factors_Impacting_Membership_Inference_CVPRW_2024_paper.html": {
    "title": "A Comprehensive Analysis of Factors Impacting Membership Inference",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Dealcala",
      "Gonzalo Mancera",
      "Aythami Morales",
      "Julian Fierrez",
      "Ruben Tolosana",
      "Javier Ortega-Garcia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Zhou_Towards_Weakly-Supervised_Domain_Adaptation_for_Lane_Detection_CVPRW_2024_paper.html": {
    "title": "Towards Weakly-Supervised Domain Adaptation for Lane Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jingxing Zhou",
      "Chongzhe Zhang",
      "Jürgen Beyerer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Qutub_Situation_Monitor_Diversity-Driven_Zero-Shot_Out-of-Distribution_Detection_using_Budding_Ensemble_Architecture_CVPRW_2024_paper.html": {
    "title": "Situation Monitor: Diversity-Driven Zero-Shot Out-of-Distribution Detection using Budding Ensemble Architecture for Object Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Syed Sha Qutub",
      "Michael Paulitsch",
      "Kay-Ulrich Scholl",
      "Neslihan Kose Cihangir",
      "Korbinian Hagn",
      "Fabian Oboril",
      "Gereon Hinz",
      "Alois Knoll"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Melki_The_Penalized_Inverse_Probability_Measure_for_Conformal_Classification_CVPRW_2024_paper.html": {
    "title": "The Penalized Inverse Probability Measure for Conformal Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paul Melki",
      "Lionel Bombrun",
      "Boubacar Diallo",
      "Jérôme Dias",
      "Jean-Pierre Da Costa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/html/Gannamaneni_Exploiting_CLIP_Self-Consistency_to_Automate_Image_Augmentation_for_Safety_Critical_CVPRW_2024_paper.html": {
    "title": "Exploiting CLIP Self-Consistency to Automate Image Augmentation for Safety Critical Scenarios",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sujan Sai Gannamaneni",
      "Frederic Klein",
      "Michael Mock",
      "Maram Akila"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Kluska_QAttn_Efficient_GPU_Kernels_for_Mixed-precision_Vision_Transformers_CVPRW_2024_paper.html": {
    "title": "QAttn: Efficient GPU Kernels for Mixed-precision Vision Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piotr Kluska",
      "Adrián Castelló",
      "Florian Scheidegger",
      "A. Cristiano I. Malossi",
      "Enrique S. Quintana-Ortí"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Wang_SAM-CLIP_Merging_Vision_Foundation_Models_Towards_Semantic_and_Spatial_Understanding_CVPRW_2024_paper.html": {
    "title": "SAM-CLIP: Merging Vision Foundation Models Towards Semantic and Spatial Understanding",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoxiang Wang",
      "Pavan Kumar Anasosalu Vasu",
      "Fartash Faghri",
      "Raviteja Vemulapalli",
      "Mehrdad Farajtabar",
      "Sachin Mehta",
      "Mohammad Rastegari",
      "Oncel Tuzel",
      "Hadi Pouransari"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Bafghi_Parameter_Efficient_Fine-tuning_of_Self-supervised_ViTs_without_Catastrophic_Forgetting_CVPRW_2024_paper.html": {
    "title": "Parameter Efficient Fine-tuning of Self-supervised ViTs without Catastrophic Forgetting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Reza Akbarian Bafghi",
      "Nidhin Harilal",
      "Claire Monteleoni",
      "Maziar Raissi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Schon_Adapting_the_Segment_Anything_Model_During_Usage_in_Novel_Situations_CVPRW_2024_paper.html": {
    "title": "Adapting the Segment Anything Model During Usage in Novel Situations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robin Schön",
      "Julian Lorenz",
      "Katja Ludwig",
      "Rainer Lienhart"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Li_PMAFusion_Projection-Based_Multi-Modal_Alignment_for_3D_Semantic_Occupancy_Prediction_CVPRW_2024_paper.html": {
    "title": "PMAFusion: Projection-Based Multi-Modal Alignment for 3D Semantic Occupancy Prediction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiyao Li",
      "Wenming Yang",
      "Qingmin Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Koyun_HaLViT_Half_of_the_Weights_are_Enough_CVPRW_2024_paper.html": {
    "title": "HaLViT: Half of the Weights are Enough",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Onur Can Koyun",
      "Behçet Uğur Töreyin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Smith_Adaptive_Memory_Replay_for_Continual_Learning_CVPRW_2024_paper.html": {
    "title": "Adaptive Memory Replay for Continual Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Seale Smith",
      "Lazar Valkov",
      "Shaunak Halbe",
      "Vyshnavi Gutta",
      "Rogerio Feris",
      "Zsolt Kira",
      "Leonid Karlinsky"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/eLVM/html/Yuan_Efficient_Transformer_Adaptation_with_Soft_Token_Merging_CVPRW_2024_paper.html": {
    "title": "Efficient Transformer Adaptation with Soft Token Merging",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Yuan",
      "Hongliang Fei",
      "Jinoo Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Huang_Automatic_Recognition_of_Food_Ingestion_Environment_from_the_AIM-2_Wearable_CVPRW_2024_paper.html": {
    "title": "Automatic Recognition of Food Ingestion Environment from the AIM-2 Wearable Sensor",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuning Huang",
      "M A Hassan",
      "Jiangpeng He",
      "J. Higgins",
      "Megan Mccrory",
      "Heather Eicher-Miller",
      "J. Graham Thomas",
      "Edward Sazonov",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Alahmari_Segment_Anything_in_Food_Images_CVPRW_2024_paper.html": {
    "title": "Segment Anything in Food Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saeed S. Alahmari",
      "Michael Gardner",
      "Tawfiq Salem"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Vinod_Food_Portion_Estimation_via_3D_Object_Scaling_CVPRW_2024_paper.html": {
    "title": "Food Portion Estimation via 3D Object Scaling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gautham Vinod",
      "Jiangpeng He",
      "Zeman Shao",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Chen_Shape-Preserving_Generation_of_Food_Images_for_Automatic_Dietary_Assessment_CVPRW_2024_paper.html": {
    "title": "Shape-Preserving Generation of Food Images for Automatic Dietary Assessment",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guangzong Chen",
      "Zhi-Hong Mao",
      "Mingui Sun",
      "Kangni Liu",
      "Wenyan Jia"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Rodriguez-De-Vera_LOFI_LOng-tailed_FIne-Grained_Network_for_Food_Recognition_CVPRW_2024_paper.html": {
    "title": "LOFI: LOng-tailed FIne-Grained Network for Food Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jesús M. Rodríguez-De-Vera",
      "Imanol G. Estepa",
      "Marc Bolaños",
      "Bhalaji Nagarajan",
      "Petia Radeva"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Wang_MP-PolarMask_A_Faster_and_Finer_Instance_Segmentation_for_Concave_Images_CVPRW_2024_paper.html": {
    "title": "MP-PolarMask: A Faster and Finer Instance Segmentation for Concave Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke-Lei Wang",
      "Pin-Hsuan Chou",
      "Young-Ching Chou",
      "Chia-Jen Liu",
      "Cheng-Kuan Lin",
      "Yu-Chee Tseng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Yang_Learning_to_Classify_New_Foods_Incrementally_Via_Compressed_Exemplars_CVPRW_2024_paper.html": {
    "title": "Learning to Classify New Foods Incrementally Via Compressed Exemplars",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin Yang",
      "Zhihao Duan",
      "Jiangpeng He",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Sharma_How_Much_You_Ate_Food_Portion_Estimation_on_Spoons_CVPRW_2024_paper.html": {
    "title": "How Much You Ate? Food Portion Estimation on Spoons",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aaryam Sharma",
      "Chris Czarnecki",
      "Yuhao Chen",
      "Pengcheng Xi",
      "Linlin Xu",
      "Alexander Wong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MTF/html/Shin_A_Generative_Exploration_of_Cuisine_Transfer__CVPRW_2024_paper.html": {
    "title": "A Generative Exploration of Cuisine Transfer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philip Wootaek Shin",
      "Ajay Narayanan Sridhar",
      "Jack Sampson",
      "Vijaykrishnan Narayanan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Frick_DiffSeg_Towards_Detecting_Diffusion-Based_Inpainting_Attacks_Using_Multi-Feature_Segmentation_CVPRW_2024_paper.html": {
    "title": "DiffSeg: Towards Detecting Diffusion-Based Inpainting Attacks Using Multi-Feature Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphael Antonius Frick",
      "Martin Steinebach"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Panzino_Evaluating_the_Integration_of_Morph_Attack_Detection_in_Automated_Face_CVPRW_2024_paper.html": {
    "title": "Evaluating the Integration of Morph Attack Detection in Automated Face Recognition Systems",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Panzino",
      "Simone Maurizio La Cava",
      "Giulia Orrù",
      "Gian Luca Marcialis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Lanzino_Faster_Than_Lies_Real-time_Deepfake_Detection_using_Binary_Neural_Networks_CVPRW_2024_paper.html": {
    "title": "Faster Than Lies: Real-time Deepfake Detection using Binary Neural Networks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Romeo Lanzino",
      "Federico Fontana",
      "Anxhelo Diko",
      "Marco Raoul Marini",
      "Luigi Cinque"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Concas_Quality-based_Artifact_Modeling_for_Facial_Deepfake_Detection_in_Videos_CVPRW_2024_paper.html": {
    "title": "Quality-based Artifact Modeling for Facial Deepfake Detection in Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sara Concas",
      "Simone Maurizio La Cava",
      "Roberto Casula",
      "Giulia Orrù",
      "Giovanni Puglisi",
      "Gian Luca Marcialis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Pellicer_PUDD_Towards_Robust_Multi-modal_Prototype-based_Deepfake_Detection_CVPRW_2024_paper.html": {
    "title": "PUDD: Towards Robust Multi-modal Prototype-based Deepfake Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alvaro Lopez Pellicer",
      "Yi Li",
      "Plamen Angelov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Ciamarra_Temporal_Surface_Frame_Anomalies_for_Deepfake_Video_Detection_CVPRW_2024_paper.html": {
    "title": "Temporal Surface Frame Anomalies for Deepfake Video Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Ciamarra",
      "Roberto Caldelli",
      "Alberto Del Bimbo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Agarwal_Deepfake_Catcher_Can_a_Simple_Fusion_be_Effective_and_Outperform_CVPRW_2024_paper.html": {
    "title": "Deepfake Catcher: Can a Simple Fusion be Effective and Outperform Complex DNNs?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshay Agarwal",
      "Nalini Ratha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Li_MaskSim_Detection_of_Synthetic_Images_by_Masked_Spectrum_Similarity_Analysis_CVPRW_2024_paper.html": {
    "title": "MaskSim: Detection of Synthetic Images by Masked Spectrum Similarity Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yanhao Li",
      "Quentin Bammey",
      "Marina Gardella",
      "Tina Nikoukhah",
      "Jean-Michel Morel",
      "Miguel Colom",
      "Rafael Grompone Von Gioi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/Leyva_Demographic_Bias_Effects_on_Face_Image_Synthesis_CVPRW_2024_paper.html": {
    "title": "Demographic Bias Effects on Face Image Synthesis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Roberto Leyva",
      "Victor Sanchez",
      "Gregory Epiphaniou",
      "Carsten Maple"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DFAD/html/K_Latent_Flow_Diffusion_for_Deepfake_Video_Generation_CVPRW_2024_paper.html": {
    "title": "Latent Flow Diffusion for Deepfake Video Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aashish Chandra K",
      "Aashutosh A V",
      "Srijan Das",
      "Abhijit Das"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Ardelean_Blind_Localization_and_Clustering_of_Anomalies_in_Textures_CVPRW_2024_paper.html": {
    "title": "Blind Localization and Clustering of Anomalies in Textures",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrei-Timotei Ardelean",
      "Tim Weyrich"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Benz_OmniCrack30k_A_Benchmark_for_Crack_Segmentation_and_the_Reasonable_Effectiveness_CVPRW_2024_paper.html": {
    "title": "OmniCrack30k: A Benchmark for Crack Segmentation and the Reasonable Effectiveness of Transfer Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christian Benz",
      "Volker Rodehorst"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/K._Video_Anomaly_Detection_via_Spatio-Temporal_Pseudo-Anomaly_Generation__A_Unified_CVPRW_2024_paper.html": {
    "title": "Video Anomaly Detection via Spatio-Temporal Pseudo-Anomaly Generation : A Unified Approach",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayush K. Rai",
      "Tarun Krishna",
      "Feiyan Hu",
      "Alexandru Drimbarean",
      "Kevin Mcguinness",
      "Alan F. Smeaton",
      "Noel E. O'connor"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Kruse_SplatPose__Detect_Pose-Agnostic_3D_Anomaly_Detection_CVPRW_2024_paper.html": {
    "title": "SplatPose & Detect: Pose-Agnostic 3D Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mathis Kruse",
      "Marco Rudolph",
      "Dominik Woiwode",
      "Bodo Rosenhahn"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Costanzino_Test_Time_Training_for_Industrial_Anomaly_Segmentation_CVPRW_2024_paper.html": {
    "title": "Test Time Training for Industrial Anomaly Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Costanzino",
      "Pierluigi Zama Ramirez",
      "Mirko Del Moro",
      "Agostino Aiezzo",
      "Giuseppe Lisanti",
      "Samuele Salti",
      "Luigi Di Stefano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Zhao_LogicAL_Towards_Logical_Anomaly_Synthesis_for_Unsupervised_Anomaly_Localization_CVPRW_2024_paper.html": {
    "title": "LogicAL: Towards Logical Anomaly Synthesis for Unsupervised Anomaly Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Singh_Tracklet-based_Explainable_Video_Anomaly_Localization_CVPRW_2024_paper.html": {
    "title": "Tracklet-based Explainable Video Anomaly Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ashish Singh",
      "Michael J. Jones",
      "Erik G. Learned-Miller"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Tebbe_Dynamic_Addition_of_Noise_in_a_Diffusion_Model_for_Anomaly_CVPRW_2024_paper.html": {
    "title": "Dynamic Addition of Noise in a Diffusion Model for Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin Tebbe",
      "Jawad Tayyub"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Fooladgar_Manifold_DivideMix_A_Semi-Supervised_Contrastive_Learning_Framework_for_Severe_Label_CVPRW_2024_paper.html": {
    "title": "Manifold DivideMix: A Semi-Supervised Contrastive Learning Framework for Severe Label Noise",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fahimeh Fooladgar",
      "Minh Nguyen Nhat To",
      "Parvin Mousavi",
      "Purang Abolmaesumi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Hogeweg_COOD_Combined_Out-of-distribution_Detection_Using_Multiple_Measures_for_Anomaly__CVPRW_2024_paper.html": {
    "title": "COOD: Combined Out-of-distribution Detection Using Multiple Measures for Anomaly & Novel Class Detection in Large-scale Hierarchical Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Laurens E. Hogeweg",
      "Rajesh Gangireddy",
      "Django Brunink",
      "Vincent J. Kalkman",
      "Ludo Cornelissen",
      "Jacob W. Kamminga"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Wijanarko_Tri-VAE_Triplet_Variational_Autoencoder_for_Unsupervised_Anomaly_Detection_in_Brain_CVPRW_2024_paper.html": {
    "title": "Tri-VAE: Triplet Variational Autoencoder for Unsupervised Anomaly Detection in Brain Tumor MRI",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hansen Wijanarko",
      "Evelyne Calista",
      "Li-Fen Chen",
      "Yong-Sheng Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Artola_Model-guided_Contrastive_Fine-tuning_for_Industrial_Anomaly_Detection_CVPRW_2024_paper.html": {
    "title": "Model-guided Contrastive Fine-tuning for Industrial Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aitor Artola",
      "Yannis Kolodziej",
      "Jean-Michel Morel",
      "Thibaud Ehret"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Lappas_Dynamic_Distinction_Learning_Adaptive_Pseudo_Anomalies_for_Video_Anomaly_Detection_CVPRW_2024_paper.html": {
    "title": "Dynamic Distinction Learning: Adaptive Pseudo Anomalies for Video Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Demetris Lappas",
      "Vasileios Argyriou",
      "Dimitrios Makris"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Choi_DMR_Disentangling_Marginal_Representations_for_Out-of-Distribution_Detection_CVPRW_2024_paper.html": {
    "title": "DMR: Disentangling Marginal Representations for Out-of-Distribution Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dasol Choi",
      "Dongbin Na"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Lee_TAB_Text-Align_Anomaly_Backbone_Model_for_Industrial_Inspection_Tasks_CVPRW_2024_paper.html": {
    "title": "TAB: Text-Align Anomaly Backbone Model for Industrial Inspection Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ho-Weng Lee",
      "Shang-Hong Lai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Bao_BMAD_Benchmarks_for_Medical_Anomaly_Detection_CVPRW_2024_paper.html": {
    "title": "BMAD: Benchmarks for Medical Anomaly Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinan Bao",
      "Hanshi Sun",
      "Hanqiu Deng",
      "Yinsheng He",
      "Zhaoxiang Zhang",
      "Xingyu Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Yang_Context-aware_Video_Anomaly_Detection_in_Long-Term_Datasets_CVPRW_2024_paper.html": {
    "title": "Context-aware Video Anomaly Detection in Long-Term Datasets",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhengye Yang",
      "Richard J. Radke"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VAND/html/Rolih_Divide_and_Conquer_High-Resolution_Industrial_Anomaly_Detection_via_Memory_Efficient_CVPRW_2024_paper.html": {
    "title": "Divide and Conquer: High-Resolution Industrial Anomaly Detection via Memory Efficient Tiled Ensemble",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Blaž Rolih",
      "Dick Ameln",
      "Ashwin Vaidya",
      "Samet Akcay"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Singh_Wake-Sleep_Energy_Based_Models_for_Continual_Learning_CVPRW_2024_paper.html": {
    "title": "Wake-Sleep Energy Based Models for Continual Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vaibhav Singh",
      "Anna Choromanska",
      "Shuang Li",
      "Yilun Du"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Bugarin_Unveiling_the_Anomalies_in_an_Ever-Changing_World_A_Benchmark_for_CVPRW_2024_paper.html": {
    "title": "Unveiling the Anomalies in an Ever-Changing World: A Benchmark for Pixel-Level Anomaly Detection in Continual Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikola Bugarin",
      "Jovana Bugaric",
      "Manuel Barusco",
      "Davide Dalle Pezze",
      "Gian Antonio Susto"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Korycki_Class-Incremental_Mixture_of_Gaussians_for_Deep_Continual_Learning_CVPRW_2024_paper.html": {
    "title": "Class-Incremental Mixture of Gaussians for Deep Continual Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lukasz Korycki",
      "Bartosz Krawczyk"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Kamath_The_Expanding_Scope_of_the_Stability_Gap_Unveiling_its_Presence_CVPRW_2024_paper.html": {
    "title": "The Expanding Scope of the Stability Gap: Unveiling its Presence in Joint Incremental Learning of Homogeneous Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sandesh Kamath",
      "Albin Soutif-Cormerais",
      "Joost Van De Weijer",
      "Bogdan Raducanu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Zhu_TAME_Task_Agnostic_Continual_Learning_using_Multiple_Experts_CVPRW_2024_paper.html": {
    "title": "TAME: Task Agnostic Continual Learning using Multiple Experts",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Zhu",
      "Maryam Majzoubi",
      "Arihant Jain",
      "Anna Choromanska"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Kim_VLM-PL_Advanced_Pseudo_Labeling_Approach_for_Class_Incremental_Object_Detection_CVPRW_2024_paper.html": {
    "title": "VLM-PL: Advanced Pseudo Labeling Approach for Class Incremental Object Detection via Vision-Language Model",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junsu Kim",
      "Yunhoe Ku",
      "Jihyeon Kim",
      "Junuk Cha",
      "Seungryul Baek"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Krawczyk_An_Analysis_of_Best-practice_Strategies_for_Replay_and_Rehearsal_in_CVPRW_2024_paper.html": {
    "title": "An Analysis of Best-practice Strategies for Replay and Rehearsal in Continual Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Krawczyk",
      "Alexander Gepperth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Raghavan_DELTA_Decoupling_Long-Tailed_Online_Continual_Learning_CVPRW_2024_paper.html": {
    "title": "DELTA: Decoupling Long-Tailed Online Continual Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddeshwar Raghavan",
      "Jiangpeng He",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Nguyen_Tackling_Domain_Shifts_in_Person_Re-Identification_A_Survey_and_Analysis_CVPRW_2024_paper.html": {
    "title": "Tackling Domain Shifts in Person Re-Identification: A Survey and Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vuong D. Nguyen",
      "Samiha Mirza",
      "Abdollah Zakeri",
      "Ayush Gupta",
      "Khadija Khaldi",
      "Rahma Aloui",
      "Pranav Mantini",
      "Shishir K. Shah",
      "Fatima Merchant"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Chavan_Active_Data_Collection_and_Management_for_Real-World_Continual_Learning_via_CVPRW_2024_paper.html": {
    "title": "Active Data Collection and Management for Real-World Continual Learning via Pretrained Oracle",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vivek Chavan",
      "Paul Koch",
      "Marian Schlüter",
      "Clemens Briese",
      "Jörg Krüger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Kozal_Continual_Learning_with_Weight_Interpolation_CVPRW_2024_paper.html": {
    "title": "Continual Learning with Weight Interpolation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jędrzej Kozal",
      "Jan Wasilewski",
      "Bartosz Krawczyk",
      "Michał Woźniak"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Belouadah_MultIOD_Rehearsal-free_Multihead_Incremental_Object_Detector_CVPRW_2024_paper.html": {
    "title": "MultIOD: Rehearsal-free Multihead Incremental Object Detector",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eden Belouadah",
      "Arnaud Dapogny",
      "Kevin Bailly"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Bayasi_Continual-Zoo_Leveraging_Zoo_Models_for_Continual_Classification_of_Medical_Images_CVPRW_2024_paper.html": {
    "title": "Continual-Zoo: Leveraging Zoo Models for Continual Classification of Medical Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nourhan Bayasi",
      "Ghassan Hamarneh",
      "Rafeef Garbi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Li_Calibration_of_Continual_Learning_Models_CVPRW_2024_paper.html": {
    "title": "Calibration of Continual Learning Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lanpei Li",
      "Elia Piccoli",
      "Andrea Cossu",
      "Davide Bacciu",
      "Vincenzo Lomonaco"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CLVISION/html/Goswami_Calibrating_Higher-Order_Statistics_for_Few-Shot_Class-Incremental_Learning_with_Pre-trained_Vision_CVPRW_2024_paper.html": {
    "title": "Calibrating Higher-Order Statistics for Few-Shot Class-Incremental Learning with Pre-trained Vision Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dipam Goswami",
      "Bartłomiej Twardowski",
      "Joost Van De Weijer"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FedVision-2024/html/Dutto_Collaborative_Visual_Place_Recognition_through_Federated_Learning_CVPRW_2024_paper.html": {
    "title": "Collaborative Visual Place Recognition through Federated Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mattia Dutto",
      "Gabriele Berton",
      "Debora Caldarola",
      "Eros Fanì",
      "Gabriele Trivigno",
      "Carlo Masone"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FedVision-2024/html/Tabassum_On_the_Efficiency_of_Privacy_Attacks_in_Federated_Learning_CVPRW_2024_paper.html": {
    "title": "On the Efficiency of Privacy Attacks in Federated Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nawrin Tabassum",
      "Ka-Ho Chow",
      "Xuyu Wang",
      "Wenbin Zhang",
      "Yanzhao Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FedVision-2024/html/Gao_FedProK_Trustworthy_Federated_Class-Incremental_Learning_via_Prototypical_Feature_Knowledge_Transfer_CVPRW_2024_paper.html": {
    "title": "FedProK: Trustworthy Federated Class-Incremental Learning via Prototypical Feature Knowledge Transfer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Gao",
      "Xin Yang",
      "Hao Yu",
      "Yan Kang",
      "Tianrui Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/FedVision-2024/html/Nakka_Federated_Hyperparameter_Optimization_Through_Reward-Based_Strategies_Challenges_and_Insights_CVPRW_2024_paper.html": {
    "title": "Federated Hyperparameter Optimization Through Reward-Based Strategies: Challenges and Insights",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Krishna Kanth Nakka",
      "Ahmed Frikha",
      "Ricardo Mendis",
      "Xue Jiang",
      "Xuebing Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/IMW/html/Berton_EarthMatch_Iterative_Coregistration_for_Fine-grained_Localization_of_Astronaut_Photography_CVPRW_2024_paper.html": {
    "title": "EarthMatch: Iterative Coregistration for Fine-grained Localization of Astronaut Photography",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriele Berton",
      "Gabriele Goletto",
      "Gabriele Trivigno",
      "Alex Stoken",
      "Barbara Caputo",
      "Carlo Masone"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/IMW/html/Chen_Affine-based_Deformable_Attention_and_Selective_Fusion_for_Semi-dense_Matching_CVPRW_2024_paper.html": {
    "title": "Affine-based Deformable Attention and Selective Fusion for Semi-dense Matching",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongkai Chen",
      "Zixin Luo",
      "Yurun Tian",
      "Xuyang Bai",
      "Ziyu Wang",
      "Lei Zhou",
      "Mingmin Zhen",
      "Tian Fang",
      "David Mckinnon",
      "Yanghai Tsin",
      "Long Quan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/IMW/html/Tuzcuoglu_XoFTR_Cross-modal_Feature_Matching_Transformer_CVPRW_2024_paper.html": {
    "title": "XoFTR: Cross-modal Feature Matching Transformer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Önder Tuzcuoğlu",
      "Aybora Köksal",
      "Buğra Sofu",
      "Sinan Kalkan",
      "A. Aydin Alatan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/IMW/html/Pendota_Are_Deep_Learning_Models_Pre-trained_on_RGB_Data_Good_Enough_CVPRW_2024_paper.html": {
    "title": "Are Deep Learning Models Pre-trained on RGB Data Good Enough for RGB-Thermal Image Retrieval?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amulya Pendota",
      "Sumohana S. Channappayya"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/IMW/html/Edstedt_DeDoDe_v2_Analyzing_and_Improving_the_DeDoDe_Keypoint_Detector_CVPRW_2024_paper.html": {
    "title": "DeDoDe v2: Analyzing and Improving the DeDoDe Keypoint Detector",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Johan Edstedt",
      "Georg Bökman",
      "Zhenjun Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Azizpour_E3_Ensemble_of_Expert_Embedders_for_Adapting_Synthetic_Image_Detectors_CVPRW_2024_paper.html": {
    "title": "E3: Ensemble of Expert Embedders for Adapting Synthetic Image Detectors to New Generators Using Limited Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aref Azizpour",
      "Tai D. Nguyen",
      "Manil Shrestha",
      "Kaidi Xu",
      "Edward Kim",
      "Matthew C. Stamm"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Norman_An_Investigation_into_the_Impact_of_AI-Powered_Image_Enhancement_on_CVPRW_2024_paper.html": {
    "title": "An Investigation into the Impact of AI-Powered Image Enhancement on Forensic Facial Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin Norman",
      "Hany Farid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Vahdati_Beyond_Deepfake_Images_Detecting_AI-Generated_Videos_CVPRW_2024_paper.html": {
    "title": "Beyond Deepfake Images: Detecting AI-Generated Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Danial Samadi Vahdati",
      "Tai D. Nguyen",
      "Aref Azizpour",
      "Matthew C. Stamm"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Karageorgiou_Fusion_Transformer_with_Object_Mask_Guidance_for_Image_Forgery_Analysis_CVPRW_2024_paper.html": {
    "title": "Fusion Transformer with Object Mask Guidance for Image Forgery Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dimitrios Karageorgiou",
      "Giorgos Kordopatis-Zilos",
      "Symeon Papadopoulos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Tariq_Beyond_the_Screen_Evaluating_Deepfake_Detectors_under_Moire_Pattern_Effects_CVPRW_2024_paper.html": {
    "title": "Beyond the Screen: Evaluating Deepfake Detectors under Moire Pattern Effects",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Razaib Tariq",
      "Minji Heo",
      "Simon S. Woo",
      "Shahroz Tariq"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Choi_Building_Secure_and_Engaging_Video_Communication_by_Using_Monitor_Illumination_CVPRW_2024_paper.html": {
    "title": "Building Secure and Engaging Video Communication by Using Monitor Illumination",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Myeong Choi",
      "Johnathan Leung",
      "Noah Frahm",
      "Max Christman",
      "Gedas Bertasius",
      "Roni Sengupta"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Shadmand_StampOne_Addressing_Frequency_Balance_in_Printer-proof_Steganography_CVPRW_2024_paper.html": {
    "title": "StampOne: Addressing Frequency Balance in Printer-proof Steganography",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Farhad Shadmand",
      "Iurii Medvedev",
      "Luiz Schirmer",
      "João Marcos",
      "Nuno Gonçalves"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Porcile_Finding_AI-Generated_Faces_in_the_Wild_CVPRW_2024_paper.html": {
    "title": "Finding AI-Generated Faces in the Wild",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gonzalo J. Aniano Porcile",
      "Jack Gindi",
      "Shivansh Mundra",
      "James R. Verbus",
      "Hany Farid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Cozzolino_Raising_the_Bar_of_AI-generated_Image_Detection_with_CLIP_CVPRW_2024_paper.html": {
    "title": "Raising the Bar of AI-generated Image Detection with CLIP",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davide Cozzolino",
      "Giovanni Poggi",
      "Riccardo Corvi",
      "Matthias Nießner",
      "Luisa Verdoliva"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Cuccovillo_Audio_Transformer_for_Synthetic_Speech_Detection_via_Multi-Formant_Analysis_CVPRW_2024_paper.html": {
    "title": "Audio Transformer for Synthetic Speech Detection via Multi-Formant Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Cuccovillo",
      "Milica Gerhardt",
      "Patrick Aichroth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Yadav_FairSSD_Understanding_Bias_in_Synthetic_Speech_Detectors_CVPRW_2024_paper.html": {
    "title": "FairSSD: Understanding Bias in Synthetic Speech Detectors",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amit Kumar Singh Yadav",
      "Kratika Bhagtani",
      "Davide Salvi",
      "Paolo Bestagini",
      "Edward J. Delp"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Jia_Can_ChatGPT_Detect_DeepFakes_A_Study_of_Using_Multimodal_Large_CVPRW_2024_paper.html": {
    "title": "Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shan Jia",
      "Reilin Lyu",
      "Kangran Zhao",
      "Yize Chen",
      "Zhiyuan Yan",
      "Yan Ju",
      "Chuanbo Hu",
      "Xin Li",
      "Baoyuan Wu",
      "Siwei Lyu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Gerhardt_Audio_Provenance_Analysis_in_Heterogeneous_Media_Sets_CVPRW_2024_paper.html": {
    "title": "Audio Provenance Analysis in Heterogeneous Media Sets",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Milica Gerhardt",
      "Luca Cuccovillo",
      "Patrick Aichroth"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WMF/html/Bohacek_Lost_in_Translation_Lip-Sync_Deepfake_Detection_from_Audio-Video_Mismatch_CVPRW_2024_paper.html": {
    "title": "Lost in Translation: Lip-Sync Deepfake Detection from Audio-Video Mismatch",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matyas Bohacek",
      "Hany Farid"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Gerin_Multi-Stream_Cellular_Test-Time_Adaptation_of_Real-Time_Models_Evolving_in_Dynamic_CVPRW_2024_paper.html": {
    "title": "Multi-Stream Cellular Test-Time Adaptation of Real-Time Models Evolving in Dynamic Environments",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benoît Gérin",
      "Anaïs Halin",
      "Anthony Cioppa",
      "Maxim Henry",
      "Bernard Ghanem",
      "Benoît Macq",
      "Christophe De Vleeschouwer",
      "Marc Van Droogenbroeck"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Shimomura_Potential_Risk_Localization_via_Weak_Labeling_out_of_Blind_Spot_CVPRW_2024_paper.html": {
    "title": "Potential Risk Localization via Weak Labeling out of Blind Spot",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kota Shimomura",
      "Tsubasa Hirakawa",
      "Takayoshi Yamashita",
      "Hironobu Fujiyoshi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Son_CaBins_CLIP-based_Adaptive_Bins_for_Monocular_Depth_Estimation_CVPRW_2024_paper.html": {
    "title": "CaBins: CLIP-based Adaptive Bins for Monocular Depth Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eunjin Son",
      "Sang Jun Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Dana_Do_More_With_What_You_Have_Transferring_Depth-Scale_from_Labeled_CVPRW_2024_paper.html": {
    "title": "Do More With What You Have: Transferring Depth-Scale from Labeled to Unlabeled Domains",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandra Dana",
      "Nadav Carmel",
      "Amit Shomer",
      "Ofer Manela",
      "Tomer Peleg"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Lindstrom_Are_NeRFs_Ready_for_Autonomous_Driving_Towards_Closing_the_Real-to-simulation_CVPRW_2024_paper.html": {
    "title": "Are NeRFs Ready for Autonomous Driving? Towards Closing the Real-to-simulation Gap",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carl Lindström",
      "Georg Hess",
      "Adam Lilja",
      "Maryam Fatemi",
      "Lars Hammarstrand",
      "Christoffer Petersson",
      "Lennart Svensson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Kannan_Click_Crop__Detect_One-Click_Offline_Annotation_for_Human-in-the-Loop_3D_CVPRW_2024_paper.html": {
    "title": "Click Crop & Detect: One-Click Offline Annotation for Human-in-the-Loop 3D Object Detection on Point Clouds",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nitin Kumar Saravana Kannan",
      "Matthias Reuse",
      "Martin Simon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Saini_CenterPoint_Transformer_for_BEV_Object_Detection_with_Automotive_Radar_CVPRW_2024_paper.html": {
    "title": "CenterPoint Transformer for BEV Object Detection with Automotive Radar",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Loveneet Saini",
      "Yu Su",
      "Hasan Tercan",
      "Tobias Meisen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Cocheteux_MULi-Ev_Maintaining_Unperturbed_LiDAR-Event_Calibration_CVPRW_2024_paper.html": {
    "title": "MULi-Ev: Maintaining Unperturbed LiDAR-Event Calibration",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mathieu Cocheteux",
      "Julien Moreau",
      "Franck Davoine"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Li_TFNet_Exploiting_Temporal_Cues_for_Fast_and_Accurate_LiDAR_Semantic_CVPRW_2024_paper.html": {
    "title": "TFNet: Exploiting Temporal Cues for Fast and Accurate LiDAR Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rong Li",
      "Shijie Li",
      "Xieyuanli Chen",
      "Teli Ma",
      "Juergen Gall",
      "Junwei Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Wang_TrajFine_Predicted_Trajectory_Refinement_for_Pedestrian_Trajectory_Forecasting_CVPRW_2024_paper.html": {
    "title": "TrajFine: Predicted Trajectory Refinement for Pedestrian Trajectory Forecasting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kuan-Lin Wang",
      "Li-Wu Tsao",
      "Jhih-Ciang Wu",
      "Hong-Han Shuai",
      "Wen-Huang Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Gunn_Lift-Attend-Splat_Birds-eye-view_Camera-lidar_Fusion_using_Transformers_CVPRW_2024_paper.html": {
    "title": "Lift-Attend-Splat: Bird's-eye-view Camera-lidar Fusion using Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Gunn",
      "Zygmunt Lenyk",
      "Anuj Sharma",
      "Andrea Donati",
      "Alexandru Buburuzan",
      "John Redford",
      "Romain Mueller"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Shi_DuST_Dual_Swin_Transformer_for_Multi-modal_Video_and_Time-Series_Modeling_CVPRW_2024_paper.html": {
    "title": "DuST: Dual Swin Transformer for Multi-modal Video and Time-Series Modeling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liang Shi",
      "Yixin Chen",
      "Meimei Liu",
      "Feng Guo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Bateman_Exploring_Real_World_Map_Change_Generalization_of_Prior-Informed_HD_Map_CVPRW_2024_paper.html": {
    "title": "Exploring Real World Map Change Generalization of Prior-Informed HD Map Prediction Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel M. Bateman",
      "Ning Xu",
      "H. Charles Zhao",
      "Yael Ben Shalom",
      "Vince Gong",
      "Greg Long",
      "Will Maddern"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/WAD/html/Sirko-Galouchenko_OccFeat_Self-supervised_Occupancy_Feature_Prediction_for_Pretraining_BEV_Segmentation_Networks_CVPRW_2024_paper.html": {
    "title": "OccFeat: Self-supervised Occupancy Feature Prediction for Pretraining BEV Segmentation Networks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sophia Sirko-Galouchenko",
      "Alexandre Boulch",
      "Spyros Gidaris",
      "Andrei Bursuc",
      "Antonin Vobecky",
      "Patrick Pérez",
      "Renaud Marlet"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Hong_Purposeful_Regularization_with_Reinforcement_Learning_for_Facial_Expression_Recognition_In-the-Wild_CVPRW_2024_paper.html": {
    "title": "Purposeful Regularization with Reinforcement Learning for Facial Expression Recognition In-the-Wild",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanghwa Hong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Vedernikov_TCCT-Net_Two-Stream_Network_Architecture_for_Fast_and_Efficient_Engagement_Estimation_CVPRW_2024_paper.html": {
    "title": "TCCT-Net: Two-Stream Network Architecture for Fast and Efficient Engagement Estimation via Behavioral Feature Signals",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Vedernikov",
      "Puneet Kumar",
      "Haoyu Chen",
      "Tapio Seppänen",
      "Xiaobai Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Zhou_Enhancing_Emotion_Recognition_with_Pre-trained_Masked_Autoencoders_and_Sequential_Learning_CVPRW_2024_paper.html": {
    "title": "Enhancing Emotion Recognition with Pre-trained Masked Autoencoders and Sequential Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiwei Zhou",
      "Jiada Lu",
      "Chengkun Ling",
      "Weifeng Wang",
      "Shaowei Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Ryumina_Zero-Shot_Audio-Visual_Compound_Expression_Recognition_Method_based_on_Emotion_Probability_CVPRW_2024_paper.html": {
    "title": "Zero-Shot Audio-Visual Compound Expression Recognition Method based on Emotion Probability Fusion",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Elena Ryumina",
      "Maxim Markitantov",
      "Dmitry Ryumin",
      "Heysem Kaya",
      "Alexey Karpov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Khan_Drone-HAT_Hybrid_Attention_Transformer_for_Complex_Action_Recognition_in_Drone_CVPRW_2024_paper.html": {
    "title": "Drone-HAT: Hybrid Attention Transformer for Complex Action Recognition in Drone Surveillance Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mustaqeem Khan",
      "Jamil Ahmad",
      "Abdulmotaleb El Saddik",
      "Wail Gueaieb",
      "Giulia De Masi",
      "Fakhri Karray"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Yu_AUD-TGN_Advancing_Action_Unit_Detection_with_Temporal_Convolution_and_GPT-2_CVPRW_2024_paper.html": {
    "title": "AUD-TGN: Advancing Action Unit Detection with Temporal Convolution and GPT-2 in Wild Audiovisual Contexts",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yu",
      "Zerui Zhang",
      "Zhihong Wei",
      "Gongpeng Zhao",
      "Zhongpeng Cai",
      "Yongqi Wang",
      "Guochen Xie",
      "Jichao Zhu",
      "Wangyuan Zhu",
      "Qingsong Liu",
      "Jiaen Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Yu_Multi_Model_Ensemble_for_Compound_Expression_Recognition_CVPRW_2024_paper.html": {
    "title": "Multi Model Ensemble for Compound Expression Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yu",
      "Jichao Zhu",
      "Wangyuan Zhu",
      "Zhongpeng Cai",
      "Gongpeng Zhao",
      "Zhihong Wei",
      "Guochen Xie",
      "Zerui Zhang",
      "Qingsong Liu",
      "Jiaen Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Lino_3D_Human_Pose_Estimation_with_Occlusions_Introducing_BlendMimic3D_Dataset_and_CVPRW_2024_paper.html": {
    "title": "3D Human Pose Estimation with Occlusions: Introducing BlendMimic3D Dataset and GCN Refinement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filipa Lino",
      "Carlos Santiago",
      "Manuel Marques"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Min_Emotion_Recognition_Using_Transformers_with_Random_Masking_CVPRW_2024_paper.html": {
    "title": "Emotion Recognition Using Transformers with Random Masking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seongjae Min",
      "Junseok Yang",
      "Sejoon Lim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Praveen_Recursive_Joint_Cross-Modal_Attention_for_Multimodal_Fusion_in_Dimensional_Emotion_CVPRW_2024_paper.html": {
    "title": "Recursive Joint Cross-Modal Attention for Multimodal Fusion in Dimensional Emotion Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "R. Gnana Praveen",
      "Jahangir Alam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Zhang_An_Effective_Ensemble_Learning_Framework_for_Affective_Behaviour_Analysis_CVPRW_2024_paper.html": {
    "title": "An Effective Ensemble Learning Framework for Affective Behaviour Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhang",
      "Feng Qiu",
      "Chen Liu",
      "Lincheng Li",
      "Heming Du",
      "Tianchen Guo",
      "Xin Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Dhake_Unravelling_Robustness_of_Deep_Face_Recognition_Networks_Against_Illicit_Drug_CVPRW_2024_paper.html": {
    "title": "Unravelling Robustness of Deep Face Recognition Networks Against Illicit Drug Abuse Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hruturaj Dhake",
      "Akshay Agarwal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Dresvyanskiy_Multi-modal_Arousal_and_Valence_Estimation_under_Noisy_Conditions_CVPRW_2024_paper.html": {
    "title": "Multi-modal Arousal and Valence Estimation under Noisy Conditions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Denis Dresvyanskiy",
      "Maxim Markitantov",
      "Jiawei Yu",
      "Heysem Kaya",
      "Alexey Karpov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Yao_Evaluating_the_Effectiveness_of_Video_Anomaly_Detection_in_the_Wild_CVPRW_2024_paper.html": {
    "title": "Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shanle Yao",
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Hamed Tabkhi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Waligora_Joint_Multimodal_Transformer_for_Emotion_Recognition_in_the_Wild_CVPRW_2024_paper.html": {
    "title": "Joint Multimodal Transformer for Emotion Recognition in the Wild",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paul Waligora",
      "Muhammad Haseeb Aslam",
      "Muhammad Osama Zeeshan",
      "Soufiane Belharbi",
      "Alessandro Lameiras Koerich",
      "Marco Pedersoli",
      "Simon Bacon",
      "Eric Granger"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Nguyen_Emotic_Masked_Autoencoder_on_Dual-views_with_Attention_Fusion_for_Facial_CVPRW_2024_paper.html": {
    "title": "Emotic Masked Autoencoder on Dual-views with Attention Fusion for Facial Expression Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan-Bach Nguyen",
      "Hoang-Thien Nguyen",
      "Thanh-Huy Nguyen",
      "Nhu-Tai Do",
      "Quang Vinh Dinh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Hardy_Unsupervised_Multi-Person_3D_Human_Pose_Estimation_From_2D_Poses_Alone_CVPRW_2024_paper.html": {
    "title": "Unsupervised Multi-Person 3D Human Pose Estimation From 2D Poses Alone",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Peter Hardy",
      "Hansung Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Wu_CMOSE_Comprehensive_Multi-Modality_Online_Student_Engagement_Dataset_with_High-Quality_Labels_CVPRW_2024_paper.html": {
    "title": "CMOSE: Comprehensive Multi-Modality Online Student Engagement Dataset with High-Quality Labels",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chi-Hsuan Wu",
      "Shih-Yang Liu",
      "Xijie Huang",
      "Xingbo Wang",
      "Rong Zhang",
      "Luca Minciullo",
      "Wong Kai Yiu",
      "Kenny Kwan",
      "Kwang-Ting Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Strizhkova_Video_Representation_Learning_for_Conversational_Facial_Expression_Recognition_Guided_by_CVPRW_2024_paper.html": {
    "title": "Video Representation Learning for Conversational Facial Expression Recognition Guided by Multiple View Reconstruction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Valeriya Strizhkova",
      "Laura M. Ferrari",
      "Hadi Kachmar",
      "Antitza Dantcheva",
      "Francois Bremond"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Senadeera_CUE-Net_Violence_Detection_Video_Analytics_with_Spatial_Cropping_Enhanced_UniformerV2_CVPRW_2024_paper.html": {
    "title": "CUE-Net: Violence Detection Video Analytics with Spatial Cropping Enhanced UniformerV2 and Modified Efficient Additive Attention",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Damith Chamalke Senadeera",
      "Xiaoyun Yang",
      "Dimitrios Kollias",
      "Gregory Slabaugh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Chumachenko_MMA-DFER_MultiModal_Adaptation_of_Unimodal_Models_for_Dynamic_Facial_Expression_CVPRW_2024_paper.html": {
    "title": "MMA-DFER: MultiModal Adaptation of Unimodal Models for Dynamic Facial Expression Recognition In-the-wild",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kateryna Chumachenko",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Yu_Efficient_Feature_Extraction_and_Late_Fusion_Strategy_for_Audiovisual_Emotional_CVPRW_2024_paper.html": {
    "title": "Efficient Feature Extraction and Late Fusion Strategy for Audiovisual Emotional Mimicry Intensity Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yu",
      "Wangyuan Zhu",
      "Jichao Zhu",
      "Zhongpeng Cai",
      "Gongpeng Zhao",
      "Zerui Zhang",
      "Guochen Xie",
      "Zhihong Wei",
      "Qingsong Liu",
      "Jiaen Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Halawa_Multi-Task_Multi-Modal_Self-Supervised_Learning_for_Facial_Expression_Recognition_CVPRW_2024_paper.html": {
    "title": "Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marah Halawa",
      "Florian Blume",
      "Pia Bideau",
      "Martin Maier",
      "Rasha Abdel Rahman",
      "Olaf Hellwich"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Savchenko_Leveraging_Pre-trained_Multi-task_Deep_Models_for_Trustworthy_Facial_Analysis_in_CVPRW_2024_paper.html": {
    "title": "Leveraging Pre-trained Multi-task Deep Models for Trustworthy Facial Analysis in Affective Behaviour Analysis In-the-Wild",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrey V. Savchenko"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Qiu_Language-guided_Multi-modal_Emotional_Mimicry_Intensity_Estimation_CVPRW_2024_paper.html": {
    "title": "Language-guided Multi-modal Emotional Mimicry Intensity Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Qiu",
      "Wei Zhang",
      "Chen Liu",
      "Lincheng Li",
      "Heming Du",
      "Tianchen Guo",
      "Xin Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Zhang_REFA_Real-time_Egocentric_Facial_Animations_for_Virtual_Reality_CVPRW_2024_paper.html": {
    "title": "REFA: Real-time Egocentric Facial Animations for Virtual Reality",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qiang Zhang",
      "Tong Xiao",
      "Haroun Habeeb",
      "Larissa Laich",
      "Sofien Bouaziz",
      "Patrick Snape",
      "Wenjing Zhang",
      "Matthew Cioffi",
      "Peizhao Zhang",
      "Pavel Pidlypenskyi",
      "Winnie Lin",
      "Luming Ma",
      "Mengjiao Wang",
      "Kunpeng Li",
      "Chengjiang Long",
      "Steven Song",
      "Martin Prazak",
      "Alexander Sjoholm",
      "Ajinkya Deogade",
      "Jaebong Lee",
      "Julio Delgado Mangas",
      "Amaury Aubel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Hallmen_Unimodal_Multi-Task_Fusion_for_Emotional_Mimicry_Intensity_Prediction_CVPRW_2024_paper.html": {
    "title": "Unimodal Multi-Task Fusion for Emotional Mimicry Intensity Prediction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias Hallmen",
      "Fabian Deuser",
      "Norbert Oswald",
      "Elisabeth André"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Qiu_Learning_Transferable_Compound_Expressions_from_Masked_AutoEncoder_Pretraining_CVPRW_2024_paper.html": {
    "title": "Learning Transferable Compound Expressions from Masked AutoEncoder Pretraining",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feng Qiu",
      "Heming Du",
      "Wei Zhang",
      "Chen Liu",
      "Lincheng Li",
      "Tianchen Guo",
      "Xin Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Kumar_Uncovering_Hidden_Emotions_with_Adaptive_Multi-Attention_Graph_Networks_CVPRW_2024_paper.html": {
    "title": "Uncovering Hidden Emotions with Adaptive Multi-Attention Graph Networks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ankith Jain Rakesh Kumar",
      "Bir Bhanu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Kollias_The_6th_Affective_Behavior_Analysis_In-the-wild_ABAW_Competition_CVPRW_2024_paper.html": {
    "title": "The 6th Affective Behavior Analysis In-the-wild (ABAW) Competition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dimitrios Kollias",
      "Panagiotis Tzirakis",
      "Alan Cowen",
      "Stefanos Zafeiriou",
      "Irene Kotsia",
      "Alice Baird",
      "Chris Gagne",
      "Chunchang Shao",
      "Guanyu Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Savchenko_EmotiEffNet_and_Temporal_Convolutional_Networks_in_Video-based_Facial_Expression_Recognition_CVPRW_2024_paper.html": {
    "title": "EmotiEffNet and Temporal Convolutional Networks in Video-based Facial Expression Recognition and Action Unit Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrey V. Savchenko",
      "Anna P. Sidorova"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Wagner_CAGE_Circumplex_Affect_Guided_Expression_Inference_CVPRW_2024_paper.html": {
    "title": "CAGE: Circumplex Affect Guided Expression Inference",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niklas Wagner",
      "Felix Mätzler",
      "Samed R. Vossberg",
      "Helen Schneider",
      "Svetlana Pavlitska",
      "J. Marius Zöllner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/ABAW/html/Yu_Exploring_Facial_Expression_Recognition_through_Semi-Supervised_Pre-training_and_Temporal_Modeling_CVPRW_2024_paper.html": {
    "title": "Exploring Facial Expression Recognition through Semi-Supervised Pre-training and Temporal Modeling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Yu",
      "Zhihong Wei",
      "Zhongpeng Cai",
      "Gongpeng Zhao",
      "Zerui Zhang",
      "Yongqi Wang",
      "Guochen Xie",
      "Jichao Zhu",
      "Wangyuan Zhu",
      "Qingsong Liu",
      "Jiaen Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Li_Advancing_COVID-19_Detection_in_3D_CT_Scans_CVPRW_2024_paper.html": {
    "title": "Advancing COVID-19 Detection in 3D CT Scans",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qingqiu Li",
      "Runtian Yuan",
      "Junlin Hou",
      "Jilan Xu",
      "Yuejie Zhang",
      "Rui Feng",
      "Hao Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Bougourzi_Deep-Adaptation_Ensembling_and_Test_Augmentation_for_Covid-19_Detection_and_Covid-19_CVPRW_2024_paper.html": {
    "title": "Deep-Adaptation: Ensembling and Test Augmentation for Covid-19 Detection and Covid-19 Domain Adaptation from 3D CT-Scans",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fares Bougourzi",
      "Feryal Windal Moulai",
      "Halim Benhabiles",
      "Fadi Dornaika",
      "Abdelmalik Taleb-Ahmed"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Aleem_Test-Time_Adaptation_with_SaLIP_A_Cascade_of_SAM_and_CLIP_CVPRW_2024_paper.html": {
    "title": "Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero-shot Medical Image Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sidra Aleem",
      "Fangyijie Wang",
      "Mayug Maniparambil",
      "Eric Arazo",
      "Julia Dietlmeier",
      "Kathleen Curran",
      "Noel E. O' Connor",
      "Suzanne Little"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Spanos_Complex_Style_Image_Transformations_for_Domain_Generalization_in_Medical_Images_CVPRW_2024_paper.html": {
    "title": "Complex Style Image Transformations for Domain Generalization in Medical Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikolaos Spanos",
      "Anastasios Arsenos",
      "Paraskevi-Antonia Theofilou",
      "Paraskevi Tzouveli",
      "Athanasios Voulodimos",
      "Stefanos Kollias"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Nguyen_ConPro_Learning_Severity_Representation_for_Medical_Images_using_Contrastive_Learning_CVPRW_2024_paper.html": {
    "title": "ConPro: Learning Severity Representation for Medical Images using Contrastive Learning and Preference Optimization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hong Nguyen",
      "Hoang Nguyen",
      "Melinda Chang",
      "Hieu Pham",
      "Shrikanth Narayanan",
      "Michael Pazzani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Ellis_Classification_of_2D_Ultrasound_Breast_Cancer_Images_with_Deep_Learning_CVPRW_2024_paper.html": {
    "title": "Classification of 2D Ultrasound Breast Cancer Images with Deep Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jack Ellis",
      "Kofi Appiah",
      "Emmanuel Amankwaa-Frempong",
      "Sze Chai Kwok"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Cardoso_Using_Counterfactual_Information_for_Breast_Classification_Diagnosis_CVPRW_2024_paper.html": {
    "title": "Using Counterfactual Information for Breast Classification Diagnosis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Cardoso",
      "Carlos Santiago",
      "Jacinto C. Nascimento"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Gu_LaPA_Latent_Prompt_Assist_Model_For_Medical_Visual_Question_Answering_CVPRW_2024_paper.html": {
    "title": "LaPA: Latent Prompt Assist Model For Medical Visual Question Answering",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiancheng Gu",
      "Kaicheng Yang",
      "Dongnan Liu",
      "Weidong Cai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Nguyen_Blurry-Consistency_Segmentation_Framework_with_Selective_Stacking_on_Differential_Interference_Contrast_CVPRW_2024_paper.html": {
    "title": "Blurry-Consistency Segmentation Framework with Selective Stacking on Differential Interference Contrast 3D Breast Cancer Spheroid",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh-Huy Nguyen",
      "Thi Kim Ngan Ngo",
      "Mai Anh Vu",
      "Ting-Yuan Tu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Hsu_A_Closer_Look_at_Spatial-Slice_Features_Learning_for_COVID-19_Detection_CVPRW_2024_paper.html": {
    "title": "A Closer Look at Spatial-Slice Features Learning for COVID-19 Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Yang Fan Chiang",
      "Yi-Shiuan Chou",
      "Chih-Yu Jiang",
      "Shen-Chieh Tai",
      "Chi-Han Tsai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Rahman_PP-SAM_Perturbed_Prompts_for_Robust_Adaption_of_Segment_Anything_Model_CVPRW_2024_paper.html": {
    "title": "PP-SAM: Perturbed Prompts for Robust Adaption of Segment Anything Model for Polyp Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Mostafijur Rahman",
      "Mustafa Munir",
      "Debesh Jha",
      "Ulas Bagci",
      "Radu Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Kollias_Domain_Adaptation_Explainability__Fairness_in_AI_for_Medical_Image_CVPRW_2024_paper.html": {
    "title": "Domain Adaptation Explainability & Fairness in AI for Medical Image Analysis: Diagnosis of COVID-19 based on 3-D Chest CT-scans",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dimitrios Kollias",
      "Anastasios Arsenos",
      "Stefanos Kollias"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Perera_SegFormer3D_An_Efficient_Transformer_for_3D_Medical_Image_Segmentation_CVPRW_2024_paper.html": {
    "title": "SegFormer3D: An Efficient Transformer for 3D Medical Image Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shehan Perera",
      "Pouyan Navard",
      "Alper Yilmaz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Yuan_Domain_Adaptation_Using_Pseudo_Labels_for_COVID-19_Detection_CVPRW_2024_paper.html": {
    "title": "Domain Adaptation Using Pseudo Labels for COVID-19 Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Runtian Yuan",
      "Qingqiu Li",
      "Junlin Hou",
      "Jilan Xu",
      "Yuejie Zhang",
      "Rui Feng",
      "Hao Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Yang_FPN-IAIA-BL_A_Multi-Scale_Interpretable_Deep_Learning_Model_for_Classification_of_CVPRW_2024_paper.html": {
    "title": "FPN-IAIA-BL: A Multi-Scale Interpretable Deep Learning Model for Classification of Mass Margins in Digital Mammography",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julia Yang",
      "Alina Jade Barnett",
      "Jon Donnelly",
      "Satvik Kishore",
      "Jerry Fang",
      "Fides Regina Schwartz",
      "Chaofan Chen",
      "Joseph Y. Lo",
      "Cynthia Rudin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Wang_Achieving_Reliable_and_Fair_Skin_Lesion_Diagnosis_via_Unsupervised_Domain_CVPRW_2024_paper.html": {
    "title": "Achieving Reliable and Fair Skin Lesion Diagnosis via Unsupervised Domain Adaptation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Janet Wang",
      "Yunbei Zhang",
      "Zhengming Ding",
      "Jihun Hamm"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Lai_Residual-based_Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks_CVPRW_2024_paper.html": {
    "title": "Residual-based Language Models are Free Boosters for Biomedical Imaging Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhixin Lai",
      "Jing Wu",
      "Suiyao Chen",
      "Yucheng Zhou",
      "Naira Hovakimyan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Zhang_Focusing_on_What_Matters_Fine-grained_Medical_Activity_Recognition_for_Trauma_CVPRW_2024_paper.html": {
    "title": "Focusing on What Matters: Fine-grained Medical Activity Recognition for Trauma Resuscitation via Actor Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenjin Zhang",
      "Keyi Li",
      "Sen Yang",
      "Sifan Yuan",
      "Ivan Marsic",
      "Genevieve J. Sippel",
      "Mary S. Kim",
      "Randall S. Burd"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Dehghani_Evaluating_Confidence_Calibration_in_Endoscopic_Diagnosis_Models_CVPRW_2024_paper.html": {
    "title": "Evaluating Confidence Calibration in Endoscopic Diagnosis Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikoo Dehghani",
      "Ayla Thijssen",
      "Quirine E. W. Van Der Zander",
      "Ramon-Michel Schreuder",
      "Erik J. Schoon",
      "Fons Van Der Sommen",
      "Peter H. N. De With"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Wood_Cluster_Triplet_Loss_for_Unsupervised_Domain_Adaptation_on_Histology_Images_CVPRW_2024_paper.html": {
    "title": "Cluster Triplet Loss for Unsupervised Domain Adaptation on Histology Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruby Wood",
      "Enric Domingo",
      "Viktor Hendrik Koelzer",
      "Timothy S. Maughan",
      "Jens Rittscher"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Farag_EfficientNet-SAM_A_Novel_EffecientNet_with_Spatial_Attention_Mechanism_for_COVID-19_CVPRW_2024_paper.html": {
    "title": "EfficientNet-SAM: A Novel EffecientNet with Spatial Attention Mechanism for COVID-19 Detection in Pulmonary CT Scans",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramy Farag",
      "Parth Upadhay",
      "Jacket Dembys",
      "Yixiang Gao",
      "Katherin Garces Montoya",
      "Seyed Mohamad Ali Tousi",
      "Gbenga Omotara",
      "Guilherme Desouza"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Zohranyan_Dr-SAM_An_End-to-End_Framework_for_Vascular_Segmentation_Diameter_Estimation_and_CVPRW_2024_paper.html": {
    "title": "Dr-SAM: An End-to-End Framework for Vascular Segmentation Diameter Estimation and Anomaly Detection on Angiography Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vazgen Zohranyan",
      "Vagner Navasardyan",
      "Hayk Navasardyan",
      "Jan Borggrefe",
      "Shant Navasardyan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Anglada-Rotger_Enhancing_Ki-67_Cell_Segmentation_with_Dual_U-Net_Models_A_Step_CVPRW_2024_paper.html": {
    "title": "Enhancing Ki-67 Cell Segmentation with Dual U-Net Models: A Step Towards Uncertainty-Informed Active Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Anglada-Rotger",
      "Julia Sala",
      "Ferran Marques",
      "Philippe Salembier",
      "Montse Pardàs"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Zhang_Improving_Consistency_in_Cardiovascular_Disease_Risk_Assessment_Cross-Camera_Adaptation_for_CVPRW_2024_paper.html": {
    "title": "Improving Consistency in Cardiovascular Disease Risk Assessment: Cross-Camera Adaptation for Retinal Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyi Zhang",
      "Danli Shi",
      "Mingguang He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Rahaman_A_Deep_Biclustering_Framework_for_Brain_Network_Analysis_CVPRW_2024_paper.html": {
    "title": "A Deep Biclustering Framework for Brain Network Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Abdur Rahaman",
      "Zening Fu",
      "Armin Iraji",
      "Vince Calhoun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Rao_IMIL_Interactive_Medical_Image_Learning_Framework_CVPRW_2024_paper.html": {
    "title": "IMIL: Interactive Medical Image Learning Framework",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrit Rao",
      "Andrea Fisher",
      "Ken Chang",
      "John Christopher Panagides",
      "Katherine Mcnamara",
      "Joon-Young Lee",
      "Oliver Aalami"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Turnbull_Separating_Lungs_in_CT_Scans_for_Improved_COVID19_Detection_CVPRW_2024_paper.html": {
    "title": "Separating Lungs in CT Scans for Improved COVID19 Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Robert Turnbull",
      "Simon Mutch"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Araujo_Key_Patches_Are_All_You_Need_A_Multiple_Instance_Learning_CVPRW_2024_paper.html": {
    "title": "Key Patches Are All You Need: A Multiple Instance Learning Framework For Robust Medical Diagnosis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "D.J. Araújo",
      "M.R. Verdelho",
      "A. Bissoto",
      "J.C. Nascimento",
      "C. Santiago",
      "C. Barata"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Nguyen_Fetal_ECG_Extraction_on_Time-Frequency_Domain_using_Conditional_GAN_CVPRW_2024_paper.html": {
    "title": "Fetal ECG Extraction on Time-Frequency Domain using Conditional GAN",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vuong D. Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Hernandez-Perez_Bridging_Domains_in_Melanoma_Diagnostics_Predicting_BRAF_Mutations_and_Sentinel_CVPRW_2024_paper.html": {
    "title": "Bridging Domains in Melanoma Diagnostics: Predicting BRAF Mutations and Sentinel Lymph Node Positivity with Attention-Based Models in Histological Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Carlos Hernandez-Perez",
      "Lauren Jimenez-Martin",
      "Veronica Vilaplana"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Zhao_One_Class_Classification-based_Quality_Assurance_of_Organs-at-risk_Delineation_in_Radiotherapy_CVPRW_2024_paper.html": {
    "title": "One Class Classification-based Quality Assurance of Organs-at-risk Delineation in Radiotherapy",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihao Zhao",
      "Cuiyun Yuan",
      "Ying Liang",
      "Yang Li",
      "Chunxia Li",
      "Man Zhao",
      "Jun Hu",
      "Ningze Zhong",
      "Chenbin Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Pandey_Interpreting_COVID_Lateral_Flow_Tests_Results_with_Foundation_Models_CVPRW_2024_paper.html": {
    "title": "Interpreting COVID Lateral Flow Tests' Results with Foundation Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stuti Pandey",
      "Josh Myers-Dean",
      "Jarek Reynolds",
      "Danna Gurari"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Pina_Unsupervised_Domain_Adaptation_for_Multi-Stain_Cell_Detection_in_Breast_Cancer_CVPRW_2024_paper.html": {
    "title": "Unsupervised Domain Adaptation for Multi-Stain Cell Detection in Breast Cancer with Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oscar Pina",
      "Verónica Vilaplana"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Singh_Prototype-based_Interpretable_Model_for_Glaucoma_Detection_CVPRW_2024_paper.html": {
    "title": "Prototype-based Interpretable Model for Glaucoma Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohana Singh",
      "B S Vivek",
      "Jayavardhana Gubbi",
      "Arpan Pal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Loaliyan_Comparative_Analysis_of_Generalization_and_Harmonization_Methods_for_3D_Brain_CVPRW_2024_paper.html": {
    "title": "Comparative Analysis of Generalization and Harmonization Methods for 3D Brain fMRI Images: A Case Study on OpenBHB Dataset",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soroosh Safari Loaliyan",
      "Greg Ver Steeg"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Zhang_Source-free_Domain_Adaptation_for_Video_Object_Detection_Under_Adverse_Image_CVPRW_2024_paper.html": {
    "title": "Source-free Domain Adaptation for Video Object Detection Under Adverse Image Conditions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingguang Zhang",
      "Chih-Hsien Chou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Diana-Albelda_How_SAM_Perceives_Different_mp-MRI_Brain_Tumor_Domains_CVPRW_2024_paper.html": {
    "title": "How SAM Perceives Different mp-MRI Brain Tumor Domains?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cecilia Diana-Albelda",
      "Roberto Alcover-Couso",
      "Álvaro García-Martín",
      "Jesus Bescos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Dong_Medical_Image_Segmentation_with_InTEnt_Integrated_Entropy_Weighting_for_Single_CVPRW_2024_paper.html": {
    "title": "Medical Image Segmentation with InTEnt: Integrated Entropy Weighting for Single Image Test-Time Adaptation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyu Dong",
      "Nicholas Konz",
      "Hanxue Gu",
      "Maciej A. Mazurowski"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/Hl_A_Multimodal_Approach_Integrating_Convolutional_and_Recurrent_Neural_Networks_for_CVPRW_2024_paper.html": {
    "title": "A Multimodal Approach Integrating Convolutional and Recurrent Neural Networks for Alzheimer's Disease Temporal Progression Prediction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Durga Supriya Hl",
      "Swetha Mary Thomas",
      "Sowmya Kamath S"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/html/M_DCE-diff_Diffusion_Model_for_Synthesis_of_Early_and_Late_Dynamic_CVPRW_2024_paper.html": {
    "title": "DCE-diff: Diffusion Model for Synthesis of Early and Late Dynamic Contrast-Enhanced MR Images from Non-Contrast Multimodal Inputs",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kishore Kumar M",
      "Sriprabha Ramanarayanan",
      "Sadhana S",
      "Arunima Sarkar",
      "Matcha Naga Gayathri",
      "Keerthi Ram",
      "Mohanasankar Sivaprakasam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DLGC/html/Hong_RDPN6D_Residual-based_Dense_Point-wise_Network_for_6Dof_Object_Pose_Estimation_CVPRW_2024_paper.html": {
    "title": "RDPN6D: Residual-based Dense Point-wise Network for 6Dof Object Pose Estimation Based on RGB-D Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zong-Wei Hong",
      "Yen-Yang Hung",
      "Chu-Song Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DLGC/html/Tabib_LGAfford-Net_A_Local_Geometry_Aware_Affordance_Detection_Network_for_3D_CVPRW_2024_paper.html": {
    "title": "LGAfford-Net: A Local Geometry Aware Affordance Detection Network for 3D Point Clouds",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ramesh Ashok Tabib",
      "Dikshit Hegde",
      "Uma Mudenagudi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DLGC/html/Jignasu_SDFConnect_Neural_Implicit_Surface_Reconstruction_of_a_Sparse_Point_Cloud_CVPRW_2024_paper.html": {
    "title": "SDFConnect: Neural Implicit Surface Reconstruction of a Sparse Point Cloud with Topological Constraints",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anushrut Jignasu",
      "Aditya Balu",
      "Soumik Sarkar",
      "Chinmay Hegde",
      "Baskar Ganapathysubramanian",
      "Adarsh Krishnamurthy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EvGenFM/html/Ji_T2VBench_Benchmarking_Temporal_Dynamics_for_Text-to-Video_Generation_CVPRW_2024_paper.html": {
    "title": "T2VBench: Benchmarking Temporal Dynamics for Text-to-Video Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengliang Ji",
      "Chuyang Xiao",
      "Huilin Tai",
      "Mingxiao Huo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EvGenFM/html/Cho_Diagnostic_Benchmark_and_Iterative_Inpainting_for_Layout-Guided_Image_Generation_CVPRW_2024_paper.html": {
    "title": "Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jaemin Cho",
      "Linjie Li",
      "Zhengyuan Yang",
      "Zhe Gan",
      "Lijuan Wang",
      "Mohit Bansal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EvGenFM/html/Ji_TlTScore_Towards_Long-Tail_Effects_in_Text-to-Visual_Evaluation_with_Generative_Foundation_CVPRW_2024_paper.html": {
    "title": "TlTScore: Towards Long-Tail Effects in Text-to-Visual Evaluation with Generative Foundation Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pengliang Ji",
      "Junchen Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EvGenFM/html/Li_Evaluating_and_Improving_Compositional_Text-to-Visual_Generation_CVPRW_2024_paper.html": {
    "title": "Evaluating and Improving Compositional Text-to-Visual Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baiqi Li",
      "Zhiqiu Lin",
      "Deepak Pathak",
      "Jiayao Li",
      "Yixin Fei",
      "Kewen Wu",
      "Xide Xia",
      "Pengchuan Zhang",
      "Graham Neubig",
      "Deva Ramanan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/EvGenFM/html/Verma_Evaluating_Multimodal_Large_Language_Models_Across_Distribution_Shifts_and_Augmentations_CVPRW_2024_paper.html": {
    "title": "Evaluating Multimodal Large Language Models Across Distribution Shifts and Augmentations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aayush Atul Verma",
      "Amir Saeidi",
      "Shamanthak Hegde",
      "Ajay Therala",
      "Fenil Denish Bardoliya",
      "Nagaraju Machavarapu",
      "Shri Ajay Kumar Ravindhiran",
      "Srija Malyala",
      "Agneet Chatterjee",
      "Yezhou Yang",
      "Chitta Baral"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Angarano_Domain_Generalization_for_Crop_Segmentation_with_Standardized_Ensemble_Knowledge_Distillation_CVPRW_2024_paper.html": {
    "title": "Domain Generalization for Crop Segmentation with Standardized Ensemble Knowledge Distillation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simone Angarano",
      "Mauro Martini",
      "Alessandro Navone",
      "Marcello Chiaberge"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Cieslak_Generating_Diverse_Agricultural_Data_for_Vision-Based_Farming_Applications_CVPRW_2024_paper.html": {
    "title": "Generating Diverse Agricultural Data for Vision-Based Farming Applications",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mikolaj Cieslak",
      "Umabharathi Govindarajan",
      "Alejandro Garcia",
      "Anuradha Chandrashekar",
      "Torsten Hadrich",
      "Aleksander Mendoza-Drosik",
      "Dominik L. Michels",
      "Soren Pirk",
      "Chia-Chun Fu",
      "Wojciech Palubicki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Yun_VisTA-SR_Improving_the_Accuracy_and_Resolution_of_Low-Cost_Thermal_Imaging_CVPRW_2024_paper.html": {
    "title": "VisTA-SR: Improving the Accuracy and Resolution of Low-Cost Thermal Imaging Cameras for Agriculture",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heesup Yun",
      "Sassoum Lo",
      "Christine H. Diepenbrock",
      "Brian N. Bailey",
      "J. Mason Earles"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Hartley_Domain_Targeted_Synthetic_Plant_Style_Transfer_using_Stable_Diffusion_LoRA_CVPRW_2024_paper.html": {
    "title": "Domain Targeted Synthetic Plant Style Transfer using Stable Diffusion LoRA and ControlNet",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zane K.J. Hartley",
      "Rob J. Lind",
      "Michael P. Pound",
      "Andrew P. French"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Li_Photorealistic_Arm_Robot_Simulation_for_3D_Plant_Reconstruction_and_Automatic_CVPRW_2024_paper.html": {
    "title": "Photorealistic Arm Robot Simulation for 3D Plant Reconstruction and Automatic Annotation using Unreal Engine 5",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingjian Li",
      "Jeremy Park",
      "Chris Reberg-Horton",
      "Steven Mirsky",
      "Edgar Lobaton",
      "Lirong Xiang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Cardoen_Label_Efficient_Lifelong_Multi-View_Broiler_Detection_CVPRW_2024_paper.html": {
    "title": "Label Efficient Lifelong Multi-View Broiler Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thorsten Cardoen",
      "Sam Leroux",
      "Pieter Simoens"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Matos_Tracking_and_Counting_Apples_in_Orchards_Under_Intermittent_Occlusions_and_CVPRW_2024_paper.html": {
    "title": "Tracking and Counting Apples in Orchards Under Intermittent Occlusions and Low Frame Rates",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gonçalo P. Matos",
      "Carlos Santiago",
      "João P. Costeira",
      "Ricardo L. Saldanha",
      "Ernesto M. Morgado"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Xu_HarvestNet_A_Dataset_for_Detecting_Smallholder_Farming_Activity_Using_Harvest_CVPRW_2024_paper.html": {
    "title": "HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using Harvest Piles and Remote Sensing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Xu",
      "Amna Elmustafa",
      "Liya Weldegebriel",
      "Emnet Negash",
      "Richard Lee",
      "Chenlin Meng",
      "Stefano Ermon",
      "David Lobell"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Sarker_Gasformer_A_Transformer-based_Architecture_for_Segmenting_Methane_Emissions_from_Livestock_CVPRW_2024_paper.html": {
    "title": "Gasformer: A Transformer-based Architecture for Segmenting Methane Emissions from Livestock in Optical Gas Imaging",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Toqi Tahamid Sarker",
      "Mohamed G Embaby",
      "Khaled R Ahmed",
      "Amer Abughazaleh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Hoque_IrrNet_Advancing_Irrigation_Mapping_with_Incremental_Patch_Size_Training_on_CVPRW_2024_paper.html": {
    "title": "IrrNet: Advancing Irrigation Mapping with Incremental Patch Size Training on Remote Sensing Imagery",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oishee Bintey Hoque",
      "Samarth Swarup",
      "Abhijin Adiga",
      "Sayjro Kossi Nouwakpo",
      "Madhav Marathe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Mohan_Lacunarity_Pooling_Layers_for_Plant_Image_Classification_using_Texture_Analysis_CVPRW_2024_paper.html": {
    "title": "Lacunarity Pooling Layers for Plant Image Classification using Texture Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akshatha Mohan",
      "Joshua Peeples"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Asad_Improved_Crop_and_Weed_Detection_with_Diverse_Data_Ensemble_Learning_CVPRW_2024_paper.html": {
    "title": "Improved Crop and Weed Detection with Diverse Data Ensemble Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Hamza Asad",
      "Saeed Anwar",
      "Abdul Bais"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Li_Knowledge_Distillation_for_Efficient_Instance_Semantic_Segmentation_with_Transformers_CVPRW_2024_paper.html": {
    "title": "Knowledge Distillation for Efficient Instance Semantic Segmentation with Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maohui Li",
      "Michael Halstead",
      "Chris Mccool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Majewski_End-to-end_Solution_for_Tenebrio_Molitor_Rearing_Monitoring_with_Uncertainty_Estimation_CVPRW_2024_paper.html": {
    "title": "End-to-end Solution for Tenebrio Molitor Rearing Monitoring with Uncertainty Estimation and Domain Shift Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paweł Majewski",
      "Piotr Lampa",
      "Robert Burduk",
      "Jacek Reiner"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Shikhar_Label-free_Anomaly_Detection_in_Aerial_Agricultural_Images_with_Masked_Image_CVPRW_2024_paper.html": {
    "title": "Label-free Anomaly Detection in Aerial Agricultural Images with Masked Image Modeling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sambal Shikhar",
      "Anupam Sobti"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Wu_The_New_Agronomists_Language_Models_are_Experts_in_Crop_Management_CVPRW_2024_paper.html": {
    "title": "The New Agronomists: Language Models are Experts in Crop Management",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Wu",
      "Zhixin Lai",
      "Suiyao Chen",
      "Ran Tao",
      "Pan Zhao",
      "Naira Hovakimyan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Waqar_End-to-End_Deep_Learning_Models_for_Gap_Identification_in_Maize_Fields_CVPRW_2024_paper.html": {
    "title": "End-to-End Deep Learning Models for Gap Identification in Maize Fields",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rana Waqar",
      "Željana Grbović",
      "Maryam Khan",
      "Nina Pajević",
      "Dimitrije Stefanović",
      "Vladan Filipović",
      "Marko Panić",
      "Nemanja Djuric"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/html/Zawish_Energy-Efficient_Uncertainty-Aware_Biomass_Composition_Prediction_at_the_Edge_CVPRW_2024_paper.html": {
    "title": "Energy-Efficient Uncertainty-Aware Biomass Composition Prediction at the Edge",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammad Zawish",
      "Paul Albert",
      "Flavio Esposito",
      "Steven Davy",
      "Lizy Abraham"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/html/Xiao_GM-DETR_Generalized_Muiltispectral_DEtection_TRansformer_with_Efficient_Fusion_Encoder_for_CVPRW_2024_paper.html": {
    "title": "GM-DETR: Generalized Muiltispectral DEtection TRansformer with Efficient Fusion Encoder for Visible-Infrared Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiming Xiao",
      "Fanman Meng",
      "Qingbo Wu",
      "Linfeng Xu",
      "Mingzhou He",
      "Hongliang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/html/Qiu_HumanFormer_Human-centric_Prompting_Multi-modal_Perception_Transformer_for_Referring_Crowd_Detection_CVPRW_2024_paper.html": {
    "title": "HumanFormer: Human-centric Prompting Multi-modal Perception Transformer for Referring Crowd Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heqian Qiu",
      "Lanxiao Wang",
      "Taijin Zhao",
      "Fanman Meng",
      "Hongliang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/html/Li_DSTCFuse_A_Method_based_on_Dual-cycled_Cross-awareness_of_Structure_Tensor_CVPRW_2024_paper.html": {
    "title": "DSTCFuse: A Method based on Dual-cycled Cross-awareness of Structure Tensor for Semantic Segmentation via Infrared and Visible Image Fusion",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuan Li",
      "Rongfu Chen",
      "Jie Wang",
      "Lei Ma",
      "Li Cheng",
      "Haiwen Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/html/Zhang_InViG_Benchmarking_Open-Ended_Interactive_Visual_Grounding_with_500K_Dialogues_CVPRW_2024_paper.html": {
    "title": "InViG: Benchmarking Open-Ended Interactive Visual Grounding with 500K Dialogues",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanbo Zhang",
      "Jie Xu",
      "Yuchen Mo",
      "Tao Kong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/html/Cheng_Must_Unsupervised_Continual_Learning_Relies_on_Previous_Information_CVPRW_2024_paper.html": {
    "title": "Must Unsupervised Continual Learning Relies on Previous Information?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Cheng",
      "Haitao Wen",
      "Heqian Qiu",
      "Lanxiao Wang",
      "Minjian Zhang",
      "Hongliang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/html/Cai_Is_Our_Continual_Learner_Reliable_Investigating_Its_Decision_Attribution_Stability_CVPRW_2024_paper.html": {
    "title": "Is Our Continual Learner Reliable? Investigating Its Decision Attribution Stability through SHAP Value Consistency",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yusong Cai",
      "Shimou Ling",
      "Liang Zhang",
      "Lili Pan",
      "Hongliang Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/html/Wu_Pre-trained_Bidirectional_Dynamic_Memory_Network_For_Long_Video_Question_Answering_CVPRW_2024_paper.html": {
    "title": "Pre-trained Bidirectional Dynamic Memory Network For Long Video Question Answering",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinmeng Wu",
      "Pengcheng Shu",
      "Hanyu Hong",
      "Lei Ma",
      "Ying Zhu",
      "Lei Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MR/html/Hodan_BOP_Challenge_2023_on_Detection_Segmentation_and_Pose_Estimation_of_CVPRW_2024_paper.html": {
    "title": "BOP Challenge 2023 on Detection Segmentation and Pose Estimation of Seen and Unseen Rigid Objects",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tomas Hodan",
      "Martin Sundermeyer",
      "Yann Labbe",
      "Van Nguyen Nguyen",
      "Gu Wang",
      "Eric Brachmann",
      "Bertram Drost",
      "Vincent Lepetit",
      "Carsten Rother",
      "Jiri Matas"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MR/html/Du_Modeling_Detailed_Human_Geometry_with_Adaptive_Local_Refinement_CVPRW_2024_paper.html": {
    "title": "Modeling Detailed Human Geometry with Adaptive Local Refinement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bang Du",
      "Kunyao Chen",
      "Haochen Zhang",
      "Fei Yin",
      "Baichuan Wu",
      "Truong Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MR/html/Shen_GRIB_Combining_Global_Reception_and_Inductive_Bias_For_Human_Segmentation_CVPRW_2024_paper.html": {
    "title": "GRIB: Combining Global Reception and Inductive Bias For Human Segmentation and Matting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yezhi Shen",
      "Weichen Xu",
      "Qian Lin",
      "Jan P. Allebach",
      "Fengqing Zhu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MR/html/Kohler_fMPI_Fast_Novel_View_Synthesis_in_the_Wild_with_Layered_CVPRW_2024_paper.html": {
    "title": "fMPI: Fast Novel View Synthesis in the Wild with Layered Scene Representations",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonas Kohler",
      "Nicolas Griffiths Sanchez",
      "Luca Cavalli",
      "Catherine Herold",
      "Alberto Garcia Garcia",
      "Albert Pumerola",
      "Ali Thabet"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CV4MR/html/Kohyama_3D_Human_Scan_With_A_Moving_Event_Camera_CVPRW_2024_paper.html": {
    "title": "3D Human Scan With A Moving Event Camera",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Kohyama",
      "Shintaro Shiba",
      "Yoshimitsu Aoki"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PRECOGNITION/html/Tang_VMRNN_Integrating_Vision_Mamba_and_LSTM_for_Efficient_and_Accurate_CVPRW_2024_paper.html": {
    "title": "VMRNN: Integrating Vision Mamba and LSTM for Efficient and Accurate Spatiotemporal Forecasting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujin Tang",
      "Peijie Dong",
      "Zhenheng Tang",
      "Xiaowen Chu",
      "Junwei Liang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PRECOGNITION/html/Truong_CONDA_Continual_Unsupervised_Domain_Adaptation_Learning_in_Visual_Perception_for_CVPRW_2024_paper.html": {
    "title": "CONDA: Continual Unsupervised Domain Adaptation Learning in Visual Perception for Self-Driving Cars",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thanh-Dat Truong",
      "Pierce Helton",
      "Ahmed Moustafa",
      "Jackson David Cothren",
      "Khoa Luu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PRECOGNITION/html/Noh_H3Net_Irregular_Posture_Detection_by_Understanding_Human_Character_and_Core_CVPRW_2024_paper.html": {
    "title": "H^3Net: Irregular Posture Detection by Understanding Human Character and Core Structures",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seungha Noh",
      "Kangmin Bae",
      "Yuseok Bae",
      "Byong-Dai Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PRECOGNITION/html/Pazho_VT-Former_An_Exploratory_Study_on_Vehicle_Trajectory_Prediction_for_Highway_CVPRW_2024_paper.html": {
    "title": "VT-Former: An Exploratory Study on Vehicle Trajectory Prediction for Highway Surveillance through Graph Isomorphism and Transformer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Armin Danesh Pazho",
      "Ghazal Alinezhad Noghre",
      "Vinit Katariya",
      "Hamed Tabkhi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/PRECOGNITION/html/Culjak_Exploration_of_Data_Augmentation_Techniques_for_Bush_Detection_in_Blueberry_CVPRW_2024_paper.html": {
    "title": "Exploration of Data Augmentation Techniques for Bush Detection in Blueberry Orchards",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boris Čuljak",
      "Nina Pajević",
      "Vladan Filipović",
      "Dimitrije Stefanović",
      "Zeljana Grbović",
      "Nemanja Djuric",
      "Marko Panić"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Aydin_A_Hybrid_ANN-SNN_Architecture_for_Low-Power_and_Low-Latency_Visual_Perception_CVPRW_2024_paper.html": {
    "title": "A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asude Aydin",
      "Mathias Gehrig",
      "Daniel Gehrig",
      "Davide Scaramuzza"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Wang_MambaPupil_Bidirectional_Selective_Recurrent_Model_for_Event-based_Eye_Tracking_CVPRW_2024_paper.html": {
    "title": "MambaPupil: Bidirectional Selective Recurrent Model for Event-based Eye Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhong Wang",
      "Zengyu Wan",
      "Han Han",
      "Bohao Liao",
      "Yuliang Wu",
      "Wei Zhai",
      "Yang Cao",
      "Zheng-Jun Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Wang_Event-Based_Eye_Tracking._AIS_2024_Challenge_Survey_CVPRW_2024_paper.html": {
    "title": "Event-Based Eye Tracking. AIS 2024 Challenge Survey",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zuowen Wang",
      "Chang Gao",
      "Zongwei Wu",
      "Marcos V. Conde",
      "Radu Timofte",
      "Shih-Chii Liu",
      "Qinyu Chen",
      "Zheng-Jun Zha",
      "Wei Zhai",
      "Han Han",
      "Bohao Liao",
      "Yuliang Wu",
      "Zengyu Wan",
      "Zhong Wang",
      "Yang Cao",
      "Ganchao Tan",
      "Jinze Chen",
      "Yan Ru Pei",
      "Sasskia Bruers",
      "Sebastien Crouzet",
      "Douglas Mclelland",
      "Oliver Coenen",
      "Baoheng Zhang",
      "Yizhao Gao",
      "Jingyuan Li",
      "Hayden Kwok-Hay So",
      "Philippe Bich",
      "Chiara Boretti",
      "Luciano Prono",
      "Mircea Lica",
      "David Dinucu-Jianu",
      "Catalin Griu",
      "Xiaopeng Lin",
      "Hongwei Ren",
      "Bojun Cheng",
      "Xinan Zhang",
      "Valentin Vial",
      "Anthony Yezzi",
      "James Tsai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Zhang_Co-designing_a_Sub-millisecond_Latency_Event-based_Eye_Tracking_System_with_Submanifold_CVPRW_2024_paper.html": {
    "title": "Co-designing a Sub-millisecond Latency Event-based Eye Tracking System with Submanifold Sparse CNN",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Baoheng Zhang",
      "Yizhao Gao",
      "Jingyuan Li",
      "Hayden Kwok-Hay So"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Hu_Low_Latency_Point_Cloud_Rendering_with_Learned_Splatting_CVPRW_2024_paper.html": {
    "title": "Low Latency Point Cloud Rendering with Learned Splatting",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yueyu Hu",
      "Ran Gong",
      "Qi Sun",
      "Yao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Lim_Adaptive_Render-Video_Streaming_for_Virtual_Environments_CVPRW_2024_paper.html": {
    "title": "Adaptive Render-Video Streaming for Virtual Environments",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jia-Jie Lim",
      "Matthias S. Treder",
      "Aaron Chadha",
      "Yiannis Andreopoulos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Bonazzi_Retina__Low-Power_Eye_Tracking_with_Event_Camera_and_Spiking_CVPRW_2024_paper.html": {
    "title": "Retina : Low-Power Eye Tracking with Event Camera and Spiking Hardware",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pietro Bonazzi",
      "Sizhen Bian",
      "Giovanni Lippolis",
      "Yawei Li",
      "Sadique Sheik",
      "Michele Magno"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Pourian_Joint_Motion_Detection_in_Neural_Videos_Training_CVPRW_2024_paper.html": {
    "title": "Joint Motion Detection in Neural Videos Training",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Niloufar Pourian",
      "Alexey Supikov"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Reich_A_Perspective_on_Deep_Vision_Performance_with_Standard_Image_and_CVPRW_2024_paper.html": {
    "title": "A Perspective on Deep Vision Performance with Standard Image and Video Codecs",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christoph Reich",
      "Oliver Hahn",
      "Daniel Cremers",
      "Stefan Roth",
      "Biplob Debnath"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Lin_FAPNet_An_Effective_Frequency_Adaptive_Point-based_Eye_Tracker_CVPRW_2024_paper.html": {
    "title": "FAPNet: An Effective Frequency Adaptive Point-based Eye Tracker",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaopeng Lin",
      "Hongwei Ren",
      "Bojun Cheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Conde_AIS_2024_Challenge_on_Video_Quality_Assessment_of_User-Generated_Content_CVPRW_2024_paper.html": {
    "title": "AIS 2024 Challenge on Video Quality Assessment of User-Generated Content: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcos V. Conde",
      "Saman Zadtootaghaj",
      "Nabajeet Barman",
      "Radu Timofte",
      "Chenlong He",
      "Qi Zheng",
      "Ruoxi Zhu",
      "Zhengzhong Tu",
      "Haiqiang Wang",
      "Xiangguang Chen",
      "Wenhui Meng",
      "Xiang Pan",
      "Huiying Shi",
      "Han Zhu",
      "Xiaozhong Xu",
      "Lei Sun",
      "Zhenzhong Chen",
      "Shan Liu",
      "Zicheng Zhang",
      "Haoning Wu",
      "Yingjie Zhou",
      "Chunyi Li",
      "Xiaohong Liu",
      "Weisi Lin",
      "Guangtao Zhai",
      "Wei Sun",
      "Yuqin Cao",
      "Yanwei Jiang",
      "Jun Jia",
      "Zhichao Zhang",
      "Zijian Chen",
      "Weixia Zhang",
      "Xiongkuo Min",
      "Steve Goring",
      "Zihao Qi",
      "Chen Feng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/He_COVER_A_Comprehensive_Video_Quality_Evaluator_CVPRW_2024_paper.html": {
    "title": "COVER: A Comprehensive Video Quality Evaluator",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenlong He",
      "Qi Zheng",
      "Ruoxi Zhu",
      "Xiaoyang Zeng",
      "Yibo Fan",
      "Zhengzhong Tu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Reich_Deep_Video_Codec_Control_for_Vision_Models_CVPRW_2024_paper.html": {
    "title": "Deep Video Codec Control for Vision Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christoph Reich",
      "Biplob Debnath",
      "Deep Patel",
      "Tim Prangemeier",
      "Daniel Cremers",
      "Srimat Chakradhar"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Conde_Real-Time_4K_Super-Resolution_of_Compressed_AVIF_Images._AIS_2024_Challenge_CVPRW_2024_paper.html": {
    "title": "Real-Time 4K Super-Resolution of Compressed AVIF Images. AIS 2024 Challenge Survey",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcos V. Conde",
      "Zhijun Lei",
      "Wen Li",
      "Ioannis Katsavounidis",
      "Radu Timofte",
      "Min Yan",
      "Xin Liu",
      "Qian Wang",
      "Xiaoqian Ye",
      "Zhan Du",
      "Tiansen Zhang",
      "Zhiyuan Li",
      "Hao Wei",
      "Chenyang Ge",
      "Jiangtao Lv",
      "Long Sun",
      "Jinshan Pan",
      "Jiangxin Dong",
      "Jinhui Tang",
      "Menghan Zhou",
      "Yiqiang Yan",
      "Kihwan Yoon",
      "Ganzorig Gankhuyag",
      "Jae-Hyeon Lee",
      "Ui-Jin Choi",
      "Hyeon-Cheol Moon",
      "Tae-Hyun Jeong",
      "Yoonmo Yang",
      "Jae-Gon Kim",
      "Jinwoo Jeong",
      "Sunjei Kim",
      "Xintao Qiu",
      "Yuanbo Zhou",
      "Kongxian Wu",
      "Xinwei Dai",
      "Hui Tang",
      "Wei Deng",
      "Qingquan Gao",
      "Tong Tong",
      "Long Peng",
      "Jiaming Guo",
      "Xin Di",
      "Bohao Liao",
      "Zhibo Du",
      "Peize Xia",
      "Renjing Pei",
      "Yang Wang",
      "Yang Cao",
      "Zhengjun Zha",
      "Bingnan Han",
      "Hongyuan Yu",
      "Zhuoyuan Wu",
      "Cheng Wan",
      "Yuqing Liu",
      "Haodong Yu",
      "Jizhe Li",
      "Zhijuan Huang",
      "Yuan Huang",
      "Yajun Zou",
      "Xianyu Guan",
      "Qi Jia",
      "Heng Zhang",
      "Xuanwu Yin",
      "Kunlong Zuo",
      "Dongyang Zhang",
      "Tianle Liu",
      "Huaian Chen",
      "Yi Jin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Pei_A_Lightweight_Spatiotemporal_Network_for_Online_Eye_Tracking_with_Event_CVPRW_2024_paper.html": {
    "title": "A Lightweight Spatiotemporal Network for Online Eye Tracking with Event Camera",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Ru Pei",
      "Sasskia Brüers",
      "Sébastien Crouzet",
      "Douglas Mclelland",
      "Olivier Coenen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Streaming/html/Hu_One-Click_Upgrade_from_2D_to_3D_Sandwiched_RGB-D_Video_Compression_CVPRW_2024_paper.html": {
    "title": "One-Click Upgrade from 2D to 3D: Sandwiched RGB-D Video Compression for Stereoscopic Teleconferencing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yueyu Hu",
      "Onur G. Guleryuz",
      "Philip A. Chou",
      "Danhang Tang",
      "Jonathan Taylor",
      "Rus Maxham",
      "Yao Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAI/html/Noor_Efficient_Skeleton-Based_Action_Recognition_for_Real-Time_Embedded_Systems_CVPRW_2024_paper.html": {
    "title": "Efficient Skeleton-Based Action Recognition for Real-Time Embedded Systems",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nadhira Noor",
      "Fabianaugie Jametoni",
      "Jinbeom Kim",
      "Hyunsu Hong",
      "In Kyu Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAI/html/Nasery_End-to-End_Neural_Network_Compression_via_l1l2_Regularized_Latency_Surrogates_CVPRW_2024_paper.html": {
    "title": "End-to-End Neural Network Compression via l1/l2 Regularized Latency Surrogates",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anshul Nasery",
      "Hardik Shah",
      "Arun Sai Suggala",
      "Prateek Jain"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAI/html/Avery_Scaling_Graph_Convolutions_for_Mobile_Vision_CVPRW_2024_paper.html": {
    "title": "Scaling Graph Convolutions for Mobile Vision",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "William Avery",
      "Mustafa Munir",
      "Radu Marculescu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MAI/html/Zhang_CoDISP_Exploring_Compressed_Domain_Camera_ISP_with_RGB-guided_Encoder_CVPRW_2024_paper.html": {
    "title": "CoDISP: Exploring Compressed Domain Camera ISP with RGB-guided Encoder",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Molin Zhang",
      "Soumendu Majee",
      "Chengyu Wang",
      "Seok-Jun Lee",
      "Hamid Sheikh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Qu_Exploring_AIGC_Video_Quality_A_Focus_on_Visual_Harmony_Video-Text_CVPRW_2024_paper.html": {
    "title": "Exploring AIGC Video Quality: A Focus on Visual Harmony Video-Text Consistency and Domain Distribution Gap",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bowen Qu",
      "Xiaoyu Liang",
      "Shangkun Sun",
      "Wei Gao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Sharma_Sketch-guided_Image_Inpainting_with_Partial_Discrete_Diffusion_Process_CVPRW_2024_paper.html": {
    "title": "Sketch-guided Image Inpainting with Partial Discrete Diffusion Process",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nakul Sharma",
      "Aditay Tripathi",
      "Anirban Chakraborty",
      "Anand Mishra"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Fang_PCQA_A_Strong_Baseline_for_AIGC_Quality_Assessment_Based_on_CVPRW_2024_paper.html": {
    "title": "PCQA: A Strong Baseline for AIGC Quality Assessment Based on Prompt Condition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Fang",
      "Weigang Wang",
      "Xiaoxin Lv",
      "Jun Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Nehete_Fourier_Prior-Based_Two-Stage_Architecture_for_Image_Restoration_CVPRW_2024_paper.html": {
    "title": "Fourier Prior-Based Two-Stage Architecture for Image Restoration",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hemkant Nehete",
      "Amit Monga",
      "Partha Kaushik",
      "Brajesh Kumar Kaushik"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chao_BigEPIT_Scaling_EPIT_for_Light_Field_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "BigEPIT: Scaling EPIT for Light Field Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wentao Chao",
      "Yiming Kan",
      "Xuechun Wang",
      "Fuqing Duan",
      "Guanghui Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Jiang_RBSFormer_Enhanced_Transformer_Network_for_Raw_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "RBSFormer: Enhanced Transformer Network for Raw Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Jiang",
      "Senyan Xu",
      "Xingfu Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Khudjaev_Dformer_Learning_Efficient_Image_Restoration_with_Perceptual_Guidance_CVPRW_2024_paper.html": {
    "title": "Dformer: Learning Efficient Image Restoration with Perceptual Guidance",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nodirkhuja Khudjaev",
      "Roman Tsoy",
      "S M A Sharif",
      "Azamat Myrzabekov",
      "Seongwan Kim",
      "Jaeho Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Liu_NTIRE_2024_Challenge_on_Low_Light_Image_Enhancement_Methods_and_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Low Light Image Enhancement: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoning Liu",
      "Zongwei Wu",
      "Ao Li",
      "Florin-Alexandru Vasluianu",
      "Yulun Zhang",
      "Shuhang Gu",
      "Le Zhang",
      "Ce Zhu",
      "Radu Timofte",
      "Zhi Jin",
      "Hongjun Wu",
      "Chenxi Wang",
      "Haitao Ling",
      "Yuanhao Cai",
      "Hao Bian",
      "Yuxin Zheng",
      "Jing Lin",
      "Alan Yuille",
      "Ben Shao",
      "Jin Guo",
      "Tian Liu",
      "Mohao Wu",
      "Yixu Feng",
      "Shuo Hou",
      "Haotian Lin",
      "Yu Zhu",
      "Peng Wu",
      "Wei Dong",
      "Jinqiu Sun",
      "Yanning Zhang",
      "Qingsen Yan",
      "Wenbin Zou",
      "Weipeng Yang",
      "Yunxiang Li",
      "Qiaomu Wei",
      "Tian Ye",
      "Sixiang Chen",
      "Zhao Zhang",
      "Suiyi Zhao",
      "Bo Wang",
      "Yan Luo",
      "Zhichao Zuo",
      "Mingshen Wang",
      "Junhu Wang",
      "Yanyan Wei",
      "Xiaopeng Sun",
      "Yu Gao",
      "Jiancheng Huang",
      "Hongming Chen",
      "Xiang Chen",
      "Hui Tang",
      "Yuanbin Chen",
      "Yuanbo Zhou",
      "Xinwei Dai",
      "Xintao Qiu",
      "Wei Deng",
      "Qinquan Gao",
      "Tong Tong",
      "Mingjia Li",
      "Jin Hu",
      "Xinyu He",
      "Xiaojie Guo",
      "Sabarinathan Sabarinathan",
      "K Uma",
      "A Sasithradevi",
      "B Sathya Rama",
      "S. Mohamed Mansoor Roomi",
      "V. Srivatsav",
      "Jinjuan Wang",
      "Long Sun",
      "Qiuying Chen",
      "Jiahong Shao",
      "Yizhi Zhang",
      "Marcos V. Conde",
      "Daniel Feijoo",
      "Juan C. Benito",
      "Alvaro Garcia",
      "Jaeho Lee",
      "Seongwan Kim",
      "Sharif S M A",
      "Nodirkhuja Khujaev",
      "Roman Tsoy",
      "Ali Murtaza",
      "Uswah Khairuddin",
      "Amad Athif Mohd Faudzi",
      "Sampada Malagi",
      "Amogh Joshi",
      "Nikhil Akalwadi",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Uma Mudenagudi",
      "Palani Yashaswini",
      "Nitish Upasi",
      "Dikshit Hegde",
      "Ujwala Patil",
      "Sujata C",
      "Xingzhuo Yan",
      "Wei Hao",
      "Minghan Fu",
      "Pooja Choksy",
      "Anjali Sarvaiya",
      "Kishor Upla",
      "Kiran Raja",
      "Hailong Yan",
      "Yunkai Zhang",
      "Baiang Li",
      "Jingyi Zhang",
      "Huan Zheng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Conde_Deep_RAW_Image_Super-Resolution._A_NTIRE_2024_Challenge_Survey_CVPRW_2024_paper.html": {
    "title": "Deep RAW Image Super-Resolution. A NTIRE 2024 Challenge Survey",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcos V. Conde",
      "Florin-Alexandru Vasluianu",
      "Radu Timofte",
      "Jianxing Zhang",
      "Jia Li",
      "Fan Wang",
      "Xiaopeng Li",
      "Zikun Liu",
      "Hyunhee Park",
      "Sejun Song",
      "Changho Kim",
      "Zhijuan Huang",
      "Hongyuan Yu",
      "Cheng Wan",
      "Wending Xiang",
      "Jiamin Lin",
      "Hang Zhong",
      "Qiaosong Zhang",
      "Yue Sun",
      "Xuanwu Yin",
      "Kunlong Zuo",
      "Senyan Xu",
      "Siyuan Jiang",
      "Zhijing Sun",
      "Jiaying Zhu",
      "Liangyan Li",
      "Ke Chen",
      "Yunzhe Li",
      "Yimo Ning",
      "Guanhua Zhao",
      "Jun Chen",
      "Jinyang Yu",
      "Kele Xu",
      "Qisheng Xu",
      "Yong Dou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wan_Swift_Parameter-free_Attention_Network_for_Efficient_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Swift Parameter-free Attention Network for Efficient Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Wan",
      "Hongyuan Yu",
      "Zhiqi Li",
      "Yihang Chen",
      "Yajun Zou",
      "Yuqing Liu",
      "Xuanwu Yin",
      "Kunlong Zuo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Korkmaz_Training_Transformer_Models_by_Wavelet_Losses_Improves_Quantitative_and_Visual_CVPRW_2024_paper.html": {
    "title": "Training Transformer Models by Wavelet Losses Improves Quantitative and Visual Performance in Single Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cansu Korkmaz",
      "A. Murat Tekalp"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Yu_SF-IQA_Quality_and_Similarity_Integration_for_AI_Generated_Image_Quality_CVPRW_2024_paper.html": {
    "title": "SF-IQA: Quality and Similarity Integration for AI Generated Image Quality Assessment",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Yu",
      "Fengbin Guan",
      "Yiting Lu",
      "Xin Li",
      "Zhibo Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Zou_Semantic_Pre-supplement_for_Exposure_Correction_CVPRW_2024_paper.html": {
    "title": "Semantic Pre-supplement for Exposure Correction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhen Zou",
      "Wei Yu",
      "Jie Huang",
      "Feng Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wang_Multi-scale_Attention_Network_for_Single_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Multi-scale Attention Network for Single Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Wang",
      "Yusen Li",
      "Gang Wang",
      "Xiaoguang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Yang_CRNet_A_Detail-Preserving_Network_for_Unified_Image_Restoration_and_Enhancement_CVPRW_2024_paper.html": {
    "title": "CRNet: A Detail-Preserving Network for Unified Image Restoration and Enhancement Task",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kangzhen Yang",
      "Tao Hu",
      "Kexin Dai",
      "Genggeng Chen",
      "Yu Cao",
      "Wei Dong",
      "Peng Wu",
      "Yanning Zhang",
      "Qingsen Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Dong_DehazeDCT_Towards_Effective_Non-Homogeneous_Dehazing_via_Deformable_Convolutional_Transformer_CVPRW_2024_paper.html": {
    "title": "DehazeDCT: Towards Effective Non-Homogeneous Dehazing via Deformable Convolutional Transformer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Dong",
      "Han Zhou",
      "Ruiyi Wang",
      "Xiaohong Liu",
      "Guangtao Zhai",
      "Jun Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Luo_Photo-Realistic_Image_Restoration_in_the_Wild_with_Controlled_Vision-Language_Models_CVPRW_2024_paper.html": {
    "title": "Photo-Realistic Image Restoration in the Wild with Controlled Vision-Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziwei Luo",
      "Fredrik K. Gustafsson",
      "Zheng Zhao",
      "Jens Sjölund",
      "Thomas B. Schön"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Feng_DiffLight_Integrating_Content_and_Detail_for_Low-light_Image_Enhancement_CVPRW_2024_paper.html": {
    "title": "DiffLight: Integrating Content and Detail for Low-light Image Enhancement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixu Feng",
      "Shuo Hou",
      "Haotian Lin",
      "Yu Zhu",
      "Peng Wu",
      "Wei Dong",
      "Jinqiu Sun",
      "Qingsen Yan",
      "Yanning Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Li_PromptCIR_Blind_Compressed_Image_Restoration_with_Prompt_Learning_CVPRW_2024_paper.html": {
    "title": "PromptCIR: Blind Compressed Image Restoration with Prompt Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bingchen Li",
      "Xin Li",
      "Yiting Lu",
      "Ruoyu Feng",
      "Mengxi Guo",
      "Shijie Zhao",
      "Li Zhang",
      "Zhibo Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Song_Two_Stage_Dehazing_Framework_for_Dense_and_Non-Homogeneous_Dehazing_CVPRW_2024_paper.html": {
    "title": "Two Stage Dehazing Framework for Dense and Non-Homogeneous Dehazing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Song",
      "Yichang Gao",
      "Jiahao Xiong",
      "Hualiang Lin",
      "Dong Li",
      "Yun Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Li_Shadow_Removal_based_on_Diffusion_Segmentation_and_Super-resolution_Models_CVPRW_2024_paper.html": {
    "title": "Shadow Removal based on Diffusion Segmentation and Super-resolution Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chenghua Li",
      "Bo Yang",
      "Zhiqi Wu",
      "Gao Chen",
      "Yihan Yu",
      "Shengxiao Zhou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Vasluianu_NTIRE_2024_Image_Shadow_Removal_Challenge_Report_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Image Shadow Removal Challenge Report",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florin-Alexandru Vasluianu",
      "Tim Seizinger",
      "Zhuyun Zhou",
      "Zongwei Wu",
      "Cailian Chen",
      "Radu Timofte",
      "Wei Dong",
      "Han Zhou",
      "Yuqiong Tian",
      "Jun Chen",
      "Xueyang Fu",
      "Xin Lu",
      "Yurui Zhu",
      "Xi Wang",
      "Dong Li",
      "Jie Xiao",
      "Yunpeng Zhang",
      "Zheng-Jun Zha",
      "Zhao Zhang",
      "Suiyi Zhao",
      "Bo Wang",
      "Yan Luo",
      "Yanyan Wei",
      "Zhihao Zhao",
      "Long Sun",
      "Tingting Yang",
      "Jinshan Pan",
      "Jiangxin Dong",
      "Jinhui Tang",
      "Bilel Benjdira",
      "Mohammed Nassif",
      "Anis Koubaa",
      "Ahmed Elhayek",
      "Anas M. Ali",
      "Kyotaro Tokoro",
      "Kento Kawai",
      "Kaname Yokoyama",
      "Takuya Seno",
      "Yuki Kondo",
      "Norimichi Ukita",
      "Chenghua Li",
      "Bo Yang",
      "Zhiqi Wu",
      "Gao Chen",
      "Yihan Yu",
      "Sixiang Chen",
      "Kai Zhang",
      "Tian Ye",
      "Wenbin Zou",
      "Yunlong Lin",
      "Zhaohu Xing",
      "Jinbin Bai",
      "Wenhao Chai",
      "Lei Zhu",
      "Ritik Maheshwari",
      "Rakshank Verma",
      "Rahul Tekchandani",
      "Praful Hambarde",
      "Satya Narayan Tazi",
      "Santosh Kumar Vipparthi",
      "Subrahmanyam Murala",
      "Jaeho Lee",
      "Seongwan Kim",
      "Sharif S M A",
      "Nodirkhuja Khujaev",
      "Roman Tsoy",
      "Fan Gao",
      "Weidan Yan",
      "Wenze Shao",
      "Dengyin Zhang",
      "Bin Chen",
      "Siqi Zhang",
      "Yanxin Qian",
      "Yuanbin Chen",
      "Yuanbo Zhou",
      "Tong Tong",
      "Rongfeng Wei",
      "Ruiqi Sun",
      "Yue Liu",
      "Nikhil Akalwadi",
      "Amogh Joshi",
      "Sampada Malagi",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Uma Mudenagudi",
      "Ali Murtaza",
      "Uswah Khairuddin",
      "Ahmad Athif Mohd Faudzi",
      "Adinath Dukre",
      "Vivek Deshmukh",
      "Shruti S. Phutke",
      "Ashutosh Kulkarni",
      "Santosh Kumar Vipparthi",
      "Anil Gonde",
      "Subrahmanyam Murala",
      "Arun Karthik K",
      "Manasa N",
      "Shri Hari Priya",
      "Wei Hao",
      "Xingzhuo Yan",
      "Minghan Fu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Khan_IDENet_Implicit_Degradation_Estimation_Network_for_Efficient_Blind_Super_Resolution_CVPRW_2024_paper.html": {
    "title": "IDENet: Implicit Degradation Estimation Network for Efficient Blind Super Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asif Hussain Khan",
      "Christian Micheloni",
      "Niki Martinel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Yang_MoE-AGIQA_Mixture-of-Experts_Boosted_Visual_Perception-Driven_and_Semantic-Aware_Quality_Assessment_for_CVPRW_2024_paper.html": {
    "title": "MoE-AGIQA: Mixture-of-Experts Boosted Visual Perception-Driven and Semantic-Aware Quality Assessment for AI-Generated Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junfeng Yang",
      "Jing Fu",
      "Wei Zhang",
      "Wenzhi Cao",
      "Limei Liu",
      "Han Peng"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Liu_Efficient_Light_Field_Image_Super-Resolution_via_Progressive_Disentangling_CVPRW_2024_paper.html": {
    "title": "Efficient Light Field Image Super-Resolution via Progressive Disentangling",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gaosheng Liu",
      "Huanjing Yue",
      "Jingyu Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Li_NTIRE_2024_Challenge_on_Short-form_UGC_Video_Quality_Assessment_Methods_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Short-form UGC Video Quality Assessment: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Li",
      "Kun Yuan",
      "Yajing Pei",
      "Yiting Lu",
      "Ming Sun",
      "Chao Zhou",
      "Zhibo Chen",
      "Radu Timofte",
      "Wei Sun",
      "Haoning Wu",
      "Zicheng Zhang",
      "Jun Jia",
      "Zhichao Zhang",
      "Linhan Cao",
      "Qiubo Chen",
      "Xiongkuo Min",
      "Weisi Lin",
      "Guangtao Zhai",
      "Jianhui Sun",
      "Tianyi Wang",
      "Lei Li",
      "Han Kong",
      "Wenxuan Wang",
      "Bing Li",
      "Cheng Luo",
      "Haiqiang Wang",
      "Xiangguang Chen",
      "Wenhui Meng",
      "Xiang Pan",
      "Huiying Shi",
      "Han Zhu",
      "Xiaozhong Xu",
      "Lei Sun",
      "Zhenzhong Chen",
      "Shan Liu",
      "Fangyuan Kong",
      "Haotian Fan",
      "Yifang Xu",
      "Haoran Xu",
      "Mengduo Yang",
      "Jie Zhou",
      "Jiaze Li",
      "Shijie Wen",
      "Mai Xu",
      "Da Li",
      "Shunyu Yao",
      "Jiazhi Du",
      "Wangmeng Zuo",
      "Zhibo Li",
      "Shuai He",
      "Anlong Ming",
      "Huiyuan Fu",
      "Huadong Ma",
      "Yong Wu",
      "Fie Xue",
      "Guozhi Zhao",
      "Lina Du",
      "Jie Guo",
      "Yu Zhang",
      "Huimin Zheng",
      "Junhao Chen",
      "Yue Liu",
      "Dulan Zhou",
      "Kele Xu",
      "Qisheng Xu",
      "Tao Sun",
      "Zhixiang Ding",
      "Yuhang Hu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ershov_NTIRE_2024_Challenge_on_Night_Photography_Rendering_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Night Photography Rendering",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Egor Ershov",
      "Artyom Panshin",
      "Oleg Karasev",
      "Sergey Korchagin",
      "Shepelev Lev",
      "Alexandr Startsev",
      "Daniil Vladimirov",
      "Ekaterina Zaychenkova",
      "Nikola Banić",
      "Dmitrii R Iarchuk",
      "Maria Efimove",
      "Radu Timofte",
      "Arseniy Terekhin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ouyang_Image_Restoration_Refinement_with_Uformer_GAN_CVPRW_2024_paper.html": {
    "title": "Image Restoration Refinement with Uformer GAN",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xu Ouyang",
      "Ying Chen",
      "Kaiyue Zhu",
      "Gady Agam"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chen_Large_Kernel_Frequency-enhanced_Network_for_Efficient_Single_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Large Kernel Frequency-enhanced Network for Efficient Single Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiadi Chen",
      "Chunjiang Duanmu",
      "Huanhuan Long"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Kim_DCDR-UNet_Deformable_Convolution_Based_Detail_Restoration_via_U-shape_Network_for_CVPRW_2024_paper.html": {
    "title": "DCDR-UNet: Deformable Convolution Based Detail Restoration via U-shape Network for Single Image HDR Reconstruction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joonsoo Kim",
      "Zhe Zhu",
      "Tien Bau",
      "Chenguang Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wang_NTIRE_2024_Challenge_on_Stereo_Image_Super-Resolution_Methods_and_Results_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Stereo Image Super-Resolution: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longguang Wang",
      "Yulan Guo",
      "Juncheng Li",
      "Hongda Liu",
      "Yang Zhao",
      "Yingqian Wang",
      "Zhi Jin",
      "Shuhang Gu",
      "Radu Timofte"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Dong_ShadowRefiner_Towards_Mask-free_Shadow_Removal_via_Fast_Fourier_Transformer_CVPRW_2024_paper.html": {
    "title": "ShadowRefiner: Towards Mask-free Shadow Removal via Fast Fourier Transformer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Dong",
      "Han Zhou",
      "Yuqiong Tian",
      "Jingke Sun",
      "Xiaohong Liu",
      "Guangtao Zhai",
      "Jun Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Yang_NTIRE_2024_Challenge_on_Blind_Enhancement_of_Compressed_Image_Methods_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Blind Enhancement of Compressed Image: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ren Yang",
      "Radu Timofte",
      "Bingchen Li",
      "Xin Li",
      "Mengxi Guo",
      "Shijie Zhao",
      "Li Zhang",
      "Zhibo Chen",
      "Dongyang Zhang",
      "Yash Arora",
      "Aditya Arora",
      "Yuanbin Chen",
      "Hui Tang",
      "Tao Wang",
      "Longxuan Zhao",
      "Bin Chen",
      "Tong Tong",
      "Qiao Mo",
      "Jingwei Bao",
      "Jinhua Hao",
      "Yukang Ding",
      "Hantang Li",
      "Ming Sun",
      "Chao Zhou",
      "Shuyuan Zhu",
      "Zhi Jin",
      "Wei Wang",
      "Dandan Zhan",
      "Jiawei Wu",
      "Jiahao Wu",
      "Luwei Tu",
      "Hongyu An",
      "Xinfeng Zhang",
      "Woon-Ha Yeo",
      "Wang-Taek Oh",
      "Young-Il Kim",
      "Han-Cheol Ryu",
      "Long Sun",
      "Mingjun Zhen",
      "Jinshan Pan",
      "Jiangxin Dong",
      "Jinhui Tang",
      "Yapeng Du",
      "Ao Li",
      "Ziyang He",
      "Lei Luo",
      "Ce Zhu",
      "Xin Yao",
      "Sunder Ali Khowaja",
      "Ik Hyun Lee",
      "Jaeho Lee",
      "Seongwan Kim",
      "Sharif S M A",
      "Nodirkhuja Khujaev",
      "Roman Tsoy"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Kim_Burst_Image_Super-Resolution_with_Base_Frame_Selection_CVPRW_2024_paper.html": {
    "title": "Burst Image Super-Resolution with Base Frame Selection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanghyun Kim",
      "Minjung Lee",
      "Woohyeok Kim",
      "Deunsol Jung",
      "Jaesung Rim",
      "Sunghyun Cho",
      "Minsu Cho"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Lu_HirFormer_Dynamic_High_Resolution_Transformer_for_Large-Scale_Image_Shadow_Removal_CVPRW_2024_paper.html": {
    "title": "HirFormer: Dynamic High Resolution Transformer for Large-Scale Image Shadow Removal",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Lu",
      "Yurui Zhu",
      "Xi Wang",
      "Dong Li",
      "Jie Xiao",
      "Yunpeng Zhang",
      "Xueyang Fu",
      "Zheng-Jun Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Li_Shadow_Removal_via_Global_Residual_Free_Unet_and_Shadow_Generation_CVPRW_2024_paper.html": {
    "title": "Shadow Removal via Global Residual Free Unet and Shadow Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dong Li",
      "Xin Lu",
      "Yurui Zhu",
      "Xi Wang",
      "Jie Xiao",
      "Yunpeng Zhang",
      "Xueyang Fu",
      "Zheng-Jun Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Choi_Reciprocal_Attention_Mixing_Transformer_for_Lightweight_Image_Restoration_CVPRW_2024_paper.html": {
    "title": "Reciprocal Attention Mixing Transformer for Lightweight Image Restoration",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haram Choi",
      "Cheolwoong Na",
      "Jihyeon Oh",
      "Seungjae Lee",
      "Jinseop Kim",
      "Subeen Choe",
      "Jeongmin Lee",
      "Taehoon Kim",
      "Jihoon Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/S_ISSR-DIL_Image_Specific_Super-Resolution_Using_Deep_Identity_Learning_CVPRW_2024_paper.html": {
    "title": "ISSR-DIL: Image Specific Super-Resolution Using Deep Identity Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sree Rama Vamsidhar S",
      "Jayadeep D",
      "Rama Krishna Gorthi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Daultani_Diffusion-Based_Adaptation_for_Classification_of_Unknown_Degraded_Images_CVPRW_2024_paper.html": {
    "title": "Diffusion-Based Adaptation for Classification of Unknown Degraded Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dinesh Daultani",
      "Masayuki Tanaka",
      "Masatoshi Okutomi",
      "Kazuki Endo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Liu_SDCNetSpatially-Adaptive_Deformable_Convolution_Networks_for_HR_NonHomogeneous_Dehazing_CVPRW_2024_paper.html": {
    "title": "SDCNet:Spatially-Adaptive Deformable Convolution Networks for HR NonHomogeneous Dehazing",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yidi Liu",
      "Xingbo Wang",
      "Yurui Zhu",
      "Xueyang Fu",
      "Zheng-Jun Zha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Liang_NTIRE_2024_Restore_Any_Image_Model_RAIM_in_the_Wild_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Restore Any Image Model (RAIM) in the Wild Challenge",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Liang",
      "Radu Timofte",
      "Qiaosi Yi",
      "Shuaizheng Liu",
      "Lingchen Sun",
      "Rongyuan Wu",
      "Xindong Zhang",
      "Hui Zeng",
      "Lei Zhang",
      "Yibin Huang",
      "Shai Liu",
      "Yongqiang Li",
      "Chaoyu Feng",
      "Xiaotao Wang",
      "Lei Lei",
      "Yuxiang Chen",
      "Xiangyu Chen",
      "Qiubo Chen",
      "Fengyu Sun",
      "Mengying Cui",
      "Jiaxu Chen",
      "Zhenyu Hu",
      "Jingyun Liu",
      "Wenzhuo Ma",
      "Ce Wang",
      "Hanyou Zheng",
      "Wanjie Sun",
      "Zhenzhong Chen",
      "Ziwei Luo",
      "Fredrik K. Gustafsson",
      "Zheng Zhao",
      "Jens Sjolund",
      "Thomas B. Schon",
      "Xiong Dun",
      "Pengzhou Ji",
      "Yujie Xing",
      "Xuquan Wang",
      "Zhanshan Wang",
      "Xinbin Cheng",
      "Jun Xiao",
      "Chenhang He",
      "Xiuyuan Wang",
      "Zhi-Song Liu",
      "Zimeng Miao",
      "Zhicun Yin",
      "Ming Liu",
      "Wangmeng Zuo",
      "Shuai Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Yu_LGFN_Lightweight_Light_Field_Image_Super-Resolution_using_Local_Convolution_Modulation_CVPRW_2024_paper.html": {
    "title": "LGFN: Lightweight Light Field Image Super-Resolution using Local Convolution Modulation and Global Attention Feature Extraction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongxin Yu",
      "Liang Chen",
      "Zhiyun Zeng",
      "Kunping Yang",
      "Shaofei Luo",
      "Shaorui Chen",
      "Cheng Zhong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chen_Bracketing_Image_Restoration_and_Enhancement_with_High-Low_Frequency_Decomposition_CVPRW_2024_paper.html": {
    "title": "Bracketing Image Restoration and Enhancement with High-Low Frequency Decomposition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Genggeng Chen",
      "Kexin Dai",
      "Kangzhen Yang",
      "Tao Hu",
      "Xiangyu Chen",
      "Yongqing Yang",
      "Wei Dong",
      "Peng Wu",
      "Yanning Zhang",
      "Qingsen Yan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chen_NTIRE_2024_Challenge_on_Image_Super-Resolution_x4_Methods_and_Results_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Image Super-Resolution (x4): Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Chen",
      "Zongwei Wu",
      "Eduard Zamfir",
      "Kai Zhang",
      "Yulun Zhang",
      "Radu Timofte",
      "Xiaokang Yang",
      "Hongyuan Yu",
      "Cheng Wan",
      "Yuxin Hong",
      "Zhijuan Huang",
      "Yajun Zou",
      "Yuan Huang",
      "Jiamin Lin",
      "Bingnan Han",
      "Xianyu Guan",
      "Yongsheng Yu",
      "Daoan Zhang",
      "Xuanwu Yin",
      "Kunlong Zuo",
      "Jinhua Hao",
      "Kai Zhao",
      "Kun Yuan",
      "Ming Sun",
      "Chao Zhou",
      "Hongyu An",
      "Xinfeng Zhang",
      "Zhiyuan Song",
      "Ziyue Dong",
      "Qing Zhao",
      "Xiaogang Xu",
      "Pengxu Wei",
      "Zhi-Chao Dou",
      "Gui-Ling Wang",
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Yi-Shiuan Chou",
      "Cansu Korkmaz",
      "A. Murat Tekalp",
      "Yubin Wei",
      "Xiaole Yan",
      "Binren Li",
      "Haonan Chen",
      "Siqi Zhang",
      "Sihan Chen",
      "Amogh Joshi",
      "Nikhil Akalwadi",
      "Sampada Malagi",
      "Palani Yashaswini",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Ujwala Patil",
      "Uma Mudenagudi",
      "Anjali Sarvaiya",
      "Pooja Choksy",
      "Jagrit Joshi",
      "Shubh Kawa",
      "Kishor Upla",
      "Sushrut Patwardhan",
      "Raghavendra Ramachandra",
      "Sadat Hossain",
      "Geongi Park",
      "S.M. Nadim Uddin",
      "Hao Xu",
      "Yanhui Guo",
      "Aman Urumbekov",
      "Xingzhuo Yan",
      "Wei Hao",
      "Minghan Fu",
      "Isaac Orais",
      "Samuel Smith",
      "Ying Liu",
      "Wangwang Jia",
      "Qisheng Xu",
      "Kele Xu",
      "Weijun Yuan",
      "Zhan Li",
      "Wenqin Kuang",
      "Ruijin Guan",
      "Ruting Deng",
      "Zhao Zhang",
      "Bo Wang",
      "Suiyi Zhao",
      "Yan Luo",
      "Yanyan Wei",
      "Asif Hussain Khan",
      "Christian Micheloni",
      "Niki Martinel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Xing_High_Quality_Reference_Feature_for_Two_Stage_Bracketing_Image_Restoration_CVPRW_2024_paper.html": {
    "title": "High Quality Reference Feature for Two Stage Bracketing Image Restoration and Enhancement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoxia Xing",
      "Hyunhee Park",
      "Fan Wang",
      "Ying Zhang",
      "Sejun Song",
      "Changho Kim",
      "Xiangyu Kong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Xu_Short-form_UGC_Video_Quality_Assessment_Based_on_Multi-Level_Video_Fusion_CVPRW_2024_paper.html": {
    "title": "Short-form UGC Video Quality Assessment Based on Multi-Level Video Fusion with Rank-Aware",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoran Xu",
      "Mengduo Yang",
      "Jie Zhou",
      "Jiaze Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Hsu_DRCT_Saving_Image_Super-Resolution_Away_from_Information_Bottleneck_CVPRW_2024_paper.html": {
    "title": "DRCT: Saving Image Super-Resolution Away from Information Bottleneck",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Yi-Shiuan Chou"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Peng_AIGC_Image_Quality_Assessment_via_Image-Prompt_Correspondence_CVPRW_2024_paper.html": {
    "title": "AIGC Image Quality Assessment via Image-Prompt Correspondence",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fei Peng",
      "Huiyuan Fu",
      "Anlong Ming",
      "Chuanming Wang",
      "Huadong Ma",
      "Shuai He",
      "Zifei Dou",
      "Shu Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ancuti_NTIRE_2024_Dense_and_Non-Homogeneous_Dehazing_Challenge_Report_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Dense and Non-Homogeneous Dehazing Challenge Report",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Codruta O. Ancuti",
      "Cosmin Ancuti",
      "Florin-Alexandru Vasluianu",
      "Radu Timofte",
      "Yidi Liu",
      "Xingbo Wang",
      "Yurui Zhu",
      "Gege Shi",
      "Xin Lu",
      "Xueyang Fu",
      "Zheng-Jun Zha",
      "Wei Dong",
      "Han Zhou",
      "Ruiyi Wang",
      "Xiaohong Liu",
      "Guangtao Zhai",
      "Jun Chen",
      "Wei Song",
      "Yichang Gao",
      "Jiahao Xiong",
      "Hualiang Lin",
      "Xianger Li",
      "Dong Li",
      "Mohab Kishawy",
      "Ruibin Li",
      "Seyed Amirreza Mousavi",
      "Rana Rauf",
      "Yangyi Liu",
      "Huan Liu",
      "Mingsheng Tu",
      "Kele Xu",
      "Jiawen Chen",
      "Qisheng Xu",
      "Tao Sun",
      "Jin Guo",
      "Ben Shao",
      "Tianli Liu",
      "Mohao Wu",
      "Xingzhuo Yan",
      "Minghan Fu",
      "Lehan Yang",
      "Xin Lin",
      "Lu Qi",
      "Jincen Song",
      "Xiaoqian Hu",
      "Linwai Tao",
      "Hongming Chen",
      "Xiang Chen",
      "Chuanlong Xie",
      "Zhao Zhang",
      "Junhu Wang",
      "Yanyan Wei",
      "Suiyi Zhao",
      "Shengeng Tang",
      "Sampada Malagi",
      "Amogh Joshi",
      "Nikhil Akalwadi",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Uma Mudenagudi",
      "Wenjing Jiang",
      "Jagadeesh Kalyanshetti",
      "Vijayalaxmi Ashok Aralikatti",
      "Yashaswini P",
      "Nitish Upasi",
      "Dikshit Hegde",
      "Ujwala Patil",
      "Sujata C"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ren_The_Ninth_NTIRE_2024_Efficient_Super-Resolution_Challenge_Report_CVPRW_2024_paper.html": {
    "title": "The Ninth NTIRE 2024 Efficient Super-Resolution Challenge Report",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bin Ren",
      "Yawei Li",
      "Nancy Mehta",
      "Radu Timofte",
      "Hongyuan Yu",
      "Cheng Wan",
      "Yuxin Hong",
      "Bingnan Han",
      "Zhuoyuan Wu",
      "Yajun Zou",
      "Yuqing Liu",
      "Jizhe Li",
      "Keji He",
      "Chao Fan",
      "Heng Zhang",
      "Xiaolin Zhang",
      "Xuanwu Yin",
      "Kunlong Zuo",
      "Bohao Liao",
      "Peizhe Xia",
      "Long Peng",
      "Zhibo Du",
      "Xin Di",
      "Wangkai Li",
      "Yang Wang",
      "Wei Zhai",
      "Renjing Pei",
      "Jiaming Guo",
      "Songcen Xu",
      "Yang Cao",
      "Zhengjun Zha",
      "Yan Wang",
      "Yi Liu",
      "Qing Wang",
      "Gang Zhang",
      "Liou Zhang",
      "Shijie Zhao",
      "Long Sun",
      "Jinshan Pan",
      "Jiangxin Dong",
      "Jinhui Tang",
      "Xin Liu",
      "Min Yan",
      "Qian Wang",
      "Menghan Zhou",
      "Yiqiang Yan",
      "Yixuan Liu",
      "Wensong Chan",
      "Dehua Tang",
      "Dong Zhou",
      "Li Wang",
      "Lu Tian",
      "Barsoum Emad",
      "Bohan Jia",
      "Junbo Qiao",
      "Yunshuai Zhou",
      "Yun Zhang",
      "Wei Li",
      "Shaohui Lin",
      "Shenglong Zhou",
      "Binbin Chen",
      "Jincheng Liao",
      "Suiyi Zhao",
      "Zhao Zhang",
      "Bo Wang",
      "Yan Luo",
      "Yanyan Wei",
      "Feng Li",
      "Mingshen Wang",
      "Yawei Li",
      "Jinhan Guan",
      "Dehua Hu",
      "Jiawei Yu",
      "Qisheng Xu",
      "Tao Sun",
      "Long Lan",
      "Kele Xu",
      "Xin Lin",
      "Jingtong Yue",
      "Lehan Yang",
      "Shiyi Du",
      "Lu Qi",
      "Chao Ren",
      "Zeyu Han",
      "Yuhan Wang",
      "Chaolin Chen",
      "Haobo Li",
      "Mingjun Zheng",
      "Zhongbao Yang",
      "Lianhong Song",
      "Xingzhuo Yan",
      "Minghan Fu",
      "Jingyi Zhang",
      "Baiang Li",
      "Qi Zhu",
      "Xiaogang Xu",
      "Dan Guo",
      "Chunle Guo",
      "Jiadi Chen",
      "Huanhuan Long",
      "Chunjiang Duanmu",
      "Xiaoyan Lei",
      "Jie Liu",
      "Weilin Jia",
      "Weifeng Cao",
      "Wenlong Zhang",
      "Yanyu Mao",
      "Ruilong Guo",
      "Nihao Zhang",
      "Qian Wang",
      "Manoj Pandey",
      "Maksym Chernozhukov",
      "Giang Le",
      "Shuli Cheng",
      "Hongyuan Wang",
      "Ziyan Wei",
      "Qingting Tang",
      "Liejun Wang",
      "Yongming Li",
      "Yanhui Guo",
      "Hao Xu",
      "Akram Khatami-Rizi",
      "Ahamad Mahmoudi-Aznaveh",
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Yi-Shiuan Chou",
      "Amogh Joshi",
      "Nikhil Akalwadi",
      "Sampada Malagi",
      "Palani Yashaswini",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Ujwala Patil",
      "Uma Mudenagudi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Dai_Learnable_Global_Spatio-Temporal_Adaptive_Aggregation_for_Bracketing_Image_Restoration_and_CVPRW_2024_paper.html": {
    "title": "Learnable Global Spatio-Temporal Adaptive Aggregation for Bracketing Image Restoration and Enhancement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinwei Dai",
      "Yuanbo Zhou",
      "Xintao Qiu",
      "Hui Tang",
      "Wei Deng",
      "Qinquan Gao",
      "Tong Tong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wang_NTIRE_2024_Challenge_on_Light_Field_Image_Super-Resolution_Methods_and_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Light Field Image Super-Resolution: Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yingqian Wang",
      "Zhengyu Liang",
      "Qianyu Chen",
      "Longguang Wang",
      "Jungang Yang",
      "Radu Timofte",
      "Yulan Guo",
      "Wentao Chao",
      "Yiming Kan",
      "Xuechun Wang",
      "Fuqing Duan",
      "Guanghui Wang",
      "Wang Xia",
      "Ziqi Wang",
      "Yue Yan",
      "Peiqi Xia",
      "Shunzhou Wang",
      "Yao Lu",
      "Angulia Yang",
      "Kai Jin",
      "Zeqiang Wei",
      "Sha Guo",
      "Mingzhi Gao",
      "Xiuzhuang Zhou",
      "Zhongxin Yu",
      "Shaofei Luo",
      "Cheng Zhong",
      "Shaorui Chen",
      "Long Peng",
      "Yuhong He",
      "Gaosheng Liu",
      "Huanjing Yue",
      "Jingyu Yang",
      "Zhengjian Yao",
      "Jiakui Hu",
      "Lujia Jin",
      "Zhi-Song Liu",
      "Chenhang He",
      "Jun Xiao",
      "Xiuyuan Wang",
      "Zonglin Tian",
      "Yifan Mao",
      "Deyang Liu",
      "Shizheng Li",
      "Ping An"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Li_Multi-Level_Feature_Fusion_Network_for_Lightweight_Stereo_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Multi-Level Feature Fusion Network for Lightweight Stereo Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunxiang Li",
      "Wenbin Zou",
      "Qiaomu Wei",
      "Feng Huang",
      "Jing Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chen_Towards_Real-world_Video_Face_Restoration_A_New_Benchmark_CVPRW_2024_paper.html": {
    "title": "Towards Real-world Video Face Restoration: A New Benchmark",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyan Chen",
      "Jingwen He",
      "Xinqi Lin",
      "Yu Qiao",
      "Chao Dong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Lei_DVMSR_Distillated_Vision_Mamba_for_Efficient_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "DVMSR: Distillated Vision Mamba for Efficient Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyan Lei",
      "Wenlong Zhang",
      "Weifeng Cao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Thiry_Towards_Online_Real-Time_Memory-based_Video_Inpainting_Transformers_CVPRW_2024_paper.html": {
    "title": "Towards Online Real-Time Memory-based Video Inpainting Transformers",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guillaume Thiry",
      "Hao Tang",
      "Radu Timofte",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Lu_AIGC-VQA_A_Holistic_Perception_Metric_for_AIGC_Video_Quality_Assessment_CVPRW_2024_paper.html": {
    "title": "AIGC-VQA: A Holistic Perception Metric for AIGC Video Quality Assessment",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiting Lu",
      "Xin Li",
      "Bingchen Li",
      "Zihao Yu",
      "Fengbin Guan",
      "Xinrui Wang",
      "Ruling Liao",
      "Yan Ye",
      "Zhibo Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ramirez_NTIRE_2024_Challenge_on_HR_Depth_from_Images_of_Specular_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on HR Depth from Images of Specular and Transparent Surfaces",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pierluigi Zama Ramirez",
      "Fabio Tosi",
      "Luigi Di Stefano",
      "Radu Timofte",
      "Alex Costanzino",
      "Matteo Poggi",
      "Samuele Salti",
      "Stefano Mattoccia",
      "Yangyang Zhang",
      "Cailin Wu",
      "Zhuangda He",
      "Shuangshuang Yin",
      "Jiaxu Dong",
      "Yangchenxu Liu",
      "Hao Jiang",
      "Jun Shi",
      "Yong A",
      "Yixiang Jin",
      "Dingzhe Li",
      "Bingxin Ke",
      "Anton Obukhov",
      "Tinafu Wang",
      "Nando Metzger",
      "Shengyu Huang",
      "Konrad Schindler",
      "Yachuan Huang",
      "Jiaqi Li",
      "Junrui Zhang",
      "Yiran Wang",
      "Zihao Huang",
      "Tianqi Liu",
      "Zhiguo Cao",
      "Pengzhi Li",
      "Jui-Lin Wang",
      "Wenjie Zhu",
      "Hui Geng",
      "Yuxin Zhang",
      "Long Lan",
      "Kele Xu",
      "Tao Sun",
      "Qisheng Xu",
      "Sourav Saini",
      "Aashray Gupta",
      "Sahaj K. Mistry",
      "Aryan Shukla",
      "Vinit Jakhetiya",
      "Sunil Jaiswal",
      "Yuejin Sun",
      "Zhuofan Zheng",
      "Yi Ning",
      "Jen-Hao Cheng",
      "Hou-I Liu",
      "Hsiang-Wei Huang",
      "Cheng-Yen Yang",
      "Zhongyu Jiang",
      "Yi-Hao Peng",
      "Aishi Huang",
      "Jenq-Neng Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chahine_Deep_Portrait_Quality_Assessment._A_NTIRE_2024_Challenge_Survey_CVPRW_2024_paper.html": {
    "title": "Deep Portrait Quality Assessment. A NTIRE 2024 Challenge Survey",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Chahine",
      "Marcos V. Conde",
      "Daniela Carfora",
      "Gabriel Pacianotto",
      "Benoit Pochon",
      "Sira Ferradans",
      "Radu Timofte",
      "Zhichao Duan",
      "Xinrui Xu",
      "Yipo Huang",
      "Quan Yuan",
      "Xiangfei Sheng",
      "Zhichao Yang",
      "Leida Li",
      "Haotian Fan",
      "Fangyuan Kong",
      "Yifang Xu",
      "Wei Sun",
      "Weixia Zhang",
      "Yanwei Jiang",
      "Haoning Wu",
      "Zicheng Zhang",
      "Jun Jia",
      "Yingjie Zhou",
      "Zhongpeng Ji",
      "Xiongkuo Min",
      "Weisi Lin",
      "Guangtao Zhai",
      "Xiaoqi Wang",
      "Junqi Liu",
      "Zixi Guo",
      "Yun Zhang",
      "Zewen Chen",
      "Wen Wang",
      "Juan Wang",
      "Bing Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chu_HMANet_Hybrid_Multi-Axis_Aggregation_Network_for_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "HMANet: Hybrid Multi-Axis Aggregation Network for Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shu-Chuan Chu",
      "Zhi-Chao Dou",
      "Jeng-Shyang Pan",
      "Shaowei Weng",
      "Junbao Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Wang_Attention_Guidance_Distillation_Network_for_Efficient_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Attention Guidance Distillation Network for Efficient Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongyuan Wang",
      "Ziyan Wei",
      "Qingting Tang",
      "Shuli Cheng",
      "Liejun Wang",
      "Yongming Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Li_AIGIQA-20K_A_Large_Database_for_AI-Generated_Image_Quality_Assessment_CVPRW_2024_paper.html": {
    "title": "AIGIQA-20K: A Large Database for AI-Generated Image Quality Assessment",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chunyi Li",
      "Tengchuan Kou",
      "Yixuan Gao",
      "Yuqin Cao",
      "Wei Sun",
      "Zicheng Zhang",
      "Yingjie Zhou",
      "Zhichao Zhang",
      "Weixia Zhang",
      "Haoning Wu",
      "Xiaohong Liu",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Morawski_Unsupervised_Image_Prior_via_Prompt_Learning_and_CLIP_Semantic_Guidance_CVPRW_2024_paper.html": {
    "title": "Unsupervised Image Prior via Prompt Learning and CLIP Semantic Guidance for Low-Light Image Enhancement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Igor Morawski",
      "Kai He",
      "Shusil Dangi",
      "Winston H. Hsu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Chen_Cross-view_Aggregation_Network_For_Stereo_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Cross-view Aggregation Network For Stereo Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhitao Chen",
      "Tao Lu",
      "Kanghui Zhao",
      "Bolin Zhu",
      "Zhen Li",
      "Jiaming Wang",
      "Yanduo Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Kubiak_S3R-Net_A_Single-Stage_Approach_to_Self-Supervised_Shadow_Removal_CVPRW_2024_paper.html": {
    "title": "S3R-Net: A Single-Stage Approach to Self-Supervised Shadow Removal",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikolina Kubiak",
      "Armin Mustafa",
      "Graeme Phillipson",
      "Stephen Jolly",
      "Simon Hadfield"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Zhang_NTIRE_2024_Challenge_on_Bracketing_Image_Restoration_and_Enhancement__CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Challenge on Bracketing Image Restoration and Enhancement: Datasets Methods and Results",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhilu Zhang",
      "Shuohao Zhang",
      "Renlong Wu",
      "Wangmeng Zuo",
      "Radu Timofte",
      "Xiaoxia Xing",
      "Hyunhee Park",
      "Sejun Song",
      "Changho Kim",
      "Xiangyu Kong",
      "Jinlong Wu",
      "Jianxing Zhang",
      "Jingfan Tan",
      "Zikun Liu",
      "Wenhan Luo",
      "Wenjie Lin",
      "Chengzhi Jiang",
      "Mingyan Han",
      "Zhen Liu",
      "Ting Jiang",
      "Jinting Luo",
      "Shen Cheng",
      "Linze Li",
      "Xinhan Niu",
      "Shuaicheng Liu",
      "Kexin Dai",
      "Kangzhen Yang",
      "Tao Hu",
      "Xiangyu Chen",
      "Yu Cao",
      "Qingsen Yan",
      "Yanning Zhang",
      "Genggeng Chen",
      "Yongqing Yang",
      "Wei Dong",
      "Xinwei Dai",
      "Yuanbo Zhou",
      "Xintao Qiu",
      "Hui Tang",
      "Wei Deng",
      "Qingquan Gao",
      "Tong Tong",
      "Peng Zhang",
      "Yifei Chen",
      "Wenbo Xiong",
      "Zhijun Song",
      "Pu Cheng",
      "Taolue Feng",
      "Yunqing He",
      "Daiguo Zhou",
      "Ying Huang",
      "Xiaowen Ma",
      "Peng Wu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Sharif_Learning_Optimized_Low-Light_Image_Enhancement_for_Edge_Vision_Tasks_CVPRW_2024_paper.html": {
    "title": "Learning Optimized Low-Light Image Enhancement for Edge Vision Tasks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "S M A Sharif",
      "Azamat Myrzabekov",
      "Nodirkhuja Khudjaev",
      "Roman Tsoy",
      "Seongwan Kim",
      "Jaeho Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Yang_Hybrid_Cross-View_Attention_Network_for_Lightweight_Stereo_Image_Super-Resolution_CVPRW_2024_paper.html": {
    "title": "Hybrid Cross-View Attention Network for Lightweight Stereo Image Super-Resolution",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqiang Yang",
      "Zhiming Zhang",
      "Yao Du",
      "Jingjing Yang",
      "Long Bao",
      "Heng Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Yaman_Audio-Visual_Speech_Representation_Expert_for_Enhanced_Talking_Face_Video_Generation_CVPRW_2024_paper.html": {
    "title": "Audio-Visual Speech Representation Expert for Enhanced Talking Face Video Generation and Evaluation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dogucan Yaman",
      "Fevziye Irem Eyiokur",
      "Leonard Bärmann",
      "Seymanur Akti",
      "Hazım Kemal Ekenel",
      "Alexander Waibel"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Ignatov_Virtually_Enriched_NYU_Depth_V2_Dataset_for_Monocular_Depth_Estimation_CVPRW_2024_paper.html": {
    "title": "Virtually Enriched NYU Depth V2 Dataset for Monocular Depth Estimation: Do We Need Artificial Augmentation?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dmitry Ignatov",
      "Andrey Ignatov",
      "Radu Timofte"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Lian_Equipping_Diffusion_Models_with_Differentiable_Spatial_Entropy_for_Low-Light_Image_CVPRW_2024_paper.html": {
    "title": "Equipping Diffusion Models with Differentiable Spatial Entropy for Low-Light Image Enhancement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenyi Lian",
      "Wenjing Lian",
      "Ziwei Luo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Liu_NTIRE_2024_Quality_Assessment_of_AI-Generated_Content_Challenge_CVPRW_2024_paper.html": {
    "title": "NTIRE 2024 Quality Assessment of AI-Generated Content Challenge",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaohong Liu",
      "Xiongkuo Min",
      "Guangtao Zhai",
      "Chunyi Li",
      "Tengchuan Kou",
      "Wei Sun",
      "Haoning Wu",
      "Yixuan Gao",
      "Yuqin Cao",
      "Zicheng Zhang",
      "Xiele Wu",
      "Radu Timofte",
      "Fei Peng",
      "Huiyuan Fu",
      "Anlong Ming",
      "Chuanming Wang",
      "Huadong Ma",
      "Shuai He",
      "Zifei Dou",
      "Shu Chen",
      "Huacong Zhang",
      "Haiyi Xie",
      "Chengwei Wang",
      "Baoying Chen",
      "Jishen Zeng",
      "Jianquan Yang",
      "Weigang Wang",
      "Xi Fang",
      "Xiaoxin Lv",
      "Jun Yan",
      "Tianwu Zhi",
      "Yabin Zhang",
      "Yaohui Li",
      "Yang Li",
      "Jingwen Xu",
      "Jianzhao Liu",
      "Yiting Liao",
      "Junlin Li",
      "Zihao Yu",
      "Fengbin Guan",
      "Yiting Lu",
      "Xin Li",
      "Hossein Motamednia",
      "S. Farhad Hosseini-Benvidi",
      "Ahmad Mahmoudi-Aznaveh",
      "Azadeh Mansouri",
      "Ganzorig Gankhuyag",
      "Kihwan Yoon",
      "Yifang Xu",
      "Haotian Fan",
      "Fangyuan Kong",
      "Shiling Zhao",
      "Weifeng Dong",
      "Haibing Yin",
      "Li Zhu",
      "Zhiling Wang",
      "Bingchen Huang",
      "Avinab Saha",
      "Sandeep Mishra",
      "Shashank Gupta",
      "Rajesh Sureddi",
      "Oindrila Saha",
      "Luigi Celona",
      "Simone Bianco",
      "Paolo Napoletano",
      "Raimondo Schettini",
      "Junfeng Yang",
      "Jing Fu",
      "Wei Zhang",
      "Wenzhi Cao",
      "Limei Liu",
      "Han Peng",
      "Weijun Yuan",
      "Zhan Li",
      "Yihang Cheng",
      "Yifan Deng",
      "Haohui Li",
      "Bowen Qu",
      "Yao Li",
      "Shuqing Luo",
      "Shunzhou Wang",
      "Wei Gao",
      "Zihao Lu",
      "Marcos V. Conde",
      "Radu Timofte",
      "Xinrui Wang",
      "Zhibo Chen",
      "Ruling Liao",
      "Yan Ye",
      "Qiulin Wang",
      "Bing Li",
      "Zhaokun Zhou",
      "Miao Geng",
      "Rui Chen",
      "Xin Tao",
      "Xiaoyu Liang",
      "Shangkun Sun",
      "Xingyuan Ma",
      "Jiaze Li",
      "Mengduo Yang",
      "Haoran Xu",
      "Jie Zhou",
      "Shiding Zhu",
      "Bohan Yu",
      "Pengfei Chen",
      "Xinrui Xu",
      "Jiabin Shen",
      "Zhichao Duan",
      "Erfan Asadi",
      "Jiahe Liu",
      "Qi Yan",
      "Youran Qu",
      "Xiaohui Zeng",
      "Lele Wang",
      "Renjie Liao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Gallet_Exploring_AI-Based_Satellite_Pose_Estimation_from_Novel_Synthetic_Dataset_to_CVPRW_2024_paper.html": {
    "title": "Exploring AI-Based Satellite Pose Estimation: from Novel Synthetic Dataset to In-Depth Performance Evaluation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fabien Gallet",
      "Christophe Marabotto",
      "Thomas Chambon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Lomashvili_Optimized_Martian_Dust_Displacement_Detection_Using_Explainable_Machine_Learning_CVPRW_2024_paper.html": {
    "title": "Optimized Martian Dust Displacement Detection Using Explainable Machine Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ana Lomashvili",
      "Kristin Rammelkamp",
      "Olivier Gasnault",
      "Protim Bhattacharjee",
      "Elise Clavé",
      "Christoph H. Egerland",
      "Susanne Schröder",
      "Begüm Demir",
      "Nina L. Lanza"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Del_Castillo_Mitigating_Challenges_of_the_Space_Environment_for_Onboard_Artificial_Intelligence_CVPRW_2024_paper.html": {
    "title": "Mitigating Challenges of the Space Environment for Onboard Artificial Intelligence: Design Overview of the Imaging Payload on SpIRIT",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Ortiz Del Castillo",
      "Jonathan Morgan",
      "Jack Mcrobbie",
      "Clint Therakam",
      "Zaher Joukhadar",
      "Robert Mearns",
      "Simon Barraclough",
      "Richard Sinnott",
      "Andrew Woods",
      "Chris Bayliss",
      "Kris Ehinger",
      "Ben Rubinstein",
      "James Bailey",
      "Airlie Chapman",
      "Michele Trenti"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Zhang_Monocular_6-DoF_Pose_Estimation_of_Spacecrafts_Utilizing_Self-iterative_Optimization_and_CVPRW_2024_paper.html": {
    "title": "Monocular 6-DoF Pose Estimation of Spacecrafts Utilizing Self-iterative Optimization and Motion Consistency",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunfeng Zhang",
      "Linjing You",
      "Luyu Yang",
      "Zhiwei Zhang",
      "Xiangli Nie",
      "Bo Zhang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Li_Cross-Temporal_Spectrogram_Autoencoder_CTSAE_Unsupervised_Dimensionality_Reduction_for_Clustering_Gravitational_CVPRW_2024_paper.html": {
    "title": "Cross-Temporal Spectrogram Autoencoder (CTSAE): Unsupervised Dimensionality Reduction for Clustering Gravitational Wave Glitches",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yi Li",
      "Yunan Wu",
      "Aggelos K. Katsaggelos"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Ostrogovich_A_Dual-Mode_Approach_for_Vision-Based_Navigation_in_a_Lunar_Landing_CVPRW_2024_paper.html": {
    "title": "A Dual-Mode Approach for Vision-Based Navigation in a Lunar Landing Scenario",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luca Ostrogovich",
      "Roberto Del Prete",
      "Giuseppe Tomasicchio",
      "Nicolas Longepe",
      "Alfredo Renga"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Zuo_CroSpace6D_Leveraging_Geometric_and_Motion_Cues_for_High-Precision_Cross-Domain_6DoF_CVPRW_2024_paper.html": {
    "title": "CroSpace6D: Leveraging Geometric and Motion Cues for High-Precision Cross-Domain 6DoF Pose Estimation for Non-Cooperative Spacecrafts",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianhong Zuo",
      "Shengyang Zhang",
      "Qianyu Zhang",
      "Yutao Zhao",
      "Baichuan Liu",
      "Aodi Wu",
      "Xue Wan",
      "Leizheng Shu",
      "Guohua Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Re_Transformers_for_Orbit_Determination_Anomaly_Detection_and_Classification_CVPRW_2024_paper.html": {
    "title": "Transformers for Orbit Determination Anomaly Detection and Classification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Parrish Ré",
      "Matthew Popplewell",
      "Michael Caudill",
      "Timothy Sullivan",
      "Tyler Hanf",
      "Benjamin Tatman",
      "Kanak Parmar",
      "Tyler Presser",
      "Sai Chikine",
      "Michael Grant",
      "Richard Poulson"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Gomez_Tackling_the_Satellite_Downlink_Bottleneck_with_Federated_Onboard_Learning_of_CVPRW_2024_paper.html": {
    "title": "Tackling the Satellite Downlink Bottleneck with Federated Onboard Learning of Image Compression",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pablo Gómez",
      "Gabriele Meoni"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Liu_Revisiting_the_Domain_Gap_Issue_in_Non-cooperative_Spacecraft_Pose_Tracking_CVPRW_2024_paper.html": {
    "title": "Revisiting the Domain Gap Issue in Non-cooperative Spacecraft Pose Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kun Liu",
      "Yongjun Yu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Mcleod_Robust_Perspective-n-Crater_for_Crater-based_Camera_Pose_Estimation_CVPRW_2024_paper.html": {
    "title": "Robust Perspective-n-Crater for Crater-based Camera Pose Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sofia Mcleod",
      "Chee Kheng Chng",
      "Tatsuharu Ono",
      "Yuta Shimizu",
      "Ryodo Hemmi",
      "Lachlan Holden",
      "Matthew Rodda",
      "Feras Dayoub",
      "Hirdy Miyamoto",
      "Yukihiro Takahashi",
      "Yasuko Kasai",
      "Tat-Jun Chin"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AI4Space/html/Murphy_Deploying_Machine_Learning_Anomaly_Detection_Models_to_Flight_Ready_AI_CVPRW_2024_paper.html": {
    "title": "Deploying Machine Learning Anomaly Detection Models to Flight Ready AI Boards",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Murphy",
      "Maria Buckley",
      "Leonie Buckley",
      "Adam Taylor",
      "Jake O'brien",
      "Brian Mac Namee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Soelistyo_Discovering_Interpretable_Models_of_Scientific_Image_Data_with_Deep_Learning_CVPRW_2024_paper.html": {
    "title": "Discovering Interpretable Models of Scientific Image Data with Deep Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Christopher J. Soelistyo",
      "Alan R. Lowe"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Yao_Weakly_Supervised_Set-Consistency_Learning_Improves_Morphological_Profiling_of_Single-Cell_Images_CVPRW_2024_paper.html": {
    "title": "Weakly Supervised Set-Consistency Learning Improves Morphological Profiling of Single-Cell Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Heming Yao",
      "Phil Hanslovsky",
      "Jan-Christian Huetter",
      "Burkhard Hoeckendorf",
      "David Richmond"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Aiyetigbo_Unsupervised_Microscopy_Video_Denoising_CVPRW_2024_paper.html": {
    "title": "Unsupervised Microscopy Video Denoising",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mary Aiyetigbo",
      "Alexander Korte",
      "Ethan Anderson",
      "Reda Chalhoub",
      "Peter Kalivas",
      "Feng Luo",
      "Nianyi Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Gopalakrishnan_Grad-CAMO_Learning_Interpretable_Single-Cell_Morphological_Profiles_from_3D_Cell_Painting_CVPRW_2024_paper.html": {
    "title": "Grad-CAMO: Learning Interpretable Single-Cell Morphological Profiles from 3D Cell Painting Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vivek Gopalakrishnan",
      "Jingzhe Ma",
      "Zhiyong Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Manne_NOISe_Nuclei-Aware_Osteoclast_Instance_Segmentation_for_Mouse-to-Human_Domain_Transfer_CVPRW_2024_paper.html": {
    "title": "NOISe: Nuclei-Aware Osteoclast Instance Segmentation for Mouse-to-Human Domain Transfer",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Kumar Reddy Manne",
      "Brendan Martin",
      "Tyler Roy",
      "Ryan Neilson",
      "Rebecca Peters",
      "Meghana Chillara",
      "Christine W. Lary",
      "Katherine J. Motyl",
      "Michael Wan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Gao_Triage_of_3D_Pathology_Data_via_2.5D_Multiple-instance_Learning_to_CVPRW_2024_paper.html": {
    "title": "Triage of 3D Pathology Data via 2.5D Multiple-instance Learning to Guide Pathologist Assessments",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gan Gao",
      "Andrew H. Song",
      "Fiona Wang",
      "David Brenes",
      "Rui Wang",
      "Sarah S.L. Chow",
      "Kevin W. Bishop",
      "Lawrence D. True",
      "Faisal Mahmood",
      "Jonathan T.C. Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Jiang_Super-resolution_of_Biomedical_Volumes_with_2D_Supervision_CVPRW_2024_paper.html": {
    "title": "Super-resolution of Biomedical Volumes with 2D Supervision",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Jiang",
      "Alexander Gedeon",
      "Yiwei Lyu",
      "Eric Landgraf",
      "Yufeng Zhang",
      "Xinhai Hou",
      "Akhil Kondepudi",
      "Asadur Chowdury",
      "Honglak Lee",
      "Todd Hollon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Yun_Uncertainty_Estimation_for_Tumor_Prediction_with_Unlabeled_Data_CVPRW_2024_paper.html": {
    "title": "Uncertainty Estimation for Tumor Prediction with Unlabeled Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juyoung Yun",
      "Shahira Abousamra",
      "Chen Li",
      "Rajarsi Gupta",
      "Tahsin Kurc",
      "Dimitris Samaras",
      "Alison Van Dyke",
      "Joel Saltz",
      "Chao Chen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Nasiri-Sarvi_Vim4Path_Self-Supervised_Vision_Mamba_for_Histopathology_Images_CVPRW_2024_paper.html": {
    "title": "Vim4Path: Self-Supervised Vision Mamba for Histopathology Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ali Nasiri-Sarvi",
      "Vincent Quoc-Huy Trinh",
      "Hassan Rivaz",
      "Mahdi S. Hosseini"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Ignatov_Histopathological_Image_Classification_with_Cell_Morphology_Aware_Deep_Neural_Networks_CVPRW_2024_paper.html": {
    "title": "Histopathological Image Classification with Cell Morphology Aware Deep Neural Networks",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrey Ignatov",
      "Josephine Yates",
      "Valentina Boeva"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Moller_Low-Resolution-Only_Microscopy_Super-Resolution_Models_Generalizing_to_Non-Periodicities_at_Atomic_Scale_CVPRW_2024_paper.html": {
    "title": "Low-Resolution-Only Microscopy Super-Resolution Models Generalizing to Non-Periodicities at Atomic Scale",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Björn Möller",
      "Zhengyang Li",
      "Markus Etzkorn",
      "Tim Fingscheidt"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/CVMI/html/Sauer_Refining_Biologically_Inconsistent_Segmentation_Masks_with_Masked_Autoencoders_CVPRW_2024_paper.html": {
    "title": "Refining Biologically Inconsistent Segmentation Masks with Masked Autoencoders",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Sauer",
      "Yuan Tian",
      "Joerg Bewersdorf",
      "Jens Rittscher"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/MMCM/html/Lee_An_End-to-End_Vision_Transformer_Approach_for_Image_Copy_Detection_CVPRW_2024_paper.html": {
    "title": "An End-to-End Vision Transformer Approach for Image Copy Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiahe Steven Lee",
      "Wynne Hsu",
      "Mong Li Lee"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Yang_An_Online_Approach_and_Evaluation_Method_for_Tracking_People_Across_CVPRW_2024_paper.html": {
    "title": "An Online Approach and Evaluation Method for Tracking People Across Cameras in Extremely Long Video Sequence",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng-Yen Yang",
      "Hsiang-Wei Huang",
      "Pyong-Kun Kim",
      "Zhongyu Jiang",
      "Kwang-Ju Kim",
      "Chung-I Huang",
      "Haiqing Du",
      "Jenq-Neng Hwang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Specker_OCMCTrack_Online_Multi-Target_Multi-Camera_Tracking_with_Corrective_Matching_Cascade_CVPRW_2024_paper.html": {
    "title": "OCMCTrack: Online Multi-Target Multi-Camera Tracking with Corrective Matching Cascade",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Specker"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Chen_An_Effective_Method_for_Detecting_Violation_of_Helmet_Rule_for_CVPRW_2024_paper.html": {
    "title": "An Effective Method for Detecting Violation of Helmet Rule for Motorcyclists",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunliang Chen",
      "Wei Zhou",
      "Zicen Zhou",
      "Bing Ma",
      "Chen Wang",
      "Yingda Shang",
      "An Guo",
      "Tianshu Chu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Otgonbold_Simple_In-place_Data_Augmentation_for_Surveillance_Object_Detection_CVPRW_2024_paper.html": {
    "title": "Simple In-place Data Augmentation for Surveillance Object Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Munkh-Erdene Otgonbold",
      "Ganzorig Batnasan",
      "Munkhjargal Gochoo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Duong_Robust_Data_Augmentation_and_Ensemble_Method_for_Object_Detection_in_CVPRW_2024_paper.html": {
    "title": "Robust Data Augmentation and Ensemble Method for Object Detection in Fisheye Camera Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Viet Hung Duong",
      "Duc Quyen Nguyen",
      "Thien Van Luong",
      "Huan Vu",
      "Tien Cuong Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Luo_FE-Det_An_Effective_Traffic_Object_Detection_Framework_for_Fish-Eye_Cameras_CVPRW_2024_paper.html": {
    "title": "FE-Det: An Effective Traffic Object Detection Framework for Fish-Eye Cameras",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xingshuang Luo",
      "Zhe Cui",
      "Fei Su"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Rahman_DeepLocalization_Using_Change_Point_Detection_for_Temporal_Action_Localization_CVPRW_2024_paper.html": {
    "title": "DeepLocalization: Using Change Point Detection for Temporal Action Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Shaiqur Rahman",
      "Ibne Farabi Shihab",
      "Lynna Chu",
      "Anuj Sharma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Cherdchusakulchai_Online_Multi-camera_People_Tracking_with_Spatial-temporal_Mechanism_and_Anchor-feature_Hierarchical_CVPRW_2024_paper.html": {
    "title": "Online Multi-camera People Tracking with Spatial-temporal Mechanism and Anchor-feature Hierarchical Clustering",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Riu Cherdchusakulchai",
      "Sasin Phimsiri",
      "Visarut Trairattanapa",
      "Suchat Tungjitnob",
      "Wasu Kudisthalert",
      "Pornprom Kiawjak",
      "Ek Thamwiwatthana",
      "Phawat Borisuitsawat",
      "Teepakorn Tosawadi",
      "Pakcheera Choppradi",
      "Kasisdis Mahakijdechachai",
      "Supawit Vatathanavaro",
      "Worawit Saetan",
      "Vasin Suttichaya"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Kim_Cluster_Self-Refinement_for_Enhanced_Online_Multi-Camera_People_Tracking_CVPRW_2024_paper.html": {
    "title": "Cluster Self-Refinement for Enhanced Online Multi-Camera People Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeongho Kim",
      "Wooksu Shin",
      "Hancheol Park",
      "Donghyuk Choi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Pham_Improving_Object_Detection_to_Fisheye_Cameras_with_Open-Vocabulary_Pseudo-Label_Approach_CVPRW_2024_paper.html": {
    "title": "Improving Object Detection to Fisheye Cameras with Open-Vocabulary Pseudo-Label Approach",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Long Hoang Pham",
      "Quoc Pham-Nam Ho",
      "Duong Nguyen-Ngoc Tran",
      "Tai Huu-Phuong Tran",
      "Huy-Hung Nguyen",
      "Duong Khac Vu",
      "Chi Dai Tran",
      "Ngoc Doan-Minh Huynh",
      "Hyung-Min Jeon",
      "Hyung-Joon Jeon",
      "Jae Wook Jeon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Nguyen_Multi-View_Spatial-Temporal_Learning_for_Understanding_Unusual_Behaviors_in_Untrimmed_Naturalistic_CVPRW_2024_paper.html": {
    "title": "Multi-View Spatial-Temporal Learning for Understanding Unusual Behaviors in Untrimmed Naturalistic Driving Videos",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huy-Hung Nguyen",
      "Chi Dai Tran",
      "Long Hoang Pham",
      "Duong Nguyen-Ngoc Tran",
      "Tai Huu-Phuong Tran",
      "Duong Khac Vu",
      "Quoc Pham-Nam Ho",
      "Ngoc Doan-Minh Huynh",
      "Hyung-Min Jeon",
      "Hyung-Joon Jeon",
      "Jae Wook Jeon"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Tran_Low-Light_Image_Enhancement_Framework_for_Improved_Object_Detection_in_Fisheye_CVPRW_2024_paper.html": {
    "title": "Low-Light Image Enhancement Framework for Improved Object Detection in Fisheye Lens Datasets",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dai Quoc Tran",
      "Armstrong Aboah",
      "Yuntae Jeon",
      "Maged Shoman",
      "Minsoo Park",
      "Seunghee Park"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Dinh_TrafficVLM_A_Controllable_Visual_Language_Model_for_Traffic_Video_Captioning_CVPRW_2024_paper.html": {
    "title": "TrafficVLM: A Controllable Visual Language Model for Traffic Video Captioning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quang Minh Dinh",
      "Minh Khoi Ho",
      "Anh Quan Dang",
      "Hung Phong Tran"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Shin_Road_Object_Detection_Robust_to_Distorted_Objects_at_the_Edge_CVPRW_2024_paper.html": {
    "title": "Road Object Detection Robust to Distorted Objects at the Edge Regions of Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wooksu Shin",
      "Donghyuk Choi",
      "Hancheol Park",
      "Jeongho Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Xuan_Divide_and_Conquer_Boosting_for_Enhanced_Traffic_Safety_Description_and_CVPRW_2024_paper.html": {
    "title": "Divide and Conquer Boosting for Enhanced Traffic Safety Description and Analysis with Large Vision Language Model",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khai Trinh Xuan",
      "Khoi Nguyen Nguyen",
      "Bach Hoang Ngo",
      "Vu Dinh Xuan",
      "Minh-Hung An",
      "Quang-Vinh Dinh"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Van_Luong_Motorcyclist_Helmet_Violation_Detection_Framework_by_Leveraging_Robust_Ensemble_and_CVPRW_2024_paper.html": {
    "title": "Motorcyclist Helmet Violation Detection Framework by Leveraging Robust Ensemble and Augmentation Methods",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thien Van Luong",
      "Huu Si Phuc Nguyen",
      "Duy Khanh Dinh",
      "Viet Hung Duong",
      "Duy Hong Sam Vo",
      "Huan Vu",
      "Minh Tuan Hoang",
      "Tien Cuong Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Zhang_Augmented_Self-Mask_Attention_Transformer_for_Naturalistic_Driving_Action_Recognition_CVPRW_2024_paper.html": {
    "title": "Augmented Self-Mask Attention Transformer for Naturalistic Driving Action Recognition",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tiantian Zhang",
      "Qingtian Wang",
      "Xiaodong Dong",
      "Wenqing Yu",
      "Hao Sun",
      "Xuyang Zhou",
      "Aigong Zhen",
      "Shun Cui",
      "Dong Wu",
      "Zhongjiang He"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Tran_Efficient_Online_Multi-Camera_Tracking_with_Memory-Efficient_Accumulated_Appearance_Features_and_CVPRW_2024_paper.html": {
    "title": "Efficient Online Multi-Camera Tracking with Memory-Efficient Accumulated Appearance Features and Trajectory Validation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lap Quoc Tran",
      "Huan Duc Vi"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Shoman_Enhancing_Traffic_Safety_with_Parallel_Dense_Video_Captioning_for_End-to-End_CVPRW_2024_paper.html": {
    "title": "Enhancing Traffic Safety with Parallel Dense Video Captioning for End-to-End Event Analysis",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maged Shoman",
      "Dongdong Wang",
      "Armstrong Aboah",
      "Mohamed Abdel-Aty"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Vo_Robust_Motorcycle_Helmet_Detection_in_Real-World_Scenarios_Using_Co-DETR_and_CVPRW_2024_paper.html": {
    "title": "Robust Motorcycle Helmet Detection in Real-World Scenarios: Using Co-DETR and Minority Class Enhancement",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Vo",
      "Sieu Tran",
      "Duc Minh Nguyen",
      "Thua Nguyen",
      "Tien Do",
      "Duy-Dinh Le",
      "Thanh Duc Ngo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Zhang_A_Coarse-to-fine_Two-stage_Helmet_Detection_Method_for_Motorcyclists_CVPRW_2024_paper.html": {
    "title": "A Coarse-to-fine Two-stage Helmet Detection Method for Motorcyclists",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongpu Zhang",
      "Zhe Cui",
      "Fei Su"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Yoshida_Overlap_Suppression_Clustering__for_Offline_Multi-Camera_People_Tracking_CVPRW_2024_paper.html": {
    "title": "Overlap Suppression Clustering for Offline Multi-Camera People Tracking",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryuto Yoshida",
      "Junichi Okubo",
      "Junichiro Fujii",
      "Masazumi Amakata",
      "Takayoshi Yamashita"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Wang_The_8th_AI_City_Challenge_CVPRW_2024_paper.html": {
    "title": "The 8th AI City Challenge",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Wang",
      "David C. Anastasiu",
      "Zheng Tang",
      "Ming-Ching Chang",
      "Yue Yao",
      "Liang Zheng",
      "Mohammed Shaiqur Rahman",
      "Meenakshi S. Arya",
      "Anuj Sharma",
      "Pranamesh Chakraborty",
      "Sanjita Prajapati",
      "Quan Kong",
      "Norimasa Kobori",
      "Munkhjargal Gochoo",
      "Munkh-Erdene Otgonbold",
      "Fady Alnajjar",
      "Ganzorig Batnasan",
      "Ping-Yang Chen",
      "Jun-Wei Hsieh",
      "Xunlei Wu",
      "Sameer Satish Pusegaonkar",
      "Yizhou Wang",
      "Sujit Biswas",
      "Rama Chellappa"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Gia_Enhancing_Road_Object_Detection_in_Fisheye_Cameras_An_Effective_Framework_CVPRW_2024_paper.html": {
    "title": "Enhancing Road Object Detection in Fisheye Cameras: An Effective Framework Integrating SAHI and Hybrid Inference",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bao Tran Gia",
      "Tuong Bui Cong Khanh",
      "Hien Ho Trong",
      "Thuyen Tran Doan",
      "Tien Do",
      "Duy-Dinh Le",
      "Thanh Duc Ngo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Xie_A_Robust_Online_Multi-Camera_People_Tracking_System_With_Geometric_Consistency_CVPRW_2024_paper.html": {
    "title": "A Robust Online Multi-Camera People Tracking System With Geometric Consistency and State-aware Re-ID Correction",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenyu Xie",
      "Zelin Ni",
      "Wenjie Yang",
      "Yuang Zhang",
      "Yihang Chen",
      "Yang Zhang",
      "Xiao Ma"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Wei_KI-GAN_Knowledge-Informed_Generative_Adversarial_Networks_for_Enhanced_Multi-Vehicle_Trajectory_Forecasting_CVPRW_2024_paper.html": {
    "title": "KI-GAN: Knowledge-Informed Generative Adversarial Networks for Enhanced Multi-Vehicle Trajectory Forecasting at Signalized Intersections",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chuheng Wei",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Kyungtae Han"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Xu_Multi-View_Action_Recognition_for_Distracted_Driver_Behavior_Localization_CVPRW_2024_paper.html": {
    "title": "Multi-View Action Recognition for Distracted Driver Behavior Localization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuehuan Xu",
      "Shuai Jiang",
      "Zhe Cui",
      "Fei Su"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/To_Multi-perspective_Traffic_Video_Description_Model_with_Fine-grained_Refinement_Approach_CVPRW_2024_paper.html": {
    "title": "Multi-perspective Traffic Video Description Model with Fine-grained Refinement Approach",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuan-An To",
      "Minh-Nam Tran",
      "Trong-Bao Ho",
      "Thien-Loc Ha",
      "Quang-Tan Nguyen",
      "Hoang-Chau Luong",
      "Thanh-Duy Cao",
      "Minh-Triet Tran"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/AICity/html/Duan_CityLLaVA_Efficient_Fine-Tuning_for_VLMs_in_City_Scenario_CVPRW_2024_paper.html": {
    "title": "CityLLaVA: Efficient Fine-Tuning for VLMs in City Scenario",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhizhao Duan",
      "Hao Cheng",
      "Duo Xu",
      "Xi Wu",
      "Xiangxie Zhang",
      "Xi Ye",
      "Zhen Xie"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Pal_Improving_Noisy_Fine-Grained_Datasets_using_Active_Label_Cleaning_Framework_CVPRW_2024_paper.html": {
    "title": "Improving Noisy Fine-Grained Datasets using Active Label Cleaning Framework",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Avik Pal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Li_DTLLM-VLT_Diverse_Text_Generation_for_Visual_Language_Tracking_Based_on_CVPRW_2024_paper.html": {
    "title": "DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on LLM",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xuchen Li",
      "Xiaokun Feng",
      "Shiyu Hu",
      "Meiqi Wu",
      "Dailing Zhang",
      "Jing Zhang",
      "Kaiqi Huang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Zhou_Optimizing_Object_Detection_via_Metric-driven_Training_Data_Selection_CVPRW_2024_paper.html": {
    "title": "Optimizing Object Detection via Metric-driven Training Data Selection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changyuan Zhou",
      "Yumin Guo",
      "Qinxue Lv",
      "Ji Yuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Khan_ALINA_Advanced_Line_Identification_and_Notation_Algorithm_CVPRW_2024_paper.html": {
    "title": "ALINA: Advanced Line Identification and Notation Algorithm",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammed Abdul Hafeez Khan",
      "Parth Ganeriwala",
      "Siddhartha Bhattacharyya",
      "Natasha Neogi",
      "Raja Muthalagu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Sanders_A_Survey_of_Video_Datasets_for_Grounded_Event_Understanding_CVPRW_2024_paper.html": {
    "title": "A Survey of Video Datasets for Grounded Event Understanding",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kate Sanders",
      "Benjamin Van Durme"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Chang_Classifier_Guided_Cluster_Density_Reduction_for_Dataset_Selection_CVPRW_2024_paper.html": {
    "title": "Classifier Guided Cluster Density Reduction for Dataset Selection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheng Chang",
      "Keyu Long",
      "Zijian Li",
      "Himanshu Rai"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Kolbeinsson_DDOS_The_Drone_Depth_and_Obstacle_Segmentation_Dataset_CVPRW_2024_paper.html": {
    "title": "DDOS: The Drone Depth and Obstacle Segmentation Dataset",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benedikt Kolbeinsson",
      "Krystian Mikolajczyk"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/VDU/html/Luo_Grounding_Stylistic_Domain_Generalization_with_Quantitative_Domain_Shift_Measures_and_CVPRW_2024_paper.html": {
    "title": "Grounding Stylistic Domain Generalization with Quantitative Domain Shift Measures and Synthetic Scene Images",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiran Luo",
      "Joshua Feinglass",
      "Tejas Gokhale",
      "Kuan-Cheng Lee",
      "Chitta Baral",
      "Yezhou Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NICE/html/Jeong_Technical_Report_of_NICE_Challenge_at_CVPR_2024_Caption_Re-ranking_CVPRW_2024_paper.html": {
    "title": "Technical Report of NICE Challenge at CVPR 2024: Caption Re-ranking Evaluation Using Ensembled CLIP and Consensus Scores",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiyoon Jeong",
      "Woojun Lee",
      "Woongchan Nam",
      "Minjeong Ma",
      "Pilsung Kang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NICE/html/Kim_NICE_CVPR_2023_Challenge_on_Zero-shot_Image_Captioning_CVPRW_2024_paper.html": {
    "title": "NICE: CVPR 2023 Challenge on Zero-shot Image Captioning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taehoon Kim",
      "Pyunghwan Ahn",
      "Sangyun Kim",
      "Sihaeng Lee",
      "Mark Marsden",
      "Alessandra Sala",
      "Seung Hwan Kim",
      "Bohyung Han",
      "Kyoung Mu Lee",
      "Honglak Lee",
      "Kyounghoon Bae",
      "Xiangyu Wu",
      "Yi Gao",
      "Hailiang Zhang",
      "Yang Yang",
      "Weili Guo",
      "Jianfeng Lu",
      "Youngtaek Oh",
      "Jae Won Cho",
      "Dong-Jin Kim",
      "In So Kweon",
      "Junmo Kim",
      "Wooyoung Kang",
      "Won Young Jhoo",
      "Byungseok Roh",
      "Jonghwan Mun",
      "Solgil Oh",
      "Kenan Emir Ak",
      "Gwang-Gook Lee",
      "Yan Xu",
      "Mingwei Shen",
      "Kyomin Hwang",
      "Wonsik Shin",
      "Kamin Lee",
      "Wonhark Park",
      "Dongkwan Lee",
      "Nojun Kwak",
      "Yujin Wang",
      "Yimu Wang",
      "Tiancheng Gu",
      "Xingchang Lv",
      "Mingmao Sun"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/NICE/html/Kim_Large-Scale_Bidirectional_Training_for_Zero-Shot_Image_Captioning_CVPRW_2024_paper.html": {
    "title": "Large-Scale Bidirectional Training for Zero-Shot Image Captioning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taehoon Kim",
      "Mark Marsden",
      "Pyunghwan Ahn",
      "Sangyun Kim",
      "Sihaeng Lee",
      "Alessandra Sala",
      "Seung Hwan Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Bodur_iEdit_Localised_Text-guided_Image_Editing_with_Weak_Supervision_CVPRW_2024_paper.html": {
    "title": "iEdit: Localised Text-guided Image Editing with Weak Supervision",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rumeysa Bodur",
      "Erhan Gundogdu",
      "Binod Bhattarai",
      "Tae-Kyun Kim",
      "Michael Donoser",
      "Loris Bazzani"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Eshratifar_Salient_Object-Aware_Background_Generation_using_Text-Guided_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "Salient Object-Aware Background Generation using Text-Guided Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amir Erfan Eshratifar",
      "Joao V.B. Soares",
      "Kapil Thadani",
      "Shaunak Mishra",
      "Mikhail Kuznetsov",
      "Yueh-Ning Ku",
      "Paloma De Juan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Le_Coz_Efficient_Exploration_of_Image_Classifier_Failures_with_Bayesian_Optimization_and_CVPRW_2024_paper.html": {
    "title": "Efficient Exploration of Image Classifier Failures with Bayesian Optimization and Text-to-Image Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adrien Le Coz",
      "Houssem Ouertatani",
      "Stéphane Herbin",
      "Faouzi Adjed"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Khan_AI_Art_Neural_Constellation_Revealing_the_Collective_and_Contrastive_State_CVPRW_2024_paper.html": {
    "title": "AI Art Neural Constellation: Revealing the Collective and Contrastive State of AI-Generated and Human Art",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Faizan Farooq Khan",
      "Diana Kim",
      "Divyansh Jha",
      "Youssef Mohamed",
      "Hanna H Chang",
      "Ahmed Elgammal",
      "Luba Elliott",
      "Mohamed Elhoseiny"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Kalluri_Robust_Disaster_Assessment_from_Aerial_Imagery_Using_Text-to-Image_Synthetic_Data_CVPRW_2024_paper.html": {
    "title": "Robust Disaster Assessment from Aerial Imagery Using Text-to-Image Synthetic Data",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tarun Kalluri",
      "Jihyeon Lee",
      "Kihyuk Sohn",
      "Sahil Singla",
      "Manmohan Chandraker",
      "Joseph Xu",
      "Jeremiah Liu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Wang_OmniControlNet_Dual-stage_Integration_for_Conditional_Image_Generation_CVPRW_2024_paper.html": {
    "title": "OmniControlNet: Dual-stage Integration for Conditional Image Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yilin Wang",
      "Haiyang Xu",
      "Xiang Zhang",
      "Zeyuan Chen",
      "Zhizhou Sha",
      "Zirui Wang",
      "Zhuowen Tu"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Demir_MixSyn_Compositional_Image_Synthesis_with_Fuzzy_Masks_and_Style_Fusion_CVPRW_2024_paper.html": {
    "title": "MixSyn: Compositional Image Synthesis with Fuzzy Masks and Style Fusion",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilke Demir",
      "Umur Aybars Ciftci"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Bourigault_MVDiff_Scalable_and_Flexible_Multi-view_Diffusion_for_3D_Object_Reconstruction_CVPRW_2024_paper.html": {
    "title": "MVDiff: Scalable and Flexible Multi-view Diffusion for 3D Object Reconstruction from Single-View",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emmanuelle Bourigault",
      "Pauline Bourigault"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Azarian_Segmentation-Free_Guidance_for_Text-to-Image_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "Segmentation-Free Guidance for Text-to-Image Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kambiz Azarian",
      "Debasmit Das",
      "Qiqi Hou",
      "Fatih Porikli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Eldesokey_LATENTMAN_Generating_Consistent_Animated_Characters_using_Image_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "LATENTMAN: Generating Consistent Animated Characters using Image Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abdelrahman Eldesokey",
      "Peter Wonka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Slavcheva_An_Empty_Room_is_All_We_Want_Automatic_Defurnishing_of_CVPRW_2024_paper.html": {
    "title": "An Empty Room is All We Want: Automatic Defurnishing of Indoor Panoramas",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mira Slavcheva",
      "Dave Gausebeck",
      "Kevin Chen",
      "David Buchhofer",
      "Azwad Sabik",
      "Chen Ma",
      "Sachal Dhillon",
      "Olaf Brandt",
      "Alan Dolhasz"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Dasgupta_Can_Synthetic_Plant_Images_From_Generative_Models_Facilitate_Rare_Species_CVPRW_2024_paper.html": {
    "title": "Can Synthetic Plant Images From Generative Models Facilitate Rare Species Identification and Classification?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Debajyoti Dasgupta",
      "Arijit Mondal",
      "Partha P. Chakrabarti"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Motamed_Investigating_the_Effectiveness_of_Cross-Attention_to_Unlock_Zero-Shot_Editing_of_CVPRW_2024_paper.html": {
    "title": "Investigating the Effectiveness of Cross-Attention to Unlock Zero-Shot Editing of Text-to-Video Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saman Motamed",
      "Wouter Van Gansbeke",
      "Luc Van Gool"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Huang_PQ-VAE_Learning_Hierarchical_Discrete_Representations_with_Progressive_Quantization_CVPRW_2024_paper.html": {
    "title": "PQ-VAE: Learning Hierarchical Discrete Representations with Progressive Quantization",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lun Huang",
      "Qiang Qiu",
      "Guillermo Sapiro"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Esposito_GeoGen_Geometry-Aware_Generative_Modeling_via_Signed_Distance_Functions_CVPRW_2024_paper.html": {
    "title": "GeoGen: Geometry-Aware Generative Modeling via Signed Distance Functions",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Salvatore Esposito",
      "Qingshan Xu",
      "Kacper Kania",
      "Charlie Hewitt",
      "Octave Mariotti",
      "Lohit Petikam",
      "Julien Valentin",
      "Arno Onken",
      "Oisin Mac Aodha"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Harsha_GenVideo_One-shot_Target-image_and_Shape_Aware_Video_Editing_using_T2I_CVPRW_2024_paper.html": {
    "title": "GenVideo: One-shot Target-image and Shape Aware Video Editing using T2I Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sai Sree Harsha",
      "Ambareesh Revanur",
      "Dhwanit Agarwal",
      "Shradha Agrawal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Weng_ART-V_Auto-Regressive_Text-to-Video_Generation_with_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "ART-V: Auto-Regressive Text-to-Video Generation with Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenming Weng",
      "Ruoyu Feng",
      "Yanhui Wang",
      "Qi Dai",
      "Chunyu Wang",
      "Dacheng Yin",
      "Zhiyuan Zhao",
      "Kai Qiu",
      "Jianmin Bao",
      "Yuhui Yuan",
      "Chong Luo",
      "Yueyi Zhang",
      "Zhiwei Xiong"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Nguyen_Contrastive_Clothing_and_Pose_Generation_for_Cloth-Changing_Person_Re-Identification_CVPRW_2024_paper.html": {
    "title": "Contrastive Clothing and Pose Generation for Cloth-Changing Person Re-Identification",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vuong D. Nguyen",
      "Pranav Mantini",
      "Shishir K. Shah"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Wang_StereoDiffusion_Training-Free_Stereo_Image_Generation_Using_Latent_Diffusion_Models_CVPRW_2024_paper.html": {
    "title": "StereoDiffusion: Training-Free Stereo Image Generation Using Latent Diffusion Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lezhong Wang",
      "Jeppe Revall Frisvad",
      "Mark Bo Jensen",
      "Siavash Arjomand Bigdeli"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/GCV/html/Pham_Style_Transfer_for_2D_Talking_Head_Generation_CVPRW_2024_paper.html": {
    "title": "Style Transfer for 2D Talking Head Generation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Trong Thang Pham",
      "Tuong Do",
      "Nhat Le",
      "Ngan Le",
      "Hung Nguyen",
      "Erman Tjiputra",
      "Quang Tran",
      "Anh Nguyen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OpenSUN3D/html/Qian_AffordanceLLM_Grounding_Affordance_from_Vision_Language_Models_CVPRW_2024_paper.html": {
    "title": "AffordanceLLM: Grounding Affordance from Vision Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shengyi Qian",
      "Weifeng Chen",
      "Min Bai",
      "Xiong Zhou",
      "Zhuowen Tu",
      "Li Erran Li"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/OpenSUN3D/html/Ton_Zero-Shot_Dual-Path_Integration_Framework_for_Open-Vocabulary_3D_Instance_Segmentation_CVPRW_2024_paper.html": {
    "title": "Zero-Shot Dual-Path Integration Framework for Open-Vocabulary 3D Instance Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tri Ton",
      "Ji Woo Hong",
      "Soohwan Eom",
      "Jun Yeop Shim",
      "Junyeong Kim",
      "Chang D. Yoo"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/USM/html/Damicantonio_uTRAND_Unsupervised_Anomaly_Detection_in_Traffic_Trajectories_CVPRW_2024_paper.html": {
    "title": "uTRAND: Unsupervised Anomaly Detection in Traffic Trajectories",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Giacomo D'amicantonio",
      "Egor Bondarau",
      "Peter H.N. De With"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/USM/html/Melekhov_ECLAIR_A_High-Fidelity_Aerial_LiDAR_Dataset_for_Semantic_Segmentation_CVPRW_2024_paper.html": {
    "title": "ECLAIR: A High-Fidelity Aerial LiDAR Dataset for Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iaroslav Melekhov",
      "Anand Umashankar",
      "Hyeong-Jin Kim",
      "Vladislav Serkov",
      "Dusty Argyle"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/USM/html/Hansen_OpenTrench3D_A_Photogrammetric_3D_Point_Cloud_Dataset_for_Semantic_Segmentation_CVPRW_2024_paper.html": {
    "title": "OpenTrench3D: A Photogrammetric 3D Point Cloud Dataset for Semantic Segmentation of Underground Utilities",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lasse H. Hansen",
      "Simon B. Jensen",
      "Mark P. Philipsen",
      "Andreas Møgelmose",
      "Lars Bodum",
      "Thomas B. Moeslund"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/USM/html/Bauchet_SimpliCity_Reconstructing_Buildings_with_Simple_Regularized_3D_Models_CVPRW_2024_paper.html": {
    "title": "SimpliCity: Reconstructing Buildings with Simple Regularized 3D Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jean-Philippe Bauchet",
      "Raphael Sulzer",
      "Florent Lafarge",
      "Yuliya Tarabalka"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/USM/html/Du_AsymFormer_Asymmetrical_Cross-Modal_Representation_Learning_for_Mobile_Platform_Real-Time_RGB-D_CVPRW_2024_paper.html": {
    "title": "AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile Platform Real-Time RGB-D Semantic Segmentation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siqi Du",
      "Weixi Wang",
      "Renzhong Guo",
      "Ruisheng Wang",
      "Shengjun Tang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Lee_Coreset_Selection_for_Object_Detection_CVPRW_2024_paper.html": {
    "title": "Coreset Selection for Object Detection",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hojun Lee",
      "Suyoung Kim",
      "Junhoo Lee",
      "Jaeyoung Yoo",
      "Nojun Kwak"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Kim_AugData_Distillation_for_Monocular_3D_Human_Pose_Estimation_CVPRW_2024_paper.html": {
    "title": "AugData Distillation for Monocular 3D Human Pose Estimation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiman Kim"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Wei_Dataset_Condensation_with_Latent_Quantile_Matching_CVPRW_2024_paper.html": {
    "title": "Dataset Condensation with Latent Quantile Matching",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Wei",
      "Tom De Schepper",
      "Kevin Mets"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/He_Large-scale_Dataset_Pruning_with_Dynamic_Uncertainty_CVPRW_2024_paper.html": {
    "title": "Large-scale Dataset Pruning with Dynamic Uncertainty",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muyang He",
      "Shuo Yang",
      "Tiejun Huang",
      "Bo Zhao"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Li_Generative_Dataset_Distillation_Balancing_Global_Structure_and_Local_Details_CVPRW_2024_paper.html": {
    "title": "Generative Dataset Distillation: Balancing Global Structure and Local Details",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Longzhen Li",
      "Guang Li",
      "Ren Togo",
      "Keisuke Maeda",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Lu_Exploring_the_Impact_of_Dataset_Bias_on_Dataset_Distillation_CVPRW_2024_paper.html": {
    "title": "Exploring the Impact of Dataset Bias on Dataset Distillation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yao Lu",
      "Jianyang Gu",
      "Xuguang Chen",
      "Saeed Vahidian",
      "Qi Xuan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Rana_DEEPDISTAL_Deepfake_Dataset_Distillation_using_Active_Learning_CVPRW_2024_paper.html": {
    "title": "DEEPDISTAL: Deepfake Dataset Distillation using Active Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Md Shohel Rana",
      "Mohammad Nur Nobi",
      "Andrew Sung"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/DDCV/html/Khaki_ATOM_Attention_Mixer_for_Efficient_Dataset_Distillation_CVPRW_2024_paper.html": {
    "title": "ATOM: Attention Mixer for Efficient Dataset Distillation",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samir Khaki",
      "Ahmad Sajedi",
      "Kai Wang",
      "Lucy Z. Liu",
      "Yuri A. Lawryshyn",
      "Konstantinos N. Plataniotis"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Shi_Data-free_Model_Fusion_with_Generator_Assistants_CVPRW_2024_paper.html": {
    "title": "Data-free Model Fusion with Generator Assistants",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luyao Shi",
      "Prashanth Vijayaraghavan",
      "Ehsan Degan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Fan_POPE_6-DoF_Promptable_Pose_Estimation_of_Any_Object_in_Any_CVPRW_2024_paper.html": {
    "title": "POPE: 6-DoF Promptable Pose Estimation of Any Object in Any Scene with One Reference",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhiwen Fan",
      "Panwang Pan",
      "Peihao Wang",
      "Yifan Jiang",
      "Dejia Xu",
      "Zhangyang Wang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Aygun_Enhancing_2D_Representation_Learning_with_a_3D_Prior_CVPRW_2024_paper.html": {
    "title": "Enhancing 2D Representation Learning with a 3D Prior",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehmet Aygun",
      "Prithviraj Dhar",
      "Zhicheng Yan",
      "Oisin Mac Aodha",
      "Rakesh Ranjan"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Majurski_A_Method_of_Moments_Embedding_Constraint_and_its_Application_to_CVPRW_2024_paper.html": {
    "title": "A Method of Moments Embedding Constraint and its Application to Semi-Supervised Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Majurski",
      "Sumeet Menon",
      "Parniyan Favardin",
      "David Chapman"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Xing_Vision-Language_Pseudo-Labels_for_Single-Positive_Multi-Label_Learning_CVPRW_2024_paper.html": {
    "title": "Vision-Language Pseudo-Labels for Single-Positive Multi-Label Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xin Xing",
      "Zhexiao Xiong",
      "Abby Stylianou",
      "Srikumar Sastry",
      "Liyu Gong",
      "Nathan Jacobs"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Zhang_i-MAE_Are_Latent_Representations_in_Masked_Autoencoders_Linearly_Separable_CVPRW_2024_paper.html": {
    "title": "i-MAE: Are Latent Representations in Masked Autoencoders Linearly Separable?",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Zhang",
      "Zhiqiang Shen"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Feinglass_Eyes_of_a_Hawk_and_Ears_of_a_Fox_Part_CVPRW_2024_paper.html": {
    "title": "`Eyes of a Hawk and Ears of a Fox': Part Prototype Network for Generalized Zero-Shot Learning",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua Feinglass",
      "Jayaraman J. Thiagarajan",
      "Rushil Anirudh",
      "T.S. Jayram",
      "Yezhou Yang"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Soni_Federated_Learning_with_a_Single_Shared_Image_CVPRW_2024_paper.html": {
    "title": "Federated Learning with a Single Shared Image",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sunny Soni",
      "Aaqib Saeed",
      "Yuki M. Asano"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Khandelwal_PromptSync_Bridging_Domain_Gaps_in_Vision-Language_Models_through_Class-Aware_Prototype_CVPRW_2024_paper.html": {
    "title": "PromptSync: Bridging Domain Gaps in Vision-Language Models through Class-Aware Prototype Alignment and Discrimination",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anant Khandelwal"
    ]
  },
  "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/html/Hirohashi_Prompt_Learning_with_One-Shot_Setting_based_Feature_Space_Analysis_in_CVPRW_2024_paper.html": {
    "title": "Prompt Learning with One-Shot Setting based Feature Space Analysis in Vision-and-Language Models",
    "volume": "workshop",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuki Hirohashi",
      "Tsubasa Hirakawa",
      "Takayoshi Yamashita",
      "Hironobu Fujiyoshi"
    ]
  }
}