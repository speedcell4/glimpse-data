{
  "http://arxiv.org/abs/2401.01879": {
    "title": "Theoretical guarantees on the best-of-n alignment policy",
    "volume": "Jan",
    "abstract": "A simple and effective method for the alignment of generative models is the best-of-$n$ policy, where $n$ samples are drawn from a base policy, and ranked based on a reward function, and the highest ranking one is selected. A commonly used analytical expression in the literature claims that the KL divergence between the best-of-$n$ policy and the base policy is equal to $\\log (n) - (n-1)/n.$ We disprove the validity of this claim, and show that it is an upper bound on the actual KL divergence. We also explore the tightness of this upper bound in different regimes. Finally, we propose a new estimator for the KL divergence and empirically show that it provides a tight approximation through a few examples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad Beirami",
      "Alekh Agarwal",
      "Jonathan Berant",
      "Alexander D'Amour",
      "Jacob Eisenstein",
      "Chirag Nagpal",
      "Ananda Theertha Suresh"
    ]
  },
  "http://arxiv.org/abs/2401.01862": {
    "title": "A Vision Check-up for Language Models",
    "volume": "Jan",
    "abstract": "What does learning to model relationships between strings teach large language models (LLMs) about the visual world? We systematically evaluate LLMs' abilities to generate and recognize an assortment of visual concepts of increasing complexity and then demonstrate how a preliminary visual representation learning system can be trained using models of text. As language models lack the ability to consume or output visual information as pixels, we use code to represent images in our study. Although LLM-generated images do not look like natural images, results on image generation and the ability of models to correct these generated images indicate that precise modeling of strings can teach language models about numerous aspects of the visual world. Furthermore, experiments on self-supervised visual representation learning, utilizing images generated with text models, highlight the potential to train vision models capable of making semantic assessments of natural images using just LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratyusha Sharma",
      "Tamar Rott Shaham",
      "Manel Baradad",
      "Stephanie Fu",
      "Adrian Rodriguez-Munoz",
      "Shivam Duggal",
      "Phillip Isola",
      "Antonio Torralba"
    ]
  },
  "http://arxiv.org/abs/2401.01854": {
    "title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality",
    "volume": "Jan",
    "abstract": "As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those languages. Finally, we find that increasing the number of languages in the instruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual generalization. Our results suggest that building massively multilingual instruction-tuned models can be done with only a very small set of multilingual instruction-responses",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Uri Shaham",
      "Jonathan Herzig",
      "Roee Aharoni",
      "Idan Szpektor",
      "Reut Tsarfaty",
      "Matan Eyal"
    ]
  },
  "http://arxiv.org/abs/2401.01843": {
    "title": "Investigating Semi-Supervised Learning Algorithms in Text Datasets",
    "volume": "Jan",
    "abstract": "Using large training datasets enhances the generalization capabilities of neural networks. Semi-supervised learning (SSL) is useful when there are few labeled data and a lot of unlabeled data. SSL methods that use data augmentation are most successful for image datasets. In contrast, texts do not have consistent augmentation methods as images. Consequently, methods that use augmentation are not as effective in text data as they are in image data. In this study, we compared SSL algorithms that do not require augmentation; these are self-training, co-training, tri-training, and tri-training with disagreement. In the experiments, we used 4 different text datasets for different tasks. We examined the algorithms from a variety of perspectives by asking experiment questions and suggested several improvements. Among the algorithms, tri-training with disagreement showed the closest performance to the Oracle; however, performance gap shows that new semi-supervised algorithms or improvements in existing methods are needed",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Himmet Toprak Kesgin",
      "Mehmet Fatih Amasyali"
    ]
  },
  "http://arxiv.org/abs/2401.01830": {
    "title": "Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling",
    "volume": "Jan",
    "abstract": "Data augmentation is an effective technique for improving the performance of machine learning models. However, it has not been explored as extensively in natural language processing (NLP) as it has in computer vision. In this paper, we propose a novel text augmentation method that leverages the Fill-Mask feature of the transformer-based BERT model. Our method involves iteratively masking words in a sentence and replacing them with language model predictions. We have tested our proposed method on various NLP tasks and found it to be effective in many cases. Our results are presented along with a comparison to existing augmentation methods. Experimental results show that our proposed method significantly improves performance, especially on topic classification datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Himmet Toprak Kesgin",
      "Mehmet Fatih Amasyali"
    ]
  },
  "http://arxiv.org/abs/2401.01825": {
    "title": "Physio: An LLM-Based Physiotherapy Advisor",
    "volume": "Jan",
    "abstract": "The capabilities of the most recent language models have increased the interest in integrating them into real-world applications. However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being. In this paper, we present Physio, a chat-based application for physical rehabilitation. Physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided. Furthermore, drawing upon external knowledge databases, Physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief. By combining these features, Physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources. A live demo of Physio is available at https://physio.inesctec.pt",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rúben Almeida",
      "Hugo Sousa",
      "Luís F. Cunha",
      "Nuno Guimarães",
      "Ricardo Campos",
      "Alípio Jorge"
    ]
  },
  "http://arxiv.org/abs/2401.01780": {
    "title": "Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering",
    "volume": "Jan",
    "abstract": "While Large Language Models (LLM) are able to accumulate and restore knowledge, they are still prone to hallucination. Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers. Augmenting these models with the ability to search on external information sources, such as the web, is a promising approach to ground knowledge to retrieve information. However, searching in a large collection of documents introduces additional computational/time costs. An optimal behavior would be to query external resources only when the LLM is not confident about answers. In this paper, we propose a new LLM able to self-estimate if it is able to answer directly or needs to request an external tool. We investigate a supervised approach by introducing a hallucination masking mechanism in which labels are generated using a close book question-answering task. In addition, we propose to leverage parameter-efficient fine-tuning techniques to train our model on a small amount of data. Our model directly provides answers for $78.2\\%$ of the known queries and opts to search for $77.2\\%$ of the unknown ones. This results in the API being utilized only $62\\%$ of the time",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pierre Erbacher",
      "Louis Falissar",
      "Vincent Guigue",
      "Laure Soulier"
    ]
  },
  "http://arxiv.org/abs/2401.01761": {
    "title": "Cross-target Stance Detection by Exploiting Target Analytical Perspectives",
    "volume": "Jan",
    "abstract": "Cross-target stance detection (CTSD) is an important task, which infers the attitude of the destination target by utilizing annotated data derived from the source target. One important approach in CTSD is to extract domain-invariant features to bridge the knowledge gap between multiple targets. However, the analysis of informal and short text structure, and implicit expressions, complicate the extraction of domain-invariant knowledge. In this paper, we propose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the analysis perspective as a bridge to transfer knowledge. First, we develop a two-stage instruct-based chain-of-thought method (TsCoT) to elicit target analysis perspectives and provide natural language explanations (NLEs) from multiple viewpoints by formulating instructions based on large language model (LLM). Second, we propose a multi-perspective prompt-tuning framework (MultiPLN) to fuse the NLEs into the stance predictor. Extensive experiments results demonstrate the superiority of MPPT against the state-of-the-art baseline methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daijun Ding",
      "Rong Chen",
      "Liwen Jing",
      "Bowen Zhang",
      "Xu Huang",
      "Li Dong",
      "Xiaowen Zhao",
      "Ge Song"
    ]
  },
  "http://arxiv.org/abs/2401.01759": {
    "title": "VGA: Vision and Graph Fused Attention Network for Rumor Detection",
    "volume": "Jan",
    "abstract": "With the development of social media, rumors have been spread broadly on social media platforms, causing great harm to society. Beside textual information, many rumors also use manipulated images or conceal textual information within images to deceive people and avoid being detected, making multimodal rumor detection be a critical problem. The majority of multimodal rumor detection methods mainly concentrate on extracting features of source claims and their corresponding images, while ignoring the comments of rumors and their propagation structures. These comments and structures imply the wisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these methods usually only extract visual features in a basic manner, seldom consider tampering or textual information in images. Therefore, in this study, we propose a novel Vision and Graph Fused Attention Network (VGA) for rumor detection to utilize propagation structures among posts so as to obtain the crowd opinions and further explore visual tampering features, as well as the textual information hidden in images. We conduct extensive experiments on three datasets, demonstrating that VGA can effectively detect multimodal rumors and outperform state-of-the-art methods significantly",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lin Bai",
      "Caiyan Jia",
      "Ziying Song",
      "Chaoqun Cui"
    ]
  },
  "http://arxiv.org/abs/2401.01711": {
    "title": "Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs",
    "volume": "Jan",
    "abstract": "Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-shot performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Phillip Schneider",
      "Manuel Klettner",
      "Kristiina Jokinen",
      "Elena Simperl",
      "Florian Matthes"
    ]
  },
  "http://arxiv.org/abs/2401.01699": {
    "title": "WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope",
    "volume": "Jan",
    "abstract": "This paper introduces the WordArt Designer API, a novel framework for user-driven artistic typography synthesis utilizing Large Language Models (LLMs) on ModelScope. We address the challenge of simplifying artistic typography for non-professionals by offering a dynamic, adaptive, and computationally efficient alternative to traditional rigid templates. Our approach leverages the power of LLMs to understand and interpret user input, facilitating a more intuitive design process. We demonstrate through various case studies how users can articulate their aesthetic preferences and functional requirements, which the system then translates into unique and creative typographic designs. Our evaluations indicate significant improvements in user satisfaction, design flexibility, and creative expression over existing systems. The WordArt Designer API not only democratizes the art of typography but also opens up new possibilities for personalized digital communication and design",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun-Yan He",
      "Zhi-Qi Cheng",
      "Chenyang Li",
      "Jingdong Sun",
      "Wangmeng Xiang",
      "Yusen Hu",
      "Xianhui Lin",
      "Xiaoyang Kang",
      "Zengke Jin",
      "Bin Luo",
      "Yifeng Geng",
      "Xuansong Xie",
      "Jingren Zhou"
    ]
  },
  "http://arxiv.org/abs/2401.01698": {
    "title": "Patterns of Persistence and Diffusibility across World's Languages",
    "volume": "Jan",
    "abstract": "Language similarities can be caused by genetic relatedness, areal contact, universality, or chance. Colexification, i.e.~a type of similarity where a single lexical form is used to convey multiple meanings, is underexplored. In our work, we shed light on the linguistic causes of cross-lingual similarity in colexification and phonology, by exploring genealogical stability (persistence) and contact-induced change (diffusibility). We construct large-scale graphs incorporating semantic, genealogical, phonological and geographical data for 1,966 languages. We then show the potential of this resource, by investigating several established hypotheses from previous work in linguistics, while proposing new ones. Our results strongly support a previously established hypothesis in the linguistic literature, while offering contradicting evidence to another. Our large scale resource opens for further research across disciplines, e.g.~in multilingual NLP and comparative linguistics",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyi Chen",
      "Johannes Bjerva"
    ]
  },
  "http://arxiv.org/abs/2401.01692": {
    "title": "Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches",
    "volume": "Jan",
    "abstract": "Effective collaboration requires groups to strategically regulate themselves to overcome challenges. Research has shown that groups may fail to regulate due to differences in members' perceptions of challenges which may benefit from external support. In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated. The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. The paper provides an extensive discussion of the three approaches' performance for automated detection and support of students' challenge moments in collaborative learning activities. It argues that, although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation. We conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wannapon Suraworachet",
      "Jennifer Seon",
      "Mutlu Cukurova"
    ]
  },
  "http://arxiv.org/abs/2401.01667": {
    "title": "MLPs Compass: What is learned when MLPs are combined with PLMs?",
    "volume": "Jan",
    "abstract": "While Transformer-based pre-trained language models and their variants exhibit strong semantic representation capabilities, the question of comprehending the information gain derived from the additional components of PLMs remains an open question in this field. Motivated by recent efforts that prove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture capabilities, even outperforming Graph Neural Networks (GNNs), this paper aims to quantify whether simple MLPs can further enhance the already potent ability of PLMs to capture linguistic information. Specifically, we design a simple yet effective probing framework containing MLPs components based on BERT structure and conduct extensive experiments encompassing 10 probing tasks spanning three distinct linguistic levels. The experimental results demonstrate that MLPs can indeed enhance the comprehension of linguistic structure by PLMs. Our research provides interpretable and valuable insights into crafting variations of PLMs utilizing MLPs for tasks that emphasize diverse linguistic structures",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Li Zhou",
      "Wenyu Chen",
      "Yong Cao",
      "Dingyi Zeng",
      "Wanlong Liu",
      "Hong Qu"
    ]
  },
  "http://arxiv.org/abs/2401.01637": {
    "title": "Social Media Ready Caption Generation for Brands",
    "volume": "Jan",
    "abstract": "Social media advertisements are key for brand marketing, aiming to attract consumers with captivating captions and pictures or logos. While previous research has focused on generating captions for general images, incorporating brand personalities into social media captioning remains unexplored. Brand personalities are shown to be affecting consumers' behaviours and social interactions and thus are proven to be a key aspect of marketing strategies. Current open-source multimodal LLMs are not directly suited for this task. Hence, we propose a pipeline solution to assist brands in creating engaging social media captions that align with the image and the brand personalities. Our architecture is based on two parts: a the first part contains an image captioning model that takes in an image that the brand wants to post online and gives a plain English caption; b the second part takes in the generated caption along with the target brand personality and outputs a catchy personality-aligned social media caption. Along with brand personality, our system also gives users the flexibility to provide hashtags, Instagram handles, URLs, and named entities they want the caption to contain, making the captions more semantically related to the social media handles. Comparative evaluations against various baselines demonstrate the effectiveness of our approach, both qualitatively and quantitatively",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Himanshu Maheshwari",
      "Koustava Goswami",
      "Apoorv Saxena",
      "Balaji Vasan Srinivasan"
    ]
  },
  "http://arxiv.org/abs/2401.01623": {
    "title": "Can AI Be as Creative as Humans?",
    "volume": "Jan",
    "abstract": "Creativity serves as a cornerstone for societal progress and innovation, but its assessment remains a complex and often subjective endeavor. With the rise of advanced generative AI models capable of tasks once reserved for human creativity, the study of AI's creative potential becomes imperative for its responsible development and application. This paper addresses the complexities in defining and evaluating creativity by introducing a new concept called Relative Creativity. Instead of trying to define creativity universally, we shift the focus to whether AI can match the creative abilities of a hypothetical human. This perspective draws inspiration from the Turing Test, expanding upon it to address the challenges and subjectivities inherent in evaluating creativity. This methodological shift facilitates a statistically quantifiable evaluation of AI's creativity, which we term Statistical Creativity. This approach allows for direct comparisons of AI's creative abilities with those of specific human groups. Building on this foundation, we discuss the application of statistical creativity in contemporary prompt-conditioned autoregressive models. In addition to defining and analyzing a measure of creativity, we introduce an actionable training guideline, effectively bridging the gap between theoretical quantification of creativity and practical model training. Through these multifaceted contributions, the paper establishes a cohesive, continuously evolving, and transformative framework for assessing and fostering statistical creativity in AI models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haonan Wang",
      "James Zou",
      "Michael Mozer",
      "Linjun Zhang",
      "Anirudh Goyal",
      "Alex Lamb",
      "Zhun Deng",
      "Michael Qizhe Xie",
      "Hannah Brown",
      "Kenji Kawaguchi"
    ]
  },
  "http://arxiv.org/abs/2401.01620": {
    "title": "Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication",
    "volume": "Jan",
    "abstract": "We investigate whether general-domain large language models such as GPT-4 Turbo can perform risk stratification and predict post-operative outcome measures using a description of the procedure and a patient's clinical notes derived from the electronic health record. We examine predictive performance on 8 different tasks: prediction of ASA Physical Status Classification, hospital admission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1 duration, hospital duration, and ICU duration. Few-shot and chain-of-thought prompting improves predictive performance for several of the tasks. We achieve F1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU admission, and 0.86 for hospital mortality. Performance on duration prediction tasks were universally poor across all prompt strategies. Current generation large language models can assist clinicians in perioperative risk stratification on classification tasks and produce high-quality natural language summaries and explanations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philip Chung",
      "Christine T Fong",
      "Andrew M Walters",
      "Nima Aghaeepour",
      "Meliha Yetisgen",
      "Vikas N O'Reilly-Shah"
    ]
  },
  "http://arxiv.org/abs/2401.01614": {
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "volume": "Jan",
    "abstract": "The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents - it can successfully complete 50% of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2) specifically fine-tuned for web agents. However, grounding still remains a major challenge. Existing LMM grounding strategies like set-of-mark prompting turns out not effective for web agents, and the best grounding strategy we develop in this paper leverages both the HTML text and visuals. Yet, there is still a substantial gap with oracle grounding, leaving ample room for further improvement",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boyuan Zheng",
      "Boyu Gou",
      "Jihyung Kil",
      "Huan Sun",
      "Yu Su"
    ]
  },
  "http://arxiv.org/abs/2401.01600": {
    "title": "PLLaMa: An Open-source Large Language Model for Plant Science",
    "volume": "Jan",
    "abstract": "Large Language Models (LLMs) have exhibited remarkable capabilities in understanding and interacting with natural language across various sectors. However, their effectiveness is limited in specialized areas requiring high accuracy, such as plant science, due to a lack of specific expertise in these fields. This paper introduces PLLaMa, an open-source language model that evolved from LLaMa-2. It's enhanced with a comprehensive database, comprising more than 1.5 million scholarly articles in plant science. This development significantly enriches PLLaMa with extensive knowledge and proficiency in plant and agricultural sciences. Our initial tests, involving specific datasets related to plants and agriculture, show that PLLaMa substantially improves its understanding of plant science-related topics. Moreover, we have formed an international panel of professionals, including plant scientists, agricultural engineers, and plant breeders. This team plays a crucial role in verifying the accuracy of PLLaMa's responses to various academic inquiries, ensuring its effective and reliable application in the field. To support further research and development, we have made the model's checkpoints and source codes accessible to the scientific community. These resources are available for download at \\url{https://github.com/Xianjun-Yang/PLLaMa}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianjun Yang",
      "Junfeng Gao",
      "Wenxin Xue",
      "Erik Alexandersson"
    ]
  },
  "http://arxiv.org/abs/2401.01596": {
    "title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries",
    "volume": "Jan",
    "abstract": "In the healthcare domain, summarizing medical questions posed by patients is critical for improving doctor-patient interactions and medical decision-making. Although medical data has grown in complexity and quantity, the current body of research in this domain has primarily concentrated on text-based methods, overlooking the integration of visual cues. Also prior works in the area of medical question summarisation have been limited to the English language. This work introduces the task of multimodal medical question summarization for codemixed input in a low-resource setting. To address this gap, we introduce the Multimodal Medical Codemixed Question Summarization MMCQS dataset, which combines Hindi-English codemixed medical queries with visual aids. This integration enriches the representation of a patient's medical condition, providing a more comprehensive perspective. We also propose a framework named MedSumm that leverages the power of LLMs and VLMs for this task. By utilizing our MMCQS dataset, we demonstrate the value of integrating visual information from images to improve the creation of medically detailed summaries. This multimodal strategy not only improves healthcare decision-making but also promotes a deeper comprehension of patient queries, paving the way for future exploration in personalized and responsive medical care. Our dataset, code, and pre-trained models will be made publicly available",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akash Ghosh",
      "Arkadeep Acharya",
      "Prince Jha",
      "Aniket Gaudgaul",
      "Rajdeep Majumdar",
      "Sriparna Saha",
      "Aman Chadha",
      "Raghav Jain",
      "Setu Sinha",
      "Shivani Agarwal"
    ]
  },
  "http://arxiv.org/abs/2401.01572": {
    "title": "Hallucinations in Neural Automatic Speech Recognition: Identifying Errors and Hallucinatory Models",
    "volume": "Jan",
    "abstract": "Hallucinations are a type of output error produced by deep neural networks. While this has been studied in natural language processing, they have not been researched previously in automatic speech recognition. Here, we define hallucinations in ASR as transcriptions generated by a model that are semantically unrelated to the source utterance, yet still fluent and coherent. The similarity of hallucinations to probable natural language outputs of the model creates a danger of deception and impacts the credibility of the system. We show that commonly used metrics, such as word error rates, cannot differentiate between hallucinatory and non-hallucinatory models. To address this, we propose a perturbation-based method for assessing the susceptibility of an automatic speech recognition (ASR) model to hallucination at test time, which does not require access to the training dataset. We demonstrate that this method helps to distinguish between hallucinatory and non-hallucinatory models that have similar baseline word error rates. We further explore the relationship between the types of ASR errors and the types of dataset noise to determine what types of noise are most likely to create hallucinatory outputs. We devise a framework for identifying hallucinations by analysing their semantic connection with the ground truth and their fluency. Finally, we discover how to induce hallucinations with a random noise injection to the utterance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rita Frieske",
      "Bertram E. Shi"
    ]
  },
  "http://arxiv.org/abs/2401.01523": {
    "title": "GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse",
    "volume": "Jan",
    "abstract": "The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness, misogyny, offensiveness, sarcasm, and harmful content. Our extensive experiments across a range of LMMs reveal that current models still exhibit a deficiency in safety awareness, showing insensitivity to various forms of implicit abuse. We posit that this shortfall represents a critical impediment to the realization of safe artificial intelligence. The GOAT-Bench and accompanying resources are publicly accessible at https://goatlmm.github.io/, contributing to ongoing research in this vital field",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongzhan Lin",
      "Ziyang Luo",
      "Bo Wang",
      "Ruichao Yang",
      "Jing Ma"
    ]
  },
  "http://arxiv.org/abs/2401.01498": {
    "title": "Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction",
    "volume": "Jan",
    "abstract": "We propose a novel text-to-speech (TTS) framework centered around a neural transducer. Our approach divides the whole TTS pipeline into semantic-level sequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling stages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings. For a robust and efficient alignment modeling, we employ a neural transducer named token transducer for the semantic token prediction, benefiting from its hard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR) speech generator efficiently synthesizes waveforms from these semantic tokens. Additionally, a reference speech controls temporal dynamics and acoustic conditions at each stage. This decoupled framework reduces the training complexity of TTS while allowing each stage to focus on semantic and acoustic modeling. Our experimental results on zero-shot adaptive TTS demonstrate that our model surpasses the baseline in terms of speech quality and speaker similarity, both objectively and subjectively. We also delve into the inference speed and prosody control capabilities of our approach, highlighting the potential of neural transducers in TTS frameworks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minchan Kim",
      "Myeonghun Jeong",
      "Byoung Jin Choi",
      "Semin Kim",
      "Joun Yeop Lee",
      "Nam Soo Kim"
    ]
  },
  "http://arxiv.org/abs/2401.01495": {
    "title": "A Two-Stage Multimodal Emotion Recognition Model Based on Graph Contrastive Learning",
    "volume": "Jan",
    "abstract": "In terms of human-computer interaction, it is becoming more and more important to correctly understand the user's emotional state in a conversation, so the task of multimodal emotion recognition (MER) started to receive more attention. However, existing emotion classification methods usually perform classification only once. Sentences are likely to be misclassified in a single round of classification. Previous work usually ignores the similarities and differences between different morphological features in the fusion process. To address the above issues, we propose a two-stage emotion recognition model based on graph contrastive learning (TS-GCL). First, we encode the original dataset with different preprocessing modalities. Second, a graph contrastive learning (GCL) strategy is introduced for these three modal data with other structures to learn similarities and differences within and between modalities. Finally, we use MLP twice to achieve the final emotion classification. This staged classification method can help the model to better focus on different levels of emotional information, thereby improving the performance of the model. Extensive experiments show that TS-GCL has superior performance on IEMOCAP and MELD datasets compared with previous methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Ai",
      "FuChen Zhang",
      "Tao Meng",
      "YunTao Shou",
      "HongEn Shao",
      "Keqin Li"
    ]
  },
  "http://arxiv.org/abs/2401.01487": {
    "title": "Natural Language Processing and Multimodal Stock Price Prediction",
    "volume": "Jan",
    "abstract": "In the realm of financial decision-making, predicting stock prices is pivotal. Artificial intelligence techniques such as long short-term memory networks (LSTMs), support-vector machines (SVMs), and natural language processing (NLP) models are commonly employed to predict said prices. This paper utilizes stock percentage change as training data, in contrast to the traditional use of raw currency values, with a focus on analyzing publicly released news articles. The choice of percentage change aims to provide models with context regarding the significance of price fluctuations and overall price change impact on a given stock. The study employs specialized BERT natural language processing models to predict stock price trends, with a particular emphasis on various data modalities. The results showcase the capabilities of such strategies with a small natural language processing model to accurately predict overall stock trends, and highlight the effectiveness of certain data features and sector-specific data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Taylor",
      "Jerry Ng"
    ]
  },
  "http://arxiv.org/abs/2401.01472": {
    "title": "A First Look at Information Highlighting in Stack Overflow Answers",
    "volume": "Jan",
    "abstract": "Context: Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or HTML so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information. Objective: We carried out the first large-scale exploratory study on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the Named Entity Recognition task. Method: In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN and BERT models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers. Results: Our models based on CNN architecture achieve precision ranging from 0.71 to 0.82. The trained model for automatic code content highlighting achieves a recall of 0.73 and an F1 score of 0.71, outperforming the trained models for other formatting styles. The BERT models have even lower recalls and F1 scores than the CNN models. Our analysis of failure cases indicates that the majority of the failure cases are missing identification (i.e., the model misses the content that is supposed to be highlighted) due to the models tend to learn the frequently highlighted words while struggling to learn less frequent words. Conclusion: Our findings suggest that it is possible to develop recommendation models for highlighting information for answers with different formatting styles on Stack Overflow",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shahla Shaan Ahmed",
      "Shaowei Wang",
      "Yuan Tian",
      "Tse-Hsun",
      "Chen",
      "Haoxiang Zhang"
    ]
  },
  "http://arxiv.org/abs/2401.01469": {
    "title": "Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation",
    "volume": "Jan",
    "abstract": "Summarization of electronic health records (EHRs) can substantially minimize 'screen time' for both patients as well as medical personnel. In recent years summarization of EHRs have employed machine learning pipelines using state of the art neural models. However, these models have produced less than adequate results that are attributed to the difficulty of obtaining sufficient annotated data for training. Moreover, the requirement to consider the entire content of an EHR in summarization has resulted in poor performance due to the fact that attention mechanisms in modern large language models (LLMs) adds a quadratic complexity in terms of the size of the input. We propose here a method that mitigates these shortcomings by combining semantic search, retrieval augmented generation (RAG) and question-answering using the latest LLMs. In our approach summarization is the extraction of answers to specific questions that are deemed important by subject-matter experts (SMEs). Our approach is quite efficient; requires minimal to no training; does not suffer from the 'hallucination' problem of LLMs; and it ensures diversity, since the summary will not have repeated content but diverse answers to specific questions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Walid Saba",
      "Suzanne Wendelken",
      "James. Shanahan"
    ]
  },
  "http://arxiv.org/abs/2401.01419": {
    "title": "To Diverge or Not to Diverge: A Morphosyntactic Perspective on Machine Translation vs Human Translation",
    "volume": "Jan",
    "abstract": "We conduct a large-scale fine-grained comparative analysis of machine translations (MT) against human translations (HT) through the lens of morphosyntactic divergence. Across three language pairs and two types of divergence defined as the structural difference between the source and the target, MT is consistently more conservative than HT, with less morphosyntactic diversity, more convergent patterns, and more one-to-one alignments. Through analysis on different decoding algorithms, we attribute this discrepancy to the use of beam search that biases MT towards more convergent patterns. This bias is most amplified when the convergent pattern appears around 50% of the time in training data. Lastly, we show that for a majority of morphosyntactic divergences, their presence in HT is correlated with decreased MT performance, presenting a greater challenge for MT systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaming Luo",
      "Colin Cherry",
      "George Foster"
    ]
  },
  "http://arxiv.org/abs/2401.01405": {
    "title": "Quantifying the Uniqueness of Donald Trump in Presidential Discourse",
    "volume": "Jan",
    "abstract": "Does Donald Trump speak differently from other presidents? If so, in what ways? Are these differences confined to any single medium of communication? To investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for comparing the lexical features of political opponents. Applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that Trump's speech patterns diverge from those of all major party nominees for the presidency in recent history. Some notable findings include Trump's employment of particularly divisive and antagonistic language targeting of his political opponents and his patterns of repetition for emphasis. Furthermore, Trump is significantly more distinctive than his fellow Republicans, whose uniqueness values are comparably closer to those of the Democrats. These differences hold across a variety of measurement strategies, arise on both the campaign trail and in official presidential addresses, and do not appear to be an artifact of secular time trends",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Karen Zhou",
      "Alexander A. Meitus",
      "Milo Chase",
      "Grace Wang",
      "Anne Mykland",
      "William Howell",
      "Chenhao Tan"
    ]
  },
  "http://arxiv.org/abs/2401.01335": {
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "volume": "Jan",
    "abstract": "Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zixiang Chen",
      "Yihe Deng",
      "Huizhuo Yuan",
      "Kaixuan Ji",
      "Quanquan Gu"
    ]
  },
  "http://arxiv.org/abs/2401.01330": {
    "title": "TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview",
    "volume": "Jan",
    "abstract": "Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works. The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT). However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context. The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them. iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action. These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions about the information space include: finding options, comparing options, identifying the pros and cons of options, etc. Given the different personas and their information need (expressed through the sequence of questions), diverse conversation trajectories will arise -- because the answers to these similar queries will be very different. In this paper, we report on the first year of TREC iKAT, describing the task, topics, data collection, and evaluation framework. We further review the submissions and summarize the findings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Aliannejadi",
      "Zahra Abbasiantaeb",
      "Shubham Chatterjee",
      "Jeffery Dalton",
      "Leif Azzopardi"
    ]
  },
  "http://arxiv.org/abs/2401.01326": {
    "title": "An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction",
    "volume": "Jan",
    "abstract": "In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \\textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zaratiana Urchade",
      "Nadi Tomeh",
      "Pierre Holat",
      "Thierry Charnois"
    ]
  },
  "http://arxiv.org/abs/2401.01325": {
    "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning",
    "volume": "Jan",
    "abstract": "This work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs' context window's length",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongye Jin",
      "Xiaotian Han",
      "Jingfeng Yang",
      "Zhimeng Jiang",
      "Zirui Liu",
      "Chia-Yuan Chang",
      "Huiyuan Chen",
      "Xia Hu"
    ]
  },
  "http://arxiv.org/abs/2401.01313": {
    "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
    "volume": "Jan",
    "abstract": "As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc. This paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in LLMs. Notable among these are Retrieval Augmented Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023), CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types. This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs. Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "S. M Towhidul Islam Tonmoy",
      "S M Mehedi Zaman",
      "Vinija Jain",
      "Anku Rani",
      "Vipula Rawte",
      "Aman Chadha",
      "Amitava Das"
    ]
  },
  "http://arxiv.org/abs/2401.01301": {
    "title": "Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models",
    "volume": "Jan",
    "abstract": "Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. (2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. (3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. (4) We provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations. Taken together, these findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks. Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most -- pro se litigants or those without access to traditional legal resources",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Dahl",
      "Varun Magesh",
      "Mirac Suzgun",
      "Daniel E. Ho"
    ]
  },
  "http://arxiv.org/abs/2401.01286": {
    "title": "A Comprehensive Study of Knowledge Editing for Large Language Models",
    "volume": "Jan",
    "abstract": "Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the knowledge editing problem and then provide a comprehensive review of cutting-edge approaches. Drawing inspiration from educational and cognitive research theories, we propose a unified categorization criterion that classifies knowledge editing methods into three groups: resorting to external knowledge, merging knowledge into the model, and editing intrinsic knowledge. Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive empirical evaluation of representative knowledge editing approaches. Additionally, we provide an in-depth analysis of knowledge location, which can provide a deeper understanding of the knowledge structures inherent within LLMs. Finally, we discuss several potential applications of knowledge editing, outlining its broad and impactful implications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ningyu Zhang",
      "Yunzhi Yao",
      "Bozhong Tian",
      "Peng Wang",
      "Shumin Deng",
      "Mengru Wang",
      "Zekun Xi",
      "Shengyu Mao",
      "Jintian Zhang",
      "Yuansheng Ni",
      "Siyuan Cheng",
      "Ziwen Xu",
      "Xin Xu",
      "Jia-Chen Gu",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Lei Liang",
      "Zhiqiang Zhang",
      "Xiaowei Zhu",
      "Jun Zhou",
      "Huajun Chen"
    ]
  },
  "http://arxiv.org/abs/2401.01283": {
    "title": "Quality and Quantity of Machine Translation References for Automated Metrics",
    "volume": "Jan",
    "abstract": "Automatic machine translation metrics often use human translations to determine the quality system translations. Common wisdom in the field dictates that the human references should be of very high quality. However, there are no cost-benefit analyses that could be used to guide practitioners who plan to collect references for machine translation evaluation. We find that higher-quality references lead to better metric correlations with humans at the segment-level. Having up to 7 references per segment and taking their average helps all metrics. Interestingly, the references from vendors of different qualities can be mixed together and improve metric success. Higher quality references, however, cost more to create and we frame this as an optimization problem: given a specific budget, what references should be collected to maximize metric success. These findings can be used by evaluators of shared tasks when references need to be created under a certain budget",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vilém Zouhar",
      "Ondřej Bojar"
    ]
  },
  "http://arxiv.org/abs/2401.01275": {
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "volume": "Jan",
    "abstract": "Recently, the advent of large language models (LLMs) has revolutionized generative agents. Among them, Role-Playing Conversational Agents (RPCAs) attract considerable attention due to their ability to emotionally engage users. However, the absence of a comprehensive benchmark impedes progress in this field. To bridge this gap, we introduce CharacterEval, a Chinese benchmark for comprehensive RPCA assessment, complemented by a tailored high-quality dataset. The dataset comprises 1,785 multi-turn role-playing dialogues, encompassing 23,020 examples and featuring 77 characters derived from Chinese novels and scripts. It was carefully constructed, beginning with initial dialogue extraction via GPT-4, followed by rigorous human-led quality control, and enhanced with in-depth character profiles sourced from Baidu Baike. CharacterEval employs a multifaceted evaluation approach, encompassing thirteen targeted metrics on four dimensions. Comprehensive experiments on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation. Source code, data source and reward model will be publicly accessible at https://github.com/morecry/CharacterEval",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan Tu",
      "Shilong Fan",
      "Zihang Tian",
      "Rui Yan"
    ]
  },
  "http://arxiv.org/abs/2401.01262": {
    "title": "Fairness Certification for Natural Language Processing and Large Language Models",
    "volume": "Jan",
    "abstract": "Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes to certify fairness, both from the perspective of the auditor and the audited organization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Freiberger",
      "Erik Buchmann"
    ]
  },
  "http://arxiv.org/abs/2401.01256": {
    "title": "VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM",
    "volume": "Jan",
    "abstract": "The recent innovations and breakthroughs in diffusion models have significantly expanded the possibilities of generating high-quality videos for the given prompts. Most existing works tackle the single-scene scenario with only one video event occurring in a single background. Extending to generate multi-scene videos nevertheless is not trivial and necessitates to nicely manage the logic in between while preserving the consistent visual appearance of key content across video scenes. In this paper, we propose a novel framework, namely VideoDrafter, for content-consistent multi-scene video generation. Technically, VideoDrafter leverages Large Language Models (LLM) to convert the input prompt into comprehensive multi-scene script that benefits from the logical knowledge learnt by LLM. The script for each scene includes a prompt describing the event, the foreground/background entities, as well as camera movement. VideoDrafter identifies the common entities throughout the script and asks LLM to detail each entity. The resultant entity description is then fed into a text-to-image model to generate a reference image for each entity. Finally, VideoDrafter outputs a multi-scene video by generating each scene video via a diffusion process that takes the reference images, the descriptive prompt of the event and camera movement into account. The diffusion model incorporates the reference images as the condition and alignment to strengthen the content consistency of multi-scene videos. Extensive experiments demonstrate that VideoDrafter outperforms the SOTA video generation models in terms of visual quality, content consistency, and user preference",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fuchen Long",
      "Zhaofan Qiu",
      "Ting Yao",
      "Tao Mei"
    ]
  },
  "http://arxiv.org/abs/2401.01218": {
    "title": "Zero-Shot Position Debiasing for Large Language Models",
    "volume": "Jan",
    "abstract": "Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality. In this work, we propose a zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets. To improve the quality of unsupervised responses, we propose a master-slave alignment (MSA) module to prune these responses. Experiments on eight datasets and five tasks show that ZOE consistently outperforms existing methods in mitigating four types of position biases. Besides, ZOE achieves this by sacrificing only a small performance on biased samples, which is simple and effective",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongkun Liu",
      "Zheng Chen",
      "Mengqi Zhang",
      "Zhaochun Ren",
      "Zhumin Chen",
      "Pengjie Ren"
    ]
  },
  "http://arxiv.org/abs/2401.01197": {
    "title": "Uncertainty Resolution in Misinformation Detection",
    "volume": "Jan",
    "abstract": "Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pipelines",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yury Orlovskiy",
      "Camille Thibault",
      "Anne Imouza",
      "Jean-François Godbout",
      "Reihaneh Rabbany",
      "Kellin Pelrine"
    ]
  },
  "http://arxiv.org/abs/2401.01183": {
    "title": "Unifying Structured Data as Graph for Data-to-Text Pre-Training",
    "volume": "Jan",
    "abstract": "Data-to-text (D2T) generation aims to transform structured data into natural language text. Data-to-text pre-training has proved to be powerful in enhancing D2T generation and yields impressive performances. However, previous pre-training methods either oversimplified structured data into a sequence without considering input structures or designed training objectives tailored for a specific data structure (e.g., table or knowledge graph). In this paper, we unify different types of structured data (i.e., table, key-value data, knowledge graph) into the graph format and cast different data-to-text generation tasks as graph-to-text generation. To effectively exploit the structural information of the input graph, we propose a structure-enhanced pre-training method for D2T generation by designing a structure-enhanced Transformer. Concretely, we devise a position matrix for the Transformer, encoding relative positional information of connected nodes in the input graph. In addition, we propose a new attention matrix to incorporate graph structures into the original Transformer by taking the available explicit connectivity structure into account. Extensive experiments on six benchmark datasets show the effectiveness of our model. Our source codes are available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shujie Li",
      "Liang Li",
      "Ruiying Geng",
      "Min Yang",
      "Binhua Li",
      "Guanghu Yuan",
      "Wanwei He",
      "Shao Yuan",
      "Can Ma",
      "Fei Huang",
      "Yongbin Li"
    ]
  },
  "http://arxiv.org/abs/2401.01108": {
    "title": "Unveiling Comparative Sentiments in Vietnamese Product Reviews: A Sequential Classification Framework",
    "volume": "Jan",
    "abstract": "Comparative opinion mining is a specialized field of sentiment analysis that aims to identify and extract sentiments expressed comparatively. To address this task, we propose an approach that consists of solving three sequential sub-tasks: (i) identifying comparative sentence, i.e., if a sentence has a comparative meaning, (ii) extracting comparative elements, i.e., what are comparison subjects, objects, aspects, predicates, and (iii) classifying comparison types which contribute to a deeper comprehension of user sentiments in Vietnamese product reviews. Our method is ranked fifth at the Vietnamese Language and Speech Processing (VLSP) 2023 challenge on Comparative Opinion Mining (ComOM) from Vietnamese Product Reviews",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ha Le",
      "Bao Tran",
      "Phuong Le",
      "Tan Nguyen",
      "Dac Nguyen",
      "Ngoan Pham",
      "Dang Huynh"
    ]
  },
  "http://arxiv.org/abs/2401.01089": {
    "title": "Quokka: An Open-source Large Language Model ChatBot for Material Science",
    "volume": "Jan",
    "abstract": "This paper presents the development of a specialized chatbot for materials science, leveraging the Llama-2 language model, and continuing pre-training on the expansive research articles in the materials science domain from the S2ORC dataset. The methodology involves an initial pretraining phase on over one million domain-specific papers, followed by an instruction-tuning process to refine the chatbot's capabilities. The chatbot is designed to assist researchers, educators, and students by providing instant, context-aware responses to queries in the field of materials science. We make the four trained checkpoints (7B, 13B, with or without chat ability) freely available to the research community at https://github.com/Xianjun-Yang/Quokka",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xianjun Yang",
      "Stephen D. Wilson",
      "Linda Petzold"
    ]
  },
  "http://arxiv.org/abs/2401.01078": {
    "title": "Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation",
    "volume": "Jan",
    "abstract": "Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the \"luc bat\" genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the \"luc bat\" genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Triet Minh Huynh",
      "Quan Le Bao"
    ]
  },
  "http://arxiv.org/abs/2401.01076": {
    "title": "DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever",
    "volume": "Jan",
    "abstract": "Recently, substantial advancements in pre-trained vision-language models have greatly enhanced the capabilities of multi-modal dialog systems. These models have demonstrated significant improvements by fine-tuning on downstream tasks. However, the existing pre-trained models primarily focus on effectively capturing the alignment between vision and language modalities, often ignoring the intricate nature of dialog context. In this paper, we propose a parameter-efficient prompt-tuning method named DialCLIP for multi-modal dialog retrieval. Specifically, our approach introduces a multi-modal context prompt generator to learn context features which are subsequently distilled into prompts within the pre-trained vision-language model CLIP. Besides, we introduce domain prompt to mitigate the disc repancy from the downstream dialog data. To facilitate various types of retrieval, we also design multiple experts to learn mappings from CLIP outputs to multi-modal representation space, with each expert being responsible to one specific retrieval type. Extensive experiments show that DialCLIP achieves state-of-the-art performance on two widely recognized benchmark datasets (i.e., PhotoChat and MMDialog) by tuning a mere 0.04% of the total parameters. These results highlight the efficacy and efficiency of our proposed approach, underscoring its potential to advance the field of multi-modal dialog retrieval",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhichao Yin",
      "Binyuan Hui",
      "Min Yang",
      "Fei Huang",
      "Yongbin Li"
    ]
  },
  "http://arxiv.org/abs/2401.01068": {
    "title": "Discovering Significant Topics from Legal Decisions with Selective Inference",
    "volume": "Jan",
    "abstract": "We propose and evaluate an automated pipeline for discovering significant topics from legal decision texts by passing features synthesized with topic models through penalised regressions and post-selection significance tests. The method identifies case topics significantly correlated with outcomes, topic-word distributions which can be manually-interpreted to gain insights about significant topics, and case-topic weights which can be used to identify representative cases for each topic. We demonstrate the method on a new dataset of domain name disputes and a canonical dataset of European Court of Human Rights violation cases. Topic models based on latent semantic analysis as well as language model embeddings are evaluated. We show that topics derived by the pipeline are consistent with legal doctrines in both areas and can be useful in other related legal analysis tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jerrold Soh"
    ]
  },
  "http://arxiv.org/abs/2401.01055": {
    "title": "LLaMA Beyond English: An Empirical Study on Language Capability Transfer",
    "volume": "Jan",
    "abstract": "In recent times, substantial advancements have been witnessed in large language models (LLMs), exemplified by ChatGPT, showcasing remarkable proficiency across a range of complex tasks. However, many mainstream LLMs (e.g. LLaMA) are pretrained on English-dominant corpus, which limits their performance in other non-English languages. In this paper, we focus on how to effectively transfer the capabilities of language generation and following instructions to a non-English language. To answer this question, we conduct an extensive empirical investigation based on LLaMA, accumulating over 1440 GPU hours. We analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer. To accurately assess the model's level of knowledge, we employ four widely used standardized testing benchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a comprehensive evaluation of the model's response quality is conducted, considering aspects such as accuracy, fluency, informativeness, logical coherence, and harmlessness, based on LLM-Eval, a benchmarks consisting instruction tasks from 17 diverse categories. Our evaluation results demonstrate that comparable performance to state-of-the-art transfer models can be achieved with less than 1% of the pretraining data, both in terms of knowledge alignment and response quality. Furthermore, the experimental outcomes across the thirteen low-resource languages also exhibit similar trends. We anticipate that the conclusions revealed by the experiments will aid the community in developing non-English LLMs",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jun Zhao",
      "Zhihao Zhang",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ]
  },
  "http://arxiv.org/abs/2401.01053": {
    "title": "Cheetah: Natural Language Generation for 517 African Languages",
    "volume": "Jan",
    "abstract": "Low-resource African languages pose unique challenges for natural language processing (NLP) tasks, including natural language generation (NLG). In this paper, we develop Cheetah, a massively multilingual NLG language model for African languages. Cheetah supports 517 African languages and language varieties, allowing us to address the scarcity of NLG resources and provide a solution to foster linguistic diversity. We demonstrate the effectiveness of Cheetah through comprehensive evaluations across seven generation downstream tasks. In five of the seven tasks, Cheetah significantly outperforms other models, showcasing its remarkable performance for generating coherent and contextually appropriate text in a wide range of African languages. We additionally conduct a detailed human evaluation to delve deeper into the linguistic capabilities of Cheetah. The introduction of Cheetah has far-reaching benefits for linguistic diversity. By leveraging pretrained models and adapting them to specific languages, our approach facilitates the development of practical NLG applications for African communities. The findings of this study contribute to advancing NLP research in low-resource settings, enabling greater accessibility and inclusion for African languages in a rapidly expanding digital landscape. We will publicly release our models for research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ife Adebara",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ]
  },
  "http://arxiv.org/abs/2401.01044": {
    "title": "Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation",
    "volume": "Jan",
    "abstract": "Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource. Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior TTA works. Through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments of text-audio alignment in TTA. Our findings reveal Auffusion's superior capability in generating audios that accurately match textual descriptions, which further demonstrated in several related tasks, such as audio style transfer, inpainting and other manipulations. Our implementation and demos are available at https://auffusion.github.io",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinlong Xue",
      "Yayue Deng",
      "Yingming Gao",
      "Ya Li"
    ]
  },
  "http://arxiv.org/abs/2401.00824": {
    "title": "Graph-Convolutional Autoencoder Ensembles for the Humanities, Illustrated with a Study of the American Slave Trade",
    "volume": "Jan",
    "abstract": "We introduce a graph-aware autoencoder ensemble framework, with associated formalisms and tooling, designed to facilitate deep learning for scholarship in the humanities. By composing sub-architectures to produce a model isomorphic to a humanistic domain we maintain interpretability while providing function signatures for each sub-architectural choice, allowing both traditional and computational researchers to collaborate without disrupting established practices. We illustrate a practical application of our approach to a historical study of the American post-Atlantic slave trade, and make several specific technical contributions: a novel hybrid graph-convolutional autoencoder mechanism, batching policies for common graph topologies, and masking techniques for particular use-cases. The effectiveness of the framework for broadening participation of diverse domains is demonstrated by a growing suite of two dozen studies, both collaborations with humanists and established tasks from machine learning literature, spanning a variety of fields and data modalities. We make performance comparisons of several different architectural choices and conclude with an ambitious list of imminent next steps for this research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Lippincott"
    ]
  },
  "http://arxiv.org/abs/2401.00820": {
    "title": "A Computational Framework for Behavioral Assessment of LLM Therapists",
    "volume": "Jan",
    "abstract": "The emergence of ChatGPT and other large language models (LLMs) has greatly increased interest in utilizing LLMs as therapists to support individuals struggling with mental health challenges. However, due to the lack of systematic studies, our understanding of how LLM therapists behave, i.e., ways in which they respond to clients, is significantly limited. Understanding their behavior across a wide range of clients and situations is crucial to accurately assess their capabilities and limitations in the high-risk setting of mental health, where undesirable behaviors can lead to severe consequences. In this paper, we propose BOLT, a novel computational framework to study the conversational behavior of LLMs when employed as therapists. We develop an in-context learning method to quantitatively measure the behavior of LLMs based on 13 different psychotherapy techniques including reflections, questions, solutions, normalizing, and psychoeducation. Subsequently, we compare the behavior of LLM therapists against that of high- and low-quality human therapy, and study how their behavior can be modulated to better reflect behaviors observed in high-quality therapy. Our analysis of GPT and Llama-variants reveals that these LLMs often resemble behaviors more commonly exhibited in low-quality therapy rather than high-quality therapy, such as offering a higher degree of problem-solving advice when clients share emotions, which is against typical recommendations. At the same time, unlike low-quality therapy, LLMs reflect significantly more upon clients' needs and strengths. Our analysis framework suggests that despite the ability of LLMs to generate anecdotal examples that appear similar to human therapists, LLM therapists are currently not fully consistent with high-quality care, and thus require additional research to ensure quality care",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Ying Chiu",
      "Ashish Sharma",
      "Inna Wanyin Lin",
      "Tim Althoff"
    ]
  },
  "http://arxiv.org/abs/2401.00812": {
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "volume": "Jan",
    "abstract": "The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Specifically, beyond enhancing LLMs in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of LLMs, enabling their applications to a range of more complex natural language tasks; (ii) steer LLMs to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improvement. In addition, we trace how these profound capabilities of LLMs, brought by code, have led to their emergence as intelligent agents (IAs) in situations where the ability to understand instructions, decompose goals, plan and execute actions, and refine from feedback are crucial to their success on downstream tasks. Finally, we present several key challenges and future directions of empowering LLMs with code",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ke Yang",
      "Jiateng Liu",
      "John Wu",
      "Chaoqi Yang",
      "Yi R. Fung",
      "Sha Li",
      "Zixuan Huang",
      "Xu Cao",
      "Xingyao Wang",
      "Yiquan Wang",
      "Heng Ji",
      "Chengxiang Zhai"
    ]
  },
  "http://arxiv.org/abs/2401.00811": {
    "title": "PerSHOP -- A Persian dataset for shopping dialogue systems modeling",
    "volume": "Jan",
    "abstract": "Nowadays, dialogue systems are used in many fields of industry and research. There are successful instances of these systems, such as Apple Siri, Google Assistant, and IBM Watson. Task-oriented dialogue system is a category of these, that are used in specific tasks. They can perform tasks such as booking plane tickets or making restaurant reservations. Shopping is one of the most popular areas on these systems. The bot replaces the human salesperson and interacts with the customers by speaking. To train the models behind the scenes of these systems, annotated data is needed. In this paper, we developed a dataset of dialogues in the Persian language through crowd-sourcing. We annotated these dialogues to train a model. This dataset contains nearly 22k utterances in 15 different domains and 1061 dialogues. This is the largest Persian dataset in this field, which is provided freely so that future researchers can use it. Also, we proposed some baseline models for natural language understanding (NLU) tasks. These models perform two tasks for NLU: intent classification and entity extraction. The F-1 score metric obtained for intent classification is around 91% and for entity extraction is around 93%, which can be a baseline for future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Keyvan Mahmoudi",
      "Heshaam Faili"
    ]
  },
  "http://arxiv.org/abs/2401.00793": {
    "title": "SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models",
    "volume": "Jan",
    "abstract": "With the growing use of large language models hosted on cloud platforms to offer inference services, privacy concerns are escalating, especially concerning sensitive data like investment plans and bank account details. Secure Multi-Party Computing (SMPC) emerges as a promising solution to protect the privacy of inference data and model parameters. However, the application of SMPC in Privacy-Preserving Inference (PPI) for large language models, particularly those based on the Transformer architecture, often leads to considerable slowdowns or declines in performance. This is largely due to the multitude of nonlinear operations in the Transformer architecture, which are not well-suited to SMPC and are difficult to circumvent or optimize effectively. To address this concern, we introduce an advanced optimization framework called SecFormer, designed to strike an optimal balance between performance and efficiency in PPI for Transformer models. By implementing knowledge distillation techniques, we successfully eliminate the high-cost exponential and maximum operations in PPI without sacrificing model performance. Additionally, we have developed a suite of efficient SMPC protocols that utilize segmented polynomials and Goldschmidt's method to handle other complex nonlinear functions within PPI, such as GeLU, LayerNorm, and Softmax. Our extensive experiments reveal that SecFormer outperforms MPCFormer in performance, showing improvements of $5.6\\%$ and $24.2\\%$ for BERT$_{\\text{BASE}}$ and BERT$_{\\text{LARGE}}$, respectively. In terms of efficiency, SecFormer is 3.4 and 3.2 times faster than Puma, demonstrating its effectiveness and speed",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinglong Luo",
      "Yehong Zhang",
      "Jiaqi Zhang",
      "Xin Mu",
      "Hui Wang",
      "Yue Yu",
      "Zenglin Xu"
    ]
  },
  "http://arxiv.org/abs/2401.00788": {
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
    "volume": "Jan",
    "abstract": "The high cost of full-parameter fine-tuning (FFT) of Large Language Models (LLMs) has led to a series of parameter-efficient fine-tuning (PEFT) methods. However, it remains unclear which methods provide the best cost-performance trade-off at different model scales. We introduce Astraios, a suite of 28 instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters. Through investigations across 5 tasks and 8 different datasets encompassing both code comprehension and code generation tasks, we find that FFT generally leads to the best downstream performance across all scales, and PEFT methods differ significantly in their efficacy based on the model scale. LoRA usually offers the most favorable trade-off between cost and performance. Further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security. At last, we explore the relationships among updated parameters, cross-entropy loss, and task performance. We find that the tuning effectiveness observed in small models generalizes well to larger models, and the validation loss in instruction tuning can be a reliable indicator of overall downstream performance",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Terry Yue Zhuo",
      "Armel Zebaze",
      "Nitchakarn Suppattarachai",
      "Leandro von Werra",
      "Harm de Vries",
      "Qian Liu",
      "Niklas Muennighoff"
    ]
  },
  "http://arxiv.org/abs/2401.00779": {
    "title": "Temporal Validity Change Prediction",
    "volume": "Jan",
    "abstract": "Temporal validity is an important property of text that is useful for many downstream applications, such as recommender systems, conversational AI, or story understanding. Existing benchmarking tasks often require models to identify the temporal validity duration of a single statement. However, in many cases, additional contextual information, such as sentences in a story or posts on a social media profile, can be collected from the available text stream. This contextual information may greatly alter the duration for which a statement is expected to be valid. We propose Temporal Validity Change Prediction, a natural language processing task benchmarking the capability of machine learning models to detect contextual statements that induce such change. We create a dataset consisting of temporal target statements sourced from Twitter and crowdsource sample context statements. We then benchmark a set of transformer-based language models on our dataset. Finally, we experiment with temporal validity duration prediction as an auxiliary task to improve the performance of the state-of-the-art model",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georg Wenzel",
      "Adam Jatowt"
    ]
  },
  "http://arxiv.org/abs/2401.00763": {
    "title": "New Job, New Gender? Measuring the Social Bias in Image Generation Models",
    "volume": "Jan",
    "abstract": "Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel metamorphic testing framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race, and age-neutral queries. These queries span 62 professions, 39 activities, 57 types of objects, and 70 personality traits. The framework then compares the edited images to the original seed images, focusing on any changes related to gender, race, and age. BiasPainter adopts a testing oracle that these characteristics should not be modified when subjected to neutral prompts. Built upon this design, BiasPainter can trigger the social bias and evaluate the fairness of image generation models. To evaluate the effectiveness of BiasPainter, we use BiasPainter to test five widely-used commercial image generation software and models, such as stable diffusion and Midjourney. Experimental results show that 100\\% of the generated test cases can successfully trigger social bias in image generation models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Wang",
      "Haonan Bai",
      "Jen-tse Huang",
      "Yuxuan Wan",
      "Youliang Yuan",
      "Haoyi Qiu",
      "Nanyun Peng",
      "Michael R. Lyu"
    ]
  },
  "http://arxiv.org/abs/2401.00761": {
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "volume": "Jan",
    "abstract": "Large Language Models (LLMs) like ChatGPT are foundational in various applications due to their extensive knowledge from pre-training and fine-tuning. Despite this, they are prone to generating factual and commonsense errors, raising concerns in critical areas like healthcare, journalism, and education to mislead users. Current methods for evaluating LLMs' veracity are limited by test data leakage or the need for extensive human labor, hindering efficient and accurate error detection. To tackle this problem, we introduce a novel, automatic testing framework, FactChecker, aimed at uncovering factual inaccuracies in LLMs. This framework involves three main steps: First, it constructs a factual knowledge graph by retrieving fact triplets from a large-scale knowledge database. Then, leveraging the knowledge graph, FactChecker employs a rule-based approach to generates three types of questions (Yes-No, Multiple-Choice, and WH questions) that involve single-hop and multi-hop relations, along with correct answers. Lastly, it assesses the LLMs' responses for accuracy using tailored matching strategies for each question type. Our extensive tests on six prominent LLMs, including text-davinci-002, text-davinci-003, ChatGPT~(gpt-3.5-turbo, gpt-4), Vicuna, and LLaMA-2, reveal that FactChecker can trigger factual errors in up to 45\\% of questions in these models. Moreover, we demonstrate that FactChecker's test cases can improve LLMs' factual accuracy through in-context learning and fine-tuning (e.g., llama-2-13b-chat's accuracy increase from 35.3\\% to 68.5\\%). We are making all code, data, and results available for future research endeavors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Wang",
      "Juluan Shi",
      "Zhaopeng Tu",
      "Youliang Yuan",
      "Jen-tse Huang",
      "Wenxiang Jiao",
      "Michael R. Lyu"
    ]
  },
  "http://arxiv.org/abs/2401.00757": {
    "title": "A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models",
    "volume": "Jan",
    "abstract": "Recent advancements in large language models (LLMs) have propelled Artificial Intelligence (AI) to new heights, enabling breakthroughs in various tasks such as writing assistance, code generation, and machine translation. A significant distinction of advanced LLMs, such as ChatGPT, is their demonstrated ability to \"reason.\" However, evaluating the reasoning ability of LLMs remains a challenge as most existing evaluations focus on their accuracy on the downstream tasks rather than directly assessing their reasoning processes. Efforts have been made to develop benchmarks and metrics to assess reasoning in LLMs, but they suffer from data leakage or limited scope. In this paper, we introduce LogicAsker, an automatic approach that comprehensively evaluates and improves the logical reasoning abilities of LLMs under a set of atomic reasoning skills based on propositional and predicate logic. The results provide insights into LLMs' reasoning abilities and reveal the logical rules the LLMs did not learn well. We evaluate LogicAsker on six widely deployed LLMs, including GPT-3, ChatGPT, GPT-4, Bard, Vicuna, and Guanaco. The results show that test cases from LogicAsker can find logical reasoning failures in different LLMs with a rate of 25\\% - 94\\%. In addition, the test cases of LogicAsker can be further used to design demonstration examples for in-context learning, which effectively improves the logical reasoning ability of LLMs, e.g., 10\\% for GPT-4. As far as we know, our work is the first to create prompts based on testing results to improve LLMs' formal reasoning ability effectively. All the code, data, and results will be released for reproduction and future research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxuan Wan",
      "Wenxuan Wang",
      "Yiliu Yang",
      "Youliang Yuan",
      "Jen-tse Huang",
      "Pinjia He",
      "Wenxiang Jiao",
      "Michael R. Lyu"
    ]
  },
  "http://arxiv.org/abs/2401.00751": {
    "title": "Machine Translation Testing via Syntactic Tree Pruning",
    "volume": "Jan",
    "abstract": "Machine translation systems have been widely adopted in our daily life, making life easier and more convenient. Unfortunately, erroneous translations may result in severe consequences, such as financial losses. This requires to improve the accuracy and the reliability of machine translation systems. However, it is challenging to test machine translation systems because of the complexity and intractability of the underlying neural models. To tackle these challenges, we propose a novel metamorphic testing approach by syntactic tree pruning (STP) to validate machine translation systems. Our key insight is that a pruned sentence should have similar crucial semantics compared with the original sentence. Specifically, STP (1) proposes a core semantics-preserving pruning strategy by basic sentence structure and dependency relations on the level of syntactic tree representation; (2) generates source sentence pairs based on the metamorphic relation; (3) reports suspicious issues whose translations break the consistency property by a bag-of-words model. We further evaluate STP on two state-of-the-art machine translation systems (i.e., Google Translate and Bing Microsoft Translator) with 1,200 source sentences as inputs. The results show that STP can accurately find 5,073 unique erroneous translations in Google Translate and 5,100 unique erroneous translations in Bing Microsoft Translator (400% more than state-of-the-art techniques), with 64.5% and 65.4% precision, respectively. The reported erroneous translations vary in types and more than 90% of them cannot be found by state-of-the-art techniques. There are 9,393 erroneous translations unique to STP, which is 711.9% more than state-of-the-art techniques. Moreover, STP is quite effective to detect translation errors for the original sentences with a recall reaching 74.0%, improving state-of-the-art techniques by 55.1% on average",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quanjun Zhang",
      "Juan Zhai",
      "Chunrong Fang",
      "Jiawei Liu",
      "Weisong Sun",
      "Haichuan Hu",
      "Qingyu Wang"
    ]
  },
  "http://arxiv.org/abs/2401.00741": {
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "volume": "Jan",
    "abstract": "Existing evaluations of tool learning primarily focus on validating the alignment of selected tools for large language models (LLMs) with expected outcomes. However, these approaches rely on a limited set of scenarios where answers can be pre-determined, diverging from genuine needs. Furthermore, a sole emphasis on outcomes disregards the intricate capabilities essential for LLMs to effectively utilize tools. To tackle this issue, we propose ToolEyes, a fine-grained system tailored for the evaluation of the LLMs' tool learning capabilities in authentic scenarios. The system meticulously examines seven real-world scenarios, analyzing five dimensions crucial to LLMs in tool learning: format alignment, intent comprehension, behavior planning, tool selection, and answer organization. Additionally, ToolEyes incorporates a tool library boasting approximately 600 tools, serving as an intermediary between LLMs and the physical world. Evaluations involving ten LLMs across three categories reveal a preference for specific scenarios and limited cognitive abilities in tool learning. Intriguingly, expanding the model size even exacerbates the hindrance to tool learning. These findings offer instructive insights aimed at advancing the field of tool learning. The data is available att https://github.com/Junjie-Ye/ToolEyes.git",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junjie Ye",
      "Guanyu Li",
      "Songyang Gao",
      "Caishuang Huang",
      "Yilong Wu",
      "Sixian Li",
      "Xiaoran Fan",
      "Shihan Dou",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ]
  },
  "http://arxiv.org/abs/2401.00698": {
    "title": "Large Language Models aren't all that you need",
    "volume": "Jan",
    "abstract": "This paper describes the architecture and systems built towards solving the SemEval 2023 Task 2: MultiCoNER II (Multilingual Complex Named Entity Recognition) [1]. We evaluate two approaches (a) a traditional Conditional Random Fields model and (b) a Large Language Model (LLM) fine-tuned with a customized head and compare the two approaches. The novel ideas explored are: 1) Decaying auxiliary loss (with residual) - where we train the model on an auxiliary task of Coarse-Grained NER and include this task as a part of the loss function 2) Triplet token blending - where we explore ways of blending the embeddings of neighboring tokens in the final NER layer prior to prediction 3) Task-optimal heads - where we explore a variety of custom heads and learning rates for the final layer of the LLM. We also explore multiple LLMs including GPT-3 and experiment with a variety of dropout and other hyperparameter settings before arriving at our final model which achieves micro & macro f1 of 0.85/0.84 (on dev) and 0.67/0.61 on the test data . We show that while pre-trained LLMs, by themselves, bring about a large improvement in scores as compared to traditional models, we also demonstrate that tangible improvements to the Macro-F1 score can be made by augmenting the LLM with additional feature/loss/model engineering techniques described above",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kiran Voderhobli Holla",
      "Chaithanya Kumar",
      "Aryan Singh"
    ]
  },
  "http://arxiv.org/abs/2401.00690": {
    "title": "Benchmarking Large Language Models on Controllable Generation under Diversified Instructions",
    "volume": "Jan",
    "abstract": "While large language models (LLMs) have exhibited impressive instruction-following capabilities, it is still unclear whether and to what extent they can respond to explicit constraints that might be entailed in various instructions. As a significant aspect of LLM alignment, it is thus important to formulate such a specialized set of instructions as well as investigate the resulting behavior of LLMs. To address this vacancy, we propose a new benchmark CoDI-Eval to systematically and comprehensively evaluate LLMs' responses to instructions with various constraints. We construct a large collection of constraints-attributed instructions as a test suite focused on both generalization and coverage. Specifically, we advocate an instruction diversification process to synthesize diverse forms of constraint expression and also deliberate the candidate task taxonomy with even finer-grained sub-categories. Finally, we automate the entire evaluation process to facilitate further developments. Different from existing studies on controllable text generation, CoDI-Eval extends the scope to the prevalent instruction-following paradigm for the first time. We provide extensive evaluations of representative LLMs (e.g., ChatGPT, Vicuna) on CoDI-Eval, revealing their limitations in following instructions with specific constraints and there is still a significant gap between open-source and commercial closed-source LLMs. We believe this benchmark will facilitate research into improving the controllability of LLMs' responses to instructions. Our data and code are available at https://github.com/Xt-cyh/CoDI-Eval",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yihan Chen",
      "Benfeng Xu",
      "Quan Wang",
      "Yi Liu",
      "Zhendong Mao"
    ]
  },
  "http://arxiv.org/abs/2401.00689": {
    "title": "Large language model for Bible sentiment analysis: Sermon on the Mount",
    "volume": "Jan",
    "abstract": "The revolution of natural language processing via large language models has motivated its use in multidisciplinary areas that include social sciences and humanities and more specifically, comparative religion. Sentiment analysis provides a mechanism to study the emotions expressed in text. Recently, sentiment analysis has been used to study and compare translations of the Bhagavad Gita, which is a fundamental and sacred Hindu text. In this study, we use sentiment analysis for studying selected chapters of the Bible. These chapters are known as the Sermon on the Mount. We utilize a pre-trained language model for sentiment analysis by reviewing five translations of the Sermon on the Mount, which include the King James version, the New International Version, the New Revised Standard Version, the Lamsa Version, and the Basic English Version. We provide a chapter-by-chapter and verse-by-verse comparison using sentiment and semantic analysis and review the major sentiments expressed. Our results highlight the varying sentiments across the chapters and verses. We found that the vocabulary of the respective translations is significantly different. We detected different levels of humour, optimism, and empathy in the respective chapters that were used by Jesus to deliver his message",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mahek Vora",
      "Tom Blau",
      "Vansh Kachhwal",
      "Ashu M. G. Solo",
      "Rohitash Chandra"
    ]
  },
  "http://arxiv.org/abs/2401.00676": {
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "volume": "Jan",
    "abstract": "Pre-training, which utilizes extensive and varied datasets, is a critical factor in the success of Large Language Models (LLMs) across numerous applications. However, the detailed makeup of these datasets is often not disclosed, leading to concerns about data security and potential misuse. This is particularly relevant when copyrighted material, still under legal protection, is used inappropriately, either intentionally or unintentionally, infringing on the rights of the authors. In this paper, we introduce a detailed framework designed to detect and assess the presence of content from potentially copyrighted books within the training datasets of LLMs. This framework also provides a confidence estimation for the likelihood of each content sample's inclusion. To validate our approach, we conduct a series of simulated experiments, the results of which affirm the framework's effectiveness in identifying and addressing instances of content misuse in LLM training processes. Furthermore, we investigate the presence of recognizable quotes from famous literary works within these datasets. The outcomes of our study have significant implications for ensuring the ethical use of copyrighted materials in the development of LLMs, highlighting the need for more transparent and responsible data management practices in this field",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haodong Li",
      "Gelei Deng",
      "Yi Liu",
      "Kailong Wang",
      "Yuekang Li",
      "Tianwei Zhang",
      "Yang Liu",
      "Guoai Xu",
      "Guosheng Xu",
      "Haoyu Wang"
    ]
  },
  "http://arxiv.org/abs/2401.00642": {
    "title": "Predicting Anti-microbial Resistance using Large Language Models",
    "volume": "Jan",
    "abstract": "During times of increasing antibiotic resistance and the spread of infectious diseases like COVID-19, it is important to classify genes related to antibiotic resistance. As natural language processing has advanced with transformer-based language models, many language models that learn characteristics of nucleotide sequences have also emerged. These models show good performance in classifying various features of nucleotide sequences. When classifying nucleotide sequences, not only the sequence itself, but also various background knowledge is utilized. In this study, we use not only a nucleotide sequence-based language model but also a text language model based on PubMed articles to reflect more biological background knowledge in the model. We propose a method to fine-tune the nucleotide sequence language model and the text language model based on various databases of antibiotic resistance genes. We also propose an LLM-based augmentation technique to supplement the data and an ensemble method to effectively combine the two models. We also propose a benchmark for evaluating the model. Our method achieved better performance than the nucleotide sequence language model in the drug resistance class prediction",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyunwoo Yoo",
      "Bahrad Sokhansanj",
      "James R. Brown",
      "Gail Rosen"
    ]
  },
  "http://arxiv.org/abs/2312.17660": {
    "title": "Normalization of Lithuanian Text Using Regular Expressions",
    "volume": "Jan",
    "abstract": "Text Normalization is an integral part of any text-to-speech synthesis system. In a natural language text, there are elements such as numbers, dates, abbreviations, etc. that belong to other semiotic classes. They are called non-standard words (NSW) and need to be expanded into ordinary words. For this purpose, it is necessary to identify the semiotic class of each NSW. The taxonomy of semiotic classes adapted to the Lithuanian language is presented in the work. Sets of rules are created for detecting and expanding NSWs based on regular expressions. Experiments with three completely different data sets were performed and the accuracy was assessed. Causes of errors are explained and recommendations are given for the development of text normalization rules",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pijus Kasparaitis"
    ]
  },
  "http://arxiv.org/abs/2312.17432": {
    "title": "Video Understanding with Large Language Models: A Survey",
    "volume": "Jan",
    "abstract": "With the burgeoning growth of online video platforms and the escalating volume of video content, the demand for proficient video understanding tools has intensified markedly. Given the remarkable capabilities of Large Language Models (LLMs) in language and multimodal tasks, this survey provides a detailed overview of the recent advancements in video understanding harnessing the power of LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly advanced, particularly their ability for open-ended spatial-temporal reasoning combined with commonsense knowledge, suggesting a promising path for future video understanding. We examine the unique characteristics and capabilities of Vid-LLMs, categorizing the approaches into four main types: LLM-based Video Agents, Vid-LLMs Pretraining, Vid-LLMs Instruction Tuning, and Hybrid Methods. Furthermore, this survey presents a comprehensive study of the tasks, datasets, and evaluation methodologies for Vid-LLMs. Additionally, it explores the expansive applications of Vid-LLMs across various domains, highlighting their remarkable scalability and versatility in real-world video understanding challenges. Finally, it summarizes the limitations of existing Vid-LLMs and outlines directions for future research. For more information, readers are recommended to visit the repository at https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunlong Tang",
      "Jing Bi",
      "Siting Xu",
      "Luchuan Song",
      "Susan Liang",
      "Teng Wang",
      "Daoan Zhang",
      "Jie An",
      "Jingyang Lin",
      "Rongyi Zhu",
      "Ali Vosoughi",
      "Chao Huang",
      "Zeliang Zhang",
      "Feng Zheng",
      "Jianguo Zhang",
      "Ping Luo",
      "Jiebo Luo",
      "Chenliang Xu"
    ]
  },
  "http://arxiv.org/abs/2312.17296": {
    "title": "Structured Packing in LLM Training Improves Long Context Utilization",
    "volume": "Jan",
    "abstract": "Recent advances in long-context Large Language Models (LCLMs) have generated significant interest, especially in applications such as querying scientific research papers. However, their potential is often limited by inadequate context utilization. We identify the absence of long-range semantic dependencies in typical training data as a primary hindrance. To address this, we delve into the benefits of frequently incorporating related documents into training inputs. Using the inherent directory structure of code data as a source of training examples, we demonstrate improvements in perplexity, even for tasks unrelated to coding. Building on these findings, but with a broader focus, we introduce Structured Packing for Long Context (SPLiCe). SPLiCe is an innovative method for creating training examples by using a retrieval method to collate the most mutually relevant documents into a single training context. Our results indicate that \\method{} enhances model performance and can be used to train large models to utilize long contexts better. We validate our results by training a large $3$B model, showing both perplexity improvements and better long-context performance on downstream tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konrad Staniszewski",
      "Szymon Tworkowski",
      "Sebastian Jaszczur",
      "Henryk Michalewski",
      "Łukasz Kuciński",
      "Piotr Miłoś"
    ]
  }
}