{
  "https://ojs.aaai.org/index.php/AAAI/article/view/25070": {
    "title": "Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "118fd51b49e4f344873b8246bb051afb66c0c8d9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25071": {
    "title": "Reducing ANN-SNN Conversion Error through Residual Membrane Potential",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "366a99da9ddef081aacd362d3da6668dfff04b2d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25072": {
    "title": "Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "58f92031574529f13dfa8455c8bb539f43c722a0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25073": {
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "462b999f9e47915c89a0c70d797d3e82276f8410",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25074": {
    "title": "A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80df6f7525f24cce6d3d4c5f1a17566613a6f60d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25075": {
    "title": "A Machine with Short-Term, Episodic, and Semantic Memory Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d823694648cff737e14a613d5c743ac2b6cf39bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25076": {
    "title": "Persuasion Strategies in Advertisements",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1bd3def5257e992cecbcd5381771d77a95cc8200",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25077": {
    "title": "Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a78605f7d9372504eee3a0d9b86f0219a29d115",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25078": {
    "title": "AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4dbc668686f89830de4c67203db0709d9c4dda2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25079": {
    "title": "ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4e685992c8635225acabbe87d3900d104c9e78e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25080": {
    "title": "Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e09dc84599f5b9165eb38641ac7167b6fcfc450c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25081": {
    "title": "Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ced7e9eecfa29e4d5a4be0a2a649efd2ab119ed6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25082": {
    "title": "Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1126255b496a35ff2f04bfe33d6eedc765b649d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25083": {
    "title": "CMNet: Contrastive Magnification Network for Micro-Expression Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9ad4ac41b1ee5e150cb5adfc16b7c370d265d1c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25084": {
    "title": "Disentangling Reafferent Effects by Doing Nothing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6908360d349167eaec8c4007a56d84cea9397dc7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25085": {
    "title": "Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fbf899db663418a2fad1aa244e8d469d89138f0c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25086": {
    "title": "ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7fa2d8608e03c22ee025a27c7d6f81cc872735c6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25087": {
    "title": "Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6fbdc73ee62c32dc61cdddfb73410e1ec65cf35c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25088": {
    "title": "Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fc21e2c94cb2ed51809a9c96eccce810ef22520",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25089": {
    "title": "Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aed3b3d9809b0b3847d1853601eee97a9798257d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25090": {
    "title": "Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d7ce2e45a56c6cae56c4c9f0011f1ed739defc7",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25091": {
    "title": "Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef6fe11aa4b7dfec9f4d8da4e039f9c8d1839b0f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25092": {
    "title": "Layout Representation Learning with Spatial and Structural Hierarchies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f27d51387a1e00921c526cf0b44d8f41dc323e21",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25093": {
    "title": "Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ad6b3041cb994c57e26c4a8fe0203ffb1f0c8ea0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25094": {
    "title": "Multi-Level Compositional Reasoning for Interactive Instruction Following",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da804b058006e9b9ccda1776f437ceda9e869363",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25095": {
    "title": "Self-Supervised Image Local Forgery Detection by JPEG Compression Trace",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8d8f2834294897104e86f68a2f492058bfe5ccb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25096": {
    "title": "VASR: Visual Analogies of Situation Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b48eb1a32dcc4dcd122a5234c0fc055b71752e98",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25097": {
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b1f3354487bdc26a6eefef82960d085e9b78bb1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25098": {
    "title": "Explicit Invariant Feature Induced Cross-Domain Crowd Counting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7a2c9710df23afea3dfb8a7639fba8273c066cf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25099": {
    "title": "Painterly Image Harmonization in Dual Domains",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "04f9cc4d25baf7df5b14aa3e4bcdb91542f75d01",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25100": {
    "title": "MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cb09c77aab947c376df4fbcc4f2d877960f35d6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25101": {
    "title": "KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c407b4721a7aab2b198d73b373c53edfd5604d5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25102": {
    "title": "Deconstructed Generation-Based Zero-Shot Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50b3996ca86a55f9d3af68cb43c79659b1429daa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25103": {
    "title": "Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ef69136aa88675e3cf8aa33d87931d44a0615b2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25104": {
    "title": "Amodal Instance Segmentation via Prior-Guided Expansion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c9b776483a0de5d919842c05b48c029a78b7399",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25105": {
    "title": "SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d874861ec9f6b58166dcfcf05caf7a4a6bd032c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25106": {
    "title": "Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e7f81eb842623b41dd0bb09334506e148b076e66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25107": {
    "title": "Improving Dynamic HDR Imaging with Fusion Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1aea87fb6d103ecfc92b309b8c9ff9f10df47b7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25108": {
    "title": "Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b10dd9f4a5dfcc782c0a0892d43fea21cbb2eaea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25109": {
    "title": "Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dbb56d48ec9efeacf1d4dd31b76e23d5fb2c84b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25110": {
    "title": "Scalable Spatial Memory for Scene Rendering and Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "532cb7ca76a0e4f4993eae3e0cd31be73bd7e117",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25111": {
    "title": "Hybrid CNN-Transformer Feature Fusion for Single Image Deraining",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44c091514f3397740a1cbe72f86b53f2f409bc5b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25112": {
    "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d60265ea72d0344e991e71dfb13b4e1f15d4d4d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25113": {
    "title": "Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e9525ebe76a1d37533539ad2f560b1b453e66f6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25114": {
    "title": "DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "13d8ce3d2ac01cc5e108c1b89e79049428a53ad5",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25115": {
    "title": "Imperceptible Adversarial Attack via Invertible Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85af65c9355dc1ff8585354e014543751b498ee3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25116": {
    "title": "Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e0e103a2a1ed0241df544928d09d2a6b55c766e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25117": {
    "title": "User-Controllable Arbitrary Style Transfer via Entropy Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7dc98ae2967d6ad9c115ccaa705540b7489e0d40",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25118": {
    "title": "Neural Architecture Search for Wide Spectrum Adversarial Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3eb76059d9115f2f746b06dfcde7f8137147c59",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25119": {
    "title": "Adversarial Alignment for Source Free Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "693a942fa34028de582d18642d73d57c70842303",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25120": {
    "title": "Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "39dfc2eeb83e8694b1adc0b484775e9d47fee37a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25121": {
    "title": "OctFormer: Efficient Octree-Based Transformer for Point Cloud Compression with Local Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7acd42a6df03f98b6760c2f22b2bd2ce90695a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25122": {
    "title": "Dual-Domain Attention for Image Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ea2350d2bbafc07267d45aac410985376a6a332",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25123": {
    "title": "Multi-Resolution Monocular Depth Map Fusion by Self-Supervised Gradient-Based Composition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1527361af4eff8d52914a9e83f43471209c7de07",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25124": {
    "title": "Improving Crowded Object Detection via Copy-Paste",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea6e1e2254a95a7f5413f9fcfa4b1c0d63de46a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25125": {
    "title": "Defending Backdoor Attacks on Vision Transformer via Patch Processing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "95cb1fe9ad477b0ee3dff5659887f3ea0347e5e9",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25126": {
    "title": "Head-Free Lightweight Semantic Segmentation with Linear Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5fbc38ed3aa2de8eb22bc263e1c4d5091b7ce05a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25127": {
    "title": "Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52740e6b55a27ed79397adc59928ca90e739a53a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25128": {
    "title": "Exploring Tuning Characteristics of Ventral Stream's Neurons for Few-Shot Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f04d225453e19cda73c0de049a59a8acd7768bec",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25129": {
    "title": "Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "df11b7fd7c6f627ac8717e91e956e4611746afe3",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25130": {
    "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e38f4b4055abecbac2e618df2ecb33554073e08",
    "citation_count": 141
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25131": {
    "title": "Domain-General Crowd Counting in Unseen Scenarios",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f8232b83e87aef507a21b7afccecdbe511e46999",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25132": {
    "title": "Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bf39a82f65d9047e676f2f85f700c73d427b4189",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25133": {
    "title": "Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a888dd6d8dd0087fc7d74da8a005922d0923ad2b",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25134": {
    "title": "Target-Free Text-Guided Image Manipulation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a426c8209b38ed63b224363f4dcf179692d51ac",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25135": {
    "title": "One Is All: Bridging the Gap between Neural Radiance Fields Architectures with Progressive Volume Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e6f661b7ce2c457af3b9a4cee77101d93c2013c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25136": {
    "title": "Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f27d61ba154ada6b375a4dc313b673be7dbfdd84",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25137": {
    "title": "Uncertainty-Aware Image Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d13f52cbff1416d11986f996fa68ee9767844c60",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25138": {
    "title": "Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b027cb327be4a5051f00f0b84d936e8b2d3b653c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25139": {
    "title": "SEFormer: Structure Embedding Transformer for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "08e31f99bd0738c34100b24ffa0b059cdeebfc26",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25140": {
    "title": "Exploit Domain-Robust Optical Flow in Domain Adaptive Video Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4c180bdfe46f3d59791c7e970ccef667ab8481d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25141": {
    "title": "Scene-Level Sketch-Based Image Retrieval with Minimal Pairwise Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85b696039df8e3a934f69c5e5d72a904d4856fa2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25142": {
    "title": "Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "610924a1aa60494f01158fdb9cb680d0e6203148",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25143": {
    "title": "Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6acab3f2379de04d4a3449ed653add6db32a4af2",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25144": {
    "title": "Progressive Multi-View Human Mesh Recovery with Self-Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f63d71bfd0c363132865a36cd2169b3915888c94",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25145": {
    "title": "Incremental Image De-raining via Associative Memory",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7ff3f133e4290b266f5881a7108a681ffa72e45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25146": {
    "title": "Flexible 3D Lane Detection by Hierarchical Shape Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "247dfec8ebff13808228e73d4ad3166b45cb4972",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25147": {
    "title": "Underwater Ranker: Learn Which Is Better and How to Be Better",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9a07858f88daf54e0ced43ddc4e1178f754458b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25148": {
    "title": "ShadowFormer: Global Context Helps Shadow Removal",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7ffb3dee668255ccffc5970c795f0c1d79ad79b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25149": {
    "title": "RAFaRe: Learning Robust and Accurate Non-parametric 3D Face Reconstruction from Pseudo 2D&3D Pairs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "743cc26eb711e740724f5a94bb3bcc17a5201728",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25150": {
    "title": "RankDNN: Learning to Rank for Few-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9c63c1de8de192c62d334eb97bdff30c2f6fc64",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25151": {
    "title": "Social Relation Reasoning Based on Triangular Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71e0b80918978266b24e1d2df79f399885ba661d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25152": {
    "title": "CALIP: Zero-Shot Enhancement of CLIP with Parameter-Free Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca26023c4dbde9a54145b68e1a6a40533fcc1a4a",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25153": {
    "title": "Few-Shot Object Detection via Variational Feature Aggregation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d1e8a99b49e5ac7325e42c5958f76c22ac26e82",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25154": {
    "title": "Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eca815987e1c6a51e00fdc202342d50a288599f0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25155": {
    "title": "Target-Aware Tracking with Long-Term Context Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "62fc770746f6a283fbc5cfc32275e23bfef82eb7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25156": {
    "title": "Weakly-Supervised Camouflaged Object Detection with Scribble Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "613ac2c205cad421a28d7b3a357472a0883803c2",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25157": {
    "title": "Efficient Mirror Detection via Multi-Level Heterogeneous Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb30447cac68f1b22466da2f3f0d85e7a8e0d7c9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25158": {
    "title": "TransVCL: Attention-Enhanced Video Copy Localization Network with Flexible Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18c912802e3d6d84283d24655beb04f904d03675",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25159": {
    "title": "Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee301715607f618d22f21cb51c2c63ca85a4340c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25160": {
    "title": "Parameter-Efficient Model Adaptation for Vision Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "af593c53a9221bd12211f78d4f1ebd6b59cc4e7c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25161": {
    "title": "DarkFeat: Noise-Robust Feature Detector and Descriptor for Extremely Low-Light RAW Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a988d11e4a2c3de692bc879cf8c3d5be5e8e3ead",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25162": {
    "title": "GAM: Gradient Attention Module of Optimization for Point Clouds Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "a5820730290e81f76d843178af927591e669053d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25163": {
    "title": "Self-Supervised Learning for Multilevel Skeleton-Based Forgery Detection via Temporal-Causal Consistency of Actions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "84a150e189e34771752a5454a6f9e143a602dbb8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25164": {
    "title": "Self-Emphasizing Network for Continuous Sign Language Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f55d35e1d1a148898a756cb0380b22fa8878dcb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25165": {
    "title": "Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e32b2e5f07434a4d6ba73ee7394829ef93260124",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25166": {
    "title": "PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models against Adversarial Examples",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aec240626448b3506860a577d5d9ea3a20bfe794",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25167": {
    "title": "High-Resolution Iterative Feedback Network for Camouflaged Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "453d36c646576b04241ca7b964698eef64ebbdc8",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25168": {
    "title": "Leveraging Sub-class Discimination for Compositional Zero-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cb450cc6ccdaa0d1914cbc4d715f0eeb2792aa7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25169": {
    "title": "GPTR: Gestalt-Perception Transformer for Diagram Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6329ee4cf6bbd30c5d76d6caa78959946c656c56",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25170": {
    "title": "Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a63eff00c20172847439826377e412934caad068",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25171": {
    "title": "ClassFormer: Exploring Class-Aware Dependency with Transformer for Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eed051a90f635adb806c025c9b1fcc790f35ba0b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25172": {
    "title": "NLIP: Noise-Robust Language-Image Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2dd4bdb71e8d1a1bb6f7f2cb500972f082aa91fd",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25173": {
    "title": "Symmetry-Aware Transformer-Based Mirror Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b819d724661b35b93aa9048062d988fc6fc868fc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25174": {
    "title": "AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b42f494bf45ec5e154a007844cc449a07279c4f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25175": {
    "title": "Boosting Point Clouds Rendering via Radiance Mapping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18289220a3f778a35d89b9fadeba25820c1ad9ad",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25176": {
    "title": "FreeEnricher: Enriching Face Landmarks without Additional Cost",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9889925126ad324f3f60b0978882f00e23541206",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25177": {
    "title": "PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7fab5b0cc0bf96a1f987f9ebf18177e7915ba60",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25178": {
    "title": "Unifying Vision-Language Representation Space with Single-Tower Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e978d2f7e2a04da803d1a224b3ad868ac919dbb8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25179": {
    "title": "Delving Deep into Pixel Alignment Feature for Accurate Multi-View Human Mesh Recovery",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b5a878716aa4ab11e84ba0973d58ab35c68711a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25180": {
    "title": "Semi-attention Partition for Occluded Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "810862a848aa164ad7e0611ee4b850d6d28f4a1a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25181": {
    "title": "Fast Online Hashing with Multi-Label Projection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f98d2bd7a791f0eaea7aab20496a2b5efa0ed44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25182": {
    "title": "Fourier-Net: Fast Image Registration with Band-Limited Deformation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "743c723118ee61e2e5cc7161247c272522d8cdd5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25183": {
    "title": "Semi-supervised Deep Large-Baseline Homography Estimation with Progressive Equivalence Constraint",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a96f76cc868630a74b758951f5206e9f7e670e83",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25184": {
    "title": "Multi-Modality Deep Network for Extreme Learned Image Compression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fcbe9b439f1f694d79a3e788a3a4e2ce4655219a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25185": {
    "title": "PolarFormer: Multi-Camera 3D Object Detection with Polar Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "67a3e04199baad91ecf25b55f294f54b173c052b",
    "citation_count": 59
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25186": {
    "title": "3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d666dd97fa2659918fff88b3b279149121158ab",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25187": {
    "title": "FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e835e50b4c067cec7457332ec119994fb1a26422",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25188": {
    "title": "Estimating Reflectance Layer from a Single Image: Integrating Reflectance Guidance and Shadow/Specular Aware Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3054551f9f9dfd8d49d029e16b0d27f46990826",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25189": {
    "title": "Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cb7e9e6a68f64972cb42fc790c3a755175b80828",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25190": {
    "title": "Correlation Loss: Enforcing Correlation between Classification and Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "448224d5629a2d3ab1571811a2d183189f424376",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25191": {
    "title": "GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8ddb147c006cdeae6cd38f458e9c7c337d5b0965",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25192": {
    "title": "3D Human Pose Lifting with Grid Convolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eab5282e937a9b09b3af8c0956f1aa09ff20cfa9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25193": {
    "title": "Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a3577255e136a2c38198ac240cec2921bd739cde",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25194": {
    "title": "Frequency Selective Augmentation for Video Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2de0034a889be933b6059f9cfebc4edb35e4ff29",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25195": {
    "title": "Pose-Guided 3D Human Generation in Indoor Scene",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b60488cb4048b89121c0f50508c473bb8527d518",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25196": {
    "title": "Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "edf262d8983ca2ee80f6196365f8bf5e225603c5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25197": {
    "title": "Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d6d1f02bba8aadc484edfc5becba4a8b91f66343",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25198": {
    "title": "CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a32aec5f06324bd0dabab8a41c97e29a954a21a",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25199": {
    "title": "Simple and Effective Synthesis of Indoor 3D Scenes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "749fc01c222e526dab89e9cb4cb280447d7d65fe",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25200": {
    "title": "MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a600a57618e4f183ceec850fc9b441dda792728a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25201": {
    "title": "InstanceFormer: An Online Video Instance Segmentation Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7eb8252d603b202c9cd06c338d132b6eecfd35e0",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25202": {
    "title": "Pixel-Wise Warping for Deep Image Stitching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cc6c9024ae3beb06dfefe7b1e7813ab9a38e954",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25203": {
    "title": "Learning to Learn Better for Video Object Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0b7bf6eb268653a35a68e712516493a82b02d0f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25204": {
    "title": "Curriculum Multi-Negative Augmentation for Debiased Video Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "235d6337eeb067042eb90c957a4380506a78c7b7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25205": {
    "title": "Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0d75d6529e6098461434f5f4b3dbdd28ef29691",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25206": {
    "title": "MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc5df2954a38581b629ae0e86b8ec90b3af4b3bd",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25207": {
    "title": "Not All Neighbors Matter: Point Distribution-Aware Pruning for 3D Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f8a9671d33837ad90a9df091e03360c43fb5cc9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25208": {
    "title": "Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc1ed0c94657e9e340a038f02cab7b225704a4b9",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25209": {
    "title": "Linking People across Text and Images Based on Social Relation Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5d0b66ca3fec08cf52d56a375aada4a1360af49e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25210": {
    "title": "ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea5e945cde29b61254115d512e9d39fb57a7514c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25211": {
    "title": "SWBNet: A Stable White Balance Network for sRGB Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ba6d7080c349fba2d29fe42357639b00d5cb2cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25212": {
    "title": "Frequency Domain Disentanglement for Arbitrary Neural Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc21b6d4fe70b99b74acb442e8cf711efabe644c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25213": {
    "title": "Pose-Oriented Transformer with Uncertainty-Guided Refinement for 2D-to-3D Human Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4cc1b3aecef868c9d56adc4e6d8a1116774faef9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25214": {
    "title": "CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09a03bcf681ef763cdbcf69869204230d205d07e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25215": {
    "title": "Real-World Deep Local Motion Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a2c6c426b7f7921a41ba61fedcef8d12e05c32fe",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25216": {
    "title": "Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from a Conditional Causal Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "be2672ba4b68a5ebf69ce7c2f6024bd60f1d75c4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25217": {
    "title": "Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6ba44d7412305c1bab39b4b568e2e8492f9c9ed",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25218": {
    "title": "FSR: A General Frequency-Oriented Framework to Accelerate Image Super-resolution Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fa82af8be2e392986ad01984ae74de495efffeb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25219": {
    "title": "Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "20e4132660bf3e93e170c38dc970f5a59fba3d7e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25220": {
    "title": "Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d98fd91ed23b3ab623a60cd1713382b2163d5ce2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25221": {
    "title": "Spatial-Spectral Transformer for Hyperspectral Image Denoising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "efc12fd00542450f688bc4d8c9fc7db73309c723",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25222": {
    "title": "Learning Semantic Alignment with Global Modality Reconstruction for Video-Language Pre-training towards Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a17e108c9a99ba9a8db813fecc45b3e651e6a74",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25223": {
    "title": "Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c79bc6ce52539e42985a892e3745822590c2865",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25224": {
    "title": "NeAF: Learning Neural Angle Fields for Point Normal Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a765befc5a9f7816a2ae6cf2a911a94ff24c3399",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25225": {
    "title": "CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification without Concrete Text Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8adfb137332a61893417609563897abe9307a11",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25226": {
    "title": "DC-Former: Diverse and Compact Transformer for Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "540dcdf4a4556facf03a6cffed4f23a584f64317",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25227": {
    "title": "Panoramic Video Salient Object Detection with Ambisonic Audio Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ecce926a9877bb7512ce4d1101582877e07db12",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25228": {
    "title": "LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e11ee3c730263c6b92c24f1d707ed35626b7e5a1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25229": {
    "title": "Adaptive Texture Filtering for Single-Domain Generalized Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8d475edd830f150b9a6aa3066524c77913510df8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25230": {
    "title": "MEID: Mixture-of-Experts with Internal Distillation for Long-Tailed Video Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a96fdfacff96f3a4e944849f856752bc374f7bf1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25231": {
    "title": "Gradient Corner Pooling for Keypoint-Based Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2812527625498e4dd256e4ddb0f4a49aeffd2d61",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25232": {
    "title": "Towards Real-Time Segmentation on the Edge",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98b67efc8ca78e7e254a1fa543996b69635aa080",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25233": {
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-View 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "234f0122e0edccba5c91763e800c2f02fe8ae4fe",
    "citation_count": 129
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25234": {
    "title": "BEVStereo: Enhancing Depth Estimation in Multi-View 3D Object Detection with Temporal Stereo",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1285d14bffedcc4362fdd05213fd6ee4ec5ca885",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25235": {
    "title": "Learning Single Image Defocus Deblurring with Misaligned Training Pairs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b31de933dc82b38a598c1d274fc9ade2d987c0ba",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25236": {
    "title": "Curriculum Temperature for Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ee96ee0d32816658daa507e2228b037768f148b",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25237": {
    "title": "Actionness Inconsistency-Guided Contrastive Learning for Weakly-Supervised Temporal Action Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fce2e326ec543ef51f6d6e0294ae21d5074320bc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25238": {
    "title": "READ: Large-Scale Neural Scene Rendering for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "982236b056edc17962853c7344e5cf43513b474c",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25239": {
    "title": "CDTA: A Cross-Domain Transfer-Based Attack with Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5206aa1f39cdbc90245bab8761375f9159d913a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25240": {
    "title": "HybridCap: Inertia-Aid Monocular Capture of Challenging Human Motions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15453b482f58c9ef4a2f55f1cfb8872ef7cb7426",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25241": {
    "title": "Global Dilated Attention and Target Focusing Network for Robust Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d2e10ada5a6ac8442d38117e92508de98f165526",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25242": {
    "title": "Only a Few Classes Confusing: Pixel-Wise Candidate Labels Disambiguation for Foggy Scene Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c4f3efd0e7c9c0e1ce649fea31d7f8836f01293",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25243": {
    "title": "Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "137330d3030f75b01c88c14e1164d9b0d8c2dc70",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25244": {
    "title": "Probability Guided Loss for Long-Tailed Multi-Label Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa528fcfa48fe9333220012501e224cde12040fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25245": {
    "title": "Self-Supervised Image Denoising Using Implicit Deep Denoiser Prior",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0753df5be5fabf893ae9604c34c12a0a6233a91c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25246": {
    "title": "Accelerating the Training of Video Super-resolution Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "060bac73d0c6cab65b91f77364645a0afe142d38",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25247": {
    "title": "SelectAugment: Hierarchical Deterministic Sample Selection for Data Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44f4975b026c7c9ab934ead385afae080b20d66b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25248": {
    "title": "AdaCM: Adaptive ColorMLP for Real-Time Universal Photo-Realistic Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b19b1569f783fc4252deb5128889b5b466afefc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25249": {
    "title": "SEPT: Towards Scalable and Efficient Visual Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53169794d50f7541ea4a93417443751ed76a2009",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25250": {
    "title": "Cross-Modality Earth Mover's Distance for Visible Thermal Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e511d05b03a4d6d3ba9c02ec1e1dbf00794ff81e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25251": {
    "title": "Hypotheses Tree Building for One-Shot Temporal Sentence Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0bfac78dbab5f4318e1a065d6de413ba8ce24ed",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25252": {
    "title": "The Devil Is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ab64c8e9e05fd2426d6cc51f16d931279b862df",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25253": {
    "title": "M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f61187d734d9dfc7cdbb5e0c8ecb6e0a2f70c85",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25254": {
    "title": "From Coarse to Fine: Hierarchical Pixel Integration for Lightweight Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f56ed9f1ca57d3fb73dd6a08c101119e278c3f65",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25255": {
    "title": "Fast Fluid Simulation via Dynamic Multi-Scale Gridding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91c3eea164d6c32dd00647594f3ca3be21030a0d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25256": {
    "title": "TransLO: A Window-Based Masked Point Transformer Framework for Large-Scale LiDAR Odometry",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "792798d7cfde416beedcae70cd5b5a92c4ab2737",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25257": {
    "title": "Low-Light Video Enhancement with Synthetic Event Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15837a406a4f6859ca89b1cbbd7b391464164195",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25258": {
    "title": "Novel Motion Patterns Matter for Practical Skeleton-Based Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6a841c4254d8d95ef69abb365087ef3544ad0f82",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25259": {
    "title": "EMEF: Ensemble Multi-Exposure Image Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e8af97164df4a203f39f6d19c17d9b58952d93d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25260": {
    "title": "Reducing Domain Gap in Frequency and Spatial Domain for Cross-Modality Domain Adaptation on Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea10d0a86d0989d97088964d9dfb3f3dbc34daa2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25261": {
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "19ddeaf042fa00814a459e12d03f15801551e423",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25262": {
    "title": "Progressive Neighborhood Aggregation for Semantic Segmentation Refinement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2be38731ed22dbb6ee0ad425fe09f3dc89c856d3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25263": {
    "title": "CoordFill: Efficient High-Resolution Image Inpainting via Parameterized Coordinate Querying",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bbefdde6de6e100794448eadd2de8fc01f147d27",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25264": {
    "title": "CCQ: Cross-Class Query Network for Partially Labeled Organ Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f27fa335b4be16de2e43b765f9dcc97ace8dfff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25265": {
    "title": "Counterfactual Dynamics Forecasting – a New Setting of Quantitative Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "6cb1a49f248413f851eb6c345a2006aca8e96192",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25266": {
    "title": "Self-Decoupling and Ensemble Distillation for Efficient Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b192a0023f769edb31dc191fcc9210318c558df",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25267": {
    "title": "Token Mixing: Parameter-Efficient Transfer Learning from Image-Language to Video-Language",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5fcb5889e7c716b2493da67b63179cb0034c0c66",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25268": {
    "title": "StereoDistill: Pick the Cream from LiDAR for Distilling Stereo-Based 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "628766d52767f8c872047708a21cc0c320366715",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25269": {
    "title": "Good Helper Is around You: Attention-Driven Masked Image Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c58af37caedda1af6833209ef6b384d350743ffd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25270": {
    "title": "RADIANT: Radar-Image Association Network for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9968d3c8e3b099e02f7e57ab8aeee0f95a781fdc",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25271": {
    "title": "CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation via Centrifugal Reference Frame",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45ea3b4f2e53eaa4fb57ea679646848c48d489eb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25272": {
    "title": "See Your Emotion from Gait Using Unlabeled Skeleton Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "42683c65f41540177c08642aa635bce8d567537f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25273": {
    "title": "Learning Progressive Modality-Shared Transformers for Effective Visible-Infrared Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee04b2b113700b71de4fe91bddc9cd10348486b7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25274": {
    "title": "Breaking Immutable: Information-Coupled Prototype Elaboration for Few-Shot Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b09025b0b145ad07346fd75e7b5c0429e422ec7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25275": {
    "title": "ParaFormer: Parallel Attention Transformer for Efficient Feature Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "467268d70982cceb82206f526485951b0cff3e80",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25276": {
    "title": "Robust One-Shot Segmentation of Brain Tissues via Image-Aligned Style Transformation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ddc061eec9873bd2b38a284e21561eda1ef0756",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25277": {
    "title": "HRDoc: Dataset and Baseline Method toward Hierarchical Reconstruction of Document Structures",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cef1779a38aeb0aefbc347318b22e7b5cf890c03",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25278": {
    "title": "Semantic 3D-Aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "01df332f62508f976fea91cdad8010669efc5701",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25279": {
    "title": "CFFT-GAN: Cross-Domain Feature Fusion Transformer for Exemplar-Based Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29d35ab84788ca14e2b65a457c7fed5ee6f150a4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25280": {
    "title": "StyleTalk: One-Shot Talking Head Generation with Controllable Speaking Styles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ef7df2ace0723583ba22bf165188cd7d2044e93",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25281": {
    "title": "Intriguing Findings of Frequency Selection for Image Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6f039e6f7b0ef12afc01f0992f477ecc7bfdb31",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25282": {
    "title": "DocEdit: Language-Guided Document Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "383db93b039c2f7d743a06dc62a8db2ff1ea33f7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25283": {
    "title": "Progressive Few-Shot Adaptation of Generative Model with Align-Free Spatial Correlation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e5bed4c8dbc00e975c9d585e7592eaaf2d9d28e5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25284": {
    "title": "Minority-Oriented Vicinity Expansion with Attentive Aggregation for Video Long-Tailed Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5020cc02130c7625836f28969aa632eb87d83f28",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25285": {
    "title": "Show, Interpret and Tell: Entity-Aware Contextualised Image Captioning in Wikipedia",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7405b595f266e02f5cac24a11d83b7e341662f6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25286": {
    "title": "TaCo: Textual Attribute Recognition via Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "69df56f5b6134ab85fbf878593eb17a968453538",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25287": {
    "title": "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6df6c71be7a04e3e5c2a0dae037fe38458fe1ef6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25288": {
    "title": "Adapting Object Size Variance and Class Imbalance for Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a30c72de1c89f3c1c38f8e4390699c86bb15626",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25289": {
    "title": "MIMO Is All You Need：A Strong Multi-in-Multi-Out Baseline for Video Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "6ec6176e06ba9918ce563dc89a96303408fd97cf",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25290": {
    "title": "Universe Points Representation Learning for Partial Multi-Graph Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61feea09030ace88eb0ddcdcf8942b002b5adfd3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25291": {
    "title": "Robust Image Denoising of No-Flash Images Guided by Consistent Flash Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "81eb06c149775e0de9ec7b04bb4d4b53abf04d43",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25292": {
    "title": "Coarse2Fine: Local Consistency Aware Re-prediction for Weakly Supervised Object Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9070385c89cf2385629b70e1ed7267a9391554d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25293": {
    "title": "Find Beauty in the Rare: Contrastive Composition Feature Clustering for Nontrivial Cropping Box Regression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "82fa44d3b927745ed1e2397eacc02596da50d0f6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25294": {
    "title": "Domain Decorrelation with Potential Energy Ranking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "55b51b993600aa23d84e1e15fb53641100e9c772",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25295": {
    "title": "PDRF: Progressively Deblurring Radiance Field for Fast Scene Reconstruction from Blurry Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "559f7202200ef3c187780301590e2f2b4665f047",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25296": {
    "title": "Efficient End-to-End Video Question Answering with Pyramidal Multimodal Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2837e0cab1d600fa9ca29ebdbfab239701065071",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25297": {
    "title": "CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b57872957f8f70573b62a27c4b91e0636b218983",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25298": {
    "title": "Better and Faster: Adaptive Event Conversion for Event-Based Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bd82d465f64ef748e3de025a2ad0edf05f300fdd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25299": {
    "title": "CSTAR: Towards Compact and Structured Deep Neural Networks with Adversarial Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29bb2597be1a499d30d23844bf19d5c43f6afc12",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25300": {
    "title": "Exploring Stochastic Autoregressive Image Modeling for Visual Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fa0872e45bf6c0fee528c86120f52490142efba6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25301": {
    "title": "Context-Aware Transformer for 3D Point Cloud Automatic Annotation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ec629633af4d16bbc8db0cc3fb26964cfa33eb6c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25302": {
    "title": "Data-Efficient Image Quality Assessment with Attention-Panel Decoder",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "959eac73869bb8ec9096871957c938840e0fdcd0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25303": {
    "title": "FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29a2c4d44117e51e0d2fa6ffac516222ecab254f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25304": {
    "title": "Exposing the Self-Supervised Space-Time Correspondence Learning via Graph Kernels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1b137feaa09a7660c26107d7cf0411e2e99058c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25305": {
    "title": "Exploring Stroke-Level Modifications for Scene Text Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8fe2b02776208670906c89f8b8d361074fc87d5",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25306": {
    "title": "Unsupervised Deep Learning for Phase Retrieval via Teacher-Student Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c02b92e4ffb3edd22280154b535017de8a1938c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25307": {
    "title": "A Learnable Radial Basis Positional Embedding for Coordinate-MLPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05450d77727a1c58854e0b8550ca9f82e05d1cd8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25308": {
    "title": "Action-Conditioned Generation of Bimanual Object Manipulation Sequences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44d343bfa354e4afa7a3bed82a7831d677e3e210",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25309": {
    "title": "Mean-Shifted Contrastive Loss for Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d90243c5a46430a36c5ba88627b5d254450a1e1",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25310": {
    "title": "Two Heads Are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a09509004fb374d794fb4065b54e9a5dda630e6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25311": {
    "title": "MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-robust Classifier",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "790ba79fa1fcc7446fd81047c9e86b2b4c862d7a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25312": {
    "title": "Domain Generalised Faster R-CNN",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b22618848e56abbf7dcf1d7f419b72215cefcdb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25313": {
    "title": "MIDMs: Matching Interleaved Diffusion Models for Exemplar-Based Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ed3b73719016f3500c5976234111b87c21837bf",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25314": {
    "title": "JR2Net: Joint Monocular 3D Face Reconstruction and Reenactment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e51e322712413d3e6d5b8abef8d74cbfdaa2ae4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25315": {
    "title": "HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "643626048cc70b1ed4ed3a0fc94d58b02b7945f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25316": {
    "title": "Channel Regeneration: Improving Channel Utilization for Compact DNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e32b11399247648b4d9f50bd54f8a383280489fb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25317": {
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6f14a642033b72454afbecdb90c82872d8085dd2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25318": {
    "title": "Edge Structure Learning via Low Rank Residuals for Robust Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "925794910710207106ee192ff97475a2617bef3c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25319": {
    "title": "Memory-Oriented Structural Pruning for Efficient Image Restoration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9f5408d8c08a2f7beb35cb16c6ccdcf67b3c7d3d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25320": {
    "title": "YOLOV: Making Still Image Object Detectors Great at Video Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa289e06d4a11f50ce1f5287415a7ff752c136f6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25321": {
    "title": "FeedFormer: Revisiting Transformer Decoder for Efficient Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "de8d3b6ef17f924fc8d01d09bcc128c068dc1469",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25322": {
    "title": "Task-Specific Scene Structure Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3194258a0374f03f1ba1b968fa181fc1e1456b49",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25323": {
    "title": "Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "41e11c36e6fd2377fe5ecb9d0d0422c635ee4be0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25324": {
    "title": "SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8fe203feefec99d20ed68003e5389a46a0d7f285",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25325": {
    "title": "Siamese-Discriminant Deep Reinforcement Learning for Solving Jigsaw Puzzles with Large Eroded Gaps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14ef45b70e11c8222baf19f30cc045f54d574c23",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25326": {
    "title": "CLIPVG: Text-Guided Image Manipulation Using Differentiable Vector Graphics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cda631065b5300aa3d3d3226a4da9d3a36939494",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25327": {
    "title": "Compact Transformer Tracker with Correlative Masked Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8e6e17ca2288c26b79cedff0a666e2549441ac1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25328": {
    "title": "Text-DIAE: A Self-Supervised Degradation Invariant Autoencoder for Text Recognition and Document Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e0714e9dc5dc5ce5b4eda032d166fb07bb26ca1",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25329": {
    "title": "PUPS: Point Cloud Unified Panoptic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72e8986a912f812b71f02e4083d349104c0db158",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25330": {
    "title": "Efficient Edge-Preserving Multi-View Stereo Network for Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "20475d345d152fa4a78b9eb37f3ffe7f2d3cfcf6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25331": {
    "title": "Referring Expression Comprehension Using Language Adaptive Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0b4d116cb264894b47e0c25cb89344c924ba9cc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25332": {
    "title": "Rethinking Data Augmentation for Single-Source Domain Generalization in Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c8368b16b978c36bcb368e673c292254d8a4cf01",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25333": {
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e4aa84de53f8d6f8245ff6bc3c535ed260edfe2",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25334": {
    "title": "Learning Event-Relevant Factors for Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f1b6f5dcd5f802f2782ef15629be57202e3b629",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25335": {
    "title": "Superpoint Transformer for 3D Scene Instance Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e015130b27aaa95674e7c4b5dcbb5a7a7fe7ed04",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25336": {
    "title": "Asynchronous Event Processing with Local-Shift Graph Convolutional Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29f12988ea953725e791e7467b479f7161a487ac",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25337": {
    "title": "DENet: Disentangled Embedding Network for Visible Watermark Removal",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5720ed9d22f2f83a75e7f8efb7b466691f631138",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25338": {
    "title": "Deep Manifold Attack on Point Clouds via Parameter Plane Stretching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38a454f66e8fca40a342f5edb3b1d433eb091971",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25339": {
    "title": "Fair Generative Models via Transfer Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c77f32cb3a030c04de992be40fdf882690afeef8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25340": {
    "title": "Learning Context-Aware Classifier for Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ca374400fc1dd1078ce39c942ff8df562fb163b",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25341": {
    "title": "TopicFM: Robust and Interpretable Topic-Assisted Feature Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1df8ce9e21c544a8ba0911e3e7825abc752236eb",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25342": {
    "title": "Learning Fractals by Gradient Descent",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8715975820cbacdc844a196e2f2f471cca982ccb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25343": {
    "title": "Leveraging Weighted Cross-Graph Attention for Visual and Semantic Enhanced Video Captioning Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a5e3cf08174095cbe4cec418d19b8fc260af49cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25344": {
    "title": "Doodle to Object: Practical Zero-Shot Sketch-Based 3D Shape Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d658819f2aad7f8fe5ec951c595d432f0d8db33f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25345": {
    "title": "Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f8860a5ef6097a9a01a352e609366343627db577",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25346": {
    "title": "Dual Memory Aggregation Network for Event-Based Object Detection with Learnable Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d902c86c7a1cbdac013523488adf85942aa11169",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25347": {
    "title": "Text to Point Cloud Localization with Relation-Enhanced Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23a24e1740bf1b5bd5f39b18114b65ceabed1db0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25348": {
    "title": "UCoL: Unsupervised Learning of Discriminative Facial Representations via Uncertainty-Aware Contrast",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77f6e57c4c5d73fe7805c662381ebad5ed643789",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25349": {
    "title": "Calibrated Teacher for Sparsely Annotated Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "045465a04985227f05a437ecc459fbc8b1cb0478",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25350": {
    "title": "Towards Real-Time Panoptic Narrative Grounding by an End-to-End Grounding Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "436f2d681c3448b6d10cea53238974987d71c0f2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25351": {
    "title": "LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36b5d21ee97844ec915f5740e37e95c41992409c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25352": {
    "title": "Defending Black-Box Skeleton-Based Human Activity Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "24d47781fb60fd3a427d426d763fc544bee8175b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25353": {
    "title": "Exploring CLIP for Assessing the Look and Feel of Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03ae89e796b1a8b566ae1554fab65c8c88b3a55f",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25354": {
    "title": "Robust Video Portrait Reenactment via Personalized Representation Quantization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f54e8f1d3af326ccbd372fe1cf7f548f7fd6a483",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25355": {
    "title": "De-biased Teacher: Rethinking IoU Matching for Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "656d87d314009a9f1925348d30652f39e0cc7ed5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25356": {
    "title": "Learning to Generate an Unbiased Scene Graph by Using Attribute-Guided Predicate Features",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da31afdbc962f0323d013a88a0c308c61b4d247c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25357": {
    "title": "Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ff504e8d0ed00d8e9d6dd317d3b7572d1f3ecaa",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25358": {
    "title": "Flora: Dual-Frequency LOss-Compensated ReAl-Time Monocular 3D Video Reconstruction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "de0d19110a0601c0741df7d26982a0c44288ce90",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25359": {
    "title": "Efficient Image Captioning for Edge Devices",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d6332c9a4607ce9823123e6407e40ab6ac33ac08",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25360": {
    "title": "Controllable Image Captioning via Prompting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f66aeec98816c3a52685e570a04fa8f2bd53dfb4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25361": {
    "title": "ECO-3D: Equivariant Contrastive Learning for Pre-training on Perturbed 3D Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c1cef162d3c6276c84deb22c08a2b6d7e2d38a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25362": {
    "title": "Global-Local Characteristic Excited Cross-Modal Attacks from Images to Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "af77300381156898024ea3a10f6d00cc31b8ee86",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25363": {
    "title": "Fine-Grained Retrieval Prompt Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "247be1257a1c5811ff48331e902771c7b00a56c5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25364": {
    "title": "Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "baf3d202261f1eb9122a157fc6480d93e2c3d03c",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25365": {
    "title": "3D Assembly Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb2256efc25ad00d4a18a9901cf83b17dbc038a4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25366": {
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "974e24ce5ca6a23b8841f3b1049edff0aeaf42ce",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25367": {
    "title": "Revisiting Unsupervised Local Descriptor Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b72f022c06dbfa52af4f31a766ca57e7758b5990",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25368": {
    "title": "Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "588042275a2e338df56ace42453c727137da36fc",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25369": {
    "title": "Learning Continuous Depth Representation via Geometric Spatial Aggregator",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9dc77eb07e11d3fd09f2dd5d2225ded4291f6d3b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25370": {
    "title": "SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bfc07ed6e6d4aef2674d0e412215b3253b95336c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25371": {
    "title": "High-Resolution GAN Inversion for Degraded Images in Large Diverse Datasets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36da639b3cba35311314a19e5bfd987c5865a061",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25372": {
    "title": "GAN Prior Based Null-Space Learning for Consistent Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c12d091ea5c16938943559fb0f3d430ba040c08",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25373": {
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65be7f0b01cf6c2a1cded708b809182fbcb43548",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25374": {
    "title": "MicroAST: Towards Super-fast Ultra-Resolution Arbitrary Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7b0183c518ebc2100569f1086fd6fedab8659d96",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25375": {
    "title": "Truncate-Split-Contrast: A Framework for Learning from Mislabeled Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bb62dd71543f4644cec09b00bdf7b8b2795063fd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25376": {
    "title": "Active Token Mixer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "20fc19d7445ec081a95a3e97bab3f1f07c92988d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25377": {
    "title": "Exploring Non-target Knowledge for Improving Ensemble Universal Adversarial Attacks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2cf7b3b2fb58431d96e934effbb0af3a3ba60eb9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25378": {
    "title": "Towards Good Practices for Missing Modality Robust Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12a43c120c9e7615535237bbee2f6375d07fdd7a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25379": {
    "title": "Reject Decoding via Language-Vision Models for Text-to-Image Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f9fff9bf668264b454ee45e67135ea2debd7b8f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25380": {
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8599f26dd40313a092dc05fe370b934beb6a29ef",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25381": {
    "title": "Super-efficient Echocardiography Video Segmentation via Proxy- and Kernel-Based Semi-supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6f991a9b4da4d520d11684d42cdf403d0be5917",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25382": {
    "title": "ACL-Net: Semi-supervised Polyp Segmentation via Affinity Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7fe355f1db5dbf47e4ac223c7a48e8dbaa7cbe1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25383": {
    "title": "Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8d3436667b7863759a5d2228366e357f35a6e8d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25384": {
    "title": "Preserving Structural Consistency in Arbitrary Artist and Artwork Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e808f718e4f195527e8ea3ecb252e25e24c98bae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25385": {
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2b2a7f713d8efe2696df85ef22dac7ef35be7e10",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25386": {
    "title": "Revisiting Classifier: Transferring Vision-Language Models for Video Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c68b9483bcd91850e27cc6d667c783edf335a3e4",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25387": {
    "title": "Scene Graph to Image Synthesis via Knowledge Consensus",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "feb5504685a92ea0b2283959a1b508f54bab1627",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25388": {
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for Unsupervised Visual Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fe6ee1f2bf6fa3093798723d3edab686fd927d1d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25389": {
    "title": "Multi-Stream Representation Learning for Pedestrian Trajectory Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b1552a37506344714092defaf1a4bc9488f9bd67",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25390": {
    "title": "Pixel Is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "088a89c3ef90e80b050ac717400209f564099654",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25391": {
    "title": "Attention-Based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6c475af6a695d494b8790ca878f146e795eeb27b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25392": {
    "title": "Skating-Mixer: Long-Term Sport Audio-Visual Modeling with MLPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14165df6bd6ebe598d65d740ee7bcefee2e178f4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25393": {
    "title": "SVFI: Spiking-Based Video Frame Interpolation for High-Speed Motion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a30499c63169d649d9104fa05de10dce6fef3e7b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25394": {
    "title": "FEditNet: Few-Shot Editing of Latent Semantics in GAN Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cde780c2bad086fa5267a11068bb40d320616b4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25395": {
    "title": "Toward Robust Diagnosis: A Contour Attention Preserving Adversarial Defense for COVID-19 Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a68b491f64daf9eee7551469e5d7a39fa62515ad",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25396": {
    "title": "Boosting Semi-Supervised Semantic Segmentation with Probabilistic Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12e668ad61fbcfb1e4752f1243082dc8c0f75f4f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25397": {
    "title": "Less Is More Important: An Attention Module Guided by Probability Density Function for Convolutional Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7624dc2e2c610040b778ce11c3261523e7b27c93",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25398": {
    "title": "Mitigating Artifacts in Real-World Video Super-resolution Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "442f3bde58bd8f736f8643a5fb2feec0854bf368",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25399": {
    "title": "Just Noticeable Visual Redundancy Forecasting: A Deep Multimodal-Driven Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4dc3f4d5a05f9af6b5c78f67b8cb6704738ad7e5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25400": {
    "title": "Cross-Modal Contrastive Learning for Domain Adaptation in 3D Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ff5d423b6dc934d58c7541df31b507fdda059be5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25401": {
    "title": "ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient Self-Supervised Monocular Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "373959536e023e451b46e6e3d60228b59568a5ac",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25402": {
    "title": "LORE: Logical Location Regression Network for Table Structure Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a90a77893708ae5070e2ed4572ca9e20837e69c6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25403": {
    "title": "Revisiting the Spatial and Temporal Modeling for Few-Shot Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7723859aa67aa5324155dfafa1f078b3bc034178",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25404": {
    "title": "Unsupervised Multi-Exposure Image Fusion Breaking Exposure Limits via Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc8f02331ed5baed6f5c0adb9c9cb2fca5e7c1a8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25405": {
    "title": "CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene Completion by Dense Feature Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ede618392b52947f4103415c97e444c20697e550",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25406": {
    "title": "Learning a Generalized Gaze Estimator from Gaze-Consistent Feature",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a79ce59268ff9b07f61ba730bdfb8f0eaa54ab0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25407": {
    "title": "Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44891165b360ccf98d7f6fd7f5361a6d5f3b4a3b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25408": {
    "title": "Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17b71c39617d654ff345d7e48491068f7d519b0c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25409": {
    "title": "Deep Parametric 3D Filters for Joint Video Denoising and Illumination Enhancement in Video Super Resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e64440b53317fa8b5b800f238d500d586ae5e17f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25410": {
    "title": "Inter-image Contrastive Consistency for Multi-Person Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e5b923a3498a977c0758a1578cb0af1fa180420",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25411": {
    "title": "DeMT: Deformable Mixer Transformer for Multi-Task Learning of Dense Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3d3c1321554d7d14eec309e61ba70102b0629e1",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25412": {
    "title": "VLTinT: Visual-Linguistic Transformer-in-Transformer for Coherent Video Paragraph Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c35fc28cb4e9336f4077cfc9cc559f55950b5996",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25413": {
    "title": "Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1b14b7ed6601b4e1fd847a3043e749ca0bf02aa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25414": {
    "title": "Video-Text Pre-training with Learned Regions for Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "615d077899e7c57c7073d427035499749fa7b355",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25415": {
    "title": "DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15d9392d12635221d6dba08a33344f6fc97060ce",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25416": {
    "title": "Self-Supervised Video Representation Learning via Latent Time Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71a971a7a86459eb7a568985fe398a7c79b3dd35",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25417": {
    "title": "One-Shot Replay: Boosting Incremental Object Detection via Retrospecting One Object",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9bc81d69b990c814770096f3aa41ded4f639df6d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25418": {
    "title": "Video Event Extraction via Tracking Visual States of Arguments",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e3516142b2d7cf7fb67805a8b45fb077c9c6bb8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25419": {
    "title": "CoMAE: Single Model Hybrid Pre-training on Small-Scale RGB-D Datasets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2feabd1e149da3aa82cc6d1d684cac836a0c01e7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25420": {
    "title": "Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae0c998d3efe583b19fd4d1274eec3520c8f813a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25421": {
    "title": "Stop-Gradient Softmax Loss for Deep Metric Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a792e32749ebb98686791d4524f4e8d4ba575433",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25422": {
    "title": "Local Path Integration for Attribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "87d4cf1dd6507e7c989b25a4a1eeea1a467c3a54",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25423": {
    "title": "Spatiotemporal Deformation Perception for Fisheye Video Rectification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fd89aa30d4917bde9a2343d5590456ce2d76ac8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25424": {
    "title": "Contrastive Multi-Task Dense Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "59c681b58d85411ba5a70284947ad728f468c54c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25425": {
    "title": "AutoStegaFont: Synthesizing Vector Fonts for Hiding Information in Documents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6225139fe937b85a1a4a7d03e10354745f764b5c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25426": {
    "title": "Towards Global Video Scene Segmentation with Context-Aware Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "807937ad69b41b6a320d9d180fa9fe0205d56804",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25427": {
    "title": "Low-Light Image Enhancement Network Based on Multi-Scale Feature Complementation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0287e28e409920e97b5b308974750914d60ba7b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25428": {
    "title": "Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "21cbb159992abffdee87c2a1bc15a3d98bdfde8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25429": {
    "title": "LidarMultiNet: Towards a Unified Multi-Task Network for LiDAR Perception",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09ce90a7d46c297db17e41cfd4e7691933408540",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25430": {
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f89d5e8e3c6e3bb035729c1f6039ee95149ce0b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25431": {
    "title": "Learning Second-Order Attentive Context for Efficient Correspondence Pruning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f5faa47345366d623a8cd3b41e63276065c404a3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25432": {
    "title": "Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "28f4d454359641f62944674ea085e84aff5ce023",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25433": {
    "title": "Can We Find Strong Lottery Tickets in Generative Models?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74fb4456760e417ec2873cfab1e4c87ce59df8f6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25434": {
    "title": "Class-Independent Regularization for Learning with Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "284858ac99309568e83377a9968a1908ee28c717",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25435": {
    "title": "Unbiased Heterogeneous Scene Graph Generation with Relation-Aware Message Passing Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b02f9674a07d6a7e4ab5f4846301dc8d15433e46",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25436": {
    "title": "Lifelong Person Re-identification via Knowledge Refreshing and Consolidation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cdba9c57d5e372bee7a382c2f287eb20da244977",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25437": {
    "title": "Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dddeca3509132717a8b5843f730b8b01a3887dcc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25438": {
    "title": "Rethinking Rotation Invariance with Point Cloud Registration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ca5939d6e64dc751de8bd513980f57a2d43af55",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25439": {
    "title": "Frame-Level Label Refinement for Skeleton-Based Weakly-Supervised Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ac0d48894ddbb9232730ab54f9a7754dc6e73c45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25440": {
    "title": "Recurrent Structure Attention Guidance for Depth Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5010526e685c33293be4317720235e639a3bf2e7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25441": {
    "title": "Structure Flow-Guided Network for Real Depth Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98338f97c57fdaea642fa19df65d761349562ca4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25442": {
    "title": "Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b489c6fe772b861a99a14f5f6474b0d44a4a8f2e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25443": {
    "title": "Cyclically Disentangled Feature Translation for Face Anti-spoofing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9abd5e50e280323e3446595d23aa696113346465",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25444": {
    "title": "FlowFace: Semantic Flow-Guided Shape-Aware Face Swapping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "166d8ab629f46c818f42fa4e802a6033d42ece16",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25445": {
    "title": "Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1820749124aa1eaa51c47cb084f13c76b1a8ed2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25446": {
    "title": "Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "297c953df13c4375527df215b57f9c72c036a569",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25447": {
    "title": "Darwinian Model Upgrades: Model Evolving with Selective Compatibility",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d49b452bf09020f032ff65aa115740e3bf99ea0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25448": {
    "title": "Mx2M: Masked Cross-Modality Modeling in Domain Adaptation for 3D Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc430bba79178483c254a072c2151f0b3e7111af",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25449": {
    "title": "Few-Shot 3D Point Cloud Semantic Segmentation via Stratified Class-Specific Attention Based Transformer Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80df029becc3fdf6789c0d4c4fdf9a832f2e2672",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25450": {
    "title": "PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement and Pose Restoration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e6ad00f8c11a9237fc112ecff222e00fd71174ae",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25451": {
    "title": "Hierarchical Consistent Contrastive Learning for Skeleton-Based Action Recognition with Growing Augmentations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51133d759e81916553edf4e35a20385d12090abe",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25452": {
    "title": "ImageNet Pre-training Also Transfers Non-robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b28004c12d1073f3b186483ecb9e8fb816dd37c8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25453": {
    "title": "Language-Assisted 3D Feature Learning for Semantic Scene Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e667180d34f837c7416358414a387595d54eee4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25454": {
    "title": "IKOL: Inverse Kinematics Optimization Layer for 3D Human Pose and Shape Estimation via Gauss-Newton Differentiation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa5262e4d46f8565de1d6049d1f85e8e2033601a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25455": {
    "title": "Mind the Gap: Polishing Pseudo Labels for Accurate Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b3854e82d71e1a36e049763bb270f1f19d2ea3c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25456": {
    "title": "ConvMatch: Rethinking Network Design for Two-View Correspondence Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8d9662d2db763abb6d427d398e76288327457b1a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25457": {
    "title": "Cross-View Geo-Localization via Learning Disentangled Geometric Layout Correspondence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae6bbeb670a0211bc2426b9afd867f8afb72e751",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25458": {
    "title": "Video Compression Artifact Reduction by Fusing Motion Compensation and Global Context in a Swin-CNN Based Parallel Architecture",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63b3c5e3c6b15394743f9bb423ac2082b2443d24",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25459": {
    "title": "MRCN: A Novel Modality Restitution and Compensation Network for Visible-Infrared Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ddd0cff0f7f959c324f9bb157f045302c66690ca",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25460": {
    "title": "A Simple Baseline for Multi-Camera 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0226ed79f7b9efe06adfd0c093228a354bc5197",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25461": {
    "title": "Positional Label for Self-Supervised Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "9ea9e48950e311387c177b5195782c8c324ac119",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25462": {
    "title": "Cross-Category Highlight Detection via Feature Decomposition and Modality Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45de3c9f58933d5ba67dbc9d4cc0266dc11eddf2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25463": {
    "title": "TrEP: Transformer-Based Evidential Prediction for Pedestrian Intention with Uncertainty",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e9e8ed0ee97296c638329a30643c2456d95e944e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25464": {
    "title": "DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f13d4d12d924727114182da54980a04be051fc87",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25465": {
    "title": "ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ae2e3d5682e755d560c34b05169a9660660f055",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25466": {
    "title": "Combating Unknown Bias with Effective Bias-Conflicting Scoring and Gradient Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5dc689a4d6827b5a441c50cb56c14d19b027d9f7",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25467": {
    "title": "RLogist: Fast Observation Strategy on Whole-Slide Images with Deep Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63195e3d637c2725913fc2fd999e3e3ae40362e4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25468": {
    "title": "Learning to Super-resolve Dynamic Scenes for Neuromorphic Spike Camera",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98528cb319f7939749cafff8d1ff08823641c009",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25469": {
    "title": "TinyNeRF: Towards 100 x Compression of Voxel Radiance Fields",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8f13253a047f76c5e9ee275d27b70274dfe2758",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25470": {
    "title": "BEST: BERT Pre-training for Sign Language Recognition with Coupling Tokenization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "919efc30ab8c45456ab72fb4ebeb5e25f2ad7642",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25471": {
    "title": "MulGT: Multi-Task Graph-Transformer with Task-Aware Knowledge Injection and Domain Knowledge-Driven Pooling for Whole Slide Image Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10968bcb3e19eb3cbd137af1bf4b82ad1c04378c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25472": {
    "title": "Grouped Knowledge Distillation for Deep Face Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68ed8b94df543dba73a619980d1c5a3fcde417a5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25473": {
    "title": "Style-Content Metric Learning for Multidomain Remote Sensing Object Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2fbd355ed0cf0bb57a3bfea9b3f12cc1e180d701",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25474": {
    "title": "Occupancy Planes for Single-View RGB-D Human Reconstruction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dde7f2b5b925c7edb8ef9c5aabc1f679a6b6c104",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25475": {
    "title": "Deep Equilibrium Models for Snapshot Compressive Imaging",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68bcc213f88a5ee875f7061cdc192cb5b4ad9832",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25476": {
    "title": "Unsupervised Deep Video Denoising with Untrained Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8132f60124089fd50fe2afbd3e60e73b05ef65e1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25477": {
    "title": "Attack Can Benefit: An Adversarial Approach to Recognizing Facial Expressions under Noisy Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4266bba4e036807378abb05b2a9ebe7063c13a94",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25478": {
    "title": "Phrase-Level Temporal Relationship Mining for Temporal Sentence Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4f70d5bdd5293b7fc53831624971fef83873d3f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25479": {
    "title": "Learning Semantic Degradation-Aware Guidance for Recognition-Driven Unsupervised Low-Light Image Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "00d66e7384eb46a290595bf54d62c2a614f8734d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25480": {
    "title": "Memory-Aided Contrastive Consensus Learning for Co-salient Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ec9799fba2f8e71a48c7606d1c725f2e2a30095",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25481": {
    "title": "MaskBooster: End-to-End Self-Training for Sparsely Supervised Instance Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc3fab136f5ee45103bad37eebafa1581781560d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25482": {
    "title": "RSPT: Reconstruct Surroundings and Predict Trajectory for Generalizable Active Object Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "0a21061ddf9c41b71c8d7b409f7dd97b18a5cd8b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25483": {
    "title": "STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d20d1d3ec1199c35d13e60351b358ac1e317401",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25484": {
    "title": "Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "154f9eb2f97cae3a7752cbc4e0261eb4e75008d4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25485": {
    "title": "Aesthetically Relevant Image Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15d6ef576fb07bb5fc07fef6f63708e440396dd9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25486": {
    "title": "Polarization-Aware Low-Light Image Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1956f7770663fc45d9035278e39eb14fefcdd76a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25487": {
    "title": "Progressive Bayesian Inference for Scribble-Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a506fdeb24c051732d7c0aa74ae99db3cedbd0f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25488": {
    "title": "Exploratory Inference Learning for Scribble Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ff5db744e5eefb95e17afd59260efbb3a78756c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25489": {
    "title": "Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "965a0ff397ff33dbb9ee9a5b725472af4ffe0892",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25490": {
    "title": "Unsupervised Hierarchical Domain Adaptation for Adverse Weather Optical Flow",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cd9aae06d5720908760b47e46516adcb9a89f03f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25491": {
    "title": "PASS: Patch Automatic Skip Scheme for Efficient Real-Time Video Perception on Edge Devices",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ebb9f49e940bdd14925a9776998244ad8aa74b57",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25492": {
    "title": "Robust Feature Rectification of Pretrained Vision Models for Object Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1d4ddca6c68ed963763711f545844557d6085b8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25493": {
    "title": "Video Object of Interest Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "21c088c0620f6bf9d7699c9547af47318257df7a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25494": {
    "title": "Tree-Structured Trajectory Encoding for Vision-and-Language Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "293951f26d10fed6950b2949e0f90571e0d67cd6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25495": {
    "title": "Self-Supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "185e0240f15d84f805d36ed30f70ebd6e85be2b4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25496": {
    "title": "Debiased Fine-Tuning for Vision-Language Models by Prompt Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8b73abefd998229f35e810f465854bdea7512f8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25497": {
    "title": "Improving Scene Text Image Super-resolution via Dual Prior Modulation Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e45d243316096cfc709e96027ebb2d353475ede6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25498": {
    "title": "SRoUDA: Meta Self-Training for Robust Unsupervised Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a7ab69f162e706901c6aa1e391004971a463a3a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25499": {
    "title": "Gradient-Based Graph Attention for Scene Text Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "30db786f5810602af4680dc4372c265e4597666e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25500": {
    "title": "RGBD1K: A Large-Scale Dataset and Benchmark for RGB-D Object Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b52382b22d25dd63c2a68424304e39024bf6e15f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25501": {
    "title": "Learn More for Food Recognition via Progressive Self-Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a332ce333d52d85ff6bb74dec4a7c7b15bff0f66",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25502": {
    "title": "Generative Image Inpainting with Segmentation Confusion Adversarial Training and Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65f5f5d54bde99776de1840e7cd59d30bbf74390",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25503": {
    "title": "Improved Algorithms for Maximum Satisfiability and Its Special Cases",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8e39247da25bb69cd9ceae1c5c5d0d4c354dd47",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25504": {
    "title": "Lifting (D)QBF Preprocessing and Solving Techniques to (D)SSAT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ae0b1ba9c743ad04020efe39e1237a5cbc7b1f5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25505": {
    "title": "NuWLS: Improving Local Search for (Weighted) Partial MaxSAT by New Weighting Techniques",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68d54d627cfaa914d277a3f4a5508de1c4abe4ef",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25506": {
    "title": "Separate but Equal: Equality in Belief Propagation for Single Cycle Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "276906bc63d919a9d576b80786c42254be84a0c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25507": {
    "title": "Complexity of Reasoning with Cardinality Minimality Conditions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "225a18fc8ae50641c5da8171cd11d00a428d32c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25508": {
    "title": "DASH: A Distributed and Parallelizable Algorithm for Size-Constrained Submodular Maximization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e912edd7f1b82df95cc569ef73cf602bf7118ea8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25509": {
    "title": "SharpSSAT: A Witness-Generating Stochastic Boolean Satisfiability Solver",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d9e4474d023987ed4c5f409176fe870db873ca85",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25510": {
    "title": "Submodular Maximization under the Intersection of Matroid and Knapsack Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d8f527c2046fcf50d9418d4d694d86c4601ac7ff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25511": {
    "title": "A Framework to Design Approximation Algorithms for Finding Diverse Solutions in Combinatorial Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "807cfcbca58e27d087a913be5c2481e524aeb7f9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25512": {
    "title": "An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-Sourcing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc8beb173d4dad28357d848b2240d560b81f39f3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25513": {
    "title": "Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0c94f185099505025b5b2ee94aa567409cdaf19",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25514": {
    "title": "Solving Explainability Queries with Quantification: The Case of Feature Relevancy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "622657250ba771cb4af66f7e54868314b777bbd4",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25515": {
    "title": "Second-Order Quantified Boolean Logic",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "84c64c851b2bbaa8533258b16dee807a25f52cbe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25516": {
    "title": "Learning Markov Random Fields for Combinatorial Structures via Sampling through Lovász Local Lemma",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cd51ce7bb450a1e8bbf3727db6b809ca45b13518",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25517": {
    "title": "Fast Converging Anytime Model Counting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1fc7323bb9f59f444be47e1624e31320e417f6b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25518": {
    "title": "Finding Good Partial Assignments during Restart-Based Branch and Bound Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51870d8e06dff589258700debae3f69dc993772b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25519": {
    "title": "Hybrid Learning with New Value Function for the Maximum Common Induced Subgraph Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dd2f352795968d59bd82169a5c5c9547b054f9e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25520": {
    "title": "Self-Supervised Primal-Dual Learning for Constrained Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27171044552454edcbd1d6a20ac0714ee3c46686",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25521": {
    "title": "Reinforcement Learning for Branch-and-Bound Optimisation Using Retrospective Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3212c957a11a46d059e981826372914045f5cc4a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25522": {
    "title": "Constraint Optimization over Semirings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "39fdccb34c7eae74dac974354db59d0ca48fc8c0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25523": {
    "title": "Generalized Confidence Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7ed381fb10c3178120b182c5e4e70fb89791f466",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25524": {
    "title": "Circuit Minimization with QBF-Based Exact Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "25f369e3318ba4ee373a5dcf2c7234e37b4ba2c8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25525": {
    "title": "Probabilistic Generalization of Backdoor Trees with Application to SAT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b0738a5a45dee62b540b60b9bb33a82e41f8a12",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25526": {
    "title": "The Expressive Power of Ad-Hoc Constraints for Modelling CSPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7e5501bfb07b6f3535263caf90d59a21724e510",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25527": {
    "title": "Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcbda9002def84b4b4467e54e1d06a18ac227103",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25528": {
    "title": "Eliminating the Impossible, Whatever Remains Must Be True: On Extracting and Applying Background Knowledge in the Context of Formal Explanations",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25529": {
    "title": "Farsighted Probabilistic Sampling: A General Strategy for Boosting Local Search MaxSAT Solvers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "56c858b81ce04d884a711a70a0b40d5f9f166beb",
    "citation_count": 0
  }
}