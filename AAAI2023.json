{
  "https://ojs.aaai.org/index.php/AAAI/article/view/25070": {
    "title": "Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "118fd51b49e4f344873b8246bb051afb66c0c8d9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25071": {
    "title": "Reducing ANN-SNN Conversion Error through Residual Membrane Potential",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "366a99da9ddef081aacd362d3da6668dfff04b2d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25072": {
    "title": "Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "58f92031574529f13dfa8455c8bb539f43c722a0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25073": {
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "462b999f9e47915c89a0c70d797d3e82276f8410",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25074": {
    "title": "A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80df6f7525f24cce6d3d4c5f1a17566613a6f60d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25075": {
    "title": "A Machine with Short-Term, Episodic, and Semantic Memory Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d823694648cff737e14a613d5c743ac2b6cf39bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25076": {
    "title": "Persuasion Strategies in Advertisements",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1bd3def5257e992cecbcd5381771d77a95cc8200",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25077": {
    "title": "Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a78605f7d9372504eee3a0d9b86f0219a29d115",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25078": {
    "title": "AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4dbc668686f89830de4c67203db0709d9c4dda2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25079": {
    "title": "ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4e685992c8635225acabbe87d3900d104c9e78e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25080": {
    "title": "Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e09dc84599f5b9165eb38641ac7167b6fcfc450c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25081": {
    "title": "Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ced7e9eecfa29e4d5a4be0a2a649efd2ab119ed6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25082": {
    "title": "Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1126255b496a35ff2f04bfe33d6eedc765b649d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25083": {
    "title": "CMNet: Contrastive Magnification Network for Micro-Expression Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9ad4ac41b1ee5e150cb5adfc16b7c370d265d1c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25084": {
    "title": "Disentangling Reafferent Effects by Doing Nothing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6908360d349167eaec8c4007a56d84cea9397dc7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25085": {
    "title": "Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fbf899db663418a2fad1aa244e8d469d89138f0c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25086": {
    "title": "ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7fa2d8608e03c22ee025a27c7d6f81cc872735c6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25087": {
    "title": "Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6fbdc73ee62c32dc61cdddfb73410e1ec65cf35c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25088": {
    "title": "Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fc21e2c94cb2ed51809a9c96eccce810ef22520",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25089": {
    "title": "Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aed3b3d9809b0b3847d1853601eee97a9798257d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25090": {
    "title": "Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d7ce2e45a56c6cae56c4c9f0011f1ed739defc7",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25091": {
    "title": "Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef6fe11aa4b7dfec9f4d8da4e039f9c8d1839b0f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25092": {
    "title": "Layout Representation Learning with Spatial and Structural Hierarchies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f27d51387a1e00921c526cf0b44d8f41dc323e21",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25093": {
    "title": "Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ad6b3041cb994c57e26c4a8fe0203ffb1f0c8ea0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25094": {
    "title": "Multi-Level Compositional Reasoning for Interactive Instruction Following",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da804b058006e9b9ccda1776f437ceda9e869363",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25095": {
    "title": "Self-Supervised Image Local Forgery Detection by JPEG Compression Trace",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8d8f2834294897104e86f68a2f492058bfe5ccb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25096": {
    "title": "VASR: Visual Analogies of Situation Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b48eb1a32dcc4dcd122a5234c0fc055b71752e98",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25097": {
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b1f3354487bdc26a6eefef82960d085e9b78bb1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25098": {
    "title": "Explicit Invariant Feature Induced Cross-Domain Crowd Counting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7a2c9710df23afea3dfb8a7639fba8273c066cf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25099": {
    "title": "Painterly Image Harmonization in Dual Domains",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "04f9cc4d25baf7df5b14aa3e4bcdb91542f75d01",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25100": {
    "title": "MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cb09c77aab947c376df4fbcc4f2d877960f35d6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25101": {
    "title": "KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c407b4721a7aab2b198d73b373c53edfd5604d5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25102": {
    "title": "Deconstructed Generation-Based Zero-Shot Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50b3996ca86a55f9d3af68cb43c79659b1429daa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25103": {
    "title": "Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ef69136aa88675e3cf8aa33d87931d44a0615b2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25104": {
    "title": "Amodal Instance Segmentation via Prior-Guided Expansion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c9b776483a0de5d919842c05b48c029a78b7399",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25105": {
    "title": "SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d874861ec9f6b58166dcfcf05caf7a4a6bd032c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25106": {
    "title": "Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e7f81eb842623b41dd0bb09334506e148b076e66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25107": {
    "title": "Improving Dynamic HDR Imaging with Fusion Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1aea87fb6d103ecfc92b309b8c9ff9f10df47b7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25108": {
    "title": "Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b10dd9f4a5dfcc782c0a0892d43fea21cbb2eaea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25109": {
    "title": "Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dbb56d48ec9efeacf1d4dd31b76e23d5fb2c84b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25110": {
    "title": "Scalable Spatial Memory for Scene Rendering and Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "532cb7ca76a0e4f4993eae3e0cd31be73bd7e117",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25111": {
    "title": "Hybrid CNN-Transformer Feature Fusion for Single Image Deraining",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44c091514f3397740a1cbe72f86b53f2f409bc5b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25112": {
    "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d60265ea72d0344e991e71dfb13b4e1f15d4d4d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25113": {
    "title": "Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e9525ebe76a1d37533539ad2f560b1b453e66f6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25114": {
    "title": "DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "13d8ce3d2ac01cc5e108c1b89e79049428a53ad5",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25115": {
    "title": "Imperceptible Adversarial Attack via Invertible Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85af65c9355dc1ff8585354e014543751b498ee3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25116": {
    "title": "Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e0e103a2a1ed0241df544928d09d2a6b55c766e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25117": {
    "title": "User-Controllable Arbitrary Style Transfer via Entropy Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7dc98ae2967d6ad9c115ccaa705540b7489e0d40",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25118": {
    "title": "Neural Architecture Search for Wide Spectrum Adversarial Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3eb76059d9115f2f746b06dfcde7f8137147c59",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25119": {
    "title": "Adversarial Alignment for Source Free Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "693a942fa34028de582d18642d73d57c70842303",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25120": {
    "title": "Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "39dfc2eeb83e8694b1adc0b484775e9d47fee37a",
    "citation_count": 2
  }
}