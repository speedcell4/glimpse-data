{
  "https://ojs.aaai.org/index.php/AAAI/article/view/25070": {
    "title": "Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork",
    "volume": "main",
    "abstract": "State of the art methods for ad hoc teamwork, i.e., for collaboration without prior coordination, often use a long history of prior observations to model the behavior of other agents (or agent types) and to determine the ad hoc agent's behavior. In many practical domains, it is difficult to obtain large training datasets, and necessary to quickly revise the existing models to account for changes in team composition or domain attributes. Our architecture builds on the principles of step-wise refinement and ecological rationality to enable an ad hoc agent to perform non-monotonic logical reasoning with prior commonsense domain knowledge and models learned rapidly from limited examples to predict the behavior of other agents. In the simulated multiagent collaboration domain Fort Attack, we experimentally demonstrate that our architecture enables an ad hoc agent to adapt to changes in the behavior of other agents, and provides enhanced transparency and better performance than a state of the art data-driven baseline",
    "checked": true,
    "id": "118fd51b49e4f344873b8246bb051afb66c0c8d9",
    "semantic_title": "back to the future: toward a hybrid architecture for ad hoc teamwork",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25071": {
    "title": "Reducing ANN-SNN Conversion Error through Residual Membrane Potential",
    "volume": "main",
    "abstract": "Spiking Neural Networks (SNNs) have received extensive academic attention due to the unique properties of low power consumption and high-speed computing on neuromorphic chips. Among various training methods of SNNs, ANN-SNN conversion has shown the equivalent level of performance as ANNs on large-scale datasets. However, unevenness error, which refers to the deviation caused by different temporal sequences of spike arrival on activation layers, has not been effectively resolved and seriously suffers the performance of SNNs under the condition of short time-steps. In this paper, we make a detailed analysis of unevenness error and divide it into four categories. We point out that the case of the ANN output being zero while the SNN output being larger than zero accounts for the largest percentage. Based on this, we theoretically prove the sufficient and necessary conditions of this case and propose an optimization strategy based on residual membrane potential to reduce unevenness error. The experimental results show that the proposed method achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet datasets. For example, we reach top-1 accuracy of 64.32% on ImageNet with 10-steps. To the best of our knowledge, this is the first time ANN-SNN conversion can simultaneously achieve high accuracy and ultra-low-latency on the complex dataset. Code is available at https://github.com/hzc1208/ANN2SNN_SRP",
    "checked": true,
    "id": "366a99da9ddef081aacd362d3da6668dfff04b2d",
    "semantic_title": "reducing ann-snn conversion error through residual membrane potential",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25072": {
    "title": "Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning",
    "volume": "main",
    "abstract": "Raven's Progressive Matrices (RPMs) have been widely used to evaluate the visual reasoning ability of humans. To tackle the challenges of visual perception and logic reasoning on RPMs, we propose a Hierarchical ConViT with Attention-based Relational Reasoner (HCV-ARR). Traditional solution methods often apply relatively shallow convolution networks to visually perceive shape patterns in RPM images, which may not fully model the long-range dependencies of complex pattern combinations in RPMs. The proposed ConViT consists of a convolutional block to capture the low-level attributes of visual patterns, and a transformer block to capture the high-level image semantics such as pattern formations. Furthermore, the proposed hierarchical ConViT captures visual features from multiple receptive fields, where the shallow layers focus on the image fine details while the deeper layers focus on the image semantics. To better model the underlying reasoning rules embedded in RPM images, an Attention-based Relational Reasoner (ARR) is proposed to establish the underlying relations among images. The proposed ARR well exploits the hidden relations among question images through the developed element-wise attentive reasoner. Experimental results on three RPM datasets demonstrate that the proposed HCV-ARR achieves a significant performance gain compared with the state-of-the-art models. The source code is available at: https://github.com/wentaoheunnc/HCV-ARR",
    "checked": true,
    "id": "58f92031574529f13dfa8455c8bb539f43c722a0",
    "semantic_title": "hierarchical convit with attention-based relational reasoner for visual analogical reasoning",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25073": {
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse",
    "volume": "main",
    "abstract": "Deep artificial neural networks (ANNs) play a major role in modeling the visual pathways of primate and rodent. However, they highly simplify the computational properties of neurons compared to their biological counterparts. Instead, Spiking Neural Networks (SNNs) are more biologically plausible models since spiking neurons encode information with time sequences of spikes, just like biological neurons do. However, there is a lack of studies on visual pathways with deep SNNs models. In this study, we model the visual cortex with deep SNNs for the first time, and also with a wide range of state-of-the-art deep CNNs and ViTs for comparison. Using three similarity metrics, we conduct neural representation similarity experiments on three neural datasets collected from two species under three types of stimuli. Based on extensive similarity analyses, we further investigate the functional hierarchy and mechanisms across species. Almost all similarity scores of SNNs are higher than their counterparts of CNNs with an average of 6.6%. Depths of the layers with the highest similarity scores exhibit little differences across mouse cortical regions, but vary significantly across macaque regions, suggesting that the visual processing structure of mice is more regionally homogeneous than that of macaques. Besides, the multi-branch structures observed in some top mouse brain-like neural networks provide computational evidence of parallel processing streams in mice, and the different performance in fitting macaque neural representations under different stimuli exhibits the functional specialization of information processing in macaques. Taken together, our study demonstrates that SNNs could serve as promising candidates to better model and explain the functional hierarchy and mechanisms of the visual system",
    "checked": true,
    "id": "462b999f9e47915c89a0c70d797d3e82276f8410",
    "semantic_title": "deep spiking neural networks with high representation similarity model visual pathways of macaque and mouse",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25074": {
    "title": "A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks",
    "volume": "main",
    "abstract": "Psychometric functions typically characterize binary sensory decisions along a single stimulus dimension. However, real-life sensory tasks vary along a greater variety of dimensions (e.g. color, contrast and luminance for visual stimuli). Approaches to characterizing high-dimensional sensory spaces either require strong parametric assumptions about these additional contextual dimensions, or fail to leverage known properties of classical psychometric curves. We overcome both limitations by introducing a semi-parametric model of sensory discrimination that applies traditional psychophysical models along a stimulus intensity dimension, but puts Gaussian process (GP) priors on the parameters of these models with respect to the remaining dimensions. By combining the flexibility of the GP with the deep literature on parametric psychophysics, our semi-parametric models achieve good performance with much less data than baselines on both synthetic and real-world, high-dimensional psychophysics datasets. We additionally show strong performance in a Bayesian active learning setting, and present a novel active learning paradigm for the semi-parametric model",
    "checked": true,
    "id": "80df6f7525f24cce6d3d4c5f1a17566613a6f60d",
    "semantic_title": "a semi-parametric model for decision making in high-dimensional sensory discrimination tasks",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25075": {
    "title": "A Machine with Short-Term, Episodic, and Semantic Memory Systems",
    "volume": "main",
    "abstract": "Inspired by the cognitive science theory of the explicit human memory systems, we have modeled an agent with short-term, episodic, and semantic memory systems, each of which is modeled with a knowledge graph. To evaluate this system and analyze the behavior of this agent, we designed and released our own reinforcement learning agent environment, \"the Room\", where an agent has to learn how to encode, store, and retrieve memories to maximize its return by answering questions. We show that our deep Q-learning based agent successfully learns whether a short-term memory should be forgotten, or rather be stored in the episodic or semantic memory systems. Our experiments indicate that an agent with human-like memory systems can outperform an agent without this memory structure in the environment",
    "checked": true,
    "id": "d823694648cff737e14a613d5c743ac2b6cf39bf",
    "semantic_title": "a machine with short-term, episodic, and semantic memory systems",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25076": {
    "title": "Persuasion Strategies in Advertisements",
    "volume": "main",
    "abstract": "Modeling what makes an advertisement persuasive, i.e., eliciting the desired response from consumer, is critical to the study of propaganda, social psychology, and marketing. Despite its importance, computational modeling of persuasion in computer vision is still in its infancy, primarily due to the lack of benchmark datasets that can provide persuasion-strategy labels associated with ads. Motivated by persuasion literature in social psychology and marketing, we introduce an extensive vocabulary of persuasion strategies and build the first ad image corpus annotated with persuasion strategies. We then formulate the task of persuasion strategy prediction with multi-modal learning, where we design a multi-task attention fusion model that can leverage other ad-understanding tasks to predict persuasion strategies. The dataset also provides image segmentation masks, which labels persuasion strategies in the corresponding ad images on the test split. We publicly release our code and dataset at https://midas-research.github.io/persuasion-advertisements/",
    "checked": false,
    "id": "1bd3def5257e992cecbcd5381771d77a95cc8200",
    "semantic_title": "persuasion strategies in advertisements: dataset, modeling, and baselines",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25077": {
    "title": "Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild",
    "volume": "main",
    "abstract": "Compared with the image-based static facial expression recognition (SFER) task, the dynamic facial expression recognition (DFER) task based on video sequences is closer to the natural expression recognition scene. However, DFER is often more challenging. One of the main reasons is that video sequences often contain frames with different expression intensities, especially for the facial expressions in the real-world scenarios, while the images in SFER frequently present uniform and high expression intensities. Nevertheless, if the expressions with different intensities are treated equally, the features learned by the networks will have large intra-class and small inter-class differences, which are harmful to DFER. To tackle this problem, we propose the global convolution-attention block (GCA) to rescale the channels of the feature maps. In addition, we introduce the intensity-aware loss (IAL) in the training process to help the network distinguish the samples with relatively low expression intensities. Experiments on two in-the-wild dynamic facial expression datasets (i.e., DFEW and FERV39k) indicate that our method outperforms the state-of-the-art DFER approaches. The source code will be available at https://github.com/muse1998/IAL-for-Facial-Expression-Recognition",
    "checked": true,
    "id": "2a78605f7d9372504eee3a0d9b86f0219a29d115",
    "semantic_title": "intensity-aware loss for dynamic facial expression recognition in the wild",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25078": {
    "title": "AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work",
    "volume": "main",
    "abstract": "We introduce AVCAffe, the first Audio-Visual dataset consisting of Cognitive load and Affect attributes. We record AVCAffe by simulating remote work scenarios over a video-conferencing platform, where subjects collaborate to complete a number of cognitively engaging tasks. AVCAffe is the largest originally collected (not collected from the Internet) affective dataset in English language. We recruit 106 participants from 18 different countries of origin, spanning an age range of 18 to 57 years old, with a balanced male-female ratio. AVCAffe comprises a total of 108 hours of video, equivalent to more than 58,000 clips along with task-based self-reported ground truth labels for arousal, valence, and cognitive load attributes such as mental demand, temporal demand, effort, and a few others. We believe AVCAffe would be a challenging benchmark for the deep learning research community given the inherent difficulty of classifying affect and cognitive load in particular. Moreover, our dataset fills an existing timely gap by facilitating the creation of learning systems for better self-management of remote work meetings, and further study of hypotheses regarding the impact of remote work on cognitive load and affective states",
    "checked": true,
    "id": "e4dbc668686f89830de4c67203db0709d9c4dda2",
    "semantic_title": "avcaffe: a large scale audio-visual dataset of cognitive load and affect for remote work",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25079": {
    "title": "ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks",
    "volume": "main",
    "abstract": "Spiking neural networks (SNNs) have manifested remarkable advantages in power consumption and event-driven property during the inference process. To take full advantage of low power consumption and improve the efficiency of these models further, the pruning methods have been explored to find sparse SNNs without redundancy connections after training. However, parameter redundancy still hinders the efficiency of SNNs during training. In the human brain, the rewiring process of neural networks is highly dynamic, while synaptic connections maintain relatively sparse during brain development. Inspired by this, here we propose an efficient evolutionary structure learning (ESL) framework for SNNs, named ESL-SNNs, to implement the sparse SNN training from scratch. The pruning and regeneration of synaptic connections in SNNs evolve dynamically during learning, yet keep the structural sparsity at a certain level. As a result, the ESL-SNNs can search for optimal sparse connectivity by exploring all possible parameters across time. Our experiments show that the proposed ESL-SNNs framework is able to learn SNNs with sparse structures effectively while reducing the limited accuracy. The ESL-SNNs achieve merely 0.28% accuracy loss with 10% connection density on the DVS-Cifar10 dataset. Our work presents a brand-new approach for sparse training of SNNs from scratch with biologically plausible evolutionary mechanisms, closing the gap in the expressibility between sparse training and dense training. Hence, it has great potential for SNN lightweight training and inference with low power consumption and small memory usage",
    "checked": true,
    "id": "f4e685992c8635225acabbe87d3900d104c9e78e",
    "semantic_title": "esl-snns: an evolutionary structure learning strategy for spiking neural networks",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25080": {
    "title": "Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs",
    "volume": "main",
    "abstract": "Humans and animals engage in rich social interactions. It is often theorized that a relatively small number of basic social interactions give rise to the full range of behavior observed. But no computational theory explaining how social interactions combine together has been proposed before. We do so here. We take a model, the Social MDP, which is able to express a range of social interactions, and extend it to represent linear combinations of social interactions. Practically for robotics applications, such models are now able to not just express that an agent should help another agent, but to express goal-centric social interactions. Perhaps an agent is helping someone get dressed, but preventing them from falling, and is happy to exchange stories in the meantime. How an agent responds socially, should depend on what it thinks the other agent is doing at that point in time. To encode this notion, we take linear combinations of social interactions as defined in Social MDPs, and compute the weights on those combinations on the fly depending on the estimated goals of other agents. This new model, the Linear Social MDP, enables zero-shot reasoning about complex social interactions, provides a mathematical basis for the long-standing intuition that social interactions should compose, and leads to interesting new behaviors that we validate using human observers. Complex social interactions are part of the future of intelligent agents, and having principled mathematical models built on a foundation like MDPs will make it possible to bring social interactions to every robotic application",
    "checked": true,
    "id": "e09dc84599f5b9165eb38641ac7167b6fcfc450c",
    "semantic_title": "zero-shot linear combinations of grounded social interactions with linear social mdps",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25081": {
    "title": "Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition",
    "volume": "main",
    "abstract": "The spiking neural network (SNN) using leaky-integrated-and-fire (LIF) neurons has been commonly used in automatic speech recognition (ASR) tasks. However, the LIF neuron is still relatively simple compared to that in the biological brain. Further research on more types of neurons with different scales of neuronal dynamics is necessary. Here we introduce four types of neuronal dynamics to post-process the sequential patterns generated from the spiking transformer to get the complex dynamic neuron improved spiking transformer neural network (DyTr-SNN). We found that the DyTr-SNN could handle the non-toy automatic speech recognition task well, representing a lower phoneme error rate, lower computational cost, and higher robustness. These results indicate that the further cooperation of SNNs and neural dynamics at the neuron and network scales might have much in store for the future, especially on the ASR tasks",
    "checked": true,
    "id": "ced7e9eecfa29e4d5a4be0a2a649efd2ab119ed6",
    "semantic_title": "complex dynamic neurons improved spiking transformer network for efficient automatic speech recognition",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25082": {
    "title": "Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis",
    "volume": "main",
    "abstract": "Cognitive diagnosis is a fundamental yet critical research task in the field of intelligent education, which aims to discover the proficiency level of different students on specific knowledge concepts. Despite the effectiveness of existing efforts, previous methods always considered the mastery level on the whole students, so they still suffer from the Long Tail Effect. A large number of students who have sparse interaction records are usually wrongly diagnosed during inference. To relieve the situation, we proposed a Self-supervised Cognitive Diagnosis (SCD) framework which leverages the self-supervised manner to assist the graph-based cognitive diagnosis, then the performance on those students with sparse data can be improved. Specifically, we came up with a graph confusion method that drops edges under some special rules to generate different sparse views of the graph. By maximizing the cross-view consistency of node representations, our model could pay more attention on long-tailed students. Additionally, we proposed an importance-based view generation rule to improve the influence of long-tailed students. Extensive experiments on real-world datasets show the effectiveness of our approach, especially on the students with much sparser interaction records. Our code is available at https://github.com/zeng-zhen/SCD",
    "checked": true,
    "id": "e1126255b496a35ff2f04bfe33d6eedc765b649d",
    "semantic_title": "self-supervised graph learning for long-tailed cognitive diagnosis",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25083": {
    "title": "CMNet: Contrastive Magnification Network for Micro-Expression Recognition",
    "volume": "main",
    "abstract": "Micro-Expression Recognition (MER) is challenging because the Micro-Expressions' (ME) motion is too weak to distinguish. This hurdle can be tackled by enhancing intensity for a more accurate acquisition of movements. However, existing magnification strategies tend to use the features of facial images that include not only intensity clues as intensity features, leading to the intensity representation deficient of credibility. In addition, the intensity variation over time, which is crucial for encoding movements, is also neglected. To this end, we provide a reliable scheme to extract intensity clues while considering their variation on the time scale. First, we devise an Intensity Distillation (ID) loss to acquire the intensity clues by contrasting the difference between frames, given that the difference in the same video lies only in the intensity. Then, the intensity clues are calibrated to follow the trend of the original video. Specifically, due to the lack of truth intensity annotation of the original video, we build the intensity tendency by setting each intensity vacancy an uncertain value, which guides the extracted intensity clues to converge towards this trend rather some fixed values. A Wilcoxon rank sum test (Wrst) method is enforced to implement the calibration. Experimental results on three public ME databases i.e. CASME II, SAMM, and SMIC-HS validate the superiority against state-of-the-art methods",
    "checked": true,
    "id": "f9ad4ac41b1ee5e150cb5adfc16b7c370d265d1c",
    "semantic_title": "cmnet: contrastive magnification network for micro-expression recognition",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25084": {
    "title": "Disentangling Reafferent Effects by Doing Nothing",
    "volume": "main",
    "abstract": "An agent's ability to distinguish between sensory effects that are self-caused, and those that are not, is instrumental in the achievement of its goals. This ability is thought to be central to a variety of functions in biological organisms, from perceptual stabilisation and accurate motor control, to higher level cognitive functions such as planning, mirroring and the sense of agency. Although many of these functions are well studied in AI, this important distinction is rarely made explicit and the focus tends to be on the associational relationship between action and sensory effect or success. Toward the development of more general agents, we develop a framework that enables agents to disentangle self-caused and externally-caused sensory effects. Informed by relevant models and experiments in robotics, and in the biological and cognitive sciences, we demonstrate the general applicability of this framework through an extensive experimental evaluation over three different environments",
    "checked": true,
    "id": "6908360d349167eaec8c4007a56d84cea9397dc7",
    "semantic_title": "disentangling reafferent effects by doing nothing",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25085": {
    "title": "Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms",
    "volume": "main",
    "abstract": "Spike camera, a new type of neuromorphic visual sensor that imitates the sampling mechanism of the primate fovea, can capture photons and output 40000 Hz binary spike streams. Benefiting from the asynchronous sampling mechanism, the spike camera can record fast-moving objects and clear images can be recovered from the spike stream at any specified timestamps without motion blurring. Despite these, due to the dense time sequence information of the discrete spike stream, it is not easy to directly apply the existing algorithms of traditional cameras to the spike camera. Therefore, it is necessary and interesting to explore a universally effective representation of dense spike streams to better fit various network architectures. In this paper, we propose to mine temporal-robust features of spikes in time-frequency space with wavelet transforms. We present a novel Wavelet-Guided Spike Enhancing (WGSE) paradigm consisting of three consecutive steps: multi-level wavelet transform, CNN-based learnable module, and inverse wavelet transform. With the assistance of WGSE, the new streaming representation of spikes can be learned. We demonstrate the effectiveness of WGSE on two downstream tasks, achieving state-of-the-art performance on the image reconstruction task and getting considerable performance on semantic segmentation. Furthermore, We build a new spike-based synthesized dataset for semantic segmentation. Code and Datasets are available at https://github.com/Leozhangjiyuan/WGSE-SpikeCamera",
    "checked": true,
    "id": "fbf899db663418a2fad1aa244e8d469d89138f0c",
    "semantic_title": "learning temporal-ordered representation for spike streams based on discrete wavelet transforms",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25086": {
    "title": "ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges",
    "volume": "main",
    "abstract": "Patient-independent detection of epileptic activities based on visual spectral representation of continuous EEG (cEEG) has been widely used for diagnosing epilepsy. However, precise detection remains a considerable challenge due to subtle variabilities across subjects, channels and time points. Thus, capturing fine-grained, discriminative features of EEG patterns, which is associated with high-frequency textural information, is yet to be resolved. In this work, we propose Scattering Transformer (ScatterFormer), an invariant scattering transform-based hierarchical Transformer that specifically pays attention to subtle features. In particular, the disentangled frequency-aware attention (FAA) enables the Transformer to capture clinically informative high-frequency components, offering a novel clinical explainability based on visual encoding of multichannel EEG signals. Evaluations on two distinct tasks of epileptiform detection demonstrate the effectiveness our method. Our proposed model achieves median AUCROC and accuracy of 98.14%, 96.39% in patients with Rolandic epilepsy. On a neonatal seizure detection benchmark, it outperforms the state-of-the-art by 9% in terms of average AUCROC",
    "checked": true,
    "id": "7fa2d8608e03c22ee025a27c7d6f81cc872735c6",
    "semantic_title": "scatterformer: locally-invariant scattering transformer for patient-independent multispectral detection of epileptiform discharges",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25087": {
    "title": "Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses",
    "volume": "main",
    "abstract": "Deep networks should be robust to rare events if they are to be successfully deployed in high-stakes real-world applications. Here we study the capability of deep networks to recognize objects in unusual poses. We create a synthetic dataset of images of objects in unusual orientations, and evaluate the robustness of a collection of 38 recent and competitive deep networks for image classification. We show that classifying these images is still a challenge for all networks tested, with an average accuracy drop of 29.5% compared to when the objects are presented upright. This brittleness is largely unaffected by various design choices, such as training losses, architectures, dataset modalities, and data-augmentation schemes. However, networks trained on very large datasets substantially outperform others, with the best network tested—Noisy Student trained on JFT-300M—showing a relatively small accuracy drop of only 14.5% on unusual poses. Nevertheless, a visual inspection of the failures of Noisy Student reveals a remaining gap in robustness with humans. Furthermore, combining multiple object transformations—3D-rotations and scaling—further degrades the performance of all networks. Our results provide another measurement of the robustness of deep networks to consider when using them in the real world. Code and datasets are available at https://github.com/amro-kamal/ObjectPose",
    "checked": true,
    "id": "6fbdc73ee62c32dc61cdddfb73410e1ec65cf35c",
    "semantic_title": "progress and limitations of deep networks to recognize objects in unusual poses",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25088": {
    "title": "Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels",
    "volume": "main",
    "abstract": "Improperly constructed datasets can result in inaccurate inferences. For instance, models trained on biased datasets perform poorly in terms of generalization (i.e., dataset bias). Recent debiasing techniques have successfully achieved generalization performance by underestimating easy-to-learn samples (i.e., bias-aligned samples) and highlighting difficult-to-learn samples (i.e., bias-conflicting samples). However, these techniques may fail owing to noisy labels, because the trained model recognizes noisy labels as difficult-to-learn and thus highlights them. In this study, we find that earlier approaches that used the provided labels to quantify difficulty could be affected by the small proportion of noisy labels. Furthermore, we find that running denoising algorithms before debiasing is ineffective because denoising algorithms reduce the impact of difficult-to-learn samples, including valuable bias-conflicting samples. Therefore, we propose an approach called denoising after entropy-based debiasing, i.e., DENEB, which has three main stages. (1) The prejudice model is trained by emphasizing (bias-aligned, clean) samples, which are selected using a Gaussian Mixture Model. (2) Using the per-sample entropy from the output of the prejudice model, the sampling probability of each sample that is proportional to the entropy is computed. (3) The final model is trained using existing denoising algorithms with the mini-batches constructed by following the computed sampling probability. Compared to existing debiasing and denoising algorithms, our method achieves better debiasing performance on multiple benchmarks",
    "checked": true,
    "id": "9fc21e2c94cb2ed51809a9c96eccce810ef22520",
    "semantic_title": "denoising after entropy-based debiasing a robust training method for dataset bias with noisy labels",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25089": {
    "title": "Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers",
    "volume": "main",
    "abstract": "Saliency methods provide post-hoc model interpretation by attributing input features to the model outputs. Current methods mainly achieve this using a single input sample, thereby failing to answer input-independent inquiries about the model. We also show that input-specific saliency mapping is intrinsically susceptible to misleading feature attribution. Current attempts to use `general' input features for model interpretation assume access to a dataset containing those features, which biases the interpretation. Addressing the gap, we introduce a new perspective of input-agnostic saliency mapping that computationally estimates the high-level features attributed by the model to its outputs. These features are geometrically correlated, and are computed by accumulating model's gradient information with respect to an unrestricted data distribution. To compute these features, we nudge independent data points over the model loss surface towards the local minima associated by a human-understandable concept, e.g., class label for classifiers. With a systematic projection, scaling and refinement process, this information is transformed into an interpretable visualization without compromising its model-fidelity. The visualization serves as a stand-alone qualitative interpretation. With an extensive evaluation, we not only demonstrate successful visualizations for a variety of concepts for large-scale models, but also showcase an interesting utility of this new form of saliency mapping by identifying backdoor signatures in compromised classifiers",
    "checked": true,
    "id": "aed3b3d9809b0b3847d1853601eee97a9798257d",
    "semantic_title": "rethinking interpretation: input-agnostic saliency mapping of deep visual classifiers",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25090": {
    "title": "Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation",
    "volume": "main",
    "abstract": "Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g., CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a multi-level adaptive feature fusion module, called MonoFormer. The design intuition behind MonoFormer is to increase shape bias by employing Transformers while compensating for the weak locality bias of Transformers by adaptively fusing multi-level representations. Extensive experiments show that the proposed method achieves state-of-the-art performance with various public datasets. Our method also shows the best generalization ability among the competitive methods",
    "checked": true,
    "id": "4d7ce2e45a56c6cae56c4c9f0011f1ed739defc7",
    "semantic_title": "deep digging into the generalization of self-supervised monocular depth estimation",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25091": {
    "title": "Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network",
    "volume": "main",
    "abstract": "Contrastive loss has significantly improved performance in supervised classification tasks by using a multi-viewed framework that leverages augmentation and label information. The augmentation enables contrast with another view of a single image but enlarges training time and memory usage. To exploit the strength of multi-views while avoiding the high computation cost, we introduce a multi-exit architecture that outputs multiple features of a single image in a single-viewed framework. To this end, we propose Self-Contrastive (SelfCon) learning, which self-contrasts within multiple outputs from the different levels of a single network. The multi-exit architecture efficiently replaces multi-augmented images and leverages various information from different layers of a network. We demonstrate that SelfCon learning improves the classification performance of the encoder network, and empirically analyze its advantages in terms of the single-view and the sub-network. Furthermore, we provide theoretical evidence of the performance increase based on the mutual information bound. For ImageNet classification on ResNet-50, SelfCon improves accuracy by +0.6% with 59% memory and 48% time of Supervised Contrastive learning, and a simple ensemble of multi-exit outputs boosts performance up to +1.5%. Our code is available at https://github.com/raymin0223/self-contrastive-learning",
    "checked": true,
    "id": "ef6fe11aa4b7dfec9f4d8da4e039f9c8d1839b0f",
    "semantic_title": "self-contrastive learning: single-viewed supervised contrastive framework using sub-network",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25092": {
    "title": "Layout Representation Learning with Spatial and Structural Hierarchies",
    "volume": "main",
    "abstract": "We present a novel hierarchical modeling method for layout representation learning, the core of design documents (e.g., user interface, poster, template). Existing works on layout representation often ignore element hierarchies, which is an important facet of layouts, and mainly rely on the spatial bounding boxes for feature extraction. This paper proposes a Spatial-Structural Hierarchical Auto-Encoder (SSH-AE) that learns hierarchical representation by treating a hierarchically annotated layout as a tree format. On the one side, we model SSH-AE from both spatial (semantic views) and structural (organization and relationships) perspectives, which are two complementary aspects to represent a layout. On the other side, the semantic/geometric properties are associated at multiple resolutions/granularities, naturally handling complex layouts. Our learned representations are used for effective layout search from both spatial and structural similarity perspectives. We also newly involve the tree-edit distance (TED) as an evaluation metric to construct a comprehensive evaluation protocol for layout similarity assessment, which benefits a systematic and customized layout search. We further present a new dataset of POSTER layouts which we believe will be useful for future layout research. We show that our proposed SSH-AE outperforms the existing methods achieving state-of-the-art performance on two benchmark datasets. Code is available at github.com/yueb17/SSH-AE",
    "checked": true,
    "id": "f27d51387a1e00921c526cf0b44d8f41dc323e21",
    "semantic_title": "layout representation learning with spatial and structural hierarchies",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25093": {
    "title": "Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization",
    "volume": "main",
    "abstract": "This paper for the first time explores audio-visual event localization in an unsupervised manner. Previous methods tackle this problem in a supervised setting and require segment-level or video-level event category ground-truth to train the model. However, building large-scale multi-modality datasets with category annotations is human-intensive and thus not scalable to real-world applications. To this end, we propose cross-modal label contrastive learning to exploit multi-modal information among unlabeled audio and visual streams as self-supervision signals. At the feature representation level, multi-modal representations are collaboratively learned from audio and visual components by using self-supervised representation learning. At the label level, we propose a novel self-supervised pretext task i.e. label contrasting to self-annotate videos with pseudo-labels for localization model training. Note that irrelevant background would hinder the acquisition of high-quality pseudo-labels and thus lead to an inferior localization model. To address this issue, we then propose an expectation-maximization algorithm that optimizes the pseudo-label acquisition and localization model in a coarse-to-fine manner. Extensive experiments demonstrate that our unsupervised approach performs reasonably well compared to the state-of-the-art supervised methods",
    "checked": true,
    "id": "ad6b3041cb994c57e26c4a8fe0203ffb1f0c8ea0",
    "semantic_title": "cross-modal label contrastive learning for unsupervised audio-visual event localization",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25094": {
    "title": "Multi-Level Compositional Reasoning for Interactive Instruction Following",
    "volume": "main",
    "abstract": "Robotic agents performing domestic chores by natural language directives are required to master the complex job of navigating environment and interacting with objects in the environments. The tasks given to the agents are often composite thus are challenging as completing them require to reason about multiple subtasks, e.g., bring a cup of coffee. To address the challenge, we propose to divide and conquer it by breaking the task into multiple subgoals and attend to them individually for better navigation and interaction. We call it Multi-level Compositional Reasoning Agent (MCR-Agent). Specifically, we learn a three-level action policy. At the highest level, we infer a sequence of human-interpretable subgoals to be executed based on language instructions by a high-level policy composition controller. At the middle level, we discriminatively control the agent's navigation by a master policy by alternating between a navigation policy and various independent interaction policies. Finally, at the lowest level, we infer manipulation actions with the corresponding object masks using the appropriate interaction policy. Our approach not only generates human interpretable subgoals but also achieves 2.03% absolute gain to comparable state of the arts in the efficiency metric (PLWSR in unseen set) without using rule-based planning or a semantic spatial memory. The code is available at https://github.com/yonseivnl/mcr-agent",
    "checked": true,
    "id": "da804b058006e9b9ccda1776f437ceda9e869363",
    "semantic_title": "multi-level compositional reasoning for interactive instruction following",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25095": {
    "title": "Self-Supervised Image Local Forgery Detection by JPEG Compression Trace",
    "volume": "main",
    "abstract": "For image local forgery detection, the existing methods require a large amount of labeled data for training, and most of them cannot detect multiple types of forgery simultaneously. In this paper, we firstly analyzed the JPEG compression traces which are mainly caused by different JPEG compression chains, and designed a trace extractor to learn such traces. Then, we utilized the trace extractor as the backbone and trained self-supervised to strengthen the discrimination ability of learned traces. With its benefits, regions with different JPEG compression chains can easily be distinguished within a forged image. Furthermore, our method does not rely on a large amount of training data, and even does not require any forged images for training. Experiments show that the proposed method can detect image local forgery on different datasets without re-training, and keep stable performance over various types of image local forgery",
    "checked": true,
    "id": "b8d8f2834294897104e86f68a2f492058bfe5ccb",
    "semantic_title": "self-supervised image local forgery detection by jpeg compression trace",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25096": {
    "title": "VASR: Visual Analogies of Situation Recognition",
    "volume": "main",
    "abstract": "A core process in human cognition is analogical mapping: the ability to identify a similar relational structure between different situations. We introduce a novel task, Visual Analogies of Situation Recognition, adapting the classical word-analogy task into the visual domain. Given a triplet of images, the task is to select an image candidate B' that completes the analogy (A to A' is like B to what?). Unlike previous work on visual analogy that focused on simple image transformations, we tackle complex analogies requiring understanding of scenes. We leverage situation recognition annotations and the CLIP model to generate a large set of 500k candidate analogies. Crowdsourced annotations for a sample of the data indicate that humans agree with the dataset label ~80% of the time (chance level 25%). Furthermore, we use human annotations to create a gold-standard dataset of 3,820 validated analogies. Our experiments demonstrate that state-of-the-art models do well when distractors are chosen randomly (~86%), but struggle with carefully chosen distractors (~53%, compared to 90% human accuracy). We hope our dataset will encourage the development of new analogy-making models. Website: https://vasr-dataset.github.io/",
    "checked": true,
    "id": "b48eb1a32dcc4dcd122a5234c0fc055b71752e98",
    "semantic_title": "vasr: visual analogies of situation recognition",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25097": {
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "volume": "main",
    "abstract": "Designing a point cloud upsampler, which aims to generate a clean and dense point cloud given a sparse point representation, is a fundamental and challenging problem in computer vision. A line of attempts achieves this goal by establishing a point-to-point mapping function via deep neural networks. However, these approaches are prone to produce outlier points due to the lack of explicit surface-level constraints. To solve this problem, we introduce a novel surface regularizer into the upsampler network by forcing the neural network to learn the underlying parametric surface represented by bicubic functions and rotation functions, where the new generated points are then constrained on the underlying surface. These designs are integrated into two different networks for two tasks that take advantages of upsampling layers -- point cloud upsampling and point cloud completion for evaluation. The state-of-the-art experimental results on both tasks demonstrate the effectiveness of the proposed method. The implementation code will be available at https://github.com/corecai163/PSCU",
    "checked": true,
    "id": "3b1f3354487bdc26a6eefef82960d085e9b78bb1",
    "semantic_title": "parametric surface constrained upsampler network for point cloud",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25098": {
    "title": "Explicit Invariant Feature Induced Cross-Domain Crowd Counting",
    "volume": "main",
    "abstract": "Cross-domain crowd counting has shown progressively improved performance. However, most methods fail to explicitly consider the transferability of different features between source and target domains. In this paper, we propose an innovative explicit Invariant Feature induced Cross-domain Knowledge Transformation framework to address the inconsistent domain-invariant features of different domains. The main idea is to explicitly extract domain-invariant features from both source and target domains, which builds a bridge to transfer more rich knowledge between two domains. The framework consists of three parts, global feature decoupling (GFD), relation exploration and alignment (REA), and graph-guided knowledge enhancement (GKE). In the GFD module, domain-invariant features are efficiently decoupled from domain-specific ones in two domains, which allows the model to distinguish crowds features from backgrounds in the complex scenes. In the REA module both inter-domain relation graph (Inter-RG) and intra-domain relation graph (Intra-RG) are built. Specifically, Inter-RG aggregates multi-scale domain-invariant features between two domains and further aligns local-level invariant features. Intra-RG preserves taskrelated specific information to assist the domain alignment. Furthermore, GKE strategy models the confidence of pseudolabels to further enhance the adaptability of the target domain. Various experiments show our method achieves state-of-theart performance on the standard benchmarks. Code is available at https://github.com/caiyiqing/IF-CKT",
    "checked": true,
    "id": "c7a2c9710df23afea3dfb8a7639fba8273c066cf",
    "semantic_title": "explicit invariant feature induced cross-domain crowd counting",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25099": {
    "title": "Painterly Image Harmonization in Dual Domains",
    "volume": "main",
    "abstract": "Image harmonization aims to produce visually harmonious composite images by adjusting the foreground appearance to be compatible with the background. When the composite image has photographic foreground and painterly background, the task is called painterly image harmonization. There are only few works on this task, which are either time-consuming or weak in generating well-harmonized results. In this work, we propose a novel painterly harmonization network consisting of a dual-domain generator and a dual-domain discriminator, which harmonizes the composite image in both spatial domain and frequency domain. The dual-domain generator performs harmonization by using AdaIN modules in the spatial domain and our proposed ResFFT modules in the frequency domain. The dual-domain discriminator attempts to distinguish the inharmonious patches based on the spatial feature and frequency feature of each patch, which can enhance the ability of generator in an adversarial manner. Extensive experiments on the benchmark dataset show the effectiveness of our method. Our code and model are available at https://github.com/bcmi/PHDNet-Painterly-Image-Harmonization",
    "checked": true,
    "id": "04f9cc4d25baf7df5b14aa3e4bcdb91542f75d01",
    "semantic_title": "painterly image harmonization in dual domains",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25100": {
    "title": "MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation",
    "volume": "main",
    "abstract": "Automatic medical report generation is an essential task in applying artificial intelligence to the medical domain, which can lighten the workloads of doctors and promote clinical automation. The state-of-the-art approaches employ Transformer-based encoder-decoder architectures to generate reports for medical images. However, they do not fully explore the relationships between multi-modal medical data, and generate inaccurate and inconsistent reports. To address these issues, this paper proposes a Multi-modal Memory Transformer Network (MMTN) to cope with multi-modal medical data for generating image-report consistent medical reports. On the one hand, MMTN reduces the occurrence of image-report inconsistencies by designing a unique encoder to associate and memorize the relationship between medical images and medical terminologies. On the other hand, MMTN utilizes the cross-modal complementarity of the medical vision and language for the word prediction, which further enhances the accuracy of generating medical reports. Extensive experiments on three real datasets show that MMTN achieves significant effectiveness over state-of-the-art approaches on both automatic metrics and human evaluation",
    "checked": true,
    "id": "7cb09c77aab947c376df4fbcc4f2d877960f35d6",
    "semantic_title": "mmtn: multi-modal memory transformer network for image-report consistent medical report generation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25101": {
    "title": "KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion",
    "volume": "main",
    "abstract": "Unpaired 3D object completion aims to predict a complete 3D shape from an incomplete input without knowing the correspondence between the complete and incomplete shapes. In this paper, we propose the novel KTNet to solve this task from the new perspective of knowledge transfer. KTNet elaborates a teacher-assistant-student network to establish multiple knowledge transfer processes. Specifically, the teacher network takes complete shape as input and learns the knowledge of complete shape. The student network takes the incomplete one as input and restores the corresponding complete shape. And the assistant modules not only help to transfer the knowledge of complete shape from the teacher to the student, but also judge the learning effect of the student network. As a result, KTNet makes use of a more comprehensive understanding to establish the geometric correspondence between complete and incomplete shapes in a perspective of knowledge transfer, which enables more detailed geometric inference for generating high-quality complete shapes. We conduct comprehensive experiments on several datasets, and the results show that our method outperforms previous methods of unpaired point cloud completion by a large margin. Code is available at https://github.com/a4152684/KT-Net",
    "checked": true,
    "id": "2c407b4721a7aab2b198d73b373c53edfd5604d5",
    "semantic_title": "kt-net: knowledge transfer for unpaired 3d shape completion",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25102": {
    "title": "Deconstructed Generation-Based Zero-Shot Model",
    "volume": "main",
    "abstract": "Recent research on Generalized Zero-Shot Learning (GZSL) has focused primarily on generation-based methods. However, current literature has overlooked the fundamental principles of these methods and has made limited progress in a complex manner. In this paper, we aim to deconstruct the generator-classifier framework and provide guidance for its improvement and extension. We begin by breaking down the generator-learned unseen class distribution into class-level and instance-level distributions. Through our analysis of the role of these two types of distributions in solving the GZSL problem, we generalize the focus of the generation-based approach, emphasizing the importance of (i) attribute generalization in generator learning and (ii) independent classifier learning with partially biased data. We present a simple method based on this analysis that outperforms SotAs on four public GZSL datasets, demonstrating the validity of our deconstruction. Furthermore, our proposed method remains effective even without a generative model, representing a step towards simplifying the generator-classifier structure. Our code is available at https://github.com/cdb342/DGZ",
    "checked": true,
    "id": "50b3996ca86a55f9d3af68cb43c79659b1429daa",
    "semantic_title": "deconstructed generation-based zero-shot model",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25103": {
    "title": "Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild",
    "volume": "main",
    "abstract": "In this work, we tackle the challenging task of jointly tracking hand object poses and reconstructing their shapes from depth point cloud sequences in the wild, given the initial poses at frame 0. We for the first time propose a point cloud-based hand joint tracking network, HandTrackNet, to estimate the inter-frame hand joint motion. Our HandTrackNet proposes a novel hand pose canonicalization module to ease the tracking task, yielding accurate and robust hand joint tracking. Our pipeline then reconstructs the full hand via converting the predicted hand joints into a MANO hand. For object tracking, we devise a simple yet effective module that estimates the object SDF from the first frame and performs optimization-based tracking. Finally, a joint optimization step is adopted to perform joint hand and object reasoning, which alleviates the occlusion-induced ambiguity and further refines the hand pose. During training, the whole pipeline only sees purely synthetic data, which are synthesized with sufficient variations and by depth simulation for the ease of generalization. The whole pipeline is pertinent to the generalization gaps and thus directly transferable to real in-the-wild data. We evaluate our method on two real hand object interaction datasets, e.g. HO3D and DexYCB, without any fine-tuning. Our experiments demonstrate that the proposed method significantly outperforms the previous state-of-the-art depth-based hand and object pose estimation and tracking methods, running at a frame rate of 9 FPS. We have released our code on https://github.com/PKU-EPIC/HOTrack",
    "checked": true,
    "id": "5ef69136aa88675e3cf8aa33d87931d44a0615b2",
    "semantic_title": "tracking and reconstructing hand object interactions from point cloud sequences in the wild",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25104": {
    "title": "Amodal Instance Segmentation via Prior-Guided Expansion",
    "volume": "main",
    "abstract": "Amodal instance segmentation aims to infer the amodal mask, including both the visible part and occluded part of each object instance. Predicting the occluded parts is challenging. Existing methods often produce incomplete amodal boxes and amodal masks, probably due to lacking visual evidences to expand the boxes and masks. To this end, we propose a prior-guided expansion framework, which builds on a two-stage segmentation model (i.e., Mask R-CNN) and performs box-level (resp., pixel-level) expansion for amodal box (resp., mask) prediction, by retrieving regression (resp., flow) transformations from a memory bank of expansion prior. We conduct extensive experiments on KINS, D2SA, and COCOA cls datasets, which show the effectiveness of our method",
    "checked": true,
    "id": "0c9b776483a0de5d919842c05b48c029a78b7399",
    "semantic_title": "amodal instance segmentation via prior-guided expansion",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25105": {
    "title": "SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting",
    "volume": "main",
    "abstract": "Data-driven medium-range weather forecasting has attracted much attention in recent years. However, the forecasting accuracy at high resolution is unsatisfactory currently. Pursuing high-resolution and high-quality weather forecasting, we develop a data-driven model SwinRDM which integrates an improved version of SwinRNN with a diffusion model. SwinRDM performs predictions at 0.25-degree resolution and achieves superior forecasting accuracy to IFS (Integrated Forecast System), the state-of-the-art operational NWP model, on representative atmospheric variables including 500 hPa geopotential (Z500), 850 hPa temperature (T850), 2-m temperature (T2M), and total precipitation (TP), at lead times of up to 5 days. We propose to leverage a two-step strategy to achieve high-resolution predictions at 0.25-degree considering the trade-off between computation memory and forecasting accuracy. Recurrent predictions for future atmospheric fields are firstly performed at 1.40625-degree resolution, and then a diffusion-based super-resolution model is leveraged to recover the high spatial resolution and finer-scale atmospheric details. SwinRDM pushes forward the performance and potential of data-driven models for a large margin towards operational applications",
    "checked": true,
    "id": "9d874861ec9f6b58166dcfcf05caf7a4a6bd032c",
    "semantic_title": "swinrdm: integrate swinrnn with diffusion model towards high-resolution and high-quality weather forecasting",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25106": {
    "title": "Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction",
    "volume": "main",
    "abstract": "Most existing light field (LF) disparity estimation algorithms focus on handling occlusion, texture-less or other areas that harm LF structure to improve accuracy, while ignoring other potential modeling ideas. In this paper, we propose a novel idea called Bad Pixel (BadPix) correction for method modeling, then implement a general post-refinement network for LF disparity estimation: Bad-pixel Correction Network (BpCNet). Given an initial disparity map generated by a specific algorithm, we assume that all BadPixs on it are in a small range. Then BpCNet is modeled as a fine-grained search strategy, and a more accurate result can be obtained by evaluating the consistency of LF images in this limited range. Due to the assumption and the consistency between input and output, BpCNet can perform as a general post-refinement network, and can work on almost all existing algorithms iteratively. We demonstrate the feasibility of our theory through extensive experiments, and achieve remarkable performance on the HCI 4D Light Field Benchmark",
    "checked": true,
    "id": "e7f81eb842623b41dd0bb09334506e148b076e66",
    "semantic_title": "take your model further: a general post-refinement network for light field disparity estimation via badpix correction",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25107": {
    "title": "Improving Dynamic HDR Imaging with Fusion Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1aea87fb6d103ecfc92b309b8c9ff9f10df47b7d",
    "semantic_title": "improving dynamic hdr imaging with fusion transformer",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25108": {
    "title": "Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera",
    "volume": "main",
    "abstract": "Spiking camera, a novel retina-inspired vision sensor, has shown its great potential for capturing high-speed dynamic scenes with a sampling rate of 40,000 Hz. The spiking camera abandons the concept of exposure window, with each of its photosensitive units continuously capturing photons and firing spikes asynchronously. However, the special sampling mechanism prevents the frame-based algorithm from being used to spiking camera. It remains to be a challenge to reconstruct dynamic scenes and perform common computer vision tasks for spiking camera. In this paper, we propose a self-supervised joint learning framework for optical flow estimation and reconstruction of spiking camera. The framework reconstructs clean frame-based spiking representations in a self-supervised manner, and then uses them to train the optical flow networks. We also propose an optical flow based inverse rendering process to achieve self-supervision by minimizing the difference with respect to the original spiking temporal aggregation image. The experimental results demonstrate that our method bridges the gap between synthetic and real-world scenes and achieves desired results in real-world scenarios. To the best of our knowledge, this is the first attempt to jointly reconstruct dynamic scenes and estimate optical flow for spiking camera from a self-supervised learning perspective",
    "checked": true,
    "id": "b10dd9f4a5dfcc782c0a0892d43fea21cbb2eaea",
    "semantic_title": "self-supervised joint dynamic scene reconstruction and optical flow estimation for spiking camera",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25109": {
    "title": "Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views",
    "volume": "main",
    "abstract": "Neural Radiance Fields (NeRF) can implicitly represent 3D-consistent RGB images and geometric by optimizing an underlying continuous volumetric scene function using a sparse set of input views, which has greatly benefited view synthesis tasks. However, NeRF fails to estimate correct geometry when given fewer views, resulting in failure to synthesize novel views. Existing works rely on introducing depth images or adding depth estimation networks to resolve the problem of poor synthetic view in NeRF with fewer views. However, due to the lack of spatial consistency of the single-depth image and the poor performance of depth estimation with fewer views, the existing methods still have challenges in addressing this problem. So this paper proposes Bidirectional Optical Flow NeRF(BOF-NeRF), which addresses this problem by mining optical flow information between 2D images. Our key insight is that utilizing 2D optical flow images to design a loss can effectively guide NeRF to learn the correct geometry and synthesize the right novel view. We also propose a view-enhanced fusion method based on geometry and color consistency to solve the problem of novel view details loss in NeRF. We conduct extensive experiments on the NeRF-LLFF and DTU MVS benchmarks for novel view synthesis tasks with fewer images in different complex real scenes. We further demonstrate the robustness of BOF-NeRF under different baseline distances on the Middlebury dataset. In all cases, BOF-NeRF outperforms current state-of-the-art baselines for novel view synthesis and scene geometry estimation",
    "checked": true,
    "id": "dbb56d48ec9efeacf1d4dd31b76e23d5fb2c84b3",
    "semantic_title": "bidirectional optical flow nerf: high accuracy and high quality under fewer views",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25110": {
    "title": "Scalable Spatial Memory for Scene Rendering and Navigation",
    "volume": "main",
    "abstract": "Neural scene representation and rendering methods have shown promise in learning the implicit form of scene structure without supervision. However, the implicit representation learned in most existing methods is non-expandable and cannot be inferred online for novel scenes, which makes the learned representation difficult to be applied across different reinforcement learning (RL) tasks. In this work, we introduce Scene Memory Network (SMN) to achieve online spatial memory construction and expansion for view rendering in novel scenes. SMN models the camera projection and back-projection as spatially aware memory control processes, where the memory values store the information of the partial 3D area, and the memory keys indicate the position of that area. The memory controller can learn the geometry property from observations without the camera's intrinsic parameters and depth supervision. We further apply the memory constructed by SMN to exploration and navigation tasks. The experimental results reveal the generalization ability of our proposed SMN in large-scale scene synthesis and its potential to improve the performance of spatial RL tasks",
    "checked": true,
    "id": "532cb7ca76a0e4f4993eae3e0cd31be73bd7e117",
    "semantic_title": "scalable spatial memory for scene rendering and navigation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25111": {
    "title": "Hybrid CNN-Transformer Feature Fusion for Single Image Deraining",
    "volume": "main",
    "abstract": "Since rain streaks exhibit diverse geometric appearances and irregular overlapped phenomena, these complex characteristics challenge the design of an effective single image deraining model. To this end, rich local-global information representations are increasingly indispensable for better satisfying rain removal. In this paper, we propose a lightweight Hybrid CNN-Transformer Feature Fusion Network (dubbed as HCT-FFN) in a stage-by-stage progressive manner, which can harmonize these two architectures to help image restoration by leveraging their individual learning strengths. Specifically, we stack a sequence of the degradation-aware mixture of experts (DaMoE) modules in the CNN-based stage, where appropriate local experts adaptively enable the model to emphasize spatially-varying rain distribution features. As for the Transformer-based stage, a background-aware vision Transformer (BaViT) module is employed to complement spatially-long feature dependencies of images, so as to achieve global texture recovery while preserving the required structure. Considering the indeterminate knowledge discrepancy among CNN features and Transformer features, we introduce an interactive fusion branch at adjacent stages to further facilitate the reconstruction of high-quality deraining results. Extensive evaluations show the effectiveness and extensibility of our developed HCT-FFN. The source code is available at https://github.com/cschenxiang/HCT-FFN",
    "checked": true,
    "id": "44c091514f3397740a1cbe72f86b53f2f409bc5b",
    "semantic_title": "hybrid cnn-transformer feature fusion for single image deraining",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25112": {
    "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "Weakly supervised detection of anomalies in surveillance videos is a challenging task. Going beyond existing works that have deficient capabilities to localize anomalies in long videos, we propose a novel glance and focus network to effectively integrate spatial-temporal information for accurate anomaly detection. In addition, we empirically found that existing approaches that use feature magnitudes to represent the degree of anomalies typically ignore the effects of scene variations, and hence result in sub-optimal performance due to the inconsistency of feature magnitudes across scenes. To address this issue, we propose the Feature Amplification Mechanism and a Magnitude Contrastive Loss to enhance the discriminativeness of feature magnitudes for detecting anomalies. Experimental results on two large-scale benchmarks UCF-Crime and XD-Violence manifest that our method outperforms state-of-the-art approaches",
    "checked": true,
    "id": "9d60265ea72d0344e991e71dfb13b4e1f15d4d4d",
    "semantic_title": "mgfn: magnitude-contrastive glance-and-focus network for weakly-supervised video anomaly detection",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25113": {
    "title": "Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval",
    "volume": "main",
    "abstract": "Vision-language alignment learning for video-text retrieval arouses a lot of attention in recent years. Most of the existing methods either transfer the knowledge of image-text pretraining model to video-text retrieval task without fully exploring the multi-modal information of videos, or simply fuse multi-modal features in a brute force manner without explicit guidance. In this paper, we integrate multi-modal information in an explicit manner by tagging, and use the tags as the anchors for better video-text alignment. Various pretrained experts are utilized for extracting the information of multiple modalities, including object, person, motion, audio, etc. To take full advantage of these information, we propose the TABLE (TAgging Before aLignmEnt) network, which consists of a visual encoder, a tag encoder, a text encoder, and a tag-guiding cross-modal encoder for jointly encoding multi-frame visual features and multi-modal tags information. Furthermore, to strengthen the interaction between video and text, we build a joint cross-modal encoder with the triplet input of [vision, tag, text] and perform two additional supervised tasks, Video Text Matching (VTM) and Masked Language Modeling (MLM). Extensive experimental results demonstrate that the TABLE model is capable of achieving State-Of-The-Art (SOTA) performance on various video-text retrieval benchmarks, including MSR-VTT, MSVD, LSMDC and DiDeMo",
    "checked": true,
    "id": "2e9525ebe76a1d37533539ad2f560b1b453e66f6",
    "semantic_title": "tagging before alignment: integrating multi-modal tags for video-text retrieval",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25114": {
    "title": "DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning",
    "volume": "main",
    "abstract": "Zero-shot learning (ZSL) aims to predict unseen classes whose samples have never appeared during training. One of the most effective and widely used semantic information for zero-shot image classification are attributes which are annotations for class-level visual characteristics. However, the current methods often fail to discriminate those subtle visual distinctions between images due to not only the shortage of fine-grained annotations, but also the attribute imbalance and co-occurrence. In this paper, we present a transformer-based end-to-end ZSL method named DUET, which integrates latent semantic knowledge from the pre-trained language models (PLMs) via a self-supervised multi-modal learning paradigm. Specifically, we (1) developed a cross-modal semantic grounding network to investigate the model's capability of disentangling semantic attributes from the images; (2) applied an attribute-level contrastive learning strategy to further enhance the model's discrimination on fine-grained visual characteristics against the attribute co-occurrence and imbalance; (3) proposed a multi-task learning policy for considering multi-model objectives. We find that our DUET can achieve state-of-the-art performance on three standard ZSL benchmarks and a knowledge graph equipped ZSL benchmark. Its components are effective and its predictions are interpretable",
    "checked": true,
    "id": "13d8ce3d2ac01cc5e108c1b89e79049428a53ad5",
    "semantic_title": "duet: cross-modal semantic grounding for contrastive zero-shot learning",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25115": {
    "title": "Imperceptible Adversarial Attack via Invertible Neural Networks",
    "volume": "main",
    "abstract": "Adding perturbations via utilizing auxiliary gradient information or discarding existing details of the benign images are two common approaches for generating adversarial examples. Though visual imperceptibility is the desired property of adversarial examples, conventional adversarial attacks still generate traceable adversarial perturbations. In this paper, we introduce a novel Adversarial Attack via Invertible Neural Networks (AdvINN) method to produce robust and imperceptible adversarial examples. Specifically, AdvINN fully takes advantage of the information preservation property of Invertible Neural Networks and thereby generates adversarial examples by simultaneously adding class-specific semantic information of the target class and dropping discriminant information of the original class. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that the proposed AdvINN method can produce less imperceptible adversarial images than the state-of-the-art methods and AdvINN yields more robust adversarial examples with high confidence compared to other adversarial attacks. Code is available at https://github.com/jjhuangcs/AdvINN",
    "checked": true,
    "id": "85af65c9355dc1ff8585354e014543751b498ee3",
    "semantic_title": "imperceptible adversarial attack via invertible neural networks",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25116": {
    "title": "Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding",
    "volume": "main",
    "abstract": "Visible-infrared person re-identification (VI-ReID) aims to retrieve the person images of the same identity from the RGB to infrared image space, which is very important for real-world surveillance system. In practice, VI-ReID is more challenging due to the heterogeneous modality discrepancy, which further aggravates the challenges of traditional single-modality person ReID problem, i.e., inter-class confusion and intra-class variations. In this paper, we propose an aggregated memory-based cross-modality deep metric learning framework, which benefits from the increasing number of learned modality-aware and modality-agnostic centroid proxies for cluster contrast and mutual information learning. Furthermore, to suppress the modality discrepancy, the proposed cross-modality alignment objective simultaneously utilizes both historical and up-to-date learned cluster proxies for enhanced cross-modality association. Such training mechanism helps to obtain hard positive references through increased diversity of learned cluster proxies, and finally achieves stronger ``pulling close'' effect between cross-modality image features. Extensive experiment results demonstrate the effectiveness of the proposed method, surpassing state-of-the-art works significantly by a large margin on the commonly used VI-ReID datasets",
    "checked": true,
    "id": "0e0e103a2a1ed0241df544928d09d2a6b55c766e",
    "semantic_title": "cross-modality person re-identification with memory-based contrastive embedding",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25117": {
    "title": "User-Controllable Arbitrary Style Transfer via Entropy Regularization",
    "volume": "main",
    "abstract": "Ensuring the overall end-user experience is a challenging task in arbitrary style transfer (AST) due to the subjective nature of style transfer quality. A good practice is to provide users many instead of one AST result. However, existing approaches require to run multiple AST models or inference a diversified AST (DAST) solution multiple times, and thus they are either slow in speed or limited in diversity. In this paper, we propose a novel solution ensuring both efficiency and diversity for generating multiple user-controllable AST results by systematically modulating AST behavior at run-time. We begin with reformulating three prominent AST methods into a unified assign-and-mix problem and discover that the entropies of their assignment matrices exhibit a large variance. We then solve the unified problem in an optimal transport framework using the Sinkhorn-Knopp algorithm with a user input ε to control the said entropy and thus modulate stylization. Empirical results demonstrate the superiority of the proposed solution, with speed and stylization quality comparable to or better than existing AST and significantly more diverse than previous DAST works. Code is available at https://github.com/cplusx/eps-Assign-and-Mix",
    "checked": true,
    "id": "7dc98ae2967d6ad9c115ccaa705540b7489e0d40",
    "semantic_title": "user-controllable arbitrary style transfer via entropy regularization",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25118": {
    "title": "Neural Architecture Search for Wide Spectrum Adversarial Robustness",
    "volume": "main",
    "abstract": "One major limitation of CNNs is that they are vulnerable to adversarial attacks. Currently, adversarial robustness in neural networks is commonly optimized with respect to a small pre-selected adversarial noise strength, causing them to have potentially limited performance when under attack by larger adversarial noises in real-world scenarios. In this research, we aim to find Neural Architectures that have improved robustness on a wide range of adversarial noise strengths through Neural Architecture Search. In detail, we propose a lightweight Adversarial Noise Estimator to reduce the high cost of generating adversarial noise with respect to different strengths. Besides, we construct an Efficient Wide Spectrum Searcher to reduce the cost of adjusting network architecture with the large adversarial validation set during the search. With the two components proposed, the number of adversarial noise strengths searched can be increased significantly while having a limited increase in search time. Extensive experiments on benchmark datasets such as CIFAR and ImageNet demonstrate that with a significantly richer search signal in robustness, our method can find architectures with improved overall robustness while having a limited impact on natural accuracy and around 40% reduction in search time compared with the naive approach of searching. Codes available at: https://github.com/zhicheng2T0/Wsr-NAS.git",
    "checked": true,
    "id": "d3eb76059d9115f2f746b06dfcde7f8137147c59",
    "semantic_title": "neural architecture search for wide spectrum adversarial robustness",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25119": {
    "title": "Adversarial Alignment for Source Free Object Detection",
    "volume": "main",
    "abstract": "Source-free object detection (SFOD) aims to transfer a detector pre-trained on a label-rich source domain to an unlabeled target domain without seeing source data. While most existing SFOD methods generate pseudo labels via a source-pretrained model to guide training, these pseudo labels usually contain high noises due to heavy domain discrepancy. In order to obtain better pseudo supervisions, we divide the target domain into source-similar and source-dissimilar parts and align them in the feature space by adversarial learning.Specifically, we design a detection variance-based criterion to divide the target domain. This criterion is motivated by a finding that larger detection variances denote higher recall and larger similarity to the source domain. Then we incorporate an adversarial module into a mean teacher framework to drive the feature spaces of these two subsets indistinguishable. Extensive experiments on multiple cross-domain object detection datasets demonstrate that our proposed method consistently outperforms the compared SFOD methods. Our implementation is available at https://github.com/ChuQiaosong",
    "checked": true,
    "id": "693a942fa34028de582d18642d73d57c70842303",
    "semantic_title": "adversarial alignment for source free object detection",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25120": {
    "title": "Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR",
    "volume": "main",
    "abstract": "Depth estimation is usually ill-posed and ambiguous for monocular camera-based 3D multi-person pose estimation. Since LiDAR can capture accurate depth information in long-range scenes, it can benefit both the global localization of individuals and the 3D pose estimation by providing rich geometry features. Motivated by this, we propose a monocular camera and single LiDAR-based method for 3D multi-person pose estimation in large-scale scenes, which is easy to deploy and insensitive to light. Specifically, we design an effective fusion strategy to take advantage of multi-modal input data, including images and point cloud, and make full use of temporal information to guide the network to learn natural and coherent human motions. Without relying on any 3D pose annotations, our method exploits the inherent geometry constraints of point cloud for self-supervision and utilizes 2D keypoints on images for weak supervision. Extensive experiments on public datasets and our newly collected dataset demonstrate the superiority and generalization capability of our proposed method. Project homepage is at \\url{https://github.com/4DVLab/FusionPose.git}",
    "checked": true,
    "id": "39dfc2eeb83e8694b1adc0b484775e9d47fee37a",
    "semantic_title": "weakly supervised 3d multi-person pose estimation for large-scale scenes based on monocular camera and single lidar",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25121": {
    "title": "OctFormer: Efficient Octree-Based Transformer for Point Cloud Compression with Local Enhancement",
    "volume": "main",
    "abstract": "Point cloud compression with a higher compression ratio and tiny loss is essential for efficient data transportation. However, previous methods that depend on 3D convolution or frequent multi-head self-attention operations bring huge computations. To address this problem, we propose an octree-based Transformer compression method called OctFormer, which does not rely on the occupancy information of sibling nodes. Our method uses non-overlapped context windows to construct octree node sequences and share the result of a multi-head self-attention operation among a sequence of nodes. Besides, we introduce a locally-enhance module for exploiting the sibling features and a positional encoding generator for enhancing the translation invariance of the octree node sequence. Compared to the previous state-of-the-art works, our method obtains up to 17% Bpp savings compared to the voxel-context-based baseline and saves an overall 99% coding time compared to the attention-based baseline",
    "checked": true,
    "id": "a7acd42a6df03f98b6760c2f22b2bd2ce90695a0",
    "semantic_title": "octformer: efficient octree-based transformer for point cloud compression with local enhancement",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25122": {
    "title": "Dual-Domain Attention for Image Deblurring",
    "volume": "main",
    "abstract": "As a long-standing and challenging task, image deblurring aims to reconstruct the latent sharp image from its degraded counterpart. In this study, to bridge the gaps between degraded/sharp image pairs in the spatial and frequency domains simultaneously, we develop the dual-domain attention mechanism for image deblurring. Self-attention is widely used in vision tasks, however, due to the quadratic complexity, it is not applicable to image deblurring with high-resolution images. To alleviate this issue, we propose a novel spatial attention module by implementing self-attention in the style of dynamic group convolution for integrating information from the local region, enhancing the representation learning capability and reducing computational burden. Regarding frequency domain learning, many frequency-based deblurring approaches either treat the spectrum as a whole or decompose frequency components in a complicated manner. In this work, we devise a frequency attention module to compactly decouple the spectrum into distinct frequency parts and accentuate the informative part with extremely lightweight learnable parameters. Finally, we incorporate attention modules into a U-shaped network. Extensive comparisons with prior arts on the common benchmarks show that our model, named Dual-domain Attention Network (DDANet), obtains comparable results with a significantly improved inference speed",
    "checked": true,
    "id": "2ea2350d2bbafc07267d45aac410985376a6a332",
    "semantic_title": "dual-domain attention for image deblurring",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25123": {
    "title": "Multi-Resolution Monocular Depth Map Fusion by Self-Supervised Gradient-Based Composition",
    "volume": "main",
    "abstract": "Monocular depth estimation is a challenging problem on which deep neural networks have demonstrated great potential. However, depth maps predicted by existing deep models usually lack fine-grained details due to convolution operations and down-samplings in networks. We find that increasing input resolution is helpful to preserve more local details while the estimation at low resolution is more accurate globally. Therefore, we propose a novel depth map fusion module to combine the advantages of estimations with multi-resolution inputs. Instead of merging the low- and high-resolution estimations equally, we adopt the core idea of Poisson fusion, trying to implant the gradient domain of high-resolution depth into the low-resolution depth. While classic Poisson fusion requires a fusion mask as supervision, we propose a self-supervised framework based on guided image filtering. We demonstrate that this gradient-based composition performs much better at noisy immunity, compared with the state-of-the-art depth map fusion method. Our lightweight depth fusion is one-shot and runs in real-time, making it 80X faster than a state-of-the-art depth fusion method. Quantitative evaluations demonstrate that the proposed method can be integrated into many fully convolutional monocular depth estimation backbones with a significant performance boost, leading to state-of-the-art results of detail enhancement on depth maps. Codes are released at https://github.com/yuinsky/gradient-based-depth-map-fusion",
    "checked": true,
    "id": "1527361af4eff8d52914a9e83f43471209c7de07",
    "semantic_title": "multi-resolution monocular depth map fusion by self-supervised gradient-based composition",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25124": {
    "title": "Improving Crowded Object Detection via Copy-Paste",
    "volume": "main",
    "abstract": "Crowdedness caused by overlapping among similar objects is a ubiquitous challenge in the field of 2D visual object detection. In this paper, we first underline two main effects of the crowdedness issue: 1) IoU-confidence correlation disturbances (ICD) and 2) confused de-duplication (CDD). Then we explore a pathway of cracking these nuts from the perspective of data augmentation. Primarily, a particular copy- paste scheme is proposed towards making crowded scenes. Based on this operation, we first design a \"consensus learning\" method to further resist the ICD problem and then find out the pasting process naturally reveals a pseudo \"depth\" of object in the scene, which can be potentially used for alleviating CDD dilemma. Both methods are derived from magical using of the copy-pasting without extra cost for hand-labeling. Experiments show that our approach can easily improve the state-of-the-art detector in typical crowded detection task by more than 2% without any bells and whistles. Moreover, this work can outperform existing data augmentation strategies in crowded scenario",
    "checked": true,
    "id": "ea6e1e2254a95a7f5413f9fcfa4b1c0d63de46a0",
    "semantic_title": "improving crowded object detection via copy-paste",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25125": {
    "title": "Defending Backdoor Attacks on Vision Transformer via Patch Processing",
    "volume": "main",
    "abstract": "Vision Transformers (ViTs) have a radically different architecture with significantly less inductive bias than Convolutional Neural Networks. Along with the improvement in performance, security and robustness of ViTs are also of great importance to study. In contrast to many recent works that exploit the robustness of ViTs against adversarial examples, this paper investigates a representative causative attack, i.e., backdoor. We first examine the vulnerability of ViTs against various backdoor attacks and find that ViTs are also quite vulnerable to existing attacks. However, we observe that the clean-data accuracy and backdoor attack success rate of ViTs respond distinctively to patch transformations before the positional encoding. Then, based on this finding, we propose an effective method for ViTs to defend both patch-based and blending-based trigger backdoor attacks via patch processing. The performances are evaluated on several benchmark datasets, including CIFAR10, GTSRB, and TinyImageNet, which show the proposedds defense is very successful in mitigating backdoor attacks for ViTs. To the best of our knowledge, this paper presents the first defensive strategy that utilizes a unique characteristic of ViTs against backdoor attacks",
    "checked": true,
    "id": "95cb1fe9ad477b0ee3dff5659887f3ea0347e5e9",
    "semantic_title": "defending backdoor attacks on vision transformer via patch processing",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25126": {
    "title": "Head-Free Lightweight Semantic Segmentation with Linear Transformer",
    "volume": "main",
    "abstract": "Existing semantic segmentation works have been mainly focused on designing effective decoders; however, the computational load introduced by the overall structure has long been ignored, which hinders their applications on resource-constrained hardwares. In this paper, we propose a head-free lightweight architecture specifically for semantic segmentation, named Adaptive Frequency Transformer (AFFormer). AFFormer adopts a parallel architecture to leverage prototype representations as specific learnable local descriptions which replaces the decoder and preserves the rich image semantics on high-resolution features. Although removing the decoder compresses most of the computation, the accuracy of the parallel structure is still limited by low computational resources. Therefore, we employ heterogeneous operators (CNN and vision Transformer) for pixel embedding and prototype representations to further save computational costs. Moreover, it is very difficult to linearize the complexity of the vision Transformer from the perspective of spatial domain. Due to the fact that semantic segmentation is very sensitive to frequency information, we construct a lightweight prototype learning block with adaptive frequency filter of complexity O(n) to replace standard self attention with O(n^2). Extensive experiments on widely adopted datasets demonstrate that AFFormer achieves superior accuracy while retaining only 3M parameters. On the ADE20K dataset, AFFormer achieves 41.8 mIoU and 4.6 GFLOPs, which is 4.4 mIoU higher than Segformer, with 45% less GFLOPs. On the Cityscapes dataset, AFFormer achieves 78.7 mIoU and 34.4 GFLOPs, which is 2.5 mIoU higher than Segformer with 72.5% less GFLOPs. Code is available at https://github.com/dongbo811/AFFormer",
    "checked": true,
    "id": "5fbc38ed3aa2de8eb22bc263e1c4d5091b7ce05a",
    "semantic_title": "head-free lightweight semantic segmentation with linear transformer",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25127": {
    "title": "Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning",
    "volume": "main",
    "abstract": "This paper targets unsupervised skeleton-based action representation learning and proposes a new Hierarchical Contrast (HiCo) framework. Different from the existing contrastive-based solutions that typically represent an input skeleton sequence into instance-level features and perform contrast holistically, our proposed HiCo represents the input into multiple-level features and performs contrast in a hierarchical manner. Specifically, given a human skeleton sequence, we represent it into multiple feature vectors of different granularities from both temporal and spatial domains via sequence-to-sequence (S2S) encoders and unified downsampling modules. Besides, the hierarchical contrast is conducted in terms of four levels: instance level, domain level, clip level, and part level. Moreover, HiCo is orthogonal to the S2S encoder, which allows us to flexibly embrace state-of-the-art S2S encoders. Extensive experiments on four datasets, i.e., NTU-60, NTU-120, PKU-I and PKU-II, show that HiCo achieves a new state-of-the-art for unsupervised skeleton-based action representation learning in two downstream tasks including action recognition and retrieval, and its learned action representation is of good transferability. Besides, we also show that our framework is effective for semi-supervised skeleton-based action recognition. Our code is available at https://github.com/HuiGuanLab/HiCo",
    "checked": true,
    "id": "52740e6b55a27ed79397adc59928ca90e739a53a",
    "semantic_title": "hierarchical contrast for unsupervised skeleton-based action representation learning",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25128": {
    "title": "Exploring Tuning Characteristics of Ventral Stream's Neurons for Few-Shot Image Classification",
    "volume": "main",
    "abstract": "Human has the remarkable ability of learning novel objects by browsing extremely few examples, which may be attributed to the generic and robust feature extracted in the ventral stream of our brain for representing visual objects. In this sense, the tuning characteristics of ventral stream's neurons can be useful prior knowledge to improve few-shot classification. Specifically, we computationally model two groups of neurons found in ventral stream which are respectively sensitive to shape cues and color cues. Then we propose the hierarchical feature regularization method with these neuron models to regularize the backbone of a few-shot model, thus making it produce more generic and robust features for few-shot classification. In addition, to simulate the tuning characteristic that neuron firing at a higher rate in response to foreground stimulus elements compared to background elements, which we call belongingness, we design a foreground segmentation algorithm based on the observation that the foreground object usually does not appear at the edge of the picture, then multiply the foreground mask with the backbone of few-shot model. Our method is model-agnostic and can be applied to few-shot models with different backbones, training paradigms and classifiers",
    "checked": true,
    "id": "f04d225453e19cda73c0de049a59a8acd7768bec",
    "semantic_title": "exploring tuning characteristics of ventral stream's neurons for few-shot image classification",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25129": {
    "title": "Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning",
    "volume": "main",
    "abstract": "Incremental few-shot object detection aims at detecting novel classes without forgetting knowledge of the base classes with only a few labeled training data from the novel classes. Most related prior works are on incremental object detection that rely on the availability of abundant training samples per novel class that substantially limits the scalability to real-world setting where novel data can be scarce. In this paper, we propose the Incremental-DETR that does incremental few-shot object detection via fine-tuning and self-supervised learning on the DETR object detector. To alleviate severe over-fitting with few novel class data, we first fine-tune the class-specific components of DETR with self-supervision from additional object proposals generated using Selective Search as pseudo labels. We further introduce an incremental few-shot fine-tuning strategy with knowledge distillation on the class-specific components of DETR to encourage the network in detecting novel classes without forgetting the base classes. Extensive experiments conducted on standard incremental object detection and incremental few-shot object detection settings show that our approach significantly outperforms state-of-the-art methods by a large margin. Our source code is available at https://github.com/dongnana777/Incremental-DETR",
    "checked": true,
    "id": "df11b7fd7c6f627ac8717e91e956e4611746afe3",
    "semantic_title": "incremental-detr: incremental few-shot object detection via self-supervised learning",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25130": {
    "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers",
    "volume": "main",
    "abstract": "This paper explores a better prediction target for BERT pre-training of vision transformers. We observe that current prediction targets disagree with human perception judgment. This contradiction motivates us to learn a perceptual prediction target. We argue that perceptually similar images should stay close to each other in the prediction target space. We surprisingly find one simple yet effective idea: enforcing perceptual similarity during the dVAE training. Moreover, we adopt a self-supervised transformer model for deep feature extraction and show that it works well for calculating perceptual similarity. We demonstrate that such learned visual tokens indeed exhibit better semantic meanings, and help pre-training achieve superior transfer performance in various downstream tasks. For example, we achieve 84.5% Top-1 accuracy on ImageNet-1K with ViT-B backbone, outperforming the competitive method BEiT by +1.3% under the same pre-training epochs. Our approach also gets significant improvement on object detection and segmentation on COCO and semantic segmentation on ADE20K. Equipped with a larger backbone ViT-H, we achieve the state-of-the-art ImageNet accuracy (88.3%) among methods using only ImageNet-1K data",
    "checked": true,
    "id": "3e38f4b4055abecbac2e618df2ecb33554073e08",
    "semantic_title": "peco: perceptual codebook for bert pre-training of vision transformers",
    "citation_count": 145
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25131": {
    "title": "Domain-General Crowd Counting in Unseen Scenarios",
    "volume": "main",
    "abstract": "Domain shift across crowd data severely hinders crowd counting models to generalize to unseen scenarios. Although domain adaptive crowd counting approaches close this gap to a certain extent, they are still dependent on the target domain data to adapt (e.g. finetune) their models to the specific domain. In this paper, we instead target to train a model based on a single source domain which can generalize well on any unseen domain. This falls into the realm of domain generalization that remains unexplored in crowd counting. We first introduce a dynamic sub-domain division scheme which divides the source domain into multiple sub-domains such that we can initiate a meta-learning framework for domain generalization. The sub-domain division is dynamically refined during the meta-learning. Next, in order to disentangle domain-invariant information from domain-specific information in image features, we design the domain-invariant and -specific crowd memory modules to re-encode image features. Two types of losses, i.e. feature reconstruction and orthogonal losses, are devised to enable this disentanglement. Extensive experiments on several standard crowd counting benchmarks i.e. SHA, SHB, QNRF, and NWPU, show the strong generalizability of our method. Our code is available at: https://github.com/ZPDu/Domain-general-Crowd-Counting-in-Unseen-Scenarios",
    "checked": true,
    "id": "f8232b83e87aef507a21b7afccecdbe511e46999",
    "semantic_title": "domain-general crowd counting in unseen scenarios",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25132": {
    "title": "Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation",
    "volume": "main",
    "abstract": "The performances of defect inspection have been severely hindered by insufficient defect images in industries, which can be alleviated by generating more samples as data augmentation. We propose the first defect image generation method in the challenging few-shot cases. Given just a handful of defect images and relatively more defect-free ones, our goal is to augment the dataset with new defect images. Our method consists of two training stages. First, we train a data-efficient StyleGAN2 on defect-free images as the backbone. Second, we attach defect-aware residual blocks to the backbone, which learn to produce reasonable defect masks and accordingly manipulate the features within the masked regions by training the added modules on limited defect images. Extensive experiments on MVTec AD dataset not only validate the effectiveness of our method in generating realistic and diverse defect images, but also manifest the benefits it brings to downstream defect inspection tasks. Codes are available at https://github.com/Ldhlwh/DFMGAN",
    "checked": true,
    "id": "bf39a82f65d9047e676f2f85f700c73d427b4189",
    "semantic_title": "few-shot defect image generation via defect-aware feature manipulation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25133": {
    "title": "Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis",
    "volume": "main",
    "abstract": "Diffusion models (DMs) have shown great potential for high-quality image synthesis. However, when it comes to producing images with complex scenes, how to properly describe both image global structures and object details remains a challenging task. In this paper, we present Frido, a Feature Pyramid Diffusion model performing a multi-scale coarse-to-fine denoising process for image synthesis. Our model decomposes an input image into scale-dependent vector quantized features, followed by a coarse-to-fine gating for producing image output. During the above multi-scale representation learning stage, additional input conditions like text, scene graph, or image layout can be further exploited. Thus, Frido can be also applied for conditional or cross-modality image synthesis. We conduct extensive experiments over various unconditioned and conditional image generation tasks, ranging from text-to-image synthesis, layout-to-image, scene-graph-to-image, to label-to-image. More specifically, we achieved state-of-the-art FID scores on five benchmarks, namely layout-to-image on COCO and OpenImages, scene-graph-to-image on COCO and Visual Genome, and label-to-image on COCO",
    "checked": true,
    "id": "a888dd6d8dd0087fc7d74da8a005922d0923ad2b",
    "semantic_title": "frido: feature pyramid diffusion for complex scene image synthesis",
    "citation_count": 31
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25134": {
    "title": "Target-Free Text-Guided Image Manipulation",
    "volume": "main",
    "abstract": "We tackle the problem of target-free text-guided image manipulation, which requires one to modify the input reference image based on the given text instruction, while no ground truth target image is observed during training. To address this challenging task, we propose a Cyclic-Manipulation GAN (cManiGAN) in this paper, which is able to realize where and how to edit the image regions of interest. Specifically, the image editor in cManiGAN learns to identify and complete the input image, while cross-modal interpreter and reasoner are deployed to verify the semantic correctness of the output image based on the input instruction. While the former utilizes factual/counterfactual description learning for authenticating the image semantics, the latter predicts the \"undo\" instruction and provides pixel-level supervision for the training of cManiGAN. With the above operational cycle-consistency, our cManiGAN can be trained in the above weakly supervised setting. We conduct extensive experiments on the datasets of CLEVR and COCO datasets, and the effectiveness and generalizability of our proposed method can be successfully verified. Project page: sites.google.com/view/wancyuanfan/projects/cmanigan",
    "checked": true,
    "id": "4a426c8209b38ed63b224363f4dcf179692d51ac",
    "semantic_title": "target-free text-guided image manipulation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25135": {
    "title": "One Is All: Bridging the Gap between Neural Radiance Fields Architectures with Progressive Volume Distillation",
    "volume": "main",
    "abstract": "Neural Radiance Fields (NeRF) methods have proved effective as compact, high-quality and versatile representations for 3D scenes, and enable downstream tasks such as editing, retrieval, navigation, etc. Various neural architectures are vying for the core structure of NeRF, including the plain Multi-Layer Perceptron (MLP), sparse tensors, low-rank tensors, hashtables and their compositions. Each of these representations has its particular set of trade-offs. For example, the hashtable-based representations admit faster training and rendering but their lack of clear geometric meaning hampers downstream tasks like spatial-relation-aware editing. In this paper, we propose Progressive Volume Distillation (PVD), a systematic distillation method that allows any-to-any conversions between different architectures, including MLP, sparse or low-rank tensors, hashtables and their compositions. PVD consequently empowers downstream applications to optimally adapt the neural representations for the task at hand in a post hoc fashion. The conversions are fast, as distillation is progressively performed on different levels of volume representations, from shallower to deeper. We also employ special treatment of density to deal with its specific numerical instability problem. Empirical evidence is presented to validate our method on the NeRF-Synthetic, LLFF and TanksAndTemples datasets. For example, with PVD, an MLP-based NeRF model can be distilled from a hashtable-based Instant-NGP model at a 10~20X faster speed than being trained the original NeRF from scratch, while achieving a superior level of synthesis quality. Code is available at https://github.com/megvii-research/AAAI2023-PVD",
    "checked": true,
    "id": "5e6f661b7ce2c457af3b9a4cee77101d93c2013c",
    "semantic_title": "one is all: bridging the gap between neural radiance fields architectures with progressive volume distillation",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25136": {
    "title": "Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint",
    "volume": "main",
    "abstract": "Tissue segmentation is a critical task in computational pathology due to its desirable ability to indicate the prognosis of cancer patients. Currently, numerous studies attempt to use image-level labels to achieve pixel-level segmentation to reduce the need for fine annotations. However, most of these methods are based on class activation map, which suffers from inaccurate segmentation boundaries. To address this problem, we propose a novel weakly-supervised tissue segmentation framework named PistoSeg, which is implemented under a fully-supervised manner by transferring tissue category labels to pixel-level masks. Firstly, a dataset synthesis method is proposed based on Mosaic transformation to generate synthesized images with pixel-level masks. Next, considering the difference between synthesized and real images, this paper devises an attention-based feature consistency, which directs the training process of a proposed pseudo-mask refining module. Finally, the refined pseudo-masks are used to train a precise segmentation model for testing. Experiments based on WSSS4LUAD and BCSS-WSSS validate that PistoSeg outperforms the state-of-the-art methods. The code is released at https://github.com/Vison307/PistoSeg",
    "checked": true,
    "id": "f27d61ba154ada6b375a4dc313b673be7dbfdd84",
    "semantic_title": "weakly-supervised semantic segmentation for histopathology images based on dataset synthesis and feature consistency constraint",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25137": {
    "title": "Uncertainty-Aware Image Captioning",
    "volume": "main",
    "abstract": "It is well believed that the higher uncertainty in a word of the caption, the more inter-correlated context information is required to determine it. However, current image captioning methods usually consider the generation of all words in a sentence sequentially and equally. In this paper, we propose an uncertainty-aware image captioning framework, which parallelly and iteratively operates insertion of discontinuous candidate words between existing words from easy to difficult until converged. We hypothesize that high-uncertainty words in a sentence need more prior information to make a correct decision and should be produced at a later stage. The resulting non-autoregressive hierarchy makes the caption generation explainable and intuitive. Specifically, we utilize an image-conditioned bag-of-word model to measure the word uncertainty and apply a dynamic programming algorithm to construct the training pairs. During inference, we devise an uncertainty-adaptive parallel beam search technique that yields an empirically logarithmic time complexity. Extensive experiments on the MS COCO benchmark reveal that our approach outperforms the strong baseline and related methods on both captioning quality as well as decoding speed",
    "checked": true,
    "id": "d13f52cbff1416d11986f996fa68ee9767844c60",
    "semantic_title": "uncertainty-aware image captioning",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25138": {
    "title": "Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment",
    "volume": "main",
    "abstract": "Generalizing a deep learning model to new domains is crucial for computer-aided medical diagnosis systems. Most existing unsupervised domain adaptation methods have made significant progress in reducing the domain distribution gap through adversarial training. However, these methods may still produce overconfident but erroneous results on unseen target images. This paper proposes a new unsupervised domain adaptation framework for cross-modality medical image segmentation. Specifically, We first introduce two data augmentation approaches to generate two sets of semantics-preserving augmented images. Based on the model's predictive consistency on these two sets of augmented images, we identify reliable and unreliable pixels. We then perform a selective entropy constraint: we minimize the entropy of reliable pixels to increase their confidence while maximizing the entropy of unreliable pixels to reduce their confidence. Based on the identified reliable and unreliable pixels, we further propose an adaptive semantic alignment module which performs class-level distribution adaptation by minimizing the distance between same class prototypes between domains, where unreliable pixels are removed to derive more accurate prototypes. We have conducted extensive experiments on the cross-modality cardiac structure segmentation task. The experimental results show that the proposed method significantly outperforms the state-of-the-art comparison algorithms. Our code and data are available at https://github.com/fengweie/SE_ASA",
    "checked": true,
    "id": "b027cb327be4a5051f00f0b84d936e8b2d3b653c",
    "semantic_title": "unsupervised domain adaptation for medical image segmentation by selective entropy constraints and adaptive semantic alignment",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25139": {
    "title": "SEFormer: Structure Embedding Transformer for 3D Object Detection",
    "volume": "main",
    "abstract": "Effectively preserving and encoding structure features from objects in irregular and sparse LiDAR points is a crucial challenge to 3D object detection on the point cloud. Recently, Transformer has demonstrated promising performance on many 2D and even 3D vision tasks. Compared with the fixed and rigid convolution kernels, the self-attention mechanism in Transformer can adaptively exclude the unrelated or noisy points and is thus suitable for preserving the local spatial structure in the irregular LiDAR point cloud. However, Transformer only performs a simple sum on the point features, based on the self-attention mechanism, and all the points share the same transformation for value. A such isotropic operation cannot capture the direction-distance-oriented local structure, which is essential for 3D object detection. In this work, we propose a Structure-Embedding transFormer (SEFormer), which can not only preserve the local structure as a traditional Transformer but also have the ability to encode the local structure. Compared to the self-attention mechanism in traditional Transformer, SEFormer learns different feature transformations for value points based on the relative directions and distances to the query point. Then we propose a SEFormer-based network for high-performance 3D object detection. Extensive experiments show that the proposed architecture can achieve SOTA results on the Waymo Open Dataset, one of the most significant 3D detection benchmarks for autonomous driving. Specifically, SEFormer achieves 79.02% mAP, which is 1.2% higher than existing works. https://github.com/tdzdog/SEFormer",
    "checked": true,
    "id": "08e31f99bd0738c34100b24ffa0b059cdeebfc26",
    "semantic_title": "seformer: structure embedding transformer for 3d object detection",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25140": {
    "title": "Exploit Domain-Robust Optical Flow in Domain Adaptive Video Semantic Segmentation",
    "volume": "main",
    "abstract": "Domain adaptive semantic segmentation aims to exploit the pixel-level annotated samples on source domain to assist the segmentation of unlabeled samples on target domain. For such a task, the key is to construct reliable supervision signals on target domain. However, existing methods can only provide unreliable supervision signals constructed by segmentation model (SegNet) that are generally domain-sensitive. In this work, we try to find a domain-robust clue to construct more reliable supervision signals. Particularly, we experimentally observe the domain-robustness of optical flow in video tasks as it mainly represents the motion characteristics of scenes. However, optical flow cannot be directly used as supervision signals of semantic segmentation since both of them essentially represent different information. To tackle this issue, we first propose a novel Segmentation-to-Flow Module (SFM) that converts semantic segmentation maps to optical flows, named the segmentation-based flow (SF), and then propose a Segmentation-based Flow Consistency (SFC) method to impose consistency between SF and optical flow, which can implicitly supervise the training of segmentation model. The extensive experiments on two challenging benchmarks demonstrate the effectiveness of our method, and it outperforms previous state-of-the-art methods with considerable performance improvement. Our code is available at https://github.com/EdenHazardan/SFC",
    "checked": true,
    "id": "e4c180bdfe46f3d59791c7e970ccef667ab8481d",
    "semantic_title": "exploit domain-robust optical flow in domain adaptive video semantic segmentation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25141": {
    "title": "Scene-Level Sketch-Based Image Retrieval with Minimal Pairwise Supervision",
    "volume": "main",
    "abstract": "The sketch-based image retrieval (SBIR) task has long been researched at the instance level, where both query sketches and candidate images are assumed to contain only one dominant object. This strong assumption constrains its application, especially with the increasingly popular intelligent terminals and human-computer interaction technology. In this work, a more general scene-level SBIR task is explored, where sketches and images can both contain multiple object instances. The new general task is extremely challenging due to several factors: (i) scene-level SBIR inherently shares sketch-specific difficulties with instance-level SBIR (e.g., sparsity, abstractness, and diversity), (ii) the cross-modal similarity is measured between two partially aligned domains (i.e., not all objects in images are drawn in scene sketches), and (iii) besides instance-level visual similarity, a more complex multi-dimensional scene-level feature matching problem is imposed (including appearance, semantics, layout, etc.). Addressing these challenges, a novel Conditional Graph Autoencoder model is proposed to deal with scene-level sketch-images retrieval. More importantly, the model can be trained with only pairwise supervision, which distinguishes our study from others in that elaborate instance-level annotations (for example, bounding boxes) are no longer required. Extensive experiments confirm the ability of our model to robustly retrieve multiple related objects at the scene level and exhibit superior performance beyond strong competitors",
    "checked": true,
    "id": "85b696039df8e3a934f69c5e5d72a904d4856fa2",
    "semantic_title": "scene-level sketch-based image retrieval with minimal pairwise supervision",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25142": {
    "title": "Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism",
    "volume": "main",
    "abstract": "Human trajectory Prediction (HTP) in complex social environments plays a crucial and fundamental role in artificial intelligence systems. Conventional methods make use of both history behaviors and social interactions to forecast future trajectories. However, we demonstrate that the social environment is a confounder that misleads the model to learn spurious correlations between history and future trajectories. To end this, we first formulate the social environment, history and future trajectory variables into a structural causal model to analyze the causalities among them. Based on causal intervention rather than conventional likelihood, we propose a Social Environment ADjustment (SEAD) method, to remove the confounding effect of the social environment. The core of our method is implemented by a Social Cross Attention (SCA) module, which is universal, simple and effective. Our method has consistent improvements on ETH-UCY datasets with three baseline models and achieves competitive performances with existing methods",
    "checked": true,
    "id": "610924a1aa60494f01158fdb9cb680d0e6203148",
    "semantic_title": "causal intervention for human trajectory prediction with cross attention mechanism",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25143": {
    "title": "Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations",
    "volume": "main",
    "abstract": "Point annotations are considerably more time-efficient than bounding box annotations. However, how to use cheap point annotations to boost the performance of semi-supervised object detection is still an open question. In this work, we present Point-Teaching, a weakly- and semi-supervised object detection framework to fully utilize the point annotations. Specifically, we propose a Hungarian-based point-matching method to generate pseudo labels for point-annotated images. We further propose multiple instance learning (MIL) approaches at the level of images and points to supervise the object detector with point annotations. Finally, we propose a simple data augmentation, named Point-Guided Copy-Paste, to reduce the impact of those unmatched points. Experiments demonstrate the effectiveness of our method on a few datasets and various data regimes. In particular, Point-Teaching outperforms the previous best method Group R-CNN by 3.1 AP with 5% fully labeled data and 2.3 AP with 30% fully labeled data on the MS COCO dataset. We believe that our proposed framework can largely lower the bar of learning accurate object detectors and pave the way for its broader applications. The code is available at https://github.com/YongtaoGe/Point-Teaching",
    "checked": true,
    "id": "6acab3f2379de04d4a3449ed653add6db32a4af2",
    "semantic_title": "point-teaching: weakly semi-supervised object detection with point annotations",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25144": {
    "title": "Progressive Multi-View Human Mesh Recovery with Self-Supervision",
    "volume": "main",
    "abstract": "To date, little attention has been given to multi-view 3D human mesh estimation, despite real-life applicability (e.g., motion capture, sport analysis) and robustness to single-view ambiguities. Existing solutions typically suffer from poor generalization performance to new settings, largely due to the limited diversity of image/3D-mesh pairs in multi-view training data. To address this shortcoming, people have explored the use of synthetic images. But besides the usual impact of visual gap between rendered and target data, synthetic-data-driven multi-view estimators also suffer from overfitting to the camera viewpoint distribution sampled during training which usually differs from real-world distributions. Tackling both challenges, we propose a novel simulation-based training pipeline for multi-view human mesh recovery, which (a) relies on intermediate 2D representations which are more robust to synthetic-to-real domain gap; (b) leverages learnable calibration and triangulation to adapt to more diversified camera setups; and (c) progressively aggregates multi-view information in a canonical 3D space to remove ambiguities in 2D representations. Through extensive benchmarking, we demonstrate the superiority of the proposed solution especially for unseen in-the-wild scenarios",
    "checked": true,
    "id": "f63d71bfd0c363132865a36cd2169b3915888c94",
    "semantic_title": "progressive multi-view human mesh recovery with self-supervision",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25145": {
    "title": "Incremental Image De-raining via Associative Memory",
    "volume": "main",
    "abstract": "While deep learning models have achieved the state-of-the-art performance on single-image rain removal, most methods only consider learning fixed mapping rules on the single synthetic dataset for lifetime. This limits the real-life application as iterative optimization may change mapping rules and training samples. However, when models learn a sequence of datasets in multiple incremental steps, they are susceptible to catastrophic forgetting that adapts to new incremental episodes while failing to preserve previously acquired mapping rules. In this paper, we argue the importance of sample diversity in the episodes on the iterative optimization, and propose a novel memory management method, Associative Memory, to achieve incremental image de-raining. It bridges connections between current and past episodes for feature reconstruction by sampling domain mappings of past learning steps, and guides the learning to trace the current pathway back to the historical environment without storing extra data. Experiments demonstrate that our method can achieve better performance than existing approaches on both inhomogeneous and incremental datasets within the spectrum of highly compact systems",
    "checked": true,
    "id": "c7ff3f133e4290b266f5881a7108a681ffa72e45",
    "semantic_title": "incremental image de-raining via associative memory",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25146": {
    "title": "Flexible 3D Lane Detection by Hierarchical Shape Matching",
    "volume": "main",
    "abstract": "As one of the basic while vital technologies for HD map construction, 3D lane detection is still an open problem due to varying visual conditions, complex typologies, and strict demands for precision. In this paper, an end-to-end flexible and hierarchical lane detector is proposed to precisely predict 3D lane lines from point clouds. Specifically, we design a hierarchical network predicting flexible representations of lane shapes at different levels, simultaneously collecting global instance semantics and avoiding local errors. In the global scope, we propose to regress parametric curves w.r.t adaptive axes that help to make more robust predictions towards complex scenes, while in the local vision the structure of lane segment is detected in each of the dynamic anchor cells sampled along the global predicted curves. Moreover, corresponding global and local shape matching losses and anchor cell generation strategies are designed. Experiments on two datasets show that we overwhelm current top methods under high precision standards, and full ablation studies also verify each part of our method. Our codes will be released at https://github.com/Doo-do/FHLD",
    "checked": true,
    "id": "247dfec8ebff13808228e73d4ad3166b45cb4972",
    "semantic_title": "flexible 3d lane detection by hierarchical shape matching",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25147": {
    "title": "Underwater Ranker: Learn Which Is Better and How to Be Better",
    "volume": "main",
    "abstract": "In this paper, we present a ranking-based underwater image quality assessment (UIQA) method, abbreviated as URanker. The URanker is built on the efficient conv-attentional image Transformer. In terms of underwater images, we specially devise (1) the histogram prior that embeds the color distribution of an underwater image as histogram token to attend global degradation and (2) the dynamic cross-scale correspondence to model local degradation. The final prediction depends on the class tokens from different scales, which comprehensively considers multi-scale dependencies. With the margin ranking loss, our URanker can accurately rank the order of underwater images of the same scene enhanced by different underwater image enhancement (UIE) algorithms according to their visual quality. To achieve that, we also contribute a dataset, URankerSet, containing sufficient results enhanced by different UIE algorithms and the corresponding perceptual rankings, to train our URanker. Apart from the good performance of URanker, we found that a simple U-shape UIE network can obtain promising performance when it is coupled with our pre-trained URanker as additional supervision. In addition, we also propose a normalization tail that can significantly improve the performance of UIE networks. Extensive experiments demonstrate the state-of-the-art performance of our method. The key designs of our method are discussed. Our code and dataset are available at https://li-chongyi.github.io/URanker_files/",
    "checked": true,
    "id": "f9a07858f88daf54e0ced43ddc4e1178f754458b",
    "semantic_title": "underwater ranker: learn which is better and how to be better",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25148": {
    "title": "ShadowFormer: Global Context Helps Shadow Removal",
    "volume": "main",
    "abstract": "Recent deep learning methods have achieved promising results in image shadow removal. However, most of the existing approaches focus on working locally within shadow and non-shadow regions, resulting in severe artifacts around the shadow boundaries as well as inconsistent illumination between shadow and non-shadow regions. It is still challenging for the deep shadow removal model to exploit the global contextual correlation between shadow and non-shadow regions. In this work, we first propose a Retinex-based shadow model, from which we derive a novel transformer-based network, dubbed ShandowFormer, to exploit non-shadow regions to help shadow region restoration. A multi-scale channel attention framework is employed to hierarchically capture the global information. Based on that, we propose a Shadow-Interaction Module (SIM) with Shadow-Interaction Attention (SIA) in the bottleneck stage to effectively model the context correlation between shadow and non-shadow regions. We conduct extensive experiments on three popular public datasets, including ISTD, ISTD+, and SRD, to evaluate the proposed method. Our method achieves state-of-the-art performance by using up to 150X fewer model parameters",
    "checked": true,
    "id": "b7ffb3dee668255ccffc5970c795f0c1d79ad79b",
    "semantic_title": "shadowformer: global context helps shadow removal",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25149": {
    "title": "RAFaRe: Learning Robust and Accurate Non-parametric 3D Face Reconstruction from Pseudo 2D&3D Pairs",
    "volume": "main",
    "abstract": "We propose a robust and accurate non-parametric method for single-view 3D face reconstruction (SVFR). While tremendous efforts have been devoted to parametric SVFR, a visible gap still lies between the result 3D shape and the ground truth. We believe there are two major obstacles: 1) the representation of the parametric model is limited to a certain face database; 2) 2D images and 3D shapes in the fitted datasets are distinctly misaligned. To resolve these issues, a large-scale pseudo 2D&3D dataset is created by first rendering the detailed 3D faces, then swapping the face in the wild images with the rendered face. These pseudo 2D&3D pairs are created from publicly available datasets which eliminate the gaps between 2D and 3D data while covering diverse appearances, poses, scenes, and illumination. We further propose a non-parametric scheme to learn a well-generalized SVFR model from the created dataset, and the proposed hierarchical signed distance function turns out to be effective in predicting middle-scale and small-scale 3D facial geometry. Our model outperforms previous methods on FaceScape-wild/lab and MICC benchmarks and is well generalized to various appearances, poses, expressions, and in-the-wild environments. The code is released at https://github.com/zhuhao-nju/rafare",
    "checked": true,
    "id": "743cc26eb711e740724f5a94bb3bcc17a5201728",
    "semantic_title": "rafare: learning robust and accurate non-parametric 3d face reconstruction from pseudo 2d&3d pairs",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25150": {
    "title": "RankDNN: Learning to Rank for Few-Shot Learning",
    "volume": "main",
    "abstract": "This paper introduces a new few-shot learning pipeline that casts relevance ranking for image retrieval as binary ranking relation classification. In comparison to image classification, ranking relation classification is sample efficient and domain agnostic. Besides, it provides a new perspective on few-shot learning and is complementary to state-of-the-art methods. The core component of our deep neural network is a simple MLP, which takes as input an image triplet encoded as the difference between two vector-Kronecker products, and outputs a binary relevance ranking order. The proposed RankMLP can be built on top of any state-of-the-art feature extractors, and our entire deep neural network is called the ranking deep neural network, or RankDNN. Meanwhile, RankDNN can be flexibly fused with other post-processing methods. During the meta test, RankDNN ranks support images according to their similarity with the query samples, and each query sample is assigned the class label of its nearest neighbor. Experiments demonstrate that RankDNN can effectively improve the performance of its baselines based on a variety of backbones and it outperforms previous state-of-the-art algorithms on multiple few-shot learning benchmarks, including miniImageNet, tieredImageNet, Caltech-UCSD Birds, and CIFAR-FS. Furthermore, experiments on the cross-domain challenge demonstrate the superior transferability of RankDNN.The code is available at: https://github.com/guoqianyu-alberta/RankDNN",
    "checked": true,
    "id": "f9c63c1de8de192c62d334eb97bdff30c2f6fc64",
    "semantic_title": "rankdnn: learning to rank for few-shot learning",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25151": {
    "title": "Social Relation Reasoning Based on Triangular Constraints",
    "volume": "main",
    "abstract": "Social networks are essentially in a graph structure where persons act as nodes and the edges connecting nodes denote social relations. The prediction of social relations, therefore, relies on the context in graphs to model the higher-order constraints among relations, which has not been exploited sufficiently by previous works, however. In this paper, we formulate the paradigm of the higher-order constraints in social relations into triangular relational closed-loop structures, i.e., triangular constraints, and further introduce the triangular reasoning graph attention network (TRGAT). Our TRGAT employs the attention mechanism to aggregate features with triangular constraints in the graph, thereby exploiting the higher-order context to reason social relations iteratively. Besides, to acquire better feature representations of persons, we introduce node contrastive learning into relation reasoning. Experimental results show that our method outperforms existing approaches significantly, with higher accuracy and better consistency in generating social relation graphs",
    "checked": true,
    "id": "71e0b80918978266b24e1d2df79f399885ba661d",
    "semantic_title": "social relation reasoning based on triangular constraints",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25152": {
    "title": "CALIP: Zero-Shot Enhancement of CLIP with Parameter-Free Attention",
    "volume": "main",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has been shown to learn visual representations with promising zero-shot performance. To further improve its downstream accuracy, existing works propose additional learnable modules upon CLIP and fine-tune them by few-shot training sets. However, the resulting extra training cost and data requirement severely hinder the efficiency for model deployment and knowledge transfer. In this paper, we introduce a free-lunch enhancement method, CALIP, to boost CLIP's zero-shot performance via a parameter-free attention module. Specifically, we guide visual and textual representations to interact with each other and explore cross-modal informative features via attention. As the pre-training has largely reduced the embedding distances between two modalities, we discard all learnable parameters in the attention and bidirectionally update the multi-modal features, enabling the whole process to be parameter-free and training-free. In this way, the images are blended with textual-aware signals and the text representations become visual-guided for better adaptive zero-shot alignment. We evaluate CALIP on various benchmarks of 14 datasets for both 2D image and 3D point cloud few-shot classification, showing consistent zero-shot performance improvement over CLIP. Based on that, we further insert a small number of linear layers in CALIP's attention module and verify our robustness under the few-shot settings, which also achieves leading performance compared to existing methods. Those extensive experiments demonstrate the superiority of our approach for efficient enhancement of CLIP. Code is available at https://github.com/ZiyuGuo99/CALIP",
    "checked": true,
    "id": "ca26023c4dbde9a54145b68e1a6a40533fcc1a4a",
    "semantic_title": "calip: zero-shot enhancement of clip with parameter-free attention",
    "citation_count": 18
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25153": {
    "title": "Few-Shot Object Detection via Variational Feature Aggregation",
    "volume": "main",
    "abstract": "As few-shot object detectors are often trained with abundant base samples and fine-tuned on few-shot novel examples, the learned models are usually biased to base classes and sensitive to the variance of novel examples. To address this issue, we propose a meta-learning framework with two novel feature aggregation schemes. More precisely, we first present a Class-Agnostic Aggregation (CAA) method, where the query and support features can be aggregated regardless of their categories. The interactions between different classes encourage class-agnostic representations and reduce confusion between base and novel classes. Based on the CAA, we then propose a Variational Feature Aggregation (VFA) method, which encodes support examples into class-level support features for robust feature aggregation. We use a variational autoencoder to estimate class distributions and sample variational features from distributions that are more robust to the variance of support examples. Besides, we decouple classification and regression tasks so that VFA is performed on the classification branch without affecting object localization. Extensive experiments on PASCAL VOC and COCO demonstrate that our method significantly outperforms a strong baseline (up to 16%) and previous state-of-the-art methods (4% in average)",
    "checked": true,
    "id": "4d1e8a99b49e5ac7325e42c5958f76c22ac26e82",
    "semantic_title": "few-shot object detection via variational feature aggregation",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25154": {
    "title": "Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization",
    "volume": "main",
    "abstract": "Recent studies have demonstrated that existing deep neural networks (DNNs) on 3D point clouds are vulnerable to adversarial examples, especially under the white-box settings where the adversaries have access to model parameters. However, adversarial 3D point clouds generated by existing white-box methods have limited transferability across different DNN architectures. They have only minor threats in real-world scenarios under the black-box settings where the adversaries can only query the deployed victim model. In this paper, we revisit the transferability of adversarial 3D point clouds. We observe that an adversarial perturbation can be randomly factorized into two sub-perturbations, which are also likely to be adversarial perturbations. It motivates us to consider the effects of the perturbation and its sub-perturbations simultaneously to increase the transferability for sub-perturbations also contain helpful information. In this paper, we propose a simple yet effective attack method to generate more transferable adversarial 3D point clouds. Specifically, rather than simply optimizing the loss of perturbation alone, we combine it with its random factorization. We conduct experiments on benchmark dataset, verifying our method's effectiveness in increasing transferability while preserving high efficiency",
    "checked": true,
    "id": "eca815987e1c6a51e00fdc202342d50a288599f0",
    "semantic_title": "generating transferable 3d adversarial point cloud via random perturbation factorization",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25155": {
    "title": "Target-Aware Tracking with Long-Term Context Attention",
    "volume": "main",
    "abstract": "Most deep trackers still follow the guidance of the siamese paradigms and use a template that contains only the target without any contextual information, which makes it difficult for the tracker to cope with large appearance changes, rapid target movement, and attraction from similar objects. To alleviate the above problem, we propose a long-term context attention (LCA) module that can perform extensive information fusion on the target and its context from long-term frames, and calculate the target correlation while enhancing target features. The complete contextual information contains the location of the target as well as the state around the target. LCA uses the target state from the previous frame to exclude the interference of similar objects and complex backgrounds, thus accurately locating the target and enabling the tracker to obtain higher robustness and regression accuracy. By embedding the LCA module in Transformer, we build a powerful online tracker with a target-aware backbone, termed as TATrack. In addition, we propose a dynamic online update algorithm based on the classification confidence of historical information without additional calculation burden. Our tracker achieves state-of-the-art performance on multiple benchmarks, with 71.1% AUC, 89.3% NP, and 73.0% AO on LaSOT, TrackingNet, and GOT-10k. The code and trained models are available on https://github.com/hekaijie123/TATrack",
    "checked": true,
    "id": "62fc770746f6a283fbc5cfc32275e23bfef82eb7",
    "semantic_title": "target-aware tracking with long-term context attention",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25156": {
    "title": "Weakly-Supervised Camouflaged Object Detection with Scribble Annotations",
    "volume": "main",
    "abstract": "Existing camouflaged object detection (COD) methods rely heavily on large-scale datasets with pixel-wise annotations. However, due to the ambiguous boundary, annotating camouflage objects pixel-wisely is very time-consuming and labor-intensive, taking ~60mins to label one image. In this paper, we propose the first weakly-supervised COD method, using scribble annotations as supervision. To achieve this, we first relabel 4,040 images in existing camouflaged object datasets with scribbles, which takes ~10s to label one image. As scribble annotations only describe the primary structure of objects without details, for the network to learn to localize the boundaries of camouflaged objects, we propose a novel consistency loss composed of two parts: a cross-view loss to attain reliable consistency over different images, and an inside-view loss to maintain consistency inside a single prediction map. Besides, we observe that humans use semantic information to segment regions near the boundaries of camouflaged objects. Hence, we further propose a feature-guided loss, which includes visual features directly extracted from images and semantically significant features captured by the model. Finally, we propose a novel network for COD via scribble learning on structural information and semantic relations. Our network has two novel modules: the local-context contrasted (LCC) module, which mimics visual inhibition to enhance image contrast/sharpness and expand the scribbles into potential camouflaged regions, and the logical semantic relation (LSR) module, which analyzes the semantic relation to determine the regions representing the camouflaged object. Experimental results show that our model outperforms relevant SOTA methods on three COD benchmarks with an average improvement of 11.0% on MAE, 3.2% on S-measure, 2.5% on E-measure, and 4.4% on weighted F-measure",
    "checked": true,
    "id": "613ac2c205cad421a28d7b3a357472a0883803c2",
    "semantic_title": "weakly-supervised camouflaged object detection with scribble annotations",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25157": {
    "title": "Efficient Mirror Detection via Multi-Level Heterogeneous Learning",
    "volume": "main",
    "abstract": "We present HetNet (Multi-level Heterogeneous Network), a highly efficient mirror detection network. Current mirror detection methods focus more on performance than efficiency, limiting the real-time applications (such as drones). Their lack of efficiency is aroused by the common design of adopting homogeneous modules at different levels, which ignores the difference between different levels of features. In contrast, HetNet detects potential mirror regions initially through low-level understandings (e.g., intensity contrasts) and then combines with high-level understandings (contextual discontinuity for instance) to finalize the predictions. To perform accurate yet efficient mirror detection, HetNet follows an effective architecture that obtains specific information at different stages to detect mirrors. We further propose a multi-orientation intensity-based contrasted module (MIC) and a reflection semantic logical module (RSL), equipped on HetNet, to predict potential mirror regions by low-level understandings and analyze semantic logic in scenarios by high-level understandings, respectively. Compared to the state-of-the-art method, HetNet runs 664% faster and draws an average performance gain of 8.9% on MAE, 3.1% on IoU, and 2.0% on F-measure on two mirror detection benchmarks. The code is available at https://github.com/Catherine-R-He/HetNet",
    "checked": true,
    "id": "eb30447cac68f1b22466da2f3f0d85e7a8e0d7c9",
    "semantic_title": "efficient mirror detection via multi-level heterogeneous learning",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25158": {
    "title": "TransVCL: Attention-Enhanced Video Copy Localization Network with Flexible Supervision",
    "volume": "main",
    "abstract": "Video copy localization aims to precisely localize all the copied segments within a pair of untrimmed videos in video retrieval applications. Previous methods typically start from frame-to-frame similarity matrix generated by cosine similarity between frame-level features of the input video pair, and then detect and refine the boundaries of copied segments on similarity matrix under temporal constraints. In this paper, we propose TransVCL: an attention-enhanced video copy localization network, which is optimized directly from initial frame-level features and trained end-to-end with three main components: a customized Transformer for feature enhancement, a correlation and softmax layer for similarity matrix generation, and a temporal alignment module for copied segments localization. In contrast to previous methods demanding the handcrafted similarity matrix, TransVCL incorporates long-range temporal information between feature sequence pair using self- and cross- attention layers. With the joint design and optimization of three components, the similarity matrix can be learned to present more discriminative copied patterns, leading to significant improvements over previous methods on segment-level labeled datasets (VCSL and VCDB). Besides the state-of-the-art performance in fully supervised setting, the attention architecture facilitates TransVCL to further exploit unlabeled or simply video-level labeled data. Additional experiments of supplementing video-level labeled datasets including SVD and FIVR reveal the high flexibility of TransVCL from full supervision to semi-supervision (with or without video-level annotation). Code is publicly available at https://github.com/transvcl/TransVCL",
    "checked": true,
    "id": "18c912802e3d6d84283d24655beb04f904d03675",
    "semantic_title": "transvcl: attention-enhanced video copy localization network with flexible supervision",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25159": {
    "title": "Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer",
    "volume": "main",
    "abstract": "Real-world recognition system often encounters the challenge of unseen labels. To identify such unseen labels, multi-label zero-shot learning (ML-ZSL) focuses on transferring knowledge by a pre-trained textual label embedding (e.g., GloVe). However, such methods only exploit single-modal knowledge from a language model, while ignoring the rich semantic information inherent in image-text pairs. Instead, recently developed open-vocabulary (OV) based methods succeed in exploiting such information of image-text pairs in object detection, and achieve impressive performance. Inspired by the success of OV-based methods, we propose a novel open-vocabulary framework, named multi-modal knowledge transfer (MKT), for multi-label classification. Specifically, our method exploits multi-modal knowledge of image-text pairs based on a vision and language pre-training (VLP) model. To facilitate transferring the image-text matching ability of VLP model, knowledge distillation is employed to guarantee the consistency of image and label embeddings, along with prompt tuning to further update the label embeddings. To further enable the recognition of multiple objects, a simple but effective two-stream module is developed to capture both local and global features. Extensive experimental results show that our method significantly outperforms state-of-the-art methods on public benchmark datasets",
    "checked": true,
    "id": "ee301715607f618d22f21cb51c2c63ca85a4340c",
    "semantic_title": "open-vocabulary multi-label classification via multi-modal knowledge transfer",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25160": {
    "title": "Parameter-Efficient Model Adaptation for Vision Transformers",
    "volume": "main",
    "abstract": "In computer vision, it has achieved great transfer learning performance via adapting large-scale pretrained vision models (e.g., vision transformers) to downstream tasks. Common approaches for model adaptation either update all model parameters or leverage linear probes. In this paper, we aim to study parameter-efficient model adaptation strategies for vision transformers on the image classification task. We formulate efficient model adaptation as a subspace training problem and perform a comprehensive benchmarking over different efficient adaptation methods. We conduct an empirical study on each efficient model adaptation method focusing on its performance alongside parameter cost. Furthermore, we propose a parameter-efficient model adaptation framework, which first selects submodules by measuring local intrinsic dimensions and then projects them into subspace for further decomposition via a novel Kronecker Adaptation method. We analyze and compare our method with a diverse set of baseline model adaptation methods (including state-of-the-art methods for pretrained language models). Our method performs the best in terms of the tradeoff between accuracy and parameter efficiency across 20 datasets under the few-shot setting and 7 image classification datasets under the full-shot setting",
    "checked": true,
    "id": "af593c53a9221bd12211f78d4f1ebd6b59cc4e7c",
    "semantic_title": "parameter-efficient model adaptation for vision transformers",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25161": {
    "title": "DarkFeat: Noise-Robust Feature Detector and Descriptor for Extremely Low-Light RAW Images",
    "volume": "main",
    "abstract": "Low-light visual perception, such as SLAM or SfM at night, has received increasing attention, in which keypoint detection and local feature description play an important role. Both handcraft designs and machine learning methods have been widely studied for local feature detection and description, however, the performance of existing methods degrades in the extreme low-light scenarios in a certain degree, due to the low signal-to-noise ratio in images. To address this challenge, images in RAW format that retain more raw sensing information have been considered in recent works with a denoise-then-detect scheme. However, existing denoising methods are still insufficient for RAW images and heavily time-consuming, which limits the practical applications of such scheme. In this paper, we propose DarkFeat, a deep learning model which directly detects and describes local features from extreme low-light RAW images in an end-to-end manner. A novel noise robustness map and selective suppression constraints are proposed to effectively mitigate the influence of noise and extract more reliable keypoints. Furthermore, a customized pipeline of synthesizing dataset containing low-light RAW image matching pairs is proposed to extend end-to-end training. Experimental results show that DarkFeat achieves state-of-the-art performance on both indoor and outdoor parts of the challenging MID benchmark, outperforms the denoise-then-detect methods and significantly reduces computational costs up to 70%. Code is available at https://github.com/THU-LYJ-Lab/DarkFeat",
    "checked": true,
    "id": "a988d11e4a2c3de692bc879cf8c3d5be5e8e3ead",
    "semantic_title": "darkfeat: noise-robust feature detector and descriptor for extremely low-light raw images",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25162": {
    "title": "GAM: Gradient Attention Module of Optimization for Point Clouds Analysis",
    "volume": "main",
    "abstract": "In the point cloud analysis task, the existing local feature aggregation descriptors (LFAD) do not fully utilize the neighborhood information of center points. Previous methods only use the distance information to constrain the local aggregation process, which is easy to be affected by abnormal points and cannot adequately fit the original geometry of the point cloud. This paper argues that fine-grained geometric information (FGGI) plays an important role in the aggregation of local features. Based on this, we propose a gradient-based local attention module to address the above problem, which is called Gradient Attention Module (GAM). GAM simplifies the process of extracting the gradient information in the neighborhood to explicit representation using the Zenith Angle matrix and Azimuth Angle matrix, which makes the module 35X faster. The comprehensive experiments on the ScanObjectNN dataset, ShapeNet dataset, S3DIS dataset, Modelnet40 dataset, and KITTI dataset demonstrate the effectiveness, efficientness, and generalization of our newly proposed GAM for 3D point cloud analysis. Especially in S3DIS, GAM achieves the highest index in the current point-based model with mIoU/OA/mAcc of 74.4%/90.6%/83.2%",
    "checked": false,
    "id": "a5820730290e81f76d843178af927591e669053d",
    "semantic_title": "gam : gradient attention module of optimization for point clouds analysis",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25163": {
    "title": "Self-Supervised Learning for Multilevel Skeleton-Based Forgery Detection via Temporal-Causal Consistency of Actions",
    "volume": "main",
    "abstract": "Skeleton-based human action recognition and analysis have become increasingly attainable in many areas, such as security surveillance and anomaly detection. Given the prevalence of skeleton-based applications, tampering attacks on human skeletal features have emerged very recently. In particular, checking the temporal inconsistency and/or incoherence (TII) in the skeletal sequence of human action is a principle of forgery detection. To this end, we propose an approach to self-supervised learning of the temporal causality behind human action, which can effectively check TII in skeletal sequences. Especially, we design a multilevel skeleton-based forgery detection framework to recognize the forgery on frame level, clip level, and action level in terms of learning the corresponding temporal-causal skeleton representations for each level. Specifically, a hierarchical graph convolution network architecture is designed to learn low-level skeleton representations based on physical skeleton connections and high-level action representations based on temporal-causal dependencies for specific actions. Extensive experiments consistently show state-of-the-art results on multilevel forgery detection tasks and superior performance of our framework compared to current competing methods",
    "checked": true,
    "id": "84a150e189e34771752a5454a6f9e143a602dbb8",
    "semantic_title": "self-supervised learning for multilevel skeleton-based forgery detection via temporal-causal consistency of actions",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25164": {
    "title": "Self-Emphasizing Network for Continuous Sign Language Recognition",
    "volume": "main",
    "abstract": "Hand and face play an important role in expressing sign language. Their features are usually especially leveraged to improve system performance. However, to effectively extract visual representations and capture trajectories for hands and face, previous methods always come at high computations with increased training complexity. They usually employ extra heavy pose-estimation networks to locate human body keypoints or rely on additional pre-extracted heatmaps for supervision. To relieve this problem, we propose a self-emphasizing network (SEN) to emphasize informative spatial regions in a self-motivated way, with few extra computations and without additional expensive supervision. Specifically, SEN first employs a lightweight subnetwork to incorporate local spatial-temporal features to identify informative regions, and then dynamically augment original features via attention maps. It's also observed that not all frames contribute equally to recognition. We present a temporal self-emphasizing module to adaptively emphasize those discriminative frames and suppress redundant ones. A comprehensive comparison with previous methods equipped with hand and face features demonstrates the superiority of our method, even though they always require huge computations and rely on expensive extra supervision. Remarkably, with few extra computations, SEN achieves new state-of-the-art accuracy on four large-scale datasets, PHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. Visualizations verify the effects of SEN on emphasizing informative spatial and temporal features. Code is available at https://github.com/hulianyuyy/SEN_CSLR",
    "checked": true,
    "id": "1f55d35e1d1a148898a756cb0380b22fa8878dcb",
    "semantic_title": "self-emphasizing network for continuous sign language recognition",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25165": {
    "title": "Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution",
    "volume": "main",
    "abstract": "Existing space-time video super-resolution (ST-VSR) methods fail to achieve high-quality reconstruction since they fail to fully explore the spatial-temporal correlations, long-range components in particular. Although the recurrent structure for ST-VSR adopts bidirectional propagation to aggregate information from the entire video, collecting the temporal information between the past and future via one-stage representations inevitably loses the long-range relations. To alleviate the limitation, this paper proposes an immediate storeand-fetch network to promote long-range correlation learning, where the stored information from the past and future can be refetched to help the representation of the current frame. Specifically, the proposed network consists of two modules: a backward recurrent module (BRM) and a forward recurrent module (FRM). The former first performs backward inference from future to past, while storing future super-resolution (SR) information for each frame. Following that, the latter performs forward inference from past to future to super-resolve all frames, while storing past SR information for each frame. Since FRM inherits SR information from BRM, therefore, spatial and temporal information from the entire video sequence is immediately stored and fetched, which allows drastic improvement for ST-VSR. Extensive experiments both on ST-VSR and space video super-resolution (S-VSR) as well as time video super-resolution (T-VSR) have demonstrated the effectiveness of our proposed method over other state-of-the-art methods on public datasets. Code is available https://github.com/hhhhhumengshun/SFI-STVR",
    "checked": true,
    "id": "e32b2e5f07434a4d6ba73ee7394829ef93260124",
    "semantic_title": "store and fetch immediately: everything is all you need for space-time video super-resolution",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25166": {
    "title": "PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models against Adversarial Examples",
    "volume": "main",
    "abstract": "Point cloud completion, as the upstream procedure of 3D recognition and segmentation, has become an essential part of many tasks such as navigation and scene understanding. While various point cloud completion models have demonstrated their powerful capabilities, their robustness against adversarial attacks, which have been proven to be fatally malicious towards deep neural networks, remains unknown. In addition, existing attack approaches towards point cloud classifiers cannot be applied to the completion models due to different output forms and attack purposes. In order to evaluate the robustness of the completion models, we propose PointCA, the first adversarial attack against 3D point cloud completion models. PointCA can generate adversarial point clouds that maintain high similarity with the original ones, while being completed as another object with totally different semantic information. Specifically, we minimize the representation discrepancy between the adversarial example and the target point set to jointly explore the adversarial point clouds in the geometry space and the feature space. Furthermore, to launch a stealthier attack, we innovatively employ the neighbourhood density information to tailor the perturbation constraint, leading to geometry-aware and distribution-adaptive modifications for each point. Extensive experiments against different premier point cloud completion networks show that PointCA can cause the performance degradation from 77.9% to 16.7%, with the structure chamfer distance kept below 0.01. We conclude that existing completion models are severely vulnerable to adversarial examples, and state-of-the-art defenses for point cloud classification will be partially invalid when applied to incomplete and uneven point cloud data",
    "checked": true,
    "id": "aec240626448b3506860a577d5d9ea3a20bfe794",
    "semantic_title": "pointca: evaluating the robustness of 3d point cloud completion models against adversarial examples",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25167": {
    "title": "High-Resolution Iterative Feedback Network for Camouflaged Object Detection",
    "volume": "main",
    "abstract": "Spotting camouflaged objects that are visually assimilated into the background is tricky for both object detection algorithms and humans who are usually confused or cheated by the perfectly intrinsic similarities between the foreground objects and the background surroundings. To tackle this challenge, we aim to extract the high-resolution texture details to avoid the detail degradation that causes blurred vision in edges and boundaries. We introduce a novel HitNet to refine the low-resolution representations by high-resolution features in an iterative feedback manner, essentially a global loop-based connection among the multi-scale resolutions. To design better feedback feature ﬂow and avoid the feature corruption caused by recurrent path, an iterative feedback strategy is proposed to impose more constraints on each feedback connection. Extensive experiments on four challenging datasets demonstrate that our HitNet breaks the performance bottleneck and achieves significant improvements compared with 29 state-of-the-art methods. In addition, to address the data scarcity in camouflaged scenarios, we provide an application example to convert the salient objects to camouflaged objects, thereby generating more camouflaged training samples from the diverse salient object datasets. Code will be made publicly available",
    "checked": true,
    "id": "453d36c646576b04241ca7b964698eef64ebbdc8",
    "semantic_title": "high-resolution iterative feedback network for camouflaged object detection",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25168": {
    "title": "Leveraging Sub-class Discimination for Compositional Zero-Shot Learning",
    "volume": "main",
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims at identifying unseen compositions composed of previously seen attributes and objects during the test phase. In real images, the visual appearances of attributes and objects (primitive concepts) generally interact with each other. Namely, the visual appearances of an attribute may change when composed with different objects, and vice versa. But previous works overlook this important property. In this paper, we introduce a simple yet effective approach with leveraging sub-class discrimination. Specifically, we define the primitive concepts in different compositions as sub-classes, and then maintain the sub-class discrimination to address the above challenge. More specifically, inspired by the observation that the composed recognition models could account for the differences across sub-classes, we first propose to impose the embedding alignment between the composed and disentangled recognition to incorporate sub-class discrimination at the feature level. Then we develop the prototype modulator networks to adjust the class prototypes w.r.t. the composition information, which can enhance sub-class discrimination at the classifier level. We conduct extensive experiments on the challenging benchmark datasets, and the considerable performance improvement over state-of-the-art approaches is achieved, which indicates the effectiveness of our method. Our code is available at https://github.com/hxm97/SCD-CZSL",
    "checked": true,
    "id": "0cb450cc6ccdaa0d1914cbc4d715f0eeb2792aa7",
    "semantic_title": "leveraging sub-class discimination for compositional zero-shot learning",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25169": {
    "title": "GPTR: Gestalt-Perception Transformer for Diagram Object Detection",
    "volume": "main",
    "abstract": "Diagram object detection is the key basis of practical applications such as textbook question answering. Because the diagram mainly consists of simple lines and color blocks, its visual features are sparser than those of natural images. In addition, diagrams usually express diverse knowledge, in which there are many low-frequency object categories in diagrams. These lead to the fact that traditional data-driven detection model is not suitable for diagrams. In this work, we propose a gestalt-perception transformer model for diagram object detection, which is based on an encoder-decoder architecture. Gestalt perception contains a series of laws to explain human perception, that the human visual system tends to perceive patches in an image that are similar, close or connected without abrupt directional changes as a perceptual whole object. Inspired by these thoughts, we build a gestalt-perception graph in transformer encoder, which is composed of diagram patches as nodes and the relationships between patches as edges. This graph aims to group these patches into objects via laws of similarity, proximity, and smoothness implied in these edges, so that the meaningful objects can be effectively detected. The experimental results demonstrate that the proposed GPTR achieves the best results in the diagram object detection task. Our model also obtains comparable results over the competitors in natural image object detection",
    "checked": true,
    "id": "6329ee4cf6bbd30c5d76d6caa78959946c656c56",
    "semantic_title": "gptr: gestalt-perception transformer for diagram object detection",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25170": {
    "title": "Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning",
    "volume": "main",
    "abstract": "The dynamic expansion architecture is becoming popular in class incremental learning, mainly due to its advantages in alleviating catastrophic forgetting. However, task confu- sion is not well assessed within this framework, e.g., the discrepancy between classes of different tasks is not well learned (i.e., inter-task confusion, ITC), and certain prior- ity is still given to the latest class batch (i.e., old-new con- fusion, ONC). We empirically validate the side effects of the two types of confusion. Meanwhile, a novel solution called Task Correlated Incremental Learning (TCIL) is pro- posed to encourage discriminative and fair feature utilization across tasks. TCIL performs a multi-level knowledge distil- lation to propagate knowledge learned from old tasks to the new one. It establishes information flow paths at both fea- ture and logit levels, enabling the learning to be aware of old classes. Besides, attention mechanism and classifier re- scoring are applied to generate more fair classification scores. We conduct extensive experiments on CIFAR100 and Ima- geNet100 datasets. The results demonstrate that TCIL con- sistently achieves state-of-the-art accuracy. It mitigates both ITC and ONC, while showing advantages in battle with catas- trophic forgetting even no rehearsal memory is reserved. Source code: https://github.com/YellowPancake/TCIL",
    "checked": true,
    "id": "a63eff00c20172847439826377e412934caad068",
    "semantic_title": "resolving task confusion in dynamic expansion architectures for class incremental learning",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25171": {
    "title": "ClassFormer: Exploring Class-Aware Dependency with Transformer for Medical Image Segmentation",
    "volume": "main",
    "abstract": "Vision Transformers have recently shown impressive performances on medical image segmentation. Despite their strong capability of modeling long-range dependencies, the current methods still give rise to two main concerns in a class-level perspective: (1) intra-class problem: the existing methods lacked in extracting class-specific correspondences of different pixels, which may lead to poor object coverage and/or boundary prediction; (2) inter-class problem: the existing methods failed to model explicit category-dependencies among various objects, which may result in inaccurate localization. In light of these two issues, we propose a novel transformer, called ClassFormer, powered by two appealing transformers, i.e., intra-class dynamic transformer and inter-class interactive transformer, to address the challenge of fully exploration on compactness and discrepancy. Technically, the intra-class dynamic transformer is first designed to decouple representations of different categories with an adaptive selection mechanism for compact learning, which optimally highlights the informative features to reflect the salient keys/values from multiple scales. We further introduce the inter-class interactive transformer to capture the category dependency among different objects, and model class tokens as the representative class centers to guide a global semantic reasoning. As a consequence, the feature consistency is ensured with the expense of intra-class penalization, while inter-class constraint strengthens the feature discriminability between different categories. Extensive empirical evidence shows that ClassFormer can be easily plugged into any architecture, and yields improvements over the state-of-the-art methods in three public benchmarks",
    "checked": true,
    "id": "eed051a90f635adb806c025c9b1fcc790f35ba0b",
    "semantic_title": "classformer: exploring class-aware dependency with transformer for medical image segmentation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25172": {
    "title": "NLIP: Noise-Robust Language-Image Pre-training",
    "volume": "main",
    "abstract": "Large-scale cross-modal pre-training paradigms have recently shown ubiquitous success on a wide range of downstream tasks, e.g., zero-shot classification, retrieval and image captioning. However, their successes highly rely on the scale and quality of web-crawled data that naturally contain much incomplete and noisy information (e.g., wrong or irrelevant contents). Existing works either design manual rules to clean data or generate pseudo-targets as auxiliary signals for reducing noise impact, which do not explicitly tackle both the incorrect and incomplete challenges at the same time. In this paper, to automatically mitigate the impact of noise by solely mining over existing data, we propose a principled Noise-robust Language-Image Pre-training framework (NLIP) to stabilize pre-training via two schemes: noise-harmonization and noise-completion. First, in noise-harmonization scheme, NLIP estimates the noise probability of each pair according to the memorization effect of cross-modal transformers, then adopts noise-adaptive regularization to harmonize the cross-modal alignments with varying degrees. Second, in noise-completion scheme, to enrich the missing object information of text, NLIP injects a concept-conditioned cross-modal decoder to obtain semantic-consistent synthetic captions to complete noisy ones, which uses the retrieved visual concepts (i.e., objects' names) for the corresponding image to guide captioning generation. By collaboratively optimizing noise-harmonization and noise-completion schemes, our NLIP can alleviate the common noise effects during image-text pre-training in a more efficient way. Extensive experiments show the significant performance improvements of our NLIP using only 26M data over existing pre-trained models (e.g., CLIP, FILIP and BLIP) on 12 zero-shot classification datasets (e.g., +8.6% over CLIP on average accuracy), MSCOCO image captioning (e.g., +1.9 over BLIP trained with 129M data on CIDEr) and zero-shot image-text retrieval tasks",
    "checked": true,
    "id": "2dd4bdb71e8d1a1bb6f7f2cb500972f082aa91fd",
    "semantic_title": "nlip: noise-robust language-image pre-training",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25173": {
    "title": "Symmetry-Aware Transformer-Based Mirror Detection",
    "volume": "main",
    "abstract": "Mirror detection aims to identify the mirror regions in the given input image. Existing works mainly focus on integrating the semantic features and structural features to mine specific relations between mirror and non-mirror regions, or introducing mirror properties like depth or chirality to help analyze the existence of mirrors. In this work, we observe that a real object typically forms a loose symmetry relationship with its corresponding reflection in the mirror, which is beneficial in distinguishing mirrors from real objects. Based on this observation, we propose a dual-path Symmetry-Aware Transformer-based mirror detection Network (SATNet), which includes two novel modules: Symmetry-Aware Attention Module (SAAM) and Contrast and Fusion Decoder Module (CFDM). Specifically, we first adopt a transformer backbone to model global information aggregation in images, extracting multi-scale features in two paths. We then feed the high-level dual-path features to SAAMs to capture the symmetry relations. Finally, we fuse the dual-path features and refine our prediction maps progressively with CFDMs to obtain the final mirror mask. Experimental results show that SATNet outperforms both RGB and RGB-D mirror detection methods on all available mirror detection datasets",
    "checked": true,
    "id": "b819d724661b35b93aa9048062d988fc6fc868fc",
    "semantic_title": "symmetry-aware transformer-based mirror detection",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25174": {
    "title": "AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio",
    "volume": "main",
    "abstract": "Spatial audio, which focuses on immersive 3D sound rendering, is widely applied in the acoustic industry. One of the key problems of current spatial audio rendering methods is the lack of personalization based on different anatomies of individuals, which is essential to produce accurate sound source positions. In this work, we address this problem from an interdisciplinary perspective. The rendering of spatial audio is strongly correlated with the 3D shape of human bodies, particularly ears. To this end, we propose to achieve personalized spatial audio by reconstructing 3D human ears with single-view images. First, to benchmark the ear reconstruction task, we introduce AudioEar3D, a high-quality 3D ear dataset consisting of 112 point cloud ear scans with RGB images. To self-supervisedly train a reconstruction model, we further collect a 2D ear dataset composed of 2,000 images, each one with manual annotation of occlusion and 55 landmarks, named AudioEar2D. To our knowledge, both datasets have the largest scale and best quality of their kinds for public use. Further, we propose AudioEarM, a reconstruction method guided by a depth estimation network that is trained on synthetic data, with two loss functions tailored for ear data. Lastly, to fill the gap between the vision and acoustics community, we develop a pipeline to integrate the reconstructed ear mesh with an off-the-shelf 3D human body and simulate a personalized Head-Related Transfer Function (HRTF), which is the core of spatial audio rendering. Code and data are publicly available in https://github.com/seanywang0408/AudioEar",
    "checked": true,
    "id": "6b42f494bf45ec5e154a007844cc449a07279c4f",
    "semantic_title": "audioear: single-view ear reconstruction for personalized spatial audio",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25175": {
    "title": "Boosting Point Clouds Rendering via Radiance Mapping",
    "volume": "main",
    "abstract": "Recent years we have witnessed rapid development in NeRF-based image rendering due to its high quality. However, point clouds rendering is somehow less explored. Compared to NeRF-based rendering which suffers from dense spatial sampling, point clouds rendering is naturally less computation intensive, which enables its deployment in mobile computing device. In this work, we focus on boosting the image quality of point clouds rendering with a compact model design. We first analyze the adaption of the volume rendering formulation on point clouds. Based on the analysis, we simplify the NeRF representation to a spatial mapping function which only requires single evaluation per pixel. Further, motivated by ray marching, we rectify the the noisy raw point clouds to the estimated intersection between rays and surfaces as queried coordinates, which could avoid spatial frequency collapse and neighbor point disturbance. Composed of rasterization, spatial mapping and the refinement stages, our method achieves the state-of-the-art performance on point clouds rendering, outperforming prior works by notable margins, with a smaller model size. We obtain a PSNR of 31.74 on NeRF-Synthetic, 25.88 on ScanNet and 30.81 on DTU. Code and data are publicly available in https://github.com/seanywang0408/RadianceMapping",
    "checked": true,
    "id": "18289220a3f778a35d89b9fadeba25820c1ad9ad",
    "semantic_title": "boosting point clouds rendering via radiance mapping",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25176": {
    "title": "FreeEnricher: Enriching Face Landmarks without Additional Cost",
    "volume": "main",
    "abstract": "Recent years have witnessed significant growth of face alignment. Though dense facial landmark is highly demanded in various scenarios, e.g., cosmetic medicine and facial beautification, most works only consider sparse face alignment. To address this problem, we present a framework that can enrich landmark density by existing sparse landmark datasets, e.g., 300W with 68 points and WFLW with 98 points. Firstly, we observe that the local patches along each semantic contour are highly similar in appearance. Then, we propose a weakly-supervised idea of learning the refinement ability on original sparse landmarks and adapting this ability to enriched dense landmarks. Meanwhile, several operators are devised and organized together to implement the idea. Finally, the trained model is applied as a plug-and-play module to the existing face alignment networks. To evaluate our method, we manually label the dense landmarks on 300W testset. Our method yields state-of-the-art accuracy not only in newly-constructed dense 300W testset but also in the original sparse 300W and WFLW testsets without additional cost",
    "checked": true,
    "id": "9889925126ad324f3f60b0978882f00e23541206",
    "semantic_title": "freeenricher: enriching face landmarks without additional cost",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25177": {
    "title": "PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues",
    "volume": "main",
    "abstract": "Humans naturally use referring expressions with verbal utterances and nonverbal gestures to refer to objects and events. As these referring expressions can be interpreted differently from the speaker's or the observer's perspective, people effectively decide on the perspective in comprehending the expressions. However, existing models do not explicitly learn perspective grounding, which often causes the models to perform poorly in understanding embodied referring expressions. To make it exacerbate, these models are often trained on datasets collected in non-embodied settings without nonverbal gestures and curated from an exocentric perspective. To address these issues, in this paper, we present a perspective-aware multitask learning model, called PATRON, for relation and object grounding tasks in embodied settings by utilizing verbal utterances and nonverbal cues. In PATRON, we have developed a guided fusion approach, where a perspective grounding task guides the relation and object grounding task. Through this approach, PATRON learns disentangled task-specific and task-guidance representations, where task-guidance representations guide the extraction of salient multimodal features to ground the relation and object accurately. Furthermore, we have curated a synthetic dataset of embodied referring expressions with multimodal cues, called CAESAR-PRO. The experimental results suggest that PATRON outperforms the evaluated state-of-the-art visual-language models. Additionally, the results indicate that learning to ground perspective helps machine learning models to improve the performance of the relation and object grounding task. Furthermore, the insights from the extensive experimental results and the proposed dataset will enable researchers to evaluate visual-language models' effectiveness in understanding referring expressions in other embodied settings",
    "checked": true,
    "id": "a7fab5b0cc0bf96a1f987f9ebf18177e7915ba60",
    "semantic_title": "patron: perspective-aware multitask model for referring expression grounding using embodied multimodal cues",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25178": {
    "title": "Unifying Vision-Language Representation Space with Single-Tower Transformer",
    "volume": "main",
    "abstract": "Contrastive learning is a form of distance learning that aims to learn invariant features from two related representations. In this work, we explore the hypothesis that an image and caption can be regarded as two different views of the underlying mutual information, and train a model to learn a unified vision-language representation space that encodes both modalities at once in a modality-agnostic manner. We first identify difficulties in learning a one-tower model for vision-language pretraining (VLP), and propose One Representation (OneR) as a simple yet effective framework for our goal. We discover intriguing properties that distinguish OneR from the previous works that have modality-specific representation spaces such as zero-shot localization, text-guided visual reasoning and multi-modal retrieval, and present analyses to provide insights into this new form of multi-modal representation learning. Thorough evaluations demonstrate the potential of a unified modality-agnostic VLP framework",
    "checked": true,
    "id": "e978d2f7e2a04da803d1a224b3ad868ac919dbb8",
    "semantic_title": "unifying vision-language representation space with single-tower transformer",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25179": {
    "title": "Delving Deep into Pixel Alignment Feature for Accurate Multi-View Human Mesh Recovery",
    "volume": "main",
    "abstract": "Regression-based methods have shown high efficiency and effectiveness for multi-view human mesh recovery. The key components of a typical regressor lie in the feature extraction of input views and the fusion of multi-view features. In this paper, we present Pixel-aligned Feedback Fusion (PaFF) for accurate yet efficient human mesh recovery from multi-view images. PaFF is an iterative regression framework that performs feature extraction and fusion alternately. At each iteration, PaFF extracts pixel-aligned feedback features from each input view according to the reprojection of the current estimation and fuses them together with respect to each vertex of the downsampled mesh. In this way, our regressor can not only perceive the misalignment status of each view from the feedback features but also correct the mesh parameters more effectively based on the feature fusion on mesh vertices. Additionally, our regressor disentangles the global orientation and translation of the body mesh from the estimation of mesh parameters such that the camera parameters of input views can be better utilized in the regression process. The efficacy of our method is validated in the Human3.6M dataset via comprehensive ablation experiments, where PaFF achieves 33.02 MPJPE and brings significant improvements over the previous best solutions by more than 29%. The project page with code and video results can be found at https://kairobo.github.io/PaFF/",
    "checked": true,
    "id": "b5a878716aa4ab11e84ba0973d58ab35c68711a1",
    "semantic_title": "delving deep into pixel alignment feature for accurate multi-view human mesh recovery",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25180": {
    "title": "Semi-attention Partition for Occluded Person Re-identification",
    "volume": "main",
    "abstract": "This paper proposes a Semi-Attention Partition (SAP) method to learn well-aligned part features for occluded person re-identification (re-ID). Currently, the mainstream methods employ either external semantic partition or attention-based partition, and the latter manner is usually better than the former one. Under this background, this paper explores a potential that the weak semantic partition can be a good teacher for the strong attention-based partition. In other words, the attention-based student can substantially surpass its noisy semantic-based teacher, contradicting the common sense that the student usually achieves inferior (or comparable) accuracy. A key to this effect is: the proposed SAP encourages the attention-based partition of the (transformer) student to be partially consistent with the semantic-based teacher partition through knowledge distillation, yielding the so-called semi-attention. Such partial consistency allows the student to have both consistency and reasonable conflict with the noisy teacher. More specifically, on the one hand, the attention is guided by the semantic partition from the teacher. On the other hand, the attention mechanism itself still has some degree of freedom to comply with the inherent similarity between different patches, thus gaining resistance against noisy supervision. Moreover, we integrate a battery of well-engineered designs into SAP to reinforce their cooperation (e.g., multiple forms of teacher-student consistency), as well as to promote reasonable conflict (e.g., mutual absorbing partition refinement and a supervision signal dropout strategy). Experimental results confirm that the transformer student achieves substantial improvement after this semi-attention learning scheme, and produces new state-of-the-art accuracy on several standard re-ID benchmarks",
    "checked": true,
    "id": "810862a848aa164ad7e0611ee4b850d6d28f4a1a",
    "semantic_title": "semi-attention partition for occluded person re-identification",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25181": {
    "title": "Fast Online Hashing with Multi-Label Projection",
    "volume": "main",
    "abstract": "Hashing has been widely researched to solve the large-scale approximate nearest neighbor search problem owing to its time and storage superiority. In recent years, a number of online hashing methods have emerged, which can update the hash functions to adapt to the new stream data and realize dynamic retrieval. However, existing online hashing methods are required to update the whole database with the latest hash functions when a query arrives, which leads to low retrieval efficiency with the continuous increase of the stream data. On the other hand, these methods ignore the supervision relationship among the examples, especially in the multi-label case. In this paper, we propose a novel Fast Online Hashing (FOH) method which only updates the binary codes of a small part of the database. To be specific, we first build a query pool in which the nearest neighbors of each central point are recorded. When a new query arrives, only the binary codes of the corresponding potential neighbors are updated. In addition, we create a similarity matrix which takes the multi-label supervision information into account and bring in the multi-label projection loss to further preserve the similarity among the multi-label data. The experimental results on two common benchmarks show that the proposed FOH can achieve dramatic superiority on query time up to 6.28 seconds less than state-of-the-art baselines with competitive retrieval accuracy",
    "checked": true,
    "id": "0f98d2bd7a791f0eaea7aab20496a2b5efa0ed44",
    "semantic_title": "fast online hashing with multi-label projection",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25182": {
    "title": "Fourier-Net: Fast Image Registration with Band-Limited Deformation",
    "volume": "main",
    "abstract": "Unsupervised image registration commonly adopts U-Net style networks to predict dense displacement fields in the full-resolution spatial domain. For high-resolution volumetric image data, this process is however resource-intensive and time-consuming. To tackle this problem, we propose the Fourier-Net, replacing the expansive path in a U-Net style network with a parameter-free model-driven decoder. Specifically, instead of our Fourier-Net learning to output a full-resolution displacement field in the spatial domain, we learn its low-dimensional representation in a band-limited Fourier domain. This representation is then decoded by our devised model-driven decoder (consisting of a zero padding layer and an inverse discrete Fourier transform layer) to the dense, full-resolution displacement field in the spatial domain. These changes allow our unsupervised Fourier-Net to contain fewer parameters and computational operations, resulting in faster inference speeds. Fourier-Net is then evaluated on two public 3D brain datasets against various state-of-the-art approaches. For example, when compared to a recent transformer-based method, named TransMorph, our Fourier-Net, which only uses 2.2% of its parameters and 6.66% of the multiply-add operations, achieves a 0.5% higher Dice score and an 11.48 times faster inference speed. Code is available at https://github.com/xi-jia/Fourier-Net",
    "checked": true,
    "id": "743c723118ee61e2e5cc7161247c272522d8cdd5",
    "semantic_title": "fourier-net: fast image registration with band-limited deformation",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25183": {
    "title": "Semi-supervised Deep Large-Baseline Homography Estimation with Progressive Equivalence Constraint",
    "volume": "main",
    "abstract": "Homography estimation is erroneous in the case of large-baseline due to the low image overlay and limited receptive field. To address it, we propose a progressive estimation strategy by converting large-baseline homography into multiple intermediate ones, cumulatively multiplying these intermediate items can reconstruct the initial homography. Meanwhile, a semi-supervised homography identity loss, which consists of two components: a supervised objective and an unsupervised objective, is introduced. The first supervised loss is acting to optimize intermediate homographies, while the second unsupervised one helps to estimate a large-baseline homography without photometric losses. To validate our method, we propose a large-scale dataset that covers regular and challenging scenes. Experiments show that our method achieves state-of-the-art performance in large-baseline scenes while keeping competitive performance in small-baseline scenes. Code and dataset are available at https://github.com/megvii-research/LBHomo",
    "checked": true,
    "id": "a96f76cc868630a74b758951f5206e9f7e670e83",
    "semantic_title": "semi-supervised deep large-baseline homography estimation with progressive equivalence constraint",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25184": {
    "title": "Multi-Modality Deep Network for Extreme Learned Image Compression",
    "volume": "main",
    "abstract": "Image-based single-modality compression learning approaches have demonstrated exceptionally powerful encoding and decoding capabilities in the past few years , but suffer from blur and severe semantics loss at extremely low bitrates. To address this issue, we propose a multimodal machine learning method for text-guided image compression, in which the semantic information of text is used as prior information to guide image compression for better compression performance. We fully study the role of text description in different components of the codec, and demonstrate its effectiveness. In addition, we adopt the image-text attention module and image-request complement module to better fuse image and text features, and propose an improved multimodal semantic-consistent loss to produce semantically complete reconstructions. Extensive experiments, including a user study, prove that our method can obtain visually pleasing results at extremely low bitrates, and achieves a comparable or even better performance than state-of-the-art methods, even though these methods are at 2x to 4x bitrates of ours",
    "checked": true,
    "id": "fcbe9b439f1f694d79a3e788a3a4e2ce4655219a",
    "semantic_title": "multi-modality deep network for extreme learned image compression",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25185": {
    "title": "PolarFormer: Multi-Camera 3D Object Detection with Polar Transformer",
    "volume": "main",
    "abstract": "3D object detection in autonomous driving aims to reason \"what\" and \"where\" the objects of interest present in a 3D world. Following the conventional wisdom of previous 2D object detection, existing methods often adopt the canonical Cartesian coordinate system with perpendicular axis. However, we conjugate that this does not fit the nature of the ego car's perspective, as each onboard camera perceives the world in shape of wedge intrinsic to the imaging geometry with radical (non perpendicular) axis. Hence, in this paper we advocate the exploitation of the Polar coordinate system and propose a new Polar Transformer (PolarFormer) for more accurate 3D object detection in the bird's-eye-view (BEV) taking as input only multi-camera 2D images. Specifically, we design a cross-attention based Polar detection head without restriction to the shape of input structure to deal with irregular Polar grids. For tackling the unconstrained object scale variations along Polar's distance dimension, we further introduce a multi-scale Polar representation learning strategy. As a result, our model can make best use of the Polar representation rasterized via attending to the corresponding image observation in a sequence-to-sequence fashion subject to the geometric constraints. Thorough experiments on the nuScenes dataset demonstrate that our PolarFormer outperforms significantly state-of-the-art 3D object detection alternatives",
    "checked": false,
    "id": "67a3e04199baad91ecf25b55f294f54b173c052b",
    "semantic_title": "polarformer: multi-camera 3d object detection with polar transformers",
    "citation_count": 61
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25186": {
    "title": "3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation",
    "volume": "main",
    "abstract": "Text-guided 3D object generation aims to generate 3D objects described by user-defined captions, which paves a flexible way to visualize what we imagined. Although some works have been devoted to solving this challenging task, these works either utilize some explicit 3D representations (e.g., mesh), which lack texture and require post-processing for rendering photo-realistic views; or require individual time-consuming optimization for every single case. Here, we make the first attempt to achieve generic text-guided cross-category 3D object generation via a new 3D-TOGO model, which integrates a text-to-views generation module and a views-to-3D generation module. The text-to-views generation module is designed to generate different views of the target 3D object given an input caption. prior-guidance, caption-guidance and view contrastive learning are proposed for achieving better view-consistency and caption similarity. Meanwhile, a pixelNeRF model is adopted for the views-to-3D generation module to obtain the implicit 3D neural representation from the previously-generated views. Our 3D-TOGO model generates 3D objects in the form of the neural radiance field with good texture and requires no time-cost optimization for every single caption. Besides, 3D-TOGO can control the category, color and shape of generated 3D objects with the input caption. Extensive experiments on the largest 3D object dataset (i.e., ABO) are conducted to verify that 3D-TOGO can better generate high-quality 3D objects according to the input captions across 98 different categories, in terms of PSNR, SSIM, LPIPS and CLIP-score, compared with text-NeRF and Dreamfields",
    "checked": true,
    "id": "378eda76558011610d1f803f543a4c57cb5d6608",
    "semantic_title": "3d-togo: towards text-guided cross-category 3d object generation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25187": {
    "title": "FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer",
    "volume": "main",
    "abstract": "Recent work has explored the potential to adapt a pre-trained vision transformer (ViT) by updating only a few parameters so as to improve storage efficiency, called parameter-efficient transfer learning (PETL). Current PETL methods have shown that by tuning only 0.5% of the parameters, ViT can be adapted to downstream tasks with even better performance than full fine-tuning. In this paper, we aim to further promote the efficiency of PETL to meet the extreme storage constraint in real-world applications. To this end, we propose a tensorization-decomposition framework to store the weight increments, in which the weights of each ViT are tensorized into a single 3D tensor, and their increments are then decomposed into lightweight factors. In the fine-tuning process, only the factors need to be updated and stored, termed Factor-Tuning (FacT). On VTAB-1K benchmark, our method performs on par with NOAH, the state-of-the-art PETL method, while being 5x more parameter-efficient. We also present a tiny version that only uses 8K (0.01% of ViT's parameters) trainable parameters but outperforms full fine-tuning and many other PETL methods such as VPT and BitFit. In few-shot settings, FacT also beats all PETL baselines using the fewest parameters, demonstrating its strong capability in the low-data regime",
    "checked": true,
    "id": "e835e50b4c067cec7457332ec119994fb1a26422",
    "semantic_title": "fact: factor-tuning for lightweight adaptation on vision transformer",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25188": {
    "title": "Estimating Reflectance Layer from a Single Image: Integrating Reflectance Guidance and Shadow/Specular Aware Learning",
    "volume": "main",
    "abstract": "Estimating the reflectance layer from a single image is a challenging task. It becomes more challenging when the input image contains shadows or specular highlights, which often render an inaccurate estimate of the reflectance layer. Therefore, we propose a two-stage learning method, including reflectance guidance and a Shadow/Specular-Aware (S-Aware) network to tackle the problem. In the first stage, an initial reflectance layer free from shadows and specularities is obtained with the constraint of novel losses that are guided by prior-based shadow-free and specular-free images. To further enforce the reflectance layer to be independent of shadows and specularities in the second-stage refinement, we introduce an S-Aware network that distinguishes the reflectance image from the input image. Our network employs a classifier to categorize shadow/shadow-free, specular/specular-free classes, enabling the activation features to function as attention maps that focus on shadow/specular regions. Our quantitative and qualitative evaluations show that our method outperforms the state-of-the-art methods in the reflectance layer estimation that is free from shadows and specularities",
    "checked": true,
    "id": "d3054551f9f9dfd8d49d029e16b0d27f46990826",
    "semantic_title": "estimating reflectance layer from a single image: integrating reflectance guidance and shadow/specular aware learning",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25189": {
    "title": "Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection",
    "volume": "main",
    "abstract": "Temporal Activity Detection aims to predict activity classes per frame, in contrast to video-level predictions in Activity Classification (i.e., Activity Recognition). Due to the expensive frame-level annotations required for detection, the scale of detection datasets is limited. Thus, commonly, previous work on temporal activity detection resorts to fine-tuning a classification model pretrained on large-scale classification datasets (e.g., Kinetics-400). However, such pretrained models are not ideal for downstream detection, due to the disparity between the pretraining and the downstream fine-tuning tasks. In this work, we propose a novel weakly-guided self-supervised pretraining method for detection. We leverage weak labels (classification) to introduce a self-supervised pretext task (detection) by generating frame-level pseudo labels, multi-action frames, and action segments. Simply put, we design a detection task similar to downstream, on large-scale classification data, without extra annotations. We show that the models pretrained with the proposed weakly-guided self-supervised detection task outperform prior work on multiple challenging activity detection benchmarks, including Charades and MultiTHUMOS. Our extensive ablations further provide insights on when and how to use the proposed models for activity detection. Code is available at github.com/kkahatapitiya/SSDet",
    "checked": true,
    "id": "cb7e9e6a68f64972cb42fc790c3a755175b80828",
    "semantic_title": "weakly-guided self-supervised pretraining for temporal activity detection",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25190": {
    "title": "Correlation Loss: Enforcing Correlation between Classification and Localization",
    "volume": "main",
    "abstract": "Object detectors are conventionally trained by a weighted sum of classification and localization losses. Recent studies (e.g., predicting IoU with an auxiliary head, Generalized Focal Loss, Rank & Sort Loss) have shown that forcing these two loss terms to interact with each other in non-conventional ways creates a useful inductive bias and improves performance. Inspired by these works, we focus on the correlation between classification and localization and make two main contributions: (i) We provide an analysis about the effects of correlation between classification and localization tasks in object detectors. We identify why correlation affects the performance of various NMS-based and NMS-free detectors, and we devise measures to evaluate the effect of correlation and use them to analyze common detectors. (ii) Motivated by our observations, e.g., that NMS-free detectors can also benefit from correlation, we propose Correlation Loss, a novel plug-in loss function that improves the performance of various object detectors by directly optimizing correlation coefficients: E.g., Correlation Loss on Sparse R-CNN, an NMS-free method, yields 1.6 AP gain on COCO and 1.8 AP gain on Cityscapes dataset. Our best model on Sparse R-CNN reaches 51.0 AP without test-time augmentation on COCO test-dev, reaching state-of-the-art. Code is available at: https://github.com/fehmikahraman/CorrLoss",
    "checked": true,
    "id": "448224d5629a2d3ab1571811a2d183189f424376",
    "semantic_title": "correlation loss: enforcing correlation between classification and localization",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25191": {
    "title": "GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps",
    "volume": "main",
    "abstract": "Data augmentation is now an essential part of the image training process, as it effectively prevents overfitting and makes the model more robust against noisy datasets. Recent mixing augmentation strategies have advanced to generate the mixup mask that can enrich the saliency information, which is a supervisory signal. However, these methods incur a significant computational burden to optimize the mixup mask. From this motivation, we propose a novel saliency-aware mixup method, GuidedMixup, which aims to retain the salient regions in mixup images with low computational overhead. We develop an efficient pairing algorithm that pursues to minimize the conflict of salient regions of paired images and achieve rich saliency in mixup images. Moreover, GuidedMixup controls the mixup ratio for each pixel to better preserve the salient region by interpolating two paired images smoothly. The experiments on several datasets demonstrate that GuidedMixup provides a good trade-off between augmentation overhead and generalization performance on classification datasets. In addition, our method shows good performance in experiments with corrupted or reduced datasets",
    "checked": true,
    "id": "8ddb147c006cdeae6cd38f458e9c7c337d5b0965",
    "semantic_title": "guidedmixup: an efficient mixup strategy guided by saliency maps",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25192": {
    "title": "3D Human Pose Lifting with Grid Convolution",
    "volume": "main",
    "abstract": "Existing lifting networks for regressing 3D human poses from 2D single-view poses are typically constructed with linear layers based on graph-structured representation learning. In sharp contrast to them, this paper presents Grid Convolution (GridConv), mimicking the wisdom of regular convolution operations in image space. GridConv is based on a novel Semantic Grid Transformation (SGT) which leverages a binary assignment matrix to map the irregular graph-structured human pose onto a regular weave-like grid pose representation joint by joint, enabling layer-wise feature learning with GridConv operations. We provide two ways to implement SGT, including handcrafted and learnable designs. Surprisingly, both designs turn out to achieve promising results and the learnable one is better, demonstrating the great potential of this new lifting representation learning formulation. To improve the ability of GridConv to encode contextual cues, we introduce an attention module over the convolutional kernel, making grid convolution operations input-dependent, spatial-aware and grid-specific. We show that our fully convolutional grid lifting network outperforms state-of-the-art methods with noticeable margins under (1) conventional evaluation on Human3.6M and (2) cross-evaluation on MPI-INF-3DHP. Code is available at https://github.com/OSVAI/GridConv",
    "checked": true,
    "id": "eab5282e937a9b09b3af8c0956f1aa09ff20cfa9",
    "semantic_title": "3d human pose lifting with grid convolution",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25193": {
    "title": "Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation",
    "volume": "main",
    "abstract": "Mixup provides interpolated training samples and allows the model to obtain smoother decision boundaries for better generalization. The idea can be naturally applied to the domain adaptation task, where we can mix the source and target samples to obtain domain-mixed samples for better adaptation. However, the extension of the idea from classification to segmentation (i.e., structured output) is nontrivial. This paper systematically studies the impact of mixup under the domain adaptive semantic segmentation task and presents a simple yet effective mixup strategy called Bidirectional Domain Mixup (BDM). In specific, we achieve domain mixup in two-step: cut and paste. Given the warm-up model trained from any adaptation techniques, we forward the source and target samples and perform a simple threshold-based cut out of the unconfident regions (cut). After then, we fill-in the dropped regions with the other domain region patches (paste). In doing so, we jointly consider class distribution, spatial structure, and pseudo label confidence. Based on our analysis, we found that BDM leaves domain transferable regions by cutting, balances the dataset-level class distribution while preserving natural scene context by pasting. We coupled our proposal with various state-of-the-art adaptation models and observe significant improvement consistently. We also provide extensive ablation experiments to empirically verify our main components of the framework. Visit our project page with the code at https://sites.google.com/view/bidirectional-domain-mixup",
    "checked": true,
    "id": "a3577255e136a2c38198ac240cec2921bd739cde",
    "semantic_title": "bidirectional domain mixup for domain adaptive semantic segmentation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25194": {
    "title": "Frequency Selective Augmentation for Video Representation Learning",
    "volume": "main",
    "abstract": "Recent self-supervised video representation learning methods focus on maximizing the similarity between multiple augmented views from the same video and largely rely on the quality of generated views. However, most existing methods lack a mechanism to prevent representation learning from bias towards static information in the video. In this paper, we propose frequency augmentation (FreqAug), a spatio-temporal data augmentation method in the frequency domain for video representation learning. FreqAug stochastically removes specific frequency components from the video so that learned representation captures essential features more from the remaining information for various downstream tasks. Specifically, FreqAug pushes the model to focus more on dynamic features rather than static features in the video via dropping spatial or temporal low-frequency components. To verify the generality of the proposed method, we experiment with FreqAug on multiple self-supervised learning frameworks along with standard augmentations. Transferring the improved representation to five video action recognition and two temporal action localization downstream tasks shows consistent improvements over baselines",
    "checked": true,
    "id": "2de0034a889be933b6059f9cfebc4edb35e4ff29",
    "semantic_title": "frequency selective augmentation for video representation learning",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25195": {
    "title": "Pose-Guided 3D Human Generation in Indoor Scene",
    "volume": "main",
    "abstract": "In this work, we address the problem of scene-aware 3D human avatar generation based on human-scene interactions. In particular, we pay attention to the fact that physical contact between a 3D human and a scene (i.e., physical human-scene interactions) requires a geometrical alignment to generate natural 3D human avatar. Motivated by this fact, we present a new 3D human generation framework that considers geometric alignment on potential contact areas between 3D human avatars and their surroundings. In addition, we introduce a compact yet effective human pose classifier that classifies the human pose and provides potential contact areas of the 3D human avatar. It allows us to adaptively use geometric alignment loss according to the classified human pose. Compared to state-of-the-art method, our method can generate physically and semantically plausible 3D humans that interact naturally with 3D scenes without additional post-processing. In our evaluations, we achieve the improvements with more plausible interactions and more variety of poses than prior research in qualitative and quantitative analysis. Project page: https://bupyeonghealer.github.io/phin/",
    "checked": true,
    "id": "b60488cb4048b89121c0f50508c473bb8527d518",
    "semantic_title": "pose-guided 3d human generation in indoor scene",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25196": {
    "title": "Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Weakly-supervised semantic segmentation aims to train a semantic segmentation network using weak labels. Among weak labels, image-level label has been the most popular choice due to its simplicity. However, since image-level labels lack accurate object region information, additional modules such as saliency detector have been exploited in weakly supervised semantic segmentation, which requires pixel-level label for training. In this paper, we explore a self-supervised vision transformer to mitigate the heavy efforts on generation of pixel-level annotations. By exploiting the features obtained from self-supervised vision transformer, our superpixel discovery method finds out the semantic-aware superpixels based on the feature similarity in an unsupervised manner. Once we obtain the superpixels, we train the semantic segmentation network using superpixel-guided seeded region growing method. Despite its simplicity, our approach achieves the competitive result with the state-of-the-arts on PASCAL VOC 2012 and MS-COCO 2014 semantic segmentation datasets for weakly supervised semantic segmentation. Our code is available at https://github.com/st17kim/semantic-aware-superpixel",
    "checked": true,
    "id": "edf262d8983ca2ee80f6196365f8bf5e225603c5",
    "semantic_title": "semantic-aware superpixel for weakly supervised semantic segmentation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25197": {
    "title": "Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films",
    "volume": "main",
    "abstract": "Multispectral object detection plays a vital role in safety-critical vision systems that require an around-the-clock operation and encounter dynamic real-world situations(e.g., self-driving cars and autonomous surveillance systems). Despite its crucial competence in safety-related applications, its security against physical attacks is severely understudied. We investigate the vulnerability of multispectral detectors against physical attacks by proposing a new physical method: Multispectral Invisible Coating. Utilizing transparent Low-e films, we realize a laminated visible-thermal physical attack by attaching Low-e films over a visible attack printing. Moreover, we apply our physical method to manufacture a Multispectral Invisible Suit that hides persons from the multiple view angles of Multispectral detectors. To simulate our attack under various surveillance scenes, we constructed a large-scale multispectral pedestrian dataset which we will release in public. Extensive experiments show that our proposed method effectively attacks the state-of-the-art multispectral detector both in the digital space and the physical world",
    "checked": true,
    "id": "d6d1f02bba8aadc484edfc5becba4a8b91f66343",
    "semantic_title": "multispectral invisible coating: laminated visible-thermal physical attack against multispectral object detectors using transparent low-e films",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25198": {
    "title": "CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer",
    "volume": "main",
    "abstract": "Camera and radar sensors have significant advantages in cost, reliability, and maintenance compared to LiDAR. Existing fusion methods often fuse the outputs of single modalities at the result-level, called the late fusion strategy. This can benefit from using off-the-shelf single sensor detection algorithms, but late fusion cannot fully exploit the complementary properties of sensors, thus having limited performance despite the huge potential of camera-radar fusion. Here we propose a novel proposal-level early fusion approach that effectively exploits both spatial and contextual properties of camera and radar for 3D object detection. Our fusion framework first associates image proposal with radar points in the polar coordinate system to efficiently handle the discrepancy between the coordinate system and spatial properties. Using this as a first stage, following consecutive cross-attention based feature fusion layers adaptively exchange spatio-contextual information between camera and radar, leading to a robust and attentive fusion. Our camera-radar fusion approach achieves the state-of-the-art 41.1% mAP and 52.3% NDS on the nuScenes test set, which is 8.7 and 10.8 points higher than the camera-only baseline, as well as yielding competitive performance on the LiDAR method",
    "checked": true,
    "id": "2a32aec5f06324bd0dabab8a41c97e29a954a21a",
    "semantic_title": "craft: camera-radar 3d object detection with spatio-contextual fusion transformer",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25199": {
    "title": "Simple and Effective Synthesis of Indoor 3D Scenes",
    "volume": "main",
    "abstract": "We study the problem of synthesizing immersive 3D indoor scenes from one or a few images. Our aim is to generate high-resolution images and videos from novel viewpoints, including viewpoints that extrapolate far beyond the input images while maintaining 3D consistency. Existing approaches are highly complex, with many separately trained stages and components. We propose a simple alternative: an image-to-image GAN that maps directly from reprojections of incomplete point clouds to full high-resolution RGB-D images. On the Matterport3D and RealEstate10K datasets, our approach significantly outperforms prior work when evaluated by humans, as well as on FID scores. Further, we show that our model is useful for generative data augmentation. A vision-and-language navigation (VLN) agent trained with trajectories spatially-perturbed by our model improves success rate by up to 1.5% over a state of the art baseline on the mature R2R benchmark. Our code will be made available to facilitate generative data augmentation and applications to downstream robotics and embodied AI tasks",
    "checked": true,
    "id": "749fc01c222e526dab89e9cb4cb280447d7d65fe",
    "semantic_title": "simple and effective synthesis of indoor 3d scenes",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25200": {
    "title": "MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection",
    "volume": "main",
    "abstract": "Most scanning LiDAR sensors generate a sequence of point clouds in real-time. While conventional 3D object detectors use a set of unordered LiDAR points acquired over a fixed time interval, recent studies have revealed that substantial performance improvement can be achieved by exploiting the spatio-temporal context present in a sequence of LiDAR point sets. In this paper, we propose a novel 3D object detection architecture, which can encode LiDAR point cloud sequences acquired by multiple successive scans. The encoding process of the point cloud sequence is performed on two different time scales. We first design a short-term motion-aware voxel encoding that captures the short-term temporal changes of point clouds driven by the motion of objects in each voxel. We also propose long-term motion-guided bird's eye view (BEV) feature enhancement that adaptively aligns and aggregates the BEV feature maps obtained by the short-term voxel encoding by utilizing the dynamic motion context inferred from the sequence of the feature maps. The experiments conducted on the public nuScenes benchmark demonstrate that the proposed 3D object detector offers significant improvements in performance compared to the baseline methods and that it sets a state-of-the-art performance for certain 3D object detection categories. Code is available at https://github.com/HYjhkoh/MGTANet.git",
    "checked": true,
    "id": "a600a57618e4f183ceec850fc9b441dda792728a",
    "semantic_title": "mgtanet: encoding sequential lidar points using long short-term motion-guided temporal attention for 3d object detection",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25201": {
    "title": "InstanceFormer: An Online Video Instance Segmentation Framework",
    "volume": "main",
    "abstract": "Recent transformer-based offline video instance segmentation (VIS) approaches achieve encouraging results and significantly outperform online approaches. However, their reliance on the whole video and the immense computational complexity caused by full Spatio-temporal attention limit them in real-life applications such as processing lengthy videos. In this paper, we propose a single-stage transformer-based efficient online VIS framework named InstanceFormer, which is especially suitable for long and challenging videos. We propose three novel components to model short-term and long-term dependency and temporal coherence. First, we propagate the representation, location, and semantic information of prior instances to model short-term changes. Second, we propose a novel memory cross-attention in the decoder, which allows the network to look into earlier instances within a certain temporal window. Finally, we employ a temporal contrastive loss to impose coherence in the representation of an instance across all frames. Memory attention and temporal coherence are particularly beneficial to long-range dependency modeling, including challenging scenarios like occlusion. The proposed InstanceFormer outperforms previous online benchmark methods by a large margin across multiple datasets. Most importantly, InstanceFormer surpasses offline approaches for challenging and long datasets such as YouTube-VIS-2021 and OVIS. Code is available at https://github.com/rajatkoner08/InstanceFormer",
    "checked": true,
    "id": "7eb8252d603b202c9cd06c338d132b6eecfd35e0",
    "semantic_title": "instanceformer: an online video instance segmentation framework",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25202": {
    "title": "Pixel-Wise Warping for Deep Image Stitching",
    "volume": "main",
    "abstract": "Existing image stitching approaches based on global or local homography estimation are not free from the parallax problem and suffer from undesired artifacts. In this paper, instead of relying on the homography-based warp, we propose a novel deep image stitching framework exploiting the pixel-wise warp field to handle the large-parallax problem. The proposed deep image stitching framework consists of a Pixel-wise Warping Module (PWM) and a Stitched Image Generating Module (SIGMo). For PWM, we obtain pixel-wise warp in a similar manner as estimating an optical flow (OF). In the stitching scenario, the input images usually include non-overlap (NOV) regions of which warp cannot be directly estimated, unlike the overlap (OV) regions. To help the PWM predict a reasonable warp on the NOV region, we impose two geometrical constraints: an epipolar loss and a line-preservation loss. With the obtained warp field, we relocate the pixels of the target image using forward warping. Finally, the SIGMo is trained by the proposed multi-branch training framework to generate a stitched image from a reference image and a warped target image. For training and evaluating the proposed framework, we build and publish a novel dataset including image pairs with corresponding pixel-wise ground truth warp and stitched result images. We show that the results of the proposed framework are quantitatively and qualitatively superior to those of the conventional methods",
    "checked": true,
    "id": "0cc6c9024ae3beb06dfefe7b1e7813ab9a38e954",
    "semantic_title": "pixel-wise warping for deep image stitching",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25203": {
    "title": "Learning to Learn Better for Video Object Segmentation",
    "volume": "main",
    "abstract": "Recently, the joint learning framework (JOINT) integrates matching based transductive reasoning and online inductive learning to achieve accurate and robust semi-supervised video object segmentation (SVOS). However, using the mask embedding as the label to guide the generation of target features in the two branches may result in inadequate target representation and degrade the performance. Besides, how to reasonably fuse the target features in the two different branches rather than simply adding them together to avoid the adverse effect of one dominant branch has not been investigated. In this paper, we propose a novel framework that emphasizes Learning to Learn Better (LLB) target features for SVOS, termed LLB, where we design the discriminative label generation module (DLGM) and the adaptive fusion module to address these issues. Technically, the DLGM takes the background-filtered frame instead of the target mask as input and adopts a lightweight encoder to generate the target features, which serves as the label of the online few-shot learner and the value of the decoder in the transformer to guide the two branches to learn more discriminative target representation. The adaptive fusion module maintains a learnable gate for each branch, which reweighs the element-wise feature representation and allows an adaptive amount of target information in each branch flowing to the fused target feature, thus preventing one branch from being dominant and making the target feature more robust to distractor. Extensive experiments on public benchmarks show that our proposed LLB method achieves state-of-the-art performance",
    "checked": true,
    "id": "b0b7bf6eb268653a35a68e712516493a82b02d0f",
    "semantic_title": "learning to learn better for video object segmentation",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25204": {
    "title": "Curriculum Multi-Negative Augmentation for Debiased Video Grounding",
    "volume": "main",
    "abstract": "Video Grounding (VG) aims to locate the desired segment from a video given a sentence query. Recent studies have found that current VG models are prone to over-rely the groundtruth moment annotation distribution biases in the training set. To discourage the standard VG model's behavior of exploiting such temporal annotation biases and improve the model generalization ability, we propose multiple negative augmentations in a hierarchical way, including cross-video augmentations from clip-/video-level, and self-shuffled augmentations with masks. These augmentations can effectively diversify the data distribution so that the model can make more reasonable predictions instead of merely fitting the temporal biases. However, directly adopting such data augmentation strategy may inevitably carry some noise shown in our cases, since not all of the handcrafted augmentations are semantically irrelevant to the groundtruth video. To further denoise and improve the grounding accuracy, we design a multi-stage curriculum strategy to adaptively train the standard VG model from easy to hard negative augmentations. Experiments on newly collected Charades-CD and ActivityNet-CD datasets demonstrate our proposed strategy can improve the performance of the base model on both i.i.d and o.o.d scenarios",
    "checked": true,
    "id": "235d6337eeb067042eb90c957a4380506a78c7b7",
    "semantic_title": "curriculum multi-negative augmentation for debiased video grounding",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25205": {
    "title": "Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency",
    "volume": "main",
    "abstract": "As manual point-wise label is time and labor-intensive for fully supervised large-scale point cloud semantic segmentation, weakly supervised method is increasingly active. However, existing methods fail to generate high-quality pseudo labels effectively, leading to unsatisfactory results. In this paper, we propose a weakly supervised point cloud semantic segmentation framework via receptive-driven pseudo label consistency and structural consistency to mine potential knowledge. Specifically, we propose three consistency contrains: pseudo label consistency among different scales, semantic structure consistency between intra-class features and class-level relation structure consistency between pair-wise categories. Three consistency constraints are jointly used to effectively prepares and utilizes pseudo labels simultaneously for stable training. Finally, extensive experimental results on three challenging datasets demonstrate that our method significantly outperforms state-of-the-art weakly supervised methods and even achieves comparable performance to the fully supervised methods",
    "checked": true,
    "id": "e0d75d6529e6098461434f5f4b3dbdd28ef29691",
    "semantic_title": "weakly supervised 3d segmentation via receptive-driven pseudo label consistency and structural consistency",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25206": {
    "title": "MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels",
    "volume": "main",
    "abstract": "We tackle the problem of generating long-term 3D human motion from multiple action labels. Two main previous approaches, such as action- and motion-conditioned methods, have limitations to solve this problem. The action-conditioned methods generate a sequence of motion from a single action. Hence, it cannot generate long-term motions composed of multiple actions and transitions between actions. Meanwhile, the motion-conditioned methods generate future motions from initial motion. The generated future motions only depend on the past, so they are not controllable by the user's desired actions. We present MultiAct, the first framework to generate long-term 3D human motion from multiple action labels. MultiAct takes account of both action and motion conditions with a unified recurrent generation system. It repetitively takes the previous motion and action label; then, it generates a smooth transition and the motion of the given action. As a result, MultiAct produces realistic long-term motion controlled by the given sequence of multiple action labels. The code is publicly available in https://github.com/TaeryungLee/MultiAct RELEASE",
    "checked": true,
    "id": "cc5df2954a38581b629ae0e86b8ec90b3af4b3bd",
    "semantic_title": "multiact: long-term 3d human motion generation from multiple action labels",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25207": {
    "title": "Not All Neighbors Matter: Point Distribution-Aware Pruning for 3D Point Cloud",
    "volume": "main",
    "abstract": "Applying deep neural networks to 3D point cloud processing has demonstrated a rapid pace of advancement in those domains where 3D geometry information can greatly boost task performance, such as AR/VR, robotics, and autonomous driving. However, as the size of both the neural network model and 3D point cloud continues to scale, reducing the entailed computation and memory access overhead is a primary challenge to meet strict latency and energy constraints of practical applications. This paper proposes a new weight pruning technique for 3D point cloud based on spatial point distribution. We identify that particular groups of neighborhood voxels in 3D point cloud contribute more frequently to actual output features than others. Based on this observation, we propose to selectively prune less contributing groups of neighborhood voxels first to reduce the computation overhead while minimizing the impact on model accuracy. We apply our proposal to three representative sparse 3D convolution libraries. Our proposal reduces the inference latency by 1.60× on average and energy consumption by 1.74× on NVIDIA GV100 GPU with no loss in accuracy metric",
    "checked": true,
    "id": "5f8a9671d33837ad90a9df091e03360c43fb5cc9",
    "semantic_title": "not all neighbors matter: point distribution-aware pruning for 3d point cloud",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25208": {
    "title": "Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task",
    "volume": "main",
    "abstract": "VQA is an ambitious task aiming to answer any image-related question. However, in reality, it is hard to build such a system once for all since the needs of users are continuously updated, and the system has to implement new functions. Thus, Continual Learning (CL) ability is a must in developing advanced VQA systems. Recently, a pioneer work split a VQA dataset into disjoint answer sets to study this topic. However, CL on VQA involves not only the expansion of label sets (new Answer sets). It is crucial to study how to answer questions when deploying VQA systems to new environments (new Visual scenes) and how to answer questions requiring new functions (new Question types). Thus, we propose CLOVE, a benchmark for Continual Learning On Visual quEstion answering, which contains scene- and function-incremental settings for the two aforementioned CL scenarios. In terms of methodology, the main difference between CL on VQA and classification is that the former additionally involves expanding and preventing forgetting of reasoning mechanisms, while the latter focusing on class representation. Thus, we propose a real-data-free replay-based method tailored for CL on VQA, named Scene Graph as Prompt for Symbolic Replay. Using a piece of scene graph as a prompt, it replays pseudo scene graphs to represent the past images, along with correlated QA pairs. A unified VQA model is also proposed to utilize the current and replayed data to enhance its QA ability. Finally, experimental results reveal challenges in CLOVE and demonstrate the effectiveness of our method. Code and data are available at https://github.com/showlab/CLVQA",
    "checked": true,
    "id": "fc1ed0c94657e9e340a038f02cab7b225704a4b9",
    "semantic_title": "symbolic replay: scene graph as prompt for continual learning on vqa task",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25209": {
    "title": "Linking People across Text and Images Based on Social Relation Reasoning",
    "volume": "main",
    "abstract": "As a sub-task of visual grounding, linking people across text and images aims to localize target people in images with corresponding sentences. Existing approaches tend to capture superficial features of people (e.g., dress and location) that suffer from the incompleteness information across text and images. We observe that humans are adept at exploring social relations to assist identifying people. Therefore, we propose a Social Relation Reasoning (SRR) model to address the aforementioned issues. Firstly, we design a Social Relation Extraction (SRE) module to extract social relations between people in the input sentence. Specially, the SRE module based on zero-shot learning is able to extract social relations even though they are not defined in the existing datasets. A Reasoning based Cross-modal Matching (RCM) module is further used to generate matching matrices by reasoning on the social relations and visual features. Experimental results show that the accuracy of our proposed SRR model outperforms the state-of-the-art models on the challenging datasets Who's Waldo and FL: MSRE, by more than 5\\% and 7\\%, respectively. Our source code is available at https://github.com/VILAN-Lab/SRR",
    "checked": true,
    "id": "5d0b66ca3fec08cf52d56a375aada4a1360af49e",
    "semantic_title": "linking people across text and images based on social relation reasoning",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25210": {
    "title": "ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing",
    "volume": "main",
    "abstract": "The StyleGAN family succeed in high-fidelity image generation and allow for flexible and plausible editing of generated images by manipulating the semantic-rich latent style space. However, projecting a real image into its latent space encounters an inherent trade-off between inversion quality and editability. Existing encoder-based or optimization-based StyleGAN inversion methods attempt to mitigate the trade-off but see limited performance. To fundamentally resolve this problem, we propose a novel two-phase framework by designating two separate networks to tackle editing and reconstruction respectively, instead of balancing the two. Specifically, in Phase I, a W-space-oriented StyleGAN inversion network is trained and used to perform image inversion and edit- ing, which assures the editability but sacrifices reconstruction quality. In Phase II, a carefully designed rectifying network is utilized to rectify the inversion errors and perform ideal reconstruction. Experimental results show that our approach yields near-perfect reconstructions without sacrificing the editability, thus allowing accurate manipulation of real images. Further, we evaluate the performance of our rectifying net- work, and see great generalizability towards unseen manipulation types and out-of-domain images",
    "checked": true,
    "id": "ea5e945cde29b61254115d512e9d39fb57a7514c",
    "semantic_title": "reganie: rectifying gan inversion errors for accurate real image editing",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25211": {
    "title": "SWBNet: A Stable White Balance Network for sRGB Images",
    "volume": "main",
    "abstract": "The white balance methods for sRGB images (sRGB-WB) aim to directly remove their color temperature shifts. Despite achieving promising white balance (WB) performance, the existing methods suffer from WB instability, i.e., their results are inconsistent for images with different color temperatures. We propose a stable white balance network (SWBNet) to alleviate this problem. It learns the color temperature-insensitive features to generate white-balanced images, resulting in consistent WB results. Specifically, the color temperatureinsensitive features are learned by implicitly suppressing lowfrequency information sensitive to color temperatures. Then, a color temperature contrastive loss is introduced to facilitate the most information shared among features of the same scene and different color temperatures. This way, features from the same scene are more insensitive to color temperatures regardless of the inputs. We also present a color temperature sensitivity-oriented transformer that globally perceives multiple color temperature shifts within an image and corrects them by different weights. It helps to improve the accuracy of stabilized SWBNet, especially for multiillumination sRGB images. Experiments indicate that our SWBNet achieves stable and remarkable WB performance",
    "checked": true,
    "id": "9ba6d7080c349fba2d29fe42357639b00d5cb2cb",
    "semantic_title": "swbnet: a stable white balance network for srgb images",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25212": {
    "title": "Frequency Domain Disentanglement for Arbitrary Neural Style Transfer",
    "volume": "main",
    "abstract": "Arbitrary neural style transfer has been a popular research topic due to its rich application scenarios. Effective disentanglement of content and style is the critical factor for synthesizing an image with arbitrary style. The existing methods focus on disentangling feature representations of content and style in the spatial domain where the content and style components are innately entangled and difficult to be disentangled clearly. Therefore, these methods always suffer from low-quality results because of the sub-optimal disentanglement. To address such a challenge, this paper proposes the frequency mixer (FreMixer) module that disentangles and re-entangles the frequency spectrum of content and style components in the frequency domain. Since content and style components have different frequency-domain characteristics (frequency bands and frequency patterns), the FreMixer could well disentangle these two components. Based on the FreMixer module, we design a novel Frequency Domain Disentanglement (FDD) framework for arbitrary neural style transfer. Qualitative and quantitative experiments verify that the proposed method can render better stylized results compared to the state-of-the-art methods",
    "checked": true,
    "id": "dc21b6d4fe70b99b74acb442e8cf711efabe644c",
    "semantic_title": "frequency domain disentanglement for arbitrary neural style transfer",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25213": {
    "title": "Pose-Oriented Transformer with Uncertainty-Guided Refinement for 2D-to-3D Human Pose Estimation",
    "volume": "main",
    "abstract": "There has been a recent surge of interest in introducing transformers to 3D human pose estimation (HPE) due to their powerful capabilities in modeling long-term dependencies. However, existing transformer-based methods treat body joints as equally important inputs and ignore the prior knowledge of human skeleton topology in the self-attention mechanism. To tackle this issue, in this paper, we propose a Pose-Oriented Transformer (POT) with uncertainty guided refinement for 3D HPE. Specifically, we first develop novel pose-oriented self-attention mechanism and distance-related position embedding for POT to explicitly exploit the human skeleton topology. The pose-oriented self-attention mechanism explicitly models the topological interactions between body joints, whereas the distance-related position embedding encodes the distance of joints to the root joint to distinguish groups of joints with different difficulties in regression. Furthermore, we present an Uncertainty-Guided Refinement Network (UGRN) to refine pose predictions from POT, especially for the difficult joints, by considering the estimated uncertainty of each joint with uncertainty-guided sampling strategy and self-attention mechanism. Extensive experiments demonstrate that our method significantly outperforms the state-of-the-art methods with reduced model parameters on 3D HPE benchmarks such as Human3.6M and MPI-INF-3DHP",
    "checked": true,
    "id": "4cc1b3aecef868c9d56adc4e6d8a1116774faef9",
    "semantic_title": "pose-oriented transformer with uncertainty-guided refinement for 2d-to-3d human pose estimation",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25214": {
    "title": "CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation",
    "volume": "main",
    "abstract": "The limited number of actors and actions in existing datasets make 3D pose estimators tend to overfit, which can be seen from the performance degradation of the algorithm on cross-datasets, especially for rare and complex poses. Although previous data augmentation works have increased the diversity of the training set, the changes in camera viewpoint and position play a dominant role in improving the accuracy of the estimator, while the generated 3D poses are limited and still heavily rely on the source dataset. In addition, these works do not consider the adaptability of the pose estimator to generated data, and complex poses will cause training collapse. In this paper, we propose the CEE-Net, a Complementary End-to-End Network for 3D human pose generation and estimation. The generator extremely expands the distribution of each joint-angle in the existing dataset and limits them to a reasonable range. By learning the correlations within and between the torso and limbs, the estimator can combine different body-parts more effectively and weaken the influence of specific joint-angle changes on the global pose, improving the generalization ability. Extensive ablation studies show that our pose generator greatly strengthens the joint-angle distribution, and our pose estimator can utilize these poses positively. Compared with the state-of-the-art methods, our method can achieve much better performance on various cross-datasets, rare and complex poses",
    "checked": true,
    "id": "09a03bcf681ef763cdbcf69869204230d205d07e",
    "semantic_title": "cee-net: complementary end-to-end network for 3d human pose generation and estimation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25215": {
    "title": "Real-World Deep Local Motion Deblurring",
    "volume": "main",
    "abstract": "Most existing deblurring methods focus on removing global blur caused by camera shake, while they cannot well handle local blur caused by object movements. To fill the vacancy of local deblurring in real scenes, we establish the first real local motion blur dataset (ReLoBlur), which is captured by a synchronized beam-splitting photographing system and corrected by a post-progressing pipeline. Based on ReLoBlur, we propose a Local Blur-Aware Gated network (LBAG) and several local blur-aware techniques to bridge the gap between global and local deblurring: 1) a blur detection approach based on background subtraction to localize blurred regions; 2) a gate mechanism to guide our network to focus on blurred regions; and 3) a blur-aware patch cropping strategy to address data imbalance problem. Extensive experiments prove the reliability of ReLoBlur dataset, and demonstrate that LBAG achieves better performance than state-of-the-art global deblurring methods and our proposed local blur-aware techniques are effective",
    "checked": true,
    "id": "a2c6c426b7f7921a41ba61fedcef8d12e05c32fe",
    "semantic_title": "real-world deep local motion deblurring",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25216": {
    "title": "Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from a Conditional Causal Perspective",
    "volume": "main",
    "abstract": "Few-shot learning models learn representations with limited human annotations, and such a learning paradigm demonstrates practicability in various tasks, e.g., image classification, object detection, etc. However, few-shot object detection methods suffer from an intrinsic defect that the limited training data makes the model cannot sufficiently explore semantic information. To tackle this, we introduce knowledge distillation to the few-shot object detection learning paradigm. We further run a motivating experiment, which demonstrates that in the process of knowledge distillation, the empirical error of the teacher model degenerates the prediction performance of the few-shot object detection model as the student. To understand the reasons behind this phenomenon, we revisit the learning paradigm of knowledge distillation on the few-shot object detection task from the causal theoretic standpoint, and accordingly, develop a Structural Causal Model. Following the theoretical guidance, we propose a backdoor adjustment-based knowledge distillation method for the few-shot object detection task, namely Disentangle and Remerge (D&R), to perform conditional causal intervention toward the corresponding Structural Causal Model. Empirically, the experiments on benchmarks demonstrate that D&R can yield significant performance boosts in few-shot object detection. Code is available at https://github.com/ZYN-1101/DandR.git",
    "checked": true,
    "id": "be2672ba4b68a5ebf69ce7c2f6024bd60f1d75c4",
    "semantic_title": "disentangle and remerge: interventional knowledge distillation for few-shot object detection from a conditional causal perspective",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25217": {
    "title": "Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos",
    "volume": "main",
    "abstract": "Remote photoplethysmography (rPPG) enables non-contact heart rate (HR) estimation from facial videos which gives significant convenience compared with traditional contact-based measurements. In the real-world long-term health monitoring scenario, the distance of the participants and their head movements usually vary by time, resulting in the inaccurate rPPG measurement due to the varying face resolution and complex motion artifacts. Different from the previous rPPG models designed for a constant distance between camera and participants, in this paper, we propose two plug-and-play blocks (i.e., physiological signal feature extraction block (PFE) and temporal face alignment block (TFA)) to alleviate the degradation of changing distance and head motion. On one side, guided with representative-area information, PFE adaptively encodes the arbitrary resolution facial frames to the fixed-resolution facial structure features. On the other side, leveraging the estimated optical flow, TFA is able to counteract the rPPG signal confusion caused by the head movement thus benefit the motion-robust rPPG signal recovery. Besides, we also train the model with a cross-resolution constraint using a two-stream dual-resolution framework, which further helps PFE learn resolution-robust facial rPPG features. Extensive experiments on three benchmark datasets (UBFC-rPPG, COHFACE and PURE) demonstrate the superior performance of the proposed method. One highlight is that with PFE and TFA, the off-the-shelf spatio-temporal rPPG models can predict more robust rPPG signals under both varying face resolution and severe head movement scenarios. The codes are available at https://github.com/LJWGIT/Arbitrary_Resolution_rPPG",
    "checked": true,
    "id": "b6ba44d7412305c1bab39b4b568e2e8492f9c9ed",
    "semantic_title": "learning motion-robust remote photoplethysmography through arbitrary resolution videos",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25218": {
    "title": "FSR: A General Frequency-Oriented Framework to Accelerate Image Super-resolution Networks",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) have witnessed remarkable achievement in image super-resolution (SR), and plenty of DNN-based SR models with elaborated network designs have recently been proposed. However, existing methods usually require substantial computations by operating in spatial domain. To address this issue, we propose a general frequency-oriented framework (FSR) to accelerate SR networks by considering data characteristics in frequency domain. Our FSR mainly contains dual feature aggregation module (DFAM) to extract informative features in both spatial and transform domains, followed by a four-path SR-Module with different capacities to super-resolve in the frequency domain. Specifically, DFAM further consists of a transform attention block (TABlock) and a spatial context block (SCBlock) to extract global spectral information and local spatial information, respectively, while SR-Module is a parallel network container that contains four to-be-accelerated branches. Furthermore, we propose an adaptive weight strategy for a trade-off between image details recovery and visual quality. Extensive experiments show that our FSR can save FLOPs by almost 40% while reducing inference time by 50% for other SR methods (e.g., FSRCNN, CARN, SRResNet and RCAN). Code is available at https://github.com/THU-Kingmin/FSR",
    "checked": true,
    "id": "9fa82af8be2e392986ad01984ae74de495efffeb",
    "semantic_title": "fsr: a general frequency-oriented framework to accelerate image super-resolution networks",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25219": {
    "title": "Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing",
    "volume": "main",
    "abstract": "Along with the widespread use of face recognition systems, their vulnerability has become highlighted. While existing face anti-spoofing methods can be generalized between attack types, generic solutions are still challenging due to the diversity of spoof characteristics. Recently, the spoof trace disentanglement framework has shown great potential for coping with both seen and unseen spoof scenarios, but the performance is largely restricted by the single-modal input. This paper focuses on this issue and presents a multi-modal disentanglement model which targetedly learns polysemantic spoof traces for more accurate and robust generic attack detection. In particular, based on the adversarial learning mechanism, a two-stream disentangling network is designed to estimate spoof patterns from the RGB and depth inputs, respectively. In this case, it captures complementary spoofing clues inhering in different attacks. Furthermore, a fusion module is exploited, which recalibrates both representations at multiple stages to promote the disentanglement in each individual modality. It then performs cross-modality aggregation to deliver a more comprehensive spoof trace representation for prediction. Extensive evaluations are conducted on multiple benchmarks, demonstrating that learning polysemantic spoof traces favorably contributes to anti-spoofing with more perceptible and interpretable results",
    "checked": true,
    "id": "20e4132660bf3e93e170c38dc970f5a59fba3d7e",
    "semantic_title": "learning polysemantic spoof trace: a multi-modal disentanglement network for face anti-spoofing",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25220": {
    "title": "Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration",
    "volume": "main",
    "abstract": "Stroke extraction of Chinese characters plays an important role in the field of character recognition and generation. The most existing character stroke extraction methods focus on image morphological features. These methods usually lead to errors of cross strokes extraction and stroke matching due to rarely using stroke semantics and prior information. In this paper, we propose a deep learning-based character stroke extraction method that takes semantic features and prior information of strokes into consideration. This method consists of three parts: image registration-based stroke registration that establishes the rough registration of the reference strokes and the target as prior information; image semantic segmentation-based stroke segmentation that preliminarily separates target strokes into seven categories; and high-precision extraction of single strokes. In the stroke registration, we propose a structure deformable image registration network to achieve structure-deformable transformation while maintaining the stable morphology of single strokes for character images with complex structures. In order to verify the effectiveness of the method, we construct two datasets respectively for calligraphy characters and regular handwriting characters. The experimental results show that our method strongly outperforms the baselines. Code is available at https://github.com/MengLi-l1/StrokeExtraction",
    "checked": true,
    "id": "d98fd91ed23b3ab623a60cd1713382b2163d5ce2",
    "semantic_title": "stroke extraction of chinese character based on deep structure deformable image registration",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25221": {
    "title": "Spatial-Spectral Transformer for Hyperspectral Image Denoising",
    "volume": "main",
    "abstract": "Hyperspectral image (HSI) denoising is a crucial preprocessing procedure for the subsequent HSI applications. Unfortunately, though witnessing the development of deep learning in HSI denoising area, existing convolution-based methods face the trade-off between computational efficiency and capability to model non-local characteristics of HSI. In this paper, we propose a Spatial-Spectral Transformer (SST) to alleviate this problem. To fully explore intrinsic similarity characteristics in both spatial dimension and spectral dimension, we conduct non-local spatial self-attention and global spectral self-attention with Transformer architecture. The window-based spatial self-attention focuses on the spatial similarity beyond the neighboring region. While, the spectral self-attention exploits the long-range dependencies between highly correlative bands. Experimental results show that our proposed method outperforms the state-of-the-art HSI denoising methods in quantitative quality and visual results. The code is released at https://github.com/MyuLi/SST",
    "checked": true,
    "id": "efc12fd00542450f688bc4d8c9fc7db73309c723",
    "semantic_title": "spatial-spectral transformer for hyperspectral image denoising",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25222": {
    "title": "Learning Semantic Alignment with Global Modality Reconstruction for Video-Language Pre-training towards Retrieval",
    "volume": "main",
    "abstract": "Video-language pre-training for text-based video retrieval tasks is vitally important. Previous pre-training methods suffer from the semantic misalignments. The reason is that these methods ignore sequence alignments but focusing on critical token alignment. To alleviate the problem, we propose a video-language pre-training framework, termed videolanguage pre-training For lEarning sEmantic aLignments (FEEL), to learn semantic alignments at the sequence level. Specifically, the global modality reconstruction and the cross- modal self-contrasting method is utilized to learn the alignments at the sequence level better. Extensive experimental results demonstrate the effectiveness of FEEL on text-based video retrieval and text-based video corpus moment retrieval",
    "checked": true,
    "id": "4a17e108c9a99ba9a8db813fecc45b3e651e6a74",
    "semantic_title": "learning semantic alignment with global modality reconstruction for video-language pre-training towards retrieval",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25223": {
    "title": "Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding",
    "volume": "main",
    "abstract": "In this work, we study the problem of Embodied Referring Expression Grounding, where an agent needs to navigate in a previously unseen environment and localize a remote object described by a concise high-level natural language instruction. When facing such a situation, a human tends to imagine what the destination may look like and to explore the environment based on prior knowledge of the environmental layout, such as the fact that a bathroom is more likely to be found near a bedroom than a kitchen. We have designed an autonomous agent called Layout-aware Dreamer (LAD), including two novel modules, that is, the Layout Learner and the Goal Dreamer to mimic this cognitive decision process. The Layout Learner learns to infer the room category distribution of neighboring unexplored areas along the path for coarse layout estimation, which effectively introduces layout common sense of room-to-room transitions to our agent. To learn an effective exploration of the environment, the Goal Dreamer imagines the destination beforehand. Our agent achieves new state-of-the-art performance on the public leaderboard of REVERIE dataset in challenging unseen test environments with improvement on navigation success rate (SR) by 4.02% and remote grounding success (RGS) by 3.43% comparing to previous previous state of the art. The code is released at https://github.com/zehao-wang/LAD",
    "checked": true,
    "id": "0c79bc6ce52539e42985a892e3745822590c2865",
    "semantic_title": "layout-aware dreamer for embodied visual referring expression grounding",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25224": {
    "title": "NeAF: Learning Neural Angle Fields for Point Normal Estimation",
    "volume": "main",
    "abstract": "Normal estimation for unstructured point clouds is an important task in 3D computer vision. Current methods achieve encouraging results by mapping local patches to normal vectors or learning local surface fitting using neural networks. However, these methods are not generalized well to unseen scenarios and are sensitive to parameter settings. To resolve these issues, we propose an implicit function to learn an angle field around the normal of each point in the spherical coordinate system, which is dubbed as Neural Angle Fields (NeAF). Instead of directly predicting the normal of an input point, we predict the angle offset between the ground truth normal and a randomly sampled query normal. This strategy pushes the network to observe more diverse samples, which leads to higher prediction accuracy in a more robust manner. To predict normals from the learned angle fields at inference time, we randomly sample query vectors in a unit spherical space and take the vectors with minimal angle values as the predicted normals. To further leverage the prior learned by NeAF, we propose to refine the predicted normal vectors by minimizing the angle offsets. The experimental results with synthetic data and real scans show significant improvements over the state-of-the-art under widely used benchmarks. Project page: https://lisj575.github.io/NeAF/",
    "checked": true,
    "id": "a765befc5a9f7816a2ae6cf2a911a94ff24c3399",
    "semantic_title": "neaf: learning neural angle fields for point normal estimation",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25225": {
    "title": "CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification without Concrete Text Labels",
    "volume": "main",
    "abstract": "Pre-trained vision-language models like CLIP have recently shown superior performances on various downstream tasks, including image classification and segmentation. However, in fine-grained image re-identification (ReID), the labels are indexes, lacking concrete text descriptions. Therefore, it remains to be determined how such models could be applied to these tasks. This paper first finds out that simply fine-tuning the visual model initialized by the image encoder in CLIP, has already obtained competitive performances in various ReID tasks. Then we propose a two-stage strategy to facilitate a better visual representation. The key idea is to fully exploit the cross-modal description ability in CLIP through a set of learnable text tokens for each ID and give them to the text encoder to form ambiguous descriptions. In the first training stage, image and text encoders from CLIP keep fixed, and only the text tokens are optimized from scratch by the contrastive loss computed within a batch. In the second stage, the ID-specific text tokens and their encoder become static, providing constraints for fine-tuning the image encoder. With the help of the designed loss in the downstream task, the image encoder is able to represent data as vectors in the feature embedding accurately. The effectiveness of the proposed strategy is validated on several datasets for the person or vehicle ReID tasks. Code is available at https://github.com/Syliz517/CLIP-ReID",
    "checked": true,
    "id": "a8adfb137332a61893417609563897abe9307a11",
    "semantic_title": "clip-reid: exploiting vision-language model for image re-identification without concrete text labels",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25226": {
    "title": "DC-Former: Diverse and Compact Transformer for Person Re-identification",
    "volume": "main",
    "abstract": "In person re-identification (ReID) task, it is still challenging to learn discriminative representation by deep learning, due to limited data. Generally speaking, the model will get better performance when increasing the amount of data. The addition of similar classes strengthens the ability of the classifier to identify similar identities, thereby improving the discrimination of representation. In this paper, we propose a Diverse and Compact Transformer (DC-Former) that can achieve a similar effect by splitting embedding space into multiple diverse and compact subspaces. Compact embedding subspace helps model learn more robust and discriminative embedding to identify similar classes. And the fusion of these diverse embeddings containing more fine-grained information can further improve the effect of ReID. Specifically, multiple class tokens are used in vision transformer to represent multiple embedding spaces. Then, a self-diverse constraint (SDC) is applied to these spaces to push them away from each other, which makes each embedding space diverse and compact. Further, a dynamic weight controller (DWC) is further designed for balancing the relative importance among them during training. The experimental results of our method are promising, which surpass previous state-of-the-art methods on several commonly used person ReID benchmarks. Our code is available at https://github.com/ant-research/Diverse-and-Compact-Transformer",
    "checked": true,
    "id": "540dcdf4a4556facf03a6cffed4f23a584f64317",
    "semantic_title": "dc-former: diverse and compact transformer for person re-identification",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25227": {
    "title": "Panoramic Video Salient Object Detection with Ambisonic Audio Guidance",
    "volume": "main",
    "abstract": "Video salient object detection (VSOD), as a fundamental computer vision problem, has been extensively discussed in the last decade. However, all existing works focus on addressing the VSOD problem in 2D scenarios. With the rapid development of VR devices, panoramic videos have been a promising alternative to 2D videos to provide immersive feelings of the real world. In this paper, we aim to tackle the video salient object detection problem for panoramic videos, with their corresponding ambisonic audios. A multimodal fusion module equipped with two pseudo-siamese audio-visual context fusion (ACF) blocks is proposed to effectively conduct audio-visual interaction. The ACF block equipped with spherical positional encoding enables the fusion in the 3D context to capture the spatial correspondence between pixels and sound sources from the equirectangular frames and ambisonic audios. Experimental results verify the effectiveness of our proposed components and demonstrate that our method achieves state-of-the-art performance on the ASOD60K dataset",
    "checked": true,
    "id": "1ecce926a9877bb7512ce4d1101582877e07db12",
    "semantic_title": "panoramic video salient object detection with ambisonic audio guidance",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25228": {
    "title": "LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving",
    "volume": "main",
    "abstract": "Image instance segmentation is a fundamental research topic in autonomous driving, which is crucial for scene understanding and road safety. Advanced learning-based approaches often rely on the costly 2D mask annotations for training. In this paper, we present a more artful framework, LiDAR-guided Weakly Supervised Instance Segmentation (LWSIS), which leverages the off-the-shelf 3D data, i.e., Point Cloud, together with the 3D boxes, as natural weak supervisions for training the 2D image instance segmentation models. Our LWSIS not only exploits the complementary information in multimodal data during training but also significantly reduces the annotation cost of the dense 2D masks. In detail, LWSIS consists of two crucial modules, Point Label Assignment (PLA) and Graph-based Consistency Regularization (GCR). The former module aims to automatically assign the 3D point cloud as 2D point-wise labels, while the atter further refines the predictions by enforcing geometry and appearance consistency of the multimodal data. Moreover, we conduct a secondary instance segmentation annotation on the nuScenes, named nuInsSeg, to encourage further research on multimodal perception tasks. Extensive experiments on the nuInsSeg, as well as the large-scale Waymo, show that LWSIS can substantially improve existing weakly supervised segmentation models by only involving 3D data during training. Additionally, LWSIS can also be incorporated into 3D object detectors like PointPainting to boost the 3D detection performance for free. The code and dataset are available at https://github.com/Serenos/LWSIS",
    "checked": true,
    "id": "e11ee3c730263c6b92c24f1d707ed35626b7e5a1",
    "semantic_title": "lwsis: lidar-guided weakly supervised instance segmentation for autonomous driving",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25229": {
    "title": "Adaptive Texture Filtering for Single-Domain Generalized Segmentation",
    "volume": "main",
    "abstract": "Domain generalization in semantic segmentation aims to alleviate the performance degradation on unseen domains through learning domain-invariant features. Existing methods diversify images in the source domain by adding complex or even abnormal textures to reduce the sensitivity to domain-specific features. However, these approaches depends heavily on the richness of the texture bank and training them can be time-consuming. In contrast to importing textures arbitrarily or augmenting styles randomly, we focus on the single source domain itself to achieve the generalization. In this paper, we present a novel adaptive texture filtering mechanism to suppress the influence of texture without using augmentation, thus eliminating the interference of domain-specific features. Further, we design a hierarchical guidance generalization network equipped with structure-guided enhancement modules, which purpose to learn the domain-invariant generalized knowledge. Extensive experiments together with ablation studies on widely-used datasets are conducted to verify the effectiveness of the proposed model, and reveal its superiority over other state-of-the-art alternatives",
    "checked": true,
    "id": "8d475edd830f150b9a6aa3066524c77913510df8",
    "semantic_title": "adaptive texture filtering for single-domain generalized segmentation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25230": {
    "title": "MEID: Mixture-of-Experts with Internal Distillation for Long-Tailed Video Recognition",
    "volume": "main",
    "abstract": "The long-tailed video recognition problem is especially challenging, as videos tend to be long and untrimmed, and each video may contain multiple classes, causing frame-level class imbalance. The previous method tackles the long-tailed video recognition only through frame-level sampling for class re-balance without distinguishing the frame-level feature representation between head and tail classes. To improve the frame-level feature representation of tail classes, we modulate the frame-level features with an auxiliary distillation loss to reduce the distribution distance between head and tail classes. Moreover, we design a mixture-of-experts framework with two different expert designs, i.e., the first expert with an attention-based classification network handling the original long-tailed distribution, and the second expert dealing with the re-balanced distribution from class-balanced sampling. Notably, in the second expert, we specifically focus on the frames unsolved by the first expert through designing a complementary frame selection module, which inherits the attention weights from the first expert and selects frames with low attention weights, and we also enhance the motion feature representation for these selected frames. To highlight the multi-label challenge in long-tailed video recognition, we create two additional benchmarks based on Charades and CharadesEgo videos with the multi-label property, called CharadesLT and CharadesEgoLT. Extensive experiments are conducted on the existing long-tailed video benchmark VideoLT and the two new benchmarks to verify the effectiveness of our proposed method with state-of-the-art performance. The code and proposed benchmarks are released at https://github.com/VisionLanguageLab/MEID",
    "checked": true,
    "id": "a96fdfacff96f3a4e944849f856752bc374f7bf1",
    "semantic_title": "meid: mixture-of-experts with internal distillation for long-tailed video recognition",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25231": {
    "title": "Gradient Corner Pooling for Keypoint-Based Object Detection",
    "volume": "main",
    "abstract": "Detecting objects as multiple keypoints is an important approach in the anchor-free object detection methods while corner pooling is an effective feature encoding method for corner positioning. The corners of the bounding box are located by summing the feature maps which are max-pooled in the x and y directions respectively by corner pooling. In the unidirectional max pooling operation, the features of the densely arranged objects of the same class are prone to occlusion. To this end, we propose a method named Gradient Corner Pooling. The spatial distance information of objects on the feature map is encoded during the unidirectional pooling process, which effectively alleviates the occlusion of the homogeneous object features. Further, the computational complexity of gradient corner pooling is the same as traditional corner pooling and hence it can be implemented efficiently. Gradient corner pooling obtains consistent improvements for various keypoint-based methods by directly replacing corner pooling. We verify the gradient corner pooling algorithm on the dataset and in real scenarios, respectively. The networks with gradient corner pooling located the corner points earlier in the training process and achieve an average accuracy improvement of 0.2%-1.6% on the MS-COCO dataset. The detectors with gradient corner pooling show better angle adaptability for arrayed objects in the actual scene test",
    "checked": true,
    "id": "2812527625498e4dd256e4ddb0f4a49aeffd2d61",
    "semantic_title": "gradient corner pooling for keypoint-based object detection",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25232": {
    "title": "Towards Real-Time Segmentation on the Edge",
    "volume": "main",
    "abstract": "The research in real-time segmentation mainly focuses on desktop GPUs. However, autonomous driving and many other applications rely on real-time segmentation on the edge, and current arts are far from the goal. In addition, recent advances in vision transformers also inspire us to re-design the network architecture for dense prediction task. In this work, we propose to combine the self attention block with lightweight convolutions to form new building blocks, and employ latency constraints to search an efficient sub-network. We train an MLP latency model based on generated architecture configurations and their latency measured on mobile devices, so that we can predict the latency of subnets during search phase. To the best of our knowledge, we are the first to achieve over 74% mIoU on Cityscapes with semi-real-time inference (over 15 FPS) on mobile GPU from an off-the-shelf phone",
    "checked": true,
    "id": "98b67efc8ca78e7e254a1fa543996b69635aa080",
    "semantic_title": "towards real-time segmentation on the edge",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25233": {
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-View 3D Object Detection",
    "volume": "main",
    "abstract": "In this research, we propose a new 3D object detector with a trustworthy depth estimation, dubbed BEVDepth, for camera-based Bird's-Eye-View~(BEV) 3D object detection. Our work is based on a key observation -- depth estimation in recent approaches is surprisingly inadequate given the fact that depth is essential to camera 3D detection. Our BEVDepth resolves this by leveraging explicit depth supervision. A camera-awareness depth estimation module is also introduced to facilitate the depth predicting capability. Besides, we design a novel Depth Refinement Module to counter the side effects carried by imprecise feature unprojection. Aided by customized Efficient Voxel Pooling and multi-frame mechanism, BEVDepth achieves the new state-of-the-art 60.9% NDS on the challenging nuScenes test set while maintaining high efficiency. For the first time, the NDS score of a camera model reaches 60%. Codes have been released",
    "checked": true,
    "id": "234f0122e0edccba5c91763e800c2f02fe8ae4fe",
    "semantic_title": "bevdepth: acquisition of reliable depth for multi-view 3d object detection",
    "citation_count": 133
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25234": {
    "title": "BEVStereo: Enhancing Depth Estimation in Multi-View 3D Object Detection with Temporal Stereo",
    "volume": "main",
    "abstract": "Restricted by the ability of depth perception, all Multi-view 3D object detection methods fall into the bottleneck of depth accuracy. By constructing temporal stereo, depth estimation is quite reliable in indoor scenarios. However, there are two difficulties in directly integrating temporal stereo into outdoor multi-view 3D object detectors: 1) The construction of temporal stereos for all views results in high computing costs. 2) Unable to adapt to challenging outdoor scenarios. In this study, we propose an effective method for creating temporal stereo by dynamically determining the center and range of the temporal stereo. The most confident center is found using the EM algorithm. Numerous experiments on nuScenes have shown the BEVStereo's ability to deal with complex outdoor scenarios that other stereo-based methods are unable to handle. For the first time, a stereo-based approach shows superiority in scenarios like a static ego vehicle and moving objects. BEVStereo achieves the new state-of-the-art in the camera-only track of nuScenes dataset while maintaining memory efficiency. Codes have been released",
    "checked": true,
    "id": "1285d14bffedcc4362fdd05213fd6ee4ec5ca885",
    "semantic_title": "bevstereo: enhancing depth estimation in multi-view 3d object detection with temporal stereo",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25235": {
    "title": "Learning Single Image Defocus Deblurring with Misaligned Training Pairs",
    "volume": "main",
    "abstract": "By adopting popular pixel-wise loss, existing methods for defocus deblurring heavily rely on well aligned training image pairs. Although training pairs of ground-truth and blurry images are carefully collected, e.g., DPDD dataset, misalignment is inevitable between training pairs, making existing methods possibly suffer from deformation artifacts. In this paper, we propose a joint deblurring and reblurring learning (JDRL) framework for single image defocus deblurring with misaligned training pairs. Generally, JDRL consists of a deblurring module and a spatially invariant reblurring module, by which deblurred result can be adaptively supervised by ground-truth image to recover sharp textures while maintaining spatial consistency with the blurry image. First, in the deblurring module, a bi-directional optical flow-based deformation is introduced to tolerate spatial misalignment between deblurred and ground-truth images. Second, in the reblurring module, deblurred result is reblurred to be spatially aligned with blurry image, by predicting a set of isotropic blur kernels and weighting maps. Moreover, we establish a new single image defocus deblurring (SDD) dataset, further validating our JDRL and also benefiting future research. Our JDRL can be applied to boost defocus deblurring networks in terms of both quantitative metrics and visual quality on DPDD, RealDOF and our SDD datasets",
    "checked": true,
    "id": "b31de933dc82b38a598c1d274fc9ade2d987c0ba",
    "semantic_title": "learning single image defocus deblurring with misaligned training pairs",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25236": {
    "title": "Curriculum Temperature for Knowledge Distillation",
    "volume": "main",
    "abstract": "Most existing distillation methods ignore the flexible role of the temperature in the loss function and fix it as a hyper-parameter that can be decided by an inefficient grid search. In general, the temperature controls the discrepancy between two distributions and can faithfully determine the difficulty level of the distillation task. Keeping a constant temperature, i.e., a fixed level of task difficulty, is usually sub-optimal for a growing student during its progressive learning stages. In this paper, we propose a simple curriculum-based technique, termed Curriculum Temperature for Knowledge Distillation (CTKD), which controls the task difficulty level during the student's learning career through a dynamic and learnable temperature. Specifically, following an easy-to-hard curriculum, we gradually increase the distillation loss w.r.t. the temperature, leading to increased distillation difficulty in an adversarial manner. As an easy-to-use plug-in technique, CTKD can be seamlessly integrated into existing knowledge distillation frameworks and brings general improvements at a negligible additional computation cost. Extensive experiments on CIFAR-100, ImageNet-2012, and MS-COCO demonstrate the effectiveness of our method",
    "checked": true,
    "id": "6ee96ee0d32816658daa507e2228b037768f148b",
    "semantic_title": "curriculum temperature for knowledge distillation",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25237": {
    "title": "Actionness Inconsistency-Guided Contrastive Learning for Weakly-Supervised Temporal Action Localization",
    "volume": "main",
    "abstract": "Weakly-supervised temporal action localization (WTAL) aims to detect action instances given only video-level labels. To address the challenge, recent methods commonly employ a two-branch framework, consisting of a class-aware branch and a class-agnostic branch. In principle, the two branches are supposed to produce the same actionness activation. However, we observe that there are actually many inconsistent activation regions. These inconsistent regions usually contain some challenging segments whose semantic information (action or background) is ambiguous. In this work, we propose a novel Actionness Inconsistency-guided Contrastive Learning (AICL) method which utilizes the consistent segments to boost the representation learning of the inconsistent segments. Specifically, we first define the consistent and inconsistent segments by comparing the predictions of two branches and then construct positive and negative pairs between consistent segments and inconsistent segments for contrastive learning. In addition, to avoid the trivial case where there is no consistent sample, we introduce an action consistency constraint to control the difference between the two branches. We conduct extensive experiments on THUMOS14, ActivityNet v1.2, and ActivityNet v1.3 datasets, and the results show the effectiveness of AICL with state-of-the-art performance. Our code is available at https://github.com/lizhilin-ustc/AAAI2023-AICL",
    "checked": true,
    "id": "fce2e326ec543ef51f6d6e0294ae21d5074320bc",
    "semantic_title": "actionness inconsistency-guided contrastive learning for weakly-supervised temporal action localization",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25238": {
    "title": "READ: Large-Scale Neural Scene Rendering for Autonomous Driving",
    "volume": "main",
    "abstract": "With the development of advanced driver assistance systems~(ADAS) and autonomous vehicles, conducting experiments in various scenarios becomes an urgent need. Although having been capable of synthesizing photo-realistic street scenes, conventional image-to-image translation methods cannot produce coherent scenes due to the lack of 3D information. In this paper, a large-scale neural rendering method is proposed to synthesize the autonomous driving scene~(READ), which makes it possible to generate large-scale driving scenes in real time on a PC through a variety of sampling schemes. In order to effectively represent driving scenarios, we propose an ω-net rendering network to learn neural descriptors from sparse point clouds. Our model can not only synthesize photo-realistic driving scenes but also stitch and edit them. The promising experimental results show that our model performs well in large-scale driving scenarios",
    "checked": true,
    "id": "982236b056edc17962853c7344e5cf43513b474c",
    "semantic_title": "read: large-scale neural scene rendering for autonomous driving",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25239": {
    "title": "CDTA: A Cross-Domain Transfer-Based Attack with Contrastive Learning",
    "volume": "main",
    "abstract": "Despite the excellent performance, deep neural networks (DNNs) have been shown to be vulnerable to adversarial examples. Besides, these examples are often transferable among different models. In other words, the same adversarial example can fool multiple models with different architectures at the same time. Based on this property, many black-box transfer-based attack techniques have been developed. However, current transfer-based attacks generally focus on the cross-architecture setting, where the attacker has access to the training data of the target model, which is not guaranteed in realistic situations. In this paper, we design a Cross-Domain Transfer-Based Attack (CDTA), which works in the cross-domain scenario. In this setting, attackers have no information about the target model, such as its architecture and training data. Specifically, we propose a contrastive spectral training method to train a feature extractor on a source domain (e.g., ImageNet) and use it to craft adversarial examples on target domains (e.g., Oxford 102 Flower). Our method corrupts the semantic information of the benign image by scrambling the outputs of both the intermediate feature layers and the final layer of the feature extractor. We evaluate CDTA with 16 target deep models on four datasets with widely varying styles. The results confirm that, in terms of the attack success rate, our approach can consistently outperform the state-of-the-art baselines by an average of 11.45% across all target models. Our code is available at https://github.com/LiulietLee/CDTA",
    "checked": true,
    "id": "5206aa1f39cdbc90245bab8761375f9159d913a0",
    "semantic_title": "cdta: a cross-domain transfer-based attack with contrastive learning",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25240": {
    "title": "HybridCap: Inertia-Aid Monocular Capture of Challenging Human Motions",
    "volume": "main",
    "abstract": "Monocular 3D motion capture (mocap) is beneficial to many applications. The use of a single camera, however, often fails to handle occlusions of different body parts and hence it is limited to capture relatively simple movements. We present a light-weight, hybrid mocap technique called HybridCap that augments the camera with only 4 Inertial Measurement Units (IMUs) in a novel learning-and-optimization framework. We first employ a weakly-supervised and hierarchical motion inference module based on cooperative pure residual recurrent blocks that serve as limb, body and root trackers as well as an inverse kinematics solver. Our network effectively narrows the search space of plausible motions via coarse-to-fine pose estimation and manages to tackle challenging movements with high efficiency. We further develop a hybrid optimization scheme that combines inertial feedback and visual cues to improve tracking accuracy. Extensive experiments on various datasets demonstrate HybridCap can robustly handle challenging movements ranging from fitness actions to Latin dance. It also achieves real-time performance up to 60 fps with state-of-the-art accuracy",
    "checked": true,
    "id": "15453b482f58c9ef4a2f55f1cfb8872ef7cb7426",
    "semantic_title": "hybridcap: inertia-aid monocular capture of challenging human motions",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25241": {
    "title": "Global Dilated Attention and Target Focusing Network for Robust Tracking",
    "volume": "main",
    "abstract": "Self Attention has shown the excellent performance in tracking due to its global modeling capability. However, it brings two challenges: First, its global receptive field has less attention on local structure and inter-channel associations, which limits the semantics to distinguish objects and backgrounds; Second, its feature fusion with linear process cannot avoid the interference of non-target semantic objects. To solve the above issues, this paper proposes a robust tracking method named GdaTFT by defining the Global Dilated Attention (GDA) and Target Focusing Network (TFN). The GDA provides a new global semantics modeling approach to enhance the semantic objects while eliminating the background. It is defined via the local focusing module, dilated attention and channel adaption module. Thus, it promotes semantics by focusing local key information, building long-range dependencies and enhancing the semantics of channels. Subsequently, to distinguish the target and non-target objects both with rich semantics, the TFN is proposed to accurately focus the target region. Different from the present feature fusion, it uses the template as the query to build a point-to-point correlation between the template and search region, and finally achieves part-level augmentation of target feature in the search region. Thus, the TFN efficiently augments the target embedding while weakening the non-target objects. Experiments on challenging benchmarks (LaSOT, TrackingNet, GOT-10k, OTB-100) demonstrate that the GdaTFT outperforms many state-of-the-art trackers and achieves leading performance. Code will be available",
    "checked": true,
    "id": "d2e10ada5a6ac8442d38117e92508de98f165526",
    "semantic_title": "global dilated attention and target focusing network for robust tracking",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25242": {
    "title": "Only a Few Classes Confusing: Pixel-Wise Candidate Labels Disambiguation for Foggy Scene Understanding",
    "volume": "main",
    "abstract": "Not all semantics become confusing when deploying a semantic segmentation model for real-world scene understanding of adverse weather. The true semantics of most pixels have a high likelihood of appearing in the few top classes according to confidence ranking. In this paper, we replace the one-hot pseudo label with a candidate label set (CLS) that consists of only a few ambiguous classes and exploit its effects on self-training-based unsupervised domain adaptation. Specifically, we formulate the problem as a coarse-to-fine process. In the coarse-level process, adaptive CLS selection is proposed to pick a minimal set of confusing candidate labels based on the reliability of label predictions. Then, representation learning and label rectification are iteratively performed to facilitate feature clustering in an embedding space and to disambiguate the confusing semantics. Experimentally, our method outperforms the state-of-the-art methods on three realistic foggy benchmarks",
    "checked": true,
    "id": "2c4f3efd0e7c9c0e1ce649fea31d7f8836f01293",
    "semantic_title": "only a few classes confusing: pixel-wise candidate labels disambiguation for foggy scene understanding",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25243": {
    "title": "Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation",
    "volume": "main",
    "abstract": "Vision-Language Navigation (VLN) is a challenging task which requires an agent to align complex visual observations to language instructions to reach the goal position. Most existing VLN agents directly learn to align the raw directional features and visual features trained using one-hot labels to linguistic instruction features. However, the big semantic gap among these multi-modal inputs makes the alignment difficult and therefore limits the navigation performance. In this paper, we propose Actional Atomic-Concept Learning (AACL), which maps visual observations to actional atomic concepts for facilitating the alignment. Specifically, an actional atomic concept is a natural language phrase containing an atomic action and an object, e.g., ``go up stairs''. These actional atomic concepts, which serve as the bridge between observations and instructions, can effectively mitigate the semantic gap and simplify the alignment. AACL contains three core components: 1) a concept mapping module to map the observations to the actional atomic concept representations through the VLN environment and the recently proposed Contrastive Language-Image Pretraining (CLIP) model, 2) a concept refining adapter to encourage more instruction-oriented object concept extraction by re-ranking the predicted object concepts by CLIP, and 3) an observation co-embedding module which utilizes concept representations to regularize the observation representations. Our AACL establishes new state-of-the-art results on both fine-grained (R2R) and high-level (REVERIE and R2R-Last) VLN benchmarks. Moreover, the visualization shows that AACL significantly improves the interpretability in action decision. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/VLN-AACL",
    "checked": true,
    "id": "137330d3030f75b01c88c14e1164d9b0d8c2dc70",
    "semantic_title": "actional atomic-concept learning for demystifying vision-language navigation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25244": {
    "title": "Probability Guided Loss for Long-Tailed Multi-Label Image Classification",
    "volume": "main",
    "abstract": "Long-tailed learning has attracted increasing attention in very recent years. Long-tailed multi-label image classification is one subtask and remains challenging and poorly researched. In this paper, we provide a fresh perspective from probability to tackle this problem. More specifically, we find that existing cost-sensitive learning methods for long-tailed multi-label classification will affect the predicted probability of positive and negative labels in varying degrees during training, and different processes of probability will affect the final performance in turn. We thus propose a probability guided loss which contains two components to control this process. One is the probability re-balancing which can flexibly adjust the process of training probability. And the other is the adaptive probability-aware focal which can further reduce the probability gap between positive and negative labels. We conduct extensive experiments on two long-tailed multi-label image classification datasets: VOC-LT and COCO-LT. The results demonstrate the rationality and superiority of our strategy",
    "checked": true,
    "id": "aa528fcfa48fe9333220012501e224cde12040fa",
    "semantic_title": "probability guided loss for long-tailed multi-label image classification",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25245": {
    "title": "Self-Supervised Image Denoising Using Implicit Deep Denoiser Prior",
    "volume": "main",
    "abstract": "We devise a new regularization for denoising with self-supervised learning. The regularization uses a deep image prior learned by the network, rather than a traditional predefined prior. Specifically, we treat the output of the network as a ``prior'' that we again denoise after ``re-noising.'' The network is updated to minimize the discrepancy between the twice-denoised image and its prior. We demonstrate that this regularization enables the network to learn to denoise even if it has not seen any clean images. The effectiveness of our method is based on the fact that CNNs naturally tend to capture low-level image statistics. Since our method utilizes the image prior implicitly captured by the deep denoising CNN to guide denoising, we refer to this training strategy as an Implicit Deep Denoiser Prior (IDDP). IDDP can be seen as a mixture of learning-based methods and traditional model-based denoising methods, in which regularization is adaptively formulated using the output of the network. We apply IDDP to various denoising tasks using only observed corrupted data and show that it achieves better denoising results than other self-supervised denoising methods",
    "checked": true,
    "id": "0753df5be5fabf893ae9604c34c12a0a6233a91c",
    "semantic_title": "self-supervised image denoising using implicit deep denoiser prior",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25246": {
    "title": "Accelerating the Training of Video Super-resolution Models",
    "volume": "main",
    "abstract": "Despite that convolution neural networks (CNN) have recently demonstrated high-quality reconstruction for video super-resolution (VSR), efficiently training competitive VSR models remains a challenging problem. It usually takes an order of magnitude more time than training their counterpart image models, leading to long research cycles. Existing VSR methods typically train models with fixed spatial and temporal sizes from beginning to end. The fixed sizes are usually set to large values for good performance, resulting to slow training. However, is such a rigid training strategy necessary for VSR? In this work, we show that it is possible to gradually train video models from small to large spatial/temporal sizes, \\ie, in an easy-to-hard manner. In particular, the whole training is divided into several stages and the earlier stage has smaller training spatial shape. Inside each stage, the temporal size also varies from short to long while the spatial size remains unchanged. Training is accelerated by such a multigrid training strategy, as most of computation is performed on smaller spatial and shorter temporal shapes. For further acceleration with GPU parallelization, we also investigate the large minibatch training without the loss in accuracy. Extensive experiments demonstrate that our method is capable of largely speeding up training (up to $6.2\\times$ speedup in wall-clock training time) without performance drop for various VSR models",
    "checked": true,
    "id": "060bac73d0c6cab65b91f77364645a0afe142d38",
    "semantic_title": "accelerating the training of video super-resolution models",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25247": {
    "title": "SelectAugment: Hierarchical Deterministic Sample Selection for Data Augmentation",
    "volume": "main",
    "abstract": "Data augmentation (DA) has been extensively studied to facilitate model optimization in many tasks. Prior DA works focus on designing augmentation operations themselves, while leaving selecting suitable samples for augmentation out of consideration. This might incur visual ambiguities and further induce training biases. In this paper, we propose an effective approach, dubbed SelectAugment, to select samples for augmentation in a deterministic and online manner based on the sample contents and the network training status. To facilitate the policy learning, in each batch, we exploit the hierarchy of this task by first determining the augmentation ratio and then deciding whether to augment each training sample under this ratio. We model this process as two-step decision-making and adopt Hierarchical Reinforcement Learning (HRL) to learn the selection policy. In this way, the negative effects of the randomness in selecting samples to augment can be effectively alleviated and the effectiveness of DA is improved. Extensive experiments demonstrate that our proposed SelectAugment significantly improves various off-the-shelf DA methods on image classification and fine-grained image recognition",
    "checked": true,
    "id": "44f4975b026c7c9ab934ead385afae080b20d66b",
    "semantic_title": "selectaugment: hierarchical deterministic sample selection for data augmentation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25248": {
    "title": "AdaCM: Adaptive ColorMLP for Real-Time Universal Photo-Realistic Style Transfer",
    "volume": "main",
    "abstract": "Photo-realistic style transfer aims at migrating the artistic style from an exemplar style image to a content image, producing a result image without spatial distortions or unrealistic artifacts. Impressive results have been achieved by recent deep models. However, deep neural network based methods are too expensive to run in real-time. Meanwhile, bilateral grid based methods are much faster but still contain artifacts like overexposure. In this work, we propose the Adaptive ColorMLP (AdaCM), an effective and efficient framework for universal photo-realistic style transfer. First, we find the complex non-linear color mapping between input and target domain can be efficiently modeled by a small multi-layer perceptron (ColorMLP) model. Then, in AdaCM, we adopt a CNN encoder to adaptively predict all parameters for the ColorMLP conditioned on each input content and style image pair. Experimental results demonstrate that AdaCM can generate vivid and high-quality stylization results. Meanwhile, our AdaCM is ultrafast and can process a 4K resolution image in 6ms on one V100 GPU",
    "checked": true,
    "id": "0b19b1569f783fc4252deb5128889b5b466afefc",
    "semantic_title": "adacm: adaptive colormlp for real-time universal photo-realistic style transfer",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25249": {
    "title": "SEPT: Towards Scalable and Efficient Visual Pre-training",
    "volume": "main",
    "abstract": "Recently, the self-supervised pre-training paradigm has shown great potential in leveraging large-scale unlabeled data to improve downstream task performance. However, increasing the scale of unlabeled pre-training data in real-world scenarios requires prohibitive computational costs and faces the challenge of uncurated samples. To address these issues, we build a task-specific self-supervised pre-training framework from a data selection perspective based on a simple hypothesis that pre-training on the unlabeled samples with similar distribution to the target task can bring substantial performance gains. Buttressed by the hypothesis, we propose the first yet novel framework for Scalable and Efficient visual Pre-Training (SEPT) by introducing a retrieval pipeline for data selection. SEPT first leverage a self-supervised pre-trained model to extract the features of the entire unlabeled dataset for retrieval pipeline initialization. Then, for a specific target task, SEPT retrievals the most similar samples from the unlabeled dataset based on feature similarity for each target instance for pre-training. Finally, SEPT pre-trains the target model with the selected unlabeled samples in a self-supervised manner for target data finetuning. By decoupling the scale of pre-training and available upstream data for a target task, SEPT achieves high scalability of the upstream dataset and high efficiency of pre-training, resulting in high model architecture flexibility. Results on various downstream tasks demonstrate that SEPT can achieve competitive or even better performance compared with ImageNet pre-training while reducing the size of training samples by one magnitude without resorting to any extra annotations",
    "checked": true,
    "id": "53169794d50f7541ea4a93417443751ed76a2009",
    "semantic_title": "sept: towards scalable and efficient visual pre-training",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25250": {
    "title": "Cross-Modality Earth Mover's Distance for Visible Thermal Person Re-identification",
    "volume": "main",
    "abstract": "Visible thermal person re-identification (VT-ReID) suffers from inter-modality discrepancy and intra-identity variations. Distribution alignment is a popular solution for VT-ReID, however, it is usually restricted to the influence of the intra-identity variations. In this paper, we propose the Cross-Modality Earth Mover's Distance (CM-EMD) that can alleviate the impact of the intra-identity variations during modality alignment. CM-EMD selects an optimal transport strategy and assigns high weights to pairs that have a smaller intra-identity variation. In this manner, the model will focus on reducing the inter-modality discrepancy while paying less attention to intra-identity variations, leading to a more effective modality alignment. Moreover, we introduce two techniques to improve the advantage of CM-EMD. First, Cross-Modality Discrimination Learning (CM-DL) is designed to overcome the discrimination degradation problem caused by modality alignment. By reducing the ratio between intra-identity and inter-identity variances, CM-DL leads the model to learn more discriminative representations. Second, we construct the Multi-Granularity Structure (MGS), enabling us to align modalities from both coarse- and fine-grained levels with the proposed CM-EMD. Extensive experiments show the benefits of the proposed CM-EMD and its auxiliary techniques (CM-DL and MGS). Our method achieves state-of-the-art performance on two VT-ReID benchmarks",
    "checked": true,
    "id": "e511d05b03a4d6d3ba9c02ec1e1dbf00794ff81e",
    "semantic_title": "cross-modality earth mover's distance for visible thermal person re-identification",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25251": {
    "title": "Hypotheses Tree Building for One-Shot Temporal Sentence Localization",
    "volume": "main",
    "abstract": "Given an untrimmed video, temporal sentence localization (TSL) aims to localize a specific segment according to a given sentence query. Though respectable works have made decent achievements in this task, they severely rely on dense video frame annotations, which require a tremendous amount of human effort to collect. In this paper, we target another more practical and challenging setting: one-shot temporal sentence localization (one-shot TSL), which learns to retrieve the query information among the entire video with only one annotated frame. Particularly, we propose an effective and novel tree-structure baseline for one-shot TSL, called Multiple Hypotheses Segment Tree (MHST), to capture the query-aware discriminative frame-wise information under the insufficient annotations. Each video frame is taken as the leaf-node, and the adjacent frames sharing the same visual-linguistic semantics will be merged into the upper non-leaf node for tree building. At last, each root node is an individual segment hypothesis containing the consecutive frames of its leaf-nodes. During the tree construction, we also introduce a pruning strategy to eliminate the interference of query-irrelevant nodes. With our designed self-supervised loss functions, our MHST is able to generate high-quality segment hypotheses for ranking and selection with the query. Experiments on two challenging datasets demonstrate that MHST achieves competitive performance compared to existing methods",
    "checked": true,
    "id": "d0bfac78dbab5f4318e1a065d6de413ba8ce24ed",
    "semantic_title": "hypotheses tree building for one-shot temporal sentence localization",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25252": {
    "title": "The Devil Is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-training",
    "volume": "main",
    "abstract": "The self-supervised Masked Image Modeling (MIM) schema, following \"mask-and-reconstruct\" pipeline of recovering contents from masked image, has recently captured the increasing interest in the community, owing to the excellent ability of learning visual representation from unlabeled data. Aiming at learning representations with high semantics abstracted, a group of works attempts to reconstruct non-semantic pixels with large-ratio masking strategy, which may suffer from \"over-smoothing\" problem, while others directly infuse semantics into targets in off-line way requiring extra data. Different from them, we shift the perspective to the Fourier domain which naturally has global perspective and present a new Masked Image Modeling (MIM), termed Geminated Gestalt Autoencoder (Ge^2-AE) for visual pre-training. Specifically, we equip our model with geminated decoders in charge of reconstructing image contents from both pixel and frequency space, where each other serves as not only the complementation but also the reciprocal constraints. Through this way, more robust representations can be learned in the pre-trained encoders, of which the effectiveness is confirmed by the juxtaposing experimental results on downstream recognition tasks. We also conduct several quantitative and qualitative experiments to investigate the learning behavior of our method. To our best knowledge, this is the first MIM work to solve the visual pre-training through the lens of frequency domain",
    "checked": true,
    "id": "3ab64c8e9e05fd2426d6cc51f16d931279b862df",
    "semantic_title": "the devil is in the frequency: geminated gestalt autoencoder for self-supervised visual pre-training",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25253": {
    "title": "M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities",
    "volume": "main",
    "abstract": "Multimodal magnetic resonance imaging (MRI) provides complementary information for sub-region analysis of brain tumors. Plenty of methods have been proposed for automatic brain tumor segmentation using four common MRI modalities and achieved remarkable performance. In practice, however, it is common to have one or more modalities missing due to image corruption, artifacts, acquisition protocols, allergy to contrast agents, or simply cost. In this work, we propose a novel two-stage framework for brain tumor segmentation with missing modalities. In the first stage, a multimodal masked autoencoder (M3AE) is proposed, where both random modalities (i.e., modality dropout) and random patches of the remaining modalities are masked for a reconstruction task, for self-supervised learning of robust multimodal representations against missing modalities. To this end, we name our framework M3AE. Meanwhile, we employ model inversion to optimize a representative full-modal image at marginal extra cost, which will be used to substitute for the missing modalities and boost performance during inference. Then in the second stage, a memory-efficient self distillation is proposed to distill knowledge between heterogenous missing-modal situations while fine-tuning the model for supervised segmentation. Our M3AE belongs to the ‘catch-all' genre where a single model can be applied to all possible subsets of modalities, thus is economic for both training and deployment. Extensive experiments on BraTS 2018 and 2020 datasets demonstrate its superior performance to existing state-of-the-art methods with missing modalities, as well as the efficacy of its components. Our code is available at: https://github.com/ccarliu/m3ae",
    "checked": true,
    "id": "0f61187d734d9dfc7cdbb5e0c8ecb6e0a2f70c85",
    "semantic_title": "m3ae: multimodal representation learning for brain tumor segmentation with missing modalities",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25254": {
    "title": "From Coarse to Fine: Hierarchical Pixel Integration for Lightweight Image Super-resolution",
    "volume": "main",
    "abstract": "Image super-resolution (SR) serves as a fundamental tool for the processing and transmission of multimedia data. Recently, Transformer-based models have achieved competitive performances in image SR. They divide images into fixed-size patches and apply self-attention on these patches to model long-range dependencies among pixels. However, this architecture design is originated for high-level vision tasks, which lacks design guideline from SR knowledge. In this paper, we aim to design a new attention block whose insights are from the interpretation of Local Attribution Map (LAM) for SR networks. Specifically, LAM presents a hierarchical importance map where the most important pixels are located in a fine area of a patch and some less important pixels are spread in a coarse area of the whole image. To access pixels in the coarse area, instead of using a very large patch size, we propose a lightweight Global Pixel Access (GPA) module that applies cross-attention with the most similar patch in an image. In the fine area, we use an Intra-Patch Self-Attention (IPSA) module to model long-range pixel dependencies in a local patch, and then a spatial convolution is applied to process the finest details. In addition, a Cascaded Patch Division (CPD) strategy is proposed to enhance perceptual quality of recovered images. Extensive experiments suggest that our method outperforms state-of-the-art lightweight SR methods by a large margin. Code is available at https://github.com/passerer/HPINet",
    "checked": true,
    "id": "f56ed9f1ca57d3fb73dd6a08c101119e278c3f65",
    "semantic_title": "from coarse to fine: hierarchical pixel integration for lightweight image super-resolution",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25255": {
    "title": "Fast Fluid Simulation via Dynamic Multi-Scale Gridding",
    "volume": "main",
    "abstract": "Recent works on learning-based frameworks for Lagrangian (i.e., particle-based) fluid simulation, though bypassing iterative pressure projection via efficient convolution operators, are still time-consuming due to excessive amount of particles. To address this challenge, we propose a dynamic multi-scale gridding method to reduce the magnitude of elements that have to be processed, by observing repeated particle motion patterns within certain consistent regions. Specifically, we hierarchically generate multi-scale micelles in Euclidean space by grouping particles that share similar motion patterns/characteristics based on super-light motion and scale estimation modules. With little internal motion variation, each micelle is modeled as a single rigid body with convolution only applied to a single representative particle. In addition, a distance-based interpolation is conducted to propagate relative motion message among micelles. With our efficient design, the network produces high visual fidelity fluid simulations with the inference time to be only 4.24 ms/frame (with 6K fluid particles), hence enables real-time human-computer interaction and animation. Experimental results on multiple datasets show that our work achieves great simulation acceleration with negligible prediction error increase",
    "checked": true,
    "id": "91c3eea164d6c32dd00647594f3ca3be21030a0d",
    "semantic_title": "fast fluid simulation via dynamic multi-scale gridding",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25256": {
    "title": "TransLO: A Window-Based Masked Point Transformer Framework for Large-Scale LiDAR Odometry",
    "volume": "main",
    "abstract": "Recently, transformer architecture has gained great success in the computer vision community, such as image classification, object detection, etc. Nonetheless, its application for 3D vision remains to be explored, given that point cloud is inherently sparse, irregular, and unordered. Furthermore, existing point transformer frameworks usually feed raw point cloud of N×3 dimension into transformers, which limits the point processing scale because of their quadratic computational costs to the input size N. In this paper, we rethink the structure of point transformer. Instead of directly applying transformer to points, our network (TransLO) can process tens of thousands of points simultaneously by projecting points onto a 2D surface and then feeding them into a local transformer with linear complexity. Specifically, it is mainly composed of two components: Window-based Masked transformer with Self Attention (WMSA) to capture long-range dependencies; Masked Cross-Frame Attention (MCFA) to associate two frames and predict pose estimation. To deal with the sparsity issue of point cloud, we propose a binary mask to remove invalid and dynamic points. To our knowledge, this is the first transformer-based LiDAR odometry network. The experiment results on the KITTI odometry dataset show that our average rotation and translation RMSE achieves 0.500°/100m and 0.993% respectively. The performance of our network surpasses all recent learning-based methods and even outperforms LOAM on most evaluation sequences.Codes will be released on https://github.com/IRMVLab/TransLO",
    "checked": true,
    "id": "792798d7cfde416beedcae70cd5b5a92c4ab2737",
    "semantic_title": "translo: a window-based masked point transformer framework for large-scale lidar odometry",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25257": {
    "title": "Low-Light Video Enhancement with Synthetic Event Guidance",
    "volume": "main",
    "abstract": "Low-light video enhancement (LLVE) is an important yet challenging task with many applications such as photographing and autonomous driving. Unlike single image low-light enhancement, most LLVE methods utilize temporal information from adjacent frames to restore the color and remove the noise of the target frame. However, these algorithms, based on the framework of multi-frame alignment and enhancement, may produce multi-frame fusion artifacts when encountering extreme low light or fast motion. In this paper, inspired by the low latency and high dynamic range of events, we use synthetic events from multiple frames to guide the enhancement and restoration of low-light videos. Our method contains three stages: 1) event synthesis and enhancement, 2) event and image fusion, and 3) low-light enhancement. In this framework, we design two novel modules (event-image fusion transform and event-guided dual branch) for the second and third stages, respectively. Extensive experiments show that our method outperforms existing low-light video or single image enhancement approaches on both synthetic and real LLVE datasets. Our code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/LLVE-SEG",
    "checked": true,
    "id": "15837a406a4f6859ca89b1cbbd7b391464164195",
    "semantic_title": "low-light video enhancement with synthetic event guidance",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25258": {
    "title": "Novel Motion Patterns Matter for Practical Skeleton-Based Action Recognition",
    "volume": "main",
    "abstract": "Most skeleton-based action recognition methods assume that the same type of action samples in the training set and the test set share similar motion patterns. However, action samples in real scenarios usually contain novel motion patterns which are not involved in the training set. As it is laborious to collect sufficient training samples to enumerate various types of novel motion patterns, this paper presents a practical skeleton-based action recognition task where the training set contains common motion patterns of action samples and the test set contains action samples that suffer from novel motion patterns. For this task, we present a Mask Graph Convolutional Network (Mask-GCN) to focus on learning action-specific skeleton joints that mainly convey action information meanwhile masking action-agnostic skeleton joints that convey rare action information and suffer more from novel motion patterns. Specifically, we design a policy network to learn layer-wise body masks to construct masked adjacency matrices, which guide a GCN-based backbone to learn stable yet informative action features from dynamic graph structure. Extensive experiments on our newly collected dataset verify that Mask-GCN outperforms most GCN-based methods when testing with various novel motion patterns",
    "checked": true,
    "id": "6a841c4254d8d95ef69abb365087ef3544ad0f82",
    "semantic_title": "novel motion patterns matter for practical skeleton-based action recognition",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25259": {
    "title": "EMEF: Ensemble Multi-Exposure Image Fusion",
    "volume": "main",
    "abstract": "Although remarkable progress has been made in recent years, current multi-exposure image fusion (MEF) research is still bounded by the lack of real ground truth, objective evaluation function, and robust fusion strategy. In this paper, we study the MEF problem from a new perspective. We don't utilize any synthesized ground truth, design any loss function, or develop any fusion strategy. Our proposed method EMEF takes advantage of the wisdom of multiple imperfect MEF contributors including both conventional and deep learning-based methods. Specifically, EMEF consists of two main stages: pre-train an imitator network and tune the imitator in the runtime. In the first stage, we make a unified network imitate different MEF targets in a style modulation way. In the second stage, we tune the imitator network by optimizing the style code, in order to find an optimal fusion result for each input pair. In the experiment, we construct EMEF from four state-of-the-art MEF methods and then make comparisons with the individuals and several other competitive methods on the latest released MEF benchmark dataset. The promising experimental results demonstrate that our ensemble framework can \"get the best of all worlds\". The code is available at https://github.com/medalwill/EMEF",
    "checked": true,
    "id": "7e8af97164df4a203f39f6d19c17d9b58952d93d",
    "semantic_title": "emef: ensemble multi-exposure image fusion",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25260": {
    "title": "Reducing Domain Gap in Frequency and Spatial Domain for Cross-Modality Domain Adaptation on Medical Image Segmentation",
    "volume": "main",
    "abstract": "Unsupervised domain adaptation (UDA) aims to learn a model trained on source domain and performs well on unlabeled target domain. In medical image segmentation field, most existing UDA methods depend on adversarial learning to address the domain gap between different image modalities, which is ineffective due to its complicated training process. In this paper, we propose a simple yet effective UDA method based on frequency and spatial domain transfer under multi-teacher distillation framework. In the frequency domain, we first introduce non-subsampled contourlet transform for identifying domain-invariant and domain-variant frequency components (DIFs and DVFs), and then keep the DIFs unchanged while replacing the DVFs of the source domain images with that of the target domain images to narrow the domain gap. In the spatial domain, we propose a batch momentum update-based histogram matching strategy to reduce the domain-variant image style bias. Experiments on two commonly used cross-modality medical image segmentation datasets show that our proposed method achieves superior performance compared to state-of-the-art methods",
    "checked": true,
    "id": "ea10d0a86d0989d97088964d9dfb3f3dbc34daa2",
    "semantic_title": "reducing domain gap in frequency and spatial domain for cross-modality domain adaptation on medical image segmentation",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25261": {
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding",
    "volume": "main",
    "abstract": "In this paper, we study the problem of visual grounding by considering both phrase extraction and grounding (PEG). In contrast to the previous phrase-known-at-test setting, PEG requires a model to extract phrases from text and locate objects from image simultaneously, which is a more practical setting in real applications. As phrase extraction can be regarded as a 1D text segmentation problem, we formulate PEG as a dual detection problem and propose a novel DQ-DETR model, which introduces dual queries to probe different features from image and text for object prediction and phrase mask prediction. Each pair of dual queries are designed to have shared positional parts but different content parts. Such a design effectively alleviates the difficulty of modality alignment between image and text (in contrast to a single query design) and empowers Transformer decoder to leverage phrase mask-guided attention to improve the performance. To evaluate the performance of PEG, we also propose a new metric CMAP (cross-modal average precision), analogous to the AP metric in object detection. The new metric overcomes the ambiguity of Recall@1 in many-box-to-one-phrase cases in phrase grounding. As a result, our PEG pre-trained DQ-DETR establishes new state-of-the-art results on all visual grounding benchmarks with a ResNet-101 backbone. For example, it achieves 91.04% and 83.51% in terms of recall rate on RefCOCO testA and testB with a ResNet-101 backbone",
    "checked": true,
    "id": "19ddeaf042fa00814a459e12d03f15801551e423",
    "semantic_title": "dq-detr: dual query detection transformer for phrase extraction and grounding",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25262": {
    "title": "Progressive Neighborhood Aggregation for Semantic Segmentation Refinement",
    "volume": "main",
    "abstract": "Multi-scale features from backbone networks have been widely applied to recover object details in segmentation tasks. Generally, the multi-level features are fused in a certain manner for further pixel-level dense prediction. Whereas, the spatial structure information is not fully explored, that is similar nearby pixels can be used to complement each other. In this paper, we investigate a progressive neighborhood aggregation (PNA) framework to refine the semantic segmentation prediction, resulting in an end-to-end solution that can perform the coarse prediction and refinement in a unified network. Specifically, we first present a neighborhood aggregation module, the neighborhood similarity matrices for each pixel are estimated on multi-scale features, which are further used to progressively aggregate the high-level feature for recovering the spatial structure. In addition, to further integrate the high-resolution details into the aggregated feature, we apply a self-aggregation module on the low-level features to emphasize important semantic information for complementing losing spatial details. Extensive experiments on five segmentation datasets, including Pascal VOC 2012, CityScapes, COCO-Stuff 10k, DeepGlobe, and Trans10k, demonstrate that the proposed framework can be cascaded into existing segmentation models providing consistent improvements. In particular, our method achieves new state-of-the-art performances on two challenging datasets, DeepGlobe and Trans10k. The code is available at https://github.com/liutinglt/PNA",
    "checked": true,
    "id": "2be38731ed22dbb6ee0ad425fe09f3dc89c856d3",
    "semantic_title": "progressive neighborhood aggregation for semantic segmentation refinement",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25263": {
    "title": "CoordFill: Efficient High-Resolution Image Inpainting via Parameterized Coordinate Querying",
    "volume": "main",
    "abstract": "Image inpainting aims to fill the missing hole of the input. It is hard to solve this task efficiently when facing high-resolution images due to two reasons: (1) Large reception field needs to be handled for high-resolution image inpainting. (2) The general encoder and decoder network synthesizes many background pixels synchronously due to the form of the image matrix. In this paper, we try to break the above limitations for the first time thanks to the recent development of continuous implicit representation. In detail, we down-sample and encode the degraded image to produce the spatial-adaptive parameters for each spatial patch via an attentional Fast Fourier Convolution (FFC)-based parameter generation network. Then, we take these parameters as the weights and biases of a series of multi-layer perceptron (MLP), where the input is the encoded continuous coordinates and the output is the synthesized color value. Thanks to the proposed structure, we only encode the high-resolution image in a relatively low resolution for larger reception field capturing. Then, the continuous position encoding will be helpful to synthesize the photo-realistic high-frequency textures by re-sampling the coordinate in a higher resolution. Also, our framework enables us to query the coordinates of missing pixels only in parallel, yielding a more efficient solution than the previous methods. Experiments show that the proposed method achieves real-time performance on the 2048X2048 images using a single GTX 2080 Ti GPU and can handle 4096X4096 images, with much better performance than existing state-of-the-art methods visually and numerically. The code is available at: https://github.com/NiFangBaAGe/CoordFill",
    "checked": true,
    "id": "bbefdde6de6e100794448eadd2de8fc01f147d27",
    "semantic_title": "coordfill: efficient high-resolution image inpainting via parameterized coordinate querying",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25264": {
    "title": "CCQ: Cross-Class Query Network for Partially Labeled Organ Segmentation",
    "volume": "main",
    "abstract": "Learning multi-organ segmentation from multiple partially-labeled datasets attracts increasing attention. It can be a promising solution for the scarcity of large-scale, fully labeled 3D medical image segmentation datasets. However, existing algorithms of multi-organ segmentation on partially-labeled datasets neglect the semantic relations and anatomical priors between different categories of organs, which is crucial for partially-labeled multi-organ segmentation. In this paper, we tackle the limitations above by proposing the Cross-Class Query Network (CCQ). CCQ consists of an image encoder, a cross-class query learning module, and an attentive refinement segmentation module. More specifically, the image encoder captures the long-range dependency of a single image via the transformer encoder. Cross-class query learning module first generates query vectors that represent semantic concepts of different categories and then utilizes these query vectors to find the class-relevant features of image representation for segmentation. The attentive refinement segmentation module with an attentive skip connection incorporates the high-resolution image details and eliminates the class-irrelevant noise. Extensive experiment results demonstrate that CCQ outperforms all the state-of-the-art models on the MOTS dataset, which consists of seven organ and tumor segmentation tasks. Code is available at https://github.com/Yang-007/CCQ.git",
    "checked": true,
    "id": "1f27fa335b4be16de2e43b765f9dcc97ace8dfff",
    "semantic_title": "ccq: cross-class query network for partially labeled organ segmentation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25265": {
    "title": "Counterfactual Dynamics Forecasting – a New Setting of Quantitative Reasoning",
    "volume": "main",
    "abstract": "Rethinking and introspection are important elements of human intelligence. To mimic these capabilities, counterfactual reasoning has attracted attention of AI researchers recently, which aims to forecast the alternative outcomes for hypothetical scenarios (\"what-if\"). However, most existing approaches focused on qualitative reasoning (e.g., casual-effect relationship). It lacks a well-defined description of the differences between counterfactuals and facts, as well as how these differences evolve over time. This paper defines a new problem formulation - counterfactual dynamics forecasting - which is described in middle-level abstraction under the structural causal models (SCM) framework and derived as ordinary differential equations (ODEs) as low-level quantitative computation. Based on it, we propose a method to infer counterfactual dynamics considering the factual dynamics as demonstration. Moreover, the evolution of differences between facts and counterfactuals are modelled by an explicit temporal component. The experimental results on two dynamical systems demonstrate the effectiveness of the proposed method",
    "checked": false,
    "id": "6cb1a49f248413f851eb6c345a2006aca8e96192",
    "semantic_title": "counterfactual dynamics forecasting - a new setting of quantitative reasoning",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25266": {
    "title": "Self-Decoupling and Ensemble Distillation for Efficient Segmentation",
    "volume": "main",
    "abstract": "Knowledge distillation (KD) is a promising teacher-student learning paradigm that transfers information from a cumbersome teacher to a student network. To avoid the training cost of a large teacher network, the recent studies propose to distill knowledge from the student itself, called Self-KD. However, due to the limitations of the performance and capacity of the student, the soft-labels or features distilled by the student barely provide reliable guidance. Moreover, most of the Self-KD algorithms are specific to classification tasks based on soft-labels, and not suitable for semantic segmentation. To alleviate these contradictions, we revisit the label and feature distillation problem in segmentation, and propose Self-Decoupling and Ensemble Distillation for Efficient Segmentation (SDES). Specifically, we design a decoupled prediction ensemble distillation (DPED) algorithm that generates reliable soft-labels with multiple expert decoders, and a decoupled feature ensemble distillation (DFED) mechanism to utilize more important channel-wise feature maps for encoder learning. The extensive experiments on three public segmentation datasets demonstrate the superiority of our approach and the efficacy of each component in the framework through the ablation study",
    "checked": true,
    "id": "6b192a0023f769edb31dc191fcc9210318c558df",
    "semantic_title": "self-decoupling and ensemble distillation for efficient segmentation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25267": {
    "title": "Token Mixing: Parameter-Efficient Transfer Learning from Image-Language to Video-Language",
    "volume": "main",
    "abstract": "Applying large scale pre-trained image-language model to video-language tasks has recently become a trend, which brings two challenges. One is how to effectively transfer knowledge from static images to dynamic videos, and the other is how to deal with the prohibitive cost of fully fine-tuning due to growing model size. Existing works that attempt to realize parameter-efficient image-language to video-language transfer learning can be categorized into two types: 1) appending a sequence of temporal transformer blocks after the 2D Vision Transformer (ViT), and 2) inserting a temporal block into the ViT architecture. While these two types of methods only require fine-tuning the newly added components, there are still many parameters to update, and they are only validated on a single video-language task. In this work, based on our analysis of the core ideas of different temporal modeling components in existing approaches, we propose a token mixing strategy to enable cross-frame interactions, which enables transferring from the pre-trained image-language model to video-language tasks through selecting and mixing a key set and a value set from the input video samples. As token mixing does not require the addition of any components or modules, we can directly partially fine-tune the pre-trained image-language model to achieve parameter-efficiency. We carry out extensive experiments to compare our proposed token mixing method with other parameter-efficient transfer learning methods. Our token mixing method outperforms other methods on both understanding tasks and generation tasks. Besides, our method achieves new records on multiple video-language tasks. The code is available at https://github.com/yuqi657/video_language_model",
    "checked": true,
    "id": "5fcb5889e7c716b2493da67b63179cb0034c0c66",
    "semantic_title": "token mixing: parameter-efficient transfer learning from image-language to video-language",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25268": {
    "title": "StereoDistill: Pick the Cream from LiDAR for Distilling Stereo-Based 3D Object Detection",
    "volume": "main",
    "abstract": "In this paper, we propose a cross-modal distillation method named StereoDistill to narrow the gap between the stereo and LiDAR-based approaches via distilling the stereo detectors from the superior LiDAR model at the response level, which is usually overlooked in 3D object detection distillation. The key designs of StereoDistill are: the X-component Guided Distillation~(XGD) for regression and the Cross-anchor Logit Distillation~(CLD) for classification. In XGD, instead of empirically adopting a threshold to select the high-quality teacher predictions as soft targets, we decompose the predicted 3D box into sub-components and retain the corresponding part for distillation if the teacher component pilot is consistent with ground truth to largely boost the number of positive predictions and alleviate the mimicking difficulty of the student model. For CLD, we aggregate the probability distribution of all anchors at the same position to encourage the highest probability anchor rather than individually distill the distribution at the anchor level. Finally, our StereoDistill achieves state-of-the-art results for stereo-based 3D detection on the KITTI test benchmark and extensive experiments on KITTI and Argoverse Dataset validate the effectiveness",
    "checked": true,
    "id": "628766d52767f8c872047708a21cc0c320366715",
    "semantic_title": "stereodistill: pick the cream from lidar for distilling stereo-based 3d object detection",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25269": {
    "title": "Good Helper Is around You: Attention-Driven Masked Image Modeling",
    "volume": "main",
    "abstract": "It has been witnessed that masked image modeling (MIM) has shown a huge potential in self-supervised learning in the past year. Benefiting from the universal backbone vision transformer, MIM learns self-supervised visual representations through masking a part of patches of the image while attempting to recover the missing pixels. Most previous works mask patches of the image randomly, which underutilizes the semantic information that is beneficial to visual representation learning. On the other hand, due to the large size of the backbone, most previous works have to spend much time on pre-training. In this paper, we propose Attention-driven Masking and Throwing Strategy (AMT), which could solve both problems above. We first leverage the self-attention mechanism to obtain the semantic information of the image during the training process automatically without using any supervised methods. Masking strategy can be guided by that information to mask areas selectively, which is helpful for representation learning. Moreover, a redundant patch throwing strategy is proposed, which makes learning more efficient. As a plug-and-play module for masked image modeling, AMT improves the linear probing accuracy of MAE by 2.9% ~ 5.9% on CIFAR-10/100, STL-10, Tiny ImageNet, and ImageNet-1K, and obtains an improved performance with respect to fine-tuning accuracy of MAE and SimMIM. Moreover, this design also achieves superior performance on downstream detection and segmentation tasks",
    "checked": true,
    "id": "c58af37caedda1af6833209ef6b384d350743ffd",
    "semantic_title": "good helper is around you: attention-driven masked image modeling",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25270": {
    "title": "RADIANT: Radar-Image Association Network for 3D Object Detection",
    "volume": "main",
    "abstract": "As a direct depth sensor, radar holds promise as a tool to improve monocular 3D object detection, which suffers from depth errors, due in part to the depth-scale ambiguity. On the other hand, leveraging radar depths is hampered by difficulties in precisely associating radar returns with 3D estimates from monocular methods, effectively erasing its benefits. This paper proposes a fusion network that addresses this radar-camera association challenge. We train our network to predict the 3D offsets between radar returns and object centers, enabling radar depths to enhance the accuracy of 3D monocular detection. By using parallel radar and camera backbones, our network fuses information at both the feature level and detection level, while at the same time leveraging a state-of-the-art monocular detection technique without retraining it. Experimental results show significant improvement in mean average precision and translation error on the nuScenes dataset over monocular counterparts. Our source code is available at https://github.com/longyunf/radiant",
    "checked": true,
    "id": "9968d3c8e3b099e02f7e57ab8aeee0f95a781fdc",
    "semantic_title": "radiant: radar-image association network for 3d object detection",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25271": {
    "title": "CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation via Centrifugal Reference Frame",
    "volume": "main",
    "abstract": "Various recent methods attempt to implement rotation-invariant 3D deep learning by replacing the input coordinates of points with relative distances and angles. Due to the incompleteness of these low-level features, they have to undertake the expense of losing global information. In this paper, we propose the CRIN, namely Centrifugal Rotation-Invariant Network. CRIN directly takes the coordinates of points as input and transforms local points into rotation-invariant representations via centrifugal reference frames. Aided by centrifugal reference frames, each point corresponds to a discrete rotation so that the information of rotations can be implicitly stored in point features. Unfortunately, discrete points are far from describing the whole rotation space. We further introduce a continuous distribution for 3D rotations based on points. Furthermore, we propose an attention-based down-sampling strategy to sample points invariant to rotations. A relation module is adopted at last for reinforcing the long-range dependencies between sampled points and predicts the anchor point for unsupervised rotation estimation. Extensive experiments show that our method achieves rotation invariance, accurately estimates the object rotation, and obtains state-of-the-art results on rotation-augmented classification and part segmentation. Ablation studies validate the effectiveness of the network design",
    "checked": true,
    "id": "45ea3b4f2e53eaa4fb57ea679646848c48d489eb",
    "semantic_title": "crin: rotation-invariant point cloud analysis and rotation estimation via centrifugal reference frame",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25272": {
    "title": "See Your Emotion from Gait Using Unlabeled Skeleton Data",
    "volume": "main",
    "abstract": "This paper focuses on contrastive learning for gait-based emotion recognition. The existing contrastive learning approaches are rarely suitable for learning skeleton-based gait representations, which suffer from limited gait diversity and inconsistent semantics. In this paper, we propose a Cross-coordinate contrastive learning framework utilizing Ambiguity samples for self-supervised Gait-based Emotion representation (CAGE). First, we propose ambiguity transform to push positive samples into ambiguous semantic space. By learning similarities between ambiguity samples and positive samples, our model can learn higher-level semantics of the gait sequences and maintain semantic diversity. Second, to encourage learning the semantic invariance, we uniquely propose cross-coordinate contrastive learning between the Cartesian coordinate and the Spherical coordinate, which brings rich supervisory signals to learn the intrinsic semantic consistency information. Exhaustive experiments show that CAGE improves existing self-supervised methods by 5%–10% accuracy, and it achieves comparable or even superior performance to supervised methods",
    "checked": true,
    "id": "42683c65f41540177c08642aa635bce8d567537f",
    "semantic_title": "see your emotion from gait using unlabeled skeleton data",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25273": {
    "title": "Learning Progressive Modality-Shared Transformers for Effective Visible-Infrared Person Re-identification",
    "volume": "main",
    "abstract": "Visible-Infrared Person Re-Identification (VI-ReID) is a challenging retrieval task under complex modality changes. Existing methods usually focus on extracting discriminative visual features while ignoring the reliability and commonality of visual features between different modalities. In this paper, we propose a novel deep learning framework named Progressive Modality-shared Transformer (PMT) for effective VI-ReID. To reduce the negative effect of modality gaps, we first take the gray-scale images as an auxiliary modality and propose a progressive learning strategy. Then, we propose a Modality-Shared Enhancement Loss (MSEL) to guide the model to explore more reliable identity information from modality-shared features. Finally, to cope with the problem of large intra-class differences and small inter-class differences, we propose a Discriminative Center Loss (DCL) combined with the MSEL to further improve the discrimination of reliable features. Extensive experiments on SYSU-MM01 and RegDB datasets show that our proposed framework performs better than most state-of-the-art methods. For model reproduction, we release the source code at https://github.com/hulu88/PMT",
    "checked": true,
    "id": "ee04b2b113700b71de4fe91bddc9cd10348486b7",
    "semantic_title": "learning progressive modality-shared transformers for effective visible-infrared person re-identification",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25274": {
    "title": "Breaking Immutable: Information-Coupled Prototype Elaboration for Few-Shot Object Detection",
    "volume": "main",
    "abstract": "Few-shot object detection, expecting detectors to detect novel classes with a few instances, has made conspicuous progress. However, the prototypes extracted by existing meta-learning based methods still suffer from insufficient representative information and lack awareness of query images, which cannot be adaptively tailored to different query images. Firstly, only the support images are involved for extracting prototypes, resulting in scarce perceptual information of query images. Secondly, all pixels of all support images are treated equally when aggregating features into prototype vectors, thus the salient objects are overwhelmed by the cluttered background. In this paper, we propose an Information-Coupled Prototype Elaboration (ICPE) method to generate specific and representative prototypes for each query image. Concretely, a conditional information coupling module is introduced to couple information from the query branch to the support branch, strengthening the query-perceptual information in support features. Besides, we design a prototype dynamic aggregation module that dynamically adjusts intra-image and inter-image aggregation weights to highlight the salient information useful for detecting query images. Experimental results on both Pascal VOC and MS COCO demonstrate that our method achieves state-of-the-art performance in almost all settings. Code will be available at: https://github.com/lxn96/ICPE",
    "checked": true,
    "id": "b09025b0b145ad07346fd75e7b5c0429e422ec7d",
    "semantic_title": "breaking immutable: information-coupled prototype elaboration for few-shot object detection",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25275": {
    "title": "ParaFormer: Parallel Attention Transformer for Efficient Feature Matching",
    "volume": "main",
    "abstract": "Heavy computation is a bottleneck limiting deep-learning-based feature matching algorithms to be applied in many real-time applications. However, existing lightweight networks optimized for Euclidean data cannot address classical feature matching tasks, since sparse keypoint based descriptors are expected to be matched. This paper tackles this problem and proposes two concepts: 1) a novel parallel attention model entitled ParaFormer and 2) a graph based U-Net architecture with attentional pooling. First, ParaFormer fuses features and keypoint positions through the concept of amplitude and phase, and integrates self- and cross-attention in a parallel manner which achieves a win-win performance in terms of accuracy and efficiency. Second, with U-Net architecture and proposed attentional pooling, the ParaFormer-U variant significantly reduces computational complexity, and minimize performance loss caused by downsampling. Sufficient experiments on various applications, including homography estimation, pose estimation, and image matching, demonstrate that ParaFormer achieves state-of-the-art performance while maintaining high efficiency. The efficient ParaFormer-U variant achieves comparable performance with less than 50% FLOPs of the existing attention-based models",
    "checked": true,
    "id": "467268d70982cceb82206f526485951b0cff3e80",
    "semantic_title": "paraformer: parallel attention transformer for efficient feature matching",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25276": {
    "title": "Robust One-Shot Segmentation of Brain Tissues via Image-Aligned Style Transformation",
    "volume": "main",
    "abstract": "One-shot segmentation of brain tissues is typically a dual-model iterative learning: a registration model (reg-model) warps a carefully-labeled atlas onto unlabeled images to initialize their pseudo masks for training a segmentation model (seg-model); the seg-model revises the pseudo masks to enhance the reg-model for a better warping in the next iteration. However, there is a key weakness in such dual-model iteration that the spatial misalignment inevitably caused by the reg-model could misguide the seg-model, which makes it converge on an inferior segmentation performance eventually. In this paper, we propose a novel image-aligned style transformation to reinforce the dual-model iterative learning for robust one-shot segmentation of brain tissues. Specifically, we first utilize the reg-model to warp the atlas onto an unlabeled image, and then employ the Fourier-based amplitude exchange with perturbation to transplant the style of the unlabeled image into the aligned atlas. This allows the subsequent seg-model to learn on the aligned and style-transferred copies of the atlas instead of unlabeled images, which naturally guarantees the correct spatial correspondence of an image-mask training pair, without sacrificing the diversity of intensity patterns carried by the unlabeled images. Furthermore, we introduce a feature-aware content consistency in addition to the image-level similarity to constrain the reg-model for a promising initialization, which avoids the collapse of image-aligned style transformation in the first iteration. Experimental results on two public datasets demonstrate 1) a competitive segmentation performance of our method compared to the fully-supervised method, and 2) a superior performance over other state-of-the-art with an increase of average Dice by up to 4.67%. The source code is available at: https://github.com/JinxLv/One-shot-segmentation-via-IST",
    "checked": true,
    "id": "2ddc061eec9873bd2b38a284e21561eda1ef0756",
    "semantic_title": "robust one-shot segmentation of brain tissues via image-aligned style transformation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25277": {
    "title": "HRDoc: Dataset and Baseline Method toward Hierarchical Reconstruction of Document Structures",
    "volume": "main",
    "abstract": "The problem of document structure reconstruction refers to converting digital or scanned documents into corresponding semantic structures. Most existing works mainly focus on splitting the boundary of each element in a single document page, neglecting the reconstruction of semantic structure in multi-page documents. This paper introduces hierarchical reconstruction of document structures as a novel task suitable for NLP and CV fields. To better evaluate the system performance on the new task, we built a large-scale dataset named HRDoc, which consists of 2,500 multi-page documents with nearly 2 million semantic units. Every document in HRDoc has line-level annotations including categories and relations obtained from rule-based extractors and human annotators. Moreover, we proposed an encoder-decoder-based hierarchical document structure parsing system (DSPS) to tackle this problem. By adopting a multi-modal bidirectional encoder and a structure-aware GRU decoder with soft-mask operation, the DSPS model surpass the baseline method by a large margin. All scripts and datasets will be made publicly available at https://github.com/jfma-USTC/HRDoc",
    "checked": true,
    "id": "cef1779a38aeb0aefbc347318b22e7b5cf890c03",
    "semantic_title": "hrdoc: dataset and baseline method toward hierarchical reconstruction of document structures",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25278": {
    "title": "Semantic 3D-Aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field",
    "volume": "main",
    "abstract": "Recently 3D-aware GAN methods with neural radiance field have developed rapidly. However, current methods model the whole image as an overall neural radiance field, which limits the partial semantic editability of synthetic results. Since NeRF renders an image pixel by pixel, it is possible to split NeRF in the spatial dimension. We propose a Compositional Neural Radiance Field (CNeRF) for semantic 3D-aware portrait synthesis and manipulation. CNeRF divides the image by semantic regions and learns an independent neural radiance field for each region, and finally fuses them and renders the complete image. Thus we can manipulate the synthesized semantic regions independently, while fixing the other parts unchanged. Furthermore, CNeRF is also designed to decouple shape and texture within each semantic region. Compared to state-of-the-art 3D-aware GAN methods, our approach enables fine-grained semantic region manipulation, while maintaining high-quality 3D-consistent synthesis. The ablation studies show the effectiveness of the structure and loss function used by our method. In addition real image inversion and cartoon portrait 3D editing experiments demonstrate the application potential of our method",
    "checked": true,
    "id": "01df332f62508f976fea91cdad8010669efc5701",
    "semantic_title": "semantic 3d-aware portrait synthesis and manipulation based on compositional neural radiance field",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25279": {
    "title": "CFFT-GAN: Cross-Domain Feature Fusion Transformer for Exemplar-Based Image Translation",
    "volume": "main",
    "abstract": "Exemplar-based image translation refers to the task of generating images with the desired style, while conditioning on certain input image. Most of the current methods learn the correspondence between two input domains and lack the mining of information within the domain. In this paper, we propose a more general learning approach by considering two domain features as a whole and learning both inter-domain correspondence and intra-domain potential information interactions. Specifically, we propose a Cross-domain Feature Fusion Transformer (CFFT) to learn inter- and intra-domain feature fusion. Based on CFFT, the proposed CFFT-GAN works well on exemplar-based image translation. Moreover, CFFT-GAN is able to decouple and fuse features from multiple domains by cascading CFFT modules. We conduct rich quantitative and qualitative experiments on several image translation tasks, and the results demonstrate the superiority of our approach compared to state-of-the-art methods. Ablation studies show the importance of our proposed CFFT. Application experimental results reflect the potential of our method",
    "checked": true,
    "id": "29d35ab84788ca14e2b65a457c7fed5ee6f150a4",
    "semantic_title": "cfft-gan: cross-domain feature fusion transformer for exemplar-based image translation",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25280": {
    "title": "StyleTalk: One-Shot Talking Head Generation with Controllable Speaking Styles",
    "volume": "main",
    "abstract": "Different people speak with diverse personalized speaking styles. Although existing one-shot talking head methods have made significant progress in lip sync, natural facial expressions, and stable head motions, they still cannot generate diverse speaking styles in the final talking head videos. To tackle this problem, we propose a one-shot style-controllable talking face generation framework. In a nutshell, we aim to attain a speaking style from an arbitrary reference speaking video and then drive the one-shot portrait to speak with the reference speaking style and another piece of audio. Specifically, we first develop a style encoder to extract dynamic facial motion patterns of a style reference video and then encode them into a style code. Afterward, we introduce a style-controllable decoder to synthesize stylized facial animations from the speech content and style code. In order to integrate the reference speaking style into generated videos, we design a style-aware adaptive transformer, which enables the encoded style code to adjust the weights of the feed-forward layers accordingly. Thanks to the style-aware adaptation mechanism, the reference speaking style can be better embedded into synthesized videos during decoding. Extensive experiments demonstrate that our method is capable of generating talking head videos with diverse speaking styles from only one portrait image and an audio clip while achieving authentic visual effects. Project Page: https://github.com/FuxiVirtualHuman/styletalk",
    "checked": true,
    "id": "9ef7df2ace0723583ba22bf165188cd7d2044e93",
    "semantic_title": "styletalk: one-shot talking head generation with controllable speaking styles",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25281": {
    "title": "Intriguing Findings of Frequency Selection for Image Deblurring",
    "volume": "main",
    "abstract": "Blur was naturally analyzed in the frequency domain, by estimating the latent sharp image and the blur kernel given a blurry image. Recent progress on image deblurring always designs end-to-end architectures and aims at learning the difference between blurry and sharp image pairs from pixel-level, which inevitably overlooks the importance of blur kernels. This paper reveals an intriguing phenomenon that simply applying ReLU operation on the frequency domain of a blur image followed by inverse Fourier transform, i.e., frequency selection, provides faithful information about the blur pattern (e.g., the blur direction and blur level, implicitly shows the kernel pattern). Based on this observation, we attempt to leverage kernel-level information for image deblurring networks by inserting Fourier transform, ReLU operation, and inverse Fourier transform to the standard ResBlock. 1 × 1 convolution is further added to let the network modulate flexible thresholds for frequency selection. We term our newly built block as Res FFT-ReLU Block, which takes advantages of both kernel-level and pixel-level features via learning frequency-spatial dual-domain representations. Extensive experiments are conducted to acquire a thorough analysis on the insights of the method. Moreover, after plugging the proposed block into NAFNet, we can achieve 33.85 dB in PSNR on GoPro dataset. Our method noticeably improves backbone architectures without introducing many parameters, while maintaining low computational complexity. Code is available at https://github.com/DeepMed-Lab/DeepRFT-AAAI2023",
    "checked": true,
    "id": "a6f039e6f7b0ef12afc01f0992f477ecc7bfdb31",
    "semantic_title": "intriguing findings of frequency selection for image deblurring",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25282": {
    "title": "DocEdit: Language-Guided Document Editing",
    "volume": "main",
    "abstract": "Professional document editing tools require a certain level of expertise to perform complex edit operations. To make editing tools accessible to increasingly novice users, we investigate intelligent document assistant systems that can make or suggest edits based on a user's natural language request. Such a system should be able to understand the user's ambiguous requests and contextualize them to the visual cues and textual content found in a document image to edit localized unstructured text and structured layouts. To this end, we propose a new task of language-guided localized document editing, where the user provides a document and an open vocabulary editing request, and the intelligent system produces a command that can be used to automate edits in real-world document editing software. In support of this task, we curate the DocEdit dataset, a collection of approximately 28K instances of user edit requests over PDF and design templates along with their corresponding ground truth software executable commands. To our knowledge, this is the first dataset that provides a diverse mix of edit operations with direct and indirect references to the embedded text and visual objects such as paragraphs, lists, tables, etc. We also propose DocEditor, a Transformer-based localization-aware multimodal (textual, spatial, and visual) model that performs the new task. The model attends to both document objects and related text contents which may be referred to in a user edit request, generating a multimodal embedding that is used to predict an edit command and associated bounding box localizing it. Our proposed model empirically outperforms other baseline deep learning approaches by 15-18%, providing a strong starting point for future work",
    "checked": true,
    "id": "383db93b039c2f7d743a06dc62a8db2ff1ea33f7",
    "semantic_title": "docedit: language-guided document editing",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25283": {
    "title": "Progressive Few-Shot Adaptation of Generative Model with Align-Free Spatial Correlation",
    "volume": "main",
    "abstract": "In few-shot generative model adaptation, the model for target domain is prone to the mode-collapse. Recent studies attempted to mitigate the problem by matching the relationship among samples generated from the same latent codes in source and target domains. The objective is further extended to image patch-level to transfer the spatial correlation within an instance. However, the patch-level approach assumes the consistency of spatial structure between source and target domains. For example, the positions of eyes in two domains are almost identical. Thus, it can bring visual artifacts if source and target domain images are not nicely aligned. In this paper, we propose a few-shot generative model adaptation method free from such assumption, based on a motivation that generative models are progressively adapting from the source domain to the target domain. Such progressive changes allow us to identify semantically coherent image regions between instances generated by models at a neighboring training iteration to consider the spatial correlation. We also propose an importance-based patch selection strategy to reduce the complexity of patch-level correlation matching. Our method shows the state-of-the-art few-shot domain adaptation performance in the qualitative and quantitative evaluations",
    "checked": true,
    "id": "e5bed4c8dbc00e975c9d585e7592eaaf2d9d28e5",
    "semantic_title": "progressive few-shot adaptation of generative model with align-free spatial correlation",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25284": {
    "title": "Minority-Oriented Vicinity Expansion with Attentive Aggregation for Video Long-Tailed Recognition",
    "volume": "main",
    "abstract": "A dramatic increase in real-world video volume with extremely diverse and emerging topics naturally forms a long-tailed video distribution in terms of their categories, and it spotlights the need for Video Long-Tailed Recognition (VLTR). In this work, we summarize the challenges in VLTR and explore how to overcome them. The challenges are: (1) it is impractical to re-train the whole model for high-quality features, (2) acquiring frame-wise labels requires extensive cost, and (3) long-tailed data triggers biased training. Yet, most existing works for VLTR unavoidably utilize image-level features extracted from pretrained models which are task-irrelevant, and learn by video-level labels. Therefore, to deal with such (1) task-irrelevant features and (2) video-level labels, we introduce two complementary learnable feature aggregators. Learnable layers in each aggregator are to produce task-relevant representations, and each aggregator is to assemble the snippet-wise knowledge into a video representative. Then, we propose Minority-Oriented Vicinity Expansion (MOVE) that explicitly leverages the class frequency into approximating the vicinity distributions to alleviate (3) biased training. By combining these solutions, our approach achieves state-of-the-art results on large-scale VideoLT and synthetically induced Imbalanced-MiniKinetics200. With VideoLT features from ResNet-50, it attains 18% and 58% relative improvements on head and tail classes over the previous state-of-the-art method, respectively. Code and dataset are available at https://github.com/wjun0830/MOVE",
    "checked": true,
    "id": "5020cc02130c7625836f28969aa632eb87d83f28",
    "semantic_title": "minority-oriented vicinity expansion with attentive aggregation for video long-tailed recognition",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25285": {
    "title": "Show, Interpret and Tell: Entity-Aware Contextualised Image Captioning in Wikipedia",
    "volume": "main",
    "abstract": "Humans exploit prior knowledge to describe images, and are able to adapt their explanation to specific contextual information given, even to the extent of inventing plausible explanations when contextual information and images do not match. In this work, we propose the novel task of captioning Wikipedia images by integrating contextual knowledge. Specifically, we produce models that jointly reason over Wikipedia articles, Wikimedia images and their associated descriptions to produce contextualized captions. The same Wikimedia image can be used to illustrate different articles, and the produced caption needs to be adapted to the specific context allowing us to explore the limits of the model to adjust captions to different contextual information. Dealing with out-of-dictionary words and Named Entities is a challenging task in this domain. To address this, we propose a pre-training objective, Masked Named Entity Modeling (MNEM), and show that this pretext task results to significantly improved models. Furthermore, we verify that a model pre-trained in Wikipedia generalizes well to News Captioning datasets. We further define two different test splits according to the difficulty of the captioning task. We offer insights on the role and the importance of each modality and highlight the limitations of our model",
    "checked": true,
    "id": "c7405b595f266e02f5cac24a11d83b7e341662f6",
    "semantic_title": "show, interpret and tell: entity-aware contextualised image captioning in wikipedia",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25286": {
    "title": "TaCo: Textual Attribute Recognition via Contrastive Learning",
    "volume": "main",
    "abstract": "As textual attributes like font are core design elements of document format and page style, automatic attributes recognition favor comprehensive practical applications. Existing approaches already yield satisfactory performance in differentiating disparate attributes, but they still suffer in distinguishing similar attributes with only subtle difference. Moreover, their performance drop severely in real-world scenarios where unexpected and obvious imaging distortions appear. In this paper, we aim to tackle these problems by proposing TaCo, a contrastive framework for textual attribute recognition tailored toward the most common document scenes. Specifically, TaCo leverages contrastive learning to dispel the ambiguity trap arising from vague and open-ended attributes. To realize this goal, we design the learning paradigm from three perspectives: 1) generating attribute views, 2) extracting subtle but crucial details, and 3) exploiting valued view pairs for learning, to fully unlock the pre-training potential. Extensive experiments show that TaCo surpasses the supervised counterparts and advances the state-of-the-art remarkably on multiple attribute recognition tasks. Online services of TaCo will be made available",
    "checked": true,
    "id": "69df56f5b6134ab85fbf878593eb17a968453538",
    "semantic_title": "taco: textual attribute recognition via contrastive learning",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25287": {
    "title": "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds",
    "volume": "main",
    "abstract": "Current 3D single object tracking methods are typically based on VoteNet, a 3D region proposal network. Despite the success, using a single seed point feature as the cue for offset learning in VoteNet prevents high-quality 3D proposals from being generated. Moreover, seed points with different importance are treated equally in the voting process, aggravating this defect. To address these issues, we propose a novel global-local transformer voting scheme to provide more informative cues and guide the model pay more attention on potential seed points, promoting the generation of high-quality 3D proposals. Technically, a global-local transformer (GLT) module is employed to integrate object- and patch-aware prior into seed point features to effectively form strong feature representation for geometric positions of the seed points, thus providing more robust and accurate cues for offset learning. Subsequently, a simple yet effective training strategy is designed to train the GLT module. We develop an importance prediction branch to learn the potential importance of the seed points and treat the output weights vector as a training constraint term. By incorporating the above components together, we exhibit a superior tracking method GLT-T. Extensive experiments on challenging KITTI and NuScenes benchmarks demonstrate that GLT-T achieves state-of-the-art performance in the 3D single object tracking task. Besides, further ablation studies show the advantages of the proposed global-local transformer voting scheme over the original VoteNet. Code and models will be available at https://github.com/haooozi/GLT-T",
    "checked": true,
    "id": "6df6c71be7a04e3e5c2a0dae037fe38458fe1ef6",
    "semantic_title": "glt-t: global-local transformer voting for 3d single object tracking in point clouds",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25288": {
    "title": "Adapting Object Size Variance and Class Imbalance for Semi-supervised Object Detection",
    "volume": "main",
    "abstract": "Semi-supervised object detection (SSOD) attracts extensive research interest due to its great significance in reducing the data annotation effort. Collecting high-quality and category-balanced pseudo labels for unlabeled images is critical to addressing the SSOD problem. However, most of the existing pseudo-labeling-based methods depend on a large and fixed threshold to select high-quality pseudo labels from the predictions of a teacher model. Considering different object classes usually have different detection difficulty levels due to scale variance and data distribution imbalance, conventional pseudo-labeling-based methods are arduous to explore the value of unlabeled data sufficiently. To address these issues, we propose an adaptive pseudo labeling strategy, which can assign thresholds to classes with respect to their \"hardness\". This is beneficial for ensuring the high quality of easier classes and increasing the quantity of harder classes simultaneously. Besides, label refinement modules are set up based on box jittering for guaranteeing the localization quality of pseudo labels. To further improve the algorithm's robustness against scale variance and make the most of pseudo labels, we devise a joint feature-level and prediction-level consistency learning pipeline for transferring the information of the teacher model to the student model. Extensive experiments on COCO and VOC datasets indicate that our method achieves state-of-the-art performance. Especially, it brings mean average precision gains of 2.08 and 1.28 on MS-COCO dataset with 5% and 10% labeled images, respectively",
    "checked": true,
    "id": "7a30c72de1c89f3c1c38f8e4390699c86bb15626",
    "semantic_title": "adapting object size variance and class imbalance for semi-supervised object detection",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25289": {
    "title": "MIMO Is All You Need：A Strong Multi-in-Multi-Out Baseline for Video Prediction",
    "volume": "main",
    "abstract": "The mainstream of the existing approaches for video prediction builds up their models based on a Single-In-Single-Out (SISO) architecture, which takes the current frame as input to predict the next frame in a recursive manner. This way often leads to severe performance degradation when they try to extrapolate a longer period of future, thus limiting the practical use of the prediction model. Alternatively, a Multi-In-Multi-Out (MIMO) architecture that outputs all the future frames at one shot naturally breaks the recursive manner and therefore prevents error accumulation. However, only a few MIMO models for video prediction are proposed and they only achieve inferior performance due to the date. The real strength of the MIMO model in this area is not well noticed and is largely under-explored. Motivated by that, we conduct a comprehensive investigation in this paper to thoroughly exploit how far a simple MIMO architecture can go. Surprisingly, our empirical studies reveal that a simple MIMO model can outperform the state-of-the-art work with a large margin much more than expected, especially in dealing with long-term error accumulation. After exploring a number of ways and designs, we propose a new MIMO architecture based on extending the pure Transformer with local spatio-temporal blocks and a new multi-output decoder, namely MIMO-VP, to establish a new standard in video prediction. We evaluate our model in four highly competitive benchmarks. Extensive experiments show that our model wins 1st place on all the benchmarks with remarkable performance gains and surpasses the best SISO model in all aspects including efficiency, quantity, and quality. A dramatic error reduction is achieved when predicting 10 frames on Moving MNIST and Weather datasets respectively. We believe our model can serve as a new baseline to facilitate the future research of video prediction tasks. The code will be released",
    "checked": false,
    "id": "6ec6176e06ba9918ce563dc89a96303408fd97cf",
    "semantic_title": "mimo is all you need : a strong multi-in-multi-out baseline for video prediction",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25290": {
    "title": "Universe Points Representation Learning for Partial Multi-Graph Matching",
    "volume": "main",
    "abstract": "Many challenges from natural world can be formulated as a graph matching problem. Previous deep learning-based methods mainly consider a full two-graph matching setting. In this work, we study the more general partial matching problem with multi-graph cycle consistency guarantees. Building on a recent progress in deep learning on graphs, we propose a novel data-driven method (URL) for partial multi-graph matching, which uses an object-to-universe formulation and learns latent representations of abstract universe points. The proposed approach advances the state of the art in semantic keypoint matching problem, evaluated on Pascal VOC, CUB, and Willow datasets. Moreover, the set of controlled experiments on a synthetic graph matching dataset demonstrates the scalability of our method to graphs with large number of nodes and its robustness to high partiality",
    "checked": true,
    "id": "61feea09030ace88eb0ddcdcf8942b002b5adfd3",
    "semantic_title": "universe points representation learning for partial multi-graph matching",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25291": {
    "title": "Robust Image Denoising of No-Flash Images Guided by Consistent Flash Images",
    "volume": "main",
    "abstract": "Images taken in low light conditions typically contain distracting noise, and eliminating such noise is a crucial computer vision problem. Additional photos captured with a camera flash can guide an image denoiser to preserve edges since the flash images often contain fine details with reduced noise. Nonetheless, a denoiser can be misled by inconsistent flash images, which have image structures (e.g., edges) that do not exist in no-flash images. Unfortunately, this disparity frequently occurs as the flash/no-flash pairs are taken in different light conditions. We propose a learning-based technique that robustly fuses the image pairs while considering their inconsistency. Our framework infers consistent flash image patches locally, which have similar image structures with the ground truth, and denoises no-flash images using the inferred ones via a combination model. We demonstrate that our technique can produce more robust results than state-of-the-art methods, given various flash/no-flash pairs with inconsistent image structures. The source code is available at https://github.com/CGLab-GIST/RIDFnF",
    "checked": true,
    "id": "81eb06c149775e0de9ec7b04bb4d4b53abf04d43",
    "semantic_title": "robust image denoising of no-flash images guided by consistent flash images",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25292": {
    "title": "Coarse2Fine: Local Consistency Aware Re-prediction for Weakly Supervised Object Localization",
    "volume": "main",
    "abstract": "Weakly supervised object localization aims to localize objects of interest by using only image-level labels. Existing methods generally segment activation map by threshold to obtain mask and generate bounding box. However, the activation map is locally inconsistent, i.e., similar neighboring pixels of the same object are not equally activated, which leads to the blurred boundary issue: the localization result is sensitive to the threshold, and the mask obtained directly from the activation map loses the fine contours of the object, making it difficult to obtain a tight bounding box. In this paper, we introduce the Local Consistency Aware Re-prediction (LCAR) framework, which aims to recover the complete fine object mask from locally inconsistent activation map and hence obtain a tight bounding box. To this end, we propose the self-guided re-prediction module (SGRM), which employs a novel superpixel aggregation network to replace the post-processing of threshold segmentation. In order to derive more reliable pseudo label from the activation map to supervise the SGRM, we further design an affinity refinement module (ARM) that utilizes the original image feature to better align the activation map with the image appearance, and design a self-distillation CAM (SD-CAM) to alleviate the locator dependence on saliency. Experiments demonstrate that our LCAR outperforms the state-of-the-art on both the CUB-200-2011 and ILSVRC datasets, achieving 95.89% and 70.72% of GT-Know localization accuracy, respectively",
    "checked": true,
    "id": "9070385c89cf2385629b70e1ed7267a9391554d8",
    "semantic_title": "coarse2fine: local consistency aware re-prediction for weakly supervised object localization",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25293": {
    "title": "Find Beauty in the Rare: Contrastive Composition Feature Clustering for Nontrivial Cropping Box Regression",
    "volume": "main",
    "abstract": "Automatic image cropping algorithms aim to recompose images like human-being photographers by generating the cropping boxes with improved composition quality. Cropping box regression approaches learn the beauty of composition from annotated cropping boxes. However, the bias of annotations leads to quasi-trivial recomposing results, which has an obvious tendency to the average location of training samples. The crux of this predicament is that the task is naively treated as a box regression problem, where rare samples might be dominated by normal samples, and the composition patterns of rare samples are not well exploited. Observing that similar composition patterns tend to be shared by the cropping boundaries annotated nearly, we argue to find the beauty of composition from the rare samples by clustering the samples with similar cropping boundary annotations, i.e., similar composition patterns. We propose a novel Contrastive Composition Clustering (C2C) to regularize the composition features by contrasting dynamically established similar and dissimilar pairs. In this way, common composition patterns of multiple images can be better summarized, which especially benefits the rare samples and endows our model with better generalizability to render nontrivial results. Extensive experimental results show the superiority of our model compared with prior arts. We also illustrate the philosophy of our design with an interesting analytical visualization",
    "checked": true,
    "id": "82fa44d3b927745ed1e2397eacc02596da50d0f6",
    "semantic_title": "find beauty in the rare: contrastive composition feature clustering for nontrivial cropping box regression",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25294": {
    "title": "Domain Decorrelation with Potential Energy Ranking",
    "volume": "main",
    "abstract": "Machine learning systems, especially the methods based on deep learning, enjoy great success in modern computer vision tasks under ideal experimental settings. Generally, these classic deep learning methods are built on the i.i.d. assumption, supposing the training and test data are drawn from the same distribution independently and identically. However, the aforementioned i.i.d. assumption is, in general, unavailable in the real-world scenarios, and as a result, leads to sharp performance decay of deep learning algorithms. Behind this, domain shift is one of the primary factors to be blamed. In order to tackle this problem, we propose using Potential Energy Ranking (PoER) to decouple the object feature and the domain feature in given images, promoting the learning of label-discriminative representations while filtering out the irrelevant correlations between the objects and the background. PoER employs the ranking loss in shallow layers to make features with identical category and domain labels close to each other and vice versa. This makes the neural networks aware of both objects and background characteristics, which is vital for generating domain-invariant features. Subsequently, with the stacked convolutional blocks, PoER further uses the contrastive loss to make features within the same categories distribute densely no matter domains, filtering out the domain information progressively for feature alignment. PoER reports superior performance on domain generalization benchmarks, improving the average top-1 accuracy by at least 1.20% compared to the existing methods. Moreover, we use PoER in the ECCV 2022 NICO Challenge, achieving top place with only a vanilla ResNet-18 and winning the jury award. The code has been made publicly available at: https://github.com/ForeverPs/PoER",
    "checked": true,
    "id": "55b51b993600aa23d84e1e15fb53641100e9c772",
    "semantic_title": "domain decorrelation with potential energy ranking",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25295": {
    "title": "PDRF: Progressively Deblurring Radiance Field for Fast Scene Reconstruction from Blurry Images",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "559f7202200ef3c187780301590e2f2b4665f047",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25296": {
    "title": "Efficient End-to-End Video Question Answering with Pyramidal Multimodal Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2837e0cab1d600fa9ca29ebdbfab239701065071",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25297": {
    "title": "CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b57872957f8f70573b62a27c4b91e0636b218983",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25298": {
    "title": "Better and Faster: Adaptive Event Conversion for Event-Based Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bd82d465f64ef748e3de025a2ad0edf05f300fdd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25299": {
    "title": "CSTAR: Towards Compact and Structured Deep Neural Networks with Adversarial Robustness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "29bb2597be1a499d30d23844bf19d5c43f6afc12",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25300": {
    "title": "Exploring Stochastic Autoregressive Image Modeling for Visual Representation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fa0872e45bf6c0fee528c86120f52490142efba6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25301": {
    "title": "Context-Aware Transformer for 3D Point Cloud Automatic Annotation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ec629633af4d16bbc8db0cc3fb26964cfa33eb6c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25302": {
    "title": "Data-Efficient Image Quality Assessment with Attention-Panel Decoder",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "959eac73869bb8ec9096871957c938840e0fdcd0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25303": {
    "title": "FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "29a2c4d44117e51e0d2fa6ffac516222ecab254f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25304": {
    "title": "Exposing the Self-Supervised Space-Time Correspondence Learning via Graph Kernels",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1b137feaa09a7660c26107d7cf0411e2e99058c3",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25305": {
    "title": "Exploring Stroke-Level Modifications for Scene Text Editing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b8fe2b02776208670906c89f8b8d361074fc87d5",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25306": {
    "title": "Unsupervised Deep Learning for Phase Retrieval via Teacher-Student Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c02b92e4ffb3edd22280154b535017de8a1938c9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25307": {
    "title": "A Learnable Radial Basis Positional Embedding for Coordinate-MLPs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "05450d77727a1c58854e0b8550ca9f82e05d1cd8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25308": {
    "title": "Action-Conditioned Generation of Bimanual Object Manipulation Sequences",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "44d343bfa354e4afa7a3bed82a7831d677e3e210",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25309": {
    "title": "Mean-Shifted Contrastive Loss for Anomaly Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7d90243c5a46430a36c5ba88627b5d254450a1e1",
    "semantic_title": "",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25310": {
    "title": "Two Heads Are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0a09509004fb374d794fb4065b54e9a5dda630e6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25311": {
    "title": "MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-robust Classifier",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "790ba79fa1fcc7446fd81047c9e86b2b4c862d7a",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25312": {
    "title": "Domain Generalised Faster R-CNN",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b22618848e56abbf7dcf1d7f419b72215cefcdb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25313": {
    "title": "MIDMs: Matching Interleaved Diffusion Models for Exemplar-Based Image Translation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1ed3b73719016f3500c5976234111b87c21837bf",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25314": {
    "title": "JR2Net: Joint Monocular 3D Face Reconstruction and Reenactment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2e51e322712413d3e6d5b8abef8d74cbfdaa2ae4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25315": {
    "title": "HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "643626048cc70b1ed4ed3a0fc94d58b02b7945f7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25316": {
    "title": "Channel Regeneration: Improving Channel Utilization for Compact DNNs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e32b11399247648b4d9f50bd54f8a383280489fb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25317": {
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6f14a642033b72454afbecdb90c82872d8085dd2",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25318": {
    "title": "Edge Structure Learning via Low Rank Residuals for Robust Image Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "925794910710207106ee192ff97475a2617bef3c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25319": {
    "title": "Memory-Oriented Structural Pruning for Efficient Image Restoration",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9f5408d8c08a2f7beb35cb16c6ccdcf67b3c7d3d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25320": {
    "title": "YOLOV: Making Still Image Object Detectors Great at Video Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aa289e06d4a11f50ce1f5287415a7ff752c136f6",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25321": {
    "title": "FeedFormer: Revisiting Transformer Decoder for Efficient Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "de8d3b6ef17f924fc8d01d09bcc128c068dc1469",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25322": {
    "title": "Task-Specific Scene Structure Representations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3194258a0374f03f1ba1b968fa181fc1e1456b49",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25323": {
    "title": "Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "41e11c36e6fd2377fe5ecb9d0d0422c635ee4be0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25324": {
    "title": "SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8fe203feefec99d20ed68003e5389a46a0d7f285",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25325": {
    "title": "Siamese-Discriminant Deep Reinforcement Learning for Solving Jigsaw Puzzles with Large Eroded Gaps",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14ef45b70e11c8222baf19f30cc045f54d574c23",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25326": {
    "title": "CLIPVG: Text-Guided Image Manipulation Using Differentiable Vector Graphics",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cda631065b5300aa3d3d3226a4da9d3a36939494",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25327": {
    "title": "Compact Transformer Tracker with Correlative Masked Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b8e6e17ca2288c26b79cedff0a666e2549441ac1",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25328": {
    "title": "Text-DIAE: A Self-Supervised Degradation Invariant Autoencoder for Text Recognition and Document Enhancement",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0e0714e9dc5dc5ce5b4eda032d166fb07bb26ca1",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25329": {
    "title": "PUPS: Point Cloud Unified Panoptic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "72e8986a912f812b71f02e4083d349104c0db158",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25330": {
    "title": "Efficient Edge-Preserving Multi-View Stereo Network for Depth Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "20475d345d152fa4a78b9eb37f3ffe7f2d3cfcf6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25331": {
    "title": "Referring Expression Comprehension Using Language Adaptive Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d0b4d116cb264894b47e0c25cb89344c924ba9cc",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25332": {
    "title": "Rethinking Data Augmentation for Single-Source Domain Generalization in Medical Image Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c8368b16b978c36bcb368e673c292254d8a4cf01",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25333": {
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0e4aa84de53f8d6f8245ff6bc3c535ed260edfe2",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25334": {
    "title": "Learning Event-Relevant Factors for Video Anomaly Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1f1b6f5dcd5f802f2782ef15629be57202e3b629",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25335": {
    "title": "Superpoint Transformer for 3D Scene Instance Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e015130b27aaa95674e7c4b5dcbb5a7a7fe7ed04",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25336": {
    "title": "Asynchronous Event Processing with Local-Shift Graph Convolutional Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "29f12988ea953725e791e7467b479f7161a487ac",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25337": {
    "title": "DENet: Disentangled Embedding Network for Visible Watermark Removal",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5720ed9d22f2f83a75e7f8efb7b466691f631138",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25338": {
    "title": "Deep Manifold Attack on Point Clouds via Parameter Plane Stretching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38a454f66e8fca40a342f5edb3b1d433eb091971",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25339": {
    "title": "Fair Generative Models via Transfer Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c77f32cb3a030c04de992be40fdf882690afeef8",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25340": {
    "title": "Learning Context-Aware Classifier for Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4ca374400fc1dd1078ce39c942ff8df562fb163b",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25341": {
    "title": "TopicFM: Robust and Interpretable Topic-Assisted Feature Matching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1df8ce9e21c544a8ba0911e3e7825abc752236eb",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25342": {
    "title": "Learning Fractals by Gradient Descent",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8715975820cbacdc844a196e2f2f471cca982ccb",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25343": {
    "title": "Leveraging Weighted Cross-Graph Attention for Visual and Semantic Enhanced Video Captioning Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a5e3cf08174095cbe4cec418d19b8fc260af49cb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25344": {
    "title": "Doodle to Object: Practical Zero-Shot Sketch-Based 3D Shape Retrieval",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d658819f2aad7f8fe5ec951c595d432f0d8db33f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25345": {
    "title": "Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f8860a5ef6097a9a01a352e609366343627db577",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25346": {
    "title": "Dual Memory Aggregation Network for Event-Based Object Detection with Learnable Representation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d902c86c7a1cbdac013523488adf85942aa11169",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25347": {
    "title": "Text to Point Cloud Localization with Relation-Enhanced Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "23a24e1740bf1b5bd5f39b18114b65ceabed1db0",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25348": {
    "title": "UCoL: Unsupervised Learning of Discriminative Facial Representations via Uncertainty-Aware Contrast",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "77f6e57c4c5d73fe7805c662381ebad5ed643789",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25349": {
    "title": "Calibrated Teacher for Sparsely Annotated Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "045465a04985227f05a437ecc459fbc8b1cb0478",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25350": {
    "title": "Towards Real-Time Panoptic Narrative Grounding by an End-to-End Grounding Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "436f2d681c3448b6d10cea53238974987d71c0f2",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25351": {
    "title": "LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "36b5d21ee97844ec915f5740e37e95c41992409c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25352": {
    "title": "Defending Black-Box Skeleton-Based Human Activity Classifiers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "24d47781fb60fd3a427d426d763fc544bee8175b",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25353": {
    "title": "Exploring CLIP for Assessing the Look and Feel of Images",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "03ae89e796b1a8b566ae1554fab65c8c88b3a55f",
    "semantic_title": "",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25354": {
    "title": "Robust Video Portrait Reenactment via Personalized Representation Quantization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f54e8f1d3af326ccbd372fe1cf7f548f7fd6a483",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25355": {
    "title": "De-biased Teacher: Rethinking IoU Matching for Semi-supervised Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "656d87d314009a9f1925348d30652f39e0cc7ed5",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25356": {
    "title": "Learning to Generate an Unbiased Scene Graph by Using Attribute-Guided Predicate Features",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "da31afdbc962f0323d013a88a0c308c61b4d247c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25357": {
    "title": "Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1ff504e8d0ed00d8e9d6dd317d3b7572d1f3ecaa",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25358": {
    "title": "Flora: Dual-Frequency LOss-Compensated ReAl-Time Monocular 3D Video Reconstruction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "de0d19110a0601c0741df7d26982a0c44288ce90",
    "semantic_title": "",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25359": {
    "title": "Efficient Image Captioning for Edge Devices",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d6332c9a4607ce9823123e6407e40ab6ac33ac08",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25360": {
    "title": "Controllable Image Captioning via Prompting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f66aeec98816c3a52685e570a04fa8f2bd53dfb4",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25361": {
    "title": "ECO-3D: Equivariant Contrastive Learning for Pre-training on Perturbed 3D Point Cloud",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8c1cef162d3c6276c84deb22c08a2b6d7e2d38a1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25362": {
    "title": "Global-Local Characteristic Excited Cross-Modal Attacks from Images to Videos",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "af77300381156898024ea3a10f6d00cc31b8ee86",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25363": {
    "title": "Fine-Grained Retrieval Prompt Tuning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "247be1257a1c5811ff48331e902771c7b00a56c5",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25364": {
    "title": "Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "baf3d202261f1eb9122a157fc6480d93e2c3d03c",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25365": {
    "title": "3D Assembly Completion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "eb2256efc25ad00d4a18a9901cf83b17dbc038a4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25366": {
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "974e24ce5ca6a23b8841f3b1049edff0aeaf42ce",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25367": {
    "title": "Revisiting Unsupervised Local Descriptor Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b72f022c06dbfa52af4f31a766ca57e7758b5990",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25368": {
    "title": "Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "588042275a2e338df56ace42453c727137da36fc",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25369": {
    "title": "Learning Continuous Depth Representation via Geometric Spatial Aggregator",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9dc77eb07e11d3fd09f2dd5d2225ded4291f6d3b",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25370": {
    "title": "SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bfc07ed6e6d4aef2674d0e412215b3253b95336c",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25371": {
    "title": "High-Resolution GAN Inversion for Degraded Images in Large Diverse Datasets",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "36da639b3cba35311314a19e5bfd987c5865a061",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25372": {
    "title": "GAN Prior Based Null-Space Learning for Consistent Super-resolution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7c12d091ea5c16938943559fb0f3d430ba040c08",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25373": {
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "65be7f0b01cf6c2a1cded708b809182fbcb43548",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25374": {
    "title": "MicroAST: Towards Super-fast Ultra-Resolution Arbitrary Style Transfer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7b0183c518ebc2100569f1086fd6fedab8659d96",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25375": {
    "title": "Truncate-Split-Contrast: A Framework for Learning from Mislabeled Videos",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bb62dd71543f4644cec09b00bdf7b8b2795063fd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25376": {
    "title": "Active Token Mixer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "20fc19d7445ec081a95a3e97bab3f1f07c92988d",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25377": {
    "title": "Exploring Non-target Knowledge for Improving Ensemble Universal Adversarial Attacks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2cf7b3b2fb58431d96e934effbb0af3a3ba60eb9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25378": {
    "title": "Towards Good Practices for Missing Modality Robust Action Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "12a43c120c9e7615535237bbee2f6375d07fdd7a",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25379": {
    "title": "Reject Decoding via Language-Vision Models for Text-to-Image Synthesis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1f9fff9bf668264b454ee45e67135ea2debd7b8f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25380": {
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8599f26dd40313a092dc05fe370b934beb6a29ef",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25381": {
    "title": "Super-efficient Echocardiography Video Segmentation via Proxy- and Kernel-Based Semi-supervised Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b6f991a9b4da4d520d11684d42cdf403d0be5917",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25382": {
    "title": "ACL-Net: Semi-supervised Polyp Segmentation via Affinity Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b7fe355f1db5dbf47e4ac223c7a48e8dbaa7cbe1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25383": {
    "title": "Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot Image Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b8d3436667b7863759a5d2228366e357f35a6e8d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25384": {
    "title": "Preserving Structural Consistency in Arbitrary Artist and Artwork Style Transfer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e808f718e4f195527e8ea3ecb252e25e24c98bae",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25385": {
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2b2a7f713d8efe2696df85ef22dac7ef35be7e10",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25386": {
    "title": "Revisiting Classifier: Transferring Vision-Language Models for Video Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c68b9483bcd91850e27cc6d667c783edf335a3e4",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25387": {
    "title": "Scene Graph to Image Synthesis via Knowledge Consensus",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "feb5504685a92ea0b2283959a1b508f54bab1627",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25388": {
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for Unsupervised Visual Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fe6ee1f2bf6fa3093798723d3edab686fd927d1d",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25389": {
    "title": "Multi-Stream Representation Learning for Pedestrian Trajectory Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b1552a37506344714092defaf1a4bc9488f9bd67",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25390": {
    "title": "Pixel Is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "088a89c3ef90e80b050ac717400209f564099654",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25391": {
    "title": "Attention-Based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6c475af6a695d494b8790ca878f146e795eeb27b",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25392": {
    "title": "Skating-Mixer: Long-Term Sport Audio-Visual Modeling with MLPs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14165df6bd6ebe598d65d740ee7bcefee2e178f4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25393": {
    "title": "SVFI: Spiking-Based Video Frame Interpolation for High-Speed Motion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a30499c63169d649d9104fa05de10dce6fef3e7b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25394": {
    "title": "FEditNet: Few-Shot Editing of Latent Semantics in GAN Spaces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5cde780c2bad086fa5267a11068bb40d320616b4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25395": {
    "title": "Toward Robust Diagnosis: A Contour Attention Preserving Adversarial Defense for COVID-19 Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a68b491f64daf9eee7551469e5d7a39fa62515ad",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25396": {
    "title": "Boosting Semi-Supervised Semantic Segmentation with Probabilistic Representations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "12e668ad61fbcfb1e4752f1243082dc8c0f75f4f",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25397": {
    "title": "Less Is More Important: An Attention Module Guided by Probability Density Function for Convolutional Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7624dc2e2c610040b778ce11c3261523e7b27c93",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25398": {
    "title": "Mitigating Artifacts in Real-World Video Super-resolution Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "442f3bde58bd8f736f8643a5fb2feec0854bf368",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25399": {
    "title": "Just Noticeable Visual Redundancy Forecasting: A Deep Multimodal-Driven Approach",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4dc3f4d5a05f9af6b5c78f67b8cb6704738ad7e5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25400": {
    "title": "Cross-Modal Contrastive Learning for Domain Adaptation in 3D Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ff5d423b6dc934d58c7541df31b507fdda059be5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25401": {
    "title": "ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient Self-Supervised Monocular Depth Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "373959536e023e451b46e6e3d60228b59568a5ac",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25402": {
    "title": "LORE: Logical Location Regression Network for Table Structure Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a90a77893708ae5070e2ed4572ca9e20837e69c6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25403": {
    "title": "Revisiting the Spatial and Temporal Modeling for Few-Shot Action Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7723859aa67aa5324155dfafa1f078b3bc034178",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25404": {
    "title": "Unsupervised Multi-Exposure Image Fusion Breaking Exposure Limits via Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fc8f02331ed5baed6f5c0adb9c9cb2fca5e7c1a8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25405": {
    "title": "CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene Completion by Dense Feature Fusion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ede618392b52947f4103415c97e444c20697e550",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25406": {
    "title": "Learning a Generalized Gaze Estimator from Gaze-Consistent Feature",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7a79ce59268ff9b07f61ba730bdfb8f0eaa54ab0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25407": {
    "title": "Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "44891165b360ccf98d7f6fd7f5361a6d5f3b4a3b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25408": {
    "title": "Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "17b71c39617d654ff345d7e48491068f7d519b0c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25409": {
    "title": "Deep Parametric 3D Filters for Joint Video Denoising and Illumination Enhancement in Video Super Resolution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e64440b53317fa8b5b800f238d500d586ae5e17f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25410": {
    "title": "Inter-image Contrastive Consistency for Multi-Person Pose Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7e5b923a3498a977c0758a1578cb0af1fa180420",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25411": {
    "title": "DeMT: Deformable Mixer Transformer for Multi-Task Learning of Dense Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e3d3c1321554d7d14eec309e61ba70102b0629e1",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25412": {
    "title": "VLTinT: Visual-Linguistic Transformer-in-Transformer for Coherent Video Paragraph Captioning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c35fc28cb4e9336f4077cfc9cc559f55950b5996",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25413": {
    "title": "Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f1b14b7ed6601b4e1fd847a3043e749ca0bf02aa",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25414": {
    "title": "Video-Text Pre-training with Learned Regions for Retrieval",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "615d077899e7c57c7073d427035499749fa7b355",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25415": {
    "title": "DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth Completion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "15d9392d12635221d6dba08a33344f6fc97060ce",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25416": {
    "title": "Self-Supervised Video Representation Learning via Latent Time Navigation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "71a971a7a86459eb7a568985fe398a7c79b3dd35",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25417": {
    "title": "One-Shot Replay: Boosting Incremental Object Detection via Retrospecting One Object",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9bc81d69b990c814770096f3aa41ded4f639df6d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25418": {
    "title": "Video Event Extraction via Tracking Visual States of Arguments",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2e3516142b2d7cf7fb67805a8b45fb077c9c6bb8",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25419": {
    "title": "CoMAE: Single Model Hybrid Pre-training on Small-Scale RGB-D Datasets",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2feabd1e149da3aa82cc6d1d684cac836a0c01e7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25420": {
    "title": "Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ae0c998d3efe583b19fd4d1274eec3520c8f813a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25421": {
    "title": "Stop-Gradient Softmax Loss for Deep Metric Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a792e32749ebb98686791d4524f4e8d4ba575433",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25422": {
    "title": "Local Path Integration for Attribution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "87d4cf1dd6507e7c989b25a4a1eeea1a467c3a54",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25423": {
    "title": "Spatiotemporal Deformation Perception for Fisheye Video Rectification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1fd89aa30d4917bde9a2343d5590456ce2d76ac8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25424": {
    "title": "Contrastive Multi-Task Dense Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "59c681b58d85411ba5a70284947ad728f468c54c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25425": {
    "title": "AutoStegaFont: Synthesizing Vector Fonts for Hiding Information in Documents",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6225139fe937b85a1a4a7d03e10354745f764b5c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25426": {
    "title": "Towards Global Video Scene Segmentation with Context-Aware Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "807937ad69b41b6a320d9d180fa9fe0205d56804",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25427": {
    "title": "Low-Light Image Enhancement Network Based on Multi-Scale Feature Complementation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b0287e28e409920e97b5b308974750914d60ba7b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25428": {
    "title": "Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "21cbb159992abffdee87c2a1bc15a3d98bdfde8a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25429": {
    "title": "LidarMultiNet: Towards a Unified Multi-Task Network for LiDAR Perception",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "09ce90a7d46c297db17e41cfd4e7691933408540",
    "semantic_title": "",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25430": {
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f89d5e8e3c6e3bb035729c1f6039ee95149ce0b",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25431": {
    "title": "Learning Second-Order Attentive Context for Efficient Correspondence Pruning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f5faa47345366d623a8cd3b41e63276065c404a3",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25432": {
    "title": "Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "28f4d454359641f62944674ea085e84aff5ce023",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25433": {
    "title": "Can We Find Strong Lottery Tickets in Generative Models?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "74fb4456760e417ec2873cfab1e4c87ce59df8f6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25434": {
    "title": "Class-Independent Regularization for Learning with Noisy Labels",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "284858ac99309568e83377a9968a1908ee28c717",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25435": {
    "title": "Unbiased Heterogeneous Scene Graph Generation with Relation-Aware Message Passing Neural Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b02f9674a07d6a7e4ab5f4846301dc8d15433e46",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25436": {
    "title": "Lifelong Person Re-identification via Knowledge Refreshing and Consolidation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cdba9c57d5e372bee7a382c2f287eb20da244977",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25437": {
    "title": "Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dddeca3509132717a8b5843f730b8b01a3887dcc",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25438": {
    "title": "Rethinking Rotation Invariance with Point Cloud Registration",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6ca5939d6e64dc751de8bd513980f57a2d43af55",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25439": {
    "title": "Frame-Level Label Refinement for Skeleton-Based Weakly-Supervised Action Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ac0d48894ddbb9232730ab54f9a7754dc6e73c45",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25440": {
    "title": "Recurrent Structure Attention Guidance for Depth Super-resolution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5010526e685c33293be4317720235e639a3bf2e7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25441": {
    "title": "Structure Flow-Guided Network for Real Depth Super-resolution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98338f97c57fdaea642fa19df65d761349562ca4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25442": {
    "title": "Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b489c6fe772b861a99a14f5f6474b0d44a4a8f2e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25443": {
    "title": "Cyclically Disentangled Feature Translation for Face Anti-spoofing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9abd5e50e280323e3446595d23aa696113346465",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25444": {
    "title": "FlowFace: Semantic Flow-Guided Shape-Aware Face Swapping",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "166d8ab629f46c818f42fa4e802a6033d42ece16",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25445": {
    "title": "Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f1820749124aa1eaa51c47cb084f13c76b1a8ed2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25446": {
    "title": "Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "297c953df13c4375527df215b57f9c72c036a569",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25447": {
    "title": "Darwinian Model Upgrades: Model Evolving with Selective Compatibility",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7d49b452bf09020f032ff65aa115740e3bf99ea0",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25448": {
    "title": "Mx2M: Masked Cross-Modality Modeling in Domain Adaptation for 3D Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dc430bba79178483c254a072c2151f0b3e7111af",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25449": {
    "title": "Few-Shot 3D Point Cloud Semantic Segmentation via Stratified Class-Specific Attention Based Transformer Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "80df029becc3fdf6789c0d4c4fdf9a832f2e2672",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25450": {
    "title": "PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement and Pose Restoration",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e6ad00f8c11a9237fc112ecff222e00fd71174ae",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25451": {
    "title": "Hierarchical Consistent Contrastive Learning for Skeleton-Based Action Recognition with Growing Augmentations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "51133d759e81916553edf4e35a20385d12090abe",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25452": {
    "title": "ImageNet Pre-training Also Transfers Non-robustness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b28004c12d1073f3b186483ecb9e8fb816dd37c8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25453": {
    "title": "Language-Assisted 3D Feature Learning for Semantic Scene Understanding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7e667180d34f837c7416358414a387595d54eee4",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25454": {
    "title": "IKOL: Inverse Kinematics Optimization Layer for 3D Human Pose and Shape Estimation via Gauss-Newton Differentiation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aa5262e4d46f8565de1d6049d1f85e8e2033601a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25455": {
    "title": "Mind the Gap: Polishing Pseudo Labels for Accurate Semi-supervised Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0b3854e82d71e1a36e049763bb270f1f19d2ea3c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25456": {
    "title": "ConvMatch: Rethinking Network Design for Two-View Correspondence Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8d9662d2db763abb6d427d398e76288327457b1a",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25457": {
    "title": "Cross-View Geo-Localization via Learning Disentangled Geometric Layout Correspondence",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ae6bbeb670a0211bc2426b9afd867f8afb72e751",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25458": {
    "title": "Video Compression Artifact Reduction by Fusing Motion Compensation and Global Context in a Swin-CNN Based Parallel Architecture",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "63b3c5e3c6b15394743f9bb423ac2082b2443d24",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25459": {
    "title": "MRCN: A Novel Modality Restitution and Compensation Network for Visible-Infrared Person Re-identification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ddd0cff0f7f959c324f9bb157f045302c66690ca",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25460": {
    "title": "A Simple Baseline for Multi-Camera 3D Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b0226ed79f7b9efe06adfd0c093228a354bc5197",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25461": {
    "title": "Positional Label for Self-Supervised Vision Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "9ea9e48950e311387c177b5195782c8c324ac119",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25462": {
    "title": "Cross-Category Highlight Detection via Feature Decomposition and Modality Alignment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "45de3c9f58933d5ba67dbc9d4cc0266dc11eddf2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25463": {
    "title": "TrEP: Transformer-Based Evidential Prediction for Pedestrian Intention with Uncertainty",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e9e8ed0ee97296c638329a30643c2456d95e944e",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25464": {
    "title": "DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f13d4d12d924727114182da54980a04be051fc87",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25465": {
    "title": "ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6ae2e3d5682e755d560c34b05169a9660660f055",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25466": {
    "title": "Combating Unknown Bias with Effective Bias-Conflicting Scoring and Gradient Alignment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5dc689a4d6827b5a441c50cb56c14d19b027d9f7",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25467": {
    "title": "RLogist: Fast Observation Strategy on Whole-Slide Images with Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "63195e3d637c2725913fc2fd999e3e3ae40362e4",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25468": {
    "title": "Learning to Super-resolve Dynamic Scenes for Neuromorphic Spike Camera",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98528cb319f7939749cafff8d1ff08823641c009",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25469": {
    "title": "TinyNeRF: Towards 100 x Compression of Voxel Radiance Fields",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a8f13253a047f76c5e9ee275d27b70274dfe2758",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25470": {
    "title": "BEST: BERT Pre-training for Sign Language Recognition with Coupling Tokenization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "919efc30ab8c45456ab72fb4ebeb5e25f2ad7642",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25471": {
    "title": "MulGT: Multi-Task Graph-Transformer with Task-Aware Knowledge Injection and Domain Knowledge-Driven Pooling for Whole Slide Image Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "10968bcb3e19eb3cbd137af1bf4b82ad1c04378c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25472": {
    "title": "Grouped Knowledge Distillation for Deep Face Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "68ed8b94df543dba73a619980d1c5a3fcde417a5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25473": {
    "title": "Style-Content Metric Learning for Multidomain Remote Sensing Object Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2fbd355ed0cf0bb57a3bfea9b3f12cc1e180d701",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25474": {
    "title": "Occupancy Planes for Single-View RGB-D Human Reconstruction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dde7f2b5b925c7edb8ef9c5aabc1f679a6b6c104",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25475": {
    "title": "Deep Equilibrium Models for Snapshot Compressive Imaging",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "68bcc213f88a5ee875f7061cdc192cb5b4ad9832",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25476": {
    "title": "Unsupervised Deep Video Denoising with Untrained Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8132f60124089fd50fe2afbd3e60e73b05ef65e1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25477": {
    "title": "Attack Can Benefit: An Adversarial Approach to Recognizing Facial Expressions under Noisy Annotations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4266bba4e036807378abb05b2a9ebe7063c13a94",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25478": {
    "title": "Phrase-Level Temporal Relationship Mining for Temporal Sentence Localization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4f70d5bdd5293b7fc53831624971fef83873d3f7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25479": {
    "title": "Learning Semantic Degradation-Aware Guidance for Recognition-Driven Unsupervised Low-Light Image Enhancement",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "00d66e7384eb46a290595bf54d62c2a614f8734d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25480": {
    "title": "Memory-Aided Contrastive Consensus Learning for Co-salient Object Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4ec9799fba2f8e71a48c7606d1c725f2e2a30095",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25481": {
    "title": "MaskBooster: End-to-End Self-Training for Sparsely Supervised Instance Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc3fab136f5ee45103bad37eebafa1581781560d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25482": {
    "title": "RSPT: Reconstruct Surroundings and Predict Trajectory for Generalizable Active Object Tracking",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "0a21061ddf9c41b71c8d7b409f7dd97b18a5cd8b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25483": {
    "title": "STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3d20d1d3ec1199c35d13e60351b358ac1e317401",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25484": {
    "title": "Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "154f9eb2f97cae3a7752cbc4e0261eb4e75008d4",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25485": {
    "title": "Aesthetically Relevant Image Captioning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "15d6ef576fb07bb5fc07fef6f63708e440396dd9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25486": {
    "title": "Polarization-Aware Low-Light Image Enhancement",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1956f7770663fc45d9035278e39eb14fefcdd76a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25487": {
    "title": "Progressive Bayesian Inference for Scribble-Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7a506fdeb24c051732d7c0aa74ae99db3cedbd0f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25488": {
    "title": "Exploratory Inference Learning for Scribble Supervised Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2ff5db744e5eefb95e17afd59260efbb3a78756c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25489": {
    "title": "Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "965a0ff397ff33dbb9ee9a5b725472af4ffe0892",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25490": {
    "title": "Unsupervised Hierarchical Domain Adaptation for Adverse Weather Optical Flow",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cd9aae06d5720908760b47e46516adcb9a89f03f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25491": {
    "title": "PASS: Patch Automatic Skip Scheme for Efficient Real-Time Video Perception on Edge Devices",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ebb9f49e940bdd14925a9776998244ad8aa74b57",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25492": {
    "title": "Robust Feature Rectification of Pretrained Vision Models for Object Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1d4ddca6c68ed963763711f545844557d6085b8a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25493": {
    "title": "Video Object of Interest Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "21c088c0620f6bf9d7699c9547af47318257df7a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25494": {
    "title": "Tree-Structured Trajectory Encoding for Vision-and-Language Navigation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "293951f26d10fed6950b2949e0f90571e0d67cd6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25495": {
    "title": "Self-Supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "185e0240f15d84f805d36ed30f70ebd6e85be2b4",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25496": {
    "title": "Debiased Fine-Tuning for Vision-Language Models by Prompt Regularization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e8b73abefd998229f35e810f465854bdea7512f8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25497": {
    "title": "Improving Scene Text Image Super-resolution via Dual Prior Modulation Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e45d243316096cfc709e96027ebb2d353475ede6",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25498": {
    "title": "SRoUDA: Meta Self-Training for Robust Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0a7ab69f162e706901c6aa1e391004971a463a3a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25499": {
    "title": "Gradient-Based Graph Attention for Scene Text Image Super-resolution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "30db786f5810602af4680dc4372c265e4597666e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25500": {
    "title": "RGBD1K: A Large-Scale Dataset and Benchmark for RGB-D Object Tracking",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b52382b22d25dd63c2a68424304e39024bf6e15f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25501": {
    "title": "Learn More for Food Recognition via Progressive Self-Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a332ce333d52d85ff6bb74dec4a7c7b15bff0f66",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25502": {
    "title": "Generative Image Inpainting with Segmentation Confusion Adversarial Training and Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "65f5f5d54bde99776de1840e7cd59d30bbf74390",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25503": {
    "title": "Improved Algorithms for Maximum Satisfiability and Its Special Cases",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e8e39247da25bb69cd9ceae1c5c5d0d4c354dd47",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25504": {
    "title": "Lifting (D)QBF Preprocessing and Solving Techniques to (D)SSAT",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6ae0b1ba9c743ad04020efe39e1237a5cbc7b1f5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25505": {
    "title": "NuWLS: Improving Local Search for (Weighted) Partial MaxSAT by New Weighting Techniques",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "68d54d627cfaa914d277a3f4a5508de1c4abe4ef",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25506": {
    "title": "Separate but Equal: Equality in Belief Propagation for Single Cycle Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "276906bc63d919a9d576b80786c42254be84a0c7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25507": {
    "title": "Complexity of Reasoning with Cardinality Minimality Conditions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "225a18fc8ae50641c5da8171cd11d00a428d32c9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25508": {
    "title": "DASH: A Distributed and Parallelizable Algorithm for Size-Constrained Submodular Maximization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e912edd7f1b82df95cc569ef73cf602bf7118ea8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25509": {
    "title": "SharpSSAT: A Witness-Generating Stochastic Boolean Satisfiability Solver",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d9e4474d023987ed4c5f409176fe870db873ca85",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25510": {
    "title": "Submodular Maximization under the Intersection of Matroid and Knapsack Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d8f527c2046fcf50d9418d4d694d86c4601ac7ff",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25511": {
    "title": "A Framework to Design Approximation Algorithms for Finding Diverse Solutions in Combinatorial Problems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "807cfcbca58e27d087a913be5c2481e524aeb7f9",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25512": {
    "title": "An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-Sourcing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc8beb173d4dad28357d848b2240d560b81f39f3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25513": {
    "title": "Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e0c94f185099505025b5b2ee94aa567409cdaf19",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25514": {
    "title": "Solving Explainability Queries with Quantification: The Case of Feature Relevancy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "622657250ba771cb4af66f7e54868314b777bbd4",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25515": {
    "title": "Second-Order Quantified Boolean Logic",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "84c64c851b2bbaa8533258b16dee807a25f52cbe",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25516": {
    "title": "Learning Markov Random Fields for Combinatorial Structures via Sampling through Lovász Local Lemma",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cd51ce7bb450a1e8bbf3727db6b809ca45b13518",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25517": {
    "title": "Fast Converging Anytime Model Counting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f1fc7323bb9f59f444be47e1624e31320e417f6b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25518": {
    "title": "Finding Good Partial Assignments during Restart-Based Branch and Bound Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "51870d8e06dff589258700debae3f69dc993772b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25519": {
    "title": "Hybrid Learning with New Value Function for the Maximum Common Induced Subgraph Problem",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dd2f352795968d59bd82169a5c5c9547b054f9e8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25520": {
    "title": "Self-Supervised Primal-Dual Learning for Constrained Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "27171044552454edcbd1d6a20ac0714ee3c46686",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25521": {
    "title": "Reinforcement Learning for Branch-and-Bound Optimisation Using Retrospective Trajectories",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3212c957a11a46d059e981826372914045f5cc4a",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25522": {
    "title": "Constraint Optimization over Semirings",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "39fdccb34c7eae74dac974354db59d0ca48fc8c0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25523": {
    "title": "Generalized Confidence Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7ed381fb10c3178120b182c5e4e70fb89791f466",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25524": {
    "title": "Circuit Minimization with QBF-Based Exact Synthesis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "25f369e3318ba4ee373a5dcf2c7234e37b4ba2c8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25525": {
    "title": "Probabilistic Generalization of Backdoor Trees with Application to SAT",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0b0738a5a45dee62b540b60b9bb33a82e41f8a12",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25526": {
    "title": "The Expressive Power of Ad-Hoc Constraints for Modelling CSPs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b7e5501bfb07b6f3535263caf90d59a21724e510",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25527": {
    "title": "Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dcbda9002def84b4b4467e54e1d06a18ac227103",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25528": {
    "title": "Eliminating the Impossible, Whatever Remains Must Be True: On Extracting and Applying Background Knowledge in the Context of Formal Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25529": {
    "title": "Farsighted Probabilistic Sampling: A General Strategy for Boosting Local Search MaxSAT Solvers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "56c858b81ce04d884a711a70a0b40d5f9f166beb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25530": {
    "title": "LANCER: A Lifetime-Aware News Recommender System",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "23627f20f53611a39a5df35642f99d3007863496",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25531": {
    "title": "Win-Win: A Privacy-Preserving Federated Framework for Dual-Target Cross-Domain Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4fcda17617d3887eb657d017bc15017fc7b3641c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25532": {
    "title": "Enhanced Multi-Relationships Integration Graph Convolutional Network for Inferring Substitutable and Complementary Items",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fa0090adfbc80de8dcc82c8d094ce800f674b094",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25533": {
    "title": "PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "57a13f7f82a11887af3baceda506e2c579d7466d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25534": {
    "title": "End-to-End Entity Linking with Hierarchical Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aec8eed33a7f9195ba0925c798e6431702d22e1a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25535": {
    "title": "Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "10d949dee482aeea1cab8b42c326d0dbf0505de3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25536": {
    "title": "Dual Low-Rank Graph Autoencoder for Semantic and Topological Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a7adc0b3b0a87de6f57cffcd3f6133cf1041214a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25537": {
    "title": "Dynamic Multi-Behavior Sequence Modeling for Next Item Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b838508bcc1f591b7db00dabe19678fe8b0b3ce0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25538": {
    "title": "Learning Representations of Bi-level Knowledge Graphs for Reasoning beyond Link Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cce3bb3d79c8c6e6f1b6b825f444a98d12f30833",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25539": {
    "title": "Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7b7bfdc2936f09b09943d78d7b4d596f27e3274b",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25540": {
    "title": "Uniform Sequence Better: Time Interval Aware Data Augmentation for Sequential Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "614938bed58a2e496cfc373b2f70f11462506131",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25541": {
    "title": "Rule Induction in Knowledge Graphs Using Linear Programming",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b8169e28b81bce7e4fb878a3935d44829035ae2d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25542": {
    "title": "Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9fab6048fc657ec13d4a59fe21b823ecd0ab0b95",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25543": {
    "title": "DAMix: Exploiting Deep Autoregressive Model Zoo for Improving Lossless Compression Generalization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a8467d3032147d2d3508b2f98e09aea566d8a03e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25544": {
    "title": "Soft Target-Enhanced Matching Framework for Deep Entity Matching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6894a73276a06f6093c23d4320d7fae2b09f4a54",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25545": {
    "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "688a20c88a022febbd7432c5231963235d4729bd",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25546": {
    "title": "Contrastive Pre-training with Adversarial Perturbations for Check-In Sequence Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d75010b4a317f6ea5a9a26bae72505b22cb8d134",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25547": {
    "title": "MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3fd66f10b978d44e063aa23c64cdfe98722a3812",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25548": {
    "title": "Generic and Dynamic Graph Representation Learning for Crowd Flow Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a9a358cf2e3f85fa7f286e392bfb0ad232c109e5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25549": {
    "title": "Conditional Diffusion Based on Discrete Graph Structures for Molecular Graph Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "67b5d57c08176787ae7b54b65ae3bf0ac11b9b04",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25550": {
    "title": "SAH: Shifting-Aware Asymmetric Hashing for Reverse k Maximum Inner Product Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "e76548be2a8c67f437daee555bc7b246c540de42",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25551": {
    "title": "Learned Distributed Image Compression with Multi-Scale Patch Matching in Feature Domain",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "102a0f62845c3e2c351969bb210bbdc1dbc9ed6d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25552": {
    "title": "Constrained Market Share Maximization by Signal-Guided Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6d1cbfd0ab6880a5fe0f5ce95e7d4a3072955839",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25553": {
    "title": "T2-GNN: Graph Neural Networks for Graphs with Incomplete Features and Structure via Teacher-Student Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9b17f8d306e0e8264830394229e38c5d79b77523",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25554": {
    "title": "Detecting Sources of Healthcare Associated Infections",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d0a7b41426bbae754e4ff50dd2dad0741b199a15",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25555": {
    "title": "Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "abf773ddd5cb8f42a20e77effcf7e1f826991d42",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25556": {
    "title": "PDFormer: Propagation Delay-Aware Dynamic Long-Range Transformer for Traffic Flow Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38381097a0add12ff685dfaac0191c31c9ae429a",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25557": {
    "title": "Continuous Trajectory Generation Based on Two-Stage GAN",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ba316f5916807fd0b49b54452f7216c366208e1e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25558": {
    "title": "Let Graph Be the Go Board: Gradient-Free Node Injection Attack for Graph Neural Networks via Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3b494763868d078aa306c1f1b3f7c21ffd83feac",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25559": {
    "title": "GLCC: A General Framework for Graph-Level Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cbcf89becf091e3abdf86f692fc3150f0dab33a9",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25560": {
    "title": "Parameterized Algorithms for Colored Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2dfe8538b77cdccf89434f1091463dd1c0db9caa",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25561": {
    "title": "Towards Reliable Item Sampling for Recommendation Evaluation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8fdb76a8fdc41eacf3c2c87a9f3d1dba9cc0e068",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25562": {
    "title": "Multiple Robust Learning for Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "50ba1ee99c52448b0abdc0143315449fa4f5664b",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25563": {
    "title": "Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "be8e35b1753cc7aed92767db46b99289997af62d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25564": {
    "title": "Adaptive Low-Precision Training for Embeddings in Click-Through Rate Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "624c0373019dabb9f5b69464c0f094013c2b101c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25565": {
    "title": "Signed Laplacian Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "23141437bffed6d5457c676bff0b59adf6d64a9a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25566": {
    "title": "PPGenCDR: A Stable and Robust Framework for Privacy-Preserving Cross-Domain Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "370cacdf83aa10e60d79025fad336ac467eb415e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25567": {
    "title": "COLA: Improving Conversational Recommender Systems by Collaborative Augmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d02536f52b22c303e902f1a5e34ac8cfeb56a293",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25568": {
    "title": "Scalable and Effective Conductance-Based Graph Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "05930e5e7684c05fe1461f404bda10434ca143f4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25569": {
    "title": "Multi-Domain Generalized Graph Meta Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3ae83395b9ca551e0efd74fac10551e396974040",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25570": {
    "title": "IterDE: An Iterative Knowledge Distillation Framework for Knowledge Graph Embeddings",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0a400be3a281ac5f0a30df63d224f00bdaad2ad8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25571": {
    "title": "Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0cc9d031ca2f85c1412d5eab9449416c47b8cacd",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25572": {
    "title": "Low-Resource Personal Attribute Prediction from Conversations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "f1e588f1fc1e6456c7ec14a984c630ef58f8df9c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25573": {
    "title": "Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b29aec89e64bb20f2b963e5615c79b9008ecfd88",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25574": {
    "title": "On Generalized Degree Fairness in Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6c26e7f14b52332087c9a1e07e09a2b882665ef3",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25575": {
    "title": "Time Series Contrastive Learning with Information-Aware Augmentations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6e70a2b7512fde9d25176c508f9cad35e47f66ad",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25576": {
    "title": "NQE: N-ary Query Embedding for Complex Query Answering over Hyper-Relational Knowledge Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d94e7aeab88d07f0b50b7866ceb5baa3c29be859",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25577": {
    "title": "FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4af58fc20efaa3856df8609921b6a022f8f9d3ac",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25578": {
    "title": "GMDNet: A Graph-Based Mixture Density Network for Estimating Packages' Multimodal Travel Time Distribution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0a9d4820dee3d1de377a7ba16223653701ba726e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25579": {
    "title": "Logic and Commonsense-Guided Temporal Knowledge Graph Completion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3e0a7f3f98e49d0a690842a5692e723615c44928",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25580": {
    "title": "Graph Structure Learning on User Mobility Data for Social Relationship Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cca56116eea606d1be0dd258f03f4c3c679c065a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25581": {
    "title": "Online Random Feature Forests for Learning in Varying Feature Spaces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4482de2f9d3ff6b74d774c9a67a9d6cf5fa5fc59",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25582": {
    "title": "Scaling Law for Recommendation Models: Towards General-Purpose User Representations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7567744a0e23174166575e8d98590967684696b4",
    "semantic_title": "",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25583": {
    "title": "Cross-Domain Adaptative Learning for Online Advertisement Customer Lifetime Value Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "562f254f7b0fccba6377a513fc95cbbb4bf80ee7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25584": {
    "title": "Self-Supervised Interest Transfer Network via Prototypical Contrastive Learning for Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "09aedbfbc314006bac8e7cead1b838439705f449",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25585": {
    "title": "Opinion Optimization in Directed Social Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a4984e10597e3c8a77f1675a48eb7dc6d5252e72",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25586": {
    "title": "Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6796467c5662e07f5f7bbd685f6a9c59cfbf99ec",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25587": {
    "title": "Self-Organization Preserved Graph Structure Learning with Principle of Relevant Information",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b501be9cac69f1fa58ef2887017d0dd94d233b68",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25588": {
    "title": "Efficient Embeddings of Logical Variables for Query Answering over Incomplete Knowledge Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7d275bb20b36926e039fb604f9fb93340a70e63c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25589": {
    "title": "Human-Instructed Deep Hierarchical Generative Learning for Automated Urban Planning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3480471572fd3908e72cf827b3e4ca532f286fc5",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25590": {
    "title": "Easy Begun Is Half Done: Spatial-Temporal Graph Modeling with ST-Curriculum Dropout",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e07be0014393a4a8c9521e49bc640074c78b6333",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25591": {
    "title": "Cross-Domain Graph Anomaly Detection via Anomaly-Aware Contrastive Alignment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c310a633d4fe1b3be759588656c0763cacc4071e",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25592": {
    "title": "WSiP: Wave Superposition Inspired Pooling for Dynamic Interactions-Aware Trajectory Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ded88b250761f197a5a8b7f225c6f914cc6b49fd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25593": {
    "title": "Beyond Graph Convolutional Network: An Interpretable Regularizer-Centered Optimization Framework",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4239fce31468d3188ce9baed53280051da19c494",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25594": {
    "title": "Augmenting Affective Dependency Graph via Iterative Incongruity Graph Learning for Sarcasm Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f50f7e50573876fde5e9ae714ffb95354b68a0bb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25595": {
    "title": "Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "26ebeeb1b9172df34ad21f1000bb6f3c374a222e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25596": {
    "title": "Online Semi-supervised Learning with Mix-Typed Streaming Features",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c5e68be7506eadf90435539490f6b75343eb7347",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25597": {
    "title": "Few-Shot Composition Learning for Image Retrieval with Prompt Tuning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "510f41c71a8751832cc97d79a0df673a0c2b0539",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25598": {
    "title": "ConTextual Masked Auto-Encoder for Dense Passage Retrieval",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "63a38cb55e0b9f91c0676efd79089debe61c7768",
    "semantic_title": "",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25599": {
    "title": "Jointly Imputing Multi-View Data with Optimal Transport",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "781fad0aaf23ca028fa35ba7ad8b3a97d349052b",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25600": {
    "title": "Knowledge Graph Embedding by Normalizing Flows",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2e3cdedd8c2ce304fdfe861f3c2f4c68e85c9aed",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25601": {
    "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "22157f0bcde877743dc95715cf570d672f76520a",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25602": {
    "title": "SCI: A Spectrum Concentrated Implicit Neural Compression for Biomedical Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d589135b7cc3019a2170676d69b1a4c1505e775c",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25603": {
    "title": "Unsupervised Legal Evidence Retrieval via Contrastive Learning with Approximate Aggregated Positive",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cc8ba45e69cd4073e43926a7abd8403236f8870b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25604": {
    "title": "One-for-All: Proposal Masked Cross-Class Anomaly Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e29734b4945611c4eeb49bd176086881e71ba25a",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25605": {
    "title": "Analogical Inference Enhanced Knowledge Graph Embedding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "354b651dbc3ba2af4c3785ccbecd3df0585d30b2",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25606": {
    "title": "A Noise-Tolerant Differentiable Learning Approach for Single Occurrence Regular Expression with Interleaving",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2764258ec19ed233f2871574f31f90e587cdac01",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25607": {
    "title": "Learning from the Wisdom of Crowds: Exploiting Similar Sessions for Session Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "163252e0a3de4b60382e158f0447c647782b591c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25608": {
    "title": "Next POI Recommendation with Dynamic Graph and Explicit Dependency",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b54d3c2e7d971ae03017b0ae196d4abc61c920ce",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25609": {
    "title": "Predicting Temporal Sets with Simplified Fully Connected Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f9c59365254eed5fa64cc9b44c29a23760dc01de",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25610": {
    "title": "Learning to Count Isomorphisms with Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "674e14227bd9aacb41a02fb195951ddddd30cd66",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25611": {
    "title": "Untargeted Attack against Federated Recommendation Systems via Poisonous Item Embeddings and the Defense",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "77f1d71efcfc733fa9efcdb7492d1310185b0de6",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25612": {
    "title": "Practical Cross-System Shilling Attacks with Limited Access to Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c81c5307175bc683b096496ff44fdb6419ae18ae",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25613": {
    "title": "Query-Aware Quantization for Maximum Inner Product Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8e74644b3d1b92037b478303df0860591a030fd3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25614": {
    "title": "TOT：Topology-Aware Optimal Transport for Multimodal Hate Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "c90d18d5cd8b1e07f8a8b6b9d14a85b03d55b4b6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25615": {
    "title": "Cross-Domain Few-Shot Graph Classification with a Reinforced Task Coordinator",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "12313819cdb18f6e11da1a449a087220810bdd99",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25616": {
    "title": "AutoSTL: Automated Spatio-Temporal Multi-Task Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "64ff803d5256b6b48c74ac5229db4c7a864172a7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25617": {
    "title": "Fair Representation Learning for Recommendation: A Mutual Information Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ef720e1b70188ef7f31f73a6940229d7e7dce73b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25618": {
    "title": "Deep Graph Structural Infomax",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c38be73c2e17cd2a0f808fe6ae008c1f248fa989",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25619": {
    "title": "Causal Conditional Hidden Markov Model for Multimodal Traffic Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f4472361e74e441a1539251868e077884c7b7042",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25620": {
    "title": "ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f1305bbd54db0345533906726e3425f742312c55",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25621": {
    "title": "A Provable Framework of Learning Graph Embeddings via Summarization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc4bf8864aff1d41ad76d677714ea21606b290c4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25622": {
    "title": "GraphSR: A Data Augmentation Algorithm for Imbalanced Node Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "296049ee701634e7919b8f334da285ca7c54bfba",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25623": {
    "title": "Detecting Multivariate Time Series Anomalies with Zero Known Label",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4ba2f8dfc1a4fccec80cf95ce3f0eeff3066f21e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25624": {
    "title": "GRLSTM: Trajectory Similarity Computation with Graph-Based Residual LSTM",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "48402bec037fc2a5033c4dc7f90733b7e86da446",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25625": {
    "title": "Heterogeneous Region Embedding with Prompt Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2c6f266b833aa65bc8014f8cd052b823929ca2c1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25626": {
    "title": "Show Me the Way! Bilevel Search for Synthesizing Programmatic Strategies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2a9f5132f22418f4c3eec95521dc7d3fb959b4f3",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25627": {
    "title": "Anytime User Engagement Prediction in Information Cascades for Arbitrary Observation Periods",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c538e5cfc2c908bf833f8453c72f82a63465a26b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25628": {
    "title": "Principled Data-Driven Decision Support for Cyber-Forensic Investigations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "36c3e9fce1e1eec51cea57ec5ebc339ba0e11e2c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25629": {
    "title": "BETA-CD: A Bayesian Meta-Learned Cognitive Diagnosis Framework for Personalized Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "44deaf38f9a4b9a0c274fbc4acc5ace2d6f06c01",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25630": {
    "title": "Set-to-Sequence Ranking-Based Concept-Aware Learning Path Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4a2ac894fad19b6c8bd0984ed5e205d63376cdb7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25631": {
    "title": "Unsupervised Deep Embedded Fusion Representation of Single-Cell Transcriptomics",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "79bbb02ade124c82c663b5f1ee9ef9fdce0d4f6d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25632": {
    "title": "Constrained Submodular Optimization for Vaccine Design",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9ded91f056e1d073029b662d69b1847e1cc1060e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25633": {
    "title": "Flow-Based Robust Watermarking with Invertible Noise Layer for Black-Box Distortions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9be90c6279e4133c7b2891bb5513b417da490857",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25634": {
    "title": "Identifying and Eliminating Majority Illusion in Social Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2195aff9d693a39c92c469cd64aef681b6716ad7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25635": {
    "title": "A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention Mechanism for Symbolic Music Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aec9ae3c0e5a5784e171dbb7aa58c209de89e404",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25636": {
    "title": "MSDC: Exploiting Multi-State Power Consumption in Non-intrusive Load Monitoring Based on a Dual-CNN Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7c238db86fc92dbd85544f4c89c3c82cf008d06e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25637": {
    "title": "Integrating Reward Maximization and Population Estimation: Sequential Decision-Making for Internal Revenue Service Audit Selection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e17ba7c1a91e51070a308039ef53f0deec2cee2a",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25638": {
    "title": "MGTCF: Multi-Generator Tropical Cyclone Forecasting with Heterogeneous Meteorological Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8651b010f8615d6dacd089f510b222e434c46f28",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25639": {
    "title": "MDM: Molecular Diffusion Model for 3D Molecule Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "161858efd41df44a826feb52c27f29eaf8bce80d",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25640": {
    "title": "Learning Chemical Rules of Retrosynthesis with Pre-training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7cbe75ef6748e461d18f964d99ea7f4e8f8d539a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25641": {
    "title": "Online Symbolic Regression with Informative Query",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b3eee07ad5e785d9d6124a08cce985fe034c83bf",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25642": {
    "title": "Repair Is Nearly Generation: Multilingual Program Repair with LLMs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "453a8fac3be9282be53908f0735160d0d21e0f48",
    "semantic_title": "",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25643": {
    "title": "Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ef7ef2cb643acb5bba3e8c249d0663ee1a4d8108",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25644": {
    "title": "Rolling Horizon Based Temporal Decomposition for the Offline Pickup and Delivery Problem with Time Windows",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "02aeb1c12b95530cd5381d13e0bc9edb121dba4b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25645": {
    "title": "GRIP: Graph Representation of Immune Repertoire Using Graph Neural Network and Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a15c413c629113dde457ffdf10d9a55b76e35a43",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25646": {
    "title": "LagNet: Deep Lagrangian Mechanics for Plug-and-Play Molecular Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a422712a543a43b3c64be2505aa8435333270b1d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25647": {
    "title": "Steganography of Steganographic Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7a672ec588ce8c11ef7b68ee8585ccf5766e7827",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25648": {
    "title": "PEN: Prediction-Explanation Network to Forecast Stock Price Movement with Better Explainability",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3901de60ef6fc8f73d0720bd76b0918254d22613",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25649": {
    "title": "Decision-Making Context Interaction Network for Click-Through Rate Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "608632865430a81e20528a57bff20cecc4f3ce1b",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25650": {
    "title": "Fine-Grained Position Helps Memorizing More, a Novel Music Compound Transformer Model with Feature Interaction Fusion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "79efb734cef71f93ad4c875044f9fb4d2cd6079d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25651": {
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "376345572946f8710e265e10be270373587d4c4e",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25652": {
    "title": "On Manipulating Weight Predictions in Signed Weighted Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6cf75aa820ccfbb7b07f80ceb4bc446f879ce65a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25653": {
    "title": "Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "65f86451e96ad61ffca50eed6a007a19bc03093d",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25654": {
    "title": "MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "31a84391e1b47fa15f3a521c43d62385a7757637",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25655": {
    "title": "HG-SL: Jointly Learning of Global and Local User Spreading Behavior for Fake News Early Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d3c6898458ee72eb35276a1244049b17f5f9be5c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25656": {
    "title": "Defending against Backdoor Attacks in Natural Language Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "834891acb1dfeacb9ff75f923feeca66347167d7",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25657": {
    "title": "GenéLive! Generating Rhythm Actions in Love Live!",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "27c4f8efcc548e74983c165f99b6711ec1c0699d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25658": {
    "title": "Deepfake Video Detection via Facial Action Dependencies Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e3e269034ebfc94da52d2133239114046c8c12ae",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25659": {
    "title": "Contrastive Attention Networks for Attribution of Early Modern Print",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d9dc309f719233be9f2a6b6910072e537f96eec8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25660": {
    "title": "AdapSafe: Adaptive and Safe-Certified Deep Reinforcement Learning-Based Frequency Control for Carbon-Neutral Power Systems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "11389a70e115c21169f365f3e944f517cebfe555",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25661": {
    "title": "Don't Predict Counterfactual Values, Predict Expected Values Instead",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "88d1fc95d1d8452d1cbb41b07fa0829e62f1fb66",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25662": {
    "title": "Molformer: Motif-Based Transformer on 3D Heterogeneous Molecular Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "540ed994eb00b5279748d1f26d04371e3a67ec0d",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25663": {
    "title": "DiffMD: A Geometric Diffusion Model for Molecular Dynamics Simulations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6fe2208f1c4dba1c9959f2dd4fdb6c2dc245b713",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25664": {
    "title": "Retrosynthesis Prediction with Local Template Retrieval",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7045e1e30c2eb8f305dcb8ded655ff659f53fefd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25665": {
    "title": "Multi-Relational Contrastive Learning Graph Neural Network for Drug-Drug Interaction Event Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0ba58a80635fad308adfa41d76931c4f73ba8c54",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25666": {
    "title": "Tighter Robust Upper Bounds for Options via No-Regret Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b764a3ccd99b4bbac95d5f321eb4ad1ac4173224",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25667": {
    "title": "KerPrint: Local-Global Knowledge Graph Enhanced Diagnosis Prediction for Retrospective and Prospective Interpretations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2b5eef580fb9fa9e0f9d946feb2819ad63eb011a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25668": {
    "title": "Multi-Label Few-Shot ICD Coding as Autoregressive Generation with Prompt",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b87c9700b8de4912fe7c361574640b5dc536ca9",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25669": {
    "title": "DMIS: Dynamic Mesh-Based Importance Sampling for Training Physics-Informed Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "45017fc77acd06a13d231900f548806bf804beb5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25670": {
    "title": "Bootstrapping Multi-View Representations for Fake News Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38ff6bae846d70d341c8732717c0f593180f318b",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25671": {
    "title": "Overcoming Forgetting in Fine-Grained Urban Flow Inference via Adaptive Knowledge Replay",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "54eec69dadad0093b38be8488968e7786a5fb376",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25672": {
    "title": "Generalized Cell Type Annotation and Discovery for Single-Cell RNA-Seq Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7ca5419b63753fbb249860d45a66cbc4052397bd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25673": {
    "title": "Mining and Applying Composition Knowledge of Dance Moves for Style-Concentrated Dance Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b1574e3fff207020073b54b7367f2da80f64740b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25674": {
    "title": "Yet Another Traffic Classifier: A Masked Autoencoder Based Traffic Transformer with Multi-Level Flow Representation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4ba78edb48d729339b109b1ae707daafcca8e005",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25675": {
    "title": "Loan Fraud Users Detection in Online Lending Leveraging Multiple Data Views",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5631b6811a2cff4d35aea151398154a929da8b24",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25676": {
    "title": "Sparse Maximum Margin Learning from Multimodal Human Behavioral Patterns",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f4150ac3683f5bb310a409c280123238e0da701f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25677": {
    "title": "Direct Heterogeneous Causal Learning for Resource Allocation Problems in Marketing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f1ca2cce6c8e53488983a89bccfe34c976202f7b",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25678": {
    "title": "Mediated Cheap Talk Design",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "b379528382393126720280c848f45bb9aa9db0e8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25679": {
    "title": "Bidding Graph Games with Partially-Observable Budgets",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cf7c118beeca6e1ed555164151a084a6286a8dc9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25680": {
    "title": "Fairness Concepts for Indivisible Items with Externalities",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f92552c73d2b67e671fec7d5fced0f2195dc0502",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25681": {
    "title": "Finding Fair Allocations under Budget Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "51e020d339e00afca58dc703ef91d217d00ea869",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25682": {
    "title": "Now We're Talking: Better Deliberation Groups through Submodular Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aead5a64ee1ef40829300401debe649772d7c26c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25683": {
    "title": "Causes of Stability in Dynamic Coalition Formation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d1664faf020d247b8b0a9cc775fb11152a6c38dc",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25684": {
    "title": "Properties of Position Matrices and Their Elections",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0eafc75d4dd73a9491dd031e54af5b048936b83a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25685": {
    "title": "Rank Aggregation Using Scoring Rules",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "36814dc10e6f759c87520b080a6dd339f74c32be",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25686": {
    "title": "Proportionality in Approval-Based Participatory Budgeting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8c4aed0f334de39822ece80507b83786f9dbc60f",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25687": {
    "title": "Multiwinner Voting with Possibly Unavailable Candidates",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c15f4da85b4d487ffed1b9c731f8411551a8a856",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25688": {
    "title": "Fair Division with Prioritized Agents",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7e2eb9aa34c5d218e195a5c9f7706a5be895081e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25689": {
    "title": "Topological Distance Games",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "31cc4da32ba25ce18bace942361fd8eff3fad994",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25690": {
    "title": "Game Implementation: What Are the Obstructions?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bbe7f2e5001559daa2f06b99c7cf5456966953e5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25691": {
    "title": "A Pair-Approximation Method for Modelling the Dynamics of Multi-Agent Stochastic Games",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ab178e4e4389cc2578617dec3186c313b4a35cb2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25692": {
    "title": "Complexity of Probabilistic Inference in Random Dichotomous Hedonic Games",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "153d83340025647e8dc36945478cd4ff4eda043e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25693": {
    "title": "Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare Optimality at Equilibrium and Optimal Deviation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7780bfd2cc56a38d0cf34edf88f7be79e9d25dd2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25694": {
    "title": "Strategyproofness and Proportionality in Party-Approval Multiwinner Elections",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3f3c8d4ad8a89239bbd9b2d31a6c54cb396d3930",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25695": {
    "title": "Tight Inapproximability for Graphical Games",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ca20eb26ec877f403db50049252511e47741c23f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25696": {
    "title": "From Monopoly to Competition: Optimal Contests Prevail",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3a0108111588f59d44689c7162e930fec1d1701d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25697": {
    "title": "Commitment Games with Conditional Information Disclosure",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "54226bde1774d6a113ad871445775a84962aab35",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25698": {
    "title": "Rawlsian Fairness in Online Bipartite Matching: Two-Sided, Group, and Individual",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e31ff605e3db3449e0c999998365f6c95c2767e6",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25699": {
    "title": "Participatory Budgeting Designs for the Real World",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "183f37a03ca82e44a6468baa7e464c013e892011",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25700": {
    "title": "PAC Learning and Stabilizing Hedonic Games: Towards a Unifying Approach",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "27a17341f41c0af03606f43f56cba72b32ffbf94",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25701": {
    "title": "Scalable Edge Blocking Algorithms for Defending Active Directory Style Attack Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7c67df2dc35e8d99dc419fbc138bbc1fab579f51",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25702": {
    "title": "Representation with Incomplete Votes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5ae0490ac110effedd47d13eeb1e71d33f31da47",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25703": {
    "title": "Optimizing Multiple Simultaneous Objectives for Voting and Facility Location",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e0cf0244be1a0ed9d761742614adec024bfa3469",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25704": {
    "title": "Class Fairness in Online Matching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "462c81b0c6b03df11b4bfa0f0345e100e3b33fbc",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25705": {
    "title": "How to Cut a Discrete Cake Fairly",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "555d80712ae5fcef4b319c3ba0265171cad33768",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25706": {
    "title": "Competition, Alignment, and Equilibria in Digital Marketplaces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a2b3696dab23be25c8cda81490c54c5e6ea53c6",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25707": {
    "title": "Voting with Preference Intensities",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0f161bcb249a2ce6a2c97b5d4a93184d89ff39fa",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25708": {
    "title": "Approximations for Indivisible Concave Allocations with Applications to Nash Welfare Maximization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bd29605b3a91f1d1166a42514a5c96a6d577ccdd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25709": {
    "title": "Strategic Facility Location with Clients That Minimize Total Waiting Time",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a22b3b66794a0d2e06f57753b555b82ee006e591",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25710": {
    "title": "Proportional Decisions in Perpetual Voting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a21a5610157afb24f4a3229f31adea835f507ca2",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25711": {
    "title": "Multiagent MST Cover: Pleasing All Optimally via a Simple Voting Rule",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c8e78fea7189e12c1778fc110852253b0f1ccca4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25712": {
    "title": "When Congestion Games Meet Mobile Crowdsourcing: Selective Information Disclosure",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2310aaa5d2e3cf9d47b1168cd4a560a144cbf28a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25713": {
    "title": "Partitioning Friends Fairly",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1fdc1d82b449862d77dbaf26b4d007c80cd74434",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25714": {
    "title": "Differentially Private Condorcet Voting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "31d165e97e8e2c13fe3b3dc55e0e338491633b9a",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25715": {
    "title": "Function Approximation for Solving Stackelberg Equilibrium in Large Perfect Information Games",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9f8ff18066b6de9249c76a23d4a8d265bc08ce5b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25716": {
    "title": "Optimal Pricing Schemes for Identical Items with Time-Sensitive Buyers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9ed19cfe4e0dcad4e45f6fe90fe62875dd851378",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25717": {
    "title": "Approval-Based Voting with Mixed Goods",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4ddf61206194976246e3498899a3e56c0623f606",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25718": {
    "title": "Utility Maximizer or Value Maximizer: Mechanism Design for Mixed Bidders in Online Advertising",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ed2c8a88b17172d3169a5b86fc83e05807639b4b",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25719": {
    "title": "Facility Location Games with Entrance Fees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3fc4bde395cfbcf0c3b3ddb0c47fd41d696a9d2e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25720": {
    "title": "Securing Lifelines: Safe Delivery of Critical Services in Areas with Volatile Security Situation via a Stackelberg Game Approach",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9222a8fd12e782e07425db00b085a52824fa62d2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25721": {
    "title": "Differentially Private Fair Division",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3828d5639e3967d199a0cd6d8a5c2aa434a30ba1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25722": {
    "title": "An Efficient Deep Reinforcement Learning Algorithm for Solving Imperfect Information Extensive-Form Games",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7674101bb85b2fc228d7a6c8b4eace078a8ba381",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25723": {
    "title": "Fast and Interpretable Dynamics for Fisher Markets via Block-Coordinate Updates",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "92841069ddd8ea9c3d9a8e46121430540382aa72",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25724": {
    "title": "Ballot Length in Instant Runoff Voting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "73a36bafe6953371e71d22e011b6aff726e6afab",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25725": {
    "title": "Multi-Stage Facility Location Problems with Transient Agents",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dcc51879ceb777063f697f1f5ae0050d273932c7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25726": {
    "title": "Bayesian Optimization-Based Combinatorial Assignment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1ec31c7e532b18a5c1724a34689baba35e050c0e",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25727": {
    "title": "Semi-random Impossibilities of Condorcet Criterion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e642adacb243f5448c31072e9c68f05905840848",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25728": {
    "title": "Tournament Fixing Parameterized by Feedback Vertex Set Number Is FPT",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "058d26b18a3b230e81fd4259aa2c903b01d93f1c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25729": {
    "title": "Truthful Mechanisms for Steiner Tree Problems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b2b230df548eef82aa4ed60aa6aa0af29fc0d42",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25730": {
    "title": "Collusion-Proof and Sybil-Proof Reward Mechanisms for Query Incentive Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8459e8869b782ded45ef762d728642d3919ae075",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25731": {
    "title": "Fisher Markets with Social Influence",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "189e54a3a2e519bfaa65e33b1d3a35fa0ba2122a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25732": {
    "title": "Probably Approximate Shapley Fairness with Applications in Machine Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a6a83c55042d4c48b4cd17b37b8a6991f69d51e6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25733": {
    "title": "The Perils of Trial-and-Error Reward Design: Misdesign through Overfitting and Invalid Task Specifications",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "688fc1e744877c3a68f306443042f016196ce98a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25734": {
    "title": "The Value of AI Guidance in Human Examination of Synthetically-Generated Faces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f02ec8381a96bf00f691fdddc28bc6dfbb8a5780",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25735": {
    "title": "Teaching to Learn: Sequential Teaching of Learners with Internal States",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1fa00fa4c018d90f2597d9e5b9a5fd2ee17896f9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25736": {
    "title": "Interactive Concept Bottleneck Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5cc7508c4168e8583a9971115117b552479c5f24",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25737": {
    "title": "Local Justice and Machine Learning: Modeling and Inferring Dynamic Ethical Preferences toward Allocations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6dc75e20e8146182e7076450841bbb8c2f70935a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25738": {
    "title": "Extracting Semantic-Dynamic Features for Long-Term Stable Brain Computer Interface",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ae324c30938b1c7a871c2de5104cd5a780e52d71",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25739": {
    "title": "Moral Machine or Tyranny of the Majority?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d655026a443d3de40ebacf61274e562ec05936ef",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25740": {
    "title": "The Effect of Modeling Human Rationality Level on Learning Rewards from Multiple Feedback Types",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e920f426eb32e64474b2a1176d97725f875dd82a",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25741": {
    "title": "The Role of Heuristics and Biases during Complex Choices with an AI Teammate",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4006f4acbcd0f97b0f4763b1dc1404ad923cfabd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25742": {
    "title": "Learning to Defer with Limited Expert Predictions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "740ea8d58050d823ed4e6bdc89e7b136ada80b26",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25743": {
    "title": "SWL-Adapt: An Unsupervised Domain Adaptation Model with Sample Weight Learning for Cross-User Wearable Human Activity Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e5306c39f2d88c7d479fbd08ae630af7239b5e56",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25744": {
    "title": "Incentive-Boosted Federated Crowdsourcing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f4368aa571b71165d19dc08ae1f589296207e144",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25745": {
    "title": "Towards Voice Reconstruction from EEG during Imagined Speech",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c6b97adc9fc7a6619d43b269a9e3dc2321df8f03",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25746": {
    "title": "Evaluating and Improving Interactions with Hazy Oracles",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dcfcac9943a67748c8f5831272a6ad545b78bcb0",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25747": {
    "title": "Human-in-the-Loop Vehicle ReID",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e8f5a0db120e6fa63e3555d6e84e4809cb0666de",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25748": {
    "title": "Modeling Human Trust and Reliance in AI-Assisted Decision Making: A Markovian Approach",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c7fbdc22ac13f0e1944262379bc1b41d188cc0b5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25749": {
    "title": "Learning Deep Hierarchical Features with Spatial Regularization for One-Class Facial Expression Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "02aa368f27c539415b555b2c01ce037e5ff6b2ec",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25750": {
    "title": "Frustratingly Easy Truth Discovery",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "3dc5c5e420a2bcdb75e98ca55a033b83bea36618",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25751": {
    "title": "Beam Search Optimized Batch Bayesian Active Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d1e41e2de8e79735b0f1302ac28544bdd450ac6e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25752": {
    "title": "Multi-Scale Control Signal-Aware Transformer for Motion Synthesis without Phase",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4c4ee8e1a92e0eda686c3bd80d25c5785c57ed28",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25753": {
    "title": "SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "040c9807983131ad611b3a927e63b1267a37986d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25754": {
    "title": "Human Joint Kinematics Diffusion-Refinement for Stochastic Motion Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "34f622243804ba15e29f1a22a8898eb4cf33772d",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25755": {
    "title": "Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3e6c44fa97a3871eb67467cfac40fb6cf56f104d",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25756": {
    "title": "Learning to Select Pivotal Samples for Meta Re-weighting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5e5e1ef8e856596df92fb65c4459052109014398",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25757": {
    "title": "Better Peer Grading through Bayesian Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c58cd28fbb8ad552b402582d32b068d7aa9452b7",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25758": {
    "title": "Maximum Entropy Population-Based Training for Zero-Shot Human-AI Coordination",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "4270f2493dfd9ae26b9f7c707cf1398ddbbdc0a1",
    "semantic_title": "",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25759": {
    "title": "A Set of Control Points Conditioned Pedestrian Trajectory Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8c6eef90065c8c35e6051e80478c993b48a783e8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25760": {
    "title": "Meta-Auxiliary Learning for Adaptive Human Pose Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "390a927e0c70bdc3e3a327dc8f18a0a90b9f82b9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25761": {
    "title": "Moving-Landmark Assisted Distributed Learning Based Decentralized Cooperative Localization (DL-DCL) with Fault Tolerance",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0bf16ee9abecd5fba62b89f9fa29c0d2b6422157",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25762": {
    "title": "Periodic Multi-Agent Path Planning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "94ccc03294726ad795c0379bf7059aa377ed3b22",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25763": {
    "title": "Improving Robotic Tactile Localization Super-resolution via Spatiotemporal Continuity Learning and Overlapping Air Chambers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "58d73309807f7811722dda39d5867548337e0412",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25764": {
    "title": "Co-imitation: Learning Design and Behaviour by Imitation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "854a3a3212d33a9a05bd498874cfa3ddb0232535",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25765": {
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "08c1b87c94e741c09985d37872c1ae14c6c7c2e4",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25766": {
    "title": "Abstract Argumentation Framework with Conditional Preferences",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ed43175c3bd2e197de2eb4558528c09017c23c17",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25767": {
    "title": "Reactive Synthesis of Dominant Strategies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "68d20218ac2adae05d799f9b2ea25d8598a1075f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25768": {
    "title": "Complexity of Safety and coSafety Fragments of Linear Temporal Logic",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "11057109ab2652f228d944be6f77c566e86a34e6",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25769": {
    "title": "Automatically Verifying Expressive Epistemic Properties of Programs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5ba6cfee1efd0cddec2e744b12f0cca7e76ad3e8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25770": {
    "title": "The Effect of Preferences in Abstract Argumentation under a Claim-Centric View",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3971d26cf23d95487e333384a3cb58bfe26dbd32",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25771": {
    "title": "The Parameterized Complexity of Network Microaggregation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "35f9b5d2e666a7139be61e30a939885917e2a844",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25772": {
    "title": "SMT Safety Verification of Ontology-Based Processes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c191ecb6c77ad9c74d6aba0f68f628436ecc6b69",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25773": {
    "title": "Epistemic Disjunctive Datalog for Querying Knowledge Bases",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "716ff41912617caddd2b4386a1071f5ad7249679",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25774": {
    "title": "Learning Logic Programs by Discovering Where Not to Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f7bcdc6e791173001b25acdd3f98b8cc44a7fd69",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25775": {
    "title": "From Width-Based Model Checking to Width-Based Automated Theorem Proving",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0b112e2d1f4876f58190322b6496cfa1011736e4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25776": {
    "title": "Model-Checking for Ability-Based Logics with Constrained Plans",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d0d9dee80c3177e67cd3e678a9c92ad6beac31b0",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25777": {
    "title": "A Structural Complexity Analysis of Synchronous Dynamical Systems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "91704981d91f327d3304eea20d75f318b969448e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25778": {
    "title": "Evaluating Epistemic Logic Programs via Answer Set Programming with Quantifiers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c27c2a50eb30d1b292b4ef1827532bd7c0d76106",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25779": {
    "title": "Reachability Games Modulo Theories with a Bounded Safety Player",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8e6d4933293895540519b1c31645456da9f94e28",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25780": {
    "title": "Splitting Answer Set Programs with Respect to Intensionality Statements",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7d0725ae29843fdd48075d7c4f228440b377be45",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25781": {
    "title": "Monitoring Arithmetic Temporal Properties on Finite Traces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "441f1b0d50a6e16de8794c1a3154405acfd40559",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25782": {
    "title": "Untangled: A Complete Dynamic Topological Logic",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9bb88a92bf5b3e4bd9813c9a85e6e2d95916311f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25783": {
    "title": "Inconsistent Cores for ASP: The Perks and Perils of Non-monotonicity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5cdd45ffb85a3b654d49983f3f8d98075c8aa83f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25784": {
    "title": "General Acyclicity and Cyclicity Notions for the Disjunctive Skolem Chase",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "56a6b99fe7d331e20786cbfedf2c96651539d59c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25785": {
    "title": "GANTEE: Generative Adversarial Network for Taxonomy Enterance Evaluation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "25db8a16e39af2aea2bc2dea7aab1862b04a9b7c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25786": {
    "title": "Finite Based Contraction and Expansion via Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "53097257a9bb71b1af91da5d99c211311b0476da",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25787": {
    "title": "MAPS-KB: A Million-Scale Probabilistic Simile Knowledge Base",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "83ab9f2fdb2d7445f8b72b732fe17f9e21603082",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25788": {
    "title": "Characterizing Structural Hardness of Logic Programs: What Makes Cycles and Reachability Hard for Treewidth?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "adbce6d521643cb25c30dc0ffb9d0d0080e7a92c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25789": {
    "title": "Conditional Syntax Splitting for Non-monotonic Inference Operators",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e10984c1c2ac697c49222a118a4cadeffa93f57d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25790": {
    "title": "Relational Program Synthesis with Numerical Reasoning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c150adaab6e5887ef9ceae25214076468f42534e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25791": {
    "title": "Common Knowledge of Abstract Groups",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e7f497d35a06594fe2722946a0ed8539b3342817",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25792": {
    "title": "FASTDIAGP: An Algorithm for Parallelized Direct Diagnosis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "349899ad280bcff77e39689df88e0fc7de852a2d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25793": {
    "title": "Two Views of Constrained Differential Privacy: Belief Revision and Update",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc06e5d3cf4ac73f5b6786ac296f9fec15026800",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25794": {
    "title": "Copyright-Certified Distillation Dataset: Distilling One Million Coins into One Bitcoin with Your Private Key",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "05cad00486c1ab88452d9b355477851e1bca9075",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25795": {
    "title": "DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link Prediction and Entity Typing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dc26b544e5bbdd149d6e52ab6e3fe155684829a2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25796": {
    "title": "Automated Verification of Propositional Agent Abstraction for Classical Planning via CTLK Model Checking",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "072f7b74cf9bf19d6b498aed1aeb23ece57cc1e9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25797": {
    "title": "Efficient Answer Enumeration in Description Logics with Functional Roles",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "22eddbaef959961c58ec8b23ea5920c2a1fc75de",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25798": {
    "title": "Distributed Spectrum-Based Fault Localization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "28ac25147389c16bf5ea4d0fdaa3b1d7bd4f8cea",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25799": {
    "title": "Multi-Level Wavelet Mapping Correlation for Statistical Dependence Measurement: Methodology and Performance",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "61a6c57d88c71dffc1cd0b9ee9a424fa4f5a84b3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25800": {
    "title": "Learning Interpretable Temporal Properties from Positive Examples Only",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "713bf335895f27fa0f08a3366cb9f74ad8523d01",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25801": {
    "title": "Editing Boolean Classifiers: A Belief Change Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f7d7e2906b9de71b55a36e155e430c80771df3c0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25802": {
    "title": "Implementing Bounded Revision via Lexicographic Revision and C-revision",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "37defded961bbaa40a5a2e4b2e7a4d64fc810761",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25803": {
    "title": "Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4020f2736d49368fc38b3f0c59c6f8b90e29e355",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25804": {
    "title": "Learning to Break Symmetries for Efficient Optimization in Answer Set Programming",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "520d96e06afb9ab0ad9afc3f3a6c31b3fae3d6de",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25805": {
    "title": "On Undisputed Sets in Abstract Argumentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a0d92572c348b42c3cdbc7b8ab2c44d0ba8b5a00",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25806": {
    "title": "Neurosymbolic Reasoning and Learning with Restricted Boltzmann Machines",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3b1d4dd5f407f08295bc5d9865f5b48bff3d67df",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25807": {
    "title": "Materialisation-Based Reasoning in DatalogMTL with Bounded Intervals",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d4a432b0cc0a5d488915053536af171eb4bd6055",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25808": {
    "title": "Efficient Extraction of EL-Ontology Deductive Modules",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6d45b678c6e09dcff3928d060e28e5d621d28272",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25809": {
    "title": "Visually Grounded Commonsense Knowledge Acquisition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "03c4ecc2796ecde6a93562fdd149cea10157f805",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25810": {
    "title": "DNG: Taxonomy Expansion by Exploring the Intrinsic Directed Structure on Non-gaussian Space",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5db9df997254ab379f195d7ad494e7ccbab4d91d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25811": {
    "title": "Quality-Aware Self-Training on Differentiable Synthesis of Rare Relational Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bbf8add6afcfba8be55b92dc94dad68d34db6594",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25812": {
    "title": "Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "10bbe48c262a4fcf666bf93855bfd3cafb9f71f7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25813": {
    "title": "McOmet: Multimodal Fusion Transformer for Physical Audiovisual Commonsense Reasoning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4cf34a7c4b622f48047df066d8be23f8984fbf09",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25814": {
    "title": "Approximating Full Conformal Prediction at Scale via Influence Functions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b29b6315506a0db2cd39cb9faee82c2e8cc0105b",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25815": {
    "title": "Efficient Distributed Inference of Deep Neural Networks via Restructuring and Pruning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f4850283e7220666b04ee78d43bdc0db38032271",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25816": {
    "title": "Symbolic Metamodels for Interpreting Black-Boxes Using Primitive Functions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b457b163f3e2ffd700918ed8e52d8c18c1115b21",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25817": {
    "title": "Utilizing Prior Solutions for Reward Shaping and Composition in Entropy-Regularized Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3098fd3d604086202f51aee3b5e6071639908be1",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25818": {
    "title": "Clustering What Matters: Optimal Approximation for Clustering with Outliers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "443ed32448436d6710b875911c6944bde47a35cf",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25819": {
    "title": "Contrastive Classification and Representation Learning with Probabilistic Interpretation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5afecbef7a28dd25117bc00db3594a8e95968941",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25820": {
    "title": "Simulating Network Paths with Recurrent Buffering Units",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f2bc5f497daf770914737e1c2ad5ed5046a46bbe",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25821": {
    "title": "Fully Dynamic Online Selection through Online Contention Resolution Schemes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a1a3675308d7b38e5b02d1b09031d84f4bf39c44",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25822": {
    "title": "Tree Learning: Optimal Sample Complexity and Algorithms",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2c4e7659c6d577ae7c1cac0d49daba5e28a7efce",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25823": {
    "title": "Meta-Learning for Simple Regret Minimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4160cce636c0f5b40ff004a1489a9ad790e46e94",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25824": {
    "title": "Generalizing Downsampling from Regular Data to Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5de89665d72d63932c993fe5dec8dc0a9f21f9c1",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25825": {
    "title": "PiCor: Multi-Task Deep Reinforcement Learning with Policy Correction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ad17af39d0bfcc2498df27dc51de85adfac97704",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25826": {
    "title": "Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "72a305df18fe9010374504bce7c0ec485809b7c3",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25827": {
    "title": "Optimal Sparse Recovery with Decision Stumps",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a4be3bc405aa5a003e44f1efd2715a1384abf22",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25828": {
    "title": "Towards Efficient and Domain-Agnostic Evasion Attack with High-Dimensional Categorical Inputs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b1e1cc7d450895d4f947c86d123e3e560fa7eff9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25829": {
    "title": "Fairness and Welfare Quantification for Regret in Multi-Armed Bandits",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e4470ac0408e958123758f424f85105efdf71fa3",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25830": {
    "title": "Alternating Layered Variational Quantum Circuits Can Be Classically Optimized Efficiently Using Classical Shadows",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e0499cb8e5a94768e79b577c83fb464b5557d46f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25831": {
    "title": "Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e0955cd4702c745d6a93bb5edef64ca143358467",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25832": {
    "title": "Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "45693b1fa3c1fcb89a67827fd63b45f0bacf0185",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25833": {
    "title": "Sustaining Fairness via Incremental Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e1583c318a4b7f97df7c6ab9a55878bd12788a8e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25834": {
    "title": "Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2aeafb78c9fead00f0fe9c8f655ccf0b82bf0390",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25835": {
    "title": "An Improved Algorithm for Online Min-Sum Set Cover",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0317a6788b14e4adf34fdced4826c6ca556b0dae",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25836": {
    "title": "AutoInit: Analytic Signal-Preserving Weight Initialization for Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f42e704bbb28331cf1eee2b09f41bcfc0815483e",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25837": {
    "title": "A Parameterized Theory of PAC Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "26b394a90119f8ee2a9820d92cc28780c600cca7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25838": {
    "title": "Fully-Dynamic Decision Trees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4b94b06d0b0e12a84c83ee644d3627961715e197",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25839": {
    "title": "Scalable Theory-Driven Regularization of Scene Graph Generation Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f4411c40c4ab7133a1811704428377b43b178b77",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25840": {
    "title": "Toward a Perspectivist Turn in Ground Truthing for Predictive Computing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "75802e1d48ac47d96808e2c9605a17ac1dd07345",
    "semantic_title": "",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25841": {
    "title": "Semantic-Enhanced Image Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ef95ed000d71c4b4d3dbddec448c258b210b1402",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25842": {
    "title": "RePreM: Representation Pre-training with Masked Model for Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1b6c1822cc273bc452eb0b3dfbe14de53dd10681",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25843": {
    "title": "FTM: A Frame-Level Timeline Modeling Method for Temporal Graph Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c1a2d4fa243981f3e8af8b37b449a4488b810acd",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25844": {
    "title": "Estimating Treatment Effects from Irregular Time Series Observations with Hidden Confounders",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "896e5cee54d50d7a1f981823b4627948610d72a5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25845": {
    "title": "InParformer: Evolutionary Decomposition Transformers with Interactive Parallel Attention for Long-Term Time Series Forecasting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4c0842b95cfaf5591790d9de1cccb4ddde155aa7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25846": {
    "title": "Meta-Sketch: A Neural Data Structure for Estimating Item Frequencies of Data Streams",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6f279bb6ec61f3c5cafb4cd9c7c4e62c2768df3a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25847": {
    "title": "Unfooling Perturbation-Based Post Hoc Explainers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "17101501b13b57f6627cf1d6f557375051e21afd",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25848": {
    "title": "Very Fast, Approximate Counterfactual Explanations for Decision Forests",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f7544bfd25ae5baefe62ce3973d368f1c4b2fa70",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25849": {
    "title": "An Equivalence Analysis of Binary Quantification Methods",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1a4131e72b4adfaf3290e27a29e904f0be341e6e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25850": {
    "title": "Soft Action Priors: Towards Robust Policy Transfer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5815a68809dbedb72515cf930f6011761c8d8ea8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25851": {
    "title": "Invariant Representations with Stochastically Quantized Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "550f29904da2ccab4a3211349aa56cb4172a80d0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25852": {
    "title": "Learning Pessimism for Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4729d7b34c60de21fc5f7c9e0e9525936f644ca6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25853": {
    "title": "Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98241cf085a52c5761278ea8eb6c51cffa3a9d38",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25854": {
    "title": "NHITS: Neural Hierarchical Interpolation for Time Series Forecasting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "597811b2fa8f5155202a08226acde69efaf1eefb",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25855": {
    "title": "Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for Movement Forecasting in Badminton",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b965a2f6173c1365a492ae6103206bed2be9820",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25856": {
    "title": "Graph Ordering Attention Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "509c7f6ec4ae7d33006f9c5e9c174f61a43df598",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25857": {
    "title": "Scalable and Globally Optimal Generalized L₁ K-center Clustering via Constraint Generation in Mixed Integer Linear Programming",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ed0ae2814794c9d86de2d2c04a2aee9cabcc01b5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25858": {
    "title": "Attribute and Structure Preserving Graph Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8730e5e6aec81f191f162d9a621ffe18cabaac82",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25859": {
    "title": "On the Stability and Generalization of Triplet Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c39f3752591181899f680644e8f6ce77cc5a8e3e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25860": {
    "title": "CF-ViT: A General Coarse-to-Fine Method for Vision Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ed00842931ebb0db2c634330a77c8dee6f77e547",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25861": {
    "title": "Context-Aware Safe Medication Recommendations with Molecular Graph and DDI Graph Embedding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "795cb7f144184139a0198b99083ecee62ff72991",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25862": {
    "title": "Min-Max Submodular Ranking for Multiple Agents",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6d45997fb96b394f4057118d2fb4caba2c9f3321",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25863": {
    "title": "Supervised Contrastive Few-Shot Learning for High-Frequency Time Series",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a2056f5affe509b50e41612057ca9cca143ef97a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25864": {
    "title": "The Sufficiency of Off-Policyness and Soft Clipping: PPO Is Still Insufficient according to an Off-Policy Measure",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3a5b68ef4736e235aa596eb6728f284258e11d18",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25865": {
    "title": "Global Convergence of Two-Timescale Actor-Critic for Solving Linear Quadratic Regulator",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4b20c81a39d1ccc41f749f59dbb632e632135d7a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25866": {
    "title": "Topological Pooling on Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "77d14bbaece056f5a94231f46f02cca86e9bc085",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25867": {
    "title": "Riemannian Local Mechanism for SPD Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fc57be2a8ce6f6ae81bc53a80e9256e4340a6ef5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25868": {
    "title": "TC-DWA:Text Clustering with Dual Word-Level Augmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "e79fbed9d087f8905e4043108bcf8591f621f21c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25869": {
    "title": "Causal Inference with Conditional Instruments Using Deep Generative Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4f79230f60316394b9cda5896d594c6f4b0c9e37",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25870": {
    "title": "Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1497a56aa25a385e1d60e6a9c2fa60aa7bd17edd",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25871": {
    "title": "Partial-Label Regression",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2959a6a949de79fee19c6340e93db35096902a07",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25872": {
    "title": "Offline Quantum Reinforcement Learning in a Conservative Manner",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d116ba398a85cd838618796a10638b9d56b58250",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25873": {
    "title": "Variational Wasserstein Barycenters with C-cyclical Monotonicity Regularization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "556bc791f59b3bc8834960d473d4226957000824",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25874": {
    "title": "MobileTL: On-Device Transfer Learning with Inverted Residual Blocks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2ac22b58453c227a560f5ec4527be9f1857ca64c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25875": {
    "title": "Learning Optimal Features via Partial Invariance",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "26c61243f679b2cfb1edb4a8f95d1b44132c38f3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25876": {
    "title": "PrimeNet: Pre-training for Irregular Multivariate Time Series",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "70e5e9bd353d1b1e54b4eebd3a67b58026a13dff",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25877": {
    "title": "Structured BFGS Method for Optimal Doubly Stochastic Matrix Approximation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "593f9a54f6e53a0d1c1c19366521ca59e491d77c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25878": {
    "title": "On the Complexity of PAC Learning in Hilbert Spaces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0138f1631efd6425f09f2457d667dbded41af7fa",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25879": {
    "title": "Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks Using an Incompetent Teacher",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "425669c368004dc43bebaa1d4acdd46a6bcca171",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25880": {
    "title": "Scalable Spatiotemporal Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5e60dc704e7933e2a3e83512f345bba0debfe3f3",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25881": {
    "title": "Exploiting Multiple Abstractions in Episodic RL via Reward Shaping",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "07e496c302ed32f6da6f535eb4b0f91b58169726",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25882": {
    "title": "Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of CountSketch to Adaptive Inputs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25883": {
    "title": "Continuous Mixtures of Tractable Probabilistic Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b7e257197e70b5979992fe7c69a7746bae0e184d",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25884": {
    "title": "End-to-End Learning for Optimization via Constraint-Enforcing Approximators",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b6e821d5841d5f2b688d610c3ca64ce4a3ee0c7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25885": {
    "title": "Practical Parallel Algorithms for Submodular Maximization Subject to a Knapsack Constraint with Nearly Optimal Adaptivity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5028562c146dd06b2a9aa8754496b86cb43de326",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25886": {
    "title": "Opposite Online Learning via Sequentially Integrated Stochastic Gradient Descent Estimators",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ba45a6c7b542b0b8e8458ea845854f57eaf96dcc",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25887": {
    "title": "Contrastive Learning with the Feature Reconstruction Amplifier",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "53901562d0ff14da779f35b6431a4bd836e4bfa5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25888": {
    "title": "Augmented Proximal Policy Optimization for Safe Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5ee4efa8f7454770df0c43ce4d6fb65dd085fca5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25889": {
    "title": "GradPU: Positive-Unlabeled Learning via Gradient Penalty and Positive Upweighting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "88e55907283a62d93d4f9b18ab5ecb6f7595f3c7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25890": {
    "title": "Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "336d6ad9ddddbe6ed9a6520e01ba2e951a2f5650",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25891": {
    "title": "Tackling Data Heterogeneity in Federated Learning with Class Prototypes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "61cbca5ac40ba71388c6d2235fa25a20014faec0",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25892": {
    "title": "CrysGNN: Distilling Pre-trained Knowledge to Enhance Property Prediction for Crystalline Materials",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "4fc96ea53bc8c08bd184126869a22f039ca4dbfe",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25893": {
    "title": "Non-reversible Parallel Tempering for Deep Posterior Approximation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "47340a5c393fdf682cb27f6c4ebd96984607e918",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25894": {
    "title": "Stability-Based Generalization Analysis of the Asynchronous Decentralized SGD",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a8059c10fb5c16aa1afb5f1263c4f4a1cd689595",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25895": {
    "title": "Integer Subspace Differential Privacy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "eccd5376c514492ea39a40720a78139467db024c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25896": {
    "title": "Black-Box Adversarial Attack on Time Series Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5cf50e00f39010b3ab3f1f96de15223f5231c652",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25897": {
    "title": "C-NTPP: Learning Cluster-Aware Neural Temporal Point Process",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bf3aed71713f62e1e26971dbf36b920768ff4a71",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25898": {
    "title": "Eliciting Structural and Semantic Global Knowledge in Unsupervised Graph Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dcb17372a0233719d84aca856c6147a01e2ba34f",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25899": {
    "title": "Incremental Reinforcement Learning with Dual-Adaptive ε-Greedy Exploration",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c1844cda42b3732a5576d05bb6e007eb1db00919",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25900": {
    "title": "Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "09f0422754142a1a58182b8238f9cd1b242adab5",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25901": {
    "title": "Non-stationary Risk-Sensitive Reinforcement Learning: Near-Optimal Dynamic Regret, Adaptive Detection, and Separation Design",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "25457e352e553a89a76ed7fddb8aa9687094614e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25902": {
    "title": "SKDBERT: Compressing BERT via Stochastic Knowledge Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3eaa17dafc8a86dc5eac9d5b46af248f3f2f6712",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25903": {
    "title": "Model-Based Offline Reinforcement Learning with Local Misspecification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3aa1eafd0198ef0f49f79ff376ac60b170bb10e0",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25904": {
    "title": "Can Label-Specific Features Help Partial-Label Learning?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "635aaf49c94c29086a8bf67b4d7819d6c023226e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25905": {
    "title": "Interpreting Unfairness in Graph Neural Networks via Training Node Attribution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ec568050b74edfdb7e463200daf42ba36663505c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25906": {
    "title": "Robust and Fast Measure of Information via Low-Rank Representation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "83838422effa238682d462396a5a251fabb079b3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25907": {
    "title": "Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ca590583797aad5bd5af7f2c8492a0b14da53810",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25908": {
    "title": "Diffeomorphic Information Neural Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "799b8695fb63c0ea41d9d4d77959b234cf4b4cb3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25909": {
    "title": "Combining Slow and Fast: Complementary Filtering for Dynamics Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8300094620aa145281956869ed7930250af0ad38",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25910": {
    "title": "Popularizing Fairness: Group Fairness and Individual Welfare",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9953d04e41a4a63f8391032a39ac3ee0e3109610",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25911": {
    "title": "FairFed: Enabling Group Fairness in Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5b8cd1183840c5717d2b7cdec298d65d6ec69c32",
    "semantic_title": "",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25912": {
    "title": "Goal-Conditioned Generators of Deep Policies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "46af8550faab2e2b67fef7278eab0b581097e6ea",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25913": {
    "title": "Directed Acyclic Graph Structure Learning from Dynamic Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a0fb1b670f62ac1de989e5f3c439ef5114196892",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25914": {
    "title": "Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4366579b70e6c408e7fd621344bc869c1dda9d0f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25915": {
    "title": "Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "02657f902758c3b85146629fe4faa3feab0ea34f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25916": {
    "title": "Wasserstein Graph Distance Based on L1–Approximated Tree Edit Distance between Weisfeiler–Lehman Subtrees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "a0ee7fda99777066554267a7c211aad9b8e1f4f2",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25917": {
    "title": "Combinatorial Causal Bandits",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3ab3e2e5a7ec0f0f994d468c017c10b5d9cf4c4c",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25918": {
    "title": "Scalable Attributed-Graph Subspace Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b2d5c6b55d03dea1273462a0c8e5a8305da4173b",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25919": {
    "title": "SigMaNet: One Laplacian to Rule Them All",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5a5ebfb550a3a949f99afcdabddb4f063f0db13f",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25920": {
    "title": "Optimal Decision Diagrams for Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4da0660eb65e50c8e71d57110e118a9c70b3a2d0",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25921": {
    "title": "Estimating Average Causal Effects from Patient Trajectories",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fae41e2dded7f20f110a57c61dd0d1dbdd4c6a24",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25922": {
    "title": "Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "165503c48e553a5559190ce74cda823f4e166b54",
    "semantic_title": "",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25923": {
    "title": "EffConv: Efficient Learning of Kernel Sizes for Convolution Layers of CNNs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "302dc87c74a8cb0c8491f1c29483693eb283df7d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25924": {
    "title": "Fast Counterfactual Inference for History-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "80f2036ab4e76c86f69a63e77e000833853c2722",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25925": {
    "title": "Robust Causal Graph Representation Learning against Confounding Effects",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8a4c8b331abc0d5522fc5262595ff7d597c8a93b",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25926": {
    "title": "Towards Decision-Friendly AUC: Learning Multi-Classifier with AUCµ",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "31cdc5c5f6994192f0c93587dc3521428c8931a1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25927": {
    "title": "Long-Tail Cross Modal Hashing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "181f5132f3a353c5bd320de91429bab04b6dbb2d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25928": {
    "title": "Handling Missing Data via Max-Entropy Regularized Graph Autoencoder",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cf0d2eb36235a15a4ad8e2b8d4cf363ff9a530b8",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25929": {
    "title": "Reinforced Approximate Exploratory Data Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "52055da99bb0fdad22f8c11b96ca69f0d3d7f9e1",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25930": {
    "title": "Learning Program Synthesis for Integer Sequences from Scratch",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7658f56be043f2d883eaeaef40998d79cf15a26f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25931": {
    "title": "Semi-transductive Learning for Generalized Zero-Shot Sketch-Based Image Retrieval",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "db7236a9c1d344fda071d003b49816e2d414b768",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25932": {
    "title": "Multi-Classifier Adversarial Optimization for Active Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fc8f1fd3f350d1c243a8e6cc373d247b3f07ae40",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25933": {
    "title": "Differentially Private Heatmaps",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a381bd5c4976f4a8aef5c2a884a1246d592265c7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25934": {
    "title": "DiFA: Differentiable Feature Acquisition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c18c34012cb678a0fd82c848283258bbf6c2f5bf",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25935": {
    "title": "Local Intrinsic Dimensional Entropy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5a4dc0635e88c7fe615aa38f7bcf1ef309d7ae16",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25936": {
    "title": "Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c545b21e71c7c51bb4cc1d94bedbf6d6fdd57639",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25937": {
    "title": "Adaptive Hierarchy-Branch Fusion for Online Knowledge Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cbd86a65d38affa84976dbb968d89c58668c3bee",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25938": {
    "title": "Deep Latent Regularity Network for Modeling Stochastic Partial Differential Equations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3da11f998d7387aeced2945064f90f6af7074d1b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25939": {
    "title": "Dynamic Representation Learning with Temporal Point Processes for Higher-Order Interaction Forecasting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6eea9f9fb4f802c509f1cd698ff42f0e67ebf338",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25940": {
    "title": "An Adaptive Layer to Leverage Both Domain and Task Specific Information from Scarce Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "91691c66df6bde3d134137dcdc61580503fe7ab9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25941": {
    "title": "Interpolating Graph Pair to Regularize Graph Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "19918de95fdfa9b6dafe5529dc746c0395baad44",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25942": {
    "title": "Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "217e4ffcffa4107a38ced923086006b73e9399a4",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25943": {
    "title": "Self-Supervised Bidirectional Learning for Graph Matching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fcb7161eb81b82d533d410532ddffc871ab61830",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25944": {
    "title": "Boosting Graph Neural Networks via Adaptive Knowledge Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "402125f4732ef1ec5974ac7513a63bf5b8414611",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25945": {
    "title": "Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dbe429e7edf790b26c0f117027dc2cddb8ab9815",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25946": {
    "title": "Discriminability and Transferability Estimation: A Bayesian Source Importance Estimation Approach for Multi-Source-Free Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1d25e3ff3c28f40bf65b467486d0862476f4e28b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25947": {
    "title": "Astromorphic Self-Repair of Neuromorphic Hardware Systems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7a2d9d1e7e63561f3fe035e24f758f063233a54e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25948": {
    "title": "Estimating Regression Predictive Distributions with Sample Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e3c78bda7118e5b887c960c47a0dd476fe782b54",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25949": {
    "title": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic Dimension",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "94f9a6982512e7a06b1cab477f2b06ec12bd86c7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25950": {
    "title": "Safeguarded Learned Convex Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "201ee94316891a6659264c86d95438e9594c8431",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25951": {
    "title": "Improving Long-Horizon Imitation through Instruction Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "300bf71c102fe349a082482f791ba15795fe69cb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25952": {
    "title": "Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs: Application to Seizure Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "29a467cc939db1607061377fa551285481b8fa4c",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25953": {
    "title": "Improving Pareto Front Learning via Multi-Sample Hypernetworks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0c7f2a3ead7688c44b45fb48aa26bf60e6364199",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25954": {
    "title": "Towards Better Visualizing the Decision Basis of Networks via Unfold and Conquer Attribution Guidance",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ab28e10316c060589a2d4b02500b537e02900526",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25955": {
    "title": "Federated Robustness Propagation: Sharing Adversarial Robustness in Heterogeneous Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c7dd25b1e9bce4d9bbb4aa8fb053d0c68da17a33",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25956": {
    "title": "Compressed Decentralized Learning of Conditional Mean Embedding Operators in Reproducing Kernel Hilbert Spaces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d243063362a4b7fd481565d876040dddfef1597d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25957": {
    "title": "RLEKF: An Optimizer for Deep Potential with Ab Initio Accuracy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aaa3c21e1532a73835239e6d75a7951f0cf7e51a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25958": {
    "title": "Background-Mixed Augmentation for Weakly Supervised Change Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0e4d8a2985ee177159ff2525aabd7415054b3374",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25959": {
    "title": "Enabling Knowledge Refinement upon New Concepts in Abductive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "970f85cd760979fc5cd70c78420481a2fc675e24",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25960": {
    "title": "Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "399c35dcde2eac017b875af1a21916a9ecb10434",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25961": {
    "title": "Reward-Biased Maximum Likelihood Estimation for Neural Contextual Bandits: A Distributional Learning Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cbf2ca54338251f762a5c548dd50554eeee9df97",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25962": {
    "title": "Learning Noise-Induced Reward Functions for Surpassing Demonstrations in Imitation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6e9f395ccc11296e291b137d31cd882b726258e5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25963": {
    "title": "XClusters: Explainability-First Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "42ce38afc731d63dfd6029eab11be492683dbfc7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25964": {
    "title": "Model-Based Reinforcement Learning with Multinomial Logistic Function Approximation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "139e16319cc2179853c440e9540c41200e3ddd3c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25965": {
    "title": "Fast Regularized Discrete Optimal Transport with Group-Sparse Regularizers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "172fb6a4ac8d0f0f4a9e8617c7babc6a16887d1f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25966": {
    "title": "Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6ea9c6d13a8797257ee59429697bf31a41d1b9d2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25967": {
    "title": "Audio-Visual Contrastive Learning with Temporal Self-Supervision",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e475885c185b803ee025bc26c220c5736a5cfd5c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25968": {
    "title": "Confidence-Aware Training of Smoothed Classifiers for Certified Robustness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d95ec70652b3afcfe263bce6e3ba2ccefff2381d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25969": {
    "title": "Learnable Path in Neural Controlled Differential Equations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f5bd94c41926c585157765b31943925cbe1b59ec",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25970": {
    "title": "DrugOOD: Out-of-Distribution Dataset Curator and Benchmark for AI-Aided Drug Discovery – a Focus on Affinity Prediction Problems with Noise Annotations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "dcb21a5a0bc8b6d1bcfff10659e192a95ea20773",
    "semantic_title": "",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25971": {
    "title": "MNER-QG: An End-to-End MRC Framework for Multimodal Named Entity Recognition with Query Grounding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "27937956a426872feace4b7c89cf892dbd75451d",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25972": {
    "title": "Learning from Training Dynamics: Identifying Mislabeled Data beyond Manually Designed Features",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0858317aa3ebce7ebaae01be87f28925e49e51d8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25973": {
    "title": "Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2ab82ae37b7d27e79f59e624fa9419682c7cf8b8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25974": {
    "title": "Robust Domain Adaptation for Machine Reading Comprehension",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d0a78f091fdfb5c77ab286400fac125ac8f46927",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25975": {
    "title": "Multi-View MOOC Quality Evaluation via Information-Aware Graph Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1997376d6922b84ca0f372cbb0b9a48596ea497d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25976": {
    "title": "Spatio-Temporal Meta-Graph Learning for Traffic Forecasting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "12dd3ea6cd7041aef237f63c03a3e90fdc16897b",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25977": {
    "title": "Complement Sparsification: Low-Overhead Model Pruning for Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4a8da6b76b6d4396e407973d236c7b7d282d7259",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25978": {
    "title": "Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "70de410aece38bf0d5d12fbf03815c80676be742",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25979": {
    "title": "Local-Global Defense against Unsupervised Adversarial Attacks on Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2235f0df7efa6571007c33c3a5f3ea4286be1b9a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25980": {
    "title": "Trafformer: Unify Time and Space in Traffic Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f98ce3517924c03ef82528fb05958934cb97d8d8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25981": {
    "title": "On Solution Functions of Optimization: Universal Approximation and Covering Number Bounds",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f1959e2743e7ff857957252dd3af836e0790253a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25982": {
    "title": "Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "647369ee45ecead812991f860caa8a96c6617063",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25983": {
    "title": "Knowledge-Constrained Answer Generation for Open-Ended Video Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e0b19fd70c0a45355767473b671e0c2f4774d460",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25984": {
    "title": "POEM: Polarization of Embeddings for Domain-Invariant Representations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "36747690b3dc56fc4479cddc1a9992c2c75fbb58",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25985": {
    "title": "An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7f36e9584a69c7cc38a0267f40c2a8e4645074b5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25986": {
    "title": "Towards More Robust Interpretation via Local Gradient Alignment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a062076a5ff4af5f8e80905d51441779d2891cd7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25987": {
    "title": "Identifying Selection Bias from Observational Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ca2820b5b7a877619744d3862401ad6e28478731",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25988": {
    "title": "PIXEL: Physics-Informed Cell Representations for Fast and Accurate PDE Solvers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "162ce23964f2aef2378297da1b20e08a8d77d000",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25989": {
    "title": "On the Sample Complexity of Vanilla Model-Based Offline Reinforcement Learning with Dependent Samples",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d96495c78401e645ee85e38ee042e6e3fc76bad3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25990": {
    "title": "Communication-Efficient Collaborative Best Arm Identification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dc178a8b1926588ffc179c5bd53edc95b5dcc0bf",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25991": {
    "title": "Variable-Based Calibration for Machine Learning Classifiers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "45847e00891099b2fcdc7fb6d4d29852c5b30258",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25992": {
    "title": "Design Amortization for Bayesian Optimal Experimental Design",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "660195b1bc56862f1a781044527080fbe486032d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25993": {
    "title": "On Error and Compression Rates for Prototype Rules",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "17422b058269f3b66a32b267a69b50e226796d84",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25994": {
    "title": "CertiFair: A Framework for Certified Global Fairness of Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3a287e857f9a002c2d626228ecea6d375035ffd8",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25995": {
    "title": "Key Feature Replacement of In-Distribution Samples for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ee507a5776a2b3c548f712f601ec5e515bd4f8d7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25996": {
    "title": "FLAME: Free-Form Language-Based Motion Synthesis & Editing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c17a983b11381fabb53f28066f76d4b2dc5a6a17",
    "semantic_title": "",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25997": {
    "title": "Inverse-Reference Priors for Fisher Regularization of Bayesian Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b2caa2a9444341fc539283e86c5e68e7658e6d2b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25998": {
    "title": "Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38b933b515db9cdb834aaecd7f5a1c24e7be6af6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25999": {
    "title": "Better Generalized Few-Shot Learning Even without Base Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9255f7866199fadec7de87323ce27ca4c5603b6c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26000": {
    "title": "Learning Topology-Specific Experts for Molecular Property Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1604c2854370b9c6c9558b360c566f058ef33e7f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26001": {
    "title": "Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e97740f9ed9cfc7d27c95f3bd7aceb5691aff4be",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26002": {
    "title": "Exploring Temporal Information Dynamics in Spiking Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d7a33032b9cc1401c60ca856fa39c03b838836c1",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26003": {
    "title": "FastAMI – a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "54b2c1035b4da593e62f6658a6e064a56c743c16",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26004": {
    "title": "A Gift from Label Smoothing: Robust Training with Adaptive Label Smoothing via Auxiliary Classifier under Label Noise",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "18048fcf06e2f131d93dbc1a6c3708f0f188a344",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26005": {
    "title": "Grouping Matrix Based Graph Pooling with Adaptive Number of Clusters",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "c7bbe399aad2da39ba8f988fec83129d60aa5d52",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26006": {
    "title": "The Influence of Dimensions on the Complexity of Computing Decision Trees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "65d6bee49cf1d2ebd40014dd53e96c7ab9842ee3",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26007": {
    "title": "Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a6eb9ecef16437bc76efbe0b016cea3bbdbf8f87",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26008": {
    "title": "Peeling the Onion: Hierarchical Reduction of Data Redundancy for Efficient Vision Transformer Training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a92d2c468835571f3302ce9299fdf37b36c2e367",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26009": {
    "title": "Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6143e809cd2e9c7a18c3bc8819419fd3b02fbcf2",
    "semantic_title": "",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26010": {
    "title": "Almost Cost-Free Communication in Federated Best Arm Identification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "52382817395bb0c6b7c07e1d41dcb2ce7e30ea1a",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26011": {
    "title": "UEQMS: UMAP Embedded Quick Mean Shift Algorithm for High Dimensional Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "507217edca49186856896dcf69d6bfbb4eef6d3d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26012": {
    "title": "The Effect of Diversity in Meta-Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "277e80c67e9dcc8572d73ff0cec5c22530df5f8a",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26013": {
    "title": "Gradient Estimation for Binary Latent Variables via Gradient Variance Clipping",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cc95439462f741ac55ecf8f728aa7c67a41ac6fe",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26014": {
    "title": "LoNe Sampler: Graph Node Embeddings by Coordinated Local Neighborhood Sampling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "56f676e55a306303863551beda729a6570aa3e30",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26015": {
    "title": "WLD-Reg: A Data-Dependent Within-Layer Diversity Regularizer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "86d12d692995538259706c383841349433712c72",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26016": {
    "title": "SpatialFormer: Semantic and Target Aware Attentions for Few-Shot Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "74277b50e285dfaa0adbed61627c10f7ea168997",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26017": {
    "title": "A Data Source for Reasoning Embodied Agents",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5c828011a508611df4d58cced9cc48d049dc4eb9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26018": {
    "title": "Generalization Bounds for Inductive Matrix Completion in Low-Noise Settings",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e42259cf0ba53f6c072cadf52d471e943e021387",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26019": {
    "title": "I'm Me, We're Us, and I'm Us: Tri-directional Contrastive Learning on Hypergraphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26020": {
    "title": "Bespoke: A Block-Level Neural Network Optimization Framework for Low-Cost Deployment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "eb36afb336dff204652ef5dc39c9ce32353e48cb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26021": {
    "title": "Time-Aware Random Walk Diffusion to Improve Dynamic Graph Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98293695c9f356ca1a5d667ff41d0287aef9a868",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26022": {
    "title": "Demystifying Randomly Initialized Networks for Evaluating Generative Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "67260931df4bda9bfd816da76dfbf0aafdaf47b0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26023": {
    "title": "Layer-Wise Adaptive Model Aggregation for Scalable Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f9a5d01f2ad2d044703dc50d63c233c5f91fe9a",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26024": {
    "title": "Goal-Conditioned Q-learning as Knowledge Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "713f4ac842a83650c63e1e43b748fcb5a83bd22d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26025": {
    "title": "Optimism in Face of a Context:Regret Guarantees for Stochastic Contextual MDP",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "3c9ee60cf7e32e08b6f177ac1d104c3ea74c3c76",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26026": {
    "title": "Differentiable Meta Multigraph Search with Partial Message Propagation on Heterogeneous Information Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c42b9e01b1c908a059220f436db2db8dd9d07f11",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26027": {
    "title": "Learning Adversarially Robust Sparse Networks via Weight Reparameterization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "72bd3ee3bc2628128e369bb1babd1c776c4f26ed",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26028": {
    "title": "ACE: Cooperative Multi-Agent Q-learning with Bidirectional Action-Dependency",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "48e556c2c67b7d05ea16ec0354bcc0372c927fbb",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26029": {
    "title": "When Online Learning Meets ODE: Learning without Forgetting on Variable Feature Space",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "42ee78b8ae50b905ba4d0b3127f609f100e7e689",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26030": {
    "title": "FanoutNet: A Neuralized PCB Fanout Automation Method Using Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7cfb571902b6dca6badfcdbe843add81f9fbba77",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26031": {
    "title": "Causal Recurrent Variational Autoencoder for Medical Time Series Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "22c670c365abefe17d1f99bba584f71d7762944f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26032": {
    "title": "Dual Mutual Information Constraints for Discriminative Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2fe34c646b8cefda49aba1b9eb36689126ea5902",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26033": {
    "title": "AdaBoost.C2: Boosting Classifiers Chains for Multi-Label Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ce63df31e8108d012be79f05d144314820fb5ed3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26034": {
    "title": "Scaling Up Dynamic Graph Representation Learning via Spiking Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f68069bd99ae7413e6db72d2a2906f732a66916",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26035": {
    "title": "Improved Kernel Alignment Regret Bound for Online Kernel Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "123bf0bf0185f67e006cd4dc309efe81a7290c88",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26036": {
    "title": "VBLC: Visibility Boosting and Logit-Constraint Learning for Domain Adaptive Semantic Segmentation under Adverse Conditions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1e515aa55d1609c19fac4b8f640811ec801bee40",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26037": {
    "title": "Understanding the Generalization Performance of Spectral Clustering Algorithms",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d54913c6d5ec12d23352d1fbde5de848d65be1da",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26038": {
    "title": "Restructuring Graph for Higher Homophily via Adaptive Spectral Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a9b816d65b92a07791ea8c359f2a2e0cc5746de4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26039": {
    "title": "Nearest-Neighbor Sampling Based Conditional Independence Testing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c7e27ec1d6edcfcd87c3c9793320ec27b65fb72a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26040": {
    "title": "Towards Fine-Grained Explainability for Heterogeneous Graph Neural Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "80d07f8cf49d0fe88bedde8a578a51fc81d0ed23",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26041": {
    "title": "Metric Nearness Made Practical",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2f91785af642140181f9063fe4b86eae33251c0e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26042": {
    "title": "Predictive Exit: Prediction of Fine-Grained Early Exits for Computation- and Energy-Efficient Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "949b0036c619bda8d3171716b20209b277211d0b",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26043": {
    "title": "Learning with Partial Labels from Semi-supervised Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6f46720a181758da276eb71a38e99b338cec5924",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26044": {
    "title": "Learning Compact Features via In-Training Representation Alignment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fef6bb50c6dce8d4b5fdcaab89400b9776bc00df",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26045": {
    "title": "An Extreme-Adaptive Time Series Prediction Model Based on Probability-Enhanced LSTM Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1023544eb078faa4100c6ac10abc2aa010dd6255",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26046": {
    "title": "Implicit Stochastic Gradient Descent for Training Physics-Informed Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "491b39c1ee81411873de6f1a1f41842195de000d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26047": {
    "title": "Provable Pathways: Learning Multiple Tasks over Multiple Paths",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9b1b0bb968d25b0573f424d7acf5e5b4e7b9fde9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26048": {
    "title": "Towards Inference Efficient Deep Ensemble Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8e9931c561dbba7227baba58f7b487a5e2b5c676",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26049": {
    "title": "SplitNet: A Reinforcement Learning Based Sequence Splitting Method for the MinMax Multiple Travelling Salesman Problem",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ac02c425ce7663042a0052845459f07413900bce",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26050": {
    "title": "Stepdown SLOPE for Controlled Feature Selection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f13fa189356fdc601e52b8a579f27447590258be",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26051": {
    "title": "Positive Distribution Pollution: Rethinking Positive Unlabeled Learning from a Unified Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7a488cc69575d623c1bf808209d166bc87e50d97",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26052": {
    "title": "Policy-Independent Behavioral Metric-Based Representation for Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "192e9ef2b836c17022cfdf66dd793c27753db488",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26053": {
    "title": "Geometry-Aware Network for Domain Adaptive Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d339a2889db2190044fbda01808b60a39a75f4f2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26054": {
    "title": "Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a5df174ce3ed582867e1c5d0bae159827d759456",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26055": {
    "title": "On the Expressive Flexibility of Self-Attention Matrices",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "32fa352ee110fd9f80c9d62282611b4a444f5300",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26056": {
    "title": "Wasserstein Actor-Critic: Directed Exploration via Optimism for Continuous-Actions Control",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d26ea31d844d51f11f0703dfae54fdfe9c0d1092",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26057": {
    "title": "Dual Label-Guided Graph Refinement for Multi-View Graph Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "89fdbaa025a339558438160fbcca2e0812abfb56",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26058": {
    "title": "Metric Residual Network for Sample Efficient Goal-Conditioned Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "58a7ecdc94d6e59454c08c9c3e132a9e6ca00094",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26059": {
    "title": "DICNet: Deep Instance-Level Contrastive Network for Double Incomplete Multi-View Multi-Label Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e0e3ccfcf9fc94b99536561ba6dd2c9dd49c96bb",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26060": {
    "title": "Incomplete Multi-View Multi-Label Learning via Label-Guided Masked View- and Category-Aware Transformers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "867b2f2a1b041a4157cf3b49e52ff1e03c1aca04",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26061": {
    "title": "Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization for Heterogeneous Representational Coarseness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "677f0dbaeddbfce9a7afb5efb6703798e2c99e0f",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26062": {
    "title": "Combating Mode Collapse via Offline Manifold Entropy Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c6cc2fc16008a57fc35887d55c84ddef0ad68955",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26063": {
    "title": "Robust Representation Learning by Clustering with Bisimulation Metrics for Visual Reinforcement Learning with Distractions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5fda3e94df50485dd7caa6940fa7435ec9bfe80c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26064": {
    "title": "Reliable Robustness Evaluation via Automatically Constructed Attack Ensembles",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "117d6de151477f7a1134b117abae09f39ac3a390",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26065": {
    "title": "Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5251da262f05511dfcd48e527ddf2d781e1c33a5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26066": {
    "title": "Safe Multi-View Deep Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4a23f3a7989e4b0b74151f5baaa5555ae917c799",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26067": {
    "title": "Tensor Compressive Sensing Fused Low-Rankness and Local-Smoothness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "db6d22c63e8ec9ea4746c5a6ed1ccf7d1ebe1135",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26068": {
    "title": "Coupling Artificial Neurons in BERT and Biological Neurons in the Human Brain",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "990a61871d6dc1aa474cf334542fb9fbfd32f996",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26069": {
    "title": "EASAL: Entity-Aware Subsequence-Based Active Learning for Named Entity Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a1306e40b8d0c89150967c6b63b4bf4cbf67c8a3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26070": {
    "title": "Online Hyperparameter Optimization for Class-Incremental Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ecc0cd4141d0600b04b313dd8e3c12626a8ffc71",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26071": {
    "title": "Hard Sample Aware Network for Contrastive Deep Graph Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6d663f1b9ec6e700c7e781e81651186d5208b6ff",
    "semantic_title": "",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26072": {
    "title": "Temporal-Frequency Co-training for Time Series Semi-supervised Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "131819cd0495e02bc2e62be869d07a8c2316a71d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26073": {
    "title": "Q-functionals for Value-Based Continuous Control",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e49fbfba9a959e408ef5dfa5b58f3320ac04735a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26074": {
    "title": "A Coreset Learning Reality Check",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fb3d8ae9e0ac948b2d7dd42293ce508093d160c8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26075": {
    "title": "Centerless Multi-View K-means Based on the Adjacency Matrix",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "576072821acc99b7576b5239b57cae5e63de9404",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26076": {
    "title": "PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3930a0285877386fca94e60c4c69305e220fd4ee",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26077": {
    "title": "Multi-View Domain Adaptive Object Detection on Camera Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fd1b60b1c2c142af4919f4b13b792f89b50cc134",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26078": {
    "title": "Generative Label Enhancement with Gaussian Mixture and Partial Ranking",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "066425bb5cc653f0548b30dfcde1cd15f6b254fb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26079": {
    "title": "Crowd-Level Abnormal Behavior Detection via Multi-Scale Motion Consistency Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d31a54553648a1001ebd63b734e5b644c10878f7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26080": {
    "title": "MVCINN: Multi-View Diabetic Retinopathy Detection Using a Deep Cross-Interaction Neural Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "852ce0da50b02fd07ab65de6a630cd2111cca543",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26081": {
    "title": "Local Explanations for Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "60f47eb09931260b43812602c636134e9f69f4f7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26082": {
    "title": "Compositional Prototypical Networks for Few-Shot Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ed3e8dc12806a03b183e0f5f54a4d1467d12d6fc",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26083": {
    "title": "Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2824ad1c27459d43e3482a6ec56579fb3e751233",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26084": {
    "title": "OMPQ: Orthogonal Mixed Precision Quantization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ca9ef03e0ff38ea65a7efb8bc1e5907e87a79c15",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26085": {
    "title": "Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "663bcc25755bdb3ca8ead4e5a0f5bb099cae1c4f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26086": {
    "title": "LIMIP: Lifelong Learning to Solve Mixed Integer Programs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a68d81e903e0a5768b9fdfaf6c5400ecc3c95be3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26087": {
    "title": "Proximal Stochastic Recursive Momentum Methods for Nonconvex Composite Decentralized Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0b40fe0a80748daa6096db08648d2f20c7272383",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26088": {
    "title": "Online Reinforcement Learning with Uncertain Episode Lengths",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a533ceb0f5c291c06a595728609b4f419a395c89",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26089": {
    "title": "Tight Performance Guarantees of Imitator Policies with Continuous Actions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "50b7baed2365f292b67cf95470b5cec170a69715",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26090": {
    "title": "Weight Predictor Network with Feature Selection for Small Sample Tabular Biomedical Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "830f264dd6d04542abdbcc54488ef491d9bd358a",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26091": {
    "title": "Learning Revenue Maximization Using Posted Prices for Stochastic Strategic Patient Buyers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a3a22947eed7be4244ede293d0526f6201b33dc8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26092": {
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "28ec0f9b24b2a909a34308f895fa7deecad31be3",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26093": {
    "title": "Diffusion Models Beat GANs on Topology Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1a1a91f78ec32619a5b2a3b43e0b4d0f7ab97737",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26094": {
    "title": "VIDM: Video Implicit Diffusion Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "13c7b29a100f67d285eb3625c160d06882d4c092",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26095": {
    "title": "Towards Interpreting and Utilizing Symmetry Property in Adversarial Examples",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "31383e9125e10365c6f58cf1dfa6f1e158bc8b4f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26096": {
    "title": "The Unreasonable Effectiveness of Deep Evidential Regression",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8b355a9c3ebc035f249407b6cbbc3904b90483fb",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26097": {
    "title": "HyperJump: Accelerating HyperBand via Risk Modelling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "10a17ea81145a70d0bcece01d4338f7060a9023c",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26098": {
    "title": "MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "08a103c145772c83f9544c8798dbcc292bdff762",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26099": {
    "title": "Off-Policy Proximal Policy Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "24d5bf9d25d1f9f46f0a72e9df522d49d747e446",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26100": {
    "title": "Information-Theoretic Causal Discovery and Intervention Detection over Multiple Environments",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0613184b7dbc1793408f89ef133855c676acbc96",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26101": {
    "title": "AIO-P: Expanding Neural Performance Predictors beyond Image Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "20d00e647349b7147316fa4672451a898e80de86",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26102": {
    "title": "GENNAPE: Towards Generalized Neural Architecture Performance Estimators",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "01b4709a79a52105f8afc05d533548823ca81aaa",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26103": {
    "title": "Adaptive Perturbation-Based Gradient Estimation for Discrete Latent Variable Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6282364a3a0486219e4878225b58ed850660ad4c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26104": {
    "title": "Why Capsule Neural Networks Do Not Scale: Challenging the Dynamic Parse-Tree Assumption",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "40e95fe0b847e9fac8253900a7fafccf38c560ba",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26105": {
    "title": "Multiplex Graph Representation Learning via Common and Private Information Mining",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c55d0c529b758c3a7112f3f9464ce4c281761548",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26106": {
    "title": "Fundamentals of Task-Agnostic Data Valuation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b8a070507b4cdcf4cc67b1e21aa7005fe2611c33",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26107": {
    "title": "Exploring the Interaction between Local and Global Latent Configurations for Clustering Single-Cell RNA-Seq: A Unified Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aceb297295bb86f617eaed59e9a9eb39c839ebb9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26108": {
    "title": "Corruption-Tolerant Algorithms for Generalized Linear Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2eb9e99cc848db3c4715d7e0161ea34146847fe1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26109": {
    "title": "Provably Efficient Causal Model-Based Reinforcement Learning for Systematic Generalization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aa4ca2d92b79d19bd938748d1233f7dc58195955",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26110": {
    "title": "Mean Estimation of Truncated Mixtures of Two Gaussians: A Gradient Based Approach",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "395471bcd2fa219a58965edf342949749b94fba2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26111": {
    "title": "An Operator Theoretic Approach for Analyzing Sequence Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d96c0d6c609f460f6761fe56113a461be719989b",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26112": {
    "title": "Do Invariances in Deep Neural Networks Align with Human Perception?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3d7003050ece3dec9b9104917ac97d440081e70a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26113": {
    "title": "Counterfactual Learning with General Data-Generating Policies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "83ac9832f81f2e2caa9a3620d8f0f8822e54eb8d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26114": {
    "title": "Efficient and Accurate Learning of Mixtures of Plackett-Luce Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b10dbb26277dd57374b5274929a9f10871d1130c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26115": {
    "title": "Behavioral Learning in Security Games: Threat of Multi-Step Manipulative Attacks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "86984f5d5b99cfe975c251098749c8b247184c27",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26116": {
    "title": "On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b61a3d718a192e39a437d32a6ed4037b8c29cc41",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26117": {
    "title": "Fast Saturating Gate for Learning Long Time Scales with Recurrent Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bf979c9598ea185a2b436c52dce0da6382e14f24",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26118": {
    "title": "Backpropagation-Free Deep Learning with Recursive Local Representation Alignment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5ea7d9d34cbe1b6c33c2f1677d577319ed658f16",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26119": {
    "title": "Bilinear Exponential Family of MDPs: Frequentist Regret Bound with Tractable Exploration & Planning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "b61c60d75f25c8b8cf23131f82d6efaced2ad3cc",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26120": {
    "title": "H-TSP: Hierarchically Solving the Large-Scale Traveling Salesman Problem",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "0973b3c792ee4ee8fc4a22e3b6bc6cd9da9bc98c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26121": {
    "title": "Ising-Traffic: Using Ising Machine Learning to Predict Traffic Congestion under Uncertainty",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3f73e7838bddfd67a265dca2dcc0492091ec5449",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26122": {
    "title": "FedMDFG: Federated Learning with Multi-Gradient Descent and Fair Guidance",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e92224b72b14ea4cf8db9801ad328f0bc65f0625",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26123": {
    "title": "Geometric Inductive Biases for Identifiable Unsupervised Learning of Disentangled Representations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fb2db75f2ee31bdd138543762383cdadbc524213",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26124": {
    "title": "Isometric Manifold Learning Using Hierarchical Flow",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "558e966b86efc2ae667115c1f769bab5955c1a1a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26125": {
    "title": "Evidential Conditional Neural Processes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a116fe984ed47fe320fc78a94ed72fa6e5e9e915",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26126": {
    "title": "Balanced Column-Wise Block Pruning for Maximizing GPU Parallelism",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6872c4cf5268a64f897cf3bcd2af0a5e1e0210e0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26127": {
    "title": "Dynamic Structure Pruning for Compressing CNNs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a58c40f637c8a7441553fe896abc22dedeceed8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26128": {
    "title": "Scaling Marginalized Importance Sampling to High-Dimensional State-Spaces via State Abstraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c6f39c3b73e5966730362bc757f44fe127b4390d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26129": {
    "title": "Conceptual Reinforcement Learning for Language-Conditioned Tasks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc8fc93514b753adda5214528486361d681892a6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26130": {
    "title": "Weighted Policy Constraints for Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cf07c1a9ec10aa546384fbd0cd62b793c3c6b978",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26131": {
    "title": "Latent Autoregressive Source Separation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "03d3b8e2a746b4d375c0d0de9ea43d4a37f4b0bd",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26132": {
    "title": "Explaining Random Forests Using Bipolar Argumentation and Markov Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "df6e8c416a0e9ba1f12421b3af34e277e6579728",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26133": {
    "title": "A Model-Agnostic Heuristics for Selective Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4ddaaf045afc618f3a1c849d6a088b7982e8477a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26134": {
    "title": "Experimental Observations of the Topology of Convolutional Neural Network Activations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "da55906dec5bd68bd45b2a0806e1d92a35fa0344",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26135": {
    "title": "CMVAE: Causal Meta VAE for Unsupervised Meta-Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f3c276c23f48d5f373346d5668045736f8bb4a06",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26136": {
    "title": "Rethinking Data-Free Quantization as a Zero-Sum Game",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "afe7d5e4a309dea2ac2a8e53c3db61b135b85092",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26137": {
    "title": "Mixture Uniform Distribution Modeling and Asymmetric Mix Distillation for Class Incremental Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aa1c7dbacc44b797698744a40c322f55258ddafc",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26138": {
    "title": "Mutual-Enhanced Incongruity Learning Network for Multi-Modal Sarcasm Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1656d9cfe2e7474ce11a862db970f34368db36d9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26139": {
    "title": "Training Meta-Surrogate Model for Transferable Adversarial Attack",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a80a626f87b4a30cfff3eea8ee39625075c2f451",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26140": {
    "title": "Stochastic Contextual Bandits with Long Horizon Rewards",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "45fbf50820d9c6756225a089dc995db368624f3d",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26141": {
    "title": "Gradient-Variation Bound for Online Convex Optimization with Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "b7d659c5ff03696de0d605796ca802ed9d5961bf",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26142": {
    "title": "Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7cf779d889dbf155e089289bab1495be2b186b11",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26143": {
    "title": "GLUECons: A Generic Benchmark for Learning under Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "757ce0529971d496e3c17155b405747f73bc18c3",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26144": {
    "title": "Provable Detection of Propagating Sampling Bias in Prediction Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "eab871a8f01a58cd589f5b8853d99aac80419a79",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26145": {
    "title": "Diffusing Gaussian Mixtures for Generating Categorical Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8ae47f3e238304f33c8cfe5f24c054339dbc4080",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26146": {
    "title": "Hypernetworks for Zero-Shot Transfer in Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f36f1a3b75778e6924461c04a607da3db4c0b534",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26147": {
    "title": "Automata Cascades: Expressivity and Sample Complexity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "273b47ea69844de1d142ea61f72fba50afcf0107",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26148": {
    "title": "ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0a52f77490300be671942909e09b4ee87e7f23a0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26149": {
    "title": "Planning and Learning with Adaptive Lookahead",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4c96156ad9561006c1528ec8ead5d9d3103669a9",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26150": {
    "title": "DisGUIDE: Disagreement-Guided Data-Free Model Extraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "406d4e8d2df6f6b58e65016fea31004f781d93e7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26151": {
    "title": "Overcoming Concept Shift in Domain-Aware Settings through Consolidated Internal Distributions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "ffec892fa0a8eecfc595e3ccd524f29f7c6aa789",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26152": {
    "title": "Inferring Patient Zero on Temporal Networks via Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f45702cf78ff21b9bc41c77d4ca1daa5ff58d8c3",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26153": {
    "title": "Accommodating Audio Modality in CLIP for Multimodal Processing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98ab8260c98030109ba8467f52b13d075276cf0f",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26154": {
    "title": "Forecasting with Sparse but Informative Variables: A Case Study in Predicting Blood Glucose",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6e59b0e36f7801a19925a4f82a47ff309fc172c9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26155": {
    "title": "On the Sample Complexity of Representation Learning in Multi-Task Bandits with Global and Local Structure",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "138a1de6ec6730fc75c3931018155803ebcb2ca1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26156": {
    "title": "Simultaneously Updating All Persistence Values in Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1711bda8fbf86301c9297b2925419fd8680cd43f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26157": {
    "title": "Continual Learning with Scaled Gradient Projection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8023869b534ae182e3e7d5df25690a062106912d",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26158": {
    "title": "Fast Offline Policy Optimization for Large Scale Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "01c27e295956a30f7208c2e32e73a2cc1a27caee",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26159": {
    "title": "Losses over Labels: Weakly Supervised Learning via Direct Loss Construction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc49647a37e649c3602c16fb06faeeb48d6ab66f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26160": {
    "title": "Representation Learning by Detecting Incorrect Location Embeddings",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8c1601b65e354ba042e6952e233fff17b5475a94",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26161": {
    "title": "Sparse Coding in a Dual Memory System for Lifelong Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "362211dccace94cafc72c819d381b836c443593e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26162": {
    "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "00768994cec0d2e74545180a59ab5407469da9ff",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26163": {
    "title": "Dropout Is NOT All You Need to Prevent Gradient Leakage",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ed5671f95cefda22861c0cddd54d50bcdcdd90fa",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26164": {
    "title": "Exploration via Epistemic Value Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0670b6552f53d2ed8b56a712bb0db4783138123a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26165": {
    "title": "Multi-Source Survival Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "00d3b4aacc5cc95277f7e3e0f560d79781a4e65a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26166": {
    "title": "What Do You MEME? Generating Explanations for Visual Semantic Role Labelling in Memes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9b659d02ffe695707077b6a3b3475fc67d168e96",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26167": {
    "title": "Post-hoc Uncertainty Learning Using a Dirichlet Meta-Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0647c14721528fc1950f883036e0806d7b3be6f9",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26168": {
    "title": "Neighbor Contrastive Learning on Learnable Graph Augmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "be6161dd5eaa1b1ecc4e62348b43e52f134ed3f5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26169": {
    "title": "ProxyBO: Accelerating Neural Architecture Search via Bayesian Optimization with Zero-Cost Proxies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9891b45b1aaac6a602e848381d145c825645e040",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26170": {
    "title": "Contrastive Predictive Autoencoders for Dynamic Point Cloud Self-Supervised Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1297adc46af434f188ca8ea1c95638849eed36b3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26171": {
    "title": "Fixed-Weight Difference Target Propagation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a1b07aad0583274d2c87e0baacd0b18183d2d582",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26172": {
    "title": "Concurrent Multi-Label Prediction in Event Streams",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f2706bbbf0a69729410f62a826b18aa5b1fbe052",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26173": {
    "title": "A Generalized Unbiased Risk Estimator for Learning with Augmented Classes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5dd1c14cc13e80ded379a8ed4cb04cbaed9aa01d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26174": {
    "title": "Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8f8b06780acbe9e2a0356c8acfcfa209bed40bd6",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26175": {
    "title": "SLIQ: Quantum Image Similarity Networks on Noisy Quantum Computers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e00e31758a224b638cc24577d3813e01a1eb0427",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26176": {
    "title": "Adaptive Mixing of Auxiliary Losses in Supervised Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "063acc1ea6ebeb4e4310e2990583f8fed253bf05",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26177": {
    "title": "Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2cb10b11951246878ad3fbd26313014e7d55b863",
    "semantic_title": "",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26178": {
    "title": "Mixture Manifold Networks: A Computationally Efficient Baseline for Inverse Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3fd8d46297d671e3400e4e4aba2f991b1bb14726",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26179": {
    "title": "Sharing Pattern Submodels for Prediction with Missing Values",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "41b729a8ff8e0d02f72774649ea5566db413ad18",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26180": {
    "title": "Scalable Optimal Multiway-Split Decision Trees with Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4cba7dfa7dc169223b1eff0c7d49955fb1cec695",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26181": {
    "title": "REMIT: Reinforced Multi-Interest Transfer for Cross-Domain Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "435514442f10030d15c6f895eb7b10912a766680",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26182": {
    "title": "Cooperative and Adversarial Learning: Co-enhancing Discriminability and Transferability in Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c7418ac06f023a210f293a66489b4a8fd4a7e4ea",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26183": {
    "title": "Fair-CDA: Continuous and Directional Augmentation for Group Fairness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e9030eaaecd19228637d4ddc6ee86745152bd579",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26184": {
    "title": "Neural Spline Search for Quantile Probabilistic Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9990802f546a575e2dd7226742e2a94f1ea50302",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26185": {
    "title": "Domain Adaptation with Adversarial Training on Penultimate Activations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "784d2998bf94b0863e7134be4e6d87dcf2884b59",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26186": {
    "title": "Fast Convergence in Learning Two-Layer Neural Networks with Separable Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4ac4e716d5e1aaacb15d6fc4c89decce59d45e37",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26187": {
    "title": "Federated Learning on Non-IID Graphs via Structural Knowledge Sharing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2f325e874aa12ebbf8f5028076e7c4c75831ce54",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26188": {
    "title": "Metric Multi-View Graph Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1a01f8994899713953d4a6f4a1cc2a638054a4a5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26189": {
    "title": "DE-net: Dynamic Text-Guided Image Editing Adversarial Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "471c1fb7477a94504b7ba3e796bcf3de13db3b57",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26190": {
    "title": "Knowledge Amalgamation for Multi-Label Classification via Label Dependency Transfer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "681b1f0320a724f9586ceba8f1f90d80b0f7d2e4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26191": {
    "title": "Leveraging Contaminated Datasets to Learn Clean-Data Distribution with Purified Generative Adversarial Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9d910b5b48859c66df9db3f8c75f653ece102676",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26192": {
    "title": "Heterogeneous Graph Masked Autoencoders",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6109164f49ae02a92579eb0c374fbd5f7948e740",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26193": {
    "title": "Unbalanced CO-optimal Transport",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "d778eda5b8e99c4dedea29e7c3e5450cc3f95a4e",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26194": {
    "title": "Linear Regularizers Enforce the Strict Saddle Property",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1703faed266b7a9dc3e67f5b6254044b86b1a959",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26195": {
    "title": "Policy-Adaptive Estimator Selection for Off-Policy Evaluation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a9d1e2b1ccfdae5eb4ea96e3d1803fe55aaf13c1",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26196": {
    "title": "A Fair Generative Model Using LeCam Divergence",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14f5e4afdd089120aa171edb7bfd424f243a618d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26197": {
    "title": "Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles between Client Data Subspaces",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2f45018de9e420ab4126becceee857331b488637",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26198": {
    "title": "Training-Time Attacks against K-nearest Neighbors",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "76dc6a8643daa0134a5372ca524e275cf756e9a3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26199": {
    "title": "Machines of Finite Depth: Towards a Formalization of Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5b932ddfe7053b49edf1e7d32a4a3cbfa70288e4",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26200": {
    "title": "Kalman Bayesian Neural Networks for Closed-Form Online Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "89f0e11f76c4d91b0838a940c31203e5635a45ce",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26201": {
    "title": "Auto-Weighted Multi-View Clustering for Large-Scale Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4140a8b76168c5817dab043b3dc3ef9bc6e9cf72",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26202": {
    "title": "Quantum Multi-Armed Bandits and Stochastic Linear Bandits Enjoy Logarithmic Regrets",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "218859bdb4492fcfa4b2f5fb2c945c25ae37691d",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26203": {
    "title": "FedABC: Targeting Fair Competition in Personalized Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7ea77fcebe88acbb1396549b297965ad40d38875",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26204": {
    "title": "Spearman Rank Correlation Screening for Ultrahigh-Dimensional Censored Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "da2815a08ac8a2885f9c6bec3b2de513bebf683d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26205": {
    "title": "Stability-Based Generalization Analysis for Mixtures of Pointwise and Pairwise Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f79eb1c0d0a044ed0dbb36883ff10a0b09867c5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26206": {
    "title": "Effective Continual Learning for Text Classification with Lightweight Snapshots",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a21037a45a1a7b886fd3e09e953cb79de19ccc3d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26207": {
    "title": "Optimistic Whittle Index Policy: Online Learning for Restless Bandits",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "44a32991258416e1fb0bbc2d91a960edce960f2e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26208": {
    "title": "AEC-GAN: Adversarial Error Correction GANs for Auto-Regressive Long Time-Series Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7a084f14b45e83fd2d870d0cdbe38560cd2c07c9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26209": {
    "title": "The Implicit Regularization of Momentum Gradient Descent in Overparametrized Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ca887ea35e2eeeb17801cbed3515ea4965c65789",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26210": {
    "title": "Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "eabfc1846af8f09d6c65e45cb04f83fa397f6799",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26211": {
    "title": "Hierarchical Contrastive Learning for Temporal Point Processes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a074e060cde0ddbb535e22863df43322a5627efb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26212": {
    "title": "Beyond ADMM: A Unified Client-Variance-Reduced Adaptive Federated Learning Framework",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e10a8abd5c7f2d6ecbe76412a56762d61b0efcbf",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26213": {
    "title": "State-Conditioned Adversarial Subgoal Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c397a67aad5bd5d08364135ac01b028af930c604",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26214": {
    "title": "Deep Attentive Model for Knowledge Tracing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e0fc4b0410f3f7a31e3cc1c2b96d856d51fbd82a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26215": {
    "title": "Correspondence-Free Domain Alignment for Unsupervised Cross-Domain Image Retrieval",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5a572fb106197d8d4f0a81f26abb2b20e2e0aa3f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26216": {
    "title": "Isolation and Impartial Aggregation: A Paradigm of Incremental Learning without Interference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "30fd486635c6174ea340c0ee003b241d32f011ce",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26217": {
    "title": "Robust Self-Supervised Multi-Instance Learning with Structure Awareness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4494cded00ff0ef0d686cc2261b891686d7ad3d6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26218": {
    "title": "Distributed Projection-Free Online Learning for Smooth and Convex Losses",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3d2f11656462ed2dfc3c58da48ba12609460541b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26219": {
    "title": "USER: Unsupervised Structural Entropy-Based Robust Graph Neural Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bd7dbcb7e51edc56427b5eb1c7d0a4275dfe44a6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26220": {
    "title": "AutoNF: Automated Architecture Optimization of Normalizing Flows with Unconstrained Continuous Relaxation Admitting Optimal Discrete Solution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "79a5783a3dc2c19c632bc5d39a57b17c87ce9633",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26221": {
    "title": "SEnsor Alignment for Multivariate Time-Series Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "33c948c4a5631806830df3dda01528cabd44bede",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26222": {
    "title": "Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fbf48e013c963aa90fa3bfd04604935d952d674a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26223": {
    "title": "FedGS: Federated Graph-Based Sampling with Arbitrary Client Availability",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98a325486370aae953268046e9e1d6fb2ed86fed",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26224": {
    "title": "Efficient Exploration in Resource-Restricted Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3d3b0704c61d47c7bafb70ae2670b2786b8e4d81",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26225": {
    "title": "Efficient Explorative Key-Term Selection Strategies for Conversational Contextual Bandits",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "79aaa0a554a1f415c9cc59eeeab8ebda4fc15379",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26226": {
    "title": "Code-Aware Cross-Program Transfer Hyperparameter Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "27c5a594fb37d33640fadeaa07d0466211a60578",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26227": {
    "title": "Predictive Multiplicity in Probabilistic Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4217a85c206e0dafd8fc39da2adc55c311ba373a",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26228": {
    "title": "Feature Distribution Fitting with Direction-Driven Weighting for Few-Shot Images Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f8680befeea08e92981739a9cf68e3332f9fa7f5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26229": {
    "title": "Learning Instrumental Variable from Data Fusion for Treatment Effect Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7aae7745d8ee4dab3e7db7037e501474332d18fd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26230": {
    "title": "Towards In-Distribution Compatible Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5aa0ccbd38dca97b6d20b37bf9f3c8a414fa26a0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26231": {
    "title": "Non-IID Transfer Learning on Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aaca28e64dd9dfd3cbcd8082d0169ebdd7326a88",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26232": {
    "title": "Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and Injecting It into MLPs: An Effective GNN-to-MLP Distillation Framework",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0648a22c8f65fbe5767650c5e779d9b2888515ea",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26233": {
    "title": "Symphony in the Latent Space: Provably Integrating High-Dimensional Techniques with Non-linear Machine Learning Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "099c63db93000de4d6bcefe196f46afeb22d2fd0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26234": {
    "title": "Decentralized Riemannian Algorithm for Nonconvex Minimax Problems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "594d1a5df8db8de6dfaf2f703d55202a2bb7a58d",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26235": {
    "title": "Faster Adaptive Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1fd1109ec922dcd683190a42dd5712b4eb6113b2",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26236": {
    "title": "Practical Markov Boundary Learning without Strong Assumptions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5e3a726719af0b96b4ab4d117ac5e3e54bef5dc1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26237": {
    "title": "FedNP: Towards Non-IID Federated Learning via Federated Neural Propagation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4648ca42ed12b940fbe4f1b2b3d2a14b1d29dc44",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26238": {
    "title": "MetaZSCIL: A Meta-Learning Approach for Generalized Zero-Shot Class Incremental Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "07ea2ebadf13d1f84c72d44ae5a9ed36af168a69",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26239": {
    "title": "Adversarial Weight Perturbation Improves Generalization in Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "1e0930a6c4ad4c62c725cfa35e76081eb971a83a",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26240": {
    "title": "Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1f18bd6c3d216d8f7c6186267cfe6dce5a66d7a7",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26241": {
    "title": "Models as Agents: Optimizing Multi-Step Predictions of Interactive Local Models in Model-Based Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a8e839087b28dc469a47a184cbd197b21f32d9e6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26242": {
    "title": "Differentially Private Learning with Per-Sample Adaptive Clipping",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2d3c5468de7641262e9c6cb8366049098e88371e",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26243": {
    "title": "Zero-Cost Operation Scoring in Differentiable Architecture Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e8a8c7dbf7b499c17c8e74a80b7f99918e467b69",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26244": {
    "title": "HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "60004428c219a22443a33fe27051f246fa99e263",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26245": {
    "title": "Bayesian Federated Neural Matching That Completes Full Information",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ff13b88c34855d1342f58e4c36509b285c1ddeb2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26246": {
    "title": "CDMA: A Practical Cross-Device Federated Learning Algorithm for General Minimax Problems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "91ec9f720172dada9ef45f9d11e53df084ec4d3d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26247": {
    "title": "Towards Optimal Randomized Strategies in Adversarial Example Game",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e6e7544a50373e59271019304e91f2a6b450ed46",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26248": {
    "title": "A Tale of Two Latent Flows: Learning Latent Space Normalizing Flow with Short-Run Langevin Flow for Approximate Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2314afc804b9c425cefda5c7854ac4110e7b4812",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26249": {
    "title": "Semi-supervised Learning with Support Isolation by Small-Paced Self-Training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "076372bb5d005e1d4b554b02fc14044d541dd78b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26250": {
    "title": "On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "48a433a400c9abb6714c351b5423b396212bf0c5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26251": {
    "title": "Decentralized Stochastic Multi-Player Multi-Armed Walking Bandits",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3fd11026cf0ac132decd37379f9bc9952799c301",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26252": {
    "title": "Federated Generative Model on Multi-Source Heterogeneous Data in IoT",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8bf3da565ba41d6f250783985a6dc3fe8b4530a5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26253": {
    "title": "Contrastive Open Set Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f67894d00bb31297f3d6c8a8a8d8de9276d3b6fc",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26254": {
    "title": "Progressive Deep Multi-View Comprehensive Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3f78556059320f881c4ff5f7ce7fe8a35f393941",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26255": {
    "title": "A Survey on Model Compression and Acceleration for Pretrained Language Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c546e5447f412bf4f274e490996718641b211aa6",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26256": {
    "title": "GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a6628b4ac0b432659a0092add3eb371608d3e065",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26257": {
    "title": "Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "03446d8730c4bc5cb3abc9d8c13e8e6d3898e2ae",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26258": {
    "title": "Efficient Top-K Feature Selection Using Coordinate Descent Method",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2e7fdbb628a22000fcdc3138d83a4f6c1bb14633",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26259": {
    "title": "Label-Specific Feature Augmentation for Long-Tailed Multi-Label Text Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3e525d0a7f6886b82d3b5e82d5a40d7d514eb2f0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26260": {
    "title": "Neighborhood-Regularized Self-Training for Learning with Few Labels",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "728a34d0cbd7fef95ce8c6016e4db803d565b860",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26261": {
    "title": "Resilient Binary Neural Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a13eb514c83580a1678efa562c7a02c60b6983fd",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26262": {
    "title": "Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a2ab63a272fa0762a75eb3d1b0a86506a9db3623",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26263": {
    "title": "BridgeTower: Building Bridges between Encoders in Vision-Language Representation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "4c2668b3ae22fa592716480ec56012775b139f52",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26264": {
    "title": "USDNL: Uncertainty-Based Single Dropout in Noisy Label Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc81135198f11b1b8015ccb02a8da0905259d68c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26265": {
    "title": "Trusted Fine-Grained Image Classification through Hierarchical Evidence Fusion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a5f444de5f3048e9ae55a92cd4b80ccba05b90c7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26266": {
    "title": "Disentangled Representation for Causal Mediation Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b674763fa4dadab6d65665d7a85a363bf6f914bc",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26267": {
    "title": "Global Concept-Based Interpretability for Graph Neural Networks via Neuron Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1566fedfe843ac88fb36803368fa84bed6db2af3",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26268": {
    "title": "Fast and Accurate Binary Neural Networks Based on Depth-Width Reshaping",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "18890b992894944bec789d1b4d9b2356382d8c28",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26269": {
    "title": "Learning the Finer Things: Bayesian Structure Learning at the Instantiation Level",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f00c90ad2f54475c2f43512a36d1fd8d673b366f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26270": {
    "title": "Semidefinite Programming versus Burer-Monteiro Factorization for Matrix Sensing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3a113d264a02bd84fc6b3ea663fee2cdfb5b5bcf",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26271": {
    "title": "DeFL: Defending against Model Poisoning Attacks in Federated Learning via Critical Learning Periods Awareness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "85e7ca020c740d9dfadfa520b9d6d2c8f383ec7f",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26272": {
    "title": "T2G-FORMER: Organizing Tabular Features into Relation Graphs Promotes Heterogeneous Feature Interaction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "611fb68240299adf0b19450b9972c55fc63df483",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26273": {
    "title": "Computably Continuous Reinforcement-Learning Objectives Are PAC-Learnable",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d3cce69894f847a66e58e2c16d2f55ab404d2892",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26274": {
    "title": "Reinforcement Causal Structure Learning on Order Graph",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e283032acaed9db53c3fc447837d2793cffa2ddc",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26275": {
    "title": "AdaTask: A Task-Aware Adaptive Learning Rate Approach to Multi-Task Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8522f9a7bc7c958b5f66373b47ff68e1833089d6",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26276": {
    "title": "WaveForM: Graph Enhanced Wavelet Learning for Long Sequence Forecasting of Multivariate Time Series",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "17332418d299ef1cbd41cfcaf0a3a3141a7a8483",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26277": {
    "title": "Layout Generation as Intermediate Action Sequence Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2096dbecf841988c15d97df2cdb033cfd8cd5151",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26278": {
    "title": "Learning-Assisted Algorithm Unrolling for Online Optimization with Budget Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f94c9daee84e5213703800863f6c0111b32bfbef",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26279": {
    "title": "ADEPT: A DEbiasing PrompT Framework",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1abd4fa45ce20175452aa238870db2aebe9c0fe0",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26280": {
    "title": "Generalized Semantic Segmentation by Self-Supervised Source Domain Projection and Multi-Level Contrastive Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2d9cc109363eae1aeb873245833b440ed917409e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26281": {
    "title": "CEM: Constrained Entropy Maximization for Task-Agnostic Safe Exploration",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0a806876e419de58b650aacbf218e23f589327ad",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26282": {
    "title": "Understanding Representation Learnability of Nonlinear Self-Supervised Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "65909b7b029f8214f574f81f4dfbef1fe7289037",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26283": {
    "title": "Simple and Efficient Heterogeneous Graph Neural Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "db5f713db2730eb07c0bd7c5103e0c7e2b3e9ceb",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26284": {
    "title": "T-distributed Spherical Feature Representation for Imbalanced Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "012b5b6e90821784c0221f75d627469425e4b178",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26285": {
    "title": "Cluster-Guided Contrastive Graph Clustering Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9706835a2bf6d727993e7bc4610067dc35cc5336",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26286": {
    "title": "Flow to Control: Offline Reinforcement Learning with Lossless Primitive Discovery",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9d1445f1845a2880ff9c752845660e9c294aa7b5",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26287": {
    "title": "Prototypical Partial Optimal Transport for Universal Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "85d1cd4db2246b32c4b68bfdb1532c7d89bd64ea",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26288": {
    "title": "DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "708b04a43ceb2a914652d2b3a8b5afe28b1875ba",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26289": {
    "title": "Purifier: Defending Data Inference Attacks via Transforming Confidence Scores",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f605cb07365acd44f7ddc64711606c834f62afef",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26290": {
    "title": "i-Code: An Integrative and Composable Multimodal Learning Framework",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b60879dda0183160c9d0a611cb7e381e6942cf75",
    "semantic_title": "",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26291": {
    "title": "Learning Dynamic Latent Spaces for Lifelong Generative Modelling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "94d1500cb6b280ff201047bf831593c4659581b7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26292": {
    "title": "Lifelong Compression Mixture Model via Knowledge Relationship Graph",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e8a560ebfb5ccf6caa8f838080c42f3686dcbdc5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26293": {
    "title": "Lifelong Variational Autoencoder via Online Adversarial Expansion Strategy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a360413dc4fea6fe6d7d85e0396e2e55fc6a856c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26294": {
    "title": "Continual Variational Autoencoder via Continual Generative Knowledge Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8be84129d04f13cfba51fc8ab453044721d16ecf",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26295": {
    "title": "Certifiable Out-of-Distribution Generalization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6a99abc1a04244c4950c5ad999b5ebb20bdc1bd0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26296": {
    "title": "Random Walk Conformer: Learning Graph Representation from Long and Short Range",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d6c2ce832157f54e1fe717bd3b1a9c4d4619c26e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26297": {
    "title": "Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "173a41e7f0eebca7deadaa623d36f83ad93c9bf5",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26298": {
    "title": "GOHSP: A Unified Framework of Graph and Optimization-Based Heterogeneous Structured Pruning for Vision Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3ea79430455304c782572dfb6ca3e5230b0351de",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26299": {
    "title": "Policy-Based Primal-Dual Methods for Convex Constrained Markov Decision Processes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7a9c4cc5bd91fe5a0a2a0e0693f1b2bc89cd70e4",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26300": {
    "title": "Priori Anchor Labels Supervised Scalable Multi-View Bipartite Graph Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b3753e2b30662c7d0135fd28cd56c0c193cf7d65",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26301": {
    "title": "STARS: Spatial-Temporal Active Re-sampling for Label-Efficient Learning from Noisy Annotations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "830a4bc446c7c9d87975a95b7cea54e2d11d5727",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26302": {
    "title": "Boosted Dynamic Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "eda07e0ab8396f45db07c39a1c7fa643d08b07c3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26303": {
    "title": "Stable Learning via Sparse Variable Independence",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e1b5ca7d17c5b46a0c93c1a4e828ddf2a94f389a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26304": {
    "title": "Compressing Transformers: Features Are Low-Rank, but Weights Are Not!",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "568160c414aa26284b04cdf3e13d25b9d7a5a290",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26305": {
    "title": "Offline Imitation Learning with Suboptimal Demonstrations via Relaxed Distribution Matching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d05a0088e6ab6ba367650527c7e1cc46524da3dc",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26306": {
    "title": "High-Level Semantic Feature Matters Few-Shot Unsupervised Domain Adaptation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "01b14c1c3e2b5b4042d57f1a2be47d423c7fd68b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26307": {
    "title": "Coordinate Descent Methods for DC Minimization: Optimality Conditions and Global Convergence",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a8dfe3f91bed3c7536b99607e342ee9badc3dc9c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26308": {
    "title": "CEMA – Cost-Efficient Machine-Assisted Document Annotations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "1dd63eff40175f2ad76b395313fa13c23393ebef",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26309": {
    "title": "Joint Multimodal Entity-Relation Extraction Based on Edge-Enhanced Graph Alignment Network and Word-Pair Relation Tagging",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "74e14a0f55bdc0b8fa7548e0762f58cf493a12a3",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26310": {
    "title": "ODE-RSSM: Learning Stochastic Recurrent State Space Model from Irregularly Sampled Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3468d4cbfd51bd2013946e7a7df1fb95253f707f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26311": {
    "title": "Value-Consistent Representation Learning for Data-Efficient Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e3c598f5233d91f887edb626bb02ba86010a69c0",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26312": {
    "title": "Learning Conflict-Noticed Architecture for Multi-Task Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8f9e13380a4ccf99e8d4a0f1dd4c36cd311f8b60",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26313": {
    "title": "Quantum Multi-Agent Meta Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6e85ed4c60ccc8eef4cc5ad69e677d0f9f5bdbfc",
    "semantic_title": "",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26314": {
    "title": "Linking Sketch Patches by Learning Synonymous Proximity for Graphic Sketch Representation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b5458d11c6b64ab51d96581a708bb0ad40001a81",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26315": {
    "title": "Neural Integro-Differential Equations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9e740a91d943873000968afb0b137c83d65959a2",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26316": {
    "title": "Leveraging Structure for Improved Classification of Grouped Biased Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7331eb901d313073d7bfe8368af826d923b6a1b2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26317": {
    "title": "Are Transformers Effective for Time Series Forecasting?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5be02c8db2078bb72224438df8003552e49b23a8",
    "semantic_title": "",
    "citation_count": 109
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26318": {
    "title": "Substructure Aware Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f70fbf51b5ff4ba4c6a0766bc77831aff9176d16",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26319": {
    "title": "ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "09d31d7f124a30f6a7ccbf430feee62633decc05",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26320": {
    "title": "Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "0a199db260704aedc67836ae61728a954e8aa24c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26321": {
    "title": "Acceleration of Large Transformer Model Training by Sensitivity-Based Layer Dropping",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "05edd3c2ede087fa0fdfe8d2ecbf1aa95ce600f3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26322": {
    "title": "Interventional SHAP Values and Interaction Values for Piecewise Linear Regression Trees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1ea60f94e6bea09a60b92351b72dec40bf2948f9",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26323": {
    "title": "Enhanced Tensor Low-Rank and Sparse Representation Recovery for Incomplete Multi-View Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "88258d707e898923359fcea017f4f0281a65be57",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26324": {
    "title": "Denoising Multi-Similarity Formulation: A Self-Paced Curriculum-Driven Approach for Robust Metric Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "586e092999ebd347237ffe372af67bef36107369",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26325": {
    "title": "Rethinking Alignment and Uniformity in Unsupervised Image Semantic Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f6fb6f464efead0c4543f97de793a439c3ca07c6",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26326": {
    "title": "Behavior Estimation from Multi-Source Data for Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6616965ea639e90c2413cff00aedf0133ce80fd9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26327": {
    "title": "DARL: Distance-Aware Uncertainty Estimation for Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "32a31c899c145d9502ba3f5ef9fc70671a45da76",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26328": {
    "title": "When Neural Networks Fail to Generalize? A Model Sensitivity Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "22cf52a10dcfec08b1c7d8b0a6eb7bbbfa1c79d5",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26329": {
    "title": "Memorization Weights for Instance Reweighting in Adversarial Training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "00bbfc9b99d74203a64dc9f40639fe48a0deff36",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26330": {
    "title": "FedALA: Adaptive Local Aggregation for Personalized Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "939a858b08e3920783c7f949687a9758a509cee9",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26331": {
    "title": "Delving into the Adversarial Robustness of Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "29b64e41bbea997019b64696d2374c3c96dbdf5c",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26332": {
    "title": "DRGCN: Dynamic Evolving Initial Residual for Deep Graph Convolutional Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e36c914b0437afe55b51b1dfe502bba1f40c7bdd",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26333": {
    "title": "Let the Data Choose: Flexible and Diverse Anchor Graph Fusion for Scalable Multi-View Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38e94c56f008e91db2203c16644687b15b05bfc1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26334": {
    "title": "Optimal Sparse Regression Trees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3d5fbe321d89febc15a450fa171b6261f9c1daf0",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26335": {
    "title": "High-Dimensional Dueling Optimization with Preference Embedding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "561f9714db2e3eafcb28c731e99d4b122aca6525",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26336": {
    "title": "Spectral Feature Augmentation for Graph Contrastive Learning and Beyond",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1d3fc84e5efeb599123605268cf6c6616ac06820",
    "semantic_title": "",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26337": {
    "title": "Scalable Bayesian Meta-Learning through Generalized Implicit Gradients",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e960e12a260556cea93ca4e02450a5edc7e30d7c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26338": {
    "title": "Dynamic Heterogeneous Graph Attention Neural Architecture Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8dd0869fd671682fa2d8e5f5f0ef14ecef04df0d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26339": {
    "title": "Dynamic Ensemble of Low-Fidelity Experts: Mitigating NAS \"Cold-Start",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "29a2acee401e86c7a6708a370a2c58bead6034d4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26340": {
    "title": "Tensorized Incomplete Multi-View Clustering with Intrinsic Graph Completion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cbc2b78e5b981c58410605b27b7ff5fc8e216c65",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26341": {
    "title": "Imbalanced Label Distribution Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "383bf49b0444f27a94c4acc8d11d7a0225142c37",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26342": {
    "title": "CoopInit: Initializing Generative Adversarial Networks via Cooperative Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a5cbcd5701f8a4db18bbfce8182a0d22b840b67",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26343": {
    "title": "AutoGraph: Optimizing DNN Computation Graph for Parallel GPU Kernel Execution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "795a7d22873640b0cffcf9632bfa3ae00dd8566e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26344": {
    "title": "Fairness and Explainability: Bridging the Gap towards Fair Model Explanations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "96fb5cf9a971a956a8ebf52a4c9e816cb458bdb6",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26345": {
    "title": "Adaptive Policy Learning for Offline-to-Online Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f6274e6ba614b46d6283c775cfe4565e8ce50bc8",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26346": {
    "title": "Multi-Level Confidence Learning for Trustworthy Multimodal Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "70d5e6d63ab786d8d50fa4de096613943d18feb6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26347": {
    "title": "CowClip: Reducing CTR Prediction Model Training Time from 12 Hours to 10 Minutes on 1 GPU",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3ca2ba62e130c104b2c01ea496af6f690474a1db",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26348": {
    "title": "Data Imputation with Iterative Graph Reconstruction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fcd957f1437d03bc419522d67a236696574cd81a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26349": {
    "title": "Does It Pay to Optimize AUC?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e903c91c38bd3bdd5e5b3455575dfc9a4b8c8cc5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26350": {
    "title": "SLOTH: Structured Learning and Task-Based Optimization for Time Series Forecasting on Hierarchies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b180f97412efe688d335f409a6589c1de6675a5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26351": {
    "title": "Robust Temporal Smoothness in Multi-Task Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7090f46777a0f35938825cb28298006e8647b308",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26352": {
    "title": "Combining Adversaries with Anti-adversaries in Training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2810e9602d87f132e2b2f3eda6539d88d5330ec6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26353": {
    "title": "Gradient-Adaptive Pareto Optimization for Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1eb5f9b321e66f0c01184e675676e329c5d06349",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26354": {
    "title": "Quantized Feature Distillation for Network Quantization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6dcdac10bbc7364740178dcd10c5b05906fe13a3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26355": {
    "title": "Bayesian Cross-Modal Alignment Learning for Few-Shot Out-of-Distribution Generalization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4d8c20a0513e51b1a5064c61e72611583352d4a2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26356": {
    "title": "ContraFeat: Contrasting Deep Features for Semantic Discovery",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7224248d35e0a877a1e5bae1d9664fd9e6cc0045",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26357": {
    "title": "Locate Then Generate: Bridging Vision and Language with Bounding Box for Scene-Text VQA",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dd67c3185aa94f089f048f654c3067ad4bb4a56d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26358": {
    "title": "ILSGAN: Independent Layer Synthesis for Unsupervised Foreground-Background Segmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "85b392d00feff27ed3249c6653ce2e94aa34aaa2",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26359": {
    "title": "SVP-T: A Shape-Level Variable-Position Transformer for Multivariate Time Series Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "86f260abb52cea53b4dbf3f5c2a5669450983374",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26360": {
    "title": "Mixed-Variable Black-Box Optimisation Using Value Proposal Trees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "58b128b995b6740b8f5aece574bc1f4024bb7016",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26361": {
    "title": "Synchronization and Diversity of Solutions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5cdadbbb6ebcab86003228ca2be7f3386c2d8a66",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26362": {
    "title": "The Multi-Agent Transportation Problem",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "098e2881eb611e46bbf7b579ff6b34ce183f380f",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26363": {
    "title": "Emergent Quantized Communication",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "69e364cb69fc8c2dcd1157ecdb8758f3fd04c431",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26364": {
    "title": "Learning Explicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning via Polarization Policy Gradient",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b8fb3b575c61020537692b4f904381e3c5fe7bfa",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26365": {
    "title": "Zero-Shot Assistance in Sequential Decision Problems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c6a733eb2dad71c8d022f5d9be81854d198ac11a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26366": {
    "title": "Multi-Unit Auctions for Allocating Chance-Constrained Resources",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "62055214297cf0ab16f2382b2b79314dc7e96316",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26367": {
    "title": "Reward-Based Negotiating Agent Strategies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "175474e2b044b2637cb904698a4fe497e4a4bd3b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26368": {
    "title": "Intersection Coordination with Priority-Based Search for Autonomous Vehicles",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "384a7cb9b19a8a7bb79be8582ab4f351a8cb69f5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26369": {
    "title": "Solving Large-Scale Pursuit-Evasion Games Using Pre-trained Strategies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b4b4a321e64dd7c4d7ae48676657f42da29b2cf",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26370": {
    "title": "Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e72c1c09c7992e7ffaeb652693955eadad522705",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26371": {
    "title": "Learning to Shape Rewards Using a Game of Two Partners",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7c1ed780d2dd7d780c5ff6371d4d14c36c357e3c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26372": {
    "title": "Reconstructing an Epidemic Outbreak Using Steiner Connectivity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "57872bf9a7fa8016cf88372f475627fbfef71c3c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26373": {
    "title": "Formal Verification of Bayesian Mechanisms",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "70c3332847d04e906ca793ce19fa1cf96717c703",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26374": {
    "title": "Memory-Augmented Theory of Mind Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a40c7a12dfd42719a778b0c7a1ee4ede65aa197",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26375": {
    "title": "Socially Optimal Non-discriminatory Restrictions for Continuous-Action Games",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "214389422b1f67fe5e545ff9a0c0ae1004188cc6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26376": {
    "title": "Fault-Tolerant Offline Multi-Agent Path Planning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "46e7c11f2503e7280a8557b3549dd7018dc61a3e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26377": {
    "title": "LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "62abe88c56d04bff38e90bbc81409b2594f77efd",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26378": {
    "title": "Networked Anti-coordination Games Meet Graphical Dynamical Systems: Equilibria and Convergence",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "154e6c775a798de03d251a5e2b4791a8d65798a4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26379": {
    "title": "Learning from Good Trajectories in Offline Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f91fe06f87bb21350d0e568548068759cbdc563",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26380": {
    "title": "Resource Sharing through Multi-Round Matchings",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "62f1d21985a64eb5a169909cd0778b88c8b1d539",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26381": {
    "title": "Effective Integration of Weighted Cost-to-Go and Conflict Heuristic within Suboptimal CBS",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0e39f92ad49eef88dfd0e3b044f3404a03f7c402",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26382": {
    "title": "DM²: Decentralized Multi-Agent Reinforcement Learning via Distribution Matching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f381189488173181f5dee719c93d698838d546f1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26383": {
    "title": "Emergence of Punishment in Social Dilemma with Environmental Feedback",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e1a0393771940b80a06fadf6e6aa763d9382b50d",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26384": {
    "title": "Subspace-Aware Exploration for Sparse-Reward Multi-Agent Tasks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9c4ece695bfe0a9e99ee21323313882078b4ef4d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26385": {
    "title": "Consensus Learning for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "74a184436ce058caf6f821f16dd7dbac9f652ca2",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26386": {
    "title": "HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8a17c4a4e6ff86f444c7c6811e307d52f443d149",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26387": {
    "title": "Hierarchical Mean-Field Deep Reinforcement Learning for Large-Scale Multiagent Systems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3d169fc1b93ce317a60e77a1b263d3f82804f85d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26388": {
    "title": "Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "223066f0c1f0d834848bf41f96a2136ef40467fb",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26389": {
    "title": "DACOM: Learning Delay-Aware Communication for Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "738d51cb7d22c3db5bd46eda05fcf1048ea2ad0d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26390": {
    "title": "Effective and Stable Role-Based Multi-Agent Collaboration by Structural Information Principles",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "832d9fda09f1c36c4eda2010295ef68cdf95ad37",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26391": {
    "title": "Learning to Play General-Sum Games against Multiple Boundedly Rational Agents",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7403a725fcffee8107a078f10dfc0df957b78057",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26392": {
    "title": "Towards Robust Metrics for Concept Representation Evaluation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b6ea8f01aafcaf689f190c5193880d1cba0461ef",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26393": {
    "title": "On the Vulnerability of Backdoor Defenses for Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "efaab402913dbec3a01a503803dda48554be97e8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26394": {
    "title": "Distributionally Robust Optimization with Probabilistic Group",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14de7ffbbc1ce1afd75f32e43787b92a0165a5a7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26395": {
    "title": "Correct for Whom? Subjectivity and the Evaluation of Personalized Image Aesthetics Assessment Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ea821689157f662ef611e7c6e65e33653fb11d7c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26396": {
    "title": "Covariate-Shift Generalization via Random Sample Weighting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "79f4bf84b817f47fa74a8b183cde7641ccfecc4f",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26397": {
    "title": "Fairness in Contextual Resource Allocation Systems: Metrics and Incompatibility Results",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ffae901292c459ac22c299279381db6ffafd1d90",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26398": {
    "title": "Improvement-Focused Causal Recourse (ICR)",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14b76875dc3d243b9f040db7df0373eb9256a196",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26399": {
    "title": "Explaining Model Confidence Using Counterfactuals",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "459e64919f6451fd93313ee2d230ddef0d3fa08a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26400": {
    "title": "Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3102b553be4f4b09bf6b2e1982ca880d1305dc38",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26401": {
    "title": "XRand: Differentially Private Defense against Explanation-Guided Attacks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "52ea77624f405563ce08778c2efa15dd9846bb63",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26402": {
    "title": "Mitigating Adversarial Norm Training with Moral Axioms",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b33afce5c6ab0cbd247a4e04018130346d0a9b2c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26403": {
    "title": "Equity Promotion in Public Transportation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7f3951422106a23841e8c712db068c130a03f3ae",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26404": {
    "title": "Online Platforms and the Fair Exposure Problem under Homophily",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "88e40be2fe3db2aec4385a1db2f3fd9a493a55de",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26405": {
    "title": "Minimax AUC Fairness: Efficient Algorithm with Provable Convergence",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a20a2ec487a1fc7923fcec479e9f86e399151a34",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26406": {
    "title": "Faster Fair Machine via Transferring Fairness Constraints to Virtual Samples",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "518a6d6cbffef3f547863cd496eabd8ad3f817a8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26407": {
    "title": "Learning Control Policies for Stochastic Systems with Reach-Avoid Guarantees",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a6c7846fb31946622302eeba2186d8c4b39e425a",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26408": {
    "title": "Robust Neuro-Symbolic Goal and Plan Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d9cb686c0c48d271f6806efb5a494d738b585fa1",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26409": {
    "title": "Heuristic Search for Multi-Objective Probabilistic Planning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "091d3e219240e8ee5c496867b3f59e69abe10da4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26410": {
    "title": "Zero-Knowledge Proofs for Classical Planning Problems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f484252fea5416e03247b649b563833f8eb92cfb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26411": {
    "title": "Planning with Hidden Parameter Polynomial MDPs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3129d24d2b60ba4ffbf0060f430e1abce32e541d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26412": {
    "title": "Privacy Attacks on Schedule-Driven Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "71c9259299e0edb95c2a755db292b5c0720b8cde",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26413": {
    "title": "Markov Decision Processes with Time-Varying Geometric Discounting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "47fa00c8948f945f85d3ebeeb434b0fb4ffbef24",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26414": {
    "title": "Learning-Augmented Algorithms for Online TSP on the Line",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "45850640a59627263b5a9b995be5f248aefc20bc",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26415": {
    "title": "Networked Restless Bandits with Positive Externalities",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f3d6ad6b700d5fc50b2f552bc735083b41a926dd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26416": {
    "title": "Planning for Learning Object Properties",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fa6786bd22a1eb67a4e1f28719103ba0e0c2398d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26417": {
    "title": "Fully Online Matching with Stochastic Arrivals and Departures",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0f618e81ea843aa638fd2445da298d52353e62bc",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26418": {
    "title": "Towards Automated Modeling Assistance: An Efficient Approach for Repairing Flawed Planning Domains",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8b4da4a73bb88131c8a19d9c1c4dc3ccaadd2e6e",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26419": {
    "title": "Was Fixing This Really That Hard? On the Complexity of Correcting HTN Domains",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "267246808c31153e8ff766fd663d59595d3fddcc",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26420": {
    "title": "On Total-Order HTN Plan Verification with Method Preconditions – An Extension of the CYK Parsing Algorithm",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "7493b69460ae3d93c07bd579335943fbf9338639",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26421": {
    "title": "A Dynamics and Task Decoupled Reinforcement Learning Architecture for High-Efficiency Dynamic Target Intercept",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f08ec6254022a2bfaeebb9d9c72404a1351c078",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26422": {
    "title": "AlphaRoute: Large-Scale Coordinated Route Planning via Monte Carlo Tree Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b39aecbf900ebdcc4846324ec887d981247df29f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26423": {
    "title": "Learning Rational Subgoals from Demonstrations and Instructions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2ddd59c64c0407f2386241b3d5f369bbea4baa8e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26424": {
    "title": "Learning Safe Numeric Action Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "85a6b466c642a50987953ea2562eb6956bfb5788",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26425": {
    "title": "Automated Verification of Social Laws in Numeric Settings",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f60df74cf98cfee51397b9827bc5979f6341fb7b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26426": {
    "title": "Expressive Optimal Temporal Planning via Optimization Modulo Theory",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc38b1104ce96be3d05047ce8d31728b19f8495e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26427": {
    "title": "Flexible Budgets in Restless Bandits: A Primal-Dual Algorithm for Efficient Budget Allocation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "06b26284e85e767313d2b4291ee01521a850d4a6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26428": {
    "title": "Structurally Restricted Fragments of Numeric Planning – a Complexity Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "243ace8039ae88f57d03cc62ca20af8db703c747",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26429": {
    "title": "Predicate Invention for Bilevel Planning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1a42134ea9d5ac1bb230e8b09dd9b0bc7fbc33b2",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26430": {
    "title": "Smoothed Online Combinatorial Optimization Using Imperfect Predictions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "905096ec9dfe7ebd4782628820fbad840feece06",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26431": {
    "title": "Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b6b6ddc7a6a13441ff87b98133dd920ba488e544",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26432": {
    "title": "Neural TSP Solver with Progressive Distillation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98abf3344d73e24eef4138a3238860602b15096e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26433": {
    "title": "The Linear Distance Traveling Tournament Problem Allows an EPTAS",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cd49c8c0ea7633798017e2583b453b4a3a428f7f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26434": {
    "title": "Learning Relational Causal Models with Cycles through Relational Acyclification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2785a607dd1a88722184b130c191f96bfd23caa0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26435": {
    "title": "Causal Effect Identification in Cluster DAGs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9aee5972617d44866993dd9bd07b6ff66452c62f",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26436": {
    "title": "A Simple Unified Approach to Testing High-Dimensional Conditional Independences for Categorical and Ordinal Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "24a2b64e8daa805c6de265a70ad7f0c2b45479d1",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26437": {
    "title": "Score-Based Learning of Graphical Event Models with Background Knowledge Augmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14ec61dad1880ef08666c7e9f2bc0822e07df1c3",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26438": {
    "title": "Entropy Regularization for Population Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "361f21c1ffd6c178ff9c5745dd15efb64dfb182c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26439": {
    "title": "Principled and Efficient Motif Finding for Structure Learning of Lifted Graphical Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "374a455fac344c990b99c6c4369f7e1a4a7bcf57",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26440": {
    "title": "A Faster Practical Approximation Scheme for the Permanent",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d883d135250580201b091e1552128b0a29a7052c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26441": {
    "title": "Neural Diffeomorphic Non-uniform B-spline Flows",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fe61a832a45cab659d617c534d4d0da142d51821",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26442": {
    "title": "Identification and Estimation of the Probabilities of Potential Outcome Types Using Covariate Information in Studies with Non-compliance",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "176b6676bbce824f0d0d53ad5d99edf1565da491",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26443": {
    "title": "Computing Divergences between Discrete Decomposable Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a03e29b3558f4d82e6f3216258c9469ed05d150",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26444": {
    "title": "Out-of-Distribution Generalization by Neural-Symbolic Joint Training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b0ed6b805c99d98e5e684a1a5eab6717eef14529",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26445": {
    "title": "Novel Ordering-Based Approaches for Causal Structure Learning in the Presence of Unobserved Variables",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b9b58dd484ea2c198b7fcc17c02ea9d91068ede",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26446": {
    "title": "Maximizing the Probability of Fixation in the Positional Voter Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6764b61918b9190914c1a11ccb4a75ab9f06ee2c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26447": {
    "title": "Certifying Fairness of Probabilistic Circuits",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0418f5b401ee793bf0e99a1523d5edcd0427d019",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26448": {
    "title": "Probabilities of Potential Outcome Types in Experimental Studies: Identification and Estimation Based on Proxy Covariate Information",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "489d2650ad53d430127b8577a2fbf4857f23387c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26449": {
    "title": "Lifted Inference with Linear Order Axiom",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1402cac2817e664ec9d76da8eab1431e4d27f7dd",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26450": {
    "title": "Vector Causal Inference between Two Groups of Variables",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b0bd0bc26c656d333ed4a5b3b7eca2ba4dc8ccc",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26451": {
    "title": "Efficient Enumeration of Markov Equivalent DAGs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ae3aad78395546c58df9b18287991508a0471873",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26452": {
    "title": "Differentially Private Nonlinear Causal Discovery from Numerical Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "23689c77d6ed841ce601eaa21db5eb946407fab6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26453": {
    "title": "Safe Interval Path Planning with Kinodynamic Constraints",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c9ed07ef6d320f32179db8acca96105265057c1c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26454": {
    "title": "Diversity Maximization in the Presence of Outliers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d2079b3c8ea31d25512a59f63992dfdeddbb7e7e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26455": {
    "title": "Fair Short Paths in Vertex-Colored Graphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0dad9f0caae52a64cc87e2663c4bb2bc0d30790b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26456": {
    "title": "AC-Band: A Combinatorial Bandit-Based Approach to Algorithm Configuration",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fe95085e0a6d19a60a524f85be5ccd63a5959735",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26457": {
    "title": "GRASMOS: Graph Signage Model Selection for Gene Regulatory Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "565a26ec9e8f548dcf20dea554d0e267a14c72f5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26458": {
    "title": "Optimal Pathfinding on Weighted Grid Maps",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e74c87d6b9d9bbe26d2114ad38add7b5442453e8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26459": {
    "title": "Warm-Starting Nested Rollout Policy Adaptation with Optimal Stopping",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "efe3b72a9da2bb9cf8ea1900d56ae0b3a422b851",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26460": {
    "title": "A Proof That Using Crossover Can Guarantee Exponential Speed-Ups in Evolutionary Multi-Objective Optimisation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "117c4cadc884afd10038fc60d1261c5db82c739c",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26461": {
    "title": "Runtime Analysis for the NSGA-II: Provable Speed-Ups from Crossover",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bac992afcc9c0b508f589751f8b9f5fe2f55b05c",
    "semantic_title": "",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26462": {
    "title": "From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "787b61c525f2489bb42076ca5afae1b439b0a3a5",
    "semantic_title": "",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26463": {
    "title": "Ultrafast Euclidean Shortest Path Computation Using Hub Labeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d47dadbcc38fdbae6d27a6999b2bdc62a763d93a",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26464": {
    "title": "A Formal Metareasoning Model of Concurrent Planning and Execution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a1e304ee403237b71740b837e934ab5153410356",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26465": {
    "title": "TransPath: Learning Heuristics for Grid-Based Pathfinding via Transformers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6ab30e5b9fcbb2203b99f8f1753ae23e0b735fa6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26466": {
    "title": "Large-State Reinforcement Learning for Hyper-Heuristics",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ab8ae110b84a98e2c9319bb2347e1d11d439f211",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26467": {
    "title": "Human Assisted Learning by Evolutionary Multi-Objective Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a6295fe7ca3873ceead43df39f8f945462cffb54",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26468": {
    "title": "OPT-GAN: A Broad-Spectrum Global Optimizer for Black-Box Problems by Learning Distribution",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4d0fe6de29720fc358348ca9f5d48edf7ece6518",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26469": {
    "title": "Analyzing and Improving the Use of the FastMap Embedding in Pathfinding Tasks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6939432fb47a75db461f89b1b44e7012adda0006",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26470": {
    "title": "Fully Computer-Assisted Proofs in Extremal Combinatorics",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c0ed378a0b63c52f17a89c5dc92e2325dbb31e35",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26471": {
    "title": "Electrophysiological Brain Source Imaging via Combinatorial Search with Provable Optimality",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d45c401bc7b192c588f24c1ae9d0f6b875579d02",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26472": {
    "title": "Improved Algorithm for Regret Ratio Minimization in Multi-Objective Submodular Maximization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "71e07dd7f9327d0a030c40b8b15bd2ee8059d34a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26473": {
    "title": "Efficient Gradient Approximation Method for Constrained Bilevel Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f23bff48ad4da52684fa983e8188343385be7a4b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26474": {
    "title": "A Generalized Scalarization Method for Evolutionary Multi-Objective Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0239c9c90a81686ac386aee7d795096858bb8c8a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26475": {
    "title": "Generalized Category Discovery with Decoupled Prototypical Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a6f06a7a03380a09e7bee185054d9bac9c32ac9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26476": {
    "title": "Structured Case-Based Reasoning for Inference-Time Adaptation of Text-to-SQL Parsers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5435ed7c26f0c250493f244acffb69dd929d116b",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26477": {
    "title": "SegFormer: A Topic Segmentation Model with Controllable Range of Attention",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cc40f72c6bbe6a78d41d34a82984b8bd107a5e4d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26478": {
    "title": "Rich Event Modeling for Script Event Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5c8191cf4cfe1abf70775ab95f01cacb3d26cdc1",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26479": {
    "title": "Avocodo: Generative Adversarial Network for Artifact-Free Vocoder",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d1a595d6f3248898a5b4f7611b24f3771eef3540",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26480": {
    "title": "End-to-End Deep Reinforcement Learning for Conversation Disentanglement",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "61643a757de121303a2af817870e2792211e6ad6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26481": {
    "title": "Self-Supervised Logic Induction for Explainable Fuzzy Temporal Commonsense Reasoning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "031970e341dfd1385ce0ac9f4a21dc8d20e85645",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26482": {
    "title": "Zero-Shot Cross-Lingual Event Argument Extraction with Language-Oriented Prefix-Tuning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "183551cf1dbc4692e9567491a204b23140bb6cde",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26483": {
    "title": "RPA: Reasoning Path Augmentation in Iterative Retrieving for Multi-Hop QA",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dfd1508ad2fd5c79fe7c17fa77f2bf660fc24999",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26484": {
    "title": "Leveraging Modality-Specific Representations for Audio-Visual Speech Recognition via Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38d4c9de406c02239cc2e7c6e8797523d8093380",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26485": {
    "title": "Converge to the Truth: Factual Error Correction via Iterative Constrained Editing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0657858dbda4546e4209505764e73b3f58964617",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26486": {
    "title": "Adversarial Word Dilution as Text Data Augmentation in Low-Resource Regime",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "51c2714ab5dbc330619a1a96db994c9905900160",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26487": {
    "title": "CP-Rec: Contextual Prompting for Conversational Recommender Systems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ae67d9b533f257584ecb91647e9520dad8de931b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26488": {
    "title": "A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4b8d3ede673ddeab9dfb5184da6b748d7a526754",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26489": {
    "title": "Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "72ae79c894cc5f4829cb190500fc143994545648",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26490": {
    "title": "Preference-Controlled Multi-Objective Reinforcement Learning for Conditional Text Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "33aa0aff496d182a8ea8bf11a5155c257dea40d4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26491": {
    "title": "Learning towards Selective Data Augmentation for Dialogue Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "50ba225bcfd6bfd34f5c6957ee0b72a4f12f4e89",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26492": {
    "title": "Learn from Yesterday: A Semi-supervised Continual Learning Method for Supervision-Limited Text-to-SQL Task Streams",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "53d62f2e7bf20c442ce7197b2d39e2f6ea77a47b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26493": {
    "title": "A Scope Sensitive and Result Attentive Model for Multi-Intent Spoken Language Understanding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38ec6fc80ccbf1dd8a7e66111ff37473f9edbad8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26494": {
    "title": "Unsupervised Explanation Generation via Correct Instantiations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "655d34b590e8911e072013ad21582c0382447600",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26495": {
    "title": "Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-Shot In-Context Learners",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "06edda0310b4ec7c5012d012349252a3a77521b6",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26496": {
    "title": "Neural Dynamic Focused Topic Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "215ca900b723a975b2fc0ad6eef4b650f522e96e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26497": {
    "title": "Improving Simultaneous Machine Translation with Monolingual Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bf4ccb8446c6f9fa79b799b407852c7a218a3c02",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26498": {
    "title": "Domain-Adapted Dependency Parsing for Cross-Domain Named Entity Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "82b2dd1bc2e7a7522d6f6abb77770be550e84ff7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26499": {
    "title": "MultiSpider: Towards Benchmarking Multilingual Text-to-SQL Semantic Parsing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f377e2768aaab569db6c985a91b5eca4afbd4e1c",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26500": {
    "title": "Learning to Select from Multiple Options",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c9feb2cf67e17e22312b30f0eb4e8484fe3d5b11",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26501": {
    "title": "Real or Fake Text?: Investigating Human Ability to Detect Boundaries between Human-Written and Machine-Generated Text",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b118283afc5d8652de52cd13a5e287d76c5ec91f",
    "semantic_title": "",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26502": {
    "title": "Diffuser: Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b0c5c673c690c644a7d4af73adb783bd98486181",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26503": {
    "title": "Cogito Ergo Summ: Abstractive Summarization of Biomedical Papers via Semantic Parsing Graphs and Consistency Rewards",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7e70391224b5dd8c2b13a3165b322858da17bcdf",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26504": {
    "title": "MIGA: A Unified Multi-Task Generation Framework for Conversational Text-to-SQL",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "642e04ece55c5b532ff7e5408d8723c7d9c835db",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26505": {
    "title": "On the Effectiveness of Parameter-Efficient Fine-Tuning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "846bdc54563f9de2e8388078ea2467b81151f6d5",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26506": {
    "title": "SumREN: Summarizing Reported Speech about Events in News",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3a356a3a48b952837c79c229531ad93a72bc62df",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26507": {
    "title": "ProKD: An Unsupervised Prototypical Knowledge Distillation Network for Zero-Resource Cross-Lingual Named Entity Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5be413ff1171d43dd531de38d1c19325569ccda3",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26508": {
    "title": "Denoising Pre-training for Machine Translation Quality Estimation with Curriculum Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "056d3bd8c3b77643bdfa34adcf602cb538600e0c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26509": {
    "title": "Generating Coherent Narratives by Learning Dynamic and Discrete Entity States with a Contrastive Framework",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b87a519690516c47aac03b1d794e4ae199812990",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26510": {
    "title": "Learning to Imagine: Distillation-Based Interactive Context Exploitation for Dialogue State Tracking",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "03b78c85b72b973f1109dc605bc0030a55febde9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26511": {
    "title": "RenewNAT: Renewing Potential Translation for Non-autoregressive Transformer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14897d84d004b37b38ddbafc178e518ab31f616e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26512": {
    "title": "Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5349d7d21d59633553ff7ce2d57376b8e5ddd698",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26513": {
    "title": "Competition or Cooperation? Exploring Unlabeled Data via Challenging Minimax Game for Semi-supervised Relation Extraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "16bbe866a849e538dc4cd2b213ca06e50595a23b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26514": {
    "title": "Feature Normalization and Cartography-Based Demonstrations for Prompt-Based Fine-Tuning on Emotion-Related Tasks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "230137d02910e43a9d161e21af24b80fd94d351e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26515": {
    "title": "A Simple Yet Effective Subsequence-Enhanced Approach for Cross-Domain NER",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "593434904a5fe302aa876d7736a737c86e795724",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26516": {
    "title": "A Question-Answering Approach to Key Value Pair Extraction from Form-Like Document Images",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f5ddb5440ac6eb46da1b91b6bfe247c3a45eaaf1",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26517": {
    "title": "SEAT: Stable and Explainable Attention",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e2f4c22090073ddd63708bea61de1e5a5bc905f4",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26518": {
    "title": "Personalized Dialogue Generation with Persona-Adaptive Attention",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c66b4f762f94b8d3532f532a401c67c2d35e2546",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26519": {
    "title": "Question Decomposition Tree for Answering Complex Questions over Knowledge Bases",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9da75352f8d5dc289f830096edadae1849444f53",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26520": {
    "title": "Hierarchical Text Classification as Sub-hierarchy Sequence Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "22c963ff1488e009e119f6137657ddfe321affbe",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26521": {
    "title": "IndicSUPERB: A Speech Processing Universal Performance Benchmark for Indian Languages",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5b870ccad0746225c71cf1167d929d80e6db47f6",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26522": {
    "title": "SheetPT: Spreadsheet Pre-training Based on Hierarchical Attention Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7617b8476756479789a1a0964427b5a81024e123",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26523": {
    "title": "SeDepTTS: Enhancing the Naturalness via Semantic Dependency and Local Convolution for Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "08bdd31c50de29d7b69e2622ddfa6e7e842be075",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26524": {
    "title": "Prototypical Fine-Tuning: Towards Robust Performance under Varying Data Sizes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5cbd6a61a072567511789646407ea16934b10baa",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26525": {
    "title": "Cross-Modal Distillation for Speaker Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "496f94f427a63ec0e6c1a1cbab9aea995ecc9c33",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26526": {
    "title": "Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "23cb0c2f27df7d92d073c99a2c101789a5454160",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26527": {
    "title": "COCA: COllaborative CAusal Regularization for Audio-Visual Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14a208be5919ab52b8b2fc732f358295a7bc203f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26528": {
    "title": "Script, Language, and Labels: Overcoming Three Discrepancies for Low-Resource Language Specialization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6f763bd76f48c9f34fa0b9cd2ca56594566f47f4",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26529": {
    "title": "LIQUID: A Framework for List Question Answering Dataset Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3b0424149731d10829015cb4ab6299d18162128e",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26530": {
    "title": "UniSyn: An End-to-End Unified Model for Text-to-Speech and Singing Voice Synthesis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "304a8668a44730e9d12df8a479c0257c2a194190",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26531": {
    "title": "SoftCorrect: Error Correction with Soft Detection for Automatic Speech Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "09299aa885d4cef2c391c41b3f3ee444f3c00414",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26532": {
    "title": "Sequence Generation with Label Augmentation for Relation Extraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "85ca3f50c60aa13237bfa2d46d9fc3c42ef5049c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26533": {
    "title": "Reviewing Labels: Label Graph Network with Top-k Prediction Set for Relation Extraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e118becc25034e5ba287f11b2c72ebaf765f870b",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26534": {
    "title": "Online Noisy Continual Relation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1406c1a0c9d0e855e5bf16b8303f8cde86e8fb2c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26535": {
    "title": "RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6d51f4b220cb2c8321dc5f9755b7d66f10f1cad6",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26536": {
    "title": "Graphix-T5: Mixing Pre-trained Transformers with Graph-Aware Layers for Text-to-SQL Parsing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dcffef7c94546389c02c837e0e9290039938b4d2",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26537": {
    "title": "Compressed Heterogeneous Graph for Abstractive Multi-Document Summarization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8b150819910d9e05eebfa746b7648e4dc2c5b7c9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26538": {
    "title": "TrOCR: Transformer-Based Optical Character Recognition with Pre-trained Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "de688c6e73ccf6ed33ff1cc7919d24456a1f74e2",
    "semantic_title": "",
    "citation_count": 78
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26539": {
    "title": "Mitigating Negative Style Transfer in Hybrid Dialogue System",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "18220734faa6a355e949cf101aa1e2a8463c898c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26540": {
    "title": "Low Resource Quantitative Information Extraction via Structure Searching and Prefix-Based Text Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c78b90b1462a7d3c50c5d2910c8e95243ea54da4",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26541": {
    "title": "SKIER: A Symbolic Knowledge Integrated Model for Conversational Emotion Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d8088d6b45e3ae523b9472745971f698a3b1d7f5",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26542": {
    "title": "PGSS: Pitch-Guided Speech Separation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1e3e6d16bf4278815ad26d4388c3edf46c1486df",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26543": {
    "title": "DyRRen: A Dynamic Retriever-Reranker-Generator Model for Numerical Reasoning over Tabular and Textual Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6fa180f4ce4be2715f3cbe13dc5dc6d198dc7249",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26544": {
    "title": "Heterogeneous-Branch Collaborative Learning for Dialogue Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "86dcd6268324b65960f0ac6287dabf155647c5f7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26545": {
    "title": "Learning to Know Myself: A Coarse-to-Fine Persona-Aware Training Framework for Personalized Dialogue Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "775cfa30a26a723c8c4fd1dca63baed24067e17e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26546": {
    "title": "WIERT: Web Information Extraction via Render Tree",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4e5923251039ea4b118f29a3abd689b1ebfbedb0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26547": {
    "title": "STAGE: Span Tagging and Greedy Inference Scheme for Aspect Sentiment Triplet Extraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "80e01784da4c21687a67c0b68d03592d3d879ee5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26548": {
    "title": "Generalizing Math Word Problem Solvers via Solution Diversification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6d686c2232d05b92b1549a36df24720c5d4bedd1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26549": {
    "title": "On Grounded Planning for Embodied Tasks with Language Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "59b71e2a248d67a2692bc7e35faa504ee2dbc98d",
    "semantic_title": "",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26550": {
    "title": "DeAR: A Deep-Learning-Based Audio Re-recording Resilient Watermarking",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "74aa68c5ca4fef1ce13b14920427b5c229e25dd1",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26551": {
    "title": "Detecting and Grounding Important Characters in Visual Stories",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8f51efde4213a3970ed498ee8a29a0e2b6b4d9fc",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26552": {
    "title": "Boosting Few-Shot Text Classification via Distribution Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0bf970a8a5a580259891cdb40ebf8914e612ebd5",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26553": {
    "title": "SSPAttack: A Simple and Sweet Paradigm for Black-Box Hard-Label Textual Adversarial Attack",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1500c256a84a4746a70d670cdad4bf697196d5a2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26554": {
    "title": "LADA-Trans-NER: Adaptive Efficient Transformer for Chinese Named Entity Recognition Using Lexicon-Attention and Data-Augmentation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8dddf88fe5de9e01b106cfb8760c725f90ade56c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26555": {
    "title": "Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "097490170c4691eec8844bf6454ff580f1151eec",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26556": {
    "title": "A Disentangled-Attention Based Framework with Persona-Aware Prompt Learning for Dialogue Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6b36b4ef56d9ac2eb622c331610f23d6e3f6799d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26557": {
    "title": "Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f1eeba530be0ac537bcdf633ee6c462045c97fb5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26558": {
    "title": "Unsupervised Paraphrasing under Syntax Knowledge",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f40a60a240b6026266db73a432db2724693c14af",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26559": {
    "title": "Adjective Scale Probe: Can Language Models Encode Formal Semantics Information?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "23073e785f52e6641a89ba15947910870da2b32a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26560": {
    "title": "Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "db28e98d530cb6bd771f71c40a18979bad1d4df1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26561": {
    "title": "Learning Compositional Tasks from Language Instructions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ec5c45b70b136c7b125fa48af6c1bae79327448d",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26562": {
    "title": "SPRING: Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "13579f2d5d522779caeb4aa916fb9ab283f13670",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26563": {
    "title": "Universal Information Extraction as Unified Semantic Matching",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7ccfd5953e75f242536e99cdeda545a3c66ea98f",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26564": {
    "title": "PUnifiedNER: A Prompting-Based Unified NER System for Diverse Datasets",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a1aba65b617ba2c9e82f09f20b04b70e5d60ce31",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26565": {
    "title": "KICE: A Knowledge Consolidation and Expansion Framework for Relation Extraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "31bd0e8883fe9d1a3d28482543d53f7b18077114",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26566": {
    "title": "Zero-Shot Slot Filling with Slot-Prefix Prompting and Attention Relationship Descriptor",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d590e0a539e1392dc4f17ae1327bf021e0c39f58",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26567": {
    "title": "Feature-Level Debiased Natural Language Understanding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c205cea82ec5db88be8f466d5b3823e37cb8f341",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26568": {
    "title": "Graph Component Contrastive Learning for Concept Relatedness Estimation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2adc4f098c27c2a7a1cf43916a6122abcb2908f7",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26569": {
    "title": "HybridPrompt: Bridging Language Models and Human Priors in Prompt Tuning for Visual Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6470a35a46bbc8a844954af9fdf31e440d1aa289",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26570": {
    "title": "Inferential Knowledge-Enhanced Integrated Reasoning for Video Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9b35aca6a0c632bd9e773861b77b01111ea34518",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26571": {
    "title": "AUC Maximization for Low-Resource Named Entity Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "87778991ffea60f1d4e80d726335338270ecc2f6",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26572": {
    "title": "Unveiling the Black Box of PLMs with Semantic Anchors: Towards Interpretable Neural Semantic Parsing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5c4bece777bbc7c52cdd4bbb6e222163f6a580dd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26573": {
    "title": "Towards a Holistic Understanding of Mathematical Questions with Contrastive Pre-training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bde8c53c106c79bb47858b8cff1982a897061cee",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26574": {
    "title": "Improving the Cross-Lingual Generalisation in Visual Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e2c167aeccf14d2bc6b8624f08ff432b000fdc25",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26575": {
    "title": "RWEN-TTS: Relation-Aware Word Encoding Network for Natural Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2fa74769118d2726c2ba2eabf1216d029d178960",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26576": {
    "title": "Hierarchical Event Grounding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ff77105b2c345f54e1a87f4fbb3a701201f0c1a8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26577": {
    "title": "RINK: Reader-Inherited Evidence Reranker for Table-and-Text Open Domain Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ee9d38a3f889c5030209c78b2378d8a17d2b716b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26578": {
    "title": "Relation-Aware Language-Graph Transformer for Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0136f2faaa902082d0e6ad15e5fd14f5842d2b14",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26579": {
    "title": "Multi-Mask Label Mapping for Prompt-Based Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "99dca83345b957ee3eae868570a2ce9af52f729a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26580": {
    "title": "SSMI: Semantic Similarity and Mutual Information Maximization Based Enhancement for Chinese NER",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d75126cf933f80dc46a9e2fe636199817e2d52c1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26581": {
    "title": "Towards Complex Scenarios: Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a4c1e39a7fff8f761a0682320d3e4cf5f3217a02",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26582": {
    "title": "BERT-ERC: Fine-Tuning BERT Is Enough for Emotion Recognition in Conversation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "eecd7b3394fc68901db974a2ff8f950c3a7a7705",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26583": {
    "title": "Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-Grained Student Ensemble",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f305333006fb76fdf2875bd0f6b4a990d9a2028",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26584": {
    "title": "Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "11f734c937b74b4950d67f61ab822c81a3f86ac9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26585": {
    "title": "Prompting Neural Machine Translation with Translation Memories",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "90e0457049d9ff589985312c539b22a97aa04f73",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26586": {
    "title": "Improving Interpretability via Explicit Word Interaction Graph Layer",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f64745927d4a6f048dd0cba8cce7ea8c0055d26c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26587": {
    "title": "Rephrasing the Reference for Non-autoregressive Machine Translation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8671a125e0aa2c1a97ff7940008e47759ec94967",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26588": {
    "title": "Drop Clause: Enhancing Performance, Robustness and Pattern Recognition Capabilities of the Tsetlin Machine",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "558e5ffc1fd2af35d1052e70dbfdb4efab7db5a1",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26589": {
    "title": "CoP: Factual Inconsistency Detection by Controlling the Preference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "34f300edbed4e4cf57d3d9a0499578ce97c5cf00",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26590": {
    "title": "Which Shortcut Solution Do Question Answering Models Prefer to Learn?",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ad7c788824aba70deb141617410dd70b390c4ae8",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26591": {
    "title": "Exploring Faithful Rationale for Multi-Hop Fact Verification via Salience-Aware Graph Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "622ea8252a0c04e91870ed895d34fdc93ac52949",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26592": {
    "title": "A Speaker Turn-Aware Multi-Task Adversarial Network for Joint User Satisfaction Estimation and Sentiment Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cf3b0c1331f4aeb15218c5d55a46655a237afc78",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26593": {
    "title": "A Latent-Variable Model for Intrinsic Probing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4adba678d51bfa5f96b18b7c1fedb7372cf83068",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26594": {
    "title": "Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation via Hybrid Latent Variables",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f157aa29b4363d4ecba0a0afbdf03977a9f62d5",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26595": {
    "title": "ConvNTM: Conversational Neural Topic Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c16cfc3fd993d15d702186c66561a6afbdab170a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26596": {
    "title": "Contrastive Learning Reduces Hallucination in Conversations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d7ea898cc97754e06d209df0fd55ab60250601f2",
    "semantic_title": "",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26597": {
    "title": "Revisiting Denoising Diffusion Probabilistic Models for Speech Enhancement: Condition Collapse, Efficiency and Refinement",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "86acceb40f6fa368eb1c7f765f37f93f6947b9d6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26598": {
    "title": "SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1b4c0a28b0c2a30cc3b84a3222e795c90357bc8a",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26599": {
    "title": "Reducing Sentiment Bias in Pre-trained Sentiment Classification via Adaptive Gumbel Attack",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "45e175a1bde8553b02d1675a3467112c2dcb535f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26600": {
    "title": "Latent Constraints on Unsupervised Text-Graph Alignment with Information Asymmetry",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "322e76e2492dd7e136cf7f101a8992567cec12b3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26601": {
    "title": "M-sense: Modeling Narrative Structure in Short Personal Narratives Using Protagonist's Mental Representations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1d9bcccadf1cfa727125f9e745384311165cf4c9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26602": {
    "title": "Taming Continuous Posteriors for Latent Variational Dialogue Policies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d5ff8d416aa1f7027f494124380e084ecf876e36",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26603": {
    "title": "Uncertainty-Aware Self-Training for Low-Resource Neural Sequence Labeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "317948521f3e8fc5542af8cebdb28df00cc5c8ff",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26604": {
    "title": "Disentangled CVAEs with Contrastive Learning for Explainable Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b826c9318686f6e51a2f25484ea995b709283639",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26605": {
    "title": "fmLRE: A Low-Resource Relation Extraction Model Based on Feature Mapping Similarity Calculation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4eee7b8ccb5ed06a644611a91ba43a0e876086be",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26606": {
    "title": "Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c557ac809df2bf55f3ebc7701ad06af0f6ce15e6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26607": {
    "title": "Zero-Shot Face-Based Voice Conversion: Bottleneck-Free Speech Disentanglement in the Real-World Scenario",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dd923be883e8899eacb92b8b3b9bbb94ec26078a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26608": {
    "title": "Adversarial Self-Attention for Language Understanding",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "924462895c1a380acddbde3c281c8849b458f995",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26609": {
    "title": "See How You Read? Multi-Reading Habits Fusion Reasoning for Multi-Modal Fake News Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6911062acc602db1cc9f318b9407adb4778141d0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26610": {
    "title": "Identify Event Causality with Knowledge and Analogy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1cd83fa10592855f2e6b25f0b9c3fe226546ec0d",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26611": {
    "title": "Continual Graph Convolutional Network for Text Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a637239dc0c2d105c8c3d28ed07579a02aef2a3a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26612": {
    "title": "InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual Topic Modeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "36cfbdd71ca244c27e0be757f53e1696ab35f32e",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26613": {
    "title": "VideoDubber: Machine Translation with Speech-Aware Length Control for Video Dubbing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5a61cdc2fe6c9f6887c4bfc13cce10f8e6a855af",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26614": {
    "title": "Don't Be So Sure! Boosting ASR Decoding via Confidence Relaxation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "17ef526352ef379f8c9365d50e141ef153a49e7d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26615": {
    "title": "AMOM: Adaptive Masking over Masking for Conditional Masked Language Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a8767413d9b969b04c9c440a30f6b7c6a9c4b1bc",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26616": {
    "title": "Global Mixup: Eliminating Ambiguity with Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "38ea7063cf571bf59ab2bceae5865dd3a1499a44",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26617": {
    "title": "MoEC: Mixture of Expert Clusters",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1c1eaea99e0cbbd4616125049bae8c6787bd368c",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26618": {
    "title": "Factual and Informative Review Generation for Explainable Recommendation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "64c4d622b88a88b9f5ab5fdc6cb01f1ce9ccb883",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26619": {
    "title": "Dialogue Rewriting via Skeleton-Guided Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "35e6a386c486f2c57b7f0580b19d03f93c74413b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26620": {
    "title": "Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c4abda222d53e19b381f99e27afce74195d6a6cb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26621": {
    "title": "Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "037f360a564d81015ad2d404a6bb0cd3a1468088",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26622": {
    "title": "Selector-Enhancer: Learning Dynamic Selection of Local and Non-local Attention Operation for Speech Enhancement",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1829c937872bd509b1e2aceaa6c0bb92a9caad6e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26623": {
    "title": "A Graph Fusion Approach for Cross-Lingual Machine Reading Comprehension",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8c36246da412610435d605063885646b279958de",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26624": {
    "title": "Improving Biomedical Entity Linking with Cross-Entity Interaction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "600a811935bedaf25d26b908fa6a79b4c55f1191",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26625": {
    "title": "Nested Named Entity Recognition as Building Local Hypergraphs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d8b8d0109f9b02442b366b10517e99f15e08a277",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26626": {
    "title": "A Domain-Transfer Meta Task Design Paradigm for Few-Shot Slot Tagging",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b4481a16cfac0008e5b12a4e6d375df81d5a9fce",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26627": {
    "title": "Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5d1d01fd199aff94240e7452e25e915cfa7b77e7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26628": {
    "title": "What Does Your Face Sound Like? 3D Face Shape towards Voice",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "16f703e017b3e39c2aa52577a5a1882f68b2c0ef",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26629": {
    "title": "FiTs: Fine-Grained Two-Stage Training for Knowledge-Aware Question Answering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "114655441607fbf58f5b174f2905a006b3853d91",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26630": {
    "title": "On the Calibration and Uncertainty with Pólya-Gamma Augmentation for Dialog Retrieval Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14b47cc6ce6bb154dbe0cf0416cf4e0272c7cd38",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26631": {
    "title": "Preserve Context Information for Extract-Generate Long-Input Summarization Framework",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "51f8bdac8ab7ebeb99106f5e57aa047e82e0e847",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26632": {
    "title": "Transferable Post-hoc Calibration on Pretrained Transformers in Noisy Text Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "688baadc8b1902f524101a2231c6d4b58ee4bfd0",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26633": {
    "title": "Quantum-Inspired Representation for Long-Tail Senses of Word Sense Disambiguation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d704aefcf01d67af12e4281909b71a28f96c0829",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26634": {
    "title": "MPMQA: Multimodal Question Answering on Product Manuals",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5f93d785983a51efe1debf7793b02e27757d1bbd",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26635": {
    "title": "Exploring Self-Distillation Based Relational Reasoning Training for Document-Level Relation Extraction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "77afb7c2279a4a6d162810e863fdddff4c1555a8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26636": {
    "title": "Multi-Action Dialog Policy Learning from Logged User Feedback",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c9a37fb45b73fb167f2b598776b9ba51e1aaea79",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26637": {
    "title": "Improving End-to-End Speech Translation by Leveraging Auxiliary Speech and Text Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7b16564559db7b03051fa7f80ad5669d30e72471",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26638": {
    "title": "A Neural Span-Based Continual Named Entity Recognition Model",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "078de8a6e93c7679fd82bd4527681b2ff1963e25",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26639": {
    "title": "Language Model Pre-training on True Negatives",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e8033d571c2120f59f21b253e54805b5a2c96c63",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26640": {
    "title": "MCL: Multi-Granularity Contrastive Learning Framework for Chinese NER",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "01881c011e7babc706bea37bfaaa1294dbdd77fa",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26641": {
    "title": "Knowledge-Bridged Causal Interaction Network for Causal Emotion Entailment",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "97ba54394f69d5e2157d5c3e2b058cfe7999b3c9",
    "semantic_title": "",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26642": {
    "title": "Query Your Model with Definitions in FrameNet: An Effective Method for Frame Semantic Role Labeling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0ef797cae9ae6eb1e49b10cab8ccabd2b09d276c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26643": {
    "title": "Event Process Typing via Hierarchical Optimal Transport",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "77b8299c9455829db7f37116933e448255bd72d7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26644": {
    "title": "Improving Distantly Supervised Relation Extraction by Natural Language Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dc7a97da9d46e3f4a087ce404a19b8af03109bde",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26645": {
    "title": "A Generative Approach for Script Event Prediction via Contrastive Fine-Tuning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2a34d4e279e8da66a5600b1943de07ac5ddee402",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26646": {
    "title": "KPT: Keyword-Guided Pre-training for Grounded Dialog Generation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ef52ba73fbf41eed320a479f5736e127d3a06049",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26647": {
    "title": "An Ensemble Distillation Framework for Sentence Embeddings with Multilingual Round-Trip Translation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "32eca437ef020e692d93cdf3727e7158277ec395",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26648": {
    "title": "COSMOS: Catching Out-of-Context Image Misuse Using Self-Supervised Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4110d8119a2f38c610cc8e608f7e8a7fe51ae8eb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26649": {
    "title": "Med-EASi: Finely Annotated Dataset and Models for Controllable Simplification of Medical Texts",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "5584cfacf5f88efe5237b0478cb38f5b37f14458",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26650": {
    "title": "On the Challenges of Using Reinforcement Learning in Precision Drug Dosing: Delay and Prolongedness of Action Effects",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c2bd228ae10af1091cd8411ed121d723f8993a18",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26651": {
    "title": "On the Cost of Demographic Parity in Influence Maximization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "48b300c70b9f384b38044b52cf03ca587d21c0a7",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26652": {
    "title": "Improving Fairness in Information Exposure by Adding Links",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "487c75c2af91361706231b156baeca844643cdc3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26653": {
    "title": "A Fair Incentive Scheme for Community Health Workers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4eeea5d32ce847d0e36e1ccb4de7dce6036128e3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26654": {
    "title": "Rehabilitating Homeless: Dataset and Key Insights",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0ef9eca54f39083bec6ca92f6d4b42db8f122fb3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26655": {
    "title": "Counterfactuals for the Future",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7657eb913f77e3d95f2ebcd5f8e55d77f856064a",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26656": {
    "title": "Towards Learning to Discover Money Laundering Sub-network in Massive Transaction Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d19060b433e298d126ec287b372d4bb6a14043da",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26657": {
    "title": "Estimating Geographic Spillover Effects of COVID-19 Policies from Large-Scale Mobility Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f4586e3dbd70218af8ef421fa9d4ebbf9aa0bd04",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26658": {
    "title": "Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a0f6868dd37a44a952708f8171f9aee1d9be4c84",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26659": {
    "title": "Leveraging Old Knowledge to Continually Learn New Classes in Medical Images",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e2b1cd2aab7a939b90292f442bb1d0b15eeef357",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26660": {
    "title": "SARAS-Net: Scale and Relation Aware Siamese Network for Change Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "62a2cf6baa5a19a618bfd7f1be9b15c6319167ff",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26661": {
    "title": "Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "31373d8d0718050fc6f589070ba083726759da8d",
    "semantic_title": "",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26662": {
    "title": "Critical Firms Prediction for Stemming Contagion Risk in Networked-Loans through Graph-Based Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98feed9365d4449711c71130cc1e1549b3a5aa12",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26663": {
    "title": "GAN-Based Domain Inference Attack",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d9875feb6292f3c38a94b45c7037fc76ed8a11f6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26664": {
    "title": "Physics Guided Neural Networks for Time-Aware Fairness: An Application in Crop Yield Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2e698a17e4f40caa6558adb8d55c06f738acab95",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26665": {
    "title": "Nothing Abnormal\": Disambiguating Medical Reports via Contrastive Knowledge Infusion",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "be641c0c6c8f83c84963e1254b2eda74e6a29d3f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26666": {
    "title": "MTDiag: An Effective Multi-Task Framework for Automatic Diagnosis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1082d010b8011fde2156945861ca9e454d2c7a7b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26667": {
    "title": "Walkability Optimization: Formulations, Algorithms, and a Case Study of Toronto",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "93472ae4c136f940e6cb9910e67782f88ad4b057",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26668": {
    "title": "Low Emission Building Control with Zero-Shot Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "141fa4c44a663705a483c0ee877e52d5158bdc93",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26669": {
    "title": "Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1aa02bc5585a2c52e2643bf8be714e98a2e7a852",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26670": {
    "title": "Taxonomizing and Measuring Representational Harms: A Look at Image Tagging",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "56dc4105b113a48405604bb63e4ee42080e50bdd",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26671": {
    "title": "Winning the CityLearn Challenge: Adaptive Optimization with Evolutionary Search under Trajectory-Based Guidance",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "20f4c75e9d2bd0e6c31a374b2224f175f115eb59",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26672": {
    "title": "Robust Planning over Restless Groups: Engagement Interventions for a Large-Scale Maternal Telehealth Program",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d3c81daa02b979f13e61249bdbf41f0607ed61fa",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26673": {
    "title": "Equivariant Message Passing Neural Network for Crystal Material Discovery",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1c8fc598455b8e4f7017849e4c7c7741f9b91df9",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26674": {
    "title": "Accurate Fairness: Improving Individual Fairness without Trading Accuracy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b1221518c79c1f04c15393e3591639485e8a5852",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26675": {
    "title": "Point-to-Region Co-learning for Poverty Mapping at High Resolution Using Satellite Imagery",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "520a77e2dd848f56c7a7c40789c8d84a760ca1bd",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26676": {
    "title": "AirFormer: Predicting Nationwide Air Quality in China with Transformers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3253a37dd7b6ebfbe22f22ad4bedc07b4b5b0f29",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26677": {
    "title": "SimFair: A Unified Framework for Fairness-Aware Multi-Label Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7ccc297b2741090f30626e42a5d692029a764be6",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26678": {
    "title": "Human Mobility Modeling during the COVID-19 Pandemic via Deep Graph Diffusion Infomax",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "c56100ffa07b5a6a4ef58d796a6f915149821de5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26679": {
    "title": "Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "580f78af4bc37d28cbe4faaf4fc25d83b8bc8286",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26680": {
    "title": "Task-Adaptive Meta-Learning Framework for Advancing Spatial Generalizability",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1140878a116edb1cacc844e97853f4431203541e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26681": {
    "title": "A Composite Multi-Attention Framework for Intraoperative Hypotension Early Warning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7e270239bda02a2355367df7f02deafb96920c54",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26682": {
    "title": "Bugs in the Data: How ImageNet Misrepresents Biodiversity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cc6d0b1d0a11071034b2ab8b9a778f41c51a2e89",
    "semantic_title": "",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26683": {
    "title": "LUCID: Exposing Algorithmic Bias through Inverse Design",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ac886d6ccddcd3846f2e8ba59b9fc128013156ac",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26684": {
    "title": "Neighbor Auto-Grouping Graph Neural Networks for Handover Parameter Configuration in Cellular Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f680a111ecba951a08a03fa1ba3a46ab5c23c99e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26685": {
    "title": "Help Me Heal: A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc79ac3d5e1c05fbf0a4f165b8841defe6592417",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26686": {
    "title": "Carburacy: Summarization Models Tuning and Comparison in Eco-Sustainable Regimes with a Novel Carbon-Aware Accuracy",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4a8c10a38eb92267a30c9472a17409a57ba050ec",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26687": {
    "title": "Joint Self-Supervised Image-Volume Representation Learning with Intra-inter Contrastive Clustering",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "37ad559f8a5cdd982b7b7c196e82b02f7f51501a",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26688": {
    "title": "For the Underrepresented in Gender Bias Research: Chinese Name Gender Prediction with Heterogeneous Graph Attention Network",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0d4dea3b2540623a55a24201fe22738b852b42fe",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26689": {
    "title": "FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News Detection on Short Video Platforms",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "569d56db5a41bec03e810e71baa7f1c6c9daaebc",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26690": {
    "title": "EINNs: Epidemiologically-Informed Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "46c08e7571af2e9c160d76e9140510706dbc2589",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26691": {
    "title": "Counterfactual Fairness Is Basically Demographic Parity",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "564c0f5dda77fd8a6a9cd41a0ec88989d92181ad",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26692": {
    "title": "Detecting Anomalous Networks of Opioid Prescribers and Dispensers in Prescription Drug Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4cc0e3c82690b276f39826fbd6cf436d04e2c5ad",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26693": {
    "title": "Practical Disruption of Image Translation Deepfake Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8a570041fb80b01d0684e84c39c04434dc25a506",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26694": {
    "title": "Daycare Matching in Japan: Transfers and Siblings",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9272afcfbccd18c4ffca522ccee41fd691cf49ba",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26695": {
    "title": "City-Scale Pollution Aware Traffic Routing by Sampling Max Flows Using MCMC",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2800e4820ee12255799c77f1b0bbc957e79e10c9",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26696": {
    "title": "Weather2vec: Representation Learning for Causal Inference with Non-local Confounding in Air Pollution and Climate Studies",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "4a76c4b5591dcee0a2170ac12e0d5ad813beb713",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26697": {
    "title": "Evaluating Digital Agriculture Recommendations with Causal Inference",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fc28e7b6122f1ffec1078fec12734bbcefac1b19",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26698": {
    "title": "Everyone's Voice Matters: Quantifying Annotation Disagreement Using Demographic Information",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "dd9f31e29b2ec771f4b73bf3e09e4ddefb450559",
    "semantic_title": "",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26699": {
    "title": "MixFairFace: Towards Ultimate Fairness via MixFair Adapter in Face Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7915a4fafae62df0b3d2a84d2b0fe6357c10a996",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26700": {
    "title": "PateGail: A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "78aadaf3c191bbc63f97c238853b0d878b32a99f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26701": {
    "title": "Noise Based Deepfake Detection via Multi-Head Relative-Interaction",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b2c2d4b4f0ca78f58247944b1e808ba0d4197e5d",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26702": {
    "title": "Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "05b151d453012b0e2af34d36e0c6b6c57589a01f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26703": {
    "title": "Privacy-Preserved Evolutionary Graph Modeling via Gromov-Wasserstein Autoregression",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7918cfcee1fdca473d2b3e5bb47ead4ab3d10b00",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26704": {
    "title": "Auto-CM: Unsupervised Deep Learning for Satellite Imagery Composition and Cloud Masking Using Spatio-Temporal Dynamics",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "ce11f46a1d3262628578525f7597687afc115d32",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26705": {
    "title": "ERASER: AdvERsArial Sensitive Element Remover for Image Privacy Preservation",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "14bce1bc4fa59c0584a4ca10d10ce9df337426fb",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26706": {
    "title": "Deep Learning on a Healthy Data Diet: Finding Important Examples for Fairness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a45ff2a8b18abc850b267cf0ec6e391dba9138a5",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26707": {
    "title": "On the Effectiveness of Curriculum Learning in Educational Text Scoring",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aa394cd41651027edd70bdd1f7f909e648bc5a2e",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26708": {
    "title": "Censored Fairness through Awareness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "1c8f9a06fd998a582e95d3ff2d237b9c322c1851",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26709": {
    "title": "A Continual Pre-training Approach to Tele-Triaging Pregnant Women in Kenya",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "42aa79b825616927348b03fab5eb33a38750ab44",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26710": {
    "title": "Future Aware Pricing and Matching for Sustainable On-Demand Ride Pooling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "131b6d02fa5080e322e83023c1d772738e82e5cf",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26711": {
    "title": "A Crowd-AI Collaborative Duo Relational Graph Learning Framework towards Social Impact Aware Photo Classification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fa8762d3e3811563a948096967fccbf3e7392a87",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26712": {
    "title": "People Taking Photos That Faces Never Share: Privacy Protection and Fairness Enhancement from Camera to User",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "57ff9d8e827c726659750509157f220478030e86",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26713": {
    "title": "OpenMapFlow: A Library for Rapid Map Creation with Machine Learning and Remote Sensing Data",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b6b328d3ba12aea981cea10c059ae92c0cba936e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26714": {
    "title": "Formally Verified SAT-Based AI Planning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "3e95e6ef0aa1ce98c38715ddbe7b8a3d838b844d",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26715": {
    "title": "Shielding in Resource-Constrained Goal POMDPs",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6745cb3cf6b32aae0ab906c15677726988fc03c3",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26716": {
    "title": "Implicit Bilevel Optimization: Differentiating through Bilevel Optimization Programming",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "482b6ff532ba5466fbc42faea4a2840b4c425539",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26717": {
    "title": "Query-Based Hard-Image Retrieval for Object Detection at Test Time",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2a51f94fe7750a010f2e86e2936eca3cbde51796",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26718": {
    "title": "Probabilities Are Not Enough: Formal Controller Synthesis for Stochastic Dynamical Models with Epistemic Uncertainty",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9342c9886030283ca507c7a34a03ae5b57537994",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26719": {
    "title": "Accelerating Inverse Learning via Intelligent Localization with Exploratory Sampling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "123c93e88781f2602e8558b87e80c88c4b3ab529",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26720": {
    "title": "Attention-Conditioned Augmentations for Self-Supervised Anomaly Detection and Localization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fd6ca61726bc0598d25e3edd4ac98c013deebcb7",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26721": {
    "title": "Robust-by-Design Classification via Unitary-Gradient Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "416be43f270134a37dc2d42ccc469737e5780eb1",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26722": {
    "title": "Ensemble-in-One: Ensemble Learning within Random Gated Networks for Enhanced Adversarial Robustness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fe531d5918d3cc1b3ef950d154017b8c8f3f408f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26723": {
    "title": "Safe Reinforcement Learning via Shielding under Partial Observability",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2eced32191850ddfbdbc4ef9e2a8059e99e7f84a",
    "semantic_title": "",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26724": {
    "title": "PowRL: A Reinforcement Learning Framework for Robust Management of Power Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9eca0adbd644755d07ee1f503f7324c29d0ec907",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26725": {
    "title": "Two Wrongs Don't Make a Right: Combating Confirmation Bias in Learning with Label Noise",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0db4dba94d9412d3202afe2dbd76b74b50303831",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26726": {
    "title": "Testing the Channels of Convolutional Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "163e075f1a0ab9545269e5d5b8f4a1e6183303b3",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26727": {
    "title": "Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "6eaa3bbf5e36e2ac3ff1ba3dc564653c8d066744",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26728": {
    "title": "Correct-by-Construction Reinforcement Learning of Cardiac Pacemakers from Duration Calculus Requirements",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aa4a1a758e4e15eef46c5009c75092b1ba7a39b2",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26729": {
    "title": "SafeLight: A Reinforcement Learning Method toward Collision-Free Traffic Signal Control",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9683ac196f269461cd9a1018dfbf613ca336ca5a",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26730": {
    "title": "PatchNAS: Repairing DNNs in Deployment with Patched Network Architecture Search",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9a5247c8fb2d55d202489e38fe85abcceb433153",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26731": {
    "title": "Similarity Distribution Based Membership Inference Attack on Person Re-identification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "748e1978a9a9d940ae30a108f5824ab25071b664",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26732": {
    "title": "Out-of-Distribution Detection Is Not All You Need",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26733": {
    "title": "Contrastive Self-Supervised Learning Leads to Higher Adversarial Susceptibility",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "91fa90034eb88bc31c46d4e4fa242c3b3c16b2f1",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26734": {
    "title": "AutoCost: Evolving Intrinsic Cost for Zero-Violation Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b65e9e7f500437a01848ac6fde6692e6b241de85",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26735": {
    "title": "Test Time Augmentation Meets Post-hoc Calibration: Uncertainty Quantification under Real-World Conditions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "85d4f8c0e580f7cdacae5419eb58d4679787f830",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26736": {
    "title": "Robust Training of Neural Networks against Bias Field Perturbations",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b9f72ff47451132613e719ef7f08e414c786be79",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26737": {
    "title": "Redactor: A Data-Centric and Individualized Defense against Inference Attacks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8ef83ee73085e3db4914912fe8d5c483634cc063",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26738": {
    "title": "Improving Adversarial Robustness with Self-Paced Hard-Class Pair Reweighting",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "cdff55a9ffadc668dd5abdfbdb35f0280e1447e9",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26739": {
    "title": "CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming Language Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d18287d5ef8653aa1276a11957f2b3934c7c93e1",
    "semantic_title": "",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26740": {
    "title": "Formalising the Robustness of Counterfactual Explanations for Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a7e57f485f2dfe7d1a599cf976b2a7caaa424f2f",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26741": {
    "title": "READ: Aggregating Reconstruction Error into Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9669a87028cef17a9e5d30991502eae5f8179291",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26742": {
    "title": "Sample-Dependent Adaptive Temperature Scaling for Improved Calibration",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "63916bb5363d37b9a3adfd1a56dee3710190fce1",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26743": {
    "title": "Heuristic Search in Dual Space for Constrained Fixed-Horizon POMDPs with Durative Actions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "faec5b3e8650bdd2f4dbc5b2ad7385ae3907ec3f",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26744": {
    "title": "Iteratively Enhanced Semidefinite Relaxations for Efficient Neural Network Verification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "3c906f453942ece03d97c598d6b2d312a9e7ff2e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26745": {
    "title": "A Semidefinite Relaxation Based Branch-and-Bound Method for Tight Neural Network Verification",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "621bba60ab56347038696b287b21c2bd8132b16b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26746": {
    "title": "Robust Image Steganography: Hiding Messages in Frequency Coefficients",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a5d92ccf035048dd8260f6d1dea216c9115eb841",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26747": {
    "title": "Quantization-Aware Interval Bound Propagation for Training Certifiably Robust Quantized Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "54957e64705af01b3490ea0c84383fa2500e0f2b",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26748": {
    "title": "Revisiting the Importance of Amplifying Bias for Debiasing",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "76a4272b3008ebeb66631681da2a6b9f77d0b6c8",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26749": {
    "title": "WAT: Improve the Worst-Class Robustness in Adversarial Training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a9a0b9be86acb372d78f349b84a7f21fa2f53919",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26750": {
    "title": "PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "33a555467eda19fa2a8661c268b0bbab0eb69831",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26751": {
    "title": "Rethinking Label Refurbishment: Model Robustness under Label Noise",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "35b2f215847a2773f1dc1f232d2fd91f63d8354c",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26752": {
    "title": "A Holistic Approach to Undesired Content Detection in the Real World",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b69aa32ee52f5efe8e3196114581ac610da8a2b2",
    "semantic_title": "",
    "citation_count": 26
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26753": {
    "title": "A Risk-Sensitive Approach to Policy Optimization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d37ca9aa15d6f34d942180752552132c51fe27e5",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26754": {
    "title": "Anonymization for Skeleton Action Recognition",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "8035ac46f303e67b47aeb4a44ef52ad049481f7e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26755": {
    "title": "Monitoring Model Deterioration with Explainable Uncertainty Estimation via Non-parametric Bootstrap",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "42de5c885c5774839b3f08e0b0c528bc186f880f",
    "semantic_title": "",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26756": {
    "title": "Certified Policy Smoothing for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "11ed9f34b8f733ab17bf6fd8aa3686253a1d35be",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26757": {
    "title": "Constrained Reinforcement Learning in Hard Exploration Problems",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bc5bd7449e6a8c03e10c433dd65dfeee08262041",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26758": {
    "title": "Defending from Physically-Realizable Adversarial Attacks through Internal Over-Activation Analysis",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "b2c47f408cd89f1d97f57164e62ae43f245ec9ac",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26759": {
    "title": "Formally Verified Solution Methods for Markov Decision Processes",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "9fa16e38d704423feb31b35e4cd63f82d8806153",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26760": {
    "title": "Improving Training and Inference of Face Recognition Models via Random Temperature Scaling",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "98548a4f6f443cf2d7b13608941963caaaa0c352",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26761": {
    "title": "Task and Model Agnostic Adversarial Attack on Graph Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "a0755a1dc1fd8314fa3c669e54edbf1adc2f1b68",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26762": {
    "title": "Robust Sequence Networked Submodular Maximization",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0273024ab212b2fe1538b300f6ba1a424a58b52e",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26763": {
    "title": "Safe Policy Improvement for POMDPs via Finite-State Controllers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "f738aff510123771161ac0f38b218f51ac9eb7a0",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26764": {
    "title": "STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "0aec8ed21d4b34112679a39d7070f4503d61b9d8",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26765": {
    "title": "Understanding and Enhancing Robustness of Concept-Based Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "e63b3f2ac5eee86c10e2265b483957dc27d970ee",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26766": {
    "title": "Misspecification in Inverse Reinforcement Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "aae382fe95b061018f214b1f101c55b6f4ae176b",
    "semantic_title": "",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26767": {
    "title": "Planning and Learning for Non-markovian Negative Side Effects Using Finite State Controllers",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "95bbfe4bf3d83dd364ee07e6f5d65262107436c6",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26768": {
    "title": "Toward Robust Uncertainty Estimation with Random Activation Functions",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "bb1d563d52722cd148c91e24bc218bccd65ef13a",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26769": {
    "title": "Improving Robust Fariness via Balance Adversarial Training",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "a1b66604fc3464ad4041480ac93a3a40f3fff71e",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26770": {
    "title": "DPAUC: Differentially Private AUC Computation in Federated Learning",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "7db4c1b880da98466ea118af5c81d6c3d68e4986",
    "semantic_title": "",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26771": {
    "title": "Conflicting Interactions among Protection Mechanisms for Machine Learning Models",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": false,
    "id": "0e5eabc075d569ba56661efcaa913ed0023daba8",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26772": {
    "title": "Neural Policy Safety Verification via Predicate Abstraction: CEGAR",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "d5f5a9f535d80c57e75539720750faab6c779f37",
    "semantic_title": "",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26773": {
    "title": "Towards Verifying the Geometric Robustness of Large-Scale Neural Networks",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "49063a59bf80d92ecc4b58f0e44e824affe4d734",
    "semantic_title": "",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26774": {
    "title": "Revisiting Item Promotion in GNN-Based Collaborative Filtering: A Masked Targeted Topological Attack Perspective",
    "volume": "main",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "checked": true,
    "id": "fe9af9c40ff93ffbc9536964e209bf2080d241b1",
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26775": {
    "title": "Robust Average-Reward Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26776": {
    "title": "Robust Graph Meta-Learning via Manifold Calibration with Proxy Subgraphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26777": {
    "title": "HOTCOLD Block: Fooling Thermal Infrared Detectors with a Novel Wearable Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26778": {
    "title": "Beyond NaN: Resiliency of Optimization Layers in the Face of Infeasibility",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26779": {
    "title": "DeepGemini: Verifying Dependency Fairness for Deep Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26780": {
    "title": "Auditing and Robustifying COVID-19 Misinformation Datasets via Anticontent Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26781": {
    "title": "User-Oriented Robust Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26782": {
    "title": "Safety Verification of Nonlinear Systems with Bayesian Neural Network Controllers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26783": {
    "title": "Reachability Analysis of Neural Network Control Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26784": {
    "title": "BIFRNet: A Brain-Inspired Feature Restoration DNN for Partially Occluded Image Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26785": {
    "title": "Robustness to Spurious Correlations Improves Semantic Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26786": {
    "title": "Evaluating Model-Free Reinforcement Learning toward Safety-Critical Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26787": {
    "title": "Video-Audio Domain Generalization via Confounder Disentanglement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26788": {
    "title": "Rethinking Safe Control in the Presence of Self-Seeking Humans",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26789": {
    "title": "Towards Safe AI: Sandboxing DNNs-Based Controllers in Stochastic Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26790": {
    "title": "Probabilistic Programs as an Action Description Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26791": {
    "title": "Foundations of Cooperative AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26792": {
    "title": "Multimodal Propaganda Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26793": {
    "title": "Foundation Model for Material Science",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26794": {
    "title": "QA Is the New KR: Question-Answer Pairs as Knowledge Bases",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26795": {
    "title": "Customer Service Combining Human Operators and Virtual Agents: A Call for Multidisciplinary AI Research",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26796": {
    "title": "The Many Faces of Adversarial Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26797": {
    "title": "Holistic Adversarial Robustness of Deep Learning Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26798": {
    "title": "Can We Trust Fair-AI?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26799": {
    "title": "Safety Validation of Learning-Based Autonomous Systems: A Multi-Fidelity Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26800": {
    "title": "Probabilistic Reasoning and Learning for Trustworthy AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26801": {
    "title": "The Automatic Computer Scientist",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26802": {
    "title": "Perception for General-purpose Robot Manipulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26803": {
    "title": "Cooperative Multi-Agent Learning in a Complex World: Challenges and Solutions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26804": {
    "title": "Distributed Stochastic Nested Optimization for Emerging Machine Learning Models: Algorithm and Theory",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26805": {
    "title": "Targeted Knowledge Infusion To Make Conversational AI Explainable and Safe",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26806": {
    "title": "Accountability Layers: Explaining Complex System Failures by Parts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26807": {
    "title": "Generative Decision Making Under Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26808": {
    "title": "Food Information Engineering: A Systematic Literature Review",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26809": {
    "title": "Better Environments for Better AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26810": {
    "title": "Recent Developments in Data-Driven Algorithms for Discrete Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26811": {
    "title": "Advances in AI for Safety, Equity, and Well-Being on Web and Social Media: Detection, Robustness, Attribution, and Mitigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26812": {
    "title": "Intelligent Planning for Large-Scale Multi-Robot Coordination",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26813": {
    "title": "Robust and Adaptive Deep Learning via Bayesian Principles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26814": {
    "title": "AAAI New Faculty Highlights: General and Scalable Optimization for Robust AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26815": {
    "title": "Combining Runtime Monitoring and Machine Learning with Human Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26816": {
    "title": "Towards Safe and Resilient Autonomy in Multi-Robot Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26817": {
    "title": "Monitoring and Intervening on Large Populations of Weakly Coupled Processes with Social Impact Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26818": {
    "title": "Internal Robust Representations for Domain Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26819": {
    "title": "Planning and Learning for Reliable Autonomy in the Open World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26820": {
    "title": "Dynamics of Cooperation and Conflict in Multiagent Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26821": {
    "title": "Combating Disinformation on Social Media and Its Challenges: A Computational Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26822": {
    "title": "Human-Aware AI – A Foundational Framework for Human-AI Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26823": {
    "title": "Towards Unified, Explainable, and Robust Multisensory Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26824": {
    "title": "Reshaping State-Space Search: From Dominance to Contrastive Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26825": {
    "title": "Artificial Intelligence at the Service of Society to Analyse Human Arguments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26826": {
    "title": "AI for Equitable, Data-Driven Decisions in Public Health",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26827": {
    "title": "Learning to See the Physical World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26828": {
    "title": "Enhance Robustness of Machine Learning with Improved Efficiency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26829": {
    "title": "The Analysis of Deep Neural Networks by Information Theory: From Explainability to Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26830": {
    "title": "Towards Societal Impact of AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26831": {
    "title": "Information Transfer in Multitask Learning, Data Augmentation, and Beyond",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26832": {
    "title": "A New Challenge in Policy Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26833": {
    "title": "Building Compositional Robot Autonomy with Modularity and Abstraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26834": {
    "title": "Accurate Detection of Weld Seams for Laser Welding in Real-World Manufacturing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26835": {
    "title": "Blending Advertising with Organic Content in E-commerce via Virtual Bids",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26836": {
    "title": "Efficient Training of Large-Scale Industrial Fault Diagnostic Models through Federated Opportunistic Block Dropout",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26837": {
    "title": "AmnioML: Amniotic Fluid Segmentation and Volume Prediction with Uncertainty Quantification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26838": {
    "title": "A Robust and Scalable Stacked Ensemble for Day-Ahead Forecasting of Distribution Network Losses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26839": {
    "title": "Developing the Wheel Image Similarity Application with Deep Metric Learning: Hyundai Motor Company Case",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26841": {
    "title": "NewsPanda: Media Monitoring for Timely Conservation Action",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26842": {
    "title": "Trustworthy Residual Vehicle Value Prediction for Auto Finance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26843": {
    "title": "A Dataset and Baseline Approach for Identifying Usage States from Non-intrusive Power Sensing with MiDAS IoT-Based Sensors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26844": {
    "title": "Real-Time Detection of Robotic Traffic in Online Advertising",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26845": {
    "title": "Dynamic Pricing with Volume Discounts in Online Settings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26846": {
    "title": "An Explainable Forecasting System for Humanitarian Needs Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26847": {
    "title": "Industry-Scale Orchestrated Federated Learning for Drug Discovery",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26848": {
    "title": "THMA: Tencent HD Map AI System for Creating HD Map Annotations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26849": {
    "title": "Increasing Impact of Mobile Health Programs: SAHELI for Maternal and Child Care",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26850": {
    "title": "MuMIC – Multimodal Embedding for Multi-Label Image Classification with Tempered Sigmoid",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26852": {
    "title": "AHPA: Adaptive Horizontal Pod Autoscaling Systems on Alibaba Cloud Container Service for Kubernetes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26853": {
    "title": "eForecaster: Unifying Electricity Forecasting with Robust, Flexible, and Explainable Machine Learning Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26854": {
    "title": "Cosmic Microwave Background Recovery: A Graph-Based Bayesian Convolutional Network Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26855": {
    "title": "Phase-Informed Bayesian Ensemble Models Improve Performance of COVID-19 Forecasts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26856": {
    "title": "Towards Hybrid Automation by Bootstrapping Conversational Interfaces for IT Operation Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26857": {
    "title": "Compressing Cross-Lingual Multi-Task Models at Qualtrics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26858": {
    "title": "SolderNet: Towards Trustworthy Visual Inspection of Solder Joints in Electronics Manufacturing Using Explainable Artificial Intelligence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26859": {
    "title": "MobilePTX: Sparse Coding for Pneumothorax Detection Given Limited Training Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26860": {
    "title": "Vessel-to-Vessel Motion Compensation with Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26840": {
    "title": "Detecting VoIP Data Streams: Approaches Using Hidden Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26861": {
    "title": "Intuitive Access to Smartphone Settings Using Relevance Model Trained by Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26862": {
    "title": "Towards Safe Mechanical Ventilation Treatment Using Deep Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26863": {
    "title": "Data-Driven Machine Learning Models for a Multi-Objective Flapping Fin Unmanned Underwater Vehicle Control System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26864": {
    "title": "AnimateSVG: Autonomous Creation and Aesthetics Evaluation of Scalable Vector Graphics Animations for the Case of Brand Logos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26865": {
    "title": "Grape Cold Hardiness Prediction via Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26866": {
    "title": "Reward Design for an Online Reinforcement Learning Algorithm Supporting Oral Self-Care",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26867": {
    "title": "Embedding a Long Short-Term Memory Network in a Constraint Programming Framework for Tomato Greenhouse Optimisation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26868": {
    "title": "Fault Injection Based Interventional Causal Learning for Distributed Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26869": {
    "title": "High-Throughput, High-Performance Deep Learning-Driven Light Guide Plate Surface Visual Quality Inspection Tailored for Real-World Manufacturing Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26870": {
    "title": "End-to-End Pipeline for Trigger Detection on Hit and Track Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26851": {
    "title": "OPRADI: Applying Security Game to Fight Drive under the Influence in Real-World",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26871": {
    "title": "Xaitk-Saliency: An Open Source Explainable AI Toolkit for Saliency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26872": {
    "title": "DetAIL: A Tool to Automatically Detect and Analyze Drift in Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26873": {
    "title": "PARCS: A Deployment-Oriented AI System for Robust Parcel-Level Cropland Segmentation of Satellite Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26874": {
    "title": "Adaptive Temporal Planning for Multi-Robot Systems in Operations and Maintenance of Offshore Wind Farms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26875": {
    "title": "A Study of Students' Learning of Computing through an LP-Based Integrated Curriculum for Middle Schools",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26876": {
    "title": "AI and Parallelism in CS1: Experiences and Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26877": {
    "title": "Shared Tasks as Tutorials: A Methodical Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26878": {
    "title": "Maestro: A Gamified Platform for Teaching AI Robustness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26879": {
    "title": "Exploring Social Biases of Large Language Models in a College Artificial Intelligence Course",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26880": {
    "title": "An Analysis of Engineering Students' Responses to an AI Ethics Scenario",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26881": {
    "title": "Autonomous Agents: An Advanced Course on AI Integration and Deployment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26882": {
    "title": "AI Made by Youth: A Conversational AI Curriculum for Middle School Summer Camps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26883": {
    "title": "Learning Affects Trust: Design Recommendations and Concepts for Teaching Children—and Nearly Anyone—about Conversational Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26884": {
    "title": "FOLL-E: Teaching First Order Logic to Children",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26885": {
    "title": "Responsible Robotics: A Socio-Ethical Addition to Robotics Courses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26886": {
    "title": "Data Labeling for Machine Learning Engineers: Project-Based Curriculum and Data-Centric Competitions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26887": {
    "title": "Does Knowing When Help Is Needed Improve Subgoal Hint Performance in an Intelligent Data-Driven Logic Tutor?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26888": {
    "title": "Ripple: Concept-Based Interpretation for Raw Time Series Models in Education",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26889": {
    "title": "Exploring Tradeoffs in Automated School Redistricting: Computational and Ethical Perspectives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27091": {
    "title": "A Dataset for Learning University STEM Courses at Scale and Generating Questions at a Human Level",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26891": {
    "title": "Learning Logical Reasoning Using an Intelligent Tutoring System: A Hybrid Approach to Student Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26892": {
    "title": "Context-Aware Analysis of Group Submissions for Group Anomaly Detection and Performance Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26893": {
    "title": "CLGT: A Graph Transformer for Student Performance Prediction in Collaborative Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26894": {
    "title": "H-AES: Towards Automated Essay Scoring for Hindi",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26895": {
    "title": "Detecting Exclusive Language during Pair Programming",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26896": {
    "title": "Solving Math Word Problems concerning Systems of Equations with GPT-3",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26897": {
    "title": "AI Audit: A Card Game to Reflect on Everyday AI Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26898": {
    "title": "Beyond Black-Boxes: Teaching Complex Machine Learning Ideas through Scaffolded Interactive Activities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26899": {
    "title": "Exploring Artificial Intelligence in English Language Arts with StoryQ",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26900": {
    "title": "An Introduction to Rule-Based Feature and Object Perception for Middle School Students",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26901": {
    "title": "Scratch for Sports: Athletic Drills as a Platform for Experiencing, Understanding, and Developing AI-Driven Apps",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26902": {
    "title": "How Can I Code A.I. Responsibly?\": The Effect of Computational Action on K-12 Students Learning and Creating Socially Responsible A.I",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26903": {
    "title": "Build-a-Bot: Teaching Conversational AI Using a Transformer-Based Intent Recognition and Question Answering Architecture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26904": {
    "title": "Develop AI Teaching and Learning Resources for Compulsory Education in China",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26905": {
    "title": "Guiding Students to Investigate What Google Speech Recognition Knows about Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26906": {
    "title": "Literacy and STEM Teachers Adapt AI Ethics Curriculum",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26907": {
    "title": "MoMusic: A Motion-Driven Human-AI Collaborative Music Composition and Performing System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26908": {
    "title": "A Multi-User Virtual World with Music Recommendations and Mood-Based Virtual Effects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26909": {
    "title": "Learning Adaptive Game Soundtrack Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26910": {
    "title": "Predicting Perceived Music Emotions with Respect to Instrument Combinations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26911": {
    "title": "Emotion-Aware Music Recommendation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26912": {
    "title": "Music-to-Facial Expressions: Emotion-Based Music Visualization for the Hearing Impaired",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26913": {
    "title": "Model AI Assignments 2023",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26914": {
    "title": "Probabilistic Shape Models of Anatomy Directly from Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26915": {
    "title": "Modeling Strategies as Programs: How to Study Strategy Differences in Intelligent Systems with Program Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26916": {
    "title": "Non-exponential Reward Discounting in Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26917": {
    "title": "Enhancing Smart, Sustainable Mobility with Game Theory and Multi-Agent Reinforcement Learning With Applications to Ridesharing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26918": {
    "title": "Assessing Learned Representations under Open-World Novelty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26919": {
    "title": "Efficient Non-parametric Neural Density Estimation and Its Application to Outlier and Anomaly Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26920": {
    "title": "Explaining the Uncertainty in AI-Assisted Decision Making",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26921": {
    "title": "Poisoning-Based Backdoor Attacks in Computer Vision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26922": {
    "title": "Safe Interactive Autonomy for Multi-Agent Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26923": {
    "title": "Theory of Mind: A Familiar Aspect of Humanity to Give Machines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26924": {
    "title": "Multimodal Deep Generative Models for Remote Medical Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26925": {
    "title": "Topics in Selective Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26926": {
    "title": "Knowledge-Embedded Narrative Construction from Open Source Intelligence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26927": {
    "title": "Learning Better Representations Using Auxiliary Knowledge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26928": {
    "title": "Embodied, Intelligent Communication for Multi-Agent Cooperation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26929": {
    "title": "Meta Learning in Decentralized Neural Networks: Towards More General AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26930": {
    "title": "Learning and Planning under Uncertainty for Conservation Decisions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26931": {
    "title": "Failure-Resistant Intelligent Interaction for Reliable Human-AI Collaboration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26932": {
    "title": "Privacy-Preserving Representation Learning for Text-Attributed Networks with Simplicial Complexes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26933": {
    "title": "Deep Learning for Medical Prediction in Electronic Health Records",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26934": {
    "title": "Efficient Algorithms for Regret Minimization in Billboard Advertisement (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26935": {
    "title": "Multi-Horizon Learning in Procedurally-Generated Environments for Off-Policy Reinforcement Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26936": {
    "title": "Modeling Metacognitive and Cognitive Processes in Data Science Problem Solving (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26937": {
    "title": "Hey, Siri! Why Are You Biased against Women? (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26938": {
    "title": "FV-Train: Quantum Convolutional Neural Network Training with a Finite Number of Qubits by Extracting Diverse Features (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26939": {
    "title": "PanTop: Pandemic Topic Detection and Monitoring System (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26940": {
    "title": "Social Intelligence towards Human-AI Teambuilding (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26941": {
    "title": "Robust Training for AC-OPF (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26942": {
    "title": "IdProv: Identity-Based Provenance for Synthetic Image Generation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26943": {
    "title": "Latent Space Evolution under Incremental Learning with Concept Drift (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26944": {
    "title": "Model Selection of Graph Signage Models Using Maximum Likelihood (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26945": {
    "title": "Optimal Execution via Multi-Objective Multi-Armed Bandits (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26946": {
    "title": "Lightweight Transformer for Multi-Modal Object Detection (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26947": {
    "title": "Reconsidering Deception in Social Robotics: The Role of Human Vulnerability (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26948": {
    "title": "Know Your Enemy: Identifying Adversarial Behaviours in Deep Reinforcement Learning Agents (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26949": {
    "title": "An Emotion-Guided Approach to Domain Adaptive Fake News Detection Using Adversarial Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26950": {
    "title": "Deep Anomaly Detection and Search via Reinforcement Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26951": {
    "title": "Towards Deployment-Efficient and Collision-Free Multi-Agent Path Finding (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26952": {
    "title": "SkateboardAI: The Coolest Video Action Recognition for Skateboarding (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26953": {
    "title": "AsT: An Asymmetric-Sensitive Transformer for Osteonecrosis of the Femoral Head Detection (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26954": {
    "title": "Self-Paced Learning Based Graph Convolutional Neural Network for Mixed Integer Programming (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26955": {
    "title": "Multi-Modal Protein Knowledge Graph Construction and Applications (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26956": {
    "title": "CasODE: Modeling Irregular Information Cascade via Neural Ordinary Differential Equations (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26957": {
    "title": "SR-AnoGAN: You Never Detect Alone. Super Resolution in Anomaly Detection (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26958": {
    "title": "Transformer-Based Named Entity Recognition for French Using Adversarial Adaptation to Similar Domain Corpora (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26959": {
    "title": "Disentangling the Benefits of Self-Supervised Learning to Deployment-Driven Downstream Tasks of Satellite Images (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26960": {
    "title": "Performance Disparities between Accents in Automatic Speech Recognition (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26961": {
    "title": "Demystify the Gravity Well in the Optimization Landscape (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26962": {
    "title": "AlphaSnake: Policy Iteration on a Nondeterministic NP-Hard Markov Decision Process (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26963": {
    "title": "Transformer-Based Multi-Hop Question Generation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26964": {
    "title": "eCDANs: Efficient Temporal Causal Discovery from Autocorrelated and Non-stationary Data (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26965": {
    "title": "LEAN-DMKDE: Quantum Latent Density Estimation for Anomaly Detection (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26966": {
    "title": "Safety Aware Neural Pruning for Deep Reinforcement Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26967": {
    "title": "Towards Fair and Selectively Privacy-Preserving Models Using Negative Multi-Task Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26968": {
    "title": "Towards Safe Reinforcement Learning via OOD Dynamics Detection in Autonomous Driving System (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26969": {
    "title": "Neural Implicit Surface Reconstruction from Noisy Camera Observations (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26970": {
    "title": "Expert Data Augmentation in Imitation Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26971": {
    "title": "Unsupervised Contrastive Representation Learning for 3D Mesh Segmentation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26972": {
    "title": "Invertible Conditional GAN Revisited: Photo-to-Manga Face Translation with Modern Architectures (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26973": {
    "title": "Exploring Hypergraph of Earnings Call for Risk Prediction (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26974": {
    "title": "An Analysis of the Deliberation and Task Performance of an Active Logic Based Agent (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26975": {
    "title": "Mobility Prediction via Sequential Trajectory Disentanglement (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26976": {
    "title": "A Reinforcement Learning Badminton Environment for Simulating Player Tactics (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26977": {
    "title": "Less Is More: Volatility Forecasting with Contrastive Representation Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26978": {
    "title": "Understand Restart of SAT Solver Using Search Similarity Index (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26979": {
    "title": "In-Game Toxic Language Detection: Shared Task and Attention Residuals (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26980": {
    "title": "CKS: A Community-Based K-shell Decomposition Approach Using Community Bridge Nodes for Influence Maximization (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26981": {
    "title": "Incremental Density-Based Clustering with Grid Partitioning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26982": {
    "title": "Sequential Graph Attention Learning for Predicting Dynamic Stock Trends (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26983": {
    "title": "Mitigating Negative Transfer in Multi-Task Learning with Exponential Moving Average Loss Weighting Strategies (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26984": {
    "title": "A Federated Learning Monitoring Tool for Self-Driving Car Simulation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26985": {
    "title": "Summarization Attack via Paraphrasing (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26986": {
    "title": "Evaluating Robustness of Vision Transformers on Imbalanced Datasets (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26987": {
    "title": "On Analyzing the Role of Image for Visual-Enhanced Relation Extraction (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26988": {
    "title": "Double Policy Network for Aspect Sentiment Triplet Extraction (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26989": {
    "title": "Learning Generalizable Batch Active Learning Strategies via Deep Q-networks (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26990": {
    "title": "Cross-Regional Fraud Detection via Continual Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26991": {
    "title": "Category-Guided Visual Question Generation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26992": {
    "title": "Can Graph Neural Networks Learn to Solve the MaxSAT Problem? (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26993": {
    "title": "Flaky Performances When Pretraining on Relational Databases (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26994": {
    "title": "A Highly Efficient Marine Mammals Classifier Based on a Cross-Covariance Attended Compact Feed-Forward Sequential Memory Network (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26995": {
    "title": "MGIA: Mutual Gradient Inversion Attack in Multi-Modal Federated Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26996": {
    "title": "Semi-supervised Review-Aware Rating Regression (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26997": {
    "title": "Toplogical Data Analysis Detects and Classifies Sunspots (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26998": {
    "title": "Risk-Aware Decentralized Safe Control via Dynamic Responsibility Allocation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26999": {
    "title": "A Mutually Enhanced Bidirectional Approach for Jointly Mining User Demand and Sentiment (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27000": {
    "title": "Debiasing Intrinsic Bias and Application Bias Jointly via Invariant Risk Minimization (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27001": {
    "title": "Label Smoothing for Emotion Detection (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27002": {
    "title": "Counting Knot Mosaics with ALLSAT (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27003": {
    "title": "Novel Intent Detection and Active Learning Based Classification (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27004": {
    "title": "Pre-training with Scientific Text Improves Educational Question Generation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27005": {
    "title": "Fraud's Bargain Attacks to Textual Classifiers via Metropolis-Hasting Sampling (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27006": {
    "title": "Improving Adversarial Robustness to Sensitivity and Invariance Attacks with Deep Metric Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27007": {
    "title": "LVRNet: Lightweight Image Restoration for Aerial Images under Low Visibility (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27008": {
    "title": "Hardness of Learning AES Key (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27009": {
    "title": "Generative Pipeline for Data Augmentation of Unconstrained Document Images with Structural and Textural Degradation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27010": {
    "title": "Neural Language Model Based Attentive Term Dependence Model for Verbose Query (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27011": {
    "title": "Evaluating Factors Influencing COVID-19 Outcomes across Countries Using Decision Trees (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27012": {
    "title": "Ordinal Programmatic Weak Supervision and Crowdsourcing for Estimating Cognitive States (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27013": {
    "title": "A Probabilistic Graph Diffusion Model for Source Localization (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27014": {
    "title": "Explaining Large Language Model-Based Neural Semantic Parsers (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27015": {
    "title": "Fuzzy C-means: Differences on Clustering Behavior between High Dimensional and Functional Data (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27016": {
    "title": "Photogrammetry and VR for Comparing 2D and Immersive Linguistic Data Collection (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27017": {
    "title": "RFC-Net: Learning High Resolution Global Features for Medical Image Segmentation on a Computational Budget (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27018": {
    "title": "Maximizing Influence Spread through a Dynamic Social Network (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27019": {
    "title": "Can You Answer This? – Exploring Zero-Shot QA Generalization Capabilities in Large Language Models (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27020": {
    "title": "FakeKG: A Knowledge Graph of Fake Claims for Improving Automated Fact-Checking (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27021": {
    "title": "Can Adversarial Networks Make Uninformative Colonoscopy Video Frames Clinically Informative? (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27022": {
    "title": "Bayesian Models for Targeted Cyber Deception Strategies (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27023": {
    "title": "Scalable Negotiating Agent Strategy via Multi-Issue Policy Network (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27024": {
    "title": "Efficient Dynamic Batch Adaptation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27025": {
    "title": "Development of a Human-Agent Interaction System including Norm and Emotion in an Evacuation Situation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27026": {
    "title": "Persistent Homology through Image Segmentation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27027": {
    "title": "TA-DA: Topic-Aware Domain Adaptation for Scientific Keyphrase Identification and Classification (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27028": {
    "title": "Exploring the Relative Value of Collaborative Optimisation Pathways (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27029": {
    "title": "Backforward Propagation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27030": {
    "title": "Two-Streams: Dark and Light Networks with Graph Convolution for Action Recognition from Dark Videos (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27031": {
    "title": "ES-Mask: Evolutionary Strip Mask for Explaining Time Series Prediction (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27032": {
    "title": "Exploration on Physics-Informed Neural Networks on Partial Differential Equations (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27033": {
    "title": "Parallel Index-Based Search Algorithm for Coalition Structure Generation (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27034": {
    "title": "The Naughtyformer: A Transformer Understands and Moderates Adult Humor (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27035": {
    "title": "Exploring the Effectiveness of Mask-Guided Feature Modulation as a Mechanism for Localized Style Editing of Real Images (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27036": {
    "title": "Global Explanations for Image Classifiers (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27037": {
    "title": "Quantify the Political Bias in News Edits: Experiments with Few-Shot Learners (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27038": {
    "title": "Anti-drifting Feature Selection via Deep Reinforcement Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27039": {
    "title": "Learning Dynamic Temporal Relations with Continuous Graph for Multivariate Time Series Forecasting (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27040": {
    "title": "Enhancing Dynamic GCN for Node Attribute Forecasting with Meta Spatial-Temporal Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27041": {
    "title": "Tackling Safe and Efficient Multi-Agent Reinforcement Learning via Dynamic Shielding (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27042": {
    "title": "Long Legal Article Question Answering via Cascaded Key Segment Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27043": {
    "title": "Improving Dialogue Intent Classification with a Knowledge-Enhanced Multifactor Graph Model (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27044": {
    "title": "Class Incremental Learning for Task-Oriented Dialogue System with Contrastive Distillation on Internal Representations (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27045": {
    "title": "ACCD: An Adaptive Clustering-Based Collusion Detector in Crowdsourcing (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27046": {
    "title": "Logic Error Localization and Correction with Machine Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27047": {
    "title": "Mask-Net: Learning Context Aware Invariant Features Using Adversarial Forgetting (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27048": {
    "title": "Adaptive Constraint Partition Based Optimization Framework for Large-Scale Integer Linear Programming (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27049": {
    "title": "Clustered Federated Learning for Heterogeneous Data (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27050": {
    "title": "Measuring the Privacy Leakage via Graph Reconstruction Attacks on Simplicial Neural Networks (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27051": {
    "title": "DyCVAE: Learning Dynamic Causal Factors for Non-stationary Series Domain Generalization (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27052": {
    "title": "HaPPy: Harnessing the Wisdom from Multi-Perspective Graphs for Protein-Ligand Binding Affinity Prediction (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27053": {
    "title": "Graph of Graphs: A New Knowledge Representation Mechanism for Graph Learning (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27054": {
    "title": "Exploiting High-Order Interaction Relations to Explore User Intent (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27055": {
    "title": "Feature Decomposition for Reducing Negative Transfer: A Novel Multi-Task Learning Method for Recommender System (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27056": {
    "title": "Model-Based Offline Weighted Policy Optimization (Student Abstract)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27057": {
    "title": "ConceptX: A Framework for Latent Concept Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27058": {
    "title": "SOREO: A System for Safe and Autonomous Drones Fleet Navigation with Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27059": {
    "title": "A Tool for Generating Controllable Variations of Musical Themes Using Variational Autoencoders with Latent Space Regularisation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27060": {
    "title": "Dagster: Parallel Structured Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27061": {
    "title": "AI-SNIPS: A Platform for Network Intelligence-Based Pharmaceutical Security",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27062": {
    "title": "TgrApp: Anomaly Detection and Visualization of Large-Scale Call Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27063": {
    "title": "TUTORING: Instruction-Grounded Conversational Agent for Language Learners",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27064": {
    "title": "HAPI Explorer: Comprehension, Discovery, and Explanation on History of ML APIs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27065": {
    "title": "EasyRec: An Easy-to-Use, Extendable and Efficient Framework for Building Industrial Recommendation Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27066": {
    "title": "edBB-Demo: Biometrics and Behavior Analysis for Online Educational Platforms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27067": {
    "title": "DUCK: A Drone-Urban Cyber-Defense Framework Based on Pareto-Optimal Deontic Logic Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27068": {
    "title": "NL2LTL – a Python Package for Converting Natural Language (NL) Instructions to Linear Temporal Logic (LTL) Formulas",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27069": {
    "title": "DISPUTool 2.0: A Modular Architecture for Multi-Layer Argumentative Analysis of Political Debates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27070": {
    "title": "Generating Reflective Questions for Engaging Gallery Visitors in ArtMuse",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27071": {
    "title": "Augmenting Flight Training with AI to Efficiently Train Pilots",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27072": {
    "title": "Sudoku Assistant – an AI-Powered App to Help Solve Pen-and-Paper Sudokus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27073": {
    "title": "DFEE: Interactive DataFlow Execution and Evaluation Kit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27074": {
    "title": "NCTV: Neural Clamping Toolkit and Visualization for Neural Network Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27075": {
    "title": "Kajibuntan: A House Chore Division App",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27076": {
    "title": "MARCOL: A Maritime Collision Avoidance Decision-Making Testbed",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27077": {
    "title": "FC-TrackNet: Fast Convergence Net for 6D Pose Tracking in Synthetic Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27078": {
    "title": "Robust-MSA: Understanding the Impact of Modality Noise on Multimodal Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27079": {
    "title": "GAAMA 2.0: An Integrated System That Answers Boolean and Extractive Questions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27080": {
    "title": "BiRDy: Bullying Role Detection in Multi-Party Chats",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27081": {
    "title": "AI Model Factory: Scaling AI for Industry 4.0 Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27082": {
    "title": "nBIIG: A Neural BI Insights Generation System for Table Reporting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27083": {
    "title": "Prototyping Logic-Based AI Services with LogicUS",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27084": {
    "title": "KnowGL: Knowledge Generation and Linking from Text",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27085": {
    "title": "Demo Alleviate: Demonstrating Artificial Intelligence Enabled Virtual Assistance for Telehealth: The Mental Health Case",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27086": {
    "title": "Task2KB: A Public Task-Oriented Knowledge Base",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27087": {
    "title": "CodeStylist: A System for Performing Code Style Transfer Using Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27088": {
    "title": "AnoViz: A Visual Inspection Tool of Anomalies in Multivariate Time Series",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27089": {
    "title": "CLUE-AD: A Context-Based Method for Labeling Unobserved Entities in Autonomous Driving Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/27090": {
    "title": "An Online Presentation Slide Assessment System Using Visual and Semantic Segmentation Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  }
}