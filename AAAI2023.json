{
  "https://ojs.aaai.org/index.php/AAAI/article/view/25070": {
    "title": "Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "118fd51b49e4f344873b8246bb051afb66c0c8d9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25071": {
    "title": "Reducing ANN-SNN Conversion Error through Residual Membrane Potential",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "366a99da9ddef081aacd362d3da6668dfff04b2d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25072": {
    "title": "Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "58f92031574529f13dfa8455c8bb539f43c722a0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25073": {
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "462b999f9e47915c89a0c70d797d3e82276f8410",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25074": {
    "title": "A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80df6f7525f24cce6d3d4c5f1a17566613a6f60d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25075": {
    "title": "A Machine with Short-Term, Episodic, and Semantic Memory Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d823694648cff737e14a613d5c743ac2b6cf39bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25076": {
    "title": "Persuasion Strategies in Advertisements",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1bd3def5257e992cecbcd5381771d77a95cc8200",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25077": {
    "title": "Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a78605f7d9372504eee3a0d9b86f0219a29d115",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25078": {
    "title": "AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4dbc668686f89830de4c67203db0709d9c4dda2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25079": {
    "title": "ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4e685992c8635225acabbe87d3900d104c9e78e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25080": {
    "title": "Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e09dc84599f5b9165eb38641ac7167b6fcfc450c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25081": {
    "title": "Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ced7e9eecfa29e4d5a4be0a2a649efd2ab119ed6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25082": {
    "title": "Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1126255b496a35ff2f04bfe33d6eedc765b649d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25083": {
    "title": "CMNet: Contrastive Magnification Network for Micro-Expression Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9ad4ac41b1ee5e150cb5adfc16b7c370d265d1c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25084": {
    "title": "Disentangling Reafferent Effects by Doing Nothing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6908360d349167eaec8c4007a56d84cea9397dc7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25085": {
    "title": "Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fbf899db663418a2fad1aa244e8d469d89138f0c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25086": {
    "title": "ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7fa2d8608e03c22ee025a27c7d6f81cc872735c6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25087": {
    "title": "Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6fbdc73ee62c32dc61cdddfb73410e1ec65cf35c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25088": {
    "title": "Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fc21e2c94cb2ed51809a9c96eccce810ef22520",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25089": {
    "title": "Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aed3b3d9809b0b3847d1853601eee97a9798257d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25090": {
    "title": "Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d7ce2e45a56c6cae56c4c9f0011f1ed739defc7",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25091": {
    "title": "Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef6fe11aa4b7dfec9f4d8da4e039f9c8d1839b0f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25092": {
    "title": "Layout Representation Learning with Spatial and Structural Hierarchies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f27d51387a1e00921c526cf0b44d8f41dc323e21",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25093": {
    "title": "Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ad6b3041cb994c57e26c4a8fe0203ffb1f0c8ea0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25094": {
    "title": "Multi-Level Compositional Reasoning for Interactive Instruction Following",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da804b058006e9b9ccda1776f437ceda9e869363",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25095": {
    "title": "Self-Supervised Image Local Forgery Detection by JPEG Compression Trace",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8d8f2834294897104e86f68a2f492058bfe5ccb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25096": {
    "title": "VASR: Visual Analogies of Situation Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b48eb1a32dcc4dcd122a5234c0fc055b71752e98",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25097": {
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b1f3354487bdc26a6eefef82960d085e9b78bb1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25098": {
    "title": "Explicit Invariant Feature Induced Cross-Domain Crowd Counting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7a2c9710df23afea3dfb8a7639fba8273c066cf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25099": {
    "title": "Painterly Image Harmonization in Dual Domains",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "04f9cc4d25baf7df5b14aa3e4bcdb91542f75d01",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25100": {
    "title": "MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cb09c77aab947c376df4fbcc4f2d877960f35d6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25101": {
    "title": "KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c407b4721a7aab2b198d73b373c53edfd5604d5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25102": {
    "title": "Deconstructed Generation-Based Zero-Shot Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50b3996ca86a55f9d3af68cb43c79659b1429daa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25103": {
    "title": "Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ef69136aa88675e3cf8aa33d87931d44a0615b2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25104": {
    "title": "Amodal Instance Segmentation via Prior-Guided Expansion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c9b776483a0de5d919842c05b48c029a78b7399",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25105": {
    "title": "SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d874861ec9f6b58166dcfcf05caf7a4a6bd032c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25106": {
    "title": "Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e7f81eb842623b41dd0bb09334506e148b076e66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25107": {
    "title": "Improving Dynamic HDR Imaging with Fusion Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1aea87fb6d103ecfc92b309b8c9ff9f10df47b7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25108": {
    "title": "Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b10dd9f4a5dfcc782c0a0892d43fea21cbb2eaea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25109": {
    "title": "Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dbb56d48ec9efeacf1d4dd31b76e23d5fb2c84b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25110": {
    "title": "Scalable Spatial Memory for Scene Rendering and Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "532cb7ca76a0e4f4993eae3e0cd31be73bd7e117",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25111": {
    "title": "Hybrid CNN-Transformer Feature Fusion for Single Image Deraining",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44c091514f3397740a1cbe72f86b53f2f409bc5b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25112": {
    "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d60265ea72d0344e991e71dfb13b4e1f15d4d4d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25113": {
    "title": "Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e9525ebe76a1d37533539ad2f560b1b453e66f6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25114": {
    "title": "DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "13d8ce3d2ac01cc5e108c1b89e79049428a53ad5",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25115": {
    "title": "Imperceptible Adversarial Attack via Invertible Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85af65c9355dc1ff8585354e014543751b498ee3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25116": {
    "title": "Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e0e103a2a1ed0241df544928d09d2a6b55c766e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25117": {
    "title": "User-Controllable Arbitrary Style Transfer via Entropy Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7dc98ae2967d6ad9c115ccaa705540b7489e0d40",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25118": {
    "title": "Neural Architecture Search for Wide Spectrum Adversarial Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3eb76059d9115f2f746b06dfcde7f8137147c59",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25119": {
    "title": "Adversarial Alignment for Source Free Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "693a942fa34028de582d18642d73d57c70842303",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25120": {
    "title": "Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "39dfc2eeb83e8694b1adc0b484775e9d47fee37a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25121": {
    "title": "OctFormer: Efficient Octree-Based Transformer for Point Cloud Compression with Local Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7acd42a6df03f98b6760c2f22b2bd2ce90695a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25122": {
    "title": "Dual-Domain Attention for Image Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ea2350d2bbafc07267d45aac410985376a6a332",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25123": {
    "title": "Multi-Resolution Monocular Depth Map Fusion by Self-Supervised Gradient-Based Composition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1527361af4eff8d52914a9e83f43471209c7de07",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25124": {
    "title": "Improving Crowded Object Detection via Copy-Paste",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea6e1e2254a95a7f5413f9fcfa4b1c0d63de46a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25125": {
    "title": "Defending Backdoor Attacks on Vision Transformer via Patch Processing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "95cb1fe9ad477b0ee3dff5659887f3ea0347e5e9",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25126": {
    "title": "Head-Free Lightweight Semantic Segmentation with Linear Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5fbc38ed3aa2de8eb22bc263e1c4d5091b7ce05a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25127": {
    "title": "Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52740e6b55a27ed79397adc59928ca90e739a53a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25128": {
    "title": "Exploring Tuning Characteristics of Ventral Stream's Neurons for Few-Shot Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f04d225453e19cda73c0de049a59a8acd7768bec",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25129": {
    "title": "Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "df11b7fd7c6f627ac8717e91e956e4611746afe3",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25130": {
    "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e38f4b4055abecbac2e618df2ecb33554073e08",
    "citation_count": 141
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25131": {
    "title": "Domain-General Crowd Counting in Unseen Scenarios",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f8232b83e87aef507a21b7afccecdbe511e46999",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25132": {
    "title": "Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bf39a82f65d9047e676f2f85f700c73d427b4189",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25133": {
    "title": "Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a888dd6d8dd0087fc7d74da8a005922d0923ad2b",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25134": {
    "title": "Target-Free Text-Guided Image Manipulation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a426c8209b38ed63b224363f4dcf179692d51ac",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25135": {
    "title": "One Is All: Bridging the Gap between Neural Radiance Fields Architectures with Progressive Volume Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e6f661b7ce2c457af3b9a4cee77101d93c2013c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25136": {
    "title": "Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f27d61ba154ada6b375a4dc313b673be7dbfdd84",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25137": {
    "title": "Uncertainty-Aware Image Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d13f52cbff1416d11986f996fa68ee9767844c60",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25138": {
    "title": "Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b027cb327be4a5051f00f0b84d936e8b2d3b653c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25139": {
    "title": "SEFormer: Structure Embedding Transformer for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "08e31f99bd0738c34100b24ffa0b059cdeebfc26",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25140": {
    "title": "Exploit Domain-Robust Optical Flow in Domain Adaptive Video Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4c180bdfe46f3d59791c7e970ccef667ab8481d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25141": {
    "title": "Scene-Level Sketch-Based Image Retrieval with Minimal Pairwise Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85b696039df8e3a934f69c5e5d72a904d4856fa2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25142": {
    "title": "Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "610924a1aa60494f01158fdb9cb680d0e6203148",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25143": {
    "title": "Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6acab3f2379de04d4a3449ed653add6db32a4af2",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25144": {
    "title": "Progressive Multi-View Human Mesh Recovery with Self-Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f63d71bfd0c363132865a36cd2169b3915888c94",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25145": {
    "title": "Incremental Image De-raining via Associative Memory",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7ff3f133e4290b266f5881a7108a681ffa72e45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25146": {
    "title": "Flexible 3D Lane Detection by Hierarchical Shape Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "247dfec8ebff13808228e73d4ad3166b45cb4972",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25147": {
    "title": "Underwater Ranker: Learn Which Is Better and How to Be Better",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9a07858f88daf54e0ced43ddc4e1178f754458b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25148": {
    "title": "ShadowFormer: Global Context Helps Shadow Removal",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7ffb3dee668255ccffc5970c795f0c1d79ad79b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25149": {
    "title": "RAFaRe: Learning Robust and Accurate Non-parametric 3D Face Reconstruction from Pseudo 2D&3D Pairs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "743cc26eb711e740724f5a94bb3bcc17a5201728",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25150": {
    "title": "RankDNN: Learning to Rank for Few-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9c63c1de8de192c62d334eb97bdff30c2f6fc64",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25151": {
    "title": "Social Relation Reasoning Based on Triangular Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71e0b80918978266b24e1d2df79f399885ba661d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25152": {
    "title": "CALIP: Zero-Shot Enhancement of CLIP with Parameter-Free Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca26023c4dbde9a54145b68e1a6a40533fcc1a4a",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25153": {
    "title": "Few-Shot Object Detection via Variational Feature Aggregation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d1e8a99b49e5ac7325e42c5958f76c22ac26e82",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25154": {
    "title": "Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eca815987e1c6a51e00fdc202342d50a288599f0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25155": {
    "title": "Target-Aware Tracking with Long-Term Context Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "62fc770746f6a283fbc5cfc32275e23bfef82eb7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25156": {
    "title": "Weakly-Supervised Camouflaged Object Detection with Scribble Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "613ac2c205cad421a28d7b3a357472a0883803c2",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25157": {
    "title": "Efficient Mirror Detection via Multi-Level Heterogeneous Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb30447cac68f1b22466da2f3f0d85e7a8e0d7c9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25158": {
    "title": "TransVCL: Attention-Enhanced Video Copy Localization Network with Flexible Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18c912802e3d6d84283d24655beb04f904d03675",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25159": {
    "title": "Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee301715607f618d22f21cb51c2c63ca85a4340c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25160": {
    "title": "Parameter-Efficient Model Adaptation for Vision Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "af593c53a9221bd12211f78d4f1ebd6b59cc4e7c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25161": {
    "title": "DarkFeat: Noise-Robust Feature Detector and Descriptor for Extremely Low-Light RAW Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a988d11e4a2c3de692bc879cf8c3d5be5e8e3ead",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25162": {
    "title": "GAM: Gradient Attention Module of Optimization for Point Clouds Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "a5820730290e81f76d843178af927591e669053d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25163": {
    "title": "Self-Supervised Learning for Multilevel Skeleton-Based Forgery Detection via Temporal-Causal Consistency of Actions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "84a150e189e34771752a5454a6f9e143a602dbb8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25164": {
    "title": "Self-Emphasizing Network for Continuous Sign Language Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f55d35e1d1a148898a756cb0380b22fa8878dcb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25165": {
    "title": "Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e32b2e5f07434a4d6ba73ee7394829ef93260124",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25166": {
    "title": "PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models against Adversarial Examples",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aec240626448b3506860a577d5d9ea3a20bfe794",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25167": {
    "title": "High-Resolution Iterative Feedback Network for Camouflaged Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "453d36c646576b04241ca7b964698eef64ebbdc8",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25168": {
    "title": "Leveraging Sub-class Discimination for Compositional Zero-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cb450cc6ccdaa0d1914cbc4d715f0eeb2792aa7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25169": {
    "title": "GPTR: Gestalt-Perception Transformer for Diagram Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6329ee4cf6bbd30c5d76d6caa78959946c656c56",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25170": {
    "title": "Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a63eff00c20172847439826377e412934caad068",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25171": {
    "title": "ClassFormer: Exploring Class-Aware Dependency with Transformer for Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eed051a90f635adb806c025c9b1fcc790f35ba0b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25172": {
    "title": "NLIP: Noise-Robust Language-Image Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2dd4bdb71e8d1a1bb6f7f2cb500972f082aa91fd",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25173": {
    "title": "Symmetry-Aware Transformer-Based Mirror Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b819d724661b35b93aa9048062d988fc6fc868fc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25174": {
    "title": "AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b42f494bf45ec5e154a007844cc449a07279c4f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25175": {
    "title": "Boosting Point Clouds Rendering via Radiance Mapping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18289220a3f778a35d89b9fadeba25820c1ad9ad",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25176": {
    "title": "FreeEnricher: Enriching Face Landmarks without Additional Cost",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9889925126ad324f3f60b0978882f00e23541206",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25177": {
    "title": "PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7fab5b0cc0bf96a1f987f9ebf18177e7915ba60",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25178": {
    "title": "Unifying Vision-Language Representation Space with Single-Tower Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e978d2f7e2a04da803d1a224b3ad868ac919dbb8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25179": {
    "title": "Delving Deep into Pixel Alignment Feature for Accurate Multi-View Human Mesh Recovery",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b5a878716aa4ab11e84ba0973d58ab35c68711a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25180": {
    "title": "Semi-attention Partition for Occluded Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "810862a848aa164ad7e0611ee4b850d6d28f4a1a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25181": {
    "title": "Fast Online Hashing with Multi-Label Projection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f98d2bd7a791f0eaea7aab20496a2b5efa0ed44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25182": {
    "title": "Fourier-Net: Fast Image Registration with Band-Limited Deformation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "743c723118ee61e2e5cc7161247c272522d8cdd5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25183": {
    "title": "Semi-supervised Deep Large-Baseline Homography Estimation with Progressive Equivalence Constraint",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a96f76cc868630a74b758951f5206e9f7e670e83",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25184": {
    "title": "Multi-Modality Deep Network for Extreme Learned Image Compression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fcbe9b439f1f694d79a3e788a3a4e2ce4655219a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25185": {
    "title": "PolarFormer: Multi-Camera 3D Object Detection with Polar Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "67a3e04199baad91ecf25b55f294f54b173c052b",
    "citation_count": 59
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25186": {
    "title": "3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d666dd97fa2659918fff88b3b279149121158ab",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25187": {
    "title": "FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e835e50b4c067cec7457332ec119994fb1a26422",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25188": {
    "title": "Estimating Reflectance Layer from a Single Image: Integrating Reflectance Guidance and Shadow/Specular Aware Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3054551f9f9dfd8d49d029e16b0d27f46990826",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25189": {
    "title": "Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cb7e9e6a68f64972cb42fc790c3a755175b80828",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25190": {
    "title": "Correlation Loss: Enforcing Correlation between Classification and Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "448224d5629a2d3ab1571811a2d183189f424376",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25191": {
    "title": "GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8ddb147c006cdeae6cd38f458e9c7c337d5b0965",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25192": {
    "title": "3D Human Pose Lifting with Grid Convolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eab5282e937a9b09b3af8c0956f1aa09ff20cfa9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25193": {
    "title": "Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a3577255e136a2c38198ac240cec2921bd739cde",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25194": {
    "title": "Frequency Selective Augmentation for Video Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2de0034a889be933b6059f9cfebc4edb35e4ff29",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25195": {
    "title": "Pose-Guided 3D Human Generation in Indoor Scene",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b60488cb4048b89121c0f50508c473bb8527d518",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25196": {
    "title": "Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "edf262d8983ca2ee80f6196365f8bf5e225603c5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25197": {
    "title": "Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d6d1f02bba8aadc484edfc5becba4a8b91f66343",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25198": {
    "title": "CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a32aec5f06324bd0dabab8a41c97e29a954a21a",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25199": {
    "title": "Simple and Effective Synthesis of Indoor 3D Scenes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "749fc01c222e526dab89e9cb4cb280447d7d65fe",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25200": {
    "title": "MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a600a57618e4f183ceec850fc9b441dda792728a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25201": {
    "title": "InstanceFormer: An Online Video Instance Segmentation Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7eb8252d603b202c9cd06c338d132b6eecfd35e0",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25202": {
    "title": "Pixel-Wise Warping for Deep Image Stitching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cc6c9024ae3beb06dfefe7b1e7813ab9a38e954",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25203": {
    "title": "Learning to Learn Better for Video Object Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0b7bf6eb268653a35a68e712516493a82b02d0f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25204": {
    "title": "Curriculum Multi-Negative Augmentation for Debiased Video Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "235d6337eeb067042eb90c957a4380506a78c7b7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25205": {
    "title": "Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0d75d6529e6098461434f5f4b3dbdd28ef29691",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25206": {
    "title": "MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc5df2954a38581b629ae0e86b8ec90b3af4b3bd",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25207": {
    "title": "Not All Neighbors Matter: Point Distribution-Aware Pruning for 3D Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f8a9671d33837ad90a9df091e03360c43fb5cc9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25208": {
    "title": "Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc1ed0c94657e9e340a038f02cab7b225704a4b9",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25209": {
    "title": "Linking People across Text and Images Based on Social Relation Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5d0b66ca3fec08cf52d56a375aada4a1360af49e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25210": {
    "title": "ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea5e945cde29b61254115d512e9d39fb57a7514c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25211": {
    "title": "SWBNet: A Stable White Balance Network for sRGB Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ba6d7080c349fba2d29fe42357639b00d5cb2cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25212": {
    "title": "Frequency Domain Disentanglement for Arbitrary Neural Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc21b6d4fe70b99b74acb442e8cf711efabe644c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25213": {
    "title": "Pose-Oriented Transformer with Uncertainty-Guided Refinement for 2D-to-3D Human Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4cc1b3aecef868c9d56adc4e6d8a1116774faef9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25214": {
    "title": "CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09a03bcf681ef763cdbcf69869204230d205d07e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25215": {
    "title": "Real-World Deep Local Motion Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a2c6c426b7f7921a41ba61fedcef8d12e05c32fe",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25216": {
    "title": "Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from a Conditional Causal Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "be2672ba4b68a5ebf69ce7c2f6024bd60f1d75c4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25217": {
    "title": "Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6ba44d7412305c1bab39b4b568e2e8492f9c9ed",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25218": {
    "title": "FSR: A General Frequency-Oriented Framework to Accelerate Image Super-resolution Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fa82af8be2e392986ad01984ae74de495efffeb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25219": {
    "title": "Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "20e4132660bf3e93e170c38dc970f5a59fba3d7e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25220": {
    "title": "Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d98fd91ed23b3ab623a60cd1713382b2163d5ce2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25221": {
    "title": "Spatial-Spectral Transformer for Hyperspectral Image Denoising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "efc12fd00542450f688bc4d8c9fc7db73309c723",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25222": {
    "title": "Learning Semantic Alignment with Global Modality Reconstruction for Video-Language Pre-training towards Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a17e108c9a99ba9a8db813fecc45b3e651e6a74",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25223": {
    "title": "Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c79bc6ce52539e42985a892e3745822590c2865",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25224": {
    "title": "NeAF: Learning Neural Angle Fields for Point Normal Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a765befc5a9f7816a2ae6cf2a911a94ff24c3399",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25225": {
    "title": "CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification without Concrete Text Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8adfb137332a61893417609563897abe9307a11",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25226": {
    "title": "DC-Former: Diverse and Compact Transformer for Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "540dcdf4a4556facf03a6cffed4f23a584f64317",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25227": {
    "title": "Panoramic Video Salient Object Detection with Ambisonic Audio Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ecce926a9877bb7512ce4d1101582877e07db12",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25228": {
    "title": "LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e11ee3c730263c6b92c24f1d707ed35626b7e5a1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25229": {
    "title": "Adaptive Texture Filtering for Single-Domain Generalized Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8d475edd830f150b9a6aa3066524c77913510df8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25230": {
    "title": "MEID: Mixture-of-Experts with Internal Distillation for Long-Tailed Video Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a96fdfacff96f3a4e944849f856752bc374f7bf1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25231": {
    "title": "Gradient Corner Pooling for Keypoint-Based Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2812527625498e4dd256e4ddb0f4a49aeffd2d61",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25232": {
    "title": "Towards Real-Time Segmentation on the Edge",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98b67efc8ca78e7e254a1fa543996b69635aa080",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25233": {
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-View 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "234f0122e0edccba5c91763e800c2f02fe8ae4fe",
    "citation_count": 129
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25234": {
    "title": "BEVStereo: Enhancing Depth Estimation in Multi-View 3D Object Detection with Temporal Stereo",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1285d14bffedcc4362fdd05213fd6ee4ec5ca885",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25235": {
    "title": "Learning Single Image Defocus Deblurring with Misaligned Training Pairs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b31de933dc82b38a598c1d274fc9ade2d987c0ba",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25236": {
    "title": "Curriculum Temperature for Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ee96ee0d32816658daa507e2228b037768f148b",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25237": {
    "title": "Actionness Inconsistency-Guided Contrastive Learning for Weakly-Supervised Temporal Action Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fce2e326ec543ef51f6d6e0294ae21d5074320bc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25238": {
    "title": "READ: Large-Scale Neural Scene Rendering for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "982236b056edc17962853c7344e5cf43513b474c",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25239": {
    "title": "CDTA: A Cross-Domain Transfer-Based Attack with Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5206aa1f39cdbc90245bab8761375f9159d913a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25240": {
    "title": "HybridCap: Inertia-Aid Monocular Capture of Challenging Human Motions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15453b482f58c9ef4a2f55f1cfb8872ef7cb7426",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25241": {
    "title": "Global Dilated Attention and Target Focusing Network for Robust Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d2e10ada5a6ac8442d38117e92508de98f165526",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25242": {
    "title": "Only a Few Classes Confusing: Pixel-Wise Candidate Labels Disambiguation for Foggy Scene Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c4f3efd0e7c9c0e1ce649fea31d7f8836f01293",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25243": {
    "title": "Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "137330d3030f75b01c88c14e1164d9b0d8c2dc70",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25244": {
    "title": "Probability Guided Loss for Long-Tailed Multi-Label Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa528fcfa48fe9333220012501e224cde12040fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25245": {
    "title": "Self-Supervised Image Denoising Using Implicit Deep Denoiser Prior",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0753df5be5fabf893ae9604c34c12a0a6233a91c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25246": {
    "title": "Accelerating the Training of Video Super-resolution Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "060bac73d0c6cab65b91f77364645a0afe142d38",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25247": {
    "title": "SelectAugment: Hierarchical Deterministic Sample Selection for Data Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44f4975b026c7c9ab934ead385afae080b20d66b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25248": {
    "title": "AdaCM: Adaptive ColorMLP for Real-Time Universal Photo-Realistic Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b19b1569f783fc4252deb5128889b5b466afefc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25249": {
    "title": "SEPT: Towards Scalable and Efficient Visual Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53169794d50f7541ea4a93417443751ed76a2009",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25250": {
    "title": "Cross-Modality Earth Mover's Distance for Visible Thermal Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e511d05b03a4d6d3ba9c02ec1e1dbf00794ff81e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25251": {
    "title": "Hypotheses Tree Building for One-Shot Temporal Sentence Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0bfac78dbab5f4318e1a065d6de413ba8ce24ed",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25252": {
    "title": "The Devil Is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ab64c8e9e05fd2426d6cc51f16d931279b862df",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25253": {
    "title": "M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f61187d734d9dfc7cdbb5e0c8ecb6e0a2f70c85",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25254": {
    "title": "From Coarse to Fine: Hierarchical Pixel Integration for Lightweight Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f56ed9f1ca57d3fb73dd6a08c101119e278c3f65",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25255": {
    "title": "Fast Fluid Simulation via Dynamic Multi-Scale Gridding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91c3eea164d6c32dd00647594f3ca3be21030a0d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25256": {
    "title": "TransLO: A Window-Based Masked Point Transformer Framework for Large-Scale LiDAR Odometry",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "792798d7cfde416beedcae70cd5b5a92c4ab2737",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25257": {
    "title": "Low-Light Video Enhancement with Synthetic Event Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15837a406a4f6859ca89b1cbbd7b391464164195",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25258": {
    "title": "Novel Motion Patterns Matter for Practical Skeleton-Based Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6a841c4254d8d95ef69abb365087ef3544ad0f82",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25259": {
    "title": "EMEF: Ensemble Multi-Exposure Image Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e8af97164df4a203f39f6d19c17d9b58952d93d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25260": {
    "title": "Reducing Domain Gap in Frequency and Spatial Domain for Cross-Modality Domain Adaptation on Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea10d0a86d0989d97088964d9dfb3f3dbc34daa2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25261": {
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "19ddeaf042fa00814a459e12d03f15801551e423",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25262": {
    "title": "Progressive Neighborhood Aggregation for Semantic Segmentation Refinement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2be38731ed22dbb6ee0ad425fe09f3dc89c856d3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25263": {
    "title": "CoordFill: Efficient High-Resolution Image Inpainting via Parameterized Coordinate Querying",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bbefdde6de6e100794448eadd2de8fc01f147d27",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25264": {
    "title": "CCQ: Cross-Class Query Network for Partially Labeled Organ Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f27fa335b4be16de2e43b765f9dcc97ace8dfff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25265": {
    "title": "Counterfactual Dynamics Forecasting  a New Setting of Quantitative Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "6cb1a49f248413f851eb6c345a2006aca8e96192",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25266": {
    "title": "Self-Decoupling and Ensemble Distillation for Efficient Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b192a0023f769edb31dc191fcc9210318c558df",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25267": {
    "title": "Token Mixing: Parameter-Efficient Transfer Learning from Image-Language to Video-Language",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5fcb5889e7c716b2493da67b63179cb0034c0c66",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25268": {
    "title": "StereoDistill: Pick the Cream from LiDAR for Distilling Stereo-Based 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "628766d52767f8c872047708a21cc0c320366715",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25269": {
    "title": "Good Helper Is around You: Attention-Driven Masked Image Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c58af37caedda1af6833209ef6b384d350743ffd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25270": {
    "title": "RADIANT: Radar-Image Association Network for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9968d3c8e3b099e02f7e57ab8aeee0f95a781fdc",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25271": {
    "title": "CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation via Centrifugal Reference Frame",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45ea3b4f2e53eaa4fb57ea679646848c48d489eb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25272": {
    "title": "See Your Emotion from Gait Using Unlabeled Skeleton Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "42683c65f41540177c08642aa635bce8d567537f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25273": {
    "title": "Learning Progressive Modality-Shared Transformers for Effective Visible-Infrared Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee04b2b113700b71de4fe91bddc9cd10348486b7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25274": {
    "title": "Breaking Immutable: Information-Coupled Prototype Elaboration for Few-Shot Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b09025b0b145ad07346fd75e7b5c0429e422ec7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25275": {
    "title": "ParaFormer: Parallel Attention Transformer for Efficient Feature Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "467268d70982cceb82206f526485951b0cff3e80",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25276": {
    "title": "Robust One-Shot Segmentation of Brain Tissues via Image-Aligned Style Transformation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ddc061eec9873bd2b38a284e21561eda1ef0756",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25277": {
    "title": "HRDoc: Dataset and Baseline Method toward Hierarchical Reconstruction of Document Structures",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cef1779a38aeb0aefbc347318b22e7b5cf890c03",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25278": {
    "title": "Semantic 3D-Aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "01df332f62508f976fea91cdad8010669efc5701",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25279": {
    "title": "CFFT-GAN: Cross-Domain Feature Fusion Transformer for Exemplar-Based Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29d35ab84788ca14e2b65a457c7fed5ee6f150a4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25280": {
    "title": "StyleTalk: One-Shot Talking Head Generation with Controllable Speaking Styles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ef7df2ace0723583ba22bf165188cd7d2044e93",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25281": {
    "title": "Intriguing Findings of Frequency Selection for Image Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6f039e6f7b0ef12afc01f0992f477ecc7bfdb31",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25282": {
    "title": "DocEdit: Language-Guided Document Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "383db93b039c2f7d743a06dc62a8db2ff1ea33f7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25283": {
    "title": "Progressive Few-Shot Adaptation of Generative Model with Align-Free Spatial Correlation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e5bed4c8dbc00e975c9d585e7592eaaf2d9d28e5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25284": {
    "title": "Minority-Oriented Vicinity Expansion with Attentive Aggregation for Video Long-Tailed Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5020cc02130c7625836f28969aa632eb87d83f28",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25285": {
    "title": "Show, Interpret and Tell: Entity-Aware Contextualised Image Captioning in Wikipedia",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7405b595f266e02f5cac24a11d83b7e341662f6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25286": {
    "title": "TaCo: Textual Attribute Recognition via Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "69df56f5b6134ab85fbf878593eb17a968453538",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25287": {
    "title": "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6df6c71be7a04e3e5c2a0dae037fe38458fe1ef6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25288": {
    "title": "Adapting Object Size Variance and Class Imbalance for Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a30c72de1c89f3c1c38f8e4390699c86bb15626",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25289": {
    "title": "MIMO Is All You NeedA Strong Multi-in-Multi-Out Baseline for Video Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "6ec6176e06ba9918ce563dc89a96303408fd97cf",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25290": {
    "title": "Universe Points Representation Learning for Partial Multi-Graph Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61feea09030ace88eb0ddcdcf8942b002b5adfd3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25291": {
    "title": "Robust Image Denoising of No-Flash Images Guided by Consistent Flash Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "81eb06c149775e0de9ec7b04bb4d4b53abf04d43",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25292": {
    "title": "Coarse2Fine: Local Consistency Aware Re-prediction for Weakly Supervised Object Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9070385c89cf2385629b70e1ed7267a9391554d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25293": {
    "title": "Find Beauty in the Rare: Contrastive Composition Feature Clustering for Nontrivial Cropping Box Regression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "82fa44d3b927745ed1e2397eacc02596da50d0f6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25294": {
    "title": "Domain Decorrelation with Potential Energy Ranking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "55b51b993600aa23d84e1e15fb53641100e9c772",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25295": {
    "title": "PDRF: Progressively Deblurring Radiance Field for Fast Scene Reconstruction from Blurry Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "559f7202200ef3c187780301590e2f2b4665f047",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25296": {
    "title": "Efficient End-to-End Video Question Answering with Pyramidal Multimodal Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2837e0cab1d600fa9ca29ebdbfab239701065071",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25297": {
    "title": "CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b57872957f8f70573b62a27c4b91e0636b218983",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25298": {
    "title": "Better and Faster: Adaptive Event Conversion for Event-Based Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bd82d465f64ef748e3de025a2ad0edf05f300fdd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25299": {
    "title": "CSTAR: Towards Compact and Structured Deep Neural Networks with Adversarial Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29bb2597be1a499d30d23844bf19d5c43f6afc12",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25300": {
    "title": "Exploring Stochastic Autoregressive Image Modeling for Visual Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fa0872e45bf6c0fee528c86120f52490142efba6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25301": {
    "title": "Context-Aware Transformer for 3D Point Cloud Automatic Annotation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ec629633af4d16bbc8db0cc3fb26964cfa33eb6c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25302": {
    "title": "Data-Efficient Image Quality Assessment with Attention-Panel Decoder",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "959eac73869bb8ec9096871957c938840e0fdcd0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25303": {
    "title": "FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29a2c4d44117e51e0d2fa6ffac516222ecab254f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25304": {
    "title": "Exposing the Self-Supervised Space-Time Correspondence Learning via Graph Kernels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1b137feaa09a7660c26107d7cf0411e2e99058c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25305": {
    "title": "Exploring Stroke-Level Modifications for Scene Text Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8fe2b02776208670906c89f8b8d361074fc87d5",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25306": {
    "title": "Unsupervised Deep Learning for Phase Retrieval via Teacher-Student Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c02b92e4ffb3edd22280154b535017de8a1938c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25307": {
    "title": "A Learnable Radial Basis Positional Embedding for Coordinate-MLPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05450d77727a1c58854e0b8550ca9f82e05d1cd8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25308": {
    "title": "Action-Conditioned Generation of Bimanual Object Manipulation Sequences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44d343bfa354e4afa7a3bed82a7831d677e3e210",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25309": {
    "title": "Mean-Shifted Contrastive Loss for Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d90243c5a46430a36c5ba88627b5d254450a1e1",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25310": {
    "title": "Two Heads Are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a09509004fb374d794fb4065b54e9a5dda630e6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25311": {
    "title": "MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-robust Classifier",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "790ba79fa1fcc7446fd81047c9e86b2b4c862d7a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25312": {
    "title": "Domain Generalised Faster R-CNN",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b22618848e56abbf7dcf1d7f419b72215cefcdb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25313": {
    "title": "MIDMs: Matching Interleaved Diffusion Models for Exemplar-Based Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ed3b73719016f3500c5976234111b87c21837bf",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25314": {
    "title": "JR2Net: Joint Monocular 3D Face Reconstruction and Reenactment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e51e322712413d3e6d5b8abef8d74cbfdaa2ae4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25315": {
    "title": "HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "643626048cc70b1ed4ed3a0fc94d58b02b7945f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25316": {
    "title": "Channel Regeneration: Improving Channel Utilization for Compact DNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e32b11399247648b4d9f50bd54f8a383280489fb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25317": {
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6f14a642033b72454afbecdb90c82872d8085dd2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25318": {
    "title": "Edge Structure Learning via Low Rank Residuals for Robust Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "925794910710207106ee192ff97475a2617bef3c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25319": {
    "title": "Memory-Oriented Structural Pruning for Efficient Image Restoration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9f5408d8c08a2f7beb35cb16c6ccdcf67b3c7d3d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25320": {
    "title": "YOLOV: Making Still Image Object Detectors Great at Video Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa289e06d4a11f50ce1f5287415a7ff752c136f6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25321": {
    "title": "FeedFormer: Revisiting Transformer Decoder for Efficient Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "de8d3b6ef17f924fc8d01d09bcc128c068dc1469",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25322": {
    "title": "Task-Specific Scene Structure Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3194258a0374f03f1ba1b968fa181fc1e1456b49",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25323": {
    "title": "Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "41e11c36e6fd2377fe5ecb9d0d0422c635ee4be0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25324": {
    "title": "SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8fe203feefec99d20ed68003e5389a46a0d7f285",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25325": {
    "title": "Siamese-Discriminant Deep Reinforcement Learning for Solving Jigsaw Puzzles with Large Eroded Gaps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14ef45b70e11c8222baf19f30cc045f54d574c23",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25326": {
    "title": "CLIPVG: Text-Guided Image Manipulation Using Differentiable Vector Graphics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cda631065b5300aa3d3d3226a4da9d3a36939494",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25327": {
    "title": "Compact Transformer Tracker with Correlative Masked Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8e6e17ca2288c26b79cedff0a666e2549441ac1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25328": {
    "title": "Text-DIAE: A Self-Supervised Degradation Invariant Autoencoder for Text Recognition and Document Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e0714e9dc5dc5ce5b4eda032d166fb07bb26ca1",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25329": {
    "title": "PUPS: Point Cloud Unified Panoptic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72e8986a912f812b71f02e4083d349104c0db158",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25330": {
    "title": "Efficient Edge-Preserving Multi-View Stereo Network for Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "20475d345d152fa4a78b9eb37f3ffe7f2d3cfcf6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25331": {
    "title": "Referring Expression Comprehension Using Language Adaptive Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0b4d116cb264894b47e0c25cb89344c924ba9cc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25332": {
    "title": "Rethinking Data Augmentation for Single-Source Domain Generalization in Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c8368b16b978c36bcb368e673c292254d8a4cf01",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25333": {
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e4aa84de53f8d6f8245ff6bc3c535ed260edfe2",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25334": {
    "title": "Learning Event-Relevant Factors for Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f1b6f5dcd5f802f2782ef15629be57202e3b629",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25335": {
    "title": "Superpoint Transformer for 3D Scene Instance Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e015130b27aaa95674e7c4b5dcbb5a7a7fe7ed04",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25336": {
    "title": "Asynchronous Event Processing with Local-Shift Graph Convolutional Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29f12988ea953725e791e7467b479f7161a487ac",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25337": {
    "title": "DENet: Disentangled Embedding Network for Visible Watermark Removal",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5720ed9d22f2f83a75e7f8efb7b466691f631138",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25338": {
    "title": "Deep Manifold Attack on Point Clouds via Parameter Plane Stretching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38a454f66e8fca40a342f5edb3b1d433eb091971",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25339": {
    "title": "Fair Generative Models via Transfer Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c77f32cb3a030c04de992be40fdf882690afeef8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25340": {
    "title": "Learning Context-Aware Classifier for Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ca374400fc1dd1078ce39c942ff8df562fb163b",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25341": {
    "title": "TopicFM: Robust and Interpretable Topic-Assisted Feature Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1df8ce9e21c544a8ba0911e3e7825abc752236eb",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25342": {
    "title": "Learning Fractals by Gradient Descent",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8715975820cbacdc844a196e2f2f471cca982ccb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25343": {
    "title": "Leveraging Weighted Cross-Graph Attention for Visual and Semantic Enhanced Video Captioning Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a5e3cf08174095cbe4cec418d19b8fc260af49cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25344": {
    "title": "Doodle to Object: Practical Zero-Shot Sketch-Based 3D Shape Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d658819f2aad7f8fe5ec951c595d432f0d8db33f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25345": {
    "title": "Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f8860a5ef6097a9a01a352e609366343627db577",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25346": {
    "title": "Dual Memory Aggregation Network for Event-Based Object Detection with Learnable Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d902c86c7a1cbdac013523488adf85942aa11169",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25347": {
    "title": "Text to Point Cloud Localization with Relation-Enhanced Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23a24e1740bf1b5bd5f39b18114b65ceabed1db0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25348": {
    "title": "UCoL: Unsupervised Learning of Discriminative Facial Representations via Uncertainty-Aware Contrast",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77f6e57c4c5d73fe7805c662381ebad5ed643789",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25349": {
    "title": "Calibrated Teacher for Sparsely Annotated Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "045465a04985227f05a437ecc459fbc8b1cb0478",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25350": {
    "title": "Towards Real-Time Panoptic Narrative Grounding by an End-to-End Grounding Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "436f2d681c3448b6d10cea53238974987d71c0f2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25351": {
    "title": "LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36b5d21ee97844ec915f5740e37e95c41992409c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25352": {
    "title": "Defending Black-Box Skeleton-Based Human Activity Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "24d47781fb60fd3a427d426d763fc544bee8175b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25353": {
    "title": "Exploring CLIP for Assessing the Look and Feel of Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03ae89e796b1a8b566ae1554fab65c8c88b3a55f",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25354": {
    "title": "Robust Video Portrait Reenactment via Personalized Representation Quantization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f54e8f1d3af326ccbd372fe1cf7f548f7fd6a483",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25355": {
    "title": "De-biased Teacher: Rethinking IoU Matching for Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "656d87d314009a9f1925348d30652f39e0cc7ed5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25356": {
    "title": "Learning to Generate an Unbiased Scene Graph by Using Attribute-Guided Predicate Features",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da31afdbc962f0323d013a88a0c308c61b4d247c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25357": {
    "title": "Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ff504e8d0ed00d8e9d6dd317d3b7572d1f3ecaa",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25358": {
    "title": "Flora: Dual-Frequency LOss-Compensated ReAl-Time Monocular 3D Video Reconstruction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "de0d19110a0601c0741df7d26982a0c44288ce90",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25359": {
    "title": "Efficient Image Captioning for Edge Devices",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d6332c9a4607ce9823123e6407e40ab6ac33ac08",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25360": {
    "title": "Controllable Image Captioning via Prompting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f66aeec98816c3a52685e570a04fa8f2bd53dfb4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25361": {
    "title": "ECO-3D: Equivariant Contrastive Learning for Pre-training on Perturbed 3D Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c1cef162d3c6276c84deb22c08a2b6d7e2d38a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25362": {
    "title": "Global-Local Characteristic Excited Cross-Modal Attacks from Images to Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "af77300381156898024ea3a10f6d00cc31b8ee86",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25363": {
    "title": "Fine-Grained Retrieval Prompt Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "247be1257a1c5811ff48331e902771c7b00a56c5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25364": {
    "title": "Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "baf3d202261f1eb9122a157fc6480d93e2c3d03c",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25365": {
    "title": "3D Assembly Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb2256efc25ad00d4a18a9901cf83b17dbc038a4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25366": {
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "974e24ce5ca6a23b8841f3b1049edff0aeaf42ce",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25367": {
    "title": "Revisiting Unsupervised Local Descriptor Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b72f022c06dbfa52af4f31a766ca57e7758b5990",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25368": {
    "title": "Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "588042275a2e338df56ace42453c727137da36fc",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25369": {
    "title": "Learning Continuous Depth Representation via Geometric Spatial Aggregator",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9dc77eb07e11d3fd09f2dd5d2225ded4291f6d3b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25370": {
    "title": "SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bfc07ed6e6d4aef2674d0e412215b3253b95336c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25371": {
    "title": "High-Resolution GAN Inversion for Degraded Images in Large Diverse Datasets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36da639b3cba35311314a19e5bfd987c5865a061",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25372": {
    "title": "GAN Prior Based Null-Space Learning for Consistent Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c12d091ea5c16938943559fb0f3d430ba040c08",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25373": {
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65be7f0b01cf6c2a1cded708b809182fbcb43548",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25374": {
    "title": "MicroAST: Towards Super-fast Ultra-Resolution Arbitrary Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7b0183c518ebc2100569f1086fd6fedab8659d96",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25375": {
    "title": "Truncate-Split-Contrast: A Framework for Learning from Mislabeled Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bb62dd71543f4644cec09b00bdf7b8b2795063fd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25376": {
    "title": "Active Token Mixer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "20fc19d7445ec081a95a3e97bab3f1f07c92988d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25377": {
    "title": "Exploring Non-target Knowledge for Improving Ensemble Universal Adversarial Attacks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2cf7b3b2fb58431d96e934effbb0af3a3ba60eb9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25378": {
    "title": "Towards Good Practices for Missing Modality Robust Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12a43c120c9e7615535237bbee2f6375d07fdd7a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25379": {
    "title": "Reject Decoding via Language-Vision Models for Text-to-Image Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f9fff9bf668264b454ee45e67135ea2debd7b8f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25380": {
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8599f26dd40313a092dc05fe370b934beb6a29ef",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25381": {
    "title": "Super-efficient Echocardiography Video Segmentation via Proxy- and Kernel-Based Semi-supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6f991a9b4da4d520d11684d42cdf403d0be5917",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25382": {
    "title": "ACL-Net: Semi-supervised Polyp Segmentation via Affinity Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7fe355f1db5dbf47e4ac223c7a48e8dbaa7cbe1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25383": {
    "title": "Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8d3436667b7863759a5d2228366e357f35a6e8d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25384": {
    "title": "Preserving Structural Consistency in Arbitrary Artist and Artwork Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e808f718e4f195527e8ea3ecb252e25e24c98bae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25385": {
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2b2a7f713d8efe2696df85ef22dac7ef35be7e10",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25386": {
    "title": "Revisiting Classifier: Transferring Vision-Language Models for Video Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c68b9483bcd91850e27cc6d667c783edf335a3e4",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25387": {
    "title": "Scene Graph to Image Synthesis via Knowledge Consensus",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "feb5504685a92ea0b2283959a1b508f54bab1627",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25388": {
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for Unsupervised Visual Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fe6ee1f2bf6fa3093798723d3edab686fd927d1d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25389": {
    "title": "Multi-Stream Representation Learning for Pedestrian Trajectory Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b1552a37506344714092defaf1a4bc9488f9bd67",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25390": {
    "title": "Pixel Is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "088a89c3ef90e80b050ac717400209f564099654",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25391": {
    "title": "Attention-Based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6c475af6a695d494b8790ca878f146e795eeb27b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25392": {
    "title": "Skating-Mixer: Long-Term Sport Audio-Visual Modeling with MLPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14165df6bd6ebe598d65d740ee7bcefee2e178f4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25393": {
    "title": "SVFI: Spiking-Based Video Frame Interpolation for High-Speed Motion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a30499c63169d649d9104fa05de10dce6fef3e7b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25394": {
    "title": "FEditNet: Few-Shot Editing of Latent Semantics in GAN Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cde780c2bad086fa5267a11068bb40d320616b4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25395": {
    "title": "Toward Robust Diagnosis: A Contour Attention Preserving Adversarial Defense for COVID-19 Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a68b491f64daf9eee7551469e5d7a39fa62515ad",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25396": {
    "title": "Boosting Semi-Supervised Semantic Segmentation with Probabilistic Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12e668ad61fbcfb1e4752f1243082dc8c0f75f4f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25397": {
    "title": "Less Is More Important: An Attention Module Guided by Probability Density Function for Convolutional Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7624dc2e2c610040b778ce11c3261523e7b27c93",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25398": {
    "title": "Mitigating Artifacts in Real-World Video Super-resolution Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "442f3bde58bd8f736f8643a5fb2feec0854bf368",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25399": {
    "title": "Just Noticeable Visual Redundancy Forecasting: A Deep Multimodal-Driven Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4dc3f4d5a05f9af6b5c78f67b8cb6704738ad7e5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25400": {
    "title": "Cross-Modal Contrastive Learning for Domain Adaptation in 3D Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ff5d423b6dc934d58c7541df31b507fdda059be5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25401": {
    "title": "ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient Self-Supervised Monocular Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "373959536e023e451b46e6e3d60228b59568a5ac",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25402": {
    "title": "LORE: Logical Location Regression Network for Table Structure Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a90a77893708ae5070e2ed4572ca9e20837e69c6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25403": {
    "title": "Revisiting the Spatial and Temporal Modeling for Few-Shot Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7723859aa67aa5324155dfafa1f078b3bc034178",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25404": {
    "title": "Unsupervised Multi-Exposure Image Fusion Breaking Exposure Limits via Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc8f02331ed5baed6f5c0adb9c9cb2fca5e7c1a8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25405": {
    "title": "CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene Completion by Dense Feature Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ede618392b52947f4103415c97e444c20697e550",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25406": {
    "title": "Learning a Generalized Gaze Estimator from Gaze-Consistent Feature",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a79ce59268ff9b07f61ba730bdfb8f0eaa54ab0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25407": {
    "title": "Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44891165b360ccf98d7f6fd7f5361a6d5f3b4a3b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25408": {
    "title": "Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17b71c39617d654ff345d7e48491068f7d519b0c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25409": {
    "title": "Deep Parametric 3D Filters for Joint Video Denoising and Illumination Enhancement in Video Super Resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e64440b53317fa8b5b800f238d500d586ae5e17f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25410": {
    "title": "Inter-image Contrastive Consistency for Multi-Person Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e5b923a3498a977c0758a1578cb0af1fa180420",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25411": {
    "title": "DeMT: Deformable Mixer Transformer for Multi-Task Learning of Dense Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3d3c1321554d7d14eec309e61ba70102b0629e1",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25412": {
    "title": "VLTinT: Visual-Linguistic Transformer-in-Transformer for Coherent Video Paragraph Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c35fc28cb4e9336f4077cfc9cc559f55950b5996",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25413": {
    "title": "Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1b14b7ed6601b4e1fd847a3043e749ca0bf02aa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25414": {
    "title": "Video-Text Pre-training with Learned Regions for Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "615d077899e7c57c7073d427035499749fa7b355",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25415": {
    "title": "DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15d9392d12635221d6dba08a33344f6fc97060ce",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25416": {
    "title": "Self-Supervised Video Representation Learning via Latent Time Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71a971a7a86459eb7a568985fe398a7c79b3dd35",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25417": {
    "title": "One-Shot Replay: Boosting Incremental Object Detection via Retrospecting One Object",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9bc81d69b990c814770096f3aa41ded4f639df6d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25418": {
    "title": "Video Event Extraction via Tracking Visual States of Arguments",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e3516142b2d7cf7fb67805a8b45fb077c9c6bb8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25419": {
    "title": "CoMAE: Single Model Hybrid Pre-training on Small-Scale RGB-D Datasets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2feabd1e149da3aa82cc6d1d684cac836a0c01e7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25420": {
    "title": "Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae0c998d3efe583b19fd4d1274eec3520c8f813a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25421": {
    "title": "Stop-Gradient Softmax Loss for Deep Metric Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a792e32749ebb98686791d4524f4e8d4ba575433",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25422": {
    "title": "Local Path Integration for Attribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "87d4cf1dd6507e7c989b25a4a1eeea1a467c3a54",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25423": {
    "title": "Spatiotemporal Deformation Perception for Fisheye Video Rectification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fd89aa30d4917bde9a2343d5590456ce2d76ac8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25424": {
    "title": "Contrastive Multi-Task Dense Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "59c681b58d85411ba5a70284947ad728f468c54c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25425": {
    "title": "AutoStegaFont: Synthesizing Vector Fonts for Hiding Information in Documents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6225139fe937b85a1a4a7d03e10354745f764b5c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25426": {
    "title": "Towards Global Video Scene Segmentation with Context-Aware Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "807937ad69b41b6a320d9d180fa9fe0205d56804",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25427": {
    "title": "Low-Light Image Enhancement Network Based on Multi-Scale Feature Complementation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0287e28e409920e97b5b308974750914d60ba7b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25428": {
    "title": "Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "21cbb159992abffdee87c2a1bc15a3d98bdfde8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25429": {
    "title": "LidarMultiNet: Towards a Unified Multi-Task Network for LiDAR Perception",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09ce90a7d46c297db17e41cfd4e7691933408540",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25430": {
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f89d5e8e3c6e3bb035729c1f6039ee95149ce0b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25431": {
    "title": "Learning Second-Order Attentive Context for Efficient Correspondence Pruning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f5faa47345366d623a8cd3b41e63276065c404a3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25432": {
    "title": "Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "28f4d454359641f62944674ea085e84aff5ce023",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25433": {
    "title": "Can We Find Strong Lottery Tickets in Generative Models?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74fb4456760e417ec2873cfab1e4c87ce59df8f6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25434": {
    "title": "Class-Independent Regularization for Learning with Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "284858ac99309568e83377a9968a1908ee28c717",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25435": {
    "title": "Unbiased Heterogeneous Scene Graph Generation with Relation-Aware Message Passing Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b02f9674a07d6a7e4ab5f4846301dc8d15433e46",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25436": {
    "title": "Lifelong Person Re-identification via Knowledge Refreshing and Consolidation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cdba9c57d5e372bee7a382c2f287eb20da244977",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25437": {
    "title": "Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dddeca3509132717a8b5843f730b8b01a3887dcc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25438": {
    "title": "Rethinking Rotation Invariance with Point Cloud Registration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ca5939d6e64dc751de8bd513980f57a2d43af55",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25439": {
    "title": "Frame-Level Label Refinement for Skeleton-Based Weakly-Supervised Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ac0d48894ddbb9232730ab54f9a7754dc6e73c45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25440": {
    "title": "Recurrent Structure Attention Guidance for Depth Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5010526e685c33293be4317720235e639a3bf2e7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25441": {
    "title": "Structure Flow-Guided Network for Real Depth Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98338f97c57fdaea642fa19df65d761349562ca4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25442": {
    "title": "Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b489c6fe772b861a99a14f5f6474b0d44a4a8f2e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25443": {
    "title": "Cyclically Disentangled Feature Translation for Face Anti-spoofing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9abd5e50e280323e3446595d23aa696113346465",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25444": {
    "title": "FlowFace: Semantic Flow-Guided Shape-Aware Face Swapping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "166d8ab629f46c818f42fa4e802a6033d42ece16",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25445": {
    "title": "Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1820749124aa1eaa51c47cb084f13c76b1a8ed2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25446": {
    "title": "Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "297c953df13c4375527df215b57f9c72c036a569",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25447": {
    "title": "Darwinian Model Upgrades: Model Evolving with Selective Compatibility",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d49b452bf09020f032ff65aa115740e3bf99ea0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25448": {
    "title": "Mx2M: Masked Cross-Modality Modeling in Domain Adaptation for 3D Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc430bba79178483c254a072c2151f0b3e7111af",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25449": {
    "title": "Few-Shot 3D Point Cloud Semantic Segmentation via Stratified Class-Specific Attention Based Transformer Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80df029becc3fdf6789c0d4c4fdf9a832f2e2672",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25450": {
    "title": "PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement and Pose Restoration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e6ad00f8c11a9237fc112ecff222e00fd71174ae",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25451": {
    "title": "Hierarchical Consistent Contrastive Learning for Skeleton-Based Action Recognition with Growing Augmentations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51133d759e81916553edf4e35a20385d12090abe",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25452": {
    "title": "ImageNet Pre-training Also Transfers Non-robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b28004c12d1073f3b186483ecb9e8fb816dd37c8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25453": {
    "title": "Language-Assisted 3D Feature Learning for Semantic Scene Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e667180d34f837c7416358414a387595d54eee4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25454": {
    "title": "IKOL: Inverse Kinematics Optimization Layer for 3D Human Pose and Shape Estimation via Gauss-Newton Differentiation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa5262e4d46f8565de1d6049d1f85e8e2033601a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25455": {
    "title": "Mind the Gap: Polishing Pseudo Labels for Accurate Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b3854e82d71e1a36e049763bb270f1f19d2ea3c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25456": {
    "title": "ConvMatch: Rethinking Network Design for Two-View Correspondence Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8d9662d2db763abb6d427d398e76288327457b1a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25457": {
    "title": "Cross-View Geo-Localization via Learning Disentangled Geometric Layout Correspondence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae6bbeb670a0211bc2426b9afd867f8afb72e751",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25458": {
    "title": "Video Compression Artifact Reduction by Fusing Motion Compensation and Global Context in a Swin-CNN Based Parallel Architecture",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63b3c5e3c6b15394743f9bb423ac2082b2443d24",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25459": {
    "title": "MRCN: A Novel Modality Restitution and Compensation Network for Visible-Infrared Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ddd0cff0f7f959c324f9bb157f045302c66690ca",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25460": {
    "title": "A Simple Baseline for Multi-Camera 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0226ed79f7b9efe06adfd0c093228a354bc5197",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25461": {
    "title": "Positional Label for Self-Supervised Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "9ea9e48950e311387c177b5195782c8c324ac119",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25462": {
    "title": "Cross-Category Highlight Detection via Feature Decomposition and Modality Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45de3c9f58933d5ba67dbc9d4cc0266dc11eddf2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25463": {
    "title": "TrEP: Transformer-Based Evidential Prediction for Pedestrian Intention with Uncertainty",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e9e8ed0ee97296c638329a30643c2456d95e944e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25464": {
    "title": "DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f13d4d12d924727114182da54980a04be051fc87",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25465": {
    "title": "ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ae2e3d5682e755d560c34b05169a9660660f055",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25466": {
    "title": "Combating Unknown Bias with Effective Bias-Conflicting Scoring and Gradient Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5dc689a4d6827b5a441c50cb56c14d19b027d9f7",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25467": {
    "title": "RLogist: Fast Observation Strategy on Whole-Slide Images with Deep Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63195e3d637c2725913fc2fd999e3e3ae40362e4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25468": {
    "title": "Learning to Super-resolve Dynamic Scenes for Neuromorphic Spike Camera",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98528cb319f7939749cafff8d1ff08823641c009",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25469": {
    "title": "TinyNeRF: Towards 100 x Compression of Voxel Radiance Fields",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8f13253a047f76c5e9ee275d27b70274dfe2758",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25470": {
    "title": "BEST: BERT Pre-training for Sign Language Recognition with Coupling Tokenization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "919efc30ab8c45456ab72fb4ebeb5e25f2ad7642",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25471": {
    "title": "MulGT: Multi-Task Graph-Transformer with Task-Aware Knowledge Injection and Domain Knowledge-Driven Pooling for Whole Slide Image Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10968bcb3e19eb3cbd137af1bf4b82ad1c04378c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25472": {
    "title": "Grouped Knowledge Distillation for Deep Face Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68ed8b94df543dba73a619980d1c5a3fcde417a5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25473": {
    "title": "Style-Content Metric Learning for Multidomain Remote Sensing Object Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2fbd355ed0cf0bb57a3bfea9b3f12cc1e180d701",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25474": {
    "title": "Occupancy Planes for Single-View RGB-D Human Reconstruction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dde7f2b5b925c7edb8ef9c5aabc1f679a6b6c104",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25475": {
    "title": "Deep Equilibrium Models for Snapshot Compressive Imaging",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68bcc213f88a5ee875f7061cdc192cb5b4ad9832",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25476": {
    "title": "Unsupervised Deep Video Denoising with Untrained Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8132f60124089fd50fe2afbd3e60e73b05ef65e1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25477": {
    "title": "Attack Can Benefit: An Adversarial Approach to Recognizing Facial Expressions under Noisy Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4266bba4e036807378abb05b2a9ebe7063c13a94",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25478": {
    "title": "Phrase-Level Temporal Relationship Mining for Temporal Sentence Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4f70d5bdd5293b7fc53831624971fef83873d3f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25479": {
    "title": "Learning Semantic Degradation-Aware Guidance for Recognition-Driven Unsupervised Low-Light Image Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "00d66e7384eb46a290595bf54d62c2a614f8734d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25480": {
    "title": "Memory-Aided Contrastive Consensus Learning for Co-salient Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ec9799fba2f8e71a48c7606d1c725f2e2a30095",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25481": {
    "title": "MaskBooster: End-to-End Self-Training for Sparsely Supervised Instance Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc3fab136f5ee45103bad37eebafa1581781560d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25482": {
    "title": "RSPT: Reconstruct Surroundings and Predict Trajectory for Generalizable Active Object Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "0a21061ddf9c41b71c8d7b409f7dd97b18a5cd8b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25483": {
    "title": "STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d20d1d3ec1199c35d13e60351b358ac1e317401",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25484": {
    "title": "Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "154f9eb2f97cae3a7752cbc4e0261eb4e75008d4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25485": {
    "title": "Aesthetically Relevant Image Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15d6ef576fb07bb5fc07fef6f63708e440396dd9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25486": {
    "title": "Polarization-Aware Low-Light Image Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1956f7770663fc45d9035278e39eb14fefcdd76a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25487": {
    "title": "Progressive Bayesian Inference for Scribble-Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a506fdeb24c051732d7c0aa74ae99db3cedbd0f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25488": {
    "title": "Exploratory Inference Learning for Scribble Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ff5db744e5eefb95e17afd59260efbb3a78756c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25489": {
    "title": "Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "965a0ff397ff33dbb9ee9a5b725472af4ffe0892",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25490": {
    "title": "Unsupervised Hierarchical Domain Adaptation for Adverse Weather Optical Flow",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cd9aae06d5720908760b47e46516adcb9a89f03f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25491": {
    "title": "PASS: Patch Automatic Skip Scheme for Efficient Real-Time Video Perception on Edge Devices",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ebb9f49e940bdd14925a9776998244ad8aa74b57",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25492": {
    "title": "Robust Feature Rectification of Pretrained Vision Models for Object Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1d4ddca6c68ed963763711f545844557d6085b8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25493": {
    "title": "Video Object of Interest Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "21c088c0620f6bf9d7699c9547af47318257df7a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25494": {
    "title": "Tree-Structured Trajectory Encoding for Vision-and-Language Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "293951f26d10fed6950b2949e0f90571e0d67cd6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25495": {
    "title": "Self-Supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "185e0240f15d84f805d36ed30f70ebd6e85be2b4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25496": {
    "title": "Debiased Fine-Tuning for Vision-Language Models by Prompt Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8b73abefd998229f35e810f465854bdea7512f8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25497": {
    "title": "Improving Scene Text Image Super-resolution via Dual Prior Modulation Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e45d243316096cfc709e96027ebb2d353475ede6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25498": {
    "title": "SRoUDA: Meta Self-Training for Robust Unsupervised Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a7ab69f162e706901c6aa1e391004971a463a3a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25499": {
    "title": "Gradient-Based Graph Attention for Scene Text Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "30db786f5810602af4680dc4372c265e4597666e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25500": {
    "title": "RGBD1K: A Large-Scale Dataset and Benchmark for RGB-D Object Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b52382b22d25dd63c2a68424304e39024bf6e15f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25501": {
    "title": "Learn More for Food Recognition via Progressive Self-Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a332ce333d52d85ff6bb74dec4a7c7b15bff0f66",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25502": {
    "title": "Generative Image Inpainting with Segmentation Confusion Adversarial Training and Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65f5f5d54bde99776de1840e7cd59d30bbf74390",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25503": {
    "title": "Improved Algorithms for Maximum Satisfiability and Its Special Cases",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8e39247da25bb69cd9ceae1c5c5d0d4c354dd47",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25504": {
    "title": "Lifting (D)QBF Preprocessing and Solving Techniques to (D)SSAT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ae0b1ba9c743ad04020efe39e1237a5cbc7b1f5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25505": {
    "title": "NuWLS: Improving Local Search for (Weighted) Partial MaxSAT by New Weighting Techniques",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68d54d627cfaa914d277a3f4a5508de1c4abe4ef",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25506": {
    "title": "Separate but Equal: Equality in Belief Propagation for Single Cycle Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "276906bc63d919a9d576b80786c42254be84a0c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25507": {
    "title": "Complexity of Reasoning with Cardinality Minimality Conditions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "225a18fc8ae50641c5da8171cd11d00a428d32c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25508": {
    "title": "DASH: A Distributed and Parallelizable Algorithm for Size-Constrained Submodular Maximization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e912edd7f1b82df95cc569ef73cf602bf7118ea8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25509": {
    "title": "SharpSSAT: A Witness-Generating Stochastic Boolean Satisfiability Solver",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d9e4474d023987ed4c5f409176fe870db873ca85",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25510": {
    "title": "Submodular Maximization under the Intersection of Matroid and Knapsack Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d8f527c2046fcf50d9418d4d694d86c4601ac7ff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25511": {
    "title": "A Framework to Design Approximation Algorithms for Finding Diverse Solutions in Combinatorial Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "807cfcbca58e27d087a913be5c2481e524aeb7f9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25512": {
    "title": "An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-Sourcing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc8beb173d4dad28357d848b2240d560b81f39f3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25513": {
    "title": "Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0c94f185099505025b5b2ee94aa567409cdaf19",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25514": {
    "title": "Solving Explainability Queries with Quantification: The Case of Feature Relevancy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "622657250ba771cb4af66f7e54868314b777bbd4",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25515": {
    "title": "Second-Order Quantified Boolean Logic",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "84c64c851b2bbaa8533258b16dee807a25f52cbe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25516": {
    "title": "Learning Markov Random Fields for Combinatorial Structures via Sampling through Lovsz Local Lemma",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cd51ce7bb450a1e8bbf3727db6b809ca45b13518",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25517": {
    "title": "Fast Converging Anytime Model Counting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1fc7323bb9f59f444be47e1624e31320e417f6b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25518": {
    "title": "Finding Good Partial Assignments during Restart-Based Branch and Bound Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51870d8e06dff589258700debae3f69dc993772b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25519": {
    "title": "Hybrid Learning with New Value Function for the Maximum Common Induced Subgraph Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dd2f352795968d59bd82169a5c5c9547b054f9e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25520": {
    "title": "Self-Supervised Primal-Dual Learning for Constrained Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27171044552454edcbd1d6a20ac0714ee3c46686",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25521": {
    "title": "Reinforcement Learning for Branch-and-Bound Optimisation Using Retrospective Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3212c957a11a46d059e981826372914045f5cc4a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25522": {
    "title": "Constraint Optimization over Semirings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "39fdccb34c7eae74dac974354db59d0ca48fc8c0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25523": {
    "title": "Generalized Confidence Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7ed381fb10c3178120b182c5e4e70fb89791f466",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25524": {
    "title": "Circuit Minimization with QBF-Based Exact Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "25f369e3318ba4ee373a5dcf2c7234e37b4ba2c8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25525": {
    "title": "Probabilistic Generalization of Backdoor Trees with Application to SAT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b0738a5a45dee62b540b60b9bb33a82e41f8a12",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25526": {
    "title": "The Expressive Power of Ad-Hoc Constraints for Modelling CSPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7e5501bfb07b6f3535263caf90d59a21724e510",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25527": {
    "title": "Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcbda9002def84b4b4467e54e1d06a18ac227103",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25528": {
    "title": "Eliminating the Impossible, Whatever Remains Must Be True: On Extracting and Applying Background Knowledge in the Context of Formal Explanations",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25529": {
    "title": "Farsighted Probabilistic Sampling: A General Strategy for Boosting Local Search MaxSAT Solvers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "56c858b81ce04d884a711a70a0b40d5f9f166beb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25530": {
    "title": "LANCER: A Lifetime-Aware News Recommender System",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23627f20f53611a39a5df35642f99d3007863496",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25531": {
    "title": "Win-Win: A Privacy-Preserving Federated Framework for Dual-Target Cross-Domain Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4fcda17617d3887eb657d017bc15017fc7b3641c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25532": {
    "title": "Enhanced Multi-Relationships Integration Graph Convolutional Network for Inferring Substitutable and Complementary Items",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fa0090adfbc80de8dcc82c8d094ce800f674b094",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25533": {
    "title": "PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "57a13f7f82a11887af3baceda506e2c579d7466d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25534": {
    "title": "End-to-End Entity Linking with Hierarchical Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aec8eed33a7f9195ba0925c798e6431702d22e1a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25535": {
    "title": "Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10d949dee482aeea1cab8b42c326d0dbf0505de3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25536": {
    "title": "Dual Low-Rank Graph Autoencoder for Semantic and Topological Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7adc0b3b0a87de6f57cffcd3f6133cf1041214a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25537": {
    "title": "Dynamic Multi-Behavior Sequence Modeling for Next Item Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b838508bcc1f591b7db00dabe19678fe8b0b3ce0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25538": {
    "title": "Learning Representations of Bi-level Knowledge Graphs for Reasoning beyond Link Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cce3bb3d79c8c6e6f1b6b825f444a98d12f30833",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25539": {
    "title": "Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7b7bfdc2936f09b09943d78d7b4d596f27e3274b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25540": {
    "title": "Uniform Sequence Better: Time Interval Aware Data Augmentation for Sequential Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "614938bed58a2e496cfc373b2f70f11462506131",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25541": {
    "title": "Rule Induction in Knowledge Graphs Using Linear Programming",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8169e28b81bce7e4fb878a3935d44829035ae2d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25542": {
    "title": "Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fab6048fc657ec13d4a59fe21b823ecd0ab0b95",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25543": {
    "title": "DAMix: Exploiting Deep Autoregressive Model Zoo for Improving Lossless Compression Generalization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8467d3032147d2d3508b2f98e09aea566d8a03e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25544": {
    "title": "Soft Target-Enhanced Matching Framework for Deep Entity Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6894a73276a06f6093c23d4320d7fae2b09f4a54",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25545": {
    "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "688a20c88a022febbd7432c5231963235d4729bd",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25546": {
    "title": "Contrastive Pre-training with Adversarial Perturbations for Check-In Sequence Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d75010b4a317f6ea5a9a26bae72505b22cb8d134",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25547": {
    "title": "MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3fd66f10b978d44e063aa23c64cdfe98722a3812",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25548": {
    "title": "Generic and Dynamic Graph Representation Learning for Crowd Flow Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a9a358cf2e3f85fa7f286e392bfb0ad232c109e5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25549": {
    "title": "Conditional Diffusion Based on Discrete Graph Structures for Molecular Graph Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "67b5d57c08176787ae7b54b65ae3bf0ac11b9b04",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25550": {
    "title": "SAH: Shifting-Aware Asymmetric Hashing for Reverse k Maximum Inner Product Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "e76548be2a8c67f437daee555bc7b246c540de42",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25551": {
    "title": "Learned Distributed Image Compression with Multi-Scale Patch Matching in Feature Domain",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "102a0f62845c3e2c351969bb210bbdc1dbc9ed6d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25552": {
    "title": "Constrained Market Share Maximization by Signal-Guided Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d1cbfd0ab6880a5fe0f5ce95e7d4a3072955839",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25553": {
    "title": "T2-GNN: Graph Neural Networks for Graphs with Incomplete Features and Structure via Teacher-Student Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9b17f8d306e0e8264830394229e38c5d79b77523",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25554": {
    "title": "Detecting Sources of Healthcare Associated Infections",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0a7b41426bbae754e4ff50dd2dad0741b199a15",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25555": {
    "title": "Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "abf773ddd5cb8f42a20e77effcf7e1f826991d42",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25556": {
    "title": "PDFormer: Propagation Delay-Aware Dynamic Long-Range Transformer for Traffic Flow Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38381097a0add12ff685dfaac0191c31c9ae429a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25557": {
    "title": "Continuous Trajectory Generation Based on Two-Stage GAN",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ba316f5916807fd0b49b54452f7216c366208e1e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25558": {
    "title": "Let Graph Be the Go Board: Gradient-Free Node Injection Attack for Graph Neural Networks via Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b494763868d078aa306c1f1b3f7c21ffd83feac",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25559": {
    "title": "GLCC: A General Framework for Graph-Level Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cbcf89becf091e3abdf86f692fc3150f0dab33a9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25560": {
    "title": "Parameterized Algorithms for Colored Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2dfe8538b77cdccf89434f1091463dd1c0db9caa",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25561": {
    "title": "Towards Reliable Item Sampling for Recommendation Evaluation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8fdb76a8fdc41eacf3c2c87a9f3d1dba9cc0e068",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25562": {
    "title": "Multiple Robust Learning for Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50ba1ee99c52448b0abdc0143315449fa4f5664b",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25563": {
    "title": "Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "be8e35b1753cc7aed92767db46b99289997af62d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25564": {
    "title": "Adaptive Low-Precision Training for Embeddings in Click-Through Rate Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "624c0373019dabb9f5b69464c0f094013c2b101c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25565": {
    "title": "Signed Laplacian Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23141437bffed6d5457c676bff0b59adf6d64a9a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25566": {
    "title": "PPGenCDR: A Stable and Robust Framework for Privacy-Preserving Cross-Domain Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "370cacdf83aa10e60d79025fad336ac467eb415e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25567": {
    "title": "COLA: Improving Conversational Recommender Systems by Collaborative Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d02536f52b22c303e902f1a5e34ac8cfeb56a293",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25568": {
    "title": "Scalable and Effective Conductance-Based Graph Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05930e5e7684c05fe1461f404bda10434ca143f4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25569": {
    "title": "Multi-Domain Generalized Graph Meta Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ae83395b9ca551e0efd74fac10551e396974040",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25570": {
    "title": "IterDE: An Iterative Knowledge Distillation Framework for Knowledge Graph Embeddings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a400be3a281ac5f0a30df63d224f00bdaad2ad8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25571": {
    "title": "Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cc9d031ca2f85c1412d5eab9449416c47b8cacd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25572": {
    "title": "Low-Resource Personal Attribute Prediction from Conversations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "f1e588f1fc1e6456c7ec14a984c630ef58f8df9c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25573": {
    "title": "Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b29aec89e64bb20f2b963e5615c79b9008ecfd88",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25574": {
    "title": "On Generalized Degree Fairness in Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6c26e7f14b52332087c9a1e07e09a2b882665ef3",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25575": {
    "title": "Time Series Contrastive Learning with Information-Aware Augmentations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6e70a2b7512fde9d25176c508f9cad35e47f66ad",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25576": {
    "title": "NQE: N-ary Query Embedding for Complex Query Answering over Hyper-Relational Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d94e7aeab88d07f0b50b7866ceb5baa3c29be859",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25577": {
    "title": "FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4af58fc20efaa3856df8609921b6a022f8f9d3ac",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25578": {
    "title": "GMDNet: A Graph-Based Mixture Density Network for Estimating Packages' Multimodal Travel Time Distribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a9d4820dee3d1de377a7ba16223653701ba726e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25579": {
    "title": "Logic and Commonsense-Guided Temporal Knowledge Graph Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e0a7f3f98e49d0a690842a5692e723615c44928",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25580": {
    "title": "Graph Structure Learning on User Mobility Data for Social Relationship Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cca56116eea606d1be0dd258f03f4c3c679c065a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25581": {
    "title": "Online Random Feature Forests for Learning in Varying Feature Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4482de2f9d3ff6b74d774c9a67a9d6cf5fa5fc59",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25582": {
    "title": "Scaling Law for Recommendation Models: Towards General-Purpose User Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7567744a0e23174166575e8d98590967684696b4",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25583": {
    "title": "Cross-Domain Adaptative Learning for Online Advertisement Customer Lifetime Value Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "562f254f7b0fccba6377a513fc95cbbb4bf80ee7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25584": {
    "title": "Self-Supervised Interest Transfer Network via Prototypical Contrastive Learning for Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09aedbfbc314006bac8e7cead1b838439705f449",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25585": {
    "title": "Opinion Optimization in Directed Social Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a4984e10597e3c8a77f1675a48eb7dc6d5252e72",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25586": {
    "title": "Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6796467c5662e07f5f7bbd685f6a9c59cfbf99ec",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25587": {
    "title": "Self-Organization Preserved Graph Structure Learning with Principle of Relevant Information",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b501be9cac69f1fa58ef2887017d0dd94d233b68",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25588": {
    "title": "Efficient Embeddings of Logical Variables for Query Answering over Incomplete Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d275bb20b36926e039fb604f9fb93340a70e63c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25589": {
    "title": "Human-Instructed Deep Hierarchical Generative Learning for Automated Urban Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3480471572fd3908e72cf827b3e4ca532f286fc5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25590": {
    "title": "Easy Begun Is Half Done: Spatial-Temporal Graph Modeling with ST-Curriculum Dropout",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e07be0014393a4a8c9521e49bc640074c78b6333",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25591": {
    "title": "Cross-Domain Graph Anomaly Detection via Anomaly-Aware Contrastive Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c310a633d4fe1b3be759588656c0763cacc4071e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25592": {
    "title": "WSiP: Wave Superposition Inspired Pooling for Dynamic Interactions-Aware Trajectory Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ded88b250761f197a5a8b7f225c6f914cc6b49fd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25593": {
    "title": "Beyond Graph Convolutional Network: An Interpretable Regularizer-Centered Optimization Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4239fce31468d3188ce9baed53280051da19c494",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25594": {
    "title": "Augmenting Affective Dependency Graph via Iterative Incongruity Graph Learning for Sarcasm Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f50f7e50573876fde5e9ae714ffb95354b68a0bb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25595": {
    "title": "Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "26ebeeb1b9172df34ad21f1000bb6f3c374a222e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25596": {
    "title": "Online Semi-supervised Learning with Mix-Typed Streaming Features",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c5e68be7506eadf90435539490f6b75343eb7347",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25597": {
    "title": "Few-Shot Composition Learning for Image Retrieval with Prompt Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "510f41c71a8751832cc97d79a0df673a0c2b0539",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25598": {
    "title": "ConTextual Masked Auto-Encoder for Dense Passage Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63a38cb55e0b9f91c0676efd79089debe61c7768",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25599": {
    "title": "Jointly Imputing Multi-View Data with Optimal Transport",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "781fad0aaf23ca028fa35ba7ad8b3a97d349052b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25600": {
    "title": "Knowledge Graph Embedding by Normalizing Flows",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e3cdedd8c2ce304fdfe861f3c2f4c68e85c9aed",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25601": {
    "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "22157f0bcde877743dc95715cf570d672f76520a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25602": {
    "title": "SCI: A Spectrum Concentrated Implicit Neural Compression for Biomedical Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d589135b7cc3019a2170676d69b1a4c1505e775c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25603": {
    "title": "Unsupervised Legal Evidence Retrieval via Contrastive Learning with Approximate Aggregated Positive",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc8ba45e69cd4073e43926a7abd8403236f8870b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25604": {
    "title": "One-for-All: Proposal Masked Cross-Class Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e29734b4945611c4eeb49bd176086881e71ba25a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25605": {
    "title": "Analogical Inference Enhanced Knowledge Graph Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "354b651dbc3ba2af4c3785ccbecd3df0585d30b2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25606": {
    "title": "A Noise-Tolerant Differentiable Learning Approach for Single Occurrence Regular Expression with Interleaving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2764258ec19ed233f2871574f31f90e587cdac01",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25607": {
    "title": "Learning from the Wisdom of Crowds: Exploiting Similar Sessions for Session Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "163252e0a3de4b60382e158f0447c647782b591c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25608": {
    "title": "Next POI Recommendation with Dynamic Graph and Explicit Dependency",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b54d3c2e7d971ae03017b0ae196d4abc61c920ce",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25609": {
    "title": "Predicting Temporal Sets with Simplified Fully Connected Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9c59365254eed5fa64cc9b44c29a23760dc01de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25610": {
    "title": "Learning to Count Isomorphisms with Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "674e14227bd9aacb41a02fb195951ddddd30cd66",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25611": {
    "title": "Untargeted Attack against Federated Recommendation Systems via Poisonous Item Embeddings and the Defense",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77f1d71efcfc733fa9efcdb7492d1310185b0de6",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25612": {
    "title": "Practical Cross-System Shilling Attacks with Limited Access to Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c81c5307175bc683b096496ff44fdb6419ae18ae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25613": {
    "title": "Query-Aware Quantization for Maximum Inner Product Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8e74644b3d1b92037b478303df0860591a030fd3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25614": {
    "title": "TOTTopology-Aware Optimal Transport for Multimodal Hate Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "c90d18d5cd8b1e07f8a8b6b9d14a85b03d55b4b6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25615": {
    "title": "Cross-Domain Few-Shot Graph Classification with a Reinforced Task Coordinator",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12313819cdb18f6e11da1a449a087220810bdd99",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25616": {
    "title": "AutoSTL: Automated Spatio-Temporal Multi-Task Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "64ff803d5256b6b48c74ac5229db4c7a864172a7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25617": {
    "title": "Fair Representation Learning for Recommendation: A Mutual Information Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef720e1b70188ef7f31f73a6940229d7e7dce73b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25618": {
    "title": "Deep Graph Structural Infomax",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c38be73c2e17cd2a0f808fe6ae008c1f248fa989",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25619": {
    "title": "Causal Conditional Hidden Markov Model for Multimodal Traffic Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4472361e74e441a1539251868e077884c7b7042",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25620": {
    "title": "ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1305bbd54db0345533906726e3425f742312c55",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25621": {
    "title": "A Provable Framework of Learning Graph Embeddings via Summarization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc4bf8864aff1d41ad76d677714ea21606b290c4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25622": {
    "title": "GraphSR: A Data Augmentation Algorithm for Imbalanced Node Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "296049ee701634e7919b8f334da285ca7c54bfba",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25623": {
    "title": "Detecting Multivariate Time Series Anomalies with Zero Known Label",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ba2f8dfc1a4fccec80cf95ce3f0eeff3066f21e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25624": {
    "title": "GRLSTM: Trajectory Similarity Computation with Graph-Based Residual LSTM",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "48402bec037fc2a5033c4dc7f90733b7e86da446",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25625": {
    "title": "Heterogeneous Region Embedding with Prompt Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c6f266b833aa65bc8014f8cd052b823929ca2c1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25626": {
    "title": "Show Me the Way! Bilevel Search for Synthesizing Programmatic Strategies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a9f5132f22418f4c3eec95521dc7d3fb959b4f3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25627": {
    "title": "Anytime User Engagement Prediction in Information Cascades for Arbitrary Observation Periods",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c538e5cfc2c908bf833f8453c72f82a63465a26b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25628": {
    "title": "Principled Data-Driven Decision Support for Cyber-Forensic Investigations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36c3e9fce1e1eec51cea57ec5ebc339ba0e11e2c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25629": {
    "title": "BETA-CD: A Bayesian Meta-Learned Cognitive Diagnosis Framework for Personalized Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44deaf38f9a4b9a0c274fbc4acc5ace2d6f06c01",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25630": {
    "title": "Set-to-Sequence Ranking-Based Concept-Aware Learning Path Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a2ac894fad19b6c8bd0984ed5e205d63376cdb7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25631": {
    "title": "Unsupervised Deep Embedded Fusion Representation of Single-Cell Transcriptomics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "79bbb02ade124c82c663b5f1ee9ef9fdce0d4f6d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25632": {
    "title": "Constrained Submodular Optimization for Vaccine Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ded91f056e1d073029b662d69b1847e1cc1060e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25633": {
    "title": "Flow-Based Robust Watermarking with Invertible Noise Layer for Black-Box Distortions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9be90c6279e4133c7b2891bb5513b417da490857",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25634": {
    "title": "Identifying and Eliminating Majority Illusion in Social Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2195aff9d693a39c92c469cd64aef681b6716ad7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25635": {
    "title": "A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention Mechanism for Symbolic Music Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aec9ae3c0e5a5784e171dbb7aa58c209de89e404",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25636": {
    "title": "MSDC: Exploiting Multi-State Power Consumption in Non-intrusive Load Monitoring Based on a Dual-CNN Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c238db86fc92dbd85544f4c89c3c82cf008d06e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25637": {
    "title": "Integrating Reward Maximization and Population Estimation: Sequential Decision-Making for Internal Revenue Service Audit Selection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e17ba7c1a91e51070a308039ef53f0deec2cee2a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25638": {
    "title": "MGTCF: Multi-Generator Tropical Cyclone Forecasting with Heterogeneous Meteorological Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8651b010f8615d6dacd089f510b222e434c46f28",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25639": {
    "title": "MDM: Molecular Diffusion Model for 3D Molecule Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "161858efd41df44a826feb52c27f29eaf8bce80d",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25640": {
    "title": "Learning Chemical Rules of Retrosynthesis with Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cbe75ef6748e461d18f964d99ea7f4e8f8d539a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25641": {
    "title": "Online Symbolic Regression with Informative Query",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b3eee07ad5e785d9d6124a08cce985fe034c83bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25642": {
    "title": "Repair Is Nearly Generation: Multilingual Program Repair with LLMs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "453a8fac3be9282be53908f0735160d0d21e0f48",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25643": {
    "title": "Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef7ef2cb643acb5bba3e8c249d0663ee1a4d8108",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25644": {
    "title": "Rolling Horizon Based Temporal Decomposition for the Offline Pickup and Delivery Problem with Time Windows",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "02aeb1c12b95530cd5381d13e0bc9edb121dba4b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25645": {
    "title": "GRIP: Graph Representation of Immune Repertoire Using Graph Neural Network and Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a15c413c629113dde457ffdf10d9a55b76e35a43",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25646": {
    "title": "LagNet: Deep Lagrangian Mechanics for Plug-and-Play Molecular Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a422712a543a43b3c64be2505aa8435333270b1d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25647": {
    "title": "Steganography of Steganographic Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a672ec588ce8c11ef7b68ee8585ccf5766e7827",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25648": {
    "title": "PEN: Prediction-Explanation Network to Forecast Stock Price Movement with Better Explainability",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3901de60ef6fc8f73d0720bd76b0918254d22613",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25649": {
    "title": "Decision-Making Context Interaction Network for Click-Through Rate Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "608632865430a81e20528a57bff20cecc4f3ce1b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25650": {
    "title": "Fine-Grained Position Helps Memorizing More, a Novel Music Compound Transformer Model with Feature Interaction Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "79efb734cef71f93ad4c875044f9fb4d2cd6079d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25651": {
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "376345572946f8710e265e10be270373587d4c4e",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25652": {
    "title": "On Manipulating Weight Predictions in Signed Weighted Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6cf75aa820ccfbb7b07f80ceb4bc446f879ce65a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25653": {
    "title": "Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65f86451e96ad61ffca50eed6a007a19bc03093d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25654": {
    "title": "MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31a84391e1b47fa15f3a521c43d62385a7757637",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25655": {
    "title": "HG-SL: Jointly Learning of Global and Local User Spreading Behavior for Fake News Early Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3c6898458ee72eb35276a1244049b17f5f9be5c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25656": {
    "title": "Defending against Backdoor Attacks in Natural Language Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "834891acb1dfeacb9ff75f923feeca66347167d7",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25657": {
    "title": "GenLive! Generating Rhythm Actions in Love Live!",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27c4f8efcc548e74983c165f99b6711ec1c0699d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25658": {
    "title": "Deepfake Video Detection via Facial Action Dependencies Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3e269034ebfc94da52d2133239114046c8c12ae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25659": {
    "title": "Contrastive Attention Networks for Attribution of Early Modern Print",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d9dc309f719233be9f2a6b6910072e537f96eec8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25660": {
    "title": "AdapSafe: Adaptive and Safe-Certified Deep Reinforcement Learning-Based Frequency Control for Carbon-Neutral Power Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "11389a70e115c21169f365f3e944f517cebfe555",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25661": {
    "title": "Don't Predict Counterfactual Values, Predict Expected Values Instead",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "88d1fc95d1d8452d1cbb41b07fa0829e62f1fb66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25662": {
    "title": "Molformer: Motif-Based Transformer on 3D Heterogeneous Molecular Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "540ed994eb00b5279748d1f26d04371e3a67ec0d",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25663": {
    "title": "DiffMD: A Geometric Diffusion Model for Molecular Dynamics Simulations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6fe2208f1c4dba1c9959f2dd4fdb6c2dc245b713",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25664": {
    "title": "Retrosynthesis Prediction with Local Template Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7045e1e30c2eb8f305dcb8ded655ff659f53fefd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25665": {
    "title": "Multi-Relational Contrastive Learning Graph Neural Network for Drug-Drug Interaction Event Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0ba58a80635fad308adfa41d76931c4f73ba8c54",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25666": {
    "title": "Tighter Robust Upper Bounds for Options via No-Regret Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b764a3ccd99b4bbac95d5f321eb4ad1ac4173224",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25667": {
    "title": "KerPrint: Local-Global Knowledge Graph Enhanced Diagnosis Prediction for Retrospective and Prospective Interpretations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2b5eef580fb9fa9e0f9d946feb2819ad63eb011a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25668": {
    "title": "Multi-Label Few-Shot ICD Coding as Autoregressive Generation with Prompt",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b87c9700b8de4912fe7c361574640b5dc536ca9",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25669": {
    "title": "DMIS: Dynamic Mesh-Based Importance Sampling for Training Physics-Informed Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45017fc77acd06a13d231900f548806bf804beb5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25670": {
    "title": "Bootstrapping Multi-View Representations for Fake News Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38ff6bae846d70d341c8732717c0f593180f318b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25671": {
    "title": "Overcoming Forgetting in Fine-Grained Urban Flow Inference via Adaptive Knowledge Replay",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "54eec69dadad0093b38be8488968e7786a5fb376",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25672": {
    "title": "Generalized Cell Type Annotation and Discovery for Single-Cell RNA-Seq Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7ca5419b63753fbb249860d45a66cbc4052397bd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25673": {
    "title": "Mining and Applying Composition Knowledge of Dance Moves for Style-Concentrated Dance Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b1574e3fff207020073b54b7367f2da80f64740b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25674": {
    "title": "Yet Another Traffic Classifier: A Masked Autoencoder Based Traffic Transformer with Multi-Level Flow Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ba78edb48d729339b109b1ae707daafcca8e005",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25675": {
    "title": "Loan Fraud Users Detection in Online Lending Leveraging Multiple Data Views",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5631b6811a2cff4d35aea151398154a929da8b24",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25676": {
    "title": "Sparse Maximum Margin Learning from Multimodal Human Behavioral Patterns",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4150ac3683f5bb310a409c280123238e0da701f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25677": {
    "title": "Direct Heterogeneous Causal Learning for Resource Allocation Problems in Marketing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1ca2cce6c8e53488983a89bccfe34c976202f7b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25678": {
    "title": "Mediated Cheap Talk Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "b379528382393126720280c848f45bb9aa9db0e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25679": {
    "title": "Bidding Graph Games with Partially-Observable Budgets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cf7c118beeca6e1ed555164151a084a6286a8dc9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25680": {
    "title": "Fairness Concepts for Indivisible Items with Externalities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f92552c73d2b67e671fec7d5fced0f2195dc0502",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25681": {
    "title": "Finding Fair Allocations under Budget Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51e020d339e00afca58dc703ef91d217d00ea869",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25682": {
    "title": "Now We're Talking: Better Deliberation Groups through Submodular Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aead5a64ee1ef40829300401debe649772d7c26c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25683": {
    "title": "Causes of Stability in Dynamic Coalition Formation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d1664faf020d247b8b0a9cc775fb11152a6c38dc",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25684": {
    "title": "Properties of Position Matrices and Their Elections",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0eafc75d4dd73a9491dd031e54af5b048936b83a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25685": {
    "title": "Rank Aggregation Using Scoring Rules",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36814dc10e6f759c87520b080a6dd339f74c32be",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25686": {
    "title": "Proportionality in Approval-Based Participatory Budgeting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c4aed0f334de39822ece80507b83786f9dbc60f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25687": {
    "title": "Multiwinner Voting with Possibly Unavailable Candidates",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c15f4da85b4d487ffed1b9c731f8411551a8a856",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25688": {
    "title": "Fair Division with Prioritized Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e2eb9aa34c5d218e195a5c9f7706a5be895081e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25689": {
    "title": "Topological Distance Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31cc4da32ba25ce18bace942361fd8eff3fad994",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25690": {
    "title": "Game Implementation: What Are the Obstructions?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bbe7f2e5001559daa2f06b99c7cf5456966953e5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25691": {
    "title": "A Pair-Approximation Method for Modelling the Dynamics of Multi-Agent Stochastic Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ab178e4e4389cc2578617dec3186c313b4a35cb2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25692": {
    "title": "Complexity of Probabilistic Inference in Random Dichotomous Hedonic Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "153d83340025647e8dc36945478cd4ff4eda043e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25693": {
    "title": "Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare Optimality at Equilibrium and Optimal Deviation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7780bfd2cc56a38d0cf34edf88f7be79e9d25dd2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25694": {
    "title": "Strategyproofness and Proportionality in Party-Approval Multiwinner Elections",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3f3c8d4ad8a89239bbd9b2d31a6c54cb396d3930",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25695": {
    "title": "Tight Inapproximability for Graphical Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca20eb26ec877f403db50049252511e47741c23f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25696": {
    "title": "From Monopoly to Competition: Optimal Contests Prevail",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a0108111588f59d44689c7162e930fec1d1701d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25697": {
    "title": "Commitment Games with Conditional Information Disclosure",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "54226bde1774d6a113ad871445775a84962aab35",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25698": {
    "title": "Rawlsian Fairness in Online Bipartite Matching: Two-Sided, Group, and Individual",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e31ff605e3db3449e0c999998365f6c95c2767e6",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25699": {
    "title": "Participatory Budgeting Designs for the Real World",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "183f37a03ca82e44a6468baa7e464c013e892011",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25700": {
    "title": "PAC Learning and Stabilizing Hedonic Games: Towards a Unifying Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27a17341f41c0af03606f43f56cba72b32ffbf94",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25701": {
    "title": "Scalable Edge Blocking Algorithms for Defending Active Directory Style Attack Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c67df2dc35e8d99dc419fbc138bbc1fab579f51",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25702": {
    "title": "Representation with Incomplete Votes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ae0490ac110effedd47d13eeb1e71d33f31da47",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25703": {
    "title": "Optimizing Multiple Simultaneous Objectives for Voting and Facility Location",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0cf0244be1a0ed9d761742614adec024bfa3469",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25704": {
    "title": "Class Fairness in Online Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "462c81b0c6b03df11b4bfa0f0345e100e3b33fbc",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25705": {
    "title": "How to Cut a Discrete Cake Fairly",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "555d80712ae5fcef4b319c3ba0265171cad33768",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25706": {
    "title": "Competition, Alignment, and Equilibria in Digital Marketplaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a2b3696dab23be25c8cda81490c54c5e6ea53c6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25707": {
    "title": "Voting with Preference Intensities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f161bcb249a2ce6a2c97b5d4a93184d89ff39fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25708": {
    "title": "Approximations for Indivisible Concave Allocations with Applications to Nash Welfare Maximization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bd29605b3a91f1d1166a42514a5c96a6d577ccdd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25709": {
    "title": "Strategic Facility Location with Clients That Minimize Total Waiting Time",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a22b3b66794a0d2e06f57753b555b82ee006e591",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25710": {
    "title": "Proportional Decisions in Perpetual Voting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a21a5610157afb24f4a3229f31adea835f507ca2",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25711": {
    "title": "Multiagent MST Cover: Pleasing All Optimally via a Simple Voting Rule",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c8e78fea7189e12c1778fc110852253b0f1ccca4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25712": {
    "title": "When Congestion Games Meet Mobile Crowdsourcing: Selective Information Disclosure",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2310aaa5d2e3cf9d47b1168cd4a560a144cbf28a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25713": {
    "title": "Partitioning Friends Fairly",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fdc1d82b449862d77dbaf26b4d007c80cd74434",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25714": {
    "title": "Differentially Private Condorcet Voting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31d165e97e8e2c13fe3b3dc55e0e338491633b9a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25715": {
    "title": "Function Approximation for Solving Stackelberg Equilibrium in Large Perfect Information Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9f8ff18066b6de9249c76a23d4a8d265bc08ce5b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25716": {
    "title": "Optimal Pricing Schemes for Identical Items with Time-Sensitive Buyers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ed19cfe4e0dcad4e45f6fe90fe62875dd851378",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25717": {
    "title": "Approval-Based Voting with Mixed Goods",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ddf61206194976246e3498899a3e56c0623f606",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25718": {
    "title": "Utility Maximizer or Value Maximizer: Mechanism Design for Mixed Bidders in Online Advertising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed2c8a88b17172d3169a5b86fc83e05807639b4b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25719": {
    "title": "Facility Location Games with Entrance Fees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3fc4bde395cfbcf0c3b3ddb0c47fd41d696a9d2e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25720": {
    "title": "Securing Lifelines: Safe Delivery of Critical Services in Areas with Volatile Security Situation via a Stackelberg Game Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9222a8fd12e782e07425db00b085a52824fa62d2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25721": {
    "title": "Differentially Private Fair Division",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3828d5639e3967d199a0cd6d8a5c2aa434a30ba1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25722": {
    "title": "An Efficient Deep Reinforcement Learning Algorithm for Solving Imperfect Information Extensive-Form Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7674101bb85b2fc228d7a6c8b4eace078a8ba381",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25723": {
    "title": "Fast and Interpretable Dynamics for Fisher Markets via Block-Coordinate Updates",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "92841069ddd8ea9c3d9a8e46121430540382aa72",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25724": {
    "title": "Ballot Length in Instant Runoff Voting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "73a36bafe6953371e71d22e011b6aff726e6afab",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25725": {
    "title": "Multi-Stage Facility Location Problems with Transient Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcc51879ceb777063f697f1f5ae0050d273932c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25726": {
    "title": "Bayesian Optimization-Based Combinatorial Assignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ec31c7e532b18a5c1724a34689baba35e050c0e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25727": {
    "title": "Semi-random Impossibilities of Condorcet Criterion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e642adacb243f5448c31072e9c68f05905840848",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25728": {
    "title": "Tournament Fixing Parameterized by Feedback Vertex Set Number Is FPT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "058d26b18a3b230e81fd4259aa2c903b01d93f1c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25729": {
    "title": "Truthful Mechanisms for Steiner Tree Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b2b230df548eef82aa4ed60aa6aa0af29fc0d42",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25730": {
    "title": "Collusion-Proof and Sybil-Proof Reward Mechanisms for Query Incentive Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8459e8869b782ded45ef762d728642d3919ae075",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25731": {
    "title": "Fisher Markets with Social Influence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "189e54a3a2e519bfaa65e33b1d3a35fa0ba2122a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25732": {
    "title": "Probably Approximate Shapley Fairness with Applications in Machine Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6a83c55042d4c48b4cd17b37b8a6991f69d51e6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25733": {
    "title": "The Perils of Trial-and-Error Reward Design: Misdesign through Overfitting and Invalid Task Specifications",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "688fc1e744877c3a68f306443042f016196ce98a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25734": {
    "title": "The Value of AI Guidance in Human Examination of Synthetically-Generated Faces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f02ec8381a96bf00f691fdddc28bc6dfbb8a5780",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25735": {
    "title": "Teaching to Learn: Sequential Teaching of Learners with Internal States",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fa00fa4c018d90f2597d9e5b9a5fd2ee17896f9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25736": {
    "title": "Interactive Concept Bottleneck Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cc7508c4168e8583a9971115117b552479c5f24",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25737": {
    "title": "Local Justice and Machine Learning: Modeling and Inferring Dynamic Ethical Preferences toward Allocations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6dc75e20e8146182e7076450841bbb8c2f70935a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25738": {
    "title": "Extracting Semantic-Dynamic Features for Long-Term Stable Brain Computer Interface",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae324c30938b1c7a871c2de5104cd5a780e52d71",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25739": {
    "title": "Moral Machine or Tyranny of the Majority?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d655026a443d3de40ebacf61274e562ec05936ef",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25740": {
    "title": "The Effect of Modeling Human Rationality Level on Learning Rewards from Multiple Feedback Types",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e920f426eb32e64474b2a1176d97725f875dd82a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25741": {
    "title": "The Role of Heuristics and Biases during Complex Choices with an AI Teammate",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4006f4acbcd0f97b0f4763b1dc1404ad923cfabd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25742": {
    "title": "Learning to Defer with Limited Expert Predictions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "740ea8d58050d823ed4e6bdc89e7b136ada80b26",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25743": {
    "title": "SWL-Adapt: An Unsupervised Domain Adaptation Model with Sample Weight Learning for Cross-User Wearable Human Activity Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e5306c39f2d88c7d479fbd08ae630af7239b5e56",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25744": {
    "title": "Incentive-Boosted Federated Crowdsourcing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4368aa571b71165d19dc08ae1f589296207e144",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25745": {
    "title": "Towards Voice Reconstruction from EEG during Imagined Speech",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c6b97adc9fc7a6619d43b269a9e3dc2321df8f03",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25746": {
    "title": "Evaluating and Improving Interactions with Hazy Oracles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcfcac9943a67748c8f5831272a6ad545b78bcb0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25747": {
    "title": "Human-in-the-Loop Vehicle ReID",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8f5a0db120e6fa63e3555d6e84e4809cb0666de",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25748": {
    "title": "Modeling Human Trust and Reliance in AI-Assisted Decision Making: A Markovian Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7fbdc22ac13f0e1944262379bc1b41d188cc0b5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25749": {
    "title": "Learning Deep Hierarchical Features with Spatial Regularization for One-Class Facial Expression Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "02aa368f27c539415b555b2c01ce037e5ff6b2ec",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25750": {
    "title": "Frustratingly Easy Truth Discovery",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "3dc5c5e420a2bcdb75e98ca55a033b83bea36618",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25751": {
    "title": "Beam Search Optimized Batch Bayesian Active Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d1e41e2de8e79735b0f1302ac28544bdd450ac6e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25752": {
    "title": "Multi-Scale Control Signal-Aware Transformer for Motion Synthesis without Phase",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4c4ee8e1a92e0eda686c3bd80d25c5785c57ed28",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25753": {
    "title": "SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "040c9807983131ad611b3a927e63b1267a37986d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25754": {
    "title": "Human Joint Kinematics Diffusion-Refinement for Stochastic Motion Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "34f622243804ba15e29f1a22a8898eb4cf33772d",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25755": {
    "title": "Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e6c44fa97a3871eb67467cfac40fb6cf56f104d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25756": {
    "title": "Learning to Select Pivotal Samples for Meta Re-weighting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e5e1ef8e856596df92fb65c4459052109014398",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25757": {
    "title": "Better Peer Grading through Bayesian Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c58cd28fbb8ad552b402582d32b068d7aa9452b7",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25758": {
    "title": "Maximum Entropy Population-Based Training for Zero-Shot Human-AI Coordination",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "4270f2493dfd9ae26b9f7c707cf1398ddbbdc0a1",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25759": {
    "title": "A Set of Control Points Conditioned Pedestrian Trajectory Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c6eef90065c8c35e6051e80478c993b48a783e8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25760": {
    "title": "Meta-Auxiliary Learning for Adaptive Human Pose Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "390a927e0c70bdc3e3a327dc8f18a0a90b9f82b9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25761": {
    "title": "Moving-Landmark Assisted Distributed Learning Based Decentralized Cooperative Localization (DL-DCL) with Fault Tolerance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0bf16ee9abecd5fba62b89f9fa29c0d2b6422157",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25762": {
    "title": "Periodic Multi-Agent Path Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "94ccc03294726ad795c0379bf7059aa377ed3b22",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25763": {
    "title": "Improving Robotic Tactile Localization Super-resolution via Spatiotemporal Continuity Learning and Overlapping Air Chambers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "58d73309807f7811722dda39d5867548337e0412",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25764": {
    "title": "Co-imitation: Learning Design and Behaviour by Imitation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "854a3a3212d33a9a05bd498874cfa3ddb0232535",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25765": {
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "08c1b87c94e741c09985d37872c1ae14c6c7c2e4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25766": {
    "title": "Abstract Argumentation Framework with Conditional Preferences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed43175c3bd2e197de2eb4558528c09017c23c17",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25767": {
    "title": "Reactive Synthesis of Dominant Strategies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68d20218ac2adae05d799f9b2ea25d8598a1075f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25768": {
    "title": "Complexity of Safety and coSafety Fragments of Linear Temporal Logic",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "11057109ab2652f228d944be6f77c566e86a34e6",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25769": {
    "title": "Automatically Verifying Expressive Epistemic Properties of Programs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ba6cfee1efd0cddec2e744b12f0cca7e76ad3e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25770": {
    "title": "The Effect of Preferences in Abstract Argumentation under a Claim-Centric View",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3971d26cf23d95487e333384a3cb58bfe26dbd32",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25771": {
    "title": "The Parameterized Complexity of Network Microaggregation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "35f9b5d2e666a7139be61e30a939885917e2a844",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25772": {
    "title": "SMT Safety Verification of Ontology-Based Processes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c191ecb6c77ad9c74d6aba0f68f628436ecc6b69",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25773": {
    "title": "Epistemic Disjunctive Datalog for Querying Knowledge Bases",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "716ff41912617caddd2b4386a1071f5ad7249679",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25774": {
    "title": "Learning Logic Programs by Discovering Where Not to Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f7bcdc6e791173001b25acdd3f98b8cc44a7fd69",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25775": {
    "title": "From Width-Based Model Checking to Width-Based Automated Theorem Proving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b112e2d1f4876f58190322b6496cfa1011736e4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25776": {
    "title": "Model-Checking for Ability-Based Logics with Constrained Plans",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0d9dee80c3177e67cd3e678a9c92ad6beac31b0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25777": {
    "title": "A Structural Complexity Analysis of Synchronous Dynamical Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91704981d91f327d3304eea20d75f318b969448e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25778": {
    "title": "Evaluating Epistemic Logic Programs via Answer Set Programming with Quantifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c27c2a50eb30d1b292b4ef1827532bd7c0d76106",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25779": {
    "title": "Reachability Games Modulo Theories with a Bounded Safety Player",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8e6d4933293895540519b1c31645456da9f94e28",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25780": {
    "title": "Splitting Answer Set Programs with Respect to Intensionality Statements",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d0725ae29843fdd48075d7c4f228440b377be45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25781": {
    "title": "Monitoring Arithmetic Temporal Properties on Finite Traces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "441f1b0d50a6e16de8794c1a3154405acfd40559",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25782": {
    "title": "Untangled: A Complete Dynamic Topological Logic",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9bb88a92bf5b3e4bd9813c9a85e6e2d95916311f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25783": {
    "title": "Inconsistent Cores for ASP: The Perks and Perils of Non-monotonicity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cdd45ffb85a3b654d49983f3f8d98075c8aa83f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25784": {
    "title": "General Acyclicity and Cyclicity Notions for the Disjunctive Skolem Chase",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "56a6b99fe7d331e20786cbfedf2c96651539d59c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25785": {
    "title": "GANTEE: Generative Adversarial Network for Taxonomy Enterance Evaluation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "25db8a16e39af2aea2bc2dea7aab1862b04a9b7c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25786": {
    "title": "Finite Based Contraction and Expansion via Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53097257a9bb71b1af91da5d99c211311b0476da",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25787": {
    "title": "MAPS-KB: A Million-Scale Probabilistic Simile Knowledge Base",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "83ab9f2fdb2d7445f8b72b732fe17f9e21603082",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25788": {
    "title": "Characterizing Structural Hardness of Logic Programs: What Makes Cycles and Reachability Hard for Treewidth?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "adbce6d521643cb25c30dc0ffb9d0d0080e7a92c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25789": {
    "title": "Conditional Syntax Splitting for Non-monotonic Inference Operators",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e10984c1c2ac697c49222a118a4cadeffa93f57d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25790": {
    "title": "Relational Program Synthesis with Numerical Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c150adaab6e5887ef9ceae25214076468f42534e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25791": {
    "title": "Common Knowledge of Abstract Groups",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e7f497d35a06594fe2722946a0ed8539b3342817",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25792": {
    "title": "FASTDIAGP: An Algorithm for Parallelized Direct Diagnosis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "349899ad280bcff77e39689df88e0fc7de852a2d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25793": {
    "title": "Two Views of Constrained Differential Privacy: Belief Revision and Update",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc06e5d3cf4ac73f5b6786ac296f9fec15026800",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25794": {
    "title": "Copyright-Certified Distillation Dataset: Distilling One Million Coins into One Bitcoin with Your Private Key",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05cad00486c1ab88452d9b355477851e1bca9075",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25795": {
    "title": "DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link Prediction and Entity Typing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc26b544e5bbdd149d6e52ab6e3fe155684829a2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25796": {
    "title": "Automated Verification of Propositional Agent Abstraction for Classical Planning via CTLK Model Checking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "072f7b74cf9bf19d6b498aed1aeb23ece57cc1e9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25797": {
    "title": "Efficient Answer Enumeration in Description Logics with Functional Roles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "22eddbaef959961c58ec8b23ea5920c2a1fc75de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25798": {
    "title": "Distributed Spectrum-Based Fault Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "28ac25147389c16bf5ea4d0fdaa3b1d7bd4f8cea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25799": {
    "title": "Multi-Level Wavelet Mapping Correlation for Statistical Dependence Measurement: Methodology and Performance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61a6c57d88c71dffc1cd0b9ee9a424fa4f5a84b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25800": {
    "title": "Learning Interpretable Temporal Properties from Positive Examples Only",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "713bf335895f27fa0f08a3366cb9f74ad8523d01",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25801": {
    "title": "Editing Boolean Classifiers: A Belief Change Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f7d7e2906b9de71b55a36e155e430c80771df3c0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25802": {
    "title": "Implementing Bounded Revision via Lexicographic Revision and C-revision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "37defded961bbaa40a5a2e4b2e7a4d64fc810761",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25803": {
    "title": "Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4020f2736d49368fc38b3f0c59c6f8b90e29e355",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25804": {
    "title": "Learning to Break Symmetries for Efficient Optimization in Answer Set Programming",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "520d96e06afb9ab0ad9afc3f3a6c31b3fae3d6de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25805": {
    "title": "On Undisputed Sets in Abstract Argumentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a0d92572c348b42c3cdbc7b8ab2c44d0ba8b5a00",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25806": {
    "title": "Neurosymbolic Reasoning and Learning with Restricted Boltzmann Machines",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b1d4dd5f407f08295bc5d9865f5b48bff3d67df",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25807": {
    "title": "Materialisation-Based Reasoning in DatalogMTL with Bounded Intervals",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d4a432b0cc0a5d488915053536af171eb4bd6055",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25808": {
    "title": "Efficient Extraction of EL-Ontology Deductive Modules",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d45b678c6e09dcff3928d060e28e5d621d28272",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25809": {
    "title": "Visually Grounded Commonsense Knowledge Acquisition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03c4ecc2796ecde6a93562fdd149cea10157f805",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25810": {
    "title": "DNG: Taxonomy Expansion by Exploring the Intrinsic Directed Structure on Non-gaussian Space",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5db9df997254ab379f195d7ad494e7ccbab4d91d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25811": {
    "title": "Quality-Aware Self-Training on Differentiable Synthesis of Rare Relational Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bbf8add6afcfba8be55b92dc94dad68d34db6594",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25812": {
    "title": "Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10bbe48c262a4fcf666bf93855bfd3cafb9f71f7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25813": {
    "title": "McOmet: Multimodal Fusion Transformer for Physical Audiovisual Commonsense Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4cf34a7c4b622f48047df066d8be23f8984fbf09",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25814": {
    "title": "Approximating Full Conformal Prediction at Scale via Influence Functions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b29b6315506a0db2cd39cb9faee82c2e8cc0105b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25815": {
    "title": "Efficient Distributed Inference of Deep Neural Networks via Restructuring and Pruning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4850283e7220666b04ee78d43bdc0db38032271",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25816": {
    "title": "Symbolic Metamodels for Interpreting Black-Boxes Using Primitive Functions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b457b163f3e2ffd700918ed8e52d8c18c1115b21",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25817": {
    "title": "Utilizing Prior Solutions for Reward Shaping and Composition in Entropy-Regularized Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3098fd3d604086202f51aee3b5e6071639908be1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25818": {
    "title": "Clustering What Matters: Optimal Approximation for Clustering with Outliers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "443ed32448436d6710b875911c6944bde47a35cf",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25819": {
    "title": "Contrastive Classification and Representation Learning with Probabilistic Interpretation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5afecbef7a28dd25117bc00db3594a8e95968941",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25820": {
    "title": "Simulating Network Paths with Recurrent Buffering Units",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f2bc5f497daf770914737e1c2ad5ed5046a46bbe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25821": {
    "title": "Fully Dynamic Online Selection through Online Contention Resolution Schemes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a1a3675308d7b38e5b02d1b09031d84f4bf39c44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25822": {
    "title": "Tree Learning: Optimal Sample Complexity and Algorithms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c4e7659c6d577ae7c1cac0d49daba5e28a7efce",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25823": {
    "title": "Meta-Learning for Simple Regret Minimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4160cce636c0f5b40ff004a1489a9ad790e46e94",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25824": {
    "title": "Generalizing Downsampling from Regular Data to Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5de89665d72d63932c993fe5dec8dc0a9f21f9c1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25825": {
    "title": "PiCor: Multi-Task Deep Reinforcement Learning with Policy Correction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ad17af39d0bfcc2498df27dc51de85adfac97704",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25826": {
    "title": "Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72a305df18fe9010374504bce7c0ec485809b7c3",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25827": {
    "title": "Optimal Sparse Recovery with Decision Stumps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a4be3bc405aa5a003e44f1efd2715a1384abf22",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25828": {
    "title": "Towards Efficient and Domain-Agnostic Evasion Attack with High-Dimensional Categorical Inputs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b1e1cc7d450895d4f947c86d123e3e560fa7eff9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25829": {
    "title": "Fairness and Welfare Quantification for Regret in Multi-Armed Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4470ac0408e958123758f424f85105efdf71fa3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25830": {
    "title": "Alternating Layered Variational Quantum Circuits Can Be Classically Optimized Efficiently Using Classical Shadows",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0499cb8e5a94768e79b577c83fb464b5557d46f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25831": {
    "title": "Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0955cd4702c745d6a93bb5edef64ca143358467",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25832": {
    "title": "Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45693b1fa3c1fcb89a67827fd63b45f0bacf0185",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25833": {
    "title": "Sustaining Fairness via Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1583c318a4b7f97df7c6ab9a55878bd12788a8e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25834": {
    "title": "Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2aeafb78c9fead00f0fe9c8f655ccf0b82bf0390",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25835": {
    "title": "An Improved Algorithm for Online Min-Sum Set Cover",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0317a6788b14e4adf34fdced4826c6ca556b0dae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25836": {
    "title": "AutoInit: Analytic Signal-Preserving Weight Initialization for Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f42e704bbb28331cf1eee2b09f41bcfc0815483e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25837": {
    "title": "A Parameterized Theory of PAC Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "26b394a90119f8ee2a9820d92cc28780c600cca7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25838": {
    "title": "Fully-Dynamic Decision Trees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4b94b06d0b0e12a84c83ee644d3627961715e197",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25839": {
    "title": "Scalable Theory-Driven Regularization of Scene Graph Generation Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4411c40c4ab7133a1811704428377b43b178b77",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25840": {
    "title": "Toward a Perspectivist Turn in Ground Truthing for Predictive Computing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "75802e1d48ac47d96808e2c9605a17ac1dd07345",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25841": {
    "title": "Semantic-Enhanced Image Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef95ed000d71c4b4d3dbddec448c258b210b1402",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25842": {
    "title": "RePreM: Representation Pre-training with Masked Model for Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1b6c1822cc273bc452eb0b3dfbe14de53dd10681",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25843": {
    "title": "FTM: A Frame-Level Timeline Modeling Method for Temporal Graph Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c1a2d4fa243981f3e8af8b37b449a4488b810acd",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25844": {
    "title": "Estimating Treatment Effects from Irregular Time Series Observations with Hidden Confounders",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "896e5cee54d50d7a1f981823b4627948610d72a5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25845": {
    "title": "InParformer: Evolutionary Decomposition Transformers with Interactive Parallel Attention for Long-Term Time Series Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4c0842b95cfaf5591790d9de1cccb4ddde155aa7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25846": {
    "title": "Meta-Sketch: A Neural Data Structure for Estimating Item Frequencies of Data Streams",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6f279bb6ec61f3c5cafb4cd9c7c4e62c2768df3a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25847": {
    "title": "Unfooling Perturbation-Based Post Hoc Explainers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17101501b13b57f6627cf1d6f557375051e21afd",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25848": {
    "title": "Very Fast, Approximate Counterfactual Explanations for Decision Forests",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f7544bfd25ae5baefe62ce3973d368f1c4b2fa70",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25849": {
    "title": "An Equivalence Analysis of Binary Quantification Methods",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1a4131e72b4adfaf3290e27a29e904f0be341e6e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25850": {
    "title": "Soft Action Priors: Towards Robust Policy Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5815a68809dbedb72515cf930f6011761c8d8ea8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25851": {
    "title": "Invariant Representations with Stochastically Quantized Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "550f29904da2ccab4a3211349aa56cb4172a80d0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25852": {
    "title": "Learning Pessimism for Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4729d7b34c60de21fc5f7c9e0e9525936f644ca6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25853": {
    "title": "Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98241cf085a52c5761278ea8eb6c51cffa3a9d38",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25854": {
    "title": "NHITS: Neural Hierarchical Interpolation for Time Series Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "597811b2fa8f5155202a08226acde69efaf1eefb",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25855": {
    "title": "Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for Movement Forecasting in Badminton",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b965a2f6173c1365a492ae6103206bed2be9820",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25856": {
    "title": "Graph Ordering Attention Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "509c7f6ec4ae7d33006f9c5e9c174f61a43df598",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25857": {
    "title": "Scalable and Globally Optimal Generalized L K-center Clustering via Constraint Generation in Mixed Integer Linear Programming",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed0ae2814794c9d86de2d2c04a2aee9cabcc01b5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25858": {
    "title": "Attribute and Structure Preserving Graph Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8730e5e6aec81f191f162d9a621ffe18cabaac82",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25859": {
    "title": "On the Stability and Generalization of Triplet Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c39f3752591181899f680644e8f6ce77cc5a8e3e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25860": {
    "title": "CF-ViT: A General Coarse-to-Fine Method for Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed00842931ebb0db2c634330a77c8dee6f77e547",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25861": {
    "title": "Context-Aware Safe Medication Recommendations with Molecular Graph and DDI Graph Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "795cb7f144184139a0198b99083ecee62ff72991",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25862": {
    "title": "Min-Max Submodular Ranking for Multiple Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d45997fb96b394f4057118d2fb4caba2c9f3321",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25863": {
    "title": "Supervised Contrastive Few-Shot Learning for High-Frequency Time Series",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a2056f5affe509b50e41612057ca9cca143ef97a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25864": {
    "title": "The Sufficiency of Off-Policyness and Soft Clipping: PPO Is Still Insufficient according to an Off-Policy Measure",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a5b68ef4736e235aa596eb6728f284258e11d18",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25865": {
    "title": "Global Convergence of Two-Timescale Actor-Critic for Solving Linear Quadratic Regulator",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4b20c81a39d1ccc41f749f59dbb632e632135d7a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25866": {
    "title": "Topological Pooling on Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77d14bbaece056f5a94231f46f02cca86e9bc085",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25867": {
    "title": "Riemannian Local Mechanism for SPD Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc57be2a8ce6f6ae81bc53a80e9256e4340a6ef5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25868": {
    "title": "TC-DWA:Text Clustering with Dual Word-Level Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "e79fbed9d087f8905e4043108bcf8591f621f21c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25869": {
    "title": "Causal Inference with Conditional Instruments Using Deep Generative Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4f79230f60316394b9cda5896d594c6f4b0c9e37",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25870": {
    "title": "Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1497a56aa25a385e1d60e6a9c2fa60aa7bd17edd",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25871": {
    "title": "Partial-Label Regression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2959a6a949de79fee19c6340e93db35096902a07",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25872": {
    "title": "Offline Quantum Reinforcement Learning in a Conservative Manner",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d116ba398a85cd838618796a10638b9d56b58250",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25873": {
    "title": "Variational Wasserstein Barycenters with C-cyclical Monotonicity Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "556bc791f59b3bc8834960d473d4226957000824",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25874": {
    "title": "MobileTL: On-Device Transfer Learning with Inverted Residual Blocks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ac22b58453c227a560f5ec4527be9f1857ca64c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25875": {
    "title": "Learning Optimal Features via Partial Invariance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "26c61243f679b2cfb1edb4a8f95d1b44132c38f3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25876": {
    "title": "PrimeNet: Pre-training for Irregular Multivariate Time Series",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "70e5e9bd353d1b1e54b4eebd3a67b58026a13dff",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25877": {
    "title": "Structured BFGS Method for Optimal Doubly Stochastic Matrix Approximation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "593f9a54f6e53a0d1c1c19366521ca59e491d77c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25878": {
    "title": "On the Complexity of PAC Learning in Hilbert Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0138f1631efd6425f09f2457d667dbded41af7fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25879": {
    "title": "Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks Using an Incompetent Teacher",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "425669c368004dc43bebaa1d4acdd46a6bcca171",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25880": {
    "title": "Scalable Spatiotemporal Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e60dc704e7933e2a3e83512f345bba0debfe3f3",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25881": {
    "title": "Exploiting Multiple Abstractions in Episodic RL via Reward Shaping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "07e496c302ed32f6da6f535eb4b0f91b58169726",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25882": {
    "title": "Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of CountSketch to Adaptive Inputs",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25883": {
    "title": "Continuous Mixtures of Tractable Probabilistic Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7e257197e70b5979992fe7c69a7746bae0e184d",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25884": {
    "title": "End-to-End Learning for Optimization via Constraint-Enforcing Approximators",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b6e821d5841d5f2b688d610c3ca64ce4a3ee0c7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25885": {
    "title": "Practical Parallel Algorithms for Submodular Maximization Subject to a Knapsack Constraint with Nearly Optimal Adaptivity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5028562c146dd06b2a9aa8754496b86cb43de326",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25886": {
    "title": "Opposite Online Learning via Sequentially Integrated Stochastic Gradient Descent Estimators",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ba45a6c7b542b0b8e8458ea845854f57eaf96dcc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25887": {
    "title": "Contrastive Learning with the Feature Reconstruction Amplifier",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53901562d0ff14da779f35b6431a4bd836e4bfa5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25888": {
    "title": "Augmented Proximal Policy Optimization for Safe Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ee4efa8f7454770df0c43ce4d6fb65dd085fca5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25889": {
    "title": "GradPU: Positive-Unlabeled Learning via Gradient Penalty and Positive Upweighting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "88e55907283a62d93d4f9b18ab5ecb6f7595f3c7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25890": {
    "title": "Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "336d6ad9ddddbe6ed9a6520e01ba2e951a2f5650",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25891": {
    "title": "Tackling Data Heterogeneity in Federated Learning with Class Prototypes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61cbca5ac40ba71388c6d2235fa25a20014faec0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25892": {
    "title": "CrysGNN: Distilling Pre-trained Knowledge to Enhance Property Prediction for Crystalline Materials",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "4fc96ea53bc8c08bd184126869a22f039ca4dbfe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25893": {
    "title": "Non-reversible Parallel Tempering for Deep Posterior Approximation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "47340a5c393fdf682cb27f6c4ebd96984607e918",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25894": {
    "title": "Stability-Based Generalization Analysis of the Asynchronous Decentralized SGD",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8059c10fb5c16aa1afb5f1263c4f4a1cd689595",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25895": {
    "title": "Integer Subspace Differential Privacy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eccd5376c514492ea39a40720a78139467db024c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25896": {
    "title": "Black-Box Adversarial Attack on Time Series Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cf50e00f39010b3ab3f1f96de15223f5231c652",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25897": {
    "title": "C-NTPP: Learning Cluster-Aware Neural Temporal Point Process",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bf3aed71713f62e1e26971dbf36b920768ff4a71",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25898": {
    "title": "Eliciting Structural and Semantic Global Knowledge in Unsupervised Graph Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcb17372a0233719d84aca856c6147a01e2ba34f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25899": {
    "title": "Incremental Reinforcement Learning with Dual-Adaptive -Greedy Exploration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c1844cda42b3732a5576d05bb6e007eb1db00919",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25900": {
    "title": "Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09f0422754142a1a58182b8238f9cd1b242adab5",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25901": {
    "title": "Non-stationary Risk-Sensitive Reinforcement Learning: Near-Optimal Dynamic Regret, Adaptive Detection, and Separation Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "25457e352e553a89a76ed7fddb8aa9687094614e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25902": {
    "title": "SKDBERT: Compressing BERT via Stochastic Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3eaa17dafc8a86dc5eac9d5b46af248f3f2f6712",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25903": {
    "title": "Model-Based Offline Reinforcement Learning with Local Misspecification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3aa1eafd0198ef0f49f79ff376ac60b170bb10e0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25904": {
    "title": "Can Label-Specific Features Help Partial-Label Learning?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "635aaf49c94c29086a8bf67b4d7819d6c023226e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25905": {
    "title": "Interpreting Unfairness in Graph Neural Networks via Training Node Attribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ec568050b74edfdb7e463200daf42ba36663505c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25906": {
    "title": "Robust and Fast Measure of Information via Low-Rank Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "83838422effa238682d462396a5a251fabb079b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25907": {
    "title": "Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca590583797aad5bd5af7f2c8492a0b14da53810",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25908": {
    "title": "Diffeomorphic Information Neural Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "799b8695fb63c0ea41d9d4d77959b234cf4b4cb3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25909": {
    "title": "Combining Slow and Fast: Complementary Filtering for Dynamics Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8300094620aa145281956869ed7930250af0ad38",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25910": {
    "title": "Popularizing Fairness: Group Fairness and Individual Welfare",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9953d04e41a4a63f8391032a39ac3ee0e3109610",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25911": {
    "title": "FairFed: Enabling Group Fairness in Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5b8cd1183840c5717d2b7cdec298d65d6ec69c32",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25912": {
    "title": "Goal-Conditioned Generators of Deep Policies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "46af8550faab2e2b67fef7278eab0b581097e6ea",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25913": {
    "title": "Directed Acyclic Graph Structure Learning from Dynamic Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a0fb1b670f62ac1de989e5f3c439ef5114196892",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25914": {
    "title": "Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4366579b70e6c408e7fd621344bc869c1dda9d0f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25915": {
    "title": "Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "02657f902758c3b85146629fe4faa3feab0ea34f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25916": {
    "title": "Wasserstein Graph Distance Based on L1Approximated Tree Edit Distance between WeisfeilerLehman Subtrees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "a0ee7fda99777066554267a7c211aad9b8e1f4f2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25917": {
    "title": "Combinatorial Causal Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ab3e2e5a7ec0f0f994d468c017c10b5d9cf4c4c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25918": {
    "title": "Scalable Attributed-Graph Subspace Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b2d5c6b55d03dea1273462a0c8e5a8305da4173b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25919": {
    "title": "SigMaNet: One Laplacian to Rule Them All",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5a5ebfb550a3a949f99afcdabddb4f063f0db13f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25920": {
    "title": "Optimal Decision Diagrams for Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4da0660eb65e50c8e71d57110e118a9c70b3a2d0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25921": {
    "title": "Estimating Average Causal Effects from Patient Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fae41e2dded7f20f110a57c61dd0d1dbdd4c6a24",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25922": {
    "title": "Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "165503c48e553a5559190ce74cda823f4e166b54",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25923": {
    "title": "EffConv: Efficient Learning of Kernel Sizes for Convolution Layers of CNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "302dc87c74a8cb0c8491f1c29483693eb283df7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25924": {
    "title": "Fast Counterfactual Inference for History-Based Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80f2036ab4e76c86f69a63e77e000833853c2722",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25925": {
    "title": "Robust Causal Graph Representation Learning against Confounding Effects",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8a4c8b331abc0d5522fc5262595ff7d597c8a93b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25926": {
    "title": "Towards Decision-Friendly AUC: Learning Multi-Classifier with AUC",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31cdc5c5f6994192f0c93587dc3521428c8931a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25927": {
    "title": "Long-Tail Cross Modal Hashing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "181f5132f3a353c5bd320de91429bab04b6dbb2d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25928": {
    "title": "Handling Missing Data via Max-Entropy Regularized Graph Autoencoder",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cf0d2eb36235a15a4ad8e2b8d4cf363ff9a530b8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25929": {
    "title": "Reinforced Approximate Exploratory Data Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52055da99bb0fdad22f8c11b96ca69f0d3d7f9e1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25930": {
    "title": "Learning Program Synthesis for Integer Sequences from Scratch",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7658f56be043f2d883eaeaef40998d79cf15a26f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25931": {
    "title": "Semi-transductive Learning for Generalized Zero-Shot Sketch-Based Image Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "db7236a9c1d344fda071d003b49816e2d414b768",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25932": {
    "title": "Multi-Classifier Adversarial Optimization for Active Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc8f1fd3f350d1c243a8e6cc373d247b3f07ae40",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25933": {
    "title": "Differentially Private Heatmaps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a381bd5c4976f4a8aef5c2a884a1246d592265c7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25934": {
    "title": "DiFA: Differentiable Feature Acquisition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c18c34012cb678a0fd82c848283258bbf6c2f5bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25935": {
    "title": "Local Intrinsic Dimensional Entropy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5a4dc0635e88c7fe615aa38f7bcf1ef309d7ae16",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25936": {
    "title": "Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c545b21e71c7c51bb4cc1d94bedbf6d6fdd57639",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25937": {
    "title": "Adaptive Hierarchy-Branch Fusion for Online Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cbd86a65d38affa84976dbb968d89c58668c3bee",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25938": {
    "title": "Deep Latent Regularity Network for Modeling Stochastic Partial Differential Equations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3da11f998d7387aeced2945064f90f6af7074d1b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25939": {
    "title": "Dynamic Representation Learning with Temporal Point Processes for Higher-Order Interaction Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6eea9f9fb4f802c509f1cd698ff42f0e67ebf338",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25940": {
    "title": "An Adaptive Layer to Leverage Both Domain and Task Specific Information from Scarce Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91691c66df6bde3d134137dcdc61580503fe7ab9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25941": {
    "title": "Interpolating Graph Pair to Regularize Graph Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "19918de95fdfa9b6dafe5529dc746c0395baad44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25942": {
    "title": "Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "217e4ffcffa4107a38ced923086006b73e9399a4",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25943": {
    "title": "Self-Supervised Bidirectional Learning for Graph Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fcb7161eb81b82d533d410532ddffc871ab61830",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25944": {
    "title": "Boosting Graph Neural Networks via Adaptive Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "402125f4732ef1ec5974ac7513a63bf5b8414611",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25945": {
    "title": "Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dbe429e7edf790b26c0f117027dc2cddb8ab9815",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25946": {
    "title": "Discriminability and Transferability Estimation: A Bayesian Source Importance Estimation Approach for Multi-Source-Free Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1d25e3ff3c28f40bf65b467486d0862476f4e28b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25947": {
    "title": "Astromorphic Self-Repair of Neuromorphic Hardware Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a2d9d1e7e63561f3fe035e24f758f063233a54e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25948": {
    "title": "Estimating Regression Predictive Distributions with Sample Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3c78bda7118e5b887c960c47a0dd476fe782b54",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25949": {
    "title": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic Dimension",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "94f9a6982512e7a06b1cab477f2b06ec12bd86c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25950": {
    "title": "Safeguarded Learned Convex Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "201ee94316891a6659264c86d95438e9594c8431",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25951": {
    "title": "Improving Long-Horizon Imitation through Instruction Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "300bf71c102fe349a082482f791ba15795fe69cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25952": {
    "title": "Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs: Application to Seizure Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29a467cc939db1607061377fa551285481b8fa4c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25953": {
    "title": "Improving Pareto Front Learning via Multi-Sample Hypernetworks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c7f2a3ead7688c44b45fb48aa26bf60e6364199",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25954": {
    "title": "Towards Better Visualizing the Decision Basis of Networks via Unfold and Conquer Attribution Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ab28e10316c060589a2d4b02500b537e02900526",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25955": {
    "title": "Federated Robustness Propagation: Sharing Adversarial Robustness in Heterogeneous Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7dd25b1e9bce4d9bbb4aa8fb053d0c68da17a33",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25956": {
    "title": "Compressed Decentralized Learning of Conditional Mean Embedding Operators in Reproducing Kernel Hilbert Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d243063362a4b7fd481565d876040dddfef1597d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25957": {
    "title": "RLEKF: An Optimizer for Deep Potential with Ab Initio Accuracy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aaa3c21e1532a73835239e6d75a7951f0cf7e51a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25958": {
    "title": "Background-Mixed Augmentation for Weakly Supervised Change Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e4d8a2985ee177159ff2525aabd7415054b3374",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25959": {
    "title": "Enabling Knowledge Refinement upon New Concepts in Abductive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "970f85cd760979fc5cd70c78420481a2fc675e24",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25960": {
    "title": "Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "399c35dcde2eac017b875af1a21916a9ecb10434",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25961": {
    "title": "Reward-Biased Maximum Likelihood Estimation for Neural Contextual Bandits: A Distributional Learning Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cbf2ca54338251f762a5c548dd50554eeee9df97",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25962": {
    "title": "Learning Noise-Induced Reward Functions for Surpassing Demonstrations in Imitation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6e9f395ccc11296e291b137d31cd882b726258e5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25963": {
    "title": "XClusters: Explainability-First Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "42ce38afc731d63dfd6029eab11be492683dbfc7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25964": {
    "title": "Model-Based Reinforcement Learning with Multinomial Logistic Function Approximation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "139e16319cc2179853c440e9540c41200e3ddd3c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25965": {
    "title": "Fast Regularized Discrete Optimal Transport with Group-Sparse Regularizers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "172fb6a4ac8d0f0f4a9e8617c7babc6a16887d1f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25966": {
    "title": "Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ea9c6d13a8797257ee59429697bf31a41d1b9d2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25967": {
    "title": "Audio-Visual Contrastive Learning with Temporal Self-Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e475885c185b803ee025bc26c220c5736a5cfd5c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25968": {
    "title": "Confidence-Aware Training of Smoothed Classifiers for Certified Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d95ec70652b3afcfe263bce6e3ba2ccefff2381d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25969": {
    "title": "Learnable Path in Neural Controlled Differential Equations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f5bd94c41926c585157765b31943925cbe1b59ec",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25970": {
    "title": "DrugOOD: Out-of-Distribution Dataset Curator and Benchmark for AI-Aided Drug Discovery  a Focus on Affinity Prediction Problems with Noise Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "dcb21a5a0bc8b6d1bcfff10659e192a95ea20773",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25971": {
    "title": "MNER-QG: An End-to-End MRC Framework for Multimodal Named Entity Recognition with Query Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27937956a426872feace4b7c89cf892dbd75451d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25972": {
    "title": "Learning from Training Dynamics: Identifying Mislabeled Data beyond Manually Designed Features",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0858317aa3ebce7ebaae01be87f28925e49e51d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25973": {
    "title": "Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ab82ae37b7d27e79f59e624fa9419682c7cf8b8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25974": {
    "title": "Robust Domain Adaptation for Machine Reading Comprehension",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0a78f091fdfb5c77ab286400fac125ac8f46927",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25975": {
    "title": "Multi-View MOOC Quality Evaluation via Information-Aware Graph Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1997376d6922b84ca0f372cbb0b9a48596ea497d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25976": {
    "title": "Spatio-Temporal Meta-Graph Learning for Traffic Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12dd3ea6cd7041aef237f63c03a3e90fdc16897b",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25977": {
    "title": "Complement Sparsification: Low-Overhead Model Pruning for Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a8da6b76b6d4396e407973d236c7b7d282d7259",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25978": {
    "title": "Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "70de410aece38bf0d5d12fbf03815c80676be742",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25979": {
    "title": "Local-Global Defense against Unsupervised Adversarial Attacks on Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2235f0df7efa6571007c33c3a5f3ea4286be1b9a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25980": {
    "title": "Trafformer: Unify Time and Space in Traffic Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f98ce3517924c03ef82528fb05958934cb97d8d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25981": {
    "title": "On Solution Functions of Optimization: Universal Approximation and Covering Number Bounds",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1959e2743e7ff857957252dd3af836e0790253a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25982": {
    "title": "Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "647369ee45ecead812991f860caa8a96c6617063",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25983": {
    "title": "Knowledge-Constrained Answer Generation for Open-Ended Video Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0b19fd70c0a45355767473b671e0c2f4774d460",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25984": {
    "title": "POEM: Polarization of Embeddings for Domain-Invariant Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36747690b3dc56fc4479cddc1a9992c2c75fbb58",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25985": {
    "title": "An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7f36e9584a69c7cc38a0267f40c2a8e4645074b5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25986": {
    "title": "Towards More Robust Interpretation via Local Gradient Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a062076a5ff4af5f8e80905d51441779d2891cd7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25987": {
    "title": "Identifying Selection Bias from Observational Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca2820b5b7a877619744d3862401ad6e28478731",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25988": {
    "title": "PIXEL: Physics-Informed Cell Representations for Fast and Accurate PDE Solvers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "162ce23964f2aef2378297da1b20e08a8d77d000",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25989": {
    "title": "On the Sample Complexity of Vanilla Model-Based Offline Reinforcement Learning with Dependent Samples",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d96495c78401e645ee85e38ee042e6e3fc76bad3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25990": {
    "title": "Communication-Efficient Collaborative Best Arm Identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc178a8b1926588ffc179c5bd53edc95b5dcc0bf",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25991": {
    "title": "Variable-Based Calibration for Machine Learning Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45847e00891099b2fcdc7fb6d4d29852c5b30258",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25992": {
    "title": "Design Amortization for Bayesian Optimal Experimental Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "660195b1bc56862f1a781044527080fbe486032d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25993": {
    "title": "On Error and Compression Rates for Prototype Rules",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17422b058269f3b66a32b267a69b50e226796d84",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25994": {
    "title": "CertiFair: A Framework for Certified Global Fairness of Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a287e857f9a002c2d626228ecea6d375035ffd8",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25995": {
    "title": "Key Feature Replacement of In-Distribution Samples for Out-of-Distribution Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee507a5776a2b3c548f712f601ec5e515bd4f8d7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25996": {
    "title": "FLAME: Free-Form Language-Based Motion Synthesis & Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c17a983b11381fabb53f28066f76d4b2dc5a6a17",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25997": {
    "title": "Inverse-Reference Priors for Fisher Regularization of Bayesian Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b2caa2a9444341fc539283e86c5e68e7658e6d2b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25998": {
    "title": "Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38b933b515db9cdb834aaecd7f5a1c24e7be6af6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25999": {
    "title": "Better Generalized Few-Shot Learning Even without Base Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9255f7866199fadec7de87323ce27ca4c5603b6c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26000": {
    "title": "Learning Topology-Specific Experts for Molecular Property Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1604c2854370b9c6c9558b360c566f058ef33e7f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26001": {
    "title": "Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e97740f9ed9cfc7d27c95f3bd7aceb5691aff4be",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26002": {
    "title": "Exploring Temporal Information Dynamics in Spiking Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d7a33032b9cc1401c60ca856fa39c03b838836c1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26003": {
    "title": "FastAMI  a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "54b2c1035b4da593e62f6658a6e064a56c743c16",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26004": {
    "title": "A Gift from Label Smoothing: Robust Training with Adaptive Label Smoothing via Auxiliary Classifier under Label Noise",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18048fcf06e2f131d93dbc1a6c3708f0f188a344",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26005": {
    "title": "Grouping Matrix Based Graph Pooling with Adaptive Number of Clusters",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "c7bbe399aad2da39ba8f988fec83129d60aa5d52",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26006": {
    "title": "The Influence of Dimensions on the Complexity of Computing Decision Trees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65d6bee49cf1d2ebd40014dd53e96c7ab9842ee3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26007": {
    "title": "Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6eb9ecef16437bc76efbe0b016cea3bbdbf8f87",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26008": {
    "title": "Peeling the Onion: Hierarchical Reduction of Data Redundancy for Efficient Vision Transformer Training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a92d2c468835571f3302ce9299fdf37b36c2e367",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26009": {
    "title": "Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6143e809cd2e9c7a18c3bc8819419fd3b02fbcf2",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26010": {
    "title": "Almost Cost-Free Communication in Federated Best Arm Identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52382817395bb0c6b7c07e1d41dcb2ce7e30ea1a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26011": {
    "title": "UEQMS: UMAP Embedded Quick Mean Shift Algorithm for High Dimensional Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "507217edca49186856896dcf69d6bfbb4eef6d3d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26012": {
    "title": "The Effect of Diversity in Meta-Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "277e80c67e9dcc8572d73ff0cec5c22530df5f8a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26013": {
    "title": "Gradient Estimation for Binary Latent Variables via Gradient Variance Clipping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc95439462f741ac55ecf8f728aa7c67a41ac6fe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26014": {
    "title": "LoNe Sampler: Graph Node Embeddings by Coordinated Local Neighborhood Sampling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "56f676e55a306303863551beda729a6570aa3e30",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26015": {
    "title": "WLD-Reg: A Data-Dependent Within-Layer Diversity Regularizer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "86d12d692995538259706c383841349433712c72",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26016": {
    "title": "SpatialFormer: Semantic and Target Aware Attentions for Few-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74277b50e285dfaa0adbed61627c10f7ea168997",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26017": {
    "title": "A Data Source for Reasoning Embodied Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5c828011a508611df4d58cced9cc48d049dc4eb9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26018": {
    "title": "Generalization Bounds for Inductive Matrix Completion in Low-Noise Settings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e42259cf0ba53f6c072cadf52d471e943e021387",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26019": {
    "title": "I'm Me, We're Us, and I'm Us: Tri-directional Contrastive Learning on Hypergraphs",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26020": {
    "title": "Bespoke: A Block-Level Neural Network Optimization Framework for Low-Cost Deployment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb36afb336dff204652ef5dc39c9ce32353e48cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26021": {
    "title": "Time-Aware Random Walk Diffusion to Improve Dynamic Graph Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98293695c9f356ca1a5d667ff41d0287aef9a868",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26022": {
    "title": "Demystifying Randomly Initialized Networks for Evaluating Generative Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "67260931df4bda9bfd816da76dfbf0aafdaf47b0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26023": {
    "title": "Layer-Wise Adaptive Model Aggregation for Scalable Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f9a5d01f2ad2d044703dc50d63c233c5f91fe9a",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26024": {
    "title": "Goal-Conditioned Q-learning as Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "713f4ac842a83650c63e1e43b748fcb5a83bd22d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26025": {
    "title": "Optimism in Face of a Context:Regret Guarantees for Stochastic Contextual MDP",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "3c9ee60cf7e32e08b6f177ac1d104c3ea74c3c76",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26026": {
    "title": "Differentiable Meta Multigraph Search with Partial Message Propagation on Heterogeneous Information Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c42b9e01b1c908a059220f436db2db8dd9d07f11",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26027": {
    "title": "Learning Adversarially Robust Sparse Networks via Weight Reparameterization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72bd3ee3bc2628128e369bb1babd1c776c4f26ed",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26028": {
    "title": "ACE: Cooperative Multi-Agent Q-learning with Bidirectional Action-Dependency",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "48e556c2c67b7d05ea16ec0354bcc0372c927fbb",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26029": {
    "title": "When Online Learning Meets ODE: Learning without Forgetting on Variable Feature Space",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "42ee78b8ae50b905ba4d0b3127f609f100e7e689",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26030": {
    "title": "FanoutNet: A Neuralized PCB Fanout Automation Method Using Deep Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cfb571902b6dca6badfcdbe843add81f9fbba77",
    "citation_count": 0
  }
}