{
  "https://ojs.aaai.org/index.php/AAAI/article/view/25070": {
    "title": "Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "118fd51b49e4f344873b8246bb051afb66c0c8d9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25071": {
    "title": "Reducing ANN-SNN Conversion Error through Residual Membrane Potential",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "366a99da9ddef081aacd362d3da6668dfff04b2d",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25072": {
    "title": "Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "58f92031574529f13dfa8455c8bb539f43c722a0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25073": {
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "462b999f9e47915c89a0c70d797d3e82276f8410",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25074": {
    "title": "A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80df6f7525f24cce6d3d4c5f1a17566613a6f60d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25075": {
    "title": "A Machine with Short-Term, Episodic, and Semantic Memory Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d823694648cff737e14a613d5c743ac2b6cf39bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25076": {
    "title": "Persuasion Strategies in Advertisements",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1bd3def5257e992cecbcd5381771d77a95cc8200",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25077": {
    "title": "Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a78605f7d9372504eee3a0d9b86f0219a29d115",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25078": {
    "title": "AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4dbc668686f89830de4c67203db0709d9c4dda2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25079": {
    "title": "ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4e685992c8635225acabbe87d3900d104c9e78e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25080": {
    "title": "Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e09dc84599f5b9165eb38641ac7167b6fcfc450c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25081": {
    "title": "Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ced7e9eecfa29e4d5a4be0a2a649efd2ab119ed6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25082": {
    "title": "Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1126255b496a35ff2f04bfe33d6eedc765b649d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25083": {
    "title": "CMNet: Contrastive Magnification Network for Micro-Expression Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9ad4ac41b1ee5e150cb5adfc16b7c370d265d1c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25084": {
    "title": "Disentangling Reafferent Effects by Doing Nothing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6908360d349167eaec8c4007a56d84cea9397dc7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25085": {
    "title": "Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fbf899db663418a2fad1aa244e8d469d89138f0c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25086": {
    "title": "ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7fa2d8608e03c22ee025a27c7d6f81cc872735c6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25087": {
    "title": "Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6fbdc73ee62c32dc61cdddfb73410e1ec65cf35c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25088": {
    "title": "Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fc21e2c94cb2ed51809a9c96eccce810ef22520",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25089": {
    "title": "Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aed3b3d9809b0b3847d1853601eee97a9798257d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25090": {
    "title": "Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d7ce2e45a56c6cae56c4c9f0011f1ed739defc7",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25091": {
    "title": "Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef6fe11aa4b7dfec9f4d8da4e039f9c8d1839b0f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25092": {
    "title": "Layout Representation Learning with Spatial and Structural Hierarchies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f27d51387a1e00921c526cf0b44d8f41dc323e21",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25093": {
    "title": "Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ad6b3041cb994c57e26c4a8fe0203ffb1f0c8ea0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25094": {
    "title": "Multi-Level Compositional Reasoning for Interactive Instruction Following",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da804b058006e9b9ccda1776f437ceda9e869363",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25095": {
    "title": "Self-Supervised Image Local Forgery Detection by JPEG Compression Trace",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8d8f2834294897104e86f68a2f492058bfe5ccb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25096": {
    "title": "VASR: Visual Analogies of Situation Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b48eb1a32dcc4dcd122a5234c0fc055b71752e98",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25097": {
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b1f3354487bdc26a6eefef82960d085e9b78bb1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25098": {
    "title": "Explicit Invariant Feature Induced Cross-Domain Crowd Counting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7a2c9710df23afea3dfb8a7639fba8273c066cf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25099": {
    "title": "Painterly Image Harmonization in Dual Domains",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "04f9cc4d25baf7df5b14aa3e4bcdb91542f75d01",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25100": {
    "title": "MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cb09c77aab947c376df4fbcc4f2d877960f35d6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25101": {
    "title": "KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c407b4721a7aab2b198d73b373c53edfd5604d5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25102": {
    "title": "Deconstructed Generation-Based Zero-Shot Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50b3996ca86a55f9d3af68cb43c79659b1429daa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25103": {
    "title": "Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ef69136aa88675e3cf8aa33d87931d44a0615b2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25104": {
    "title": "Amodal Instance Segmentation via Prior-Guided Expansion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c9b776483a0de5d919842c05b48c029a78b7399",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25105": {
    "title": "SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d874861ec9f6b58166dcfcf05caf7a4a6bd032c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25106": {
    "title": "Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e7f81eb842623b41dd0bb09334506e148b076e66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25107": {
    "title": "Improving Dynamic HDR Imaging with Fusion Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1aea87fb6d103ecfc92b309b8c9ff9f10df47b7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25108": {
    "title": "Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b10dd9f4a5dfcc782c0a0892d43fea21cbb2eaea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25109": {
    "title": "Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dbb56d48ec9efeacf1d4dd31b76e23d5fb2c84b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25110": {
    "title": "Scalable Spatial Memory for Scene Rendering and Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "532cb7ca76a0e4f4993eae3e0cd31be73bd7e117",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25111": {
    "title": "Hybrid CNN-Transformer Feature Fusion for Single Image Deraining",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44c091514f3397740a1cbe72f86b53f2f409bc5b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25112": {
    "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d60265ea72d0344e991e71dfb13b4e1f15d4d4d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25113": {
    "title": "Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e9525ebe76a1d37533539ad2f560b1b453e66f6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25114": {
    "title": "DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "13d8ce3d2ac01cc5e108c1b89e79049428a53ad5",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25115": {
    "title": "Imperceptible Adversarial Attack via Invertible Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85af65c9355dc1ff8585354e014543751b498ee3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25116": {
    "title": "Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e0e103a2a1ed0241df544928d09d2a6b55c766e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25117": {
    "title": "User-Controllable Arbitrary Style Transfer via Entropy Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7dc98ae2967d6ad9c115ccaa705540b7489e0d40",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25118": {
    "title": "Neural Architecture Search for Wide Spectrum Adversarial Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3eb76059d9115f2f746b06dfcde7f8137147c59",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25119": {
    "title": "Adversarial Alignment for Source Free Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "693a942fa34028de582d18642d73d57c70842303",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25120": {
    "title": "Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "39dfc2eeb83e8694b1adc0b484775e9d47fee37a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25121": {
    "title": "OctFormer: Efficient Octree-Based Transformer for Point Cloud Compression with Local Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7acd42a6df03f98b6760c2f22b2bd2ce90695a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25122": {
    "title": "Dual-Domain Attention for Image Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ea2350d2bbafc07267d45aac410985376a6a332",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25123": {
    "title": "Multi-Resolution Monocular Depth Map Fusion by Self-Supervised Gradient-Based Composition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1527361af4eff8d52914a9e83f43471209c7de07",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25124": {
    "title": "Improving Crowded Object Detection via Copy-Paste",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea6e1e2254a95a7f5413f9fcfa4b1c0d63de46a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25125": {
    "title": "Defending Backdoor Attacks on Vision Transformer via Patch Processing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "95cb1fe9ad477b0ee3dff5659887f3ea0347e5e9",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25126": {
    "title": "Head-Free Lightweight Semantic Segmentation with Linear Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5fbc38ed3aa2de8eb22bc263e1c4d5091b7ce05a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25127": {
    "title": "Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52740e6b55a27ed79397adc59928ca90e739a53a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25128": {
    "title": "Exploring Tuning Characteristics of Ventral Stream's Neurons for Few-Shot Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f04d225453e19cda73c0de049a59a8acd7768bec",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25129": {
    "title": "Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "df11b7fd7c6f627ac8717e91e956e4611746afe3",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25130": {
    "title": "PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e38f4b4055abecbac2e618df2ecb33554073e08",
    "citation_count": 141
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25131": {
    "title": "Domain-General Crowd Counting in Unseen Scenarios",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f8232b83e87aef507a21b7afccecdbe511e46999",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25132": {
    "title": "Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bf39a82f65d9047e676f2f85f700c73d427b4189",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25133": {
    "title": "Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a888dd6d8dd0087fc7d74da8a005922d0923ad2b",
    "citation_count": 30
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25134": {
    "title": "Target-Free Text-Guided Image Manipulation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a426c8209b38ed63b224363f4dcf179692d51ac",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25135": {
    "title": "One Is All: Bridging the Gap between Neural Radiance Fields Architectures with Progressive Volume Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e6f661b7ce2c457af3b9a4cee77101d93c2013c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25136": {
    "title": "Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f27d61ba154ada6b375a4dc313b673be7dbfdd84",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25137": {
    "title": "Uncertainty-Aware Image Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d13f52cbff1416d11986f996fa68ee9767844c60",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25138": {
    "title": "Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b027cb327be4a5051f00f0b84d936e8b2d3b653c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25139": {
    "title": "SEFormer: Structure Embedding Transformer for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "08e31f99bd0738c34100b24ffa0b059cdeebfc26",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25140": {
    "title": "Exploit Domain-Robust Optical Flow in Domain Adaptive Video Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4c180bdfe46f3d59791c7e970ccef667ab8481d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25141": {
    "title": "Scene-Level Sketch-Based Image Retrieval with Minimal Pairwise Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85b696039df8e3a934f69c5e5d72a904d4856fa2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25142": {
    "title": "Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "610924a1aa60494f01158fdb9cb680d0e6203148",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25143": {
    "title": "Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6acab3f2379de04d4a3449ed653add6db32a4af2",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25144": {
    "title": "Progressive Multi-View Human Mesh Recovery with Self-Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f63d71bfd0c363132865a36cd2169b3915888c94",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25145": {
    "title": "Incremental Image De-raining via Associative Memory",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7ff3f133e4290b266f5881a7108a681ffa72e45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25146": {
    "title": "Flexible 3D Lane Detection by Hierarchical Shape Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "247dfec8ebff13808228e73d4ad3166b45cb4972",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25147": {
    "title": "Underwater Ranker: Learn Which Is Better and How to Be Better",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9a07858f88daf54e0ced43ddc4e1178f754458b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25148": {
    "title": "ShadowFormer: Global Context Helps Shadow Removal",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7ffb3dee668255ccffc5970c795f0c1d79ad79b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25149": {
    "title": "RAFaRe: Learning Robust and Accurate Non-parametric 3D Face Reconstruction from Pseudo 2D&3D Pairs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "743cc26eb711e740724f5a94bb3bcc17a5201728",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25150": {
    "title": "RankDNN: Learning to Rank for Few-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9c63c1de8de192c62d334eb97bdff30c2f6fc64",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25151": {
    "title": "Social Relation Reasoning Based on Triangular Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71e0b80918978266b24e1d2df79f399885ba661d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25152": {
    "title": "CALIP: Zero-Shot Enhancement of CLIP with Parameter-Free Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca26023c4dbde9a54145b68e1a6a40533fcc1a4a",
    "citation_count": 17
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25153": {
    "title": "Few-Shot Object Detection via Variational Feature Aggregation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d1e8a99b49e5ac7325e42c5958f76c22ac26e82",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25154": {
    "title": "Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eca815987e1c6a51e00fdc202342d50a288599f0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25155": {
    "title": "Target-Aware Tracking with Long-Term Context Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "62fc770746f6a283fbc5cfc32275e23bfef82eb7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25156": {
    "title": "Weakly-Supervised Camouflaged Object Detection with Scribble Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "613ac2c205cad421a28d7b3a357472a0883803c2",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25157": {
    "title": "Efficient Mirror Detection via Multi-Level Heterogeneous Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb30447cac68f1b22466da2f3f0d85e7a8e0d7c9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25158": {
    "title": "TransVCL: Attention-Enhanced Video Copy Localization Network with Flexible Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18c912802e3d6d84283d24655beb04f904d03675",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25159": {
    "title": "Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee301715607f618d22f21cb51c2c63ca85a4340c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25160": {
    "title": "Parameter-Efficient Model Adaptation for Vision Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "af593c53a9221bd12211f78d4f1ebd6b59cc4e7c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25161": {
    "title": "DarkFeat: Noise-Robust Feature Detector and Descriptor for Extremely Low-Light RAW Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a988d11e4a2c3de692bc879cf8c3d5be5e8e3ead",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25162": {
    "title": "GAM: Gradient Attention Module of Optimization for Point Clouds Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "a5820730290e81f76d843178af927591e669053d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25163": {
    "title": "Self-Supervised Learning for Multilevel Skeleton-Based Forgery Detection via Temporal-Causal Consistency of Actions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "84a150e189e34771752a5454a6f9e143a602dbb8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25164": {
    "title": "Self-Emphasizing Network for Continuous Sign Language Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f55d35e1d1a148898a756cb0380b22fa8878dcb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25165": {
    "title": "Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e32b2e5f07434a4d6ba73ee7394829ef93260124",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25166": {
    "title": "PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models against Adversarial Examples",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aec240626448b3506860a577d5d9ea3a20bfe794",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25167": {
    "title": "High-Resolution Iterative Feedback Network for Camouflaged Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "453d36c646576b04241ca7b964698eef64ebbdc8",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25168": {
    "title": "Leveraging Sub-class Discimination for Compositional Zero-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cb450cc6ccdaa0d1914cbc4d715f0eeb2792aa7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25169": {
    "title": "GPTR: Gestalt-Perception Transformer for Diagram Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6329ee4cf6bbd30c5d76d6caa78959946c656c56",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25170": {
    "title": "Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a63eff00c20172847439826377e412934caad068",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25171": {
    "title": "ClassFormer: Exploring Class-Aware Dependency with Transformer for Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eed051a90f635adb806c025c9b1fcc790f35ba0b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25172": {
    "title": "NLIP: Noise-Robust Language-Image Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2dd4bdb71e8d1a1bb6f7f2cb500972f082aa91fd",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25173": {
    "title": "Symmetry-Aware Transformer-Based Mirror Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b819d724661b35b93aa9048062d988fc6fc868fc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25174": {
    "title": "AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b42f494bf45ec5e154a007844cc449a07279c4f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25175": {
    "title": "Boosting Point Clouds Rendering via Radiance Mapping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18289220a3f778a35d89b9fadeba25820c1ad9ad",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25176": {
    "title": "FreeEnricher: Enriching Face Landmarks without Additional Cost",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9889925126ad324f3f60b0978882f00e23541206",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25177": {
    "title": "PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7fab5b0cc0bf96a1f987f9ebf18177e7915ba60",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25178": {
    "title": "Unifying Vision-Language Representation Space with Single-Tower Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e978d2f7e2a04da803d1a224b3ad868ac919dbb8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25179": {
    "title": "Delving Deep into Pixel Alignment Feature for Accurate Multi-View Human Mesh Recovery",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b5a878716aa4ab11e84ba0973d58ab35c68711a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25180": {
    "title": "Semi-attention Partition for Occluded Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "810862a848aa164ad7e0611ee4b850d6d28f4a1a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25181": {
    "title": "Fast Online Hashing with Multi-Label Projection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f98d2bd7a791f0eaea7aab20496a2b5efa0ed44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25182": {
    "title": "Fourier-Net: Fast Image Registration with Band-Limited Deformation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "743c723118ee61e2e5cc7161247c272522d8cdd5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25183": {
    "title": "Semi-supervised Deep Large-Baseline Homography Estimation with Progressive Equivalence Constraint",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a96f76cc868630a74b758951f5206e9f7e670e83",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25184": {
    "title": "Multi-Modality Deep Network for Extreme Learned Image Compression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fcbe9b439f1f694d79a3e788a3a4e2ce4655219a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25185": {
    "title": "PolarFormer: Multi-Camera 3D Object Detection with Polar Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "67a3e04199baad91ecf25b55f294f54b173c052b",
    "citation_count": 59
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25186": {
    "title": "3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d666dd97fa2659918fff88b3b279149121158ab",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25187": {
    "title": "FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e835e50b4c067cec7457332ec119994fb1a26422",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25188": {
    "title": "Estimating Reflectance Layer from a Single Image: Integrating Reflectance Guidance and Shadow/Specular Aware Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3054551f9f9dfd8d49d029e16b0d27f46990826",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25189": {
    "title": "Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cb7e9e6a68f64972cb42fc790c3a755175b80828",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25190": {
    "title": "Correlation Loss: Enforcing Correlation between Classification and Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "448224d5629a2d3ab1571811a2d183189f424376",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25191": {
    "title": "GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8ddb147c006cdeae6cd38f458e9c7c337d5b0965",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25192": {
    "title": "3D Human Pose Lifting with Grid Convolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eab5282e937a9b09b3af8c0956f1aa09ff20cfa9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25193": {
    "title": "Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a3577255e136a2c38198ac240cec2921bd739cde",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25194": {
    "title": "Frequency Selective Augmentation for Video Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2de0034a889be933b6059f9cfebc4edb35e4ff29",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25195": {
    "title": "Pose-Guided 3D Human Generation in Indoor Scene",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b60488cb4048b89121c0f50508c473bb8527d518",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25196": {
    "title": "Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "edf262d8983ca2ee80f6196365f8bf5e225603c5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25197": {
    "title": "Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d6d1f02bba8aadc484edfc5becba4a8b91f66343",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25198": {
    "title": "CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a32aec5f06324bd0dabab8a41c97e29a954a21a",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25199": {
    "title": "Simple and Effective Synthesis of Indoor 3D Scenes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "749fc01c222e526dab89e9cb4cb280447d7d65fe",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25200": {
    "title": "MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a600a57618e4f183ceec850fc9b441dda792728a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25201": {
    "title": "InstanceFormer: An Online Video Instance Segmentation Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7eb8252d603b202c9cd06c338d132b6eecfd35e0",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25202": {
    "title": "Pixel-Wise Warping for Deep Image Stitching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cc6c9024ae3beb06dfefe7b1e7813ab9a38e954",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25203": {
    "title": "Learning to Learn Better for Video Object Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0b7bf6eb268653a35a68e712516493a82b02d0f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25204": {
    "title": "Curriculum Multi-Negative Augmentation for Debiased Video Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "235d6337eeb067042eb90c957a4380506a78c7b7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25205": {
    "title": "Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0d75d6529e6098461434f5f4b3dbdd28ef29691",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25206": {
    "title": "MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc5df2954a38581b629ae0e86b8ec90b3af4b3bd",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25207": {
    "title": "Not All Neighbors Matter: Point Distribution-Aware Pruning for 3D Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f8a9671d33837ad90a9df091e03360c43fb5cc9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25208": {
    "title": "Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc1ed0c94657e9e340a038f02cab7b225704a4b9",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25209": {
    "title": "Linking People across Text and Images Based on Social Relation Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5d0b66ca3fec08cf52d56a375aada4a1360af49e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25210": {
    "title": "ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea5e945cde29b61254115d512e9d39fb57a7514c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25211": {
    "title": "SWBNet: A Stable White Balance Network for sRGB Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ba6d7080c349fba2d29fe42357639b00d5cb2cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25212": {
    "title": "Frequency Domain Disentanglement for Arbitrary Neural Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc21b6d4fe70b99b74acb442e8cf711efabe644c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25213": {
    "title": "Pose-Oriented Transformer with Uncertainty-Guided Refinement for 2D-to-3D Human Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4cc1b3aecef868c9d56adc4e6d8a1116774faef9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25214": {
    "title": "CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09a03bcf681ef763cdbcf69869204230d205d07e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25215": {
    "title": "Real-World Deep Local Motion Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a2c6c426b7f7921a41ba61fedcef8d12e05c32fe",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25216": {
    "title": "Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from a Conditional Causal Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "be2672ba4b68a5ebf69ce7c2f6024bd60f1d75c4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25217": {
    "title": "Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6ba44d7412305c1bab39b4b568e2e8492f9c9ed",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25218": {
    "title": "FSR: A General Frequency-Oriented Framework to Accelerate Image Super-resolution Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fa82af8be2e392986ad01984ae74de495efffeb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25219": {
    "title": "Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "20e4132660bf3e93e170c38dc970f5a59fba3d7e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25220": {
    "title": "Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d98fd91ed23b3ab623a60cd1713382b2163d5ce2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25221": {
    "title": "Spatial-Spectral Transformer for Hyperspectral Image Denoising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "efc12fd00542450f688bc4d8c9fc7db73309c723",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25222": {
    "title": "Learning Semantic Alignment with Global Modality Reconstruction for Video-Language Pre-training towards Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a17e108c9a99ba9a8db813fecc45b3e651e6a74",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25223": {
    "title": "Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c79bc6ce52539e42985a892e3745822590c2865",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25224": {
    "title": "NeAF: Learning Neural Angle Fields for Point Normal Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a765befc5a9f7816a2ae6cf2a911a94ff24c3399",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25225": {
    "title": "CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification without Concrete Text Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8adfb137332a61893417609563897abe9307a11",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25226": {
    "title": "DC-Former: Diverse and Compact Transformer for Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "540dcdf4a4556facf03a6cffed4f23a584f64317",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25227": {
    "title": "Panoramic Video Salient Object Detection with Ambisonic Audio Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ecce926a9877bb7512ce4d1101582877e07db12",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25228": {
    "title": "LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e11ee3c730263c6b92c24f1d707ed35626b7e5a1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25229": {
    "title": "Adaptive Texture Filtering for Single-Domain Generalized Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8d475edd830f150b9a6aa3066524c77913510df8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25230": {
    "title": "MEID: Mixture-of-Experts with Internal Distillation for Long-Tailed Video Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a96fdfacff96f3a4e944849f856752bc374f7bf1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25231": {
    "title": "Gradient Corner Pooling for Keypoint-Based Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2812527625498e4dd256e4ddb0f4a49aeffd2d61",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25232": {
    "title": "Towards Real-Time Segmentation on the Edge",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98b67efc8ca78e7e254a1fa543996b69635aa080",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25233": {
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-View 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "234f0122e0edccba5c91763e800c2f02fe8ae4fe",
    "citation_count": 129
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25234": {
    "title": "BEVStereo: Enhancing Depth Estimation in Multi-View 3D Object Detection with Temporal Stereo",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1285d14bffedcc4362fdd05213fd6ee4ec5ca885",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25235": {
    "title": "Learning Single Image Defocus Deblurring with Misaligned Training Pairs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b31de933dc82b38a598c1d274fc9ade2d987c0ba",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25236": {
    "title": "Curriculum Temperature for Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ee96ee0d32816658daa507e2228b037768f148b",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25237": {
    "title": "Actionness Inconsistency-Guided Contrastive Learning for Weakly-Supervised Temporal Action Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fce2e326ec543ef51f6d6e0294ae21d5074320bc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25238": {
    "title": "READ: Large-Scale Neural Scene Rendering for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "982236b056edc17962853c7344e5cf43513b474c",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25239": {
    "title": "CDTA: A Cross-Domain Transfer-Based Attack with Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5206aa1f39cdbc90245bab8761375f9159d913a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25240": {
    "title": "HybridCap: Inertia-Aid Monocular Capture of Challenging Human Motions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15453b482f58c9ef4a2f55f1cfb8872ef7cb7426",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25241": {
    "title": "Global Dilated Attention and Target Focusing Network for Robust Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d2e10ada5a6ac8442d38117e92508de98f165526",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25242": {
    "title": "Only a Few Classes Confusing: Pixel-Wise Candidate Labels Disambiguation for Foggy Scene Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c4f3efd0e7c9c0e1ce649fea31d7f8836f01293",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25243": {
    "title": "Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "137330d3030f75b01c88c14e1164d9b0d8c2dc70",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25244": {
    "title": "Probability Guided Loss for Long-Tailed Multi-Label Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa528fcfa48fe9333220012501e224cde12040fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25245": {
    "title": "Self-Supervised Image Denoising Using Implicit Deep Denoiser Prior",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0753df5be5fabf893ae9604c34c12a0a6233a91c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25246": {
    "title": "Accelerating the Training of Video Super-resolution Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "060bac73d0c6cab65b91f77364645a0afe142d38",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25247": {
    "title": "SelectAugment: Hierarchical Deterministic Sample Selection for Data Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44f4975b026c7c9ab934ead385afae080b20d66b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25248": {
    "title": "AdaCM: Adaptive ColorMLP for Real-Time Universal Photo-Realistic Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b19b1569f783fc4252deb5128889b5b466afefc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25249": {
    "title": "SEPT: Towards Scalable and Efficient Visual Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53169794d50f7541ea4a93417443751ed76a2009",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25250": {
    "title": "Cross-Modality Earth Mover's Distance for Visible Thermal Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e511d05b03a4d6d3ba9c02ec1e1dbf00794ff81e",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25251": {
    "title": "Hypotheses Tree Building for One-Shot Temporal Sentence Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0bfac78dbab5f4318e1a065d6de413ba8ce24ed",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25252": {
    "title": "The Devil Is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ab64c8e9e05fd2426d6cc51f16d931279b862df",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25253": {
    "title": "M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f61187d734d9dfc7cdbb5e0c8ecb6e0a2f70c85",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25254": {
    "title": "From Coarse to Fine: Hierarchical Pixel Integration for Lightweight Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f56ed9f1ca57d3fb73dd6a08c101119e278c3f65",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25255": {
    "title": "Fast Fluid Simulation via Dynamic Multi-Scale Gridding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91c3eea164d6c32dd00647594f3ca3be21030a0d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25256": {
    "title": "TransLO: A Window-Based Masked Point Transformer Framework for Large-Scale LiDAR Odometry",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "792798d7cfde416beedcae70cd5b5a92c4ab2737",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25257": {
    "title": "Low-Light Video Enhancement with Synthetic Event Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15837a406a4f6859ca89b1cbbd7b391464164195",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25258": {
    "title": "Novel Motion Patterns Matter for Practical Skeleton-Based Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6a841c4254d8d95ef69abb365087ef3544ad0f82",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25259": {
    "title": "EMEF: Ensemble Multi-Exposure Image Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e8af97164df4a203f39f6d19c17d9b58952d93d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25260": {
    "title": "Reducing Domain Gap in Frequency and Spatial Domain for Cross-Modality Domain Adaptation on Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea10d0a86d0989d97088964d9dfb3f3dbc34daa2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25261": {
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "19ddeaf042fa00814a459e12d03f15801551e423",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25262": {
    "title": "Progressive Neighborhood Aggregation for Semantic Segmentation Refinement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2be38731ed22dbb6ee0ad425fe09f3dc89c856d3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25263": {
    "title": "CoordFill: Efficient High-Resolution Image Inpainting via Parameterized Coordinate Querying",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bbefdde6de6e100794448eadd2de8fc01f147d27",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25264": {
    "title": "CCQ: Cross-Class Query Network for Partially Labeled Organ Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f27fa335b4be16de2e43b765f9dcc97ace8dfff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25265": {
    "title": "Counterfactual Dynamics Forecasting  a New Setting of Quantitative Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "6cb1a49f248413f851eb6c345a2006aca8e96192",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25266": {
    "title": "Self-Decoupling and Ensemble Distillation for Efficient Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b192a0023f769edb31dc191fcc9210318c558df",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25267": {
    "title": "Token Mixing: Parameter-Efficient Transfer Learning from Image-Language to Video-Language",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5fcb5889e7c716b2493da67b63179cb0034c0c66",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25268": {
    "title": "StereoDistill: Pick the Cream from LiDAR for Distilling Stereo-Based 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "628766d52767f8c872047708a21cc0c320366715",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25269": {
    "title": "Good Helper Is around You: Attention-Driven Masked Image Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c58af37caedda1af6833209ef6b384d350743ffd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25270": {
    "title": "RADIANT: Radar-Image Association Network for 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9968d3c8e3b099e02f7e57ab8aeee0f95a781fdc",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25271": {
    "title": "CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation via Centrifugal Reference Frame",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45ea3b4f2e53eaa4fb57ea679646848c48d489eb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25272": {
    "title": "See Your Emotion from Gait Using Unlabeled Skeleton Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "42683c65f41540177c08642aa635bce8d567537f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25273": {
    "title": "Learning Progressive Modality-Shared Transformers for Effective Visible-Infrared Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee04b2b113700b71de4fe91bddc9cd10348486b7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25274": {
    "title": "Breaking Immutable: Information-Coupled Prototype Elaboration for Few-Shot Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b09025b0b145ad07346fd75e7b5c0429e422ec7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25275": {
    "title": "ParaFormer: Parallel Attention Transformer for Efficient Feature Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "467268d70982cceb82206f526485951b0cff3e80",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25276": {
    "title": "Robust One-Shot Segmentation of Brain Tissues via Image-Aligned Style Transformation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ddc061eec9873bd2b38a284e21561eda1ef0756",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25277": {
    "title": "HRDoc: Dataset and Baseline Method toward Hierarchical Reconstruction of Document Structures",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cef1779a38aeb0aefbc347318b22e7b5cf890c03",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25278": {
    "title": "Semantic 3D-Aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "01df332f62508f976fea91cdad8010669efc5701",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25279": {
    "title": "CFFT-GAN: Cross-Domain Feature Fusion Transformer for Exemplar-Based Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29d35ab84788ca14e2b65a457c7fed5ee6f150a4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25280": {
    "title": "StyleTalk: One-Shot Talking Head Generation with Controllable Speaking Styles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ef7df2ace0723583ba22bf165188cd7d2044e93",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25281": {
    "title": "Intriguing Findings of Frequency Selection for Image Deblurring",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6f039e6f7b0ef12afc01f0992f477ecc7bfdb31",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25282": {
    "title": "DocEdit: Language-Guided Document Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "383db93b039c2f7d743a06dc62a8db2ff1ea33f7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25283": {
    "title": "Progressive Few-Shot Adaptation of Generative Model with Align-Free Spatial Correlation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e5bed4c8dbc00e975c9d585e7592eaaf2d9d28e5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25284": {
    "title": "Minority-Oriented Vicinity Expansion with Attentive Aggregation for Video Long-Tailed Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5020cc02130c7625836f28969aa632eb87d83f28",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25285": {
    "title": "Show, Interpret and Tell: Entity-Aware Contextualised Image Captioning in Wikipedia",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7405b595f266e02f5cac24a11d83b7e341662f6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25286": {
    "title": "TaCo: Textual Attribute Recognition via Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "69df56f5b6134ab85fbf878593eb17a968453538",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25287": {
    "title": "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6df6c71be7a04e3e5c2a0dae037fe38458fe1ef6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25288": {
    "title": "Adapting Object Size Variance and Class Imbalance for Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a30c72de1c89f3c1c38f8e4390699c86bb15626",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25289": {
    "title": "MIMO Is All You NeedA Strong Multi-in-Multi-Out Baseline for Video Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "6ec6176e06ba9918ce563dc89a96303408fd97cf",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25290": {
    "title": "Universe Points Representation Learning for Partial Multi-Graph Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61feea09030ace88eb0ddcdcf8942b002b5adfd3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25291": {
    "title": "Robust Image Denoising of No-Flash Images Guided by Consistent Flash Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "81eb06c149775e0de9ec7b04bb4d4b53abf04d43",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25292": {
    "title": "Coarse2Fine: Local Consistency Aware Re-prediction for Weakly Supervised Object Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9070385c89cf2385629b70e1ed7267a9391554d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25293": {
    "title": "Find Beauty in the Rare: Contrastive Composition Feature Clustering for Nontrivial Cropping Box Regression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "82fa44d3b927745ed1e2397eacc02596da50d0f6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25294": {
    "title": "Domain Decorrelation with Potential Energy Ranking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "55b51b993600aa23d84e1e15fb53641100e9c772",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25295": {
    "title": "PDRF: Progressively Deblurring Radiance Field for Fast Scene Reconstruction from Blurry Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "559f7202200ef3c187780301590e2f2b4665f047",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25296": {
    "title": "Efficient End-to-End Video Question Answering with Pyramidal Multimodal Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2837e0cab1d600fa9ca29ebdbfab239701065071",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25297": {
    "title": "CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b57872957f8f70573b62a27c4b91e0636b218983",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25298": {
    "title": "Better and Faster: Adaptive Event Conversion for Event-Based Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bd82d465f64ef748e3de025a2ad0edf05f300fdd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25299": {
    "title": "CSTAR: Towards Compact and Structured Deep Neural Networks with Adversarial Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29bb2597be1a499d30d23844bf19d5c43f6afc12",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25300": {
    "title": "Exploring Stochastic Autoregressive Image Modeling for Visual Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fa0872e45bf6c0fee528c86120f52490142efba6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25301": {
    "title": "Context-Aware Transformer for 3D Point Cloud Automatic Annotation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ec629633af4d16bbc8db0cc3fb26964cfa33eb6c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25302": {
    "title": "Data-Efficient Image Quality Assessment with Attention-Panel Decoder",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "959eac73869bb8ec9096871957c938840e0fdcd0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25303": {
    "title": "FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29a2c4d44117e51e0d2fa6ffac516222ecab254f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25304": {
    "title": "Exposing the Self-Supervised Space-Time Correspondence Learning via Graph Kernels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1b137feaa09a7660c26107d7cf0411e2e99058c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25305": {
    "title": "Exploring Stroke-Level Modifications for Scene Text Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8fe2b02776208670906c89f8b8d361074fc87d5",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25306": {
    "title": "Unsupervised Deep Learning for Phase Retrieval via Teacher-Student Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c02b92e4ffb3edd22280154b535017de8a1938c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25307": {
    "title": "A Learnable Radial Basis Positional Embedding for Coordinate-MLPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05450d77727a1c58854e0b8550ca9f82e05d1cd8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25308": {
    "title": "Action-Conditioned Generation of Bimanual Object Manipulation Sequences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44d343bfa354e4afa7a3bed82a7831d677e3e210",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25309": {
    "title": "Mean-Shifted Contrastive Loss for Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d90243c5a46430a36c5ba88627b5d254450a1e1",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25310": {
    "title": "Two Heads Are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a09509004fb374d794fb4065b54e9a5dda630e6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25311": {
    "title": "MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-robust Classifier",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "790ba79fa1fcc7446fd81047c9e86b2b4c862d7a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25312": {
    "title": "Domain Generalised Faster R-CNN",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b22618848e56abbf7dcf1d7f419b72215cefcdb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25313": {
    "title": "MIDMs: Matching Interleaved Diffusion Models for Exemplar-Based Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ed3b73719016f3500c5976234111b87c21837bf",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25314": {
    "title": "JR2Net: Joint Monocular 3D Face Reconstruction and Reenactment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e51e322712413d3e6d5b8abef8d74cbfdaa2ae4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25315": {
    "title": "HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "643626048cc70b1ed4ed3a0fc94d58b02b7945f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25316": {
    "title": "Channel Regeneration: Improving Channel Utilization for Compact DNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e32b11399247648b4d9f50bd54f8a383280489fb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25317": {
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6f14a642033b72454afbecdb90c82872d8085dd2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25318": {
    "title": "Edge Structure Learning via Low Rank Residuals for Robust Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "925794910710207106ee192ff97475a2617bef3c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25319": {
    "title": "Memory-Oriented Structural Pruning for Efficient Image Restoration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9f5408d8c08a2f7beb35cb16c6ccdcf67b3c7d3d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25320": {
    "title": "YOLOV: Making Still Image Object Detectors Great at Video Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa289e06d4a11f50ce1f5287415a7ff752c136f6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25321": {
    "title": "FeedFormer: Revisiting Transformer Decoder for Efficient Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "de8d3b6ef17f924fc8d01d09bcc128c068dc1469",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25322": {
    "title": "Task-Specific Scene Structure Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3194258a0374f03f1ba1b968fa181fc1e1456b49",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25323": {
    "title": "Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "41e11c36e6fd2377fe5ecb9d0d0422c635ee4be0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25324": {
    "title": "SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8fe203feefec99d20ed68003e5389a46a0d7f285",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25325": {
    "title": "Siamese-Discriminant Deep Reinforcement Learning for Solving Jigsaw Puzzles with Large Eroded Gaps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14ef45b70e11c8222baf19f30cc045f54d574c23",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25326": {
    "title": "CLIPVG: Text-Guided Image Manipulation Using Differentiable Vector Graphics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cda631065b5300aa3d3d3226a4da9d3a36939494",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25327": {
    "title": "Compact Transformer Tracker with Correlative Masked Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8e6e17ca2288c26b79cedff0a666e2549441ac1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25328": {
    "title": "Text-DIAE: A Self-Supervised Degradation Invariant Autoencoder for Text Recognition and Document Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e0714e9dc5dc5ce5b4eda032d166fb07bb26ca1",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25329": {
    "title": "PUPS: Point Cloud Unified Panoptic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72e8986a912f812b71f02e4083d349104c0db158",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25330": {
    "title": "Efficient Edge-Preserving Multi-View Stereo Network for Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "20475d345d152fa4a78b9eb37f3ffe7f2d3cfcf6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25331": {
    "title": "Referring Expression Comprehension Using Language Adaptive Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0b4d116cb264894b47e0c25cb89344c924ba9cc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25332": {
    "title": "Rethinking Data Augmentation for Single-Source Domain Generalization in Medical Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c8368b16b978c36bcb368e673c292254d8a4cf01",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25333": {
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e4aa84de53f8d6f8245ff6bc3c535ed260edfe2",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25334": {
    "title": "Learning Event-Relevant Factors for Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f1b6f5dcd5f802f2782ef15629be57202e3b629",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25335": {
    "title": "Superpoint Transformer for 3D Scene Instance Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e015130b27aaa95674e7c4b5dcbb5a7a7fe7ed04",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25336": {
    "title": "Asynchronous Event Processing with Local-Shift Graph Convolutional Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29f12988ea953725e791e7467b479f7161a487ac",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25337": {
    "title": "DENet: Disentangled Embedding Network for Visible Watermark Removal",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5720ed9d22f2f83a75e7f8efb7b466691f631138",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25338": {
    "title": "Deep Manifold Attack on Point Clouds via Parameter Plane Stretching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38a454f66e8fca40a342f5edb3b1d433eb091971",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25339": {
    "title": "Fair Generative Models via Transfer Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c77f32cb3a030c04de992be40fdf882690afeef8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25340": {
    "title": "Learning Context-Aware Classifier for Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ca374400fc1dd1078ce39c942ff8df562fb163b",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25341": {
    "title": "TopicFM: Robust and Interpretable Topic-Assisted Feature Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1df8ce9e21c544a8ba0911e3e7825abc752236eb",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25342": {
    "title": "Learning Fractals by Gradient Descent",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8715975820cbacdc844a196e2f2f471cca982ccb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25343": {
    "title": "Leveraging Weighted Cross-Graph Attention for Visual and Semantic Enhanced Video Captioning Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a5e3cf08174095cbe4cec418d19b8fc260af49cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25344": {
    "title": "Doodle to Object: Practical Zero-Shot Sketch-Based 3D Shape Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d658819f2aad7f8fe5ec951c595d432f0d8db33f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25345": {
    "title": "Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f8860a5ef6097a9a01a352e609366343627db577",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25346": {
    "title": "Dual Memory Aggregation Network for Event-Based Object Detection with Learnable Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d902c86c7a1cbdac013523488adf85942aa11169",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25347": {
    "title": "Text to Point Cloud Localization with Relation-Enhanced Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23a24e1740bf1b5bd5f39b18114b65ceabed1db0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25348": {
    "title": "UCoL: Unsupervised Learning of Discriminative Facial Representations via Uncertainty-Aware Contrast",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77f6e57c4c5d73fe7805c662381ebad5ed643789",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25349": {
    "title": "Calibrated Teacher for Sparsely Annotated Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "045465a04985227f05a437ecc459fbc8b1cb0478",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25350": {
    "title": "Towards Real-Time Panoptic Narrative Grounding by an End-to-End Grounding Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "436f2d681c3448b6d10cea53238974987d71c0f2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25351": {
    "title": "LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36b5d21ee97844ec915f5740e37e95c41992409c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25352": {
    "title": "Defending Black-Box Skeleton-Based Human Activity Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "24d47781fb60fd3a427d426d763fc544bee8175b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25353": {
    "title": "Exploring CLIP for Assessing the Look and Feel of Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03ae89e796b1a8b566ae1554fab65c8c88b3a55f",
    "citation_count": 19
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25354": {
    "title": "Robust Video Portrait Reenactment via Personalized Representation Quantization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f54e8f1d3af326ccbd372fe1cf7f548f7fd6a483",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25355": {
    "title": "De-biased Teacher: Rethinking IoU Matching for Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "656d87d314009a9f1925348d30652f39e0cc7ed5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25356": {
    "title": "Learning to Generate an Unbiased Scene Graph by Using Attribute-Guided Predicate Features",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da31afdbc962f0323d013a88a0c308c61b4d247c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25357": {
    "title": "Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ff504e8d0ed00d8e9d6dd317d3b7572d1f3ecaa",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25358": {
    "title": "Flora: Dual-Frequency LOss-Compensated ReAl-Time Monocular 3D Video Reconstruction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "de0d19110a0601c0741df7d26982a0c44288ce90",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25359": {
    "title": "Efficient Image Captioning for Edge Devices",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d6332c9a4607ce9823123e6407e40ab6ac33ac08",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25360": {
    "title": "Controllable Image Captioning via Prompting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f66aeec98816c3a52685e570a04fa8f2bd53dfb4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25361": {
    "title": "ECO-3D: Equivariant Contrastive Learning for Pre-training on Perturbed 3D Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c1cef162d3c6276c84deb22c08a2b6d7e2d38a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25362": {
    "title": "Global-Local Characteristic Excited Cross-Modal Attacks from Images to Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "af77300381156898024ea3a10f6d00cc31b8ee86",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25363": {
    "title": "Fine-Grained Retrieval Prompt Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "247be1257a1c5811ff48331e902771c7b00a56c5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25364": {
    "title": "Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "baf3d202261f1eb9122a157fc6480d93e2c3d03c",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25365": {
    "title": "3D Assembly Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb2256efc25ad00d4a18a9901cf83b17dbc038a4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25366": {
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "974e24ce5ca6a23b8841f3b1049edff0aeaf42ce",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25367": {
    "title": "Revisiting Unsupervised Local Descriptor Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b72f022c06dbfa52af4f31a766ca57e7758b5990",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25368": {
    "title": "Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "588042275a2e338df56ace42453c727137da36fc",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25369": {
    "title": "Learning Continuous Depth Representation via Geometric Spatial Aggregator",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9dc77eb07e11d3fd09f2dd5d2225ded4291f6d3b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25370": {
    "title": "SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bfc07ed6e6d4aef2674d0e412215b3253b95336c",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25371": {
    "title": "High-Resolution GAN Inversion for Degraded Images in Large Diverse Datasets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36da639b3cba35311314a19e5bfd987c5865a061",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25372": {
    "title": "GAN Prior Based Null-Space Learning for Consistent Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c12d091ea5c16938943559fb0f3d430ba040c08",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25373": {
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65be7f0b01cf6c2a1cded708b809182fbcb43548",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25374": {
    "title": "MicroAST: Towards Super-fast Ultra-Resolution Arbitrary Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7b0183c518ebc2100569f1086fd6fedab8659d96",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25375": {
    "title": "Truncate-Split-Contrast: A Framework for Learning from Mislabeled Videos",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bb62dd71543f4644cec09b00bdf7b8b2795063fd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25376": {
    "title": "Active Token Mixer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "20fc19d7445ec081a95a3e97bab3f1f07c92988d",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25377": {
    "title": "Exploring Non-target Knowledge for Improving Ensemble Universal Adversarial Attacks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2cf7b3b2fb58431d96e934effbb0af3a3ba60eb9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25378": {
    "title": "Towards Good Practices for Missing Modality Robust Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12a43c120c9e7615535237bbee2f6375d07fdd7a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25379": {
    "title": "Reject Decoding via Language-Vision Models for Text-to-Image Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f9fff9bf668264b454ee45e67135ea2debd7b8f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25380": {
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8599f26dd40313a092dc05fe370b934beb6a29ef",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25381": {
    "title": "Super-efficient Echocardiography Video Segmentation via Proxy- and Kernel-Based Semi-supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6f991a9b4da4d520d11684d42cdf403d0be5917",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25382": {
    "title": "ACL-Net: Semi-supervised Polyp Segmentation via Affinity Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7fe355f1db5dbf47e4ac223c7a48e8dbaa7cbe1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25383": {
    "title": "Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8d3436667b7863759a5d2228366e357f35a6e8d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25384": {
    "title": "Preserving Structural Consistency in Arbitrary Artist and Artwork Style Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e808f718e4f195527e8ea3ecb252e25e24c98bae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25385": {
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2b2a7f713d8efe2696df85ef22dac7ef35be7e10",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25386": {
    "title": "Revisiting Classifier: Transferring Vision-Language Models for Video Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c68b9483bcd91850e27cc6d667c783edf335a3e4",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25387": {
    "title": "Scene Graph to Image Synthesis via Knowledge Consensus",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "feb5504685a92ea0b2283959a1b508f54bab1627",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25388": {
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for Unsupervised Visual Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fe6ee1f2bf6fa3093798723d3edab686fd927d1d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25389": {
    "title": "Multi-Stream Representation Learning for Pedestrian Trajectory Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b1552a37506344714092defaf1a4bc9488f9bd67",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25390": {
    "title": "Pixel Is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "088a89c3ef90e80b050ac717400209f564099654",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25391": {
    "title": "Attention-Based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6c475af6a695d494b8790ca878f146e795eeb27b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25392": {
    "title": "Skating-Mixer: Long-Term Sport Audio-Visual Modeling with MLPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14165df6bd6ebe598d65d740ee7bcefee2e178f4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25393": {
    "title": "SVFI: Spiking-Based Video Frame Interpolation for High-Speed Motion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a30499c63169d649d9104fa05de10dce6fef3e7b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25394": {
    "title": "FEditNet: Few-Shot Editing of Latent Semantics in GAN Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cde780c2bad086fa5267a11068bb40d320616b4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25395": {
    "title": "Toward Robust Diagnosis: A Contour Attention Preserving Adversarial Defense for COVID-19 Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a68b491f64daf9eee7551469e5d7a39fa62515ad",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25396": {
    "title": "Boosting Semi-Supervised Semantic Segmentation with Probabilistic Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12e668ad61fbcfb1e4752f1243082dc8c0f75f4f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25397": {
    "title": "Less Is More Important: An Attention Module Guided by Probability Density Function for Convolutional Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7624dc2e2c610040b778ce11c3261523e7b27c93",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25398": {
    "title": "Mitigating Artifacts in Real-World Video Super-resolution Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "442f3bde58bd8f736f8643a5fb2feec0854bf368",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25399": {
    "title": "Just Noticeable Visual Redundancy Forecasting: A Deep Multimodal-Driven Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4dc3f4d5a05f9af6b5c78f67b8cb6704738ad7e5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25400": {
    "title": "Cross-Modal Contrastive Learning for Domain Adaptation in 3D Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ff5d423b6dc934d58c7541df31b507fdda059be5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25401": {
    "title": "ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient Self-Supervised Monocular Depth Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "373959536e023e451b46e6e3d60228b59568a5ac",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25402": {
    "title": "LORE: Logical Location Regression Network for Table Structure Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a90a77893708ae5070e2ed4572ca9e20837e69c6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25403": {
    "title": "Revisiting the Spatial and Temporal Modeling for Few-Shot Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7723859aa67aa5324155dfafa1f078b3bc034178",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25404": {
    "title": "Unsupervised Multi-Exposure Image Fusion Breaking Exposure Limits via Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc8f02331ed5baed6f5c0adb9c9cb2fca5e7c1a8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25405": {
    "title": "CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene Completion by Dense Feature Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ede618392b52947f4103415c97e444c20697e550",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25406": {
    "title": "Learning a Generalized Gaze Estimator from Gaze-Consistent Feature",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a79ce59268ff9b07f61ba730bdfb8f0eaa54ab0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25407": {
    "title": "Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44891165b360ccf98d7f6fd7f5361a6d5f3b4a3b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25408": {
    "title": "Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17b71c39617d654ff345d7e48491068f7d519b0c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25409": {
    "title": "Deep Parametric 3D Filters for Joint Video Denoising and Illumination Enhancement in Video Super Resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e64440b53317fa8b5b800f238d500d586ae5e17f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25410": {
    "title": "Inter-image Contrastive Consistency for Multi-Person Pose Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e5b923a3498a977c0758a1578cb0af1fa180420",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25411": {
    "title": "DeMT: Deformable Mixer Transformer for Multi-Task Learning of Dense Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3d3c1321554d7d14eec309e61ba70102b0629e1",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25412": {
    "title": "VLTinT: Visual-Linguistic Transformer-in-Transformer for Coherent Video Paragraph Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c35fc28cb4e9336f4077cfc9cc559f55950b5996",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25413": {
    "title": "Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1b14b7ed6601b4e1fd847a3043e749ca0bf02aa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25414": {
    "title": "Video-Text Pre-training with Learned Regions for Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "615d077899e7c57c7073d427035499749fa7b355",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25415": {
    "title": "DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15d9392d12635221d6dba08a33344f6fc97060ce",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25416": {
    "title": "Self-Supervised Video Representation Learning via Latent Time Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71a971a7a86459eb7a568985fe398a7c79b3dd35",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25417": {
    "title": "One-Shot Replay: Boosting Incremental Object Detection via Retrospecting One Object",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9bc81d69b990c814770096f3aa41ded4f639df6d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25418": {
    "title": "Video Event Extraction via Tracking Visual States of Arguments",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e3516142b2d7cf7fb67805a8b45fb077c9c6bb8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25419": {
    "title": "CoMAE: Single Model Hybrid Pre-training on Small-Scale RGB-D Datasets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2feabd1e149da3aa82cc6d1d684cac836a0c01e7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25420": {
    "title": "Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae0c998d3efe583b19fd4d1274eec3520c8f813a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25421": {
    "title": "Stop-Gradient Softmax Loss for Deep Metric Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a792e32749ebb98686791d4524f4e8d4ba575433",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25422": {
    "title": "Local Path Integration for Attribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "87d4cf1dd6507e7c989b25a4a1eeea1a467c3a54",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25423": {
    "title": "Spatiotemporal Deformation Perception for Fisheye Video Rectification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fd89aa30d4917bde9a2343d5590456ce2d76ac8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25424": {
    "title": "Contrastive Multi-Task Dense Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "59c681b58d85411ba5a70284947ad728f468c54c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25425": {
    "title": "AutoStegaFont: Synthesizing Vector Fonts for Hiding Information in Documents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6225139fe937b85a1a4a7d03e10354745f764b5c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25426": {
    "title": "Towards Global Video Scene Segmentation with Context-Aware Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "807937ad69b41b6a320d9d180fa9fe0205d56804",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25427": {
    "title": "Low-Light Image Enhancement Network Based on Multi-Scale Feature Complementation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0287e28e409920e97b5b308974750914d60ba7b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25428": {
    "title": "Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "21cbb159992abffdee87c2a1bc15a3d98bdfde8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25429": {
    "title": "LidarMultiNet: Towards a Unified Multi-Task Network for LiDAR Perception",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09ce90a7d46c297db17e41cfd4e7691933408540",
    "citation_count": 24
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25430": {
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f89d5e8e3c6e3bb035729c1f6039ee95149ce0b",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25431": {
    "title": "Learning Second-Order Attentive Context for Efficient Correspondence Pruning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f5faa47345366d623a8cd3b41e63276065c404a3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25432": {
    "title": "Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "28f4d454359641f62944674ea085e84aff5ce023",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25433": {
    "title": "Can We Find Strong Lottery Tickets in Generative Models?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74fb4456760e417ec2873cfab1e4c87ce59df8f6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25434": {
    "title": "Class-Independent Regularization for Learning with Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "284858ac99309568e83377a9968a1908ee28c717",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25435": {
    "title": "Unbiased Heterogeneous Scene Graph Generation with Relation-Aware Message Passing Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b02f9674a07d6a7e4ab5f4846301dc8d15433e46",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25436": {
    "title": "Lifelong Person Re-identification via Knowledge Refreshing and Consolidation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cdba9c57d5e372bee7a382c2f287eb20da244977",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25437": {
    "title": "Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dddeca3509132717a8b5843f730b8b01a3887dcc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25438": {
    "title": "Rethinking Rotation Invariance with Point Cloud Registration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ca5939d6e64dc751de8bd513980f57a2d43af55",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25439": {
    "title": "Frame-Level Label Refinement for Skeleton-Based Weakly-Supervised Action Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ac0d48894ddbb9232730ab54f9a7754dc6e73c45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25440": {
    "title": "Recurrent Structure Attention Guidance for Depth Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5010526e685c33293be4317720235e639a3bf2e7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25441": {
    "title": "Structure Flow-Guided Network for Real Depth Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98338f97c57fdaea642fa19df65d761349562ca4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25442": {
    "title": "Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b489c6fe772b861a99a14f5f6474b0d44a4a8f2e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25443": {
    "title": "Cyclically Disentangled Feature Translation for Face Anti-spoofing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9abd5e50e280323e3446595d23aa696113346465",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25444": {
    "title": "FlowFace: Semantic Flow-Guided Shape-Aware Face Swapping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "166d8ab629f46c818f42fa4e802a6033d42ece16",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25445": {
    "title": "Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1820749124aa1eaa51c47cb084f13c76b1a8ed2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25446": {
    "title": "Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "297c953df13c4375527df215b57f9c72c036a569",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25447": {
    "title": "Darwinian Model Upgrades: Model Evolving with Selective Compatibility",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d49b452bf09020f032ff65aa115740e3bf99ea0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25448": {
    "title": "Mx2M: Masked Cross-Modality Modeling in Domain Adaptation for 3D Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc430bba79178483c254a072c2151f0b3e7111af",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25449": {
    "title": "Few-Shot 3D Point Cloud Semantic Segmentation via Stratified Class-Specific Attention Based Transformer Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80df029becc3fdf6789c0d4c4fdf9a832f2e2672",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25450": {
    "title": "PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement and Pose Restoration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e6ad00f8c11a9237fc112ecff222e00fd71174ae",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25451": {
    "title": "Hierarchical Consistent Contrastive Learning for Skeleton-Based Action Recognition with Growing Augmentations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51133d759e81916553edf4e35a20385d12090abe",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25452": {
    "title": "ImageNet Pre-training Also Transfers Non-robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b28004c12d1073f3b186483ecb9e8fb816dd37c8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25453": {
    "title": "Language-Assisted 3D Feature Learning for Semantic Scene Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e667180d34f837c7416358414a387595d54eee4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25454": {
    "title": "IKOL: Inverse Kinematics Optimization Layer for 3D Human Pose and Shape Estimation via Gauss-Newton Differentiation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa5262e4d46f8565de1d6049d1f85e8e2033601a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25455": {
    "title": "Mind the Gap: Polishing Pseudo Labels for Accurate Semi-supervised Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b3854e82d71e1a36e049763bb270f1f19d2ea3c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25456": {
    "title": "ConvMatch: Rethinking Network Design for Two-View Correspondence Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8d9662d2db763abb6d427d398e76288327457b1a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25457": {
    "title": "Cross-View Geo-Localization via Learning Disentangled Geometric Layout Correspondence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae6bbeb670a0211bc2426b9afd867f8afb72e751",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25458": {
    "title": "Video Compression Artifact Reduction by Fusing Motion Compensation and Global Context in a Swin-CNN Based Parallel Architecture",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63b3c5e3c6b15394743f9bb423ac2082b2443d24",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25459": {
    "title": "MRCN: A Novel Modality Restitution and Compensation Network for Visible-Infrared Person Re-identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ddd0cff0f7f959c324f9bb157f045302c66690ca",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25460": {
    "title": "A Simple Baseline for Multi-Camera 3D Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0226ed79f7b9efe06adfd0c093228a354bc5197",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25461": {
    "title": "Positional Label for Self-Supervised Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "9ea9e48950e311387c177b5195782c8c324ac119",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25462": {
    "title": "Cross-Category Highlight Detection via Feature Decomposition and Modality Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45de3c9f58933d5ba67dbc9d4cc0266dc11eddf2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25463": {
    "title": "TrEP: Transformer-Based Evidential Prediction for Pedestrian Intention with Uncertainty",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e9e8ed0ee97296c638329a30643c2456d95e944e",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25464": {
    "title": "DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f13d4d12d924727114182da54980a04be051fc87",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25465": {
    "title": "ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ae2e3d5682e755d560c34b05169a9660660f055",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25466": {
    "title": "Combating Unknown Bias with Effective Bias-Conflicting Scoring and Gradient Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5dc689a4d6827b5a441c50cb56c14d19b027d9f7",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25467": {
    "title": "RLogist: Fast Observation Strategy on Whole-Slide Images with Deep Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63195e3d637c2725913fc2fd999e3e3ae40362e4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25468": {
    "title": "Learning to Super-resolve Dynamic Scenes for Neuromorphic Spike Camera",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98528cb319f7939749cafff8d1ff08823641c009",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25469": {
    "title": "TinyNeRF: Towards 100 x Compression of Voxel Radiance Fields",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8f13253a047f76c5e9ee275d27b70274dfe2758",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25470": {
    "title": "BEST: BERT Pre-training for Sign Language Recognition with Coupling Tokenization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "919efc30ab8c45456ab72fb4ebeb5e25f2ad7642",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25471": {
    "title": "MulGT: Multi-Task Graph-Transformer with Task-Aware Knowledge Injection and Domain Knowledge-Driven Pooling for Whole Slide Image Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10968bcb3e19eb3cbd137af1bf4b82ad1c04378c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25472": {
    "title": "Grouped Knowledge Distillation for Deep Face Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68ed8b94df543dba73a619980d1c5a3fcde417a5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25473": {
    "title": "Style-Content Metric Learning for Multidomain Remote Sensing Object Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2fbd355ed0cf0bb57a3bfea9b3f12cc1e180d701",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25474": {
    "title": "Occupancy Planes for Single-View RGB-D Human Reconstruction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dde7f2b5b925c7edb8ef9c5aabc1f679a6b6c104",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25475": {
    "title": "Deep Equilibrium Models for Snapshot Compressive Imaging",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68bcc213f88a5ee875f7061cdc192cb5b4ad9832",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25476": {
    "title": "Unsupervised Deep Video Denoising with Untrained Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8132f60124089fd50fe2afbd3e60e73b05ef65e1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25477": {
    "title": "Attack Can Benefit: An Adversarial Approach to Recognizing Facial Expressions under Noisy Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4266bba4e036807378abb05b2a9ebe7063c13a94",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25478": {
    "title": "Phrase-Level Temporal Relationship Mining for Temporal Sentence Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4f70d5bdd5293b7fc53831624971fef83873d3f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25479": {
    "title": "Learning Semantic Degradation-Aware Guidance for Recognition-Driven Unsupervised Low-Light Image Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "00d66e7384eb46a290595bf54d62c2a614f8734d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25480": {
    "title": "Memory-Aided Contrastive Consensus Learning for Co-salient Object Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ec9799fba2f8e71a48c7606d1c725f2e2a30095",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25481": {
    "title": "MaskBooster: End-to-End Self-Training for Sparsely Supervised Instance Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc3fab136f5ee45103bad37eebafa1581781560d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25482": {
    "title": "RSPT: Reconstruct Surroundings and Predict Trajectory for Generalizable Active Object Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "0a21061ddf9c41b71c8d7b409f7dd97b18a5cd8b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25483": {
    "title": "STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d20d1d3ec1199c35d13e60351b358ac1e317401",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25484": {
    "title": "Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "154f9eb2f97cae3a7752cbc4e0261eb4e75008d4",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25485": {
    "title": "Aesthetically Relevant Image Captioning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "15d6ef576fb07bb5fc07fef6f63708e440396dd9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25486": {
    "title": "Polarization-Aware Low-Light Image Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1956f7770663fc45d9035278e39eb14fefcdd76a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25487": {
    "title": "Progressive Bayesian Inference for Scribble-Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a506fdeb24c051732d7c0aa74ae99db3cedbd0f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25488": {
    "title": "Exploratory Inference Learning for Scribble Supervised Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ff5db744e5eefb95e17afd59260efbb3a78756c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25489": {
    "title": "Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "965a0ff397ff33dbb9ee9a5b725472af4ffe0892",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25490": {
    "title": "Unsupervised Hierarchical Domain Adaptation for Adverse Weather Optical Flow",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cd9aae06d5720908760b47e46516adcb9a89f03f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25491": {
    "title": "PASS: Patch Automatic Skip Scheme for Efficient Real-Time Video Perception on Edge Devices",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ebb9f49e940bdd14925a9776998244ad8aa74b57",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25492": {
    "title": "Robust Feature Rectification of Pretrained Vision Models for Object Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1d4ddca6c68ed963763711f545844557d6085b8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25493": {
    "title": "Video Object of Interest Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "21c088c0620f6bf9d7699c9547af47318257df7a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25494": {
    "title": "Tree-Structured Trajectory Encoding for Vision-and-Language Navigation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "293951f26d10fed6950b2949e0f90571e0d67cd6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25495": {
    "title": "Self-Supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "185e0240f15d84f805d36ed30f70ebd6e85be2b4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25496": {
    "title": "Debiased Fine-Tuning for Vision-Language Models by Prompt Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8b73abefd998229f35e810f465854bdea7512f8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25497": {
    "title": "Improving Scene Text Image Super-resolution via Dual Prior Modulation Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e45d243316096cfc709e96027ebb2d353475ede6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25498": {
    "title": "SRoUDA: Meta Self-Training for Robust Unsupervised Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a7ab69f162e706901c6aa1e391004971a463a3a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25499": {
    "title": "Gradient-Based Graph Attention for Scene Text Image Super-resolution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "30db786f5810602af4680dc4372c265e4597666e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25500": {
    "title": "RGBD1K: A Large-Scale Dataset and Benchmark for RGB-D Object Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b52382b22d25dd63c2a68424304e39024bf6e15f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25501": {
    "title": "Learn More for Food Recognition via Progressive Self-Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a332ce333d52d85ff6bb74dec4a7c7b15bff0f66",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25502": {
    "title": "Generative Image Inpainting with Segmentation Confusion Adversarial Training and Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65f5f5d54bde99776de1840e7cd59d30bbf74390",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25503": {
    "title": "Improved Algorithms for Maximum Satisfiability and Its Special Cases",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8e39247da25bb69cd9ceae1c5c5d0d4c354dd47",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25504": {
    "title": "Lifting (D)QBF Preprocessing and Solving Techniques to (D)SSAT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ae0b1ba9c743ad04020efe39e1237a5cbc7b1f5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25505": {
    "title": "NuWLS: Improving Local Search for (Weighted) Partial MaxSAT by New Weighting Techniques",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68d54d627cfaa914d277a3f4a5508de1c4abe4ef",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25506": {
    "title": "Separate but Equal: Equality in Belief Propagation for Single Cycle Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "276906bc63d919a9d576b80786c42254be84a0c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25507": {
    "title": "Complexity of Reasoning with Cardinality Minimality Conditions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "225a18fc8ae50641c5da8171cd11d00a428d32c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25508": {
    "title": "DASH: A Distributed and Parallelizable Algorithm for Size-Constrained Submodular Maximization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e912edd7f1b82df95cc569ef73cf602bf7118ea8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25509": {
    "title": "SharpSSAT: A Witness-Generating Stochastic Boolean Satisfiability Solver",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d9e4474d023987ed4c5f409176fe870db873ca85",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25510": {
    "title": "Submodular Maximization under the Intersection of Matroid and Knapsack Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d8f527c2046fcf50d9418d4d694d86c4601ac7ff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25511": {
    "title": "A Framework to Design Approximation Algorithms for Finding Diverse Solutions in Combinatorial Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "807cfcbca58e27d087a913be5c2481e524aeb7f9",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25512": {
    "title": "An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-Sourcing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc8beb173d4dad28357d848b2240d560b81f39f3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25513": {
    "title": "Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0c94f185099505025b5b2ee94aa567409cdaf19",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25514": {
    "title": "Solving Explainability Queries with Quantification: The Case of Feature Relevancy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "622657250ba771cb4af66f7e54868314b777bbd4",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25515": {
    "title": "Second-Order Quantified Boolean Logic",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "84c64c851b2bbaa8533258b16dee807a25f52cbe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25516": {
    "title": "Learning Markov Random Fields for Combinatorial Structures via Sampling through Lovsz Local Lemma",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cd51ce7bb450a1e8bbf3727db6b809ca45b13518",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25517": {
    "title": "Fast Converging Anytime Model Counting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1fc7323bb9f59f444be47e1624e31320e417f6b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25518": {
    "title": "Finding Good Partial Assignments during Restart-Based Branch and Bound Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51870d8e06dff589258700debae3f69dc993772b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25519": {
    "title": "Hybrid Learning with New Value Function for the Maximum Common Induced Subgraph Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dd2f352795968d59bd82169a5c5c9547b054f9e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25520": {
    "title": "Self-Supervised Primal-Dual Learning for Constrained Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27171044552454edcbd1d6a20ac0714ee3c46686",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25521": {
    "title": "Reinforcement Learning for Branch-and-Bound Optimisation Using Retrospective Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3212c957a11a46d059e981826372914045f5cc4a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25522": {
    "title": "Constraint Optimization over Semirings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "39fdccb34c7eae74dac974354db59d0ca48fc8c0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25523": {
    "title": "Generalized Confidence Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7ed381fb10c3178120b182c5e4e70fb89791f466",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25524": {
    "title": "Circuit Minimization with QBF-Based Exact Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "25f369e3318ba4ee373a5dcf2c7234e37b4ba2c8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25525": {
    "title": "Probabilistic Generalization of Backdoor Trees with Application to SAT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b0738a5a45dee62b540b60b9bb33a82e41f8a12",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25526": {
    "title": "The Expressive Power of Ad-Hoc Constraints for Modelling CSPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7e5501bfb07b6f3535263caf90d59a21724e510",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25527": {
    "title": "Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcbda9002def84b4b4467e54e1d06a18ac227103",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25528": {
    "title": "Eliminating the Impossible, Whatever Remains Must Be True: On Extracting and Applying Background Knowledge in the Context of Formal Explanations",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25529": {
    "title": "Farsighted Probabilistic Sampling: A General Strategy for Boosting Local Search MaxSAT Solvers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "56c858b81ce04d884a711a70a0b40d5f9f166beb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25530": {
    "title": "LANCER: A Lifetime-Aware News Recommender System",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23627f20f53611a39a5df35642f99d3007863496",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25531": {
    "title": "Win-Win: A Privacy-Preserving Federated Framework for Dual-Target Cross-Domain Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4fcda17617d3887eb657d017bc15017fc7b3641c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25532": {
    "title": "Enhanced Multi-Relationships Integration Graph Convolutional Network for Inferring Substitutable and Complementary Items",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fa0090adfbc80de8dcc82c8d094ce800f674b094",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25533": {
    "title": "PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "57a13f7f82a11887af3baceda506e2c579d7466d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25534": {
    "title": "End-to-End Entity Linking with Hierarchical Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aec8eed33a7f9195ba0925c798e6431702d22e1a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25535": {
    "title": "Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10d949dee482aeea1cab8b42c326d0dbf0505de3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25536": {
    "title": "Dual Low-Rank Graph Autoencoder for Semantic and Topological Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a7adc0b3b0a87de6f57cffcd3f6133cf1041214a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25537": {
    "title": "Dynamic Multi-Behavior Sequence Modeling for Next Item Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b838508bcc1f591b7db00dabe19678fe8b0b3ce0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25538": {
    "title": "Learning Representations of Bi-level Knowledge Graphs for Reasoning beyond Link Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cce3bb3d79c8c6e6f1b6b825f444a98d12f30833",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25539": {
    "title": "Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7b7bfdc2936f09b09943d78d7b4d596f27e3274b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25540": {
    "title": "Uniform Sequence Better: Time Interval Aware Data Augmentation for Sequential Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "614938bed58a2e496cfc373b2f70f11462506131",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25541": {
    "title": "Rule Induction in Knowledge Graphs Using Linear Programming",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8169e28b81bce7e4fb878a3935d44829035ae2d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25542": {
    "title": "Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9fab6048fc657ec13d4a59fe21b823ecd0ab0b95",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25543": {
    "title": "DAMix: Exploiting Deep Autoregressive Model Zoo for Improving Lossless Compression Generalization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8467d3032147d2d3508b2f98e09aea566d8a03e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25544": {
    "title": "Soft Target-Enhanced Matching Framework for Deep Entity Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6894a73276a06f6093c23d4320d7fae2b09f4a54",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25545": {
    "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "688a20c88a022febbd7432c5231963235d4729bd",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25546": {
    "title": "Contrastive Pre-training with Adversarial Perturbations for Check-In Sequence Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d75010b4a317f6ea5a9a26bae72505b22cb8d134",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25547": {
    "title": "MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3fd66f10b978d44e063aa23c64cdfe98722a3812",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25548": {
    "title": "Generic and Dynamic Graph Representation Learning for Crowd Flow Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a9a358cf2e3f85fa7f286e392bfb0ad232c109e5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25549": {
    "title": "Conditional Diffusion Based on Discrete Graph Structures for Molecular Graph Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "67b5d57c08176787ae7b54b65ae3bf0ac11b9b04",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25550": {
    "title": "SAH: Shifting-Aware Asymmetric Hashing for Reverse k Maximum Inner Product Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "e76548be2a8c67f437daee555bc7b246c540de42",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25551": {
    "title": "Learned Distributed Image Compression with Multi-Scale Patch Matching in Feature Domain",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "102a0f62845c3e2c351969bb210bbdc1dbc9ed6d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25552": {
    "title": "Constrained Market Share Maximization by Signal-Guided Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d1cbfd0ab6880a5fe0f5ce95e7d4a3072955839",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25553": {
    "title": "T2-GNN: Graph Neural Networks for Graphs with Incomplete Features and Structure via Teacher-Student Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9b17f8d306e0e8264830394229e38c5d79b77523",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25554": {
    "title": "Detecting Sources of Healthcare Associated Infections",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0a7b41426bbae754e4ff50dd2dad0741b199a15",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25555": {
    "title": "Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "abf773ddd5cb8f42a20e77effcf7e1f826991d42",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25556": {
    "title": "PDFormer: Propagation Delay-Aware Dynamic Long-Range Transformer for Traffic Flow Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38381097a0add12ff685dfaac0191c31c9ae429a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25557": {
    "title": "Continuous Trajectory Generation Based on Two-Stage GAN",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ba316f5916807fd0b49b54452f7216c366208e1e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25558": {
    "title": "Let Graph Be the Go Board: Gradient-Free Node Injection Attack for Graph Neural Networks via Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b494763868d078aa306c1f1b3f7c21ffd83feac",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25559": {
    "title": "GLCC: A General Framework for Graph-Level Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cbcf89becf091e3abdf86f692fc3150f0dab33a9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25560": {
    "title": "Parameterized Algorithms for Colored Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2dfe8538b77cdccf89434f1091463dd1c0db9caa",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25561": {
    "title": "Towards Reliable Item Sampling for Recommendation Evaluation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8fdb76a8fdc41eacf3c2c87a9f3d1dba9cc0e068",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25562": {
    "title": "Multiple Robust Learning for Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50ba1ee99c52448b0abdc0143315449fa4f5664b",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25563": {
    "title": "Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "be8e35b1753cc7aed92767db46b99289997af62d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25564": {
    "title": "Adaptive Low-Precision Training for Embeddings in Click-Through Rate Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "624c0373019dabb9f5b69464c0f094013c2b101c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25565": {
    "title": "Signed Laplacian Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23141437bffed6d5457c676bff0b59adf6d64a9a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25566": {
    "title": "PPGenCDR: A Stable and Robust Framework for Privacy-Preserving Cross-Domain Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "370cacdf83aa10e60d79025fad336ac467eb415e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25567": {
    "title": "COLA: Improving Conversational Recommender Systems by Collaborative Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d02536f52b22c303e902f1a5e34ac8cfeb56a293",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25568": {
    "title": "Scalable and Effective Conductance-Based Graph Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05930e5e7684c05fe1461f404bda10434ca143f4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25569": {
    "title": "Multi-Domain Generalized Graph Meta Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ae83395b9ca551e0efd74fac10551e396974040",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25570": {
    "title": "IterDE: An Iterative Knowledge Distillation Framework for Knowledge Graph Embeddings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a400be3a281ac5f0a30df63d224f00bdaad2ad8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25571": {
    "title": "Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0cc9d031ca2f85c1412d5eab9449416c47b8cacd",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25572": {
    "title": "Low-Resource Personal Attribute Prediction from Conversations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "f1e588f1fc1e6456c7ec14a984c630ef58f8df9c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25573": {
    "title": "Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b29aec89e64bb20f2b963e5615c79b9008ecfd88",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25574": {
    "title": "On Generalized Degree Fairness in Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6c26e7f14b52332087c9a1e07e09a2b882665ef3",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25575": {
    "title": "Time Series Contrastive Learning with Information-Aware Augmentations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6e70a2b7512fde9d25176c508f9cad35e47f66ad",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25576": {
    "title": "NQE: N-ary Query Embedding for Complex Query Answering over Hyper-Relational Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d94e7aeab88d07f0b50b7866ceb5baa3c29be859",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25577": {
    "title": "FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4af58fc20efaa3856df8609921b6a022f8f9d3ac",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25578": {
    "title": "GMDNet: A Graph-Based Mixture Density Network for Estimating Packages' Multimodal Travel Time Distribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a9d4820dee3d1de377a7ba16223653701ba726e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25579": {
    "title": "Logic and Commonsense-Guided Temporal Knowledge Graph Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e0a7f3f98e49d0a690842a5692e723615c44928",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25580": {
    "title": "Graph Structure Learning on User Mobility Data for Social Relationship Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cca56116eea606d1be0dd258f03f4c3c679c065a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25581": {
    "title": "Online Random Feature Forests for Learning in Varying Feature Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4482de2f9d3ff6b74d774c9a67a9d6cf5fa5fc59",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25582": {
    "title": "Scaling Law for Recommendation Models: Towards General-Purpose User Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7567744a0e23174166575e8d98590967684696b4",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25583": {
    "title": "Cross-Domain Adaptative Learning for Online Advertisement Customer Lifetime Value Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "562f254f7b0fccba6377a513fc95cbbb4bf80ee7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25584": {
    "title": "Self-Supervised Interest Transfer Network via Prototypical Contrastive Learning for Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09aedbfbc314006bac8e7cead1b838439705f449",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25585": {
    "title": "Opinion Optimization in Directed Social Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a4984e10597e3c8a77f1675a48eb7dc6d5252e72",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25586": {
    "title": "Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6796467c5662e07f5f7bbd685f6a9c59cfbf99ec",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25587": {
    "title": "Self-Organization Preserved Graph Structure Learning with Principle of Relevant Information",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b501be9cac69f1fa58ef2887017d0dd94d233b68",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25588": {
    "title": "Efficient Embeddings of Logical Variables for Query Answering over Incomplete Knowledge Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d275bb20b36926e039fb604f9fb93340a70e63c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25589": {
    "title": "Human-Instructed Deep Hierarchical Generative Learning for Automated Urban Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3480471572fd3908e72cf827b3e4ca532f286fc5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25590": {
    "title": "Easy Begun Is Half Done: Spatial-Temporal Graph Modeling with ST-Curriculum Dropout",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e07be0014393a4a8c9521e49bc640074c78b6333",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25591": {
    "title": "Cross-Domain Graph Anomaly Detection via Anomaly-Aware Contrastive Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c310a633d4fe1b3be759588656c0763cacc4071e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25592": {
    "title": "WSiP: Wave Superposition Inspired Pooling for Dynamic Interactions-Aware Trajectory Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ded88b250761f197a5a8b7f225c6f914cc6b49fd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25593": {
    "title": "Beyond Graph Convolutional Network: An Interpretable Regularizer-Centered Optimization Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4239fce31468d3188ce9baed53280051da19c494",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25594": {
    "title": "Augmenting Affective Dependency Graph via Iterative Incongruity Graph Learning for Sarcasm Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f50f7e50573876fde5e9ae714ffb95354b68a0bb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25595": {
    "title": "Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "26ebeeb1b9172df34ad21f1000bb6f3c374a222e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25596": {
    "title": "Online Semi-supervised Learning with Mix-Typed Streaming Features",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c5e68be7506eadf90435539490f6b75343eb7347",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25597": {
    "title": "Few-Shot Composition Learning for Image Retrieval with Prompt Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "510f41c71a8751832cc97d79a0df673a0c2b0539",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25598": {
    "title": "ConTextual Masked Auto-Encoder for Dense Passage Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "63a38cb55e0b9f91c0676efd79089debe61c7768",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25599": {
    "title": "Jointly Imputing Multi-View Data with Optimal Transport",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "781fad0aaf23ca028fa35ba7ad8b3a97d349052b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25600": {
    "title": "Knowledge Graph Embedding by Normalizing Flows",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e3cdedd8c2ce304fdfe861f3c2f4c68e85c9aed",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25601": {
    "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "22157f0bcde877743dc95715cf570d672f76520a",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25602": {
    "title": "SCI: A Spectrum Concentrated Implicit Neural Compression for Biomedical Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d589135b7cc3019a2170676d69b1a4c1505e775c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25603": {
    "title": "Unsupervised Legal Evidence Retrieval via Contrastive Learning with Approximate Aggregated Positive",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc8ba45e69cd4073e43926a7abd8403236f8870b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25604": {
    "title": "One-for-All: Proposal Masked Cross-Class Anomaly Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e29734b4945611c4eeb49bd176086881e71ba25a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25605": {
    "title": "Analogical Inference Enhanced Knowledge Graph Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "354b651dbc3ba2af4c3785ccbecd3df0585d30b2",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25606": {
    "title": "A Noise-Tolerant Differentiable Learning Approach for Single Occurrence Regular Expression with Interleaving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2764258ec19ed233f2871574f31f90e587cdac01",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25607": {
    "title": "Learning from the Wisdom of Crowds: Exploiting Similar Sessions for Session Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "163252e0a3de4b60382e158f0447c647782b591c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25608": {
    "title": "Next POI Recommendation with Dynamic Graph and Explicit Dependency",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b54d3c2e7d971ae03017b0ae196d4abc61c920ce",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25609": {
    "title": "Predicting Temporal Sets with Simplified Fully Connected Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f9c59365254eed5fa64cc9b44c29a23760dc01de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25610": {
    "title": "Learning to Count Isomorphisms with Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "674e14227bd9aacb41a02fb195951ddddd30cd66",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25611": {
    "title": "Untargeted Attack against Federated Recommendation Systems via Poisonous Item Embeddings and the Defense",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77f1d71efcfc733fa9efcdb7492d1310185b0de6",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25612": {
    "title": "Practical Cross-System Shilling Attacks with Limited Access to Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c81c5307175bc683b096496ff44fdb6419ae18ae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25613": {
    "title": "Query-Aware Quantization for Maximum Inner Product Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8e74644b3d1b92037b478303df0860591a030fd3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25614": {
    "title": "TOTTopology-Aware Optimal Transport for Multimodal Hate Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "c90d18d5cd8b1e07f8a8b6b9d14a85b03d55b4b6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25615": {
    "title": "Cross-Domain Few-Shot Graph Classification with a Reinforced Task Coordinator",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12313819cdb18f6e11da1a449a087220810bdd99",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25616": {
    "title": "AutoSTL: Automated Spatio-Temporal Multi-Task Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "64ff803d5256b6b48c74ac5229db4c7a864172a7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25617": {
    "title": "Fair Representation Learning for Recommendation: A Mutual Information Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef720e1b70188ef7f31f73a6940229d7e7dce73b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25618": {
    "title": "Deep Graph Structural Infomax",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c38be73c2e17cd2a0f808fe6ae008c1f248fa989",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25619": {
    "title": "Causal Conditional Hidden Markov Model for Multimodal Traffic Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4472361e74e441a1539251868e077884c7b7042",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25620": {
    "title": "ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1305bbd54db0345533906726e3425f742312c55",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25621": {
    "title": "A Provable Framework of Learning Graph Embeddings via Summarization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc4bf8864aff1d41ad76d677714ea21606b290c4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25622": {
    "title": "GraphSR: A Data Augmentation Algorithm for Imbalanced Node Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "296049ee701634e7919b8f334da285ca7c54bfba",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25623": {
    "title": "Detecting Multivariate Time Series Anomalies with Zero Known Label",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ba2f8dfc1a4fccec80cf95ce3f0eeff3066f21e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25624": {
    "title": "GRLSTM: Trajectory Similarity Computation with Graph-Based Residual LSTM",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "48402bec037fc2a5033c4dc7f90733b7e86da446",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25625": {
    "title": "Heterogeneous Region Embedding with Prompt Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c6f266b833aa65bc8014f8cd052b823929ca2c1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25626": {
    "title": "Show Me the Way! Bilevel Search for Synthesizing Programmatic Strategies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a9f5132f22418f4c3eec95521dc7d3fb959b4f3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25627": {
    "title": "Anytime User Engagement Prediction in Information Cascades for Arbitrary Observation Periods",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c538e5cfc2c908bf833f8453c72f82a63465a26b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25628": {
    "title": "Principled Data-Driven Decision Support for Cyber-Forensic Investigations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36c3e9fce1e1eec51cea57ec5ebc339ba0e11e2c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25629": {
    "title": "BETA-CD: A Bayesian Meta-Learned Cognitive Diagnosis Framework for Personalized Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44deaf38f9a4b9a0c274fbc4acc5ace2d6f06c01",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25630": {
    "title": "Set-to-Sequence Ranking-Based Concept-Aware Learning Path Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a2ac894fad19b6c8bd0984ed5e205d63376cdb7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25631": {
    "title": "Unsupervised Deep Embedded Fusion Representation of Single-Cell Transcriptomics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "79bbb02ade124c82c663b5f1ee9ef9fdce0d4f6d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25632": {
    "title": "Constrained Submodular Optimization for Vaccine Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ded91f056e1d073029b662d69b1847e1cc1060e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25633": {
    "title": "Flow-Based Robust Watermarking with Invertible Noise Layer for Black-Box Distortions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9be90c6279e4133c7b2891bb5513b417da490857",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25634": {
    "title": "Identifying and Eliminating Majority Illusion in Social Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2195aff9d693a39c92c469cd64aef681b6716ad7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25635": {
    "title": "A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention Mechanism for Symbolic Music Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aec9ae3c0e5a5784e171dbb7aa58c209de89e404",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25636": {
    "title": "MSDC: Exploiting Multi-State Power Consumption in Non-intrusive Load Monitoring Based on a Dual-CNN Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c238db86fc92dbd85544f4c89c3c82cf008d06e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25637": {
    "title": "Integrating Reward Maximization and Population Estimation: Sequential Decision-Making for Internal Revenue Service Audit Selection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e17ba7c1a91e51070a308039ef53f0deec2cee2a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25638": {
    "title": "MGTCF: Multi-Generator Tropical Cyclone Forecasting with Heterogeneous Meteorological Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8651b010f8615d6dacd089f510b222e434c46f28",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25639": {
    "title": "MDM: Molecular Diffusion Model for 3D Molecule Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "161858efd41df44a826feb52c27f29eaf8bce80d",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25640": {
    "title": "Learning Chemical Rules of Retrosynthesis with Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cbe75ef6748e461d18f964d99ea7f4e8f8d539a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25641": {
    "title": "Online Symbolic Regression with Informative Query",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b3eee07ad5e785d9d6124a08cce985fe034c83bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25642": {
    "title": "Repair Is Nearly Generation: Multilingual Program Repair with LLMs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "453a8fac3be9282be53908f0735160d0d21e0f48",
    "citation_count": 21
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25643": {
    "title": "Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef7ef2cb643acb5bba3e8c249d0663ee1a4d8108",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25644": {
    "title": "Rolling Horizon Based Temporal Decomposition for the Offline Pickup and Delivery Problem with Time Windows",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "02aeb1c12b95530cd5381d13e0bc9edb121dba4b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25645": {
    "title": "GRIP: Graph Representation of Immune Repertoire Using Graph Neural Network and Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a15c413c629113dde457ffdf10d9a55b76e35a43",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25646": {
    "title": "LagNet: Deep Lagrangian Mechanics for Plug-and-Play Molecular Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a422712a543a43b3c64be2505aa8435333270b1d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25647": {
    "title": "Steganography of Steganographic Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a672ec588ce8c11ef7b68ee8585ccf5766e7827",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25648": {
    "title": "PEN: Prediction-Explanation Network to Forecast Stock Price Movement with Better Explainability",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3901de60ef6fc8f73d0720bd76b0918254d22613",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25649": {
    "title": "Decision-Making Context Interaction Network for Click-Through Rate Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "608632865430a81e20528a57bff20cecc4f3ce1b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25650": {
    "title": "Fine-Grained Position Helps Memorizing More, a Novel Music Compound Transformer Model with Feature Interaction Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "79efb734cef71f93ad4c875044f9fb4d2cd6079d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25651": {
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "376345572946f8710e265e10be270373587d4c4e",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25652": {
    "title": "On Manipulating Weight Predictions in Signed Weighted Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6cf75aa820ccfbb7b07f80ceb4bc446f879ce65a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25653": {
    "title": "Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65f86451e96ad61ffca50eed6a007a19bc03093d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25654": {
    "title": "MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31a84391e1b47fa15f3a521c43d62385a7757637",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25655": {
    "title": "HG-SL: Jointly Learning of Global and Local User Spreading Behavior for Fake News Early Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3c6898458ee72eb35276a1244049b17f5f9be5c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25656": {
    "title": "Defending against Backdoor Attacks in Natural Language Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "834891acb1dfeacb9ff75f923feeca66347167d7",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25657": {
    "title": "GenLive! Generating Rhythm Actions in Love Live!",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27c4f8efcc548e74983c165f99b6711ec1c0699d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25658": {
    "title": "Deepfake Video Detection via Facial Action Dependencies Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3e269034ebfc94da52d2133239114046c8c12ae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25659": {
    "title": "Contrastive Attention Networks for Attribution of Early Modern Print",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d9dc309f719233be9f2a6b6910072e537f96eec8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25660": {
    "title": "AdapSafe: Adaptive and Safe-Certified Deep Reinforcement Learning-Based Frequency Control for Carbon-Neutral Power Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "11389a70e115c21169f365f3e944f517cebfe555",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25661": {
    "title": "Don't Predict Counterfactual Values, Predict Expected Values Instead",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "88d1fc95d1d8452d1cbb41b07fa0829e62f1fb66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25662": {
    "title": "Molformer: Motif-Based Transformer on 3D Heterogeneous Molecular Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "540ed994eb00b5279748d1f26d04371e3a67ec0d",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25663": {
    "title": "DiffMD: A Geometric Diffusion Model for Molecular Dynamics Simulations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6fe2208f1c4dba1c9959f2dd4fdb6c2dc245b713",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25664": {
    "title": "Retrosynthesis Prediction with Local Template Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7045e1e30c2eb8f305dcb8ded655ff659f53fefd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25665": {
    "title": "Multi-Relational Contrastive Learning Graph Neural Network for Drug-Drug Interaction Event Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0ba58a80635fad308adfa41d76931c4f73ba8c54",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25666": {
    "title": "Tighter Robust Upper Bounds for Options via No-Regret Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b764a3ccd99b4bbac95d5f321eb4ad1ac4173224",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25667": {
    "title": "KerPrint: Local-Global Knowledge Graph Enhanced Diagnosis Prediction for Retrospective and Prospective Interpretations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2b5eef580fb9fa9e0f9d946feb2819ad63eb011a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25668": {
    "title": "Multi-Label Few-Shot ICD Coding as Autoregressive Generation with Prompt",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b87c9700b8de4912fe7c361574640b5dc536ca9",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25669": {
    "title": "DMIS: Dynamic Mesh-Based Importance Sampling for Training Physics-Informed Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45017fc77acd06a13d231900f548806bf804beb5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25670": {
    "title": "Bootstrapping Multi-View Representations for Fake News Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38ff6bae846d70d341c8732717c0f593180f318b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25671": {
    "title": "Overcoming Forgetting in Fine-Grained Urban Flow Inference via Adaptive Knowledge Replay",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "54eec69dadad0093b38be8488968e7786a5fb376",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25672": {
    "title": "Generalized Cell Type Annotation and Discovery for Single-Cell RNA-Seq Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7ca5419b63753fbb249860d45a66cbc4052397bd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25673": {
    "title": "Mining and Applying Composition Knowledge of Dance Moves for Style-Concentrated Dance Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b1574e3fff207020073b54b7367f2da80f64740b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25674": {
    "title": "Yet Another Traffic Classifier: A Masked Autoencoder Based Traffic Transformer with Multi-Level Flow Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ba78edb48d729339b109b1ae707daafcca8e005",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25675": {
    "title": "Loan Fraud Users Detection in Online Lending Leveraging Multiple Data Views",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5631b6811a2cff4d35aea151398154a929da8b24",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25676": {
    "title": "Sparse Maximum Margin Learning from Multimodal Human Behavioral Patterns",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4150ac3683f5bb310a409c280123238e0da701f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25677": {
    "title": "Direct Heterogeneous Causal Learning for Resource Allocation Problems in Marketing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1ca2cce6c8e53488983a89bccfe34c976202f7b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25678": {
    "title": "Mediated Cheap Talk Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "b379528382393126720280c848f45bb9aa9db0e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25679": {
    "title": "Bidding Graph Games with Partially-Observable Budgets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cf7c118beeca6e1ed555164151a084a6286a8dc9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25680": {
    "title": "Fairness Concepts for Indivisible Items with Externalities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f92552c73d2b67e671fec7d5fced0f2195dc0502",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25681": {
    "title": "Finding Fair Allocations under Budget Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51e020d339e00afca58dc703ef91d217d00ea869",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25682": {
    "title": "Now We're Talking: Better Deliberation Groups through Submodular Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aead5a64ee1ef40829300401debe649772d7c26c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25683": {
    "title": "Causes of Stability in Dynamic Coalition Formation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d1664faf020d247b8b0a9cc775fb11152a6c38dc",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25684": {
    "title": "Properties of Position Matrices and Their Elections",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0eafc75d4dd73a9491dd031e54af5b048936b83a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25685": {
    "title": "Rank Aggregation Using Scoring Rules",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36814dc10e6f759c87520b080a6dd339f74c32be",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25686": {
    "title": "Proportionality in Approval-Based Participatory Budgeting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c4aed0f334de39822ece80507b83786f9dbc60f",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25687": {
    "title": "Multiwinner Voting with Possibly Unavailable Candidates",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c15f4da85b4d487ffed1b9c731f8411551a8a856",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25688": {
    "title": "Fair Division with Prioritized Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e2eb9aa34c5d218e195a5c9f7706a5be895081e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25689": {
    "title": "Topological Distance Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31cc4da32ba25ce18bace942361fd8eff3fad994",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25690": {
    "title": "Game Implementation: What Are the Obstructions?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bbe7f2e5001559daa2f06b99c7cf5456966953e5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25691": {
    "title": "A Pair-Approximation Method for Modelling the Dynamics of Multi-Agent Stochastic Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ab178e4e4389cc2578617dec3186c313b4a35cb2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25692": {
    "title": "Complexity of Probabilistic Inference in Random Dichotomous Hedonic Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "153d83340025647e8dc36945478cd4ff4eda043e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25693": {
    "title": "Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare Optimality at Equilibrium and Optimal Deviation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7780bfd2cc56a38d0cf34edf88f7be79e9d25dd2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25694": {
    "title": "Strategyproofness and Proportionality in Party-Approval Multiwinner Elections",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3f3c8d4ad8a89239bbd9b2d31a6c54cb396d3930",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25695": {
    "title": "Tight Inapproximability for Graphical Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca20eb26ec877f403db50049252511e47741c23f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25696": {
    "title": "From Monopoly to Competition: Optimal Contests Prevail",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a0108111588f59d44689c7162e930fec1d1701d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25697": {
    "title": "Commitment Games with Conditional Information Disclosure",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "54226bde1774d6a113ad871445775a84962aab35",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25698": {
    "title": "Rawlsian Fairness in Online Bipartite Matching: Two-Sided, Group, and Individual",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e31ff605e3db3449e0c999998365f6c95c2767e6",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25699": {
    "title": "Participatory Budgeting Designs for the Real World",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "183f37a03ca82e44a6468baa7e464c013e892011",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25700": {
    "title": "PAC Learning and Stabilizing Hedonic Games: Towards a Unifying Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27a17341f41c0af03606f43f56cba72b32ffbf94",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25701": {
    "title": "Scalable Edge Blocking Algorithms for Defending Active Directory Style Attack Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c67df2dc35e8d99dc419fbc138bbc1fab579f51",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25702": {
    "title": "Representation with Incomplete Votes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ae0490ac110effedd47d13eeb1e71d33f31da47",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25703": {
    "title": "Optimizing Multiple Simultaneous Objectives for Voting and Facility Location",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0cf0244be1a0ed9d761742614adec024bfa3469",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25704": {
    "title": "Class Fairness in Online Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "462c81b0c6b03df11b4bfa0f0345e100e3b33fbc",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25705": {
    "title": "How to Cut a Discrete Cake Fairly",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "555d80712ae5fcef4b319c3ba0265171cad33768",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25706": {
    "title": "Competition, Alignment, and Equilibria in Digital Marketplaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a2b3696dab23be25c8cda81490c54c5e6ea53c6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25707": {
    "title": "Voting with Preference Intensities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f161bcb249a2ce6a2c97b5d4a93184d89ff39fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25708": {
    "title": "Approximations for Indivisible Concave Allocations with Applications to Nash Welfare Maximization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bd29605b3a91f1d1166a42514a5c96a6d577ccdd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25709": {
    "title": "Strategic Facility Location with Clients That Minimize Total Waiting Time",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a22b3b66794a0d2e06f57753b555b82ee006e591",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25710": {
    "title": "Proportional Decisions in Perpetual Voting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a21a5610157afb24f4a3229f31adea835f507ca2",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25711": {
    "title": "Multiagent MST Cover: Pleasing All Optimally via a Simple Voting Rule",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c8e78fea7189e12c1778fc110852253b0f1ccca4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25712": {
    "title": "When Congestion Games Meet Mobile Crowdsourcing: Selective Information Disclosure",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2310aaa5d2e3cf9d47b1168cd4a560a144cbf28a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25713": {
    "title": "Partitioning Friends Fairly",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fdc1d82b449862d77dbaf26b4d007c80cd74434",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25714": {
    "title": "Differentially Private Condorcet Voting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31d165e97e8e2c13fe3b3dc55e0e338491633b9a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25715": {
    "title": "Function Approximation for Solving Stackelberg Equilibrium in Large Perfect Information Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9f8ff18066b6de9249c76a23d4a8d265bc08ce5b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25716": {
    "title": "Optimal Pricing Schemes for Identical Items with Time-Sensitive Buyers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9ed19cfe4e0dcad4e45f6fe90fe62875dd851378",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25717": {
    "title": "Approval-Based Voting with Mixed Goods",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ddf61206194976246e3498899a3e56c0623f606",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25718": {
    "title": "Utility Maximizer or Value Maximizer: Mechanism Design for Mixed Bidders in Online Advertising",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed2c8a88b17172d3169a5b86fc83e05807639b4b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25719": {
    "title": "Facility Location Games with Entrance Fees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3fc4bde395cfbcf0c3b3ddb0c47fd41d696a9d2e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25720": {
    "title": "Securing Lifelines: Safe Delivery of Critical Services in Areas with Volatile Security Situation via a Stackelberg Game Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9222a8fd12e782e07425db00b085a52824fa62d2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25721": {
    "title": "Differentially Private Fair Division",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3828d5639e3967d199a0cd6d8a5c2aa434a30ba1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25722": {
    "title": "An Efficient Deep Reinforcement Learning Algorithm for Solving Imperfect Information Extensive-Form Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7674101bb85b2fc228d7a6c8b4eace078a8ba381",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25723": {
    "title": "Fast and Interpretable Dynamics for Fisher Markets via Block-Coordinate Updates",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "92841069ddd8ea9c3d9a8e46121430540382aa72",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25724": {
    "title": "Ballot Length in Instant Runoff Voting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "73a36bafe6953371e71d22e011b6aff726e6afab",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25725": {
    "title": "Multi-Stage Facility Location Problems with Transient Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcc51879ceb777063f697f1f5ae0050d273932c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25726": {
    "title": "Bayesian Optimization-Based Combinatorial Assignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ec31c7e532b18a5c1724a34689baba35e050c0e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25727": {
    "title": "Semi-random Impossibilities of Condorcet Criterion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e642adacb243f5448c31072e9c68f05905840848",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25728": {
    "title": "Tournament Fixing Parameterized by Feedback Vertex Set Number Is FPT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "058d26b18a3b230e81fd4259aa2c903b01d93f1c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25729": {
    "title": "Truthful Mechanisms for Steiner Tree Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b2b230df548eef82aa4ed60aa6aa0af29fc0d42",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25730": {
    "title": "Collusion-Proof and Sybil-Proof Reward Mechanisms for Query Incentive Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8459e8869b782ded45ef762d728642d3919ae075",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25731": {
    "title": "Fisher Markets with Social Influence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "189e54a3a2e519bfaa65e33b1d3a35fa0ba2122a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25732": {
    "title": "Probably Approximate Shapley Fairness with Applications in Machine Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6a83c55042d4c48b4cd17b37b8a6991f69d51e6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25733": {
    "title": "The Perils of Trial-and-Error Reward Design: Misdesign through Overfitting and Invalid Task Specifications",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "688fc1e744877c3a68f306443042f016196ce98a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25734": {
    "title": "The Value of AI Guidance in Human Examination of Synthetically-Generated Faces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f02ec8381a96bf00f691fdddc28bc6dfbb8a5780",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25735": {
    "title": "Teaching to Learn: Sequential Teaching of Learners with Internal States",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fa00fa4c018d90f2597d9e5b9a5fd2ee17896f9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25736": {
    "title": "Interactive Concept Bottleneck Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cc7508c4168e8583a9971115117b552479c5f24",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25737": {
    "title": "Local Justice and Machine Learning: Modeling and Inferring Dynamic Ethical Preferences toward Allocations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6dc75e20e8146182e7076450841bbb8c2f70935a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25738": {
    "title": "Extracting Semantic-Dynamic Features for Long-Term Stable Brain Computer Interface",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae324c30938b1c7a871c2de5104cd5a780e52d71",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25739": {
    "title": "Moral Machine or Tyranny of the Majority?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d655026a443d3de40ebacf61274e562ec05936ef",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25740": {
    "title": "The Effect of Modeling Human Rationality Level on Learning Rewards from Multiple Feedback Types",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e920f426eb32e64474b2a1176d97725f875dd82a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25741": {
    "title": "The Role of Heuristics and Biases during Complex Choices with an AI Teammate",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4006f4acbcd0f97b0f4763b1dc1404ad923cfabd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25742": {
    "title": "Learning to Defer with Limited Expert Predictions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "740ea8d58050d823ed4e6bdc89e7b136ada80b26",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25743": {
    "title": "SWL-Adapt: An Unsupervised Domain Adaptation Model with Sample Weight Learning for Cross-User Wearable Human Activity Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e5306c39f2d88c7d479fbd08ae630af7239b5e56",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25744": {
    "title": "Incentive-Boosted Federated Crowdsourcing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4368aa571b71165d19dc08ae1f589296207e144",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25745": {
    "title": "Towards Voice Reconstruction from EEG during Imagined Speech",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c6b97adc9fc7a6619d43b269a9e3dc2321df8f03",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25746": {
    "title": "Evaluating and Improving Interactions with Hazy Oracles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcfcac9943a67748c8f5831272a6ad545b78bcb0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25747": {
    "title": "Human-in-the-Loop Vehicle ReID",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8f5a0db120e6fa63e3555d6e84e4809cb0666de",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25748": {
    "title": "Modeling Human Trust and Reliance in AI-Assisted Decision Making: A Markovian Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7fbdc22ac13f0e1944262379bc1b41d188cc0b5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25749": {
    "title": "Learning Deep Hierarchical Features with Spatial Regularization for One-Class Facial Expression Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "02aa368f27c539415b555b2c01ce037e5ff6b2ec",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25750": {
    "title": "Frustratingly Easy Truth Discovery",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "3dc5c5e420a2bcdb75e98ca55a033b83bea36618",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25751": {
    "title": "Beam Search Optimized Batch Bayesian Active Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d1e41e2de8e79735b0f1302ac28544bdd450ac6e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25752": {
    "title": "Multi-Scale Control Signal-Aware Transformer for Motion Synthesis without Phase",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4c4ee8e1a92e0eda686c3bd80d25c5785c57ed28",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25753": {
    "title": "SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "040c9807983131ad611b3a927e63b1267a37986d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25754": {
    "title": "Human Joint Kinematics Diffusion-Refinement for Stochastic Motion Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "34f622243804ba15e29f1a22a8898eb4cf33772d",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25755": {
    "title": "Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e6c44fa97a3871eb67467cfac40fb6cf56f104d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25756": {
    "title": "Learning to Select Pivotal Samples for Meta Re-weighting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e5e1ef8e856596df92fb65c4459052109014398",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25757": {
    "title": "Better Peer Grading through Bayesian Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c58cd28fbb8ad552b402582d32b068d7aa9452b7",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25758": {
    "title": "Maximum Entropy Population-Based Training for Zero-Shot Human-AI Coordination",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "4270f2493dfd9ae26b9f7c707cf1398ddbbdc0a1",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25759": {
    "title": "A Set of Control Points Conditioned Pedestrian Trajectory Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c6eef90065c8c35e6051e80478c993b48a783e8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25760": {
    "title": "Meta-Auxiliary Learning for Adaptive Human Pose Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "390a927e0c70bdc3e3a327dc8f18a0a90b9f82b9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25761": {
    "title": "Moving-Landmark Assisted Distributed Learning Based Decentralized Cooperative Localization (DL-DCL) with Fault Tolerance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0bf16ee9abecd5fba62b89f9fa29c0d2b6422157",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25762": {
    "title": "Periodic Multi-Agent Path Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "94ccc03294726ad795c0379bf7059aa377ed3b22",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25763": {
    "title": "Improving Robotic Tactile Localization Super-resolution via Spatiotemporal Continuity Learning and Overlapping Air Chambers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "58d73309807f7811722dda39d5867548337e0412",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25764": {
    "title": "Co-imitation: Learning Design and Behaviour by Imitation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "854a3a3212d33a9a05bd498874cfa3ddb0232535",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25765": {
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "08c1b87c94e741c09985d37872c1ae14c6c7c2e4",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25766": {
    "title": "Abstract Argumentation Framework with Conditional Preferences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed43175c3bd2e197de2eb4558528c09017c23c17",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25767": {
    "title": "Reactive Synthesis of Dominant Strategies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "68d20218ac2adae05d799f9b2ea25d8598a1075f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25768": {
    "title": "Complexity of Safety and coSafety Fragments of Linear Temporal Logic",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "11057109ab2652f228d944be6f77c566e86a34e6",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25769": {
    "title": "Automatically Verifying Expressive Epistemic Properties of Programs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ba6cfee1efd0cddec2e744b12f0cca7e76ad3e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25770": {
    "title": "The Effect of Preferences in Abstract Argumentation under a Claim-Centric View",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3971d26cf23d95487e333384a3cb58bfe26dbd32",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25771": {
    "title": "The Parameterized Complexity of Network Microaggregation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "35f9b5d2e666a7139be61e30a939885917e2a844",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25772": {
    "title": "SMT Safety Verification of Ontology-Based Processes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c191ecb6c77ad9c74d6aba0f68f628436ecc6b69",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25773": {
    "title": "Epistemic Disjunctive Datalog for Querying Knowledge Bases",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "716ff41912617caddd2b4386a1071f5ad7249679",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25774": {
    "title": "Learning Logic Programs by Discovering Where Not to Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f7bcdc6e791173001b25acdd3f98b8cc44a7fd69",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25775": {
    "title": "From Width-Based Model Checking to Width-Based Automated Theorem Proving",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b112e2d1f4876f58190322b6496cfa1011736e4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25776": {
    "title": "Model-Checking for Ability-Based Logics with Constrained Plans",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0d9dee80c3177e67cd3e678a9c92ad6beac31b0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25777": {
    "title": "A Structural Complexity Analysis of Synchronous Dynamical Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91704981d91f327d3304eea20d75f318b969448e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25778": {
    "title": "Evaluating Epistemic Logic Programs via Answer Set Programming with Quantifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c27c2a50eb30d1b292b4ef1827532bd7c0d76106",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25779": {
    "title": "Reachability Games Modulo Theories with a Bounded Safety Player",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8e6d4933293895540519b1c31645456da9f94e28",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25780": {
    "title": "Splitting Answer Set Programs with Respect to Intensionality Statements",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7d0725ae29843fdd48075d7c4f228440b377be45",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25781": {
    "title": "Monitoring Arithmetic Temporal Properties on Finite Traces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "441f1b0d50a6e16de8794c1a3154405acfd40559",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25782": {
    "title": "Untangled: A Complete Dynamic Topological Logic",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9bb88a92bf5b3e4bd9813c9a85e6e2d95916311f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25783": {
    "title": "Inconsistent Cores for ASP: The Perks and Perils of Non-monotonicity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cdd45ffb85a3b654d49983f3f8d98075c8aa83f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25784": {
    "title": "General Acyclicity and Cyclicity Notions for the Disjunctive Skolem Chase",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "56a6b99fe7d331e20786cbfedf2c96651539d59c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25785": {
    "title": "GANTEE: Generative Adversarial Network for Taxonomy Enterance Evaluation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "25db8a16e39af2aea2bc2dea7aab1862b04a9b7c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25786": {
    "title": "Finite Based Contraction and Expansion via Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53097257a9bb71b1af91da5d99c211311b0476da",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25787": {
    "title": "MAPS-KB: A Million-Scale Probabilistic Simile Knowledge Base",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "83ab9f2fdb2d7445f8b72b732fe17f9e21603082",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25788": {
    "title": "Characterizing Structural Hardness of Logic Programs: What Makes Cycles and Reachability Hard for Treewidth?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "adbce6d521643cb25c30dc0ffb9d0d0080e7a92c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25789": {
    "title": "Conditional Syntax Splitting for Non-monotonic Inference Operators",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e10984c1c2ac697c49222a118a4cadeffa93f57d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25790": {
    "title": "Relational Program Synthesis with Numerical Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c150adaab6e5887ef9ceae25214076468f42534e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25791": {
    "title": "Common Knowledge of Abstract Groups",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e7f497d35a06594fe2722946a0ed8539b3342817",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25792": {
    "title": "FASTDIAGP: An Algorithm for Parallelized Direct Diagnosis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "349899ad280bcff77e39689df88e0fc7de852a2d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25793": {
    "title": "Two Views of Constrained Differential Privacy: Belief Revision and Update",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc06e5d3cf4ac73f5b6786ac296f9fec15026800",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25794": {
    "title": "Copyright-Certified Distillation Dataset: Distilling One Million Coins into One Bitcoin with Your Private Key",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05cad00486c1ab88452d9b355477851e1bca9075",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25795": {
    "title": "DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link Prediction and Entity Typing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc26b544e5bbdd149d6e52ab6e3fe155684829a2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25796": {
    "title": "Automated Verification of Propositional Agent Abstraction for Classical Planning via CTLK Model Checking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "072f7b74cf9bf19d6b498aed1aeb23ece57cc1e9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25797": {
    "title": "Efficient Answer Enumeration in Description Logics with Functional Roles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "22eddbaef959961c58ec8b23ea5920c2a1fc75de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25798": {
    "title": "Distributed Spectrum-Based Fault Localization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "28ac25147389c16bf5ea4d0fdaa3b1d7bd4f8cea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25799": {
    "title": "Multi-Level Wavelet Mapping Correlation for Statistical Dependence Measurement: Methodology and Performance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61a6c57d88c71dffc1cd0b9ee9a424fa4f5a84b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25800": {
    "title": "Learning Interpretable Temporal Properties from Positive Examples Only",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "713bf335895f27fa0f08a3366cb9f74ad8523d01",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25801": {
    "title": "Editing Boolean Classifiers: A Belief Change Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f7d7e2906b9de71b55a36e155e430c80771df3c0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25802": {
    "title": "Implementing Bounded Revision via Lexicographic Revision and C-revision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "37defded961bbaa40a5a2e4b2e7a4d64fc810761",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25803": {
    "title": "Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4020f2736d49368fc38b3f0c59c6f8b90e29e355",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25804": {
    "title": "Learning to Break Symmetries for Efficient Optimization in Answer Set Programming",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "520d96e06afb9ab0ad9afc3f3a6c31b3fae3d6de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25805": {
    "title": "On Undisputed Sets in Abstract Argumentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a0d92572c348b42c3cdbc7b8ab2c44d0ba8b5a00",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25806": {
    "title": "Neurosymbolic Reasoning and Learning with Restricted Boltzmann Machines",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b1d4dd5f407f08295bc5d9865f5b48bff3d67df",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25807": {
    "title": "Materialisation-Based Reasoning in DatalogMTL with Bounded Intervals",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d4a432b0cc0a5d488915053536af171eb4bd6055",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25808": {
    "title": "Efficient Extraction of EL-Ontology Deductive Modules",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d45b678c6e09dcff3928d060e28e5d621d28272",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25809": {
    "title": "Visually Grounded Commonsense Knowledge Acquisition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03c4ecc2796ecde6a93562fdd149cea10157f805",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25810": {
    "title": "DNG: Taxonomy Expansion by Exploring the Intrinsic Directed Structure on Non-gaussian Space",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5db9df997254ab379f195d7ad494e7ccbab4d91d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25811": {
    "title": "Quality-Aware Self-Training on Differentiable Synthesis of Rare Relational Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bbf8add6afcfba8be55b92dc94dad68d34db6594",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25812": {
    "title": "Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10bbe48c262a4fcf666bf93855bfd3cafb9f71f7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25813": {
    "title": "McOmet: Multimodal Fusion Transformer for Physical Audiovisual Commonsense Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4cf34a7c4b622f48047df066d8be23f8984fbf09",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25814": {
    "title": "Approximating Full Conformal Prediction at Scale via Influence Functions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b29b6315506a0db2cd39cb9faee82c2e8cc0105b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25815": {
    "title": "Efficient Distributed Inference of Deep Neural Networks via Restructuring and Pruning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4850283e7220666b04ee78d43bdc0db38032271",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25816": {
    "title": "Symbolic Metamodels for Interpreting Black-Boxes Using Primitive Functions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b457b163f3e2ffd700918ed8e52d8c18c1115b21",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25817": {
    "title": "Utilizing Prior Solutions for Reward Shaping and Composition in Entropy-Regularized Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3098fd3d604086202f51aee3b5e6071639908be1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25818": {
    "title": "Clustering What Matters: Optimal Approximation for Clustering with Outliers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "443ed32448436d6710b875911c6944bde47a35cf",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25819": {
    "title": "Contrastive Classification and Representation Learning with Probabilistic Interpretation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5afecbef7a28dd25117bc00db3594a8e95968941",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25820": {
    "title": "Simulating Network Paths with Recurrent Buffering Units",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f2bc5f497daf770914737e1c2ad5ed5046a46bbe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25821": {
    "title": "Fully Dynamic Online Selection through Online Contention Resolution Schemes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a1a3675308d7b38e5b02d1b09031d84f4bf39c44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25822": {
    "title": "Tree Learning: Optimal Sample Complexity and Algorithms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2c4e7659c6d577ae7c1cac0d49daba5e28a7efce",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25823": {
    "title": "Meta-Learning for Simple Regret Minimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4160cce636c0f5b40ff004a1489a9ad790e46e94",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25824": {
    "title": "Generalizing Downsampling from Regular Data to Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5de89665d72d63932c993fe5dec8dc0a9f21f9c1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25825": {
    "title": "PiCor: Multi-Task Deep Reinforcement Learning with Policy Correction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ad17af39d0bfcc2498df27dc51de85adfac97704",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25826": {
    "title": "Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72a305df18fe9010374504bce7c0ec485809b7c3",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25827": {
    "title": "Optimal Sparse Recovery with Decision Stumps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a4be3bc405aa5a003e44f1efd2715a1384abf22",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25828": {
    "title": "Towards Efficient and Domain-Agnostic Evasion Attack with High-Dimensional Categorical Inputs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b1e1cc7d450895d4f947c86d123e3e560fa7eff9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25829": {
    "title": "Fairness and Welfare Quantification for Regret in Multi-Armed Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e4470ac0408e958123758f424f85105efdf71fa3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25830": {
    "title": "Alternating Layered Variational Quantum Circuits Can Be Classically Optimized Efficiently Using Classical Shadows",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0499cb8e5a94768e79b577c83fb464b5557d46f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25831": {
    "title": "Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0955cd4702c745d6a93bb5edef64ca143358467",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25832": {
    "title": "Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45693b1fa3c1fcb89a67827fd63b45f0bacf0185",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25833": {
    "title": "Sustaining Fairness via Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1583c318a4b7f97df7c6ab9a55878bd12788a8e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25834": {
    "title": "Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2aeafb78c9fead00f0fe9c8f655ccf0b82bf0390",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25835": {
    "title": "An Improved Algorithm for Online Min-Sum Set Cover",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0317a6788b14e4adf34fdced4826c6ca556b0dae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25836": {
    "title": "AutoInit: Analytic Signal-Preserving Weight Initialization for Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f42e704bbb28331cf1eee2b09f41bcfc0815483e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25837": {
    "title": "A Parameterized Theory of PAC Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "26b394a90119f8ee2a9820d92cc28780c600cca7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25838": {
    "title": "Fully-Dynamic Decision Trees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4b94b06d0b0e12a84c83ee644d3627961715e197",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25839": {
    "title": "Scalable Theory-Driven Regularization of Scene Graph Generation Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f4411c40c4ab7133a1811704428377b43b178b77",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25840": {
    "title": "Toward a Perspectivist Turn in Ground Truthing for Predictive Computing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "75802e1d48ac47d96808e2c9605a17ac1dd07345",
    "citation_count": 37
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25841": {
    "title": "Semantic-Enhanced Image Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef95ed000d71c4b4d3dbddec448c258b210b1402",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25842": {
    "title": "RePreM: Representation Pre-training with Masked Model for Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1b6c1822cc273bc452eb0b3dfbe14de53dd10681",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25843": {
    "title": "FTM: A Frame-Level Timeline Modeling Method for Temporal Graph Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c1a2d4fa243981f3e8af8b37b449a4488b810acd",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25844": {
    "title": "Estimating Treatment Effects from Irregular Time Series Observations with Hidden Confounders",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "896e5cee54d50d7a1f981823b4627948610d72a5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25845": {
    "title": "InParformer: Evolutionary Decomposition Transformers with Interactive Parallel Attention for Long-Term Time Series Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4c0842b95cfaf5591790d9de1cccb4ddde155aa7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25846": {
    "title": "Meta-Sketch: A Neural Data Structure for Estimating Item Frequencies of Data Streams",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6f279bb6ec61f3c5cafb4cd9c7c4e62c2768df3a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25847": {
    "title": "Unfooling Perturbation-Based Post Hoc Explainers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17101501b13b57f6627cf1d6f557375051e21afd",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25848": {
    "title": "Very Fast, Approximate Counterfactual Explanations for Decision Forests",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f7544bfd25ae5baefe62ce3973d368f1c4b2fa70",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25849": {
    "title": "An Equivalence Analysis of Binary Quantification Methods",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1a4131e72b4adfaf3290e27a29e904f0be341e6e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25850": {
    "title": "Soft Action Priors: Towards Robust Policy Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5815a68809dbedb72515cf930f6011761c8d8ea8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25851": {
    "title": "Invariant Representations with Stochastically Quantized Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "550f29904da2ccab4a3211349aa56cb4172a80d0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25852": {
    "title": "Learning Pessimism for Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4729d7b34c60de21fc5f7c9e0e9525936f644ca6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25853": {
    "title": "Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98241cf085a52c5761278ea8eb6c51cffa3a9d38",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25854": {
    "title": "NHITS: Neural Hierarchical Interpolation for Time Series Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "597811b2fa8f5155202a08226acde69efaf1eefb",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25855": {
    "title": "Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for Movement Forecasting in Badminton",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b965a2f6173c1365a492ae6103206bed2be9820",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25856": {
    "title": "Graph Ordering Attention Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "509c7f6ec4ae7d33006f9c5e9c174f61a43df598",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25857": {
    "title": "Scalable and Globally Optimal Generalized L K-center Clustering via Constraint Generation in Mixed Integer Linear Programming",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed0ae2814794c9d86de2d2c04a2aee9cabcc01b5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25858": {
    "title": "Attribute and Structure Preserving Graph Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8730e5e6aec81f191f162d9a621ffe18cabaac82",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25859": {
    "title": "On the Stability and Generalization of Triplet Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c39f3752591181899f680644e8f6ce77cc5a8e3e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25860": {
    "title": "CF-ViT: A General Coarse-to-Fine Method for Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed00842931ebb0db2c634330a77c8dee6f77e547",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25861": {
    "title": "Context-Aware Safe Medication Recommendations with Molecular Graph and DDI Graph Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "795cb7f144184139a0198b99083ecee62ff72991",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25862": {
    "title": "Min-Max Submodular Ranking for Multiple Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d45997fb96b394f4057118d2fb4caba2c9f3321",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25863": {
    "title": "Supervised Contrastive Few-Shot Learning for High-Frequency Time Series",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a2056f5affe509b50e41612057ca9cca143ef97a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25864": {
    "title": "The Sufficiency of Off-Policyness and Soft Clipping: PPO Is Still Insufficient according to an Off-Policy Measure",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a5b68ef4736e235aa596eb6728f284258e11d18",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25865": {
    "title": "Global Convergence of Two-Timescale Actor-Critic for Solving Linear Quadratic Regulator",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4b20c81a39d1ccc41f749f59dbb632e632135d7a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25866": {
    "title": "Topological Pooling on Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77d14bbaece056f5a94231f46f02cca86e9bc085",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25867": {
    "title": "Riemannian Local Mechanism for SPD Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc57be2a8ce6f6ae81bc53a80e9256e4340a6ef5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25868": {
    "title": "TC-DWA:Text Clustering with Dual Word-Level Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "e79fbed9d087f8905e4043108bcf8591f621f21c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25869": {
    "title": "Causal Inference with Conditional Instruments Using Deep Generative Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4f79230f60316394b9cda5896d594c6f4b0c9e37",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25870": {
    "title": "Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1497a56aa25a385e1d60e6a9c2fa60aa7bd17edd",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25871": {
    "title": "Partial-Label Regression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2959a6a949de79fee19c6340e93db35096902a07",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25872": {
    "title": "Offline Quantum Reinforcement Learning in a Conservative Manner",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d116ba398a85cd838618796a10638b9d56b58250",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25873": {
    "title": "Variational Wasserstein Barycenters with C-cyclical Monotonicity Regularization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "556bc791f59b3bc8834960d473d4226957000824",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25874": {
    "title": "MobileTL: On-Device Transfer Learning with Inverted Residual Blocks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ac22b58453c227a560f5ec4527be9f1857ca64c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25875": {
    "title": "Learning Optimal Features via Partial Invariance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "26c61243f679b2cfb1edb4a8f95d1b44132c38f3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25876": {
    "title": "PrimeNet: Pre-training for Irregular Multivariate Time Series",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "70e5e9bd353d1b1e54b4eebd3a67b58026a13dff",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25877": {
    "title": "Structured BFGS Method for Optimal Doubly Stochastic Matrix Approximation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "593f9a54f6e53a0d1c1c19366521ca59e491d77c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25878": {
    "title": "On the Complexity of PAC Learning in Hilbert Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0138f1631efd6425f09f2457d667dbded41af7fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25879": {
    "title": "Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks Using an Incompetent Teacher",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "425669c368004dc43bebaa1d4acdd46a6bcca171",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25880": {
    "title": "Scalable Spatiotemporal Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e60dc704e7933e2a3e83512f345bba0debfe3f3",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25881": {
    "title": "Exploiting Multiple Abstractions in Episodic RL via Reward Shaping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "07e496c302ed32f6da6f535eb4b0f91b58169726",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25882": {
    "title": "Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of CountSketch to Adaptive Inputs",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25883": {
    "title": "Continuous Mixtures of Tractable Probabilistic Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b7e257197e70b5979992fe7c69a7746bae0e184d",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25884": {
    "title": "End-to-End Learning for Optimization via Constraint-Enforcing Approximators",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b6e821d5841d5f2b688d610c3ca64ce4a3ee0c7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25885": {
    "title": "Practical Parallel Algorithms for Submodular Maximization Subject to a Knapsack Constraint with Nearly Optimal Adaptivity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5028562c146dd06b2a9aa8754496b86cb43de326",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25886": {
    "title": "Opposite Online Learning via Sequentially Integrated Stochastic Gradient Descent Estimators",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ba45a6c7b542b0b8e8458ea845854f57eaf96dcc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25887": {
    "title": "Contrastive Learning with the Feature Reconstruction Amplifier",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53901562d0ff14da779f35b6431a4bd836e4bfa5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25888": {
    "title": "Augmented Proximal Policy Optimization for Safe Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ee4efa8f7454770df0c43ce4d6fb65dd085fca5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25889": {
    "title": "GradPU: Positive-Unlabeled Learning via Gradient Penalty and Positive Upweighting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "88e55907283a62d93d4f9b18ab5ecb6f7595f3c7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25890": {
    "title": "Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "336d6ad9ddddbe6ed9a6520e01ba2e951a2f5650",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25891": {
    "title": "Tackling Data Heterogeneity in Federated Learning with Class Prototypes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61cbca5ac40ba71388c6d2235fa25a20014faec0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25892": {
    "title": "CrysGNN: Distilling Pre-trained Knowledge to Enhance Property Prediction for Crystalline Materials",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "4fc96ea53bc8c08bd184126869a22f039ca4dbfe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25893": {
    "title": "Non-reversible Parallel Tempering for Deep Posterior Approximation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "47340a5c393fdf682cb27f6c4ebd96984607e918",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25894": {
    "title": "Stability-Based Generalization Analysis of the Asynchronous Decentralized SGD",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8059c10fb5c16aa1afb5f1263c4f4a1cd689595",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25895": {
    "title": "Integer Subspace Differential Privacy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eccd5376c514492ea39a40720a78139467db024c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25896": {
    "title": "Black-Box Adversarial Attack on Time Series Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cf50e00f39010b3ab3f1f96de15223f5231c652",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25897": {
    "title": "C-NTPP: Learning Cluster-Aware Neural Temporal Point Process",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bf3aed71713f62e1e26971dbf36b920768ff4a71",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25898": {
    "title": "Eliciting Structural and Semantic Global Knowledge in Unsupervised Graph Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcb17372a0233719d84aca856c6147a01e2ba34f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25899": {
    "title": "Incremental Reinforcement Learning with Dual-Adaptive -Greedy Exploration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c1844cda42b3732a5576d05bb6e007eb1db00919",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25900": {
    "title": "Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09f0422754142a1a58182b8238f9cd1b242adab5",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25901": {
    "title": "Non-stationary Risk-Sensitive Reinforcement Learning: Near-Optimal Dynamic Regret, Adaptive Detection, and Separation Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "25457e352e553a89a76ed7fddb8aa9687094614e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25902": {
    "title": "SKDBERT: Compressing BERT via Stochastic Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3eaa17dafc8a86dc5eac9d5b46af248f3f2f6712",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25903": {
    "title": "Model-Based Offline Reinforcement Learning with Local Misspecification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3aa1eafd0198ef0f49f79ff376ac60b170bb10e0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25904": {
    "title": "Can Label-Specific Features Help Partial-Label Learning?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "635aaf49c94c29086a8bf67b4d7819d6c023226e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25905": {
    "title": "Interpreting Unfairness in Graph Neural Networks via Training Node Attribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ec568050b74edfdb7e463200daf42ba36663505c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25906": {
    "title": "Robust and Fast Measure of Information via Low-Rank Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "83838422effa238682d462396a5a251fabb079b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25907": {
    "title": "Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca590583797aad5bd5af7f2c8492a0b14da53810",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25908": {
    "title": "Diffeomorphic Information Neural Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "799b8695fb63c0ea41d9d4d77959b234cf4b4cb3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25909": {
    "title": "Combining Slow and Fast: Complementary Filtering for Dynamics Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8300094620aa145281956869ed7930250af0ad38",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25910": {
    "title": "Popularizing Fairness: Group Fairness and Individual Welfare",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9953d04e41a4a63f8391032a39ac3ee0e3109610",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25911": {
    "title": "FairFed: Enabling Group Fairness in Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5b8cd1183840c5717d2b7cdec298d65d6ec69c32",
    "citation_count": 49
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25912": {
    "title": "Goal-Conditioned Generators of Deep Policies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "46af8550faab2e2b67fef7278eab0b581097e6ea",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25913": {
    "title": "Directed Acyclic Graph Structure Learning from Dynamic Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a0fb1b670f62ac1de989e5f3c439ef5114196892",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25914": {
    "title": "Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4366579b70e6c408e7fd621344bc869c1dda9d0f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25915": {
    "title": "Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "02657f902758c3b85146629fe4faa3feab0ea34f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25916": {
    "title": "Wasserstein Graph Distance Based on L1Approximated Tree Edit Distance between WeisfeilerLehman Subtrees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "a0ee7fda99777066554267a7c211aad9b8e1f4f2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25917": {
    "title": "Combinatorial Causal Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ab3e2e5a7ec0f0f994d468c017c10b5d9cf4c4c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25918": {
    "title": "Scalable Attributed-Graph Subspace Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b2d5c6b55d03dea1273462a0c8e5a8305da4173b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25919": {
    "title": "SigMaNet: One Laplacian to Rule Them All",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5a5ebfb550a3a949f99afcdabddb4f063f0db13f",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25920": {
    "title": "Optimal Decision Diagrams for Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4da0660eb65e50c8e71d57110e118a9c70b3a2d0",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25921": {
    "title": "Estimating Average Causal Effects from Patient Trajectories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fae41e2dded7f20f110a57c61dd0d1dbdd4c6a24",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25922": {
    "title": "Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "165503c48e553a5559190ce74cda823f4e166b54",
    "citation_count": 14
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25923": {
    "title": "EffConv: Efficient Learning of Kernel Sizes for Convolution Layers of CNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "302dc87c74a8cb0c8491f1c29483693eb283df7d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25924": {
    "title": "Fast Counterfactual Inference for History-Based Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80f2036ab4e76c86f69a63e77e000833853c2722",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25925": {
    "title": "Robust Causal Graph Representation Learning against Confounding Effects",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8a4c8b331abc0d5522fc5262595ff7d597c8a93b",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25926": {
    "title": "Towards Decision-Friendly AUC: Learning Multi-Classifier with AUC",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31cdc5c5f6994192f0c93587dc3521428c8931a1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25927": {
    "title": "Long-Tail Cross Modal Hashing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "181f5132f3a353c5bd320de91429bab04b6dbb2d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25928": {
    "title": "Handling Missing Data via Max-Entropy Regularized Graph Autoencoder",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cf0d2eb36235a15a4ad8e2b8d4cf363ff9a530b8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25929": {
    "title": "Reinforced Approximate Exploratory Data Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52055da99bb0fdad22f8c11b96ca69f0d3d7f9e1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25930": {
    "title": "Learning Program Synthesis for Integer Sequences from Scratch",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7658f56be043f2d883eaeaef40998d79cf15a26f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25931": {
    "title": "Semi-transductive Learning for Generalized Zero-Shot Sketch-Based Image Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "db7236a9c1d344fda071d003b49816e2d414b768",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25932": {
    "title": "Multi-Classifier Adversarial Optimization for Active Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fc8f1fd3f350d1c243a8e6cc373d247b3f07ae40",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25933": {
    "title": "Differentially Private Heatmaps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a381bd5c4976f4a8aef5c2a884a1246d592265c7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25934": {
    "title": "DiFA: Differentiable Feature Acquisition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c18c34012cb678a0fd82c848283258bbf6c2f5bf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25935": {
    "title": "Local Intrinsic Dimensional Entropy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5a4dc0635e88c7fe615aa38f7bcf1ef309d7ae16",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25936": {
    "title": "Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c545b21e71c7c51bb4cc1d94bedbf6d6fdd57639",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25937": {
    "title": "Adaptive Hierarchy-Branch Fusion for Online Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cbd86a65d38affa84976dbb968d89c58668c3bee",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25938": {
    "title": "Deep Latent Regularity Network for Modeling Stochastic Partial Differential Equations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3da11f998d7387aeced2945064f90f6af7074d1b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25939": {
    "title": "Dynamic Representation Learning with Temporal Point Processes for Higher-Order Interaction Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6eea9f9fb4f802c509f1cd698ff42f0e67ebf338",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25940": {
    "title": "An Adaptive Layer to Leverage Both Domain and Task Specific Information from Scarce Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91691c66df6bde3d134137dcdc61580503fe7ab9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25941": {
    "title": "Interpolating Graph Pair to Regularize Graph Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "19918de95fdfa9b6dafe5529dc746c0395baad44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25942": {
    "title": "Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "217e4ffcffa4107a38ced923086006b73e9399a4",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25943": {
    "title": "Self-Supervised Bidirectional Learning for Graph Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fcb7161eb81b82d533d410532ddffc871ab61830",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25944": {
    "title": "Boosting Graph Neural Networks via Adaptive Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "402125f4732ef1ec5974ac7513a63bf5b8414611",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25945": {
    "title": "Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dbe429e7edf790b26c0f117027dc2cddb8ab9815",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25946": {
    "title": "Discriminability and Transferability Estimation: A Bayesian Source Importance Estimation Approach for Multi-Source-Free Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1d25e3ff3c28f40bf65b467486d0862476f4e28b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25947": {
    "title": "Astromorphic Self-Repair of Neuromorphic Hardware Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a2d9d1e7e63561f3fe035e24f758f063233a54e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25948": {
    "title": "Estimating Regression Predictive Distributions with Sample Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3c78bda7118e5b887c960c47a0dd476fe782b54",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25949": {
    "title": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic Dimension",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "94f9a6982512e7a06b1cab477f2b06ec12bd86c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25950": {
    "title": "Safeguarded Learned Convex Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "201ee94316891a6659264c86d95438e9594c8431",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25951": {
    "title": "Improving Long-Horizon Imitation through Instruction Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "300bf71c102fe349a082482f791ba15795fe69cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25952": {
    "title": "Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs: Application to Seizure Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29a467cc939db1607061377fa551285481b8fa4c",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25953": {
    "title": "Improving Pareto Front Learning via Multi-Sample Hypernetworks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0c7f2a3ead7688c44b45fb48aa26bf60e6364199",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25954": {
    "title": "Towards Better Visualizing the Decision Basis of Networks via Unfold and Conquer Attribution Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ab28e10316c060589a2d4b02500b537e02900526",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25955": {
    "title": "Federated Robustness Propagation: Sharing Adversarial Robustness in Heterogeneous Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7dd25b1e9bce4d9bbb4aa8fb053d0c68da17a33",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25956": {
    "title": "Compressed Decentralized Learning of Conditional Mean Embedding Operators in Reproducing Kernel Hilbert Spaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d243063362a4b7fd481565d876040dddfef1597d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25957": {
    "title": "RLEKF: An Optimizer for Deep Potential with Ab Initio Accuracy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aaa3c21e1532a73835239e6d75a7951f0cf7e51a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25958": {
    "title": "Background-Mixed Augmentation for Weakly Supervised Change Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e4d8a2985ee177159ff2525aabd7415054b3374",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25959": {
    "title": "Enabling Knowledge Refinement upon New Concepts in Abductive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "970f85cd760979fc5cd70c78420481a2fc675e24",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25960": {
    "title": "Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "399c35dcde2eac017b875af1a21916a9ecb10434",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25961": {
    "title": "Reward-Biased Maximum Likelihood Estimation for Neural Contextual Bandits: A Distributional Learning Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cbf2ca54338251f762a5c548dd50554eeee9df97",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25962": {
    "title": "Learning Noise-Induced Reward Functions for Surpassing Demonstrations in Imitation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6e9f395ccc11296e291b137d31cd882b726258e5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25963": {
    "title": "XClusters: Explainability-First Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "42ce38afc731d63dfd6029eab11be492683dbfc7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25964": {
    "title": "Model-Based Reinforcement Learning with Multinomial Logistic Function Approximation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "139e16319cc2179853c440e9540c41200e3ddd3c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25965": {
    "title": "Fast Regularized Discrete Optimal Transport with Group-Sparse Regularizers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "172fb6a4ac8d0f0f4a9e8617c7babc6a16887d1f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25966": {
    "title": "Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ea9c6d13a8797257ee59429697bf31a41d1b9d2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25967": {
    "title": "Audio-Visual Contrastive Learning with Temporal Self-Supervision",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e475885c185b803ee025bc26c220c5736a5cfd5c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25968": {
    "title": "Confidence-Aware Training of Smoothed Classifiers for Certified Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d95ec70652b3afcfe263bce6e3ba2ccefff2381d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25969": {
    "title": "Learnable Path in Neural Controlled Differential Equations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f5bd94c41926c585157765b31943925cbe1b59ec",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25970": {
    "title": "DrugOOD: Out-of-Distribution Dataset Curator and Benchmark for AI-Aided Drug Discovery  a Focus on Affinity Prediction Problems with Noise Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "dcb21a5a0bc8b6d1bcfff10659e192a95ea20773",
    "citation_count": 32
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25971": {
    "title": "MNER-QG: An End-to-End MRC Framework for Multimodal Named Entity Recognition with Query Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27937956a426872feace4b7c89cf892dbd75451d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25972": {
    "title": "Learning from Training Dynamics: Identifying Mislabeled Data beyond Manually Designed Features",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0858317aa3ebce7ebaae01be87f28925e49e51d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25973": {
    "title": "Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ab82ae37b7d27e79f59e624fa9419682c7cf8b8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25974": {
    "title": "Robust Domain Adaptation for Machine Reading Comprehension",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d0a78f091fdfb5c77ab286400fac125ac8f46927",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25975": {
    "title": "Multi-View MOOC Quality Evaluation via Information-Aware Graph Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1997376d6922b84ca0f372cbb0b9a48596ea497d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25976": {
    "title": "Spatio-Temporal Meta-Graph Learning for Traffic Forecasting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "12dd3ea6cd7041aef237f63c03a3e90fdc16897b",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25977": {
    "title": "Complement Sparsification: Low-Overhead Model Pruning for Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a8da6b76b6d4396e407973d236c7b7d282d7259",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25978": {
    "title": "Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "70de410aece38bf0d5d12fbf03815c80676be742",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25979": {
    "title": "Local-Global Defense against Unsupervised Adversarial Attacks on Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2235f0df7efa6571007c33c3a5f3ea4286be1b9a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25980": {
    "title": "Trafformer: Unify Time and Space in Traffic Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f98ce3517924c03ef82528fb05958934cb97d8d8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25981": {
    "title": "On Solution Functions of Optimization: Universal Approximation and Covering Number Bounds",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1959e2743e7ff857957252dd3af836e0790253a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25982": {
    "title": "Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "647369ee45ecead812991f860caa8a96c6617063",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25983": {
    "title": "Knowledge-Constrained Answer Generation for Open-Ended Video Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0b19fd70c0a45355767473b671e0c2f4774d460",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25984": {
    "title": "POEM: Polarization of Embeddings for Domain-Invariant Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36747690b3dc56fc4479cddc1a9992c2c75fbb58",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25985": {
    "title": "An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7f36e9584a69c7cc38a0267f40c2a8e4645074b5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25986": {
    "title": "Towards More Robust Interpretation via Local Gradient Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a062076a5ff4af5f8e80905d51441779d2891cd7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25987": {
    "title": "Identifying Selection Bias from Observational Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca2820b5b7a877619744d3862401ad6e28478731",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25988": {
    "title": "PIXEL: Physics-Informed Cell Representations for Fast and Accurate PDE Solvers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "162ce23964f2aef2378297da1b20e08a8d77d000",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25989": {
    "title": "On the Sample Complexity of Vanilla Model-Based Offline Reinforcement Learning with Dependent Samples",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d96495c78401e645ee85e38ee042e6e3fc76bad3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25990": {
    "title": "Communication-Efficient Collaborative Best Arm Identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc178a8b1926588ffc179c5bd53edc95b5dcc0bf",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25991": {
    "title": "Variable-Based Calibration for Machine Learning Classifiers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45847e00891099b2fcdc7fb6d4d29852c5b30258",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25992": {
    "title": "Design Amortization for Bayesian Optimal Experimental Design",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "660195b1bc56862f1a781044527080fbe486032d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25993": {
    "title": "On Error and Compression Rates for Prototype Rules",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17422b058269f3b66a32b267a69b50e226796d84",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25994": {
    "title": "CertiFair: A Framework for Certified Global Fairness of Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a287e857f9a002c2d626228ecea6d375035ffd8",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25995": {
    "title": "Key Feature Replacement of In-Distribution Samples for Out-of-Distribution Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee507a5776a2b3c548f712f601ec5e515bd4f8d7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25996": {
    "title": "FLAME: Free-Form Language-Based Motion Synthesis & Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c17a983b11381fabb53f28066f76d4b2dc5a6a17",
    "citation_count": 36
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25997": {
    "title": "Inverse-Reference Priors for Fisher Regularization of Bayesian Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b2caa2a9444341fc539283e86c5e68e7658e6d2b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25998": {
    "title": "Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38b933b515db9cdb834aaecd7f5a1c24e7be6af6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/25999": {
    "title": "Better Generalized Few-Shot Learning Even without Base Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9255f7866199fadec7de87323ce27ca4c5603b6c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26000": {
    "title": "Learning Topology-Specific Experts for Molecular Property Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1604c2854370b9c6c9558b360c566f058ef33e7f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26001": {
    "title": "Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e97740f9ed9cfc7d27c95f3bd7aceb5691aff4be",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26002": {
    "title": "Exploring Temporal Information Dynamics in Spiking Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d7a33032b9cc1401c60ca856fa39c03b838836c1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26003": {
    "title": "FastAMI  a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "54b2c1035b4da593e62f6658a6e064a56c743c16",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26004": {
    "title": "A Gift from Label Smoothing: Robust Training with Adaptive Label Smoothing via Auxiliary Classifier under Label Noise",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18048fcf06e2f131d93dbc1a6c3708f0f188a344",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26005": {
    "title": "Grouping Matrix Based Graph Pooling with Adaptive Number of Clusters",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "c7bbe399aad2da39ba8f988fec83129d60aa5d52",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26006": {
    "title": "The Influence of Dimensions on the Complexity of Computing Decision Trees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65d6bee49cf1d2ebd40014dd53e96c7ab9842ee3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26007": {
    "title": "Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6eb9ecef16437bc76efbe0b016cea3bbdbf8f87",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26008": {
    "title": "Peeling the Onion: Hierarchical Reduction of Data Redundancy for Efficient Vision Transformer Training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a92d2c468835571f3302ce9299fdf37b36c2e367",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26009": {
    "title": "Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6143e809cd2e9c7a18c3bc8819419fd3b02fbcf2",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26010": {
    "title": "Almost Cost-Free Communication in Federated Best Arm Identification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52382817395bb0c6b7c07e1d41dcb2ce7e30ea1a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26011": {
    "title": "UEQMS: UMAP Embedded Quick Mean Shift Algorithm for High Dimensional Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "507217edca49186856896dcf69d6bfbb4eef6d3d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26012": {
    "title": "The Effect of Diversity in Meta-Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "277e80c67e9dcc8572d73ff0cec5c22530df5f8a",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26013": {
    "title": "Gradient Estimation for Binary Latent Variables via Gradient Variance Clipping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc95439462f741ac55ecf8f728aa7c67a41ac6fe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26014": {
    "title": "LoNe Sampler: Graph Node Embeddings by Coordinated Local Neighborhood Sampling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "56f676e55a306303863551beda729a6570aa3e30",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26015": {
    "title": "WLD-Reg: A Data-Dependent Within-Layer Diversity Regularizer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "86d12d692995538259706c383841349433712c72",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26016": {
    "title": "SpatialFormer: Semantic and Target Aware Attentions for Few-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74277b50e285dfaa0adbed61627c10f7ea168997",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26017": {
    "title": "A Data Source for Reasoning Embodied Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5c828011a508611df4d58cced9cc48d049dc4eb9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26018": {
    "title": "Generalization Bounds for Inductive Matrix Completion in Low-Noise Settings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e42259cf0ba53f6c072cadf52d471e943e021387",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26019": {
    "title": "I'm Me, We're Us, and I'm Us: Tri-directional Contrastive Learning on Hypergraphs",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26020": {
    "title": "Bespoke: A Block-Level Neural Network Optimization Framework for Low-Cost Deployment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eb36afb336dff204652ef5dc39c9ce32353e48cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26021": {
    "title": "Time-Aware Random Walk Diffusion to Improve Dynamic Graph Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98293695c9f356ca1a5d667ff41d0287aef9a868",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26022": {
    "title": "Demystifying Randomly Initialized Networks for Evaluating Generative Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "67260931df4bda9bfd816da76dfbf0aafdaf47b0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26023": {
    "title": "Layer-Wise Adaptive Model Aggregation for Scalable Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f9a5d01f2ad2d044703dc50d63c233c5f91fe9a",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26024": {
    "title": "Goal-Conditioned Q-learning as Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "713f4ac842a83650c63e1e43b748fcb5a83bd22d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26025": {
    "title": "Optimism in Face of a Context:Regret Guarantees for Stochastic Contextual MDP",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "3c9ee60cf7e32e08b6f177ac1d104c3ea74c3c76",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26026": {
    "title": "Differentiable Meta Multigraph Search with Partial Message Propagation on Heterogeneous Information Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c42b9e01b1c908a059220f436db2db8dd9d07f11",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26027": {
    "title": "Learning Adversarially Robust Sparse Networks via Weight Reparameterization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72bd3ee3bc2628128e369bb1babd1c776c4f26ed",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26028": {
    "title": "ACE: Cooperative Multi-Agent Q-learning with Bidirectional Action-Dependency",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "48e556c2c67b7d05ea16ec0354bcc0372c927fbb",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26029": {
    "title": "When Online Learning Meets ODE: Learning without Forgetting on Variable Feature Space",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "42ee78b8ae50b905ba4d0b3127f609f100e7e689",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26030": {
    "title": "FanoutNet: A Neuralized PCB Fanout Automation Method Using Deep Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cfb571902b6dca6badfcdbe843add81f9fbba77",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26031": {
    "title": "Causal Recurrent Variational Autoencoder for Medical Time Series Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "22c670c365abefe17d1f99bba584f71d7762944f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26032": {
    "title": "Dual Mutual Information Constraints for Discriminative Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2fe34c646b8cefda49aba1b9eb36689126ea5902",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26033": {
    "title": "AdaBoost.C2: Boosting Classifiers Chains for Multi-Label Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ce63df31e8108d012be79f05d144314820fb5ed3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26034": {
    "title": "Scaling Up Dynamic Graph Representation Learning via Spiking Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f68069bd99ae7413e6db72d2a2906f732a66916",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26035": {
    "title": "Improved Kernel Alignment Regret Bound for Online Kernel Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "123bf0bf0185f67e006cd4dc309efe81a7290c88",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26036": {
    "title": "VBLC: Visibility Boosting and Logit-Constraint Learning for Domain Adaptive Semantic Segmentation under Adverse Conditions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1e515aa55d1609c19fac4b8f640811ec801bee40",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26037": {
    "title": "Understanding the Generalization Performance of Spectral Clustering Algorithms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d54913c6d5ec12d23352d1fbde5de848d65be1da",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26038": {
    "title": "Restructuring Graph for Higher Homophily via Adaptive Spectral Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a9b816d65b92a07791ea8c359f2a2e0cc5746de4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26039": {
    "title": "Nearest-Neighbor Sampling Based Conditional Independence Testing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7e27ec1d6edcfcd87c3c9793320ec27b65fb72a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26040": {
    "title": "Towards Fine-Grained Explainability for Heterogeneous Graph Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80d07f8cf49d0fe88bedde8a578a51fc81d0ed23",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26041": {
    "title": "Metric Nearness Made Practical",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2f91785af642140181f9063fe4b86eae33251c0e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26042": {
    "title": "Predictive Exit: Prediction of Fine-Grained Early Exits for Computation- and Energy-Efficient Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "949b0036c619bda8d3171716b20209b277211d0b",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26043": {
    "title": "Learning with Partial Labels from Semi-supervised Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6f46720a181758da276eb71a38e99b338cec5924",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26044": {
    "title": "Learning Compact Features via In-Training Representation Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fef6bb50c6dce8d4b5fdcaab89400b9776bc00df",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26045": {
    "title": "An Extreme-Adaptive Time Series Prediction Model Based on Probability-Enhanced LSTM Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1023544eb078faa4100c6ac10abc2aa010dd6255",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26046": {
    "title": "Implicit Stochastic Gradient Descent for Training Physics-Informed Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "491b39c1ee81411873de6f1a1f41842195de000d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26047": {
    "title": "Provable Pathways: Learning Multiple Tasks over Multiple Paths",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9b1b0bb968d25b0573f424d7acf5e5b4e7b9fde9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26048": {
    "title": "Towards Inference Efficient Deep Ensemble Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8e9931c561dbba7227baba58f7b487a5e2b5c676",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26049": {
    "title": "SplitNet: A Reinforcement Learning Based Sequence Splitting Method for the MinMax Multiple Travelling Salesman Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ac02c425ce7663042a0052845459f07413900bce",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26050": {
    "title": "Stepdown SLOPE for Controlled Feature Selection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f13fa189356fdc601e52b8a579f27447590258be",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26051": {
    "title": "Positive Distribution Pollution: Rethinking Positive Unlabeled Learning from a Unified Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a488cc69575d623c1bf808209d166bc87e50d97",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26052": {
    "title": "Policy-Independent Behavioral Metric-Based Representation for Deep Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "192e9ef2b836c17022cfdf66dd793c27753db488",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26053": {
    "title": "Geometry-Aware Network for Domain Adaptive Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d339a2889db2190044fbda01808b60a39a75f4f2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26054": {
    "title": "Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a5df174ce3ed582867e1c5d0bae159827d759456",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26055": {
    "title": "On the Expressive Flexibility of Self-Attention Matrices",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "32fa352ee110fd9f80c9d62282611b4a444f5300",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26056": {
    "title": "Wasserstein Actor-Critic: Directed Exploration via Optimism for Continuous-Actions Control",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d26ea31d844d51f11f0703dfae54fdfe9c0d1092",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26057": {
    "title": "Dual Label-Guided Graph Refinement for Multi-View Graph Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "89fdbaa025a339558438160fbcca2e0812abfb56",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26058": {
    "title": "Metric Residual Network for Sample Efficient Goal-Conditioned Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "58a7ecdc94d6e59454c08c9c3e132a9e6ca00094",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26059": {
    "title": "DICNet: Deep Instance-Level Contrastive Network for Double Incomplete Multi-View Multi-Label Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0e3ccfcf9fc94b99536561ba6dd2c9dd49c96bb",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26060": {
    "title": "Incomplete Multi-View Multi-Label Learning via Label-Guided Masked View- and Category-Aware Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "867b2f2a1b041a4157cf3b49e52ff1e03c1aca04",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26061": {
    "title": "Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization for Heterogeneous Representational Coarseness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "677f0dbaeddbfce9a7afb5efb6703798e2c99e0f",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26062": {
    "title": "Combating Mode Collapse via Offline Manifold Entropy Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c6cc2fc16008a57fc35887d55c84ddef0ad68955",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26063": {
    "title": "Robust Representation Learning by Clustering with Bisimulation Metrics for Visual Reinforcement Learning with Distractions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5fda3e94df50485dd7caa6940fa7435ec9bfe80c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26064": {
    "title": "Reliable Robustness Evaluation via Automatically Constructed Attack Ensembles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "117d6de151477f7a1134b117abae09f39ac3a390",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26065": {
    "title": "Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5251da262f05511dfcd48e527ddf2d781e1c33a5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26066": {
    "title": "Safe Multi-View Deep Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4a23f3a7989e4b0b74151f5baaa5555ae917c799",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26067": {
    "title": "Tensor Compressive Sensing Fused Low-Rankness and Local-Smoothness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "db6d22c63e8ec9ea4746c5a6ed1ccf7d1ebe1135",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26068": {
    "title": "Coupling Artificial Neurons in BERT and Biological Neurons in the Human Brain",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "990a61871d6dc1aa474cf334542fb9fbfd32f996",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26069": {
    "title": "EASAL: Entity-Aware Subsequence-Based Active Learning for Named Entity Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a1306e40b8d0c89150967c6b63b4bf4cbf67c8a3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26070": {
    "title": "Online Hyperparameter Optimization for Class-Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ecc0cd4141d0600b04b313dd8e3c12626a8ffc71",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26071": {
    "title": "Hard Sample Aware Network for Contrastive Deep Graph Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d663f1b9ec6e700c7e781e81651186d5208b6ff",
    "citation_count": 15
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26072": {
    "title": "Temporal-Frequency Co-training for Time Series Semi-supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "131819cd0495e02bc2e62be869d07a8c2316a71d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26073": {
    "title": "Q-functionals for Value-Based Continuous Control",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e49fbfba9a959e408ef5dfa5b58f3320ac04735a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26074": {
    "title": "A Coreset Learning Reality Check",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fb3d8ae9e0ac948b2d7dd42293ce508093d160c8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26075": {
    "title": "Centerless Multi-View K-means Based on the Adjacency Matrix",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "576072821acc99b7576b5239b57cae5e63de9404",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26076": {
    "title": "PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3930a0285877386fca94e60c4c69305e220fd4ee",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26077": {
    "title": "Multi-View Domain Adaptive Object Detection on Camera Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fd1b60b1c2c142af4919f4b13b792f89b50cc134",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26078": {
    "title": "Generative Label Enhancement with Gaussian Mixture and Partial Ranking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "066425bb5cc653f0548b30dfcde1cd15f6b254fb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26079": {
    "title": "Crowd-Level Abnormal Behavior Detection via Multi-Scale Motion Consistency Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d31a54553648a1001ebd63b734e5b644c10878f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26080": {
    "title": "MVCINN: Multi-View Diabetic Retinopathy Detection Using a Deep Cross-Interaction Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "852ce0da50b02fd07ab65de6a630cd2111cca543",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26081": {
    "title": "Local Explanations for Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "60f47eb09931260b43812602c636134e9f69f4f7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26082": {
    "title": "Compositional Prototypical Networks for Few-Shot Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed3e8dc12806a03b183e0f5f54a4d1467d12d6fc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26083": {
    "title": "Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2824ad1c27459d43e3482a6ec56579fb3e751233",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26084": {
    "title": "OMPQ: Orthogonal Mixed Precision Quantization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca9ef03e0ff38ea65a7efb8bc1e5907e87a79c15",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26085": {
    "title": "Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "663bcc25755bdb3ca8ead4e5a0f5bb099cae1c4f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26086": {
    "title": "LIMIP: Lifelong Learning to Solve Mixed Integer Programs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a68d81e903e0a5768b9fdfaf6c5400ecc3c95be3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26087": {
    "title": "Proximal Stochastic Recursive Momentum Methods for Nonconvex Composite Decentralized Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0b40fe0a80748daa6096db08648d2f20c7272383",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26088": {
    "title": "Online Reinforcement Learning with Uncertain Episode Lengths",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a533ceb0f5c291c06a595728609b4f419a395c89",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26089": {
    "title": "Tight Performance Guarantees of Imitator Policies with Continuous Actions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50b7baed2365f292b67cf95470b5cec170a69715",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26090": {
    "title": "Weight Predictor Network with Feature Selection for Small Sample Tabular Biomedical Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "830f264dd6d04542abdbcc54488ef491d9bd358a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26091": {
    "title": "Learning Revenue Maximization Using Posted Prices for Stochastic Strategic Patient Buyers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a3a22947eed7be4244ede293d0526f6201b33dc8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26092": {
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "28ec0f9b24b2a909a34308f895fa7deecad31be3",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26093": {
    "title": "Diffusion Models Beat GANs on Topology Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1a1a91f78ec32619a5b2a3b43e0b4d0f7ab97737",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26094": {
    "title": "VIDM: Video Implicit Diffusion Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "13c7b29a100f67d285eb3625c160d06882d4c092",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26095": {
    "title": "Towards Interpreting and Utilizing Symmetry Property in Adversarial Examples",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31383e9125e10365c6f58cf1dfa6f1e158bc8b4f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26096": {
    "title": "The Unreasonable Effectiveness of Deep Evidential Regression",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8b355a9c3ebc035f249407b6cbbc3904b90483fb",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26097": {
    "title": "HyperJump: Accelerating HyperBand via Risk Modelling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "10a17ea81145a70d0bcece01d4338f7060a9023c",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26098": {
    "title": "MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "08a103c145772c83f9544c8798dbcc292bdff762",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26099": {
    "title": "Off-Policy Proximal Policy Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "24d5bf9d25d1f9f46f0a72e9df522d49d747e446",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26100": {
    "title": "Information-Theoretic Causal Discovery and Intervention Detection over Multiple Environments",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0613184b7dbc1793408f89ef133855c676acbc96",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26101": {
    "title": "AIO-P: Expanding Neural Performance Predictors beyond Image Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "20d00e647349b7147316fa4672451a898e80de86",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26102": {
    "title": "GENNAPE: Towards Generalized Neural Architecture Performance Estimators",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "01b4709a79a52105f8afc05d533548823ca81aaa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26103": {
    "title": "Adaptive Perturbation-Based Gradient Estimation for Discrete Latent Variable Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6282364a3a0486219e4878225b58ed850660ad4c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26104": {
    "title": "Why Capsule Neural Networks Do Not Scale: Challenging the Dynamic Parse-Tree Assumption",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "40e95fe0b847e9fac8253900a7fafccf38c560ba",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26105": {
    "title": "Multiplex Graph Representation Learning via Common and Private Information Mining",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c55d0c529b758c3a7112f3f9464ce4c281761548",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26106": {
    "title": "Fundamentals of Task-Agnostic Data Valuation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8a070507b4cdcf4cc67b1e21aa7005fe2611c33",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26107": {
    "title": "Exploring the Interaction between Local and Global Latent Configurations for Clustering Single-Cell RNA-Seq: A Unified Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aceb297295bb86f617eaed59e9a9eb39c839ebb9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26108": {
    "title": "Corruption-Tolerant Algorithms for Generalized Linear Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2eb9e99cc848db3c4715d7e0161ea34146847fe1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26109": {
    "title": "Provably Efficient Causal Model-Based Reinforcement Learning for Systematic Generalization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa4ca2d92b79d19bd938748d1233f7dc58195955",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26110": {
    "title": "Mean Estimation of Truncated Mixtures of Two Gaussians: A Gradient Based Approach",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "395471bcd2fa219a58965edf342949749b94fba2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26111": {
    "title": "An Operator Theoretic Approach for Analyzing Sequence Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d96c0d6c609f460f6761fe56113a461be719989b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26112": {
    "title": "Do Invariances in Deep Neural Networks Align with Human Perception?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d7003050ece3dec9b9104917ac97d440081e70a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26113": {
    "title": "Counterfactual Learning with General Data-Generating Policies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "83ac9832f81f2e2caa9a3620d8f0f8822e54eb8d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26114": {
    "title": "Efficient and Accurate Learning of Mixtures of Plackett-Luce Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b10dbb26277dd57374b5274929a9f10871d1130c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26115": {
    "title": "Behavioral Learning in Security Games: Threat of Multi-Step Manipulative Attacks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "86984f5d5b99cfe975c251098749c8b247184c27",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26116": {
    "title": "On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b61a3d718a192e39a437d32a6ed4037b8c29cc41",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26117": {
    "title": "Fast Saturating Gate for Learning Long Time Scales with Recurrent Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bf979c9598ea185a2b436c52dce0da6382e14f24",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26118": {
    "title": "Backpropagation-Free Deep Learning with Recursive Local Representation Alignment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5ea7d9d34cbe1b6c33c2f1677d577319ed658f16",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26119": {
    "title": "Bilinear Exponential Family of MDPs: Frequentist Regret Bound with Tractable Exploration & Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "b61c60d75f25c8b8cf23131f82d6efaced2ad3cc",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26120": {
    "title": "H-TSP: Hierarchically Solving the Large-Scale Traveling Salesman Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "0973b3c792ee4ee8fc4a22e3b6bc6cd9da9bc98c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26121": {
    "title": "Ising-Traffic: Using Ising Machine Learning to Predict Traffic Congestion under Uncertainty",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3f73e7838bddfd67a265dca2dcc0492091ec5449",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26122": {
    "title": "FedMDFG: Federated Learning with Multi-Gradient Descent and Fair Guidance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e92224b72b14ea4cf8db9801ad328f0bc65f0625",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26123": {
    "title": "Geometric Inductive Biases for Identifiable Unsupervised Learning of Disentangled Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fb2db75f2ee31bdd138543762383cdadbc524213",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26124": {
    "title": "Isometric Manifold Learning Using Hierarchical Flow",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "558e966b86efc2ae667115c1f769bab5955c1a1a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26125": {
    "title": "Evidential Conditional Neural Processes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a116fe984ed47fe320fc78a94ed72fa6e5e9e915",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26126": {
    "title": "Balanced Column-Wise Block Pruning for Maximizing GPU Parallelism",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6872c4cf5268a64f897cf3bcd2af0a5e1e0210e0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26127": {
    "title": "Dynamic Structure Pruning for Compressing CNNs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a58c40f637c8a7441553fe896abc22dedeceed8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26128": {
    "title": "Scaling Marginalized Importance Sampling to High-Dimensional State-Spaces via State Abstraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c6f39c3b73e5966730362bc757f44fe127b4390d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26129": {
    "title": "Conceptual Reinforcement Learning for Language-Conditioned Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc8fc93514b753adda5214528486361d681892a6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26130": {
    "title": "Weighted Policy Constraints for Offline Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cf07c1a9ec10aa546384fbd0cd62b793c3c6b978",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26131": {
    "title": "Latent Autoregressive Source Separation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03d3b8e2a746b4d375c0d0de9ea43d4a37f4b0bd",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26132": {
    "title": "Explaining Random Forests Using Bipolar Argumentation and Markov Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "df6e8c416a0e9ba1f12421b3af34e277e6579728",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26133": {
    "title": "A Model-Agnostic Heuristics for Selective Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ddaaf045afc618f3a1c849d6a088b7982e8477a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26134": {
    "title": "Experimental Observations of the Topology of Convolutional Neural Network Activations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "da55906dec5bd68bd45b2a0806e1d92a35fa0344",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26135": {
    "title": "CMVAE: Causal Meta VAE for Unsupervised Meta-Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f3c276c23f48d5f373346d5668045736f8bb4a06",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26136": {
    "title": "Rethinking Data-Free Quantization as a Zero-Sum Game",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "afe7d5e4a309dea2ac2a8e53c3db61b135b85092",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26137": {
    "title": "Mixture Uniform Distribution Modeling and Asymmetric Mix Distillation for Class Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aa1c7dbacc44b797698744a40c322f55258ddafc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26138": {
    "title": "Mutual-Enhanced Incongruity Learning Network for Multi-Modal Sarcasm Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1656d9cfe2e7474ce11a862db970f34368db36d9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26139": {
    "title": "Training Meta-Surrogate Model for Transferable Adversarial Attack",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a80a626f87b4a30cfff3eea8ee39625075c2f451",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26140": {
    "title": "Stochastic Contextual Bandits with Long Horizon Rewards",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45fbf50820d9c6756225a089dc995db368624f3d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26141": {
    "title": "Gradient-Variation Bound for Online Convex Optimization with Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "b7d659c5ff03696de0d605796ca802ed9d5961bf",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26142": {
    "title": "Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7cf779d889dbf155e089289bab1495be2b186b11",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26143": {
    "title": "GLUECons: A Generic Benchmark for Learning under Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "757ce0529971d496e3c17155b405747f73bc18c3",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26144": {
    "title": "Provable Detection of Propagating Sampling Bias in Prediction Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eab871a8f01a58cd589f5b8853d99aac80419a79",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26145": {
    "title": "Diffusing Gaussian Mixtures for Generating Categorical Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8ae47f3e238304f33c8cfe5f24c054339dbc4080",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26146": {
    "title": "Hypernetworks for Zero-Shot Transfer in Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f36f1a3b75778e6924461c04a607da3db4c0b534",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26147": {
    "title": "Automata Cascades: Expressivity and Sample Complexity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "273b47ea69844de1d142ea61f72fba50afcf0107",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26148": {
    "title": "ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a52f77490300be671942909e09b4ee87e7f23a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26149": {
    "title": "Planning and Learning with Adaptive Lookahead",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4c96156ad9561006c1528ec8ead5d9d3103669a9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26150": {
    "title": "DisGUIDE: Disagreement-Guided Data-Free Model Extraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "406d4e8d2df6f6b58e65016fea31004f781d93e7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26151": {
    "title": "Overcoming Concept Shift in Domain-Aware Settings through Consolidated Internal Distributions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "ffec892fa0a8eecfc595e3ccd524f29f7c6aa789",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26152": {
    "title": "Inferring Patient Zero on Temporal Networks via Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f45702cf78ff21b9bc41c77d4ca1daa5ff58d8c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26153": {
    "title": "Accommodating Audio Modality in CLIP for Multimodal Processing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98ab8260c98030109ba8467f52b13d075276cf0f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26154": {
    "title": "Forecasting with Sparse but Informative Variables: A Case Study in Predicting Blood Glucose",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6e59b0e36f7801a19925a4f82a47ff309fc172c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26155": {
    "title": "On the Sample Complexity of Representation Learning in Multi-Task Bandits with Global and Local Structure",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "138a1de6ec6730fc75c3931018155803ebcb2ca1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26156": {
    "title": "Simultaneously Updating All Persistence Values in Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1711bda8fbf86301c9297b2925419fd8680cd43f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26157": {
    "title": "Continual Learning with Scaled Gradient Projection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8023869b534ae182e3e7d5df25690a062106912d",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26158": {
    "title": "Fast Offline Policy Optimization for Large Scale Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "01c27e295956a30f7208c2e32e73a2cc1a27caee",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26159": {
    "title": "Losses over Labels: Weakly Supervised Learning via Direct Loss Construction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc49647a37e649c3602c16fb06faeeb48d6ab66f",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26160": {
    "title": "Representation Learning by Detecting Incorrect Location Embeddings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c1601b65e354ba042e6952e233fff17b5475a94",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26161": {
    "title": "Sparse Coding in a Dual Memory System for Lifelong Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "362211dccace94cafc72c819d381b836c443593e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26162": {
    "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "00768994cec0d2e74545180a59ab5407469da9ff",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26163": {
    "title": "Dropout Is NOT All You Need to Prevent Gradient Leakage",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ed5671f95cefda22861c0cddd54d50bcdcdd90fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26164": {
    "title": "Exploration via Epistemic Value Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0670b6552f53d2ed8b56a712bb0db4783138123a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26165": {
    "title": "Multi-Source Survival Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "00d3b4aacc5cc95277f7e3e0f560d79781a4e65a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26166": {
    "title": "What Do You MEME? Generating Explanations for Visual Semantic Role Labelling in Memes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9b659d02ffe695707077b6a3b3475fc67d168e96",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26167": {
    "title": "Post-hoc Uncertainty Learning Using a Dirichlet Meta-Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0647c14721528fc1950f883036e0806d7b3be6f9",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26168": {
    "title": "Neighbor Contrastive Learning on Learnable Graph Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "be6161dd5eaa1b1ecc4e62348b43e52f134ed3f5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26169": {
    "title": "ProxyBO: Accelerating Neural Architecture Search via Bayesian Optimization with Zero-Cost Proxies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9891b45b1aaac6a602e848381d145c825645e040",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26170": {
    "title": "Contrastive Predictive Autoencoders for Dynamic Point Cloud Self-Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1297adc46af434f188ca8ea1c95638849eed36b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26171": {
    "title": "Fixed-Weight Difference Target Propagation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a1b07aad0583274d2c87e0baacd0b18183d2d582",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26172": {
    "title": "Concurrent Multi-Label Prediction in Event Streams",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f2706bbbf0a69729410f62a826b18aa5b1fbe052",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26173": {
    "title": "A Generalized Unbiased Risk Estimator for Learning with Augmented Classes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5dd1c14cc13e80ded379a8ed4cb04cbaed9aa01d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26174": {
    "title": "Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8f8b06780acbe9e2a0356c8acfcfa209bed40bd6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26175": {
    "title": "SLIQ: Quantum Image Similarity Networks on Noisy Quantum Computers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e00e31758a224b638cc24577d3813e01a1eb0427",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26176": {
    "title": "Adaptive Mixing of Auxiliary Losses in Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "063acc1ea6ebeb4e4310e2990583f8fed253bf05",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26177": {
    "title": "Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2cb10b11951246878ad3fbd26313014e7d55b863",
    "citation_count": 29
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26178": {
    "title": "Mixture Manifold Networks: A Computationally Efficient Baseline for Inverse Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3fd8d46297d671e3400e4e4aba2f991b1bb14726",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26179": {
    "title": "Sharing Pattern Submodels for Prediction with Missing Values",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "41b729a8ff8e0d02f72774649ea5566db413ad18",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26180": {
    "title": "Scalable Optimal Multiway-Split Decision Trees with Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4cba7dfa7dc169223b1eff0c7d49955fb1cec695",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26181": {
    "title": "REMIT: Reinforced Multi-Interest Transfer for Cross-Domain Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "435514442f10030d15c6f895eb7b10912a766680",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26182": {
    "title": "Cooperative and Adversarial Learning: Co-enhancing Discriminability and Transferability in Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c7418ac06f023a210f293a66489b4a8fd4a7e4ea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26183": {
    "title": "Fair-CDA: Continuous and Directional Augmentation for Group Fairness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e9030eaaecd19228637d4ddc6ee86745152bd579",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26184": {
    "title": "Neural Spline Search for Quantile Probabilistic Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9990802f546a575e2dd7226742e2a94f1ea50302",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26185": {
    "title": "Domain Adaptation with Adversarial Training on Penultimate Activations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "784d2998bf94b0863e7134be4e6d87dcf2884b59",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26186": {
    "title": "Fast Convergence in Learning Two-Layer Neural Networks with Separable Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4ac4e716d5e1aaacb15d6fc4c89decce59d45e37",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26187": {
    "title": "Federated Learning on Non-IID Graphs via Structural Knowledge Sharing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2f325e874aa12ebbf8f5028076e7c4c75831ce54",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26188": {
    "title": "Metric Multi-View Graph Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1a01f8994899713953d4a6f4a1cc2a638054a4a5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26189": {
    "title": "DE-net: Dynamic Text-Guided Image Editing Adversarial Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "471c1fb7477a94504b7ba3e796bcf3de13db3b57",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26190": {
    "title": "Knowledge Amalgamation for Multi-Label Classification via Label Dependency Transfer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "681b1f0320a724f9586ceba8f1f90d80b0f7d2e4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26191": {
    "title": "Leveraging Contaminated Datasets to Learn Clean-Data Distribution with Purified Generative Adversarial Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d910b5b48859c66df9db3f8c75f653ece102676",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26192": {
    "title": "Heterogeneous Graph Masked Autoencoders",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6109164f49ae02a92579eb0c374fbd5f7948e740",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26193": {
    "title": "Unbalanced CO-optimal Transport",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "d778eda5b8e99c4dedea29e7c3e5450cc3f95a4e",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26194": {
    "title": "Linear Regularizers Enforce the Strict Saddle Property",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1703faed266b7a9dc3e67f5b6254044b86b1a959",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26195": {
    "title": "Policy-Adaptive Estimator Selection for Off-Policy Evaluation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a9d1e2b1ccfdae5eb4ea96e3d1803fe55aaf13c1",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26196": {
    "title": "A Fair Generative Model Using LeCam Divergence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14f5e4afdd089120aa171edb7bfd424f243a618d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26197": {
    "title": "Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles between Client Data Subspaces",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2f45018de9e420ab4126becceee857331b488637",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26198": {
    "title": "Training-Time Attacks against K-nearest Neighbors",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "76dc6a8643daa0134a5372ca524e275cf756e9a3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26199": {
    "title": "Machines of Finite Depth: Towards a Formalization of Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5b932ddfe7053b49edf1e7d32a4a3cbfa70288e4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26200": {
    "title": "Kalman Bayesian Neural Networks for Closed-Form Online Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "89f0e11f76c4d91b0838a940c31203e5635a45ce",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26201": {
    "title": "Auto-Weighted Multi-View Clustering for Large-Scale Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4140a8b76168c5817dab043b3dc3ef9bc6e9cf72",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26202": {
    "title": "Quantum Multi-Armed Bandits and Stochastic Linear Bandits Enjoy Logarithmic Regrets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "218859bdb4492fcfa4b2f5fb2c945c25ae37691d",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26203": {
    "title": "FedABC: Targeting Fair Competition in Personalized Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7ea77fcebe88acbb1396549b297965ad40d38875",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26204": {
    "title": "Spearman Rank Correlation Screening for Ultrahigh-Dimensional Censored Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "da2815a08ac8a2885f9c6bec3b2de513bebf683d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26205": {
    "title": "Stability-Based Generalization Analysis for Mixtures of Pointwise and Pairwise Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f79eb1c0d0a044ed0dbb36883ff10a0b09867c5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26206": {
    "title": "Effective Continual Learning for Text Classification with Lightweight Snapshots",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a21037a45a1a7b886fd3e09e953cb79de19ccc3d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26207": {
    "title": "Optimistic Whittle Index Policy: Online Learning for Restless Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "44a32991258416e1fb0bbc2d91a960edce960f2e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26208": {
    "title": "AEC-GAN: Adversarial Error Correction GANs for Auto-Regressive Long Time-Series Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a084f14b45e83fd2d870d0cdbe38560cd2c07c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26209": {
    "title": "The Implicit Regularization of Momentum Gradient Descent in Overparametrized Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ca887ea35e2eeeb17801cbed3515ea4965c65789",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26210": {
    "title": "Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eabfc1846af8f09d6c65e45cb04f83fa397f6799",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26211": {
    "title": "Hierarchical Contrastive Learning for Temporal Point Processes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a074e060cde0ddbb535e22863df43322a5627efb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26212": {
    "title": "Beyond ADMM: A Unified Client-Variance-Reduced Adaptive Federated Learning Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e10a8abd5c7f2d6ecbe76412a56762d61b0efcbf",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26213": {
    "title": "State-Conditioned Adversarial Subgoal Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c397a67aad5bd5d08364135ac01b028af930c604",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26214": {
    "title": "Deep Attentive Model for Knowledge Tracing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e0fc4b0410f3f7a31e3cc1c2b96d856d51fbd82a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26215": {
    "title": "Correspondence-Free Domain Alignment for Unsupervised Cross-Domain Image Retrieval",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5a572fb106197d8d4f0a81f26abb2b20e2e0aa3f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26216": {
    "title": "Isolation and Impartial Aggregation: A Paradigm of Incremental Learning without Interference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "30fd486635c6174ea340c0ee003b241d32f011ce",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26217": {
    "title": "Robust Self-Supervised Multi-Instance Learning with Structure Awareness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4494cded00ff0ef0d686cc2261b891686d7ad3d6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26218": {
    "title": "Distributed Projection-Free Online Learning for Smooth and Convex Losses",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d2f11656462ed2dfc3c58da48ba12609460541b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26219": {
    "title": "USER: Unsupervised Structural Entropy-Based Robust Graph Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bd7dbcb7e51edc56427b5eb1c7d0a4275dfe44a6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26220": {
    "title": "AutoNF: Automated Architecture Optimization of Normalizing Flows with Unconstrained Continuous Relaxation Admitting Optimal Discrete Solution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "79a5783a3dc2c19c632bc5d39a57b17c87ce9633",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26221": {
    "title": "SEnsor Alignment for Multivariate Time-Series Unsupervised Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "33c948c4a5631806830df3dda01528cabd44bede",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26222": {
    "title": "Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fbf48e013c963aa90fa3bfd04604935d952d674a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26223": {
    "title": "FedGS: Federated Graph-Based Sampling with Arbitrary Client Availability",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98a325486370aae953268046e9e1d6fb2ed86fed",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26224": {
    "title": "Efficient Exploration in Resource-Restricted Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d3b0704c61d47c7bafb70ae2670b2786b8e4d81",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26225": {
    "title": "Efficient Explorative Key-Term Selection Strategies for Conversational Contextual Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "79aaa0a554a1f415c9cc59eeeab8ebda4fc15379",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26226": {
    "title": "Code-Aware Cross-Program Transfer Hyperparameter Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "27c5a594fb37d33640fadeaa07d0466211a60578",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26227": {
    "title": "Predictive Multiplicity in Probabilistic Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4217a85c206e0dafd8fc39da2adc55c311ba373a",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26228": {
    "title": "Feature Distribution Fitting with Direction-Driven Weighting for Few-Shot Images Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f8680befeea08e92981739a9cf68e3332f9fa7f5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26229": {
    "title": "Learning Instrumental Variable from Data Fusion for Treatment Effect Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7aae7745d8ee4dab3e7db7037e501474332d18fd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26230": {
    "title": "Towards In-Distribution Compatible Out-of-Distribution Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5aa0ccbd38dca97b6d20b37bf9f3c8a414fa26a0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26231": {
    "title": "Non-IID Transfer Learning on Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "aaca28e64dd9dfd3cbcd8082d0169ebdd7326a88",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26232": {
    "title": "Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and Injecting It into MLPs: An Effective GNN-to-MLP Distillation Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0648a22c8f65fbe5767650c5e779d9b2888515ea",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26233": {
    "title": "Symphony in the Latent Space: Provably Integrating High-Dimensional Techniques with Non-linear Machine Learning Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "099c63db93000de4d6bcefe196f46afeb22d2fd0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26234": {
    "title": "Decentralized Riemannian Algorithm for Nonconvex Minimax Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "594d1a5df8db8de6dfaf2f703d55202a2bb7a58d",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26235": {
    "title": "Faster Adaptive Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1fd1109ec922dcd683190a42dd5712b4eb6113b2",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26236": {
    "title": "Practical Markov Boundary Learning without Strong Assumptions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5e3a726719af0b96b4ab4d117ac5e3e54bef5dc1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26237": {
    "title": "FedNP: Towards Non-IID Federated Learning via Federated Neural Propagation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4648ca42ed12b940fbe4f1b2b3d2a14b1d29dc44",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26238": {
    "title": "MetaZSCIL: A Meta-Learning Approach for Generalized Zero-Shot Class Incremental Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "07ea2ebadf13d1f84c72d44ae5a9ed36af168a69",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26239": {
    "title": "Adversarial Weight Perturbation Improves Generalization in Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "1e0930a6c4ad4c62c725cfa35e76081eb971a83a",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26240": {
    "title": "Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1f18bd6c3d216d8f7c6186267cfe6dce5a66d7a7",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26241": {
    "title": "Models as Agents: Optimizing Multi-Step Predictions of Interactive Local Models in Model-Based Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8e839087b28dc469a47a184cbd197b21f32d9e6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26242": {
    "title": "Differentially Private Learning with Per-Sample Adaptive Clipping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2d3c5468de7641262e9c6cb8366049098e88371e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26243": {
    "title": "Zero-Cost Operation Scoring in Differentiable Architecture Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8a8c7dbf7b499c17c8e74a80b7f99918e467b69",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26244": {
    "title": "HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "60004428c219a22443a33fe27051f246fa99e263",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26245": {
    "title": "Bayesian Federated Neural Matching That Completes Full Information",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ff13b88c34855d1342f58e4c36509b285c1ddeb2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26246": {
    "title": "CDMA: A Practical Cross-Device Federated Learning Algorithm for General Minimax Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "91ec9f720172dada9ef45f9d11e53df084ec4d3d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26247": {
    "title": "Towards Optimal Randomized Strategies in Adversarial Example Game",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e6e7544a50373e59271019304e91f2a6b450ed46",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26248": {
    "title": "A Tale of Two Latent Flows: Learning Latent Space Normalizing Flow with Short-Run Langevin Flow for Approximate Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2314afc804b9c425cefda5c7854ac4110e7b4812",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26249": {
    "title": "Semi-supervised Learning with Support Isolation by Small-Paced Self-Training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "076372bb5d005e1d4b554b02fc14044d541dd78b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26250": {
    "title": "On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "48a433a400c9abb6714c351b5423b396212bf0c5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26251": {
    "title": "Decentralized Stochastic Multi-Player Multi-Armed Walking Bandits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3fd11026cf0ac132decd37379f9bc9952799c301",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26252": {
    "title": "Federated Generative Model on Multi-Source Heterogeneous Data in IoT",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8bf3da565ba41d6f250783985a6dc3fe8b4530a5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26253": {
    "title": "Contrastive Open Set Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f67894d00bb31297f3d6c8a8a8d8de9276d3b6fc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26254": {
    "title": "Progressive Deep Multi-View Comprehensive Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3f78556059320f881c4ff5f7ce7fe8a35f393941",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26255": {
    "title": "A Survey on Model Compression and Acceleration for Pretrained Language Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c546e5447f412bf4f274e490996718641b211aa6",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26256": {
    "title": "GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6628b4ac0b432659a0092add3eb371608d3e065",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26257": {
    "title": "Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03446d8730c4bc5cb3abc9d8c13e8e6d3898e2ae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26258": {
    "title": "Efficient Top-K Feature Selection Using Coordinate Descent Method",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2e7fdbb628a22000fcdc3138d83a4f6c1bb14633",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26259": {
    "title": "Label-Specific Feature Augmentation for Long-Tailed Multi-Label Text Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3e525d0a7f6886b82d3b5e82d5a40d7d514eb2f0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26260": {
    "title": "Neighborhood-Regularized Self-Training for Learning with Few Labels",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "728a34d0cbd7fef95ce8c6016e4db803d565b860",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26261": {
    "title": "Resilient Binary Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a13eb514c83580a1678efa562c7a02c60b6983fd",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26262": {
    "title": "Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a2ab63a272fa0762a75eb3d1b0a86506a9db3623",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26263": {
    "title": "BridgeTower: Building Bridges between Encoders in Vision-Language Representation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "4c2668b3ae22fa592716480ec56012775b139f52",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26264": {
    "title": "USDNL: Uncertainty-Based Single Dropout in Noisy Label Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc81135198f11b1b8015ccb02a8da0905259d68c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26265": {
    "title": "Trusted Fine-Grained Image Classification through Hierarchical Evidence Fusion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a5f444de5f3048e9ae55a92cd4b80ccba05b90c7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26266": {
    "title": "Disentangled Representation for Causal Mediation Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b674763fa4dadab6d65665d7a85a363bf6f914bc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26267": {
    "title": "Global Concept-Based Interpretability for Graph Neural Networks via Neuron Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1566fedfe843ac88fb36803368fa84bed6db2af3",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26268": {
    "title": "Fast and Accurate Binary Neural Networks Based on Depth-Width Reshaping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18890b992894944bec789d1b4d9b2356382d8c28",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26269": {
    "title": "Learning the Finer Things: Bayesian Structure Learning at the Instantiation Level",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f00c90ad2f54475c2f43512a36d1fd8d673b366f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26270": {
    "title": "Semidefinite Programming versus Burer-Monteiro Factorization for Matrix Sensing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a113d264a02bd84fc6b3ea663fee2cdfb5b5bcf",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26271": {
    "title": "DeFL: Defending against Model Poisoning Attacks in Federated Learning via Critical Learning Periods Awareness",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85e7ca020c740d9dfadfa520b9d6d2c8f383ec7f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26272": {
    "title": "T2G-FORMER: Organizing Tabular Features into Relation Graphs Promotes Heterogeneous Feature Interaction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "611fb68240299adf0b19450b9972c55fc63df483",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26273": {
    "title": "Computably Continuous Reinforcement-Learning Objectives Are PAC-Learnable",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d3cce69894f847a66e58e2c16d2f55ab404d2892",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26274": {
    "title": "Reinforcement Causal Structure Learning on Order Graph",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e283032acaed9db53c3fc447837d2793cffa2ddc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26275": {
    "title": "AdaTask: A Task-Aware Adaptive Learning Rate Approach to Multi-Task Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8522f9a7bc7c958b5f66373b47ff68e1833089d6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26276": {
    "title": "WaveForM: Graph Enhanced Wavelet Learning for Long Sequence Forecasting of Multivariate Time Series",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17332418d299ef1cbd41cfcaf0a3a3141a7a8483",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26277": {
    "title": "Layout Generation as Intermediate Action Sequence Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2096dbecf841988c15d97df2cdb033cfd8cd5151",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26278": {
    "title": "Learning-Assisted Algorithm Unrolling for Online Optimization with Budget Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f94c9daee84e5213703800863f6c0111b32bfbef",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26279": {
    "title": "ADEPT: A DEbiasing PrompT Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1abd4fa45ce20175452aa238870db2aebe9c0fe0",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26280": {
    "title": "Generalized Semantic Segmentation by Self-Supervised Source Domain Projection and Multi-Level Contrastive Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2d9cc109363eae1aeb873245833b440ed917409e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26281": {
    "title": "CEM: Constrained Entropy Maximization for Task-Agnostic Safe Exploration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0a806876e419de58b650aacbf218e23f589327ad",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26282": {
    "title": "Understanding Representation Learnability of Nonlinear Self-Supervised Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "65909b7b029f8214f574f81f4dfbef1fe7289037",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26283": {
    "title": "Simple and Efficient Heterogeneous Graph Neural Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "db5f713db2730eb07c0bd7c5103e0c7e2b3e9ceb",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26284": {
    "title": "T-distributed Spherical Feature Representation for Imbalanced Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "012b5b6e90821784c0221f75d627469425e4b178",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26285": {
    "title": "Cluster-Guided Contrastive Graph Clustering Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9706835a2bf6d727993e7bc4610067dc35cc5336",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26286": {
    "title": "Flow to Control: Offline Reinforcement Learning with Lossless Primitive Discovery",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9d1445f1845a2880ff9c752845660e9c294aa7b5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26287": {
    "title": "Prototypical Partial Optimal Transport for Universal Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85d1cd4db2246b32c4b68bfdb1532c7d89bd64ea",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26288": {
    "title": "DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "708b04a43ceb2a914652d2b3a8b5afe28b1875ba",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26289": {
    "title": "Purifier: Defending Data Inference Attacks via Transforming Confidence Scores",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f605cb07365acd44f7ddc64711606c834f62afef",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26290": {
    "title": "i-Code: An Integrative and Composable Multimodal Learning Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b60879dda0183160c9d0a611cb7e381e6942cf75",
    "citation_count": 20
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26291": {
    "title": "Learning Dynamic Latent Spaces for Lifelong Generative Modelling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "94d1500cb6b280ff201047bf831593c4659581b7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26292": {
    "title": "Lifelong Compression Mixture Model via Knowledge Relationship Graph",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8a560ebfb5ccf6caa8f838080c42f3686dcbdc5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26293": {
    "title": "Lifelong Variational Autoencoder via Online Adversarial Expansion Strategy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a360413dc4fea6fe6d7d85e0396e2e55fc6a856c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26294": {
    "title": "Continual Variational Autoencoder via Continual Generative Knowledge Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8be84129d04f13cfba51fc8ab453044721d16ecf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26295": {
    "title": "Certifiable Out-of-Distribution Generalization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6a99abc1a04244c4950c5ad999b5ebb20bdc1bd0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26296": {
    "title": "Random Walk Conformer: Learning Graph Representation from Long and Short Range",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d6c2ce832157f54e1fe717bd3b1a9c4d4619c26e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26297": {
    "title": "Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "173a41e7f0eebca7deadaa623d36f83ad93c9bf5",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26298": {
    "title": "GOHSP: A Unified Framework of Graph and Optimization-Based Heterogeneous Structured Pruning for Vision Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ea79430455304c782572dfb6ca3e5230b0351de",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26299": {
    "title": "Policy-Based Primal-Dual Methods for Convex Constrained Markov Decision Processes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7a9c4cc5bd91fe5a0a2a0e0693f1b2bc89cd70e4",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26300": {
    "title": "Priori Anchor Labels Supervised Scalable Multi-View Bipartite Graph Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b3753e2b30662c7d0135fd28cd56c0c193cf7d65",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26301": {
    "title": "STARS: Spatial-Temporal Active Re-sampling for Label-Efficient Learning from Noisy Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "830a4bc446c7c9d87975a95b7cea54e2d11d5727",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26302": {
    "title": "Boosted Dynamic Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eda07e0ab8396f45db07c39a1c7fa643d08b07c3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26303": {
    "title": "Stable Learning via Sparse Variable Independence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1b5ca7d17c5b46a0c93c1a4e828ddf2a94f389a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26304": {
    "title": "Compressing Transformers: Features Are Low-Rank, but Weights Are Not!",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "568160c414aa26284b04cdf3e13d25b9d7a5a290",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26305": {
    "title": "Offline Imitation Learning with Suboptimal Demonstrations via Relaxed Distribution Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d05a0088e6ab6ba367650527c7e1cc46524da3dc",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26306": {
    "title": "High-Level Semantic Feature Matters Few-Shot Unsupervised Domain Adaptation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "01b14c1c3e2b5b4042d57f1a2be47d423c7fd68b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26307": {
    "title": "Coordinate Descent Methods for DC Minimization: Optimality Conditions and Global Convergence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8dfe3f91bed3c7536b99607e342ee9badc3dc9c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26308": {
    "title": "CEMA  Cost-Efficient Machine-Assisted Document Annotations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "1dd63eff40175f2ad76b395313fa13c23393ebef",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26309": {
    "title": "Joint Multimodal Entity-Relation Extraction Based on Edge-Enhanced Graph Alignment Network and Word-Pair Relation Tagging",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74e14a0f55bdc0b8fa7548e0762f58cf493a12a3",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26310": {
    "title": "ODE-RSSM: Learning Stochastic Recurrent State Space Model from Irregularly Sampled Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3468d4cbfd51bd2013946e7a7df1fb95253f707f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26311": {
    "title": "Value-Consistent Representation Learning for Data-Efficient Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e3c598f5233d91f887edb626bb02ba86010a69c0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26312": {
    "title": "Learning Conflict-Noticed Architecture for Multi-Task Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8f9e13380a4ccf99e8d4a0f1dd4c36cd311f8b60",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26313": {
    "title": "Quantum Multi-Agent Meta Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6e85ed4c60ccc8eef4cc5ad69e677d0f9f5bdbfc",
    "citation_count": 13
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26314": {
    "title": "Linking Sketch Patches by Learning Synonymous Proximity for Graphic Sketch Representation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b5458d11c6b64ab51d96581a708bb0ad40001a81",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26315": {
    "title": "Neural Integro-Differential Equations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9e740a91d943873000968afb0b137c83d65959a2",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26316": {
    "title": "Leveraging Structure for Improved Classification of Grouped Biased Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7331eb901d313073d7bfe8368af826d923b6a1b2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26317": {
    "title": "Are Transformers Effective for Time Series Forecasting?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5be02c8db2078bb72224438df8003552e49b23a8",
    "citation_count": 109
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26318": {
    "title": "Substructure Aware Graph Neural Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f70fbf51b5ff4ba4c6a0766bc77831aff9176d16",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26319": {
    "title": "ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09d31d7f124a30f6a7ccbf430feee62633decc05",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26320": {
    "title": "Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "0a199db260704aedc67836ae61728a954e8aa24c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26321": {
    "title": "Acceleration of Large Transformer Model Training by Sensitivity-Based Layer Dropping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "05edd3c2ede087fa0fdfe8d2ecbf1aa95ce600f3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26322": {
    "title": "Interventional SHAP Values and Interaction Values for Piecewise Linear Regression Trees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1ea60f94e6bea09a60b92351b72dec40bf2948f9",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26323": {
    "title": "Enhanced Tensor Low-Rank and Sparse Representation Recovery for Incomplete Multi-View Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "88258d707e898923359fcea017f4f0281a65be57",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26324": {
    "title": "Denoising Multi-Similarity Formulation: A Self-Paced Curriculum-Driven Approach for Robust Metric Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "586e092999ebd347237ffe372af67bef36107369",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26325": {
    "title": "Rethinking Alignment and Uniformity in Unsupervised Image Semantic Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f6fb6f464efead0c4543f97de793a439c3ca07c6",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26326": {
    "title": "Behavior Estimation from Multi-Source Data for Offline Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6616965ea639e90c2413cff00aedf0133ce80fd9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26327": {
    "title": "DARL: Distance-Aware Uncertainty Estimation for Offline Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "32a31c899c145d9502ba3f5ef9fc70671a45da76",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26328": {
    "title": "When Neural Networks Fail to Generalize? A Model Sensitivity Perspective",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "22cf52a10dcfec08b1c7d8b0a6eb7bbbfa1c79d5",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26329": {
    "title": "Memorization Weights for Instance Reweighting in Adversarial Training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "00bbfc9b99d74203a64dc9f40639fe48a0deff36",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26330": {
    "title": "FedALA: Adaptive Local Aggregation for Personalized Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "939a858b08e3920783c7f949687a9758a509cee9",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26331": {
    "title": "Delving into the Adversarial Robustness of Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29b64e41bbea997019b64696d2374c3c96dbdf5c",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26332": {
    "title": "DRGCN: Dynamic Evolving Initial Residual for Deep Graph Convolutional Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e36c914b0437afe55b51b1dfe502bba1f40c7bdd",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26333": {
    "title": "Let the Data Choose: Flexible and Diverse Anchor Graph Fusion for Scalable Multi-View Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38e94c56f008e91db2203c16644687b15b05bfc1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26334": {
    "title": "Optimal Sparse Regression Trees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d5fbe321d89febc15a450fa171b6261f9c1daf0",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26335": {
    "title": "High-Dimensional Dueling Optimization with Preference Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "561f9714db2e3eafcb28c731e99d4b122aca6525",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26336": {
    "title": "Spectral Feature Augmentation for Graph Contrastive Learning and Beyond",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1d3fc84e5efeb599123605268cf6c6616ac06820",
    "citation_count": 12
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26337": {
    "title": "Scalable Bayesian Meta-Learning through Generalized Implicit Gradients",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e960e12a260556cea93ca4e02450a5edc7e30d7c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26338": {
    "title": "Dynamic Heterogeneous Graph Attention Neural Architecture Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8dd0869fd671682fa2d8e5f5f0ef14ecef04df0d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26339": {
    "title": "Dynamic Ensemble of Low-Fidelity Experts: Mitigating NAS \"Cold-Start",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "29a2acee401e86c7a6708a370a2c58bead6034d4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26340": {
    "title": "Tensorized Incomplete Multi-View Clustering with Intrinsic Graph Completion",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cbc2b78e5b981c58410605b27b7ff5fc8e216c65",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26341": {
    "title": "Imbalanced Label Distribution Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "383bf49b0444f27a94c4acc8d11d7a0225142c37",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26342": {
    "title": "CoopInit: Initializing Generative Adversarial Networks via Cooperative Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a5cbcd5701f8a4db18bbfce8182a0d22b840b67",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26343": {
    "title": "AutoGraph: Optimizing DNN Computation Graph for Parallel GPU Kernel Execution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "795a7d22873640b0cffcf9632bfa3ae00dd8566e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26344": {
    "title": "Fairness and Explainability: Bridging the Gap towards Fair Model Explanations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "96fb5cf9a971a956a8ebf52a4c9e816cb458bdb6",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26345": {
    "title": "Adaptive Policy Learning for Offline-to-Online Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f6274e6ba614b46d6283c775cfe4565e8ce50bc8",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26346": {
    "title": "Multi-Level Confidence Learning for Trustworthy Multimodal Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "70d5e6d63ab786d8d50fa4de096613943d18feb6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26347": {
    "title": "CowClip: Reducing CTR Prediction Model Training Time from 12 Hours to 10 Minutes on 1 GPU",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3ca2ba62e130c104b2c01ea496af6f690474a1db",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26348": {
    "title": "Data Imputation with Iterative Graph Reconstruction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fcd957f1437d03bc419522d67a236696574cd81a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26349": {
    "title": "Does It Pay to Optimize AUC?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e903c91c38bd3bdd5e5b3455575dfc9a4b8c8cc5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26350": {
    "title": "SLOTH: Structured Learning and Task-Based Optimization for Time Series Forecasting on Hierarchies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b180f97412efe688d335f409a6589c1de6675a5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26351": {
    "title": "Robust Temporal Smoothness in Multi-Task Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7090f46777a0f35938825cb28298006e8647b308",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26352": {
    "title": "Combining Adversaries with Anti-adversaries in Training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2810e9602d87f132e2b2f3eda6539d88d5330ec6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26353": {
    "title": "Gradient-Adaptive Pareto Optimization for Constrained Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1eb5f9b321e66f0c01184e675676e329c5d06349",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26354": {
    "title": "Quantized Feature Distillation for Network Quantization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6dcdac10bbc7364740178dcd10c5b05906fe13a3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26355": {
    "title": "Bayesian Cross-Modal Alignment Learning for Few-Shot Out-of-Distribution Generalization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d8c20a0513e51b1a5064c61e72611583352d4a2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26356": {
    "title": "ContraFeat: Contrasting Deep Features for Semantic Discovery",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7224248d35e0a877a1e5bae1d9664fd9e6cc0045",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26357": {
    "title": "Locate Then Generate: Bridging Vision and Language with Bounding Box for Scene-Text VQA",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dd67c3185aa94f089f048f654c3067ad4bb4a56d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26358": {
    "title": "ILSGAN: Independent Layer Synthesis for Unsupervised Foreground-Background Segmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85b392d00feff27ed3249c6653ce2e94aa34aaa2",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26359": {
    "title": "SVP-T: A Shape-Level Variable-Position Transformer for Multivariate Time Series Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "86f260abb52cea53b4dbf3f5c2a5669450983374",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26360": {
    "title": "Mixed-Variable Black-Box Optimisation Using Value Proposal Trees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "58b128b995b6740b8f5aece574bc1f4024bb7016",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26361": {
    "title": "Synchronization and Diversity of Solutions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cdadbbb6ebcab86003228ca2be7f3386c2d8a66",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26362": {
    "title": "The Multi-Agent Transportation Problem",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "098e2881eb611e46bbf7b579ff6b34ce183f380f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26363": {
    "title": "Emergent Quantized Communication",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "69e364cb69fc8c2dcd1157ecdb8758f3fd04c431",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26364": {
    "title": "Learning Explicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning via Polarization Policy Gradient",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b8fb3b575c61020537692b4f904381e3c5fe7bfa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26365": {
    "title": "Zero-Shot Assistance in Sequential Decision Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c6a733eb2dad71c8d022f5d9be81854d198ac11a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26366": {
    "title": "Multi-Unit Auctions for Allocating Chance-Constrained Resources",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "62055214297cf0ab16f2382b2b79314dc7e96316",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26367": {
    "title": "Reward-Based Negotiating Agent Strategies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "175474e2b044b2637cb904698a4fe497e4a4bd3b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26368": {
    "title": "Intersection Coordination with Priority-Based Search for Autonomous Vehicles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "384a7cb9b19a8a7bb79be8582ab4f351a8cb69f5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26369": {
    "title": "Solving Large-Scale Pursuit-Evasion Games Using Pre-trained Strategies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b4b4a321e64dd7c4d7ae48676657f42da29b2cf",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26370": {
    "title": "Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e72c1c09c7992e7ffaeb652693955eadad522705",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26371": {
    "title": "Learning to Shape Rewards Using a Game of Two Partners",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7c1ed780d2dd7d780c5ff6371d4d14c36c357e3c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26372": {
    "title": "Reconstructing an Epidemic Outbreak Using Steiner Connectivity",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "57872bf9a7fa8016cf88372f475627fbfef71c3c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26373": {
    "title": "Formal Verification of Bayesian Mechanisms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "70c3332847d04e906ca793ce19fa1cf96717c703",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26374": {
    "title": "Memory-Augmented Theory of Mind Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a40c7a12dfd42719a778b0c7a1ee4ede65aa197",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26375": {
    "title": "Socially Optimal Non-discriminatory Restrictions for Continuous-Action Games",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "214389422b1f67fe5e545ff9a0c0ae1004188cc6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26376": {
    "title": "Fault-Tolerant Offline Multi-Agent Path Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "46e7c11f2503e7280a8557b3549dd7018dc61a3e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26377": {
    "title": "LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "62abe88c56d04bff38e90bbc81409b2594f77efd",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26378": {
    "title": "Networked Anti-coordination Games Meet Graphical Dynamical Systems: Equilibria and Convergence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "154e6c775a798de03d251a5e2b4791a8d65798a4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26379": {
    "title": "Learning from Good Trajectories in Offline Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f91fe06f87bb21350d0e568548068759cbdc563",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26380": {
    "title": "Resource Sharing through Multi-Round Matchings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "62f1d21985a64eb5a169909cd0778b88c8b1d539",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26381": {
    "title": "Effective Integration of Weighted Cost-to-Go and Conflict Heuristic within Suboptimal CBS",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0e39f92ad49eef88dfd0e3b044f3404a03f7c402",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26382": {
    "title": "DM: Decentralized Multi-Agent Reinforcement Learning via Distribution Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f381189488173181f5dee719c93d698838d546f1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26383": {
    "title": "Emergence of Punishment in Social Dilemma with Environmental Feedback",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e1a0393771940b80a06fadf6e6aa763d9382b50d",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26384": {
    "title": "Subspace-Aware Exploration for Sparse-Reward Multi-Agent Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9c4ece695bfe0a9e99ee21323313882078b4ef4d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26385": {
    "title": "Consensus Learning for Cooperative Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74a184436ce058caf6f821f16dd7dbac9f652ca2",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26386": {
    "title": "HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8a17c4a4e6ff86f444c7c6811e307d52f443d149",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26387": {
    "title": "Hierarchical Mean-Field Deep Reinforcement Learning for Large-Scale Multiagent Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3d169fc1b93ce317a60e77a1b263d3f82804f85d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26388": {
    "title": "Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "223066f0c1f0d834848bf41f96a2136ef40467fb",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26389": {
    "title": "DACOM: Learning Delay-Aware Communication for Multi-Agent Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "738d51cb7d22c3db5bd46eda05fcf1048ea2ad0d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26390": {
    "title": "Effective and Stable Role-Based Multi-Agent Collaboration by Structural Information Principles",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "832d9fda09f1c36c4eda2010295ef68cdf95ad37",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26391": {
    "title": "Learning to Play General-Sum Games against Multiple Boundedly Rational Agents",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7403a725fcffee8107a078f10dfc0df957b78057",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26392": {
    "title": "Towards Robust Metrics for Concept Representation Evaluation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6ea8f01aafcaf689f190c5193880d1cba0461ef",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26393": {
    "title": "On the Vulnerability of Backdoor Defenses for Federated Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "efaab402913dbec3a01a503803dda48554be97e8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26394": {
    "title": "Distributionally Robust Optimization with Probabilistic Group",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14de7ffbbc1ce1afd75f32e43787b92a0165a5a7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26395": {
    "title": "Correct for Whom? Subjectivity and the Evaluation of Personalized Image Aesthetics Assessment Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ea821689157f662ef611e7c6e65e33653fb11d7c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26396": {
    "title": "Covariate-Shift Generalization via Random Sample Weighting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "79f4bf84b817f47fa74a8b183cde7641ccfecc4f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26397": {
    "title": "Fairness in Contextual Resource Allocation Systems: Metrics and Incompatibility Results",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ffae901292c459ac22c299279381db6ffafd1d90",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26398": {
    "title": "Improvement-Focused Causal Recourse (ICR)",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14b76875dc3d243b9f040db7df0373eb9256a196",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26399": {
    "title": "Explaining Model Confidence Using Counterfactuals",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "459e64919f6451fd93313ee2d230ddef0d3fa08a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26400": {
    "title": "Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3102b553be4f4b09bf6b2e1982ca880d1305dc38",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26401": {
    "title": "XRand: Differentially Private Defense against Explanation-Guided Attacks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "52ea77624f405563ce08778c2efa15dd9846bb63",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26402": {
    "title": "Mitigating Adversarial Norm Training with Moral Axioms",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b33afce5c6ab0cbd247a4e04018130346d0a9b2c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26403": {
    "title": "Equity Promotion in Public Transportation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7f3951422106a23841e8c712db068c130a03f3ae",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26404": {
    "title": "Online Platforms and the Fair Exposure Problem under Homophily",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "88e40be2fe3db2aec4385a1db2f3fd9a493a55de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26405": {
    "title": "Minimax AUC Fairness: Efficient Algorithm with Provable Convergence",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a20a2ec487a1fc7923fcec479e9f86e399151a34",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26406": {
    "title": "Faster Fair Machine via Transferring Fairness Constraints to Virtual Samples",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "518a6d6cbffef3f547863cd496eabd8ad3f817a8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26407": {
    "title": "Learning Control Policies for Stochastic Systems with Reach-Avoid Guarantees",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6c7846fb31946622302eeba2186d8c4b39e425a",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26408": {
    "title": "Robust Neuro-Symbolic Goal and Plan Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d9cb686c0c48d271f6806efb5a494d738b585fa1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26409": {
    "title": "Heuristic Search for Multi-Objective Probabilistic Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "091d3e219240e8ee5c496867b3f59e69abe10da4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26410": {
    "title": "Zero-Knowledge Proofs for Classical Planning Problems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f484252fea5416e03247b649b563833f8eb92cfb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26411": {
    "title": "Planning with Hidden Parameter Polynomial MDPs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3129d24d2b60ba4ffbf0060f430e1abce32e541d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26412": {
    "title": "Privacy Attacks on Schedule-Driven Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71c9259299e0edb95c2a755db292b5c0720b8cde",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26413": {
    "title": "Markov Decision Processes with Time-Varying Geometric Discounting",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "47fa00c8948f945f85d3ebeeb434b0fb4ffbef24",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26414": {
    "title": "Learning-Augmented Algorithms for Online TSP on the Line",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45850640a59627263b5a9b995be5f248aefc20bc",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26415": {
    "title": "Networked Restless Bandits with Positive Externalities",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f3d6ad6b700d5fc50b2f552bc735083b41a926dd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26416": {
    "title": "Planning for Learning Object Properties",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fa6786bd22a1eb67a4e1f28719103ba0e0c2398d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26417": {
    "title": "Fully Online Matching with Stochastic Arrivals and Departures",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0f618e81ea843aa638fd2445da298d52353e62bc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26418": {
    "title": "Towards Automated Modeling Assistance: An Efficient Approach for Repairing Flawed Planning Domains",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8b4da4a73bb88131c8a19d9c1c4dc3ccaadd2e6e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26419": {
    "title": "Was Fixing This Really That Hard? On the Complexity of Correcting HTN Domains",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "267246808c31153e8ff766fd663d59595d3fddcc",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26420": {
    "title": "On Total-Order HTN Plan Verification with Method Preconditions  An Extension of the CYK Parsing Algorithm",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "7493b69460ae3d93c07bd579335943fbf9338639",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26421": {
    "title": "A Dynamics and Task Decoupled Reinforcement Learning Architecture for High-Efficiency Dynamic Target Intercept",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f08ec6254022a2bfaeebb9d9c72404a1351c078",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26422": {
    "title": "AlphaRoute: Large-Scale Coordinated Route Planning via Monte Carlo Tree Search",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b39aecbf900ebdcc4846324ec887d981247df29f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26423": {
    "title": "Learning Rational Subgoals from Demonstrations and Instructions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2ddd59c64c0407f2386241b3d5f369bbea4baa8e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26424": {
    "title": "Learning Safe Numeric Action Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85a6b466c642a50987953ea2562eb6956bfb5788",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26425": {
    "title": "Automated Verification of Social Laws in Numeric Settings",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f60df74cf98cfee51397b9827bc5979f6341fb7b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26426": {
    "title": "Expressive Optimal Temporal Planning via Optimization Modulo Theory",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bc38b1104ce96be3d05047ce8d31728b19f8495e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26427": {
    "title": "Flexible Budgets in Restless Bandits: A Primal-Dual Algorithm for Efficient Budget Allocation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "06b26284e85e767313d2b4291ee01521a850d4a6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26428": {
    "title": "Structurally Restricted Fragments of Numeric Planning  a Complexity Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "243ace8039ae88f57d03cc62ca20af8db703c747",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26429": {
    "title": "Predicate Invention for Bilevel Planning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1a42134ea9d5ac1bb230e8b09dd9b0bc7fbc33b2",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26430": {
    "title": "Smoothed Online Combinatorial Optimization Using Imperfect Predictions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "905096ec9dfe7ebd4782628820fbad840feece06",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26431": {
    "title": "Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b6b6ddc7a6a13441ff87b98133dd920ba488e544",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26432": {
    "title": "Neural TSP Solver with Progressive Distillation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "98abf3344d73e24eef4138a3238860602b15096e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26433": {
    "title": "The Linear Distance Traveling Tournament Problem Allows an EPTAS",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cd49c8c0ea7633798017e2583b453b4a3a428f7f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26434": {
    "title": "Learning Relational Causal Models with Cycles through Relational Acyclification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2785a607dd1a88722184b130c191f96bfd23caa0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26435": {
    "title": "Causal Effect Identification in Cluster DAGs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9aee5972617d44866993dd9bd07b6ff66452c62f",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26436": {
    "title": "A Simple Unified Approach to Testing High-Dimensional Conditional Independences for Categorical and Ordinal Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "24a2b64e8daa805c6de265a70ad7f0c2b45479d1",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26437": {
    "title": "Score-Based Learning of Graphical Event Models with Background Knowledge Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14ec61dad1880ef08666c7e9f2bc0822e07df1c3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26438": {
    "title": "Entropy Regularization for Population Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "361f21c1ffd6c178ff9c5745dd15efb64dfb182c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26439": {
    "title": "Principled and Efficient Motif Finding for Structure Learning of Lifted Graphical Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "374a455fac344c990b99c6c4369f7e1a4a7bcf57",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26440": {
    "title": "A Faster Practical Approximation Scheme for the Permanent",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d883d135250580201b091e1552128b0a29a7052c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26441": {
    "title": "Neural Diffeomorphic Non-uniform B-spline Flows",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fe61a832a45cab659d617c534d4d0da142d51821",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26442": {
    "title": "Identification and Estimation of the Probabilities of Potential Outcome Types Using Covariate Information in Studies with Non-compliance",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "176b6676bbce824f0d0d53ad5d99edf1565da491",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26443": {
    "title": "Computing Divergences between Discrete Decomposable Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a03e29b3558f4d82e6f3216258c9469ed05d150",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26444": {
    "title": "Out-of-Distribution Generalization by Neural-Symbolic Joint Training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0ed6b805c99d98e5e684a1a5eab6717eef14529",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26445": {
    "title": "Novel Ordering-Based Approaches for Causal Structure Learning in the Presence of Unobserved Variables",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b9b58dd484ea2c198b7fcc17c02ea9d91068ede",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26446": {
    "title": "Maximizing the Probability of Fixation in the Positional Voter Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6764b61918b9190914c1a11ccb4a75ab9f06ee2c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26447": {
    "title": "Certifying Fairness of Probabilistic Circuits",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0418f5b401ee793bf0e99a1523d5edcd0427d019",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26448": {
    "title": "Probabilities of Potential Outcome Types in Experimental Studies: Identification and Estimation Based on Proxy Covariate Information",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "489d2650ad53d430127b8577a2fbf4857f23387c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26449": {
    "title": "Lifted Inference with Linear Order Axiom",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1402cac2817e664ec9d76da8eab1431e4d27f7dd",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26450": {
    "title": "Vector Causal Inference between Two Groups of Variables",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b0bd0bc26c656d333ed4a5b3b7eca2ba4dc8ccc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26451": {
    "title": "Efficient Enumeration of Markov Equivalent DAGs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae3aad78395546c58df9b18287991508a0471873",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26452": {
    "title": "Differentially Private Nonlinear Causal Discovery from Numerical Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23689c77d6ed841ce601eaa21db5eb946407fab6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26453": {
    "title": "Safe Interval Path Planning with Kinodynamic Constraints",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c9ed07ef6d320f32179db8acca96105265057c1c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26454": {
    "title": "Diversity Maximization in the Presence of Outliers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d2079b3c8ea31d25512a59f63992dfdeddbb7e7e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26455": {
    "title": "Fair Short Paths in Vertex-Colored Graphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0dad9f0caae52a64cc87e2663c4bb2bc0d30790b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26456": {
    "title": "AC-Band: A Combinatorial Bandit-Based Approach to Algorithm Configuration",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "fe95085e0a6d19a60a524f85be5ccd63a5959735",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26457": {
    "title": "GRASMOS: Graph Signage Model Selection for Gene Regulatory Networks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "565a26ec9e8f548dcf20dea554d0e267a14c72f5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26458": {
    "title": "Optimal Pathfinding on Weighted Grid Maps",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e74c87d6b9d9bbe26d2114ad38add7b5442453e8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26459": {
    "title": "Warm-Starting Nested Rollout Policy Adaptation with Optimal Stopping",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "efe3b72a9da2bb9cf8ea1900d56ae0b3a422b851",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26460": {
    "title": "A Proof That Using Crossover Can Guarantee Exponential Speed-Ups in Evolutionary Multi-Objective Optimisation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "117c4cadc884afd10038fc60d1261c5db82c739c",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26461": {
    "title": "Runtime Analysis for the NSGA-II: Provable Speed-Ups from Crossover",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bac992afcc9c0b508f589751f8b9f5fe2f55b05c",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26462": {
    "title": "From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "787b61c525f2489bb42076ca5afae1b439b0a3a5",
    "citation_count": 16
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26463": {
    "title": "Ultrafast Euclidean Shortest Path Computation Using Hub Labeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d47dadbcc38fdbae6d27a6999b2bdc62a763d93a",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26464": {
    "title": "A Formal Metareasoning Model of Concurrent Planning and Execution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a1e304ee403237b71740b837e934ab5153410356",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26465": {
    "title": "TransPath: Learning Heuristics for Grid-Based Pathfinding via Transformers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6ab30e5b9fcbb2203b99f8f1753ae23e0b735fa6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26466": {
    "title": "Large-State Reinforcement Learning for Hyper-Heuristics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ab8ae110b84a98e2c9319bb2347e1d11d439f211",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26467": {
    "title": "Human Assisted Learning by Evolutionary Multi-Objective Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a6295fe7ca3873ceead43df39f8f945462cffb54",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26468": {
    "title": "OPT-GAN: A Broad-Spectrum Global Optimizer for Black-Box Problems by Learning Distribution",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4d0fe6de29720fc358348ca9f5d48edf7ece6518",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26469": {
    "title": "Analyzing and Improving the Use of the FastMap Embedding in Pathfinding Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6939432fb47a75db461f89b1b44e7012adda0006",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26470": {
    "title": "Fully Computer-Assisted Proofs in Extremal Combinatorics",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c0ed378a0b63c52f17a89c5dc92e2325dbb31e35",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26471": {
    "title": "Electrophysiological Brain Source Imaging via Combinatorial Search with Provable Optimality",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d45c401bc7b192c588f24c1ae9d0f6b875579d02",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26472": {
    "title": "Improved Algorithm for Regret Ratio Minimization in Multi-Objective Submodular Maximization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "71e07dd7f9327d0a030c40b8b15bd2ee8059d34a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26473": {
    "title": "Efficient Gradient Approximation Method for Constrained Bilevel Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f23bff48ad4da52684fa983e8188343385be7a4b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26474": {
    "title": "A Generalized Scalarization Method for Evolutionary Multi-Objective Optimization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0239c9c90a81686ac386aee7d795096858bb8c8a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26475": {
    "title": "Generalized Category Discovery with Decoupled Prototypical Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9a6f06a7a03380a09e7bee185054d9bac9c32ac9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26476": {
    "title": "Structured Case-Based Reasoning for Inference-Time Adaptation of Text-to-SQL Parsers",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5435ed7c26f0c250493f244acffb69dd929d116b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26477": {
    "title": "SegFormer: A Topic Segmentation Model with Controllable Range of Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cc40f72c6bbe6a78d41d34a82984b8bd107a5e4d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26478": {
    "title": "Rich Event Modeling for Script Event Prediction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5c8191cf4cfe1abf70775ab95f01cacb3d26cdc1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26479": {
    "title": "Avocodo: Generative Adversarial Network for Artifact-Free Vocoder",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d1a595d6f3248898a5b4f7611b24f3771eef3540",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26480": {
    "title": "End-to-End Deep Reinforcement Learning for Conversation Disentanglement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "61643a757de121303a2af817870e2792211e6ad6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26481": {
    "title": "Self-Supervised Logic Induction for Explainable Fuzzy Temporal Commonsense Reasoning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "031970e341dfd1385ce0ac9f4a21dc8d20e85645",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26482": {
    "title": "Zero-Shot Cross-Lingual Event Argument Extraction with Language-Oriented Prefix-Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "183551cf1dbc4692e9567491a204b23140bb6cde",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26483": {
    "title": "RPA: Reasoning Path Augmentation in Iterative Retrieving for Multi-Hop QA",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dfd1508ad2fd5c79fe7c17fa77f2bf660fc24999",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26484": {
    "title": "Leveraging Modality-Specific Representations for Audio-Visual Speech Recognition via Reinforcement Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38d4c9de406c02239cc2e7c6e8797523d8093380",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26485": {
    "title": "Converge to the Truth: Factual Error Correction via Iterative Constrained Editing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0657858dbda4546e4209505764e73b3f58964617",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26486": {
    "title": "Adversarial Word Dilution as Text Data Augmentation in Low-Resource Regime",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": false,
    "id": "51c2714ab5dbc330619a1a96db994c9905900160",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26487": {
    "title": "CP-Rec: Contextual Prompting for Conversational Recommender Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ae67d9b533f257584ecb91647e9520dad8de931b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26488": {
    "title": "A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4b8d3ede673ddeab9dfb5184da6b748d7a526754",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26489": {
    "title": "Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "72ae79c894cc5f4829cb190500fc143994545648",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26490": {
    "title": "Preference-Controlled Multi-Objective Reinforcement Learning for Conditional Text Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "33aa0aff496d182a8ea8bf11a5155c257dea40d4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26491": {
    "title": "Learning towards Selective Data Augmentation for Dialogue Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "50ba225bcfd6bfd34f5c6957ee0b72a4f12f4e89",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26492": {
    "title": "Learn from Yesterday: A Semi-supervised Continual Learning Method for Supervision-Limited Text-to-SQL Task Streams",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "53d62f2e7bf20c442ce7197b2d39e2f6ea77a47b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26493": {
    "title": "A Scope Sensitive and Result Attentive Model for Multi-Intent Spoken Language Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38ec6fc80ccbf1dd8a7e66111ff37473f9edbad8",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26494": {
    "title": "Unsupervised Explanation Generation via Correct Instantiations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "655d34b590e8911e072013ad21582c0382447600",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26495": {
    "title": "Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-Shot In-Context Learners",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "06edda0310b4ec7c5012d012349252a3a77521b6",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26496": {
    "title": "Neural Dynamic Focused Topic Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "215ca900b723a975b2fc0ad6eef4b650f522e96e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26497": {
    "title": "Improving Simultaneous Machine Translation with Monolingual Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bf4ccb8446c6f9fa79b799b407852c7a218a3c02",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26498": {
    "title": "Domain-Adapted Dependency Parsing for Cross-Domain Named Entity Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "82b2dd1bc2e7a7522d6f6abb77770be550e84ff7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26499": {
    "title": "MultiSpider: Towards Benchmarking Multilingual Text-to-SQL Semantic Parsing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f377e2768aaab569db6c985a91b5eca4afbd4e1c",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26500": {
    "title": "Learning to Select from Multiple Options",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c9feb2cf67e17e22312b30f0eb4e8484fe3d5b11",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26501": {
    "title": "Real or Fake Text?: Investigating Human Ability to Detect Boundaries between Human-Written and Machine-Generated Text",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b118283afc5d8652de52cd13a5e287d76c5ec91f",
    "citation_count": 10
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26502": {
    "title": "Diffuser: Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b0c5c673c690c644a7d4af73adb783bd98486181",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26503": {
    "title": "Cogito Ergo Summ: Abstractive Summarization of Biomedical Papers via Semantic Parsing Graphs and Consistency Rewards",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7e70391224b5dd8c2b13a3165b322858da17bcdf",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26504": {
    "title": "MIGA: A Unified Multi-Task Generation Framework for Conversational Text-to-SQL",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "642e04ece55c5b532ff7e5408d8723c7d9c835db",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26505": {
    "title": "On the Effectiveness of Parameter-Efficient Fine-Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "846bdc54563f9de2e8388078ea2467b81151f6d5",
    "citation_count": 8
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26506": {
    "title": "SumREN: Summarizing Reported Speech about Events in News",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3a356a3a48b952837c79c229531ad93a72bc62df",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26507": {
    "title": "ProKD: An Unsupervised Prototypical Knowledge Distillation Network for Zero-Resource Cross-Lingual Named Entity Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5be413ff1171d43dd531de38d1c19325569ccda3",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26508": {
    "title": "Denoising Pre-training for Machine Translation Quality Estimation with Curriculum Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "056d3bd8c3b77643bdfa34adcf602cb538600e0c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26509": {
    "title": "Generating Coherent Narratives by Learning Dynamic and Discrete Entity States with a Contrastive Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b87a519690516c47aac03b1d794e4ae199812990",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26510": {
    "title": "Learning to Imagine: Distillation-Based Interactive Context Exploitation for Dialogue State Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "03b78c85b72b973f1109dc605bc0030a55febde9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26511": {
    "title": "RenewNAT: Renewing Potential Translation for Non-autoregressive Transformer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14897d84d004b37b38ddbafc178e518ab31f616e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26512": {
    "title": "Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5349d7d21d59633553ff7ce2d57376b8e5ddd698",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26513": {
    "title": "Competition or Cooperation? Exploring Unlabeled Data via Challenging Minimax Game for Semi-supervised Relation Extraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "16bbe866a849e538dc4cd2b213ca06e50595a23b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26514": {
    "title": "Feature Normalization and Cartography-Based Demonstrations for Prompt-Based Fine-Tuning on Emotion-Related Tasks",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "230137d02910e43a9d161e21af24b80fd94d351e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26515": {
    "title": "A Simple Yet Effective Subsequence-Enhanced Approach for Cross-Domain NER",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "593434904a5fe302aa876d7736a737c86e795724",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26516": {
    "title": "A Question-Answering Approach to Key Value Pair Extraction from Form-Like Document Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f5ddb5440ac6eb46da1b91b6bfe247c3a45eaaf1",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26517": {
    "title": "SEAT: Stable and Explainable Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e2f4c22090073ddd63708bea61de1e5a5bc905f4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26518": {
    "title": "Personalized Dialogue Generation with Persona-Adaptive Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c66b4f762f94b8d3532f532a401c67c2d35e2546",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26519": {
    "title": "Question Decomposition Tree for Answering Complex Questions over Knowledge Bases",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9da75352f8d5dc289f830096edadae1849444f53",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26520": {
    "title": "Hierarchical Text Classification as Sub-hierarchy Sequence Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "22c963ff1488e009e119f6137657ddfe321affbe",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26521": {
    "title": "IndicSUPERB: A Speech Processing Universal Performance Benchmark for Indian Languages",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5b870ccad0746225c71cf1167d929d80e6db47f6",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26522": {
    "title": "SheetPT: Spreadsheet Pre-training Based on Hierarchical Attention Network",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7617b8476756479789a1a0964427b5a81024e123",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26523": {
    "title": "SeDepTTS: Enhancing the Naturalness via Semantic Dependency and Local Convolution for Text-to-Speech Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "08bdd31c50de29d7b69e2622ddfa6e7e842be075",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26524": {
    "title": "Prototypical Fine-Tuning: Towards Robust Performance under Varying Data Sizes",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5cbd6a61a072567511789646407ea16934b10baa",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26525": {
    "title": "Cross-Modal Distillation for Speaker Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "496f94f427a63ec0e6c1a1cbab9aea995ecc9c33",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26526": {
    "title": "Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23cb0c2f27df7d92d073c99a2c101789a5454160",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26527": {
    "title": "COCA: COllaborative CAusal Regularization for Audio-Visual Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14a208be5919ab52b8b2fc732f358295a7bc203f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26528": {
    "title": "Script, Language, and Labels: Overcoming Three Discrepancies for Low-Resource Language Specialization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6f763bd76f48c9f34fa0b9cd2ca56594566f47f4",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26529": {
    "title": "LIQUID: A Framework for List Question Answering Dataset Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "3b0424149731d10829015cb4ab6299d18162128e",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26530": {
    "title": "UniSyn: An End-to-End Unified Model for Text-to-Speech and Singing Voice Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "304a8668a44730e9d12df8a479c0257c2a194190",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26531": {
    "title": "SoftCorrect: Error Correction with Soft Detection for Automatic Speech Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "09299aa885d4cef2c391c41b3f3ee444f3c00414",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26532": {
    "title": "Sequence Generation with Label Augmentation for Relation Extraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "85ca3f50c60aa13237bfa2d46d9fc3c42ef5049c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26533": {
    "title": "Reviewing Labels: Label Graph Network with Top-k Prediction Set for Relation Extraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e118becc25034e5ba287f11b2c72ebaf765f870b",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26534": {
    "title": "Online Noisy Continual Relation Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1406c1a0c9d0e855e5bf16b8303f8cde86e8fb2c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26535": {
    "title": "RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d51f4b220cb2c8321dc5f9755b7d66f10f1cad6",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26536": {
    "title": "Graphix-T5: Mixing Pre-trained Transformers with Graph-Aware Layers for Text-to-SQL Parsing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dcffef7c94546389c02c837e0e9290039938b4d2",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26537": {
    "title": "Compressed Heterogeneous Graph for Abstractive Multi-Document Summarization",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8b150819910d9e05eebfa746b7648e4dc2c5b7c9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26538": {
    "title": "TrOCR: Transformer-Based Optical Character Recognition with Pre-trained Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "de688c6e73ccf6ed33ff1cc7919d24456a1f74e2",
    "citation_count": 78
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26539": {
    "title": "Mitigating Negative Style Transfer in Hybrid Dialogue System",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "18220734faa6a355e949cf101aa1e2a8463c898c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26540": {
    "title": "Low Resource Quantitative Information Extraction via Structure Searching and Prefix-Based Text Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c78b90b1462a7d3c50c5d2910c8e95243ea54da4",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26541": {
    "title": "SKIER: A Symbolic Knowledge Integrated Model for Conversational Emotion Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d8088d6b45e3ae523b9472745971f698a3b1d7f5",
    "citation_count": 6
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26542": {
    "title": "PGSS: Pitch-Guided Speech Separation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1e3e6d16bf4278815ad26d4388c3edf46c1486df",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26543": {
    "title": "DyRRen: A Dynamic Retriever-Reranker-Generator Model for Numerical Reasoning over Tabular and Textual Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6fa180f4ce4be2715f3cbe13dc5dc6d198dc7249",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26544": {
    "title": "Heterogeneous-Branch Collaborative Learning for Dialogue Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "86dcd6268324b65960f0ac6287dabf155647c5f7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26545": {
    "title": "Learning to Know Myself: A Coarse-to-Fine Persona-Aware Training Framework for Personalized Dialogue Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "775cfa30a26a723c8c4fd1dca63baed24067e17e",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26546": {
    "title": "WIERT: Web Information Extraction via Render Tree",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4e5923251039ea4b118f29a3abd689b1ebfbedb0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26547": {
    "title": "STAGE: Span Tagging and Greedy Inference Scheme for Aspect Sentiment Triplet Extraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "80e01784da4c21687a67c0b68d03592d3d879ee5",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26548": {
    "title": "Generalizing Math Word Problem Solvers via Solution Diversification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6d686c2232d05b92b1549a36df24720c5d4bedd1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26549": {
    "title": "On Grounded Planning for Embodied Tasks with Language Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "59b71e2a248d67a2692bc7e35faa504ee2dbc98d",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26550": {
    "title": "DeAR: A Deep-Learning-Based Audio Re-recording Resilient Watermarking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "74aa68c5ca4fef1ce13b14920427b5c229e25dd1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26551": {
    "title": "Detecting and Grounding Important Characters in Visual Stories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8f51efde4213a3970ed498ee8a29a0e2b6b4d9fc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26552": {
    "title": "Boosting Few-Shot Text Classification via Distribution Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0bf970a8a5a580259891cdb40ebf8914e612ebd5",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26553": {
    "title": "SSPAttack: A Simple and Sweet Paradigm for Black-Box Hard-Label Textual Adversarial Attack",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1500c256a84a4746a70d670cdad4bf697196d5a2",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26554": {
    "title": "LADA-Trans-NER: Adaptive Efficient Transformer for Chinese Named Entity Recognition Using Lexicon-Attention and Data-Augmentation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8dddf88fe5de9e01b106cfb8760c725f90ade56c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26555": {
    "title": "Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "097490170c4691eec8844bf6454ff580f1151eec",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26556": {
    "title": "A Disentangled-Attention Based Framework with Persona-Aware Prompt Learning for Dialogue Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6b36b4ef56d9ac2eb622c331610f23d6e3f6799d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26557": {
    "title": "Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f1eeba530be0ac537bcdf633ee6c462045c97fb5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26558": {
    "title": "Unsupervised Paraphrasing under Syntax Knowledge",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f40a60a240b6026266db73a432db2724693c14af",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26559": {
    "title": "Adjective Scale Probe: Can Language Models Encode Formal Semantics Information?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "23073e785f52e6641a89ba15947910870da2b32a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26560": {
    "title": "Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "db28e98d530cb6bd771f71c40a18979bad1d4df1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26561": {
    "title": "Learning Compositional Tasks from Language Instructions",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ec5c45b70b136c7b125fa48af6c1bae79327448d",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26562": {
    "title": "SPRING: Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "13579f2d5d522779caeb4aa916fb9ab283f13670",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26563": {
    "title": "Universal Information Extraction as Unified Semantic Matching",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7ccfd5953e75f242536e99cdeda545a3c66ea98f",
    "citation_count": 7
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26564": {
    "title": "PUnifiedNER: A Prompting-Based Unified NER System for Diverse Datasets",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a1aba65b617ba2c9e82f09f20b04b70e5d60ce31",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26565": {
    "title": "KICE: A Knowledge Consolidation and Expansion Framework for Relation Extraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "31bd0e8883fe9d1a3d28482543d53f7b18077114",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26566": {
    "title": "Zero-Shot Slot Filling with Slot-Prefix Prompting and Attention Relationship Descriptor",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d590e0a539e1392dc4f17ae1327bf021e0c39f58",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26567": {
    "title": "Feature-Level Debiased Natural Language Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c205cea82ec5db88be8f466d5b3823e37cb8f341",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26568": {
    "title": "Graph Component Contrastive Learning for Concept Relatedness Estimation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2adc4f098c27c2a7a1cf43916a6122abcb2908f7",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26569": {
    "title": "HybridPrompt: Bridging Language Models and Human Priors in Prompt Tuning for Visual Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6470a35a46bbc8a844954af9fdf31e440d1aa289",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26570": {
    "title": "Inferential Knowledge-Enhanced Integrated Reasoning for Video Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "9b35aca6a0c632bd9e773861b77b01111ea34518",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26571": {
    "title": "AUC Maximization for Low-Resource Named Entity Recognition",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "87778991ffea60f1d4e80d726335338270ecc2f6",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26572": {
    "title": "Unveiling the Black Box of PLMs with Semantic Anchors: Towards Interpretable Neural Semantic Parsing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5c4bece777bbc7c52cdd4bbb6e222163f6a580dd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26573": {
    "title": "Towards a Holistic Understanding of Mathematical Questions with Contrastive Pre-training",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "bde8c53c106c79bb47858b8cff1982a897061cee",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26574": {
    "title": "Improving the Cross-Lingual Generalisation in Visual Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e2c167aeccf14d2bc6b8624f08ff432b000fdc25",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26575": {
    "title": "RWEN-TTS: Relation-Aware Word Encoding Network for Natural Text-to-Speech Synthesis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2fa74769118d2726c2ba2eabf1216d029d178960",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26576": {
    "title": "Hierarchical Event Grounding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ff77105b2c345f54e1a87f4fbb3a701201f0c1a8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26577": {
    "title": "RINK: Reader-Inherited Evidence Reranker for Table-and-Text Open Domain Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ee9d38a3f889c5030209c78b2378d8a17d2b716b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26578": {
    "title": "Relation-Aware Language-Graph Transformer for Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0136f2faaa902082d0e6ad15e5fd14f5842d2b14",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26579": {
    "title": "Multi-Mask Label Mapping for Prompt-Based Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "99dca83345b957ee3eae868570a2ce9af52f729a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26580": {
    "title": "SSMI: Semantic Similarity and Mutual Information Maximization Based Enhancement for Chinese NER",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d75126cf933f80dc46a9e2fe636199817e2d52c1",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26581": {
    "title": "Towards Complex Scenarios: Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a4c1e39a7fff8f761a0682320d3e4cf5f3217a02",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26582": {
    "title": "BERT-ERC: Fine-Tuning BERT Is Enough for Emotion Recognition in Conversation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "eecd7b3394fc68901db974a2ff8f950c3a7a7705",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26583": {
    "title": "Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-Grained Student Ensemble",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f305333006fb76fdf2875bd0f6b4a990d9a2028",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26584": {
    "title": "Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "11f734c937b74b4950d67f61ab822c81a3f86ac9",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26585": {
    "title": "Prompting Neural Machine Translation with Translation Memories",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "90e0457049d9ff589985312c539b22a97aa04f73",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26586": {
    "title": "Improving Interpretability via Explicit Word Interaction Graph Layer",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "f64745927d4a6f048dd0cba8cce7ea8c0055d26c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26587": {
    "title": "Rephrasing the Reference for Non-autoregressive Machine Translation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8671a125e0aa2c1a97ff7940008e47759ec94967",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26588": {
    "title": "Drop Clause: Enhancing Performance, Robustness and Pattern Recognition Capabilities of the Tsetlin Machine",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "558e5ffc1fd2af35d1052e70dbfdb4efab7db5a1",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26589": {
    "title": "CoP: Factual Inconsistency Detection by Controlling the Preference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "34f300edbed4e4cf57d3d9a0499578ce97c5cf00",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26590": {
    "title": "Which Shortcut Solution Do Question Answering Models Prefer to Learn?",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ad7c788824aba70deb141617410dd70b390c4ae8",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26591": {
    "title": "Exploring Faithful Rationale for Multi-Hop Fact Verification via Salience-Aware Graph Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "622ea8252a0c04e91870ed895d34fdc93ac52949",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26592": {
    "title": "A Speaker Turn-Aware Multi-Task Adversarial Network for Joint User Satisfaction Estimation and Sentiment Analysis",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "cf3b0c1331f4aeb15218c5d55a46655a237afc78",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26593": {
    "title": "A Latent-Variable Model for Intrinsic Probing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4adba678d51bfa5f96b18b7c1fedb7372cf83068",
    "citation_count": 3
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26594": {
    "title": "Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation via Hybrid Latent Variables",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f157aa29b4363d4ecba0a0afbdf03977a9f62d5",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26595": {
    "title": "ConvNTM: Conversational Neural Topic Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c16cfc3fd993d15d702186c66561a6afbdab170a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26596": {
    "title": "Contrastive Learning Reduces Hallucination in Conversations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d7ea898cc97754e06d209df0fd55ab60250601f2",
    "citation_count": 11
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26597": {
    "title": "Revisiting Denoising Diffusion Probabilistic Models for Speech Enhancement: Condition Collapse, Efficiency and Refinement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "86acceb40f6fa368eb1c7f765f37f93f6947b9d6",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26598": {
    "title": "SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1b4c0a28b0c2a30cc3b84a3222e795c90357bc8a",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26599": {
    "title": "Reducing Sentiment Bias in Pre-trained Sentiment Classification via Adaptive Gumbel Attack",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "45e175a1bde8553b02d1675a3467112c2dcb535f",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26600": {
    "title": "Latent Constraints on Unsupervised Text-Graph Alignment with Information Asymmetry",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "322e76e2492dd7e136cf7f101a8992567cec12b3",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26601": {
    "title": "M-sense: Modeling Narrative Structure in Short Personal Narratives Using Protagonist's Mental Representations",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1d9bcccadf1cfa727125f9e745384311165cf4c9",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26602": {
    "title": "Taming Continuous Posteriors for Latent Variational Dialogue Policies",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d5ff8d416aa1f7027f494124380e084ecf876e36",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26603": {
    "title": "Uncertainty-Aware Self-Training for Low-Resource Neural Sequence Labeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "317948521f3e8fc5542af8cebdb28df00cc5c8ff",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26604": {
    "title": "Disentangled CVAEs with Contrastive Learning for Explainable Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b826c9318686f6e51a2f25484ea995b709283639",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26605": {
    "title": "fmLRE: A Low-Resource Relation Extraction Model Based on Feature Mapping Similarity Calculation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "4eee7b8ccb5ed06a644611a91ba43a0e876086be",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26606": {
    "title": "Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c557ac809df2bf55f3ebc7701ad06af0f6ce15e6",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26607": {
    "title": "Zero-Shot Face-Based Voice Conversion: Bottleneck-Free Speech Disentanglement in the Real-World Scenario",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dd923be883e8899eacb92b8b3b9bbb94ec26078a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26608": {
    "title": "Adversarial Self-Attention for Language Understanding",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "924462895c1a380acddbde3c281c8849b458f995",
    "citation_count": 5
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26609": {
    "title": "See How You Read? Multi-Reading Habits Fusion Reasoning for Multi-Modal Fake News Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "6911062acc602db1cc9f318b9407adb4778141d0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26610": {
    "title": "Identify Event Causality with Knowledge and Analogy",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1cd83fa10592855f2e6b25f0b9c3fe226546ec0d",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26611": {
    "title": "Continual Graph Convolutional Network for Text Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a637239dc0c2d105c8c3d28ed07579a02aef2a3a",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26612": {
    "title": "InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual Topic Modeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "36cfbdd71ca244c27e0be757f53e1696ab35f32e",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26613": {
    "title": "VideoDubber: Machine Translation with Speech-Aware Length Control for Video Dubbing",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5a61cdc2fe6c9f6887c4bfc13cce10f8e6a855af",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26614": {
    "title": "Don't Be So Sure! Boosting ASR Decoding via Confidence Relaxation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "17ef526352ef379f8c9365d50e141ef153a49e7d",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26615": {
    "title": "AMOM: Adaptive Masking over Masking for Conditional Masked Language Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "a8767413d9b969b04c9c440a30f6b7c6a9c4b1bc",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26616": {
    "title": "Global Mixup: Eliminating Ambiguity with Clustering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "38ea7063cf571bf59ab2bceae5865dd3a1499a44",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26617": {
    "title": "MoEC: Mixture of Expert Clusters",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1c1eaea99e0cbbd4616125049bae8c6787bd368c",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26618": {
    "title": "Factual and Informative Review Generation for Explainable Recommendation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "64c4d622b88a88b9f5ab5fdc6cb01f1ce9ccb883",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26619": {
    "title": "Dialogue Rewriting via Skeleton-Guided Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "35e6a386c486f2c57b7f0580b19d03f93c74413b",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26620": {
    "title": "Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c4abda222d53e19b381f99e27afce74195d6a6cb",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26621": {
    "title": "Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "037f360a564d81015ad2d404a6bb0cd3a1468088",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26622": {
    "title": "Selector-Enhancer: Learning Dynamic Selection of Local and Non-local Attention Operation for Speech Enhancement",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "1829c937872bd509b1e2aceaa6c0bb92a9caad6e",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26623": {
    "title": "A Graph Fusion Approach for Cross-Lingual Machine Reading Comprehension",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "8c36246da412610435d605063885646b279958de",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26624": {
    "title": "Improving Biomedical Entity Linking with Cross-Entity Interaction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "600a811935bedaf25d26b908fa6a79b4c55f1191",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26625": {
    "title": "Nested Named Entity Recognition as Building Local Hypergraphs",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d8b8d0109f9b02442b366b10517e99f15e08a277",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26626": {
    "title": "A Domain-Transfer Meta Task Design Paradigm for Few-Shot Slot Tagging",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "b4481a16cfac0008e5b12a4e6d375df81d5a9fce",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26627": {
    "title": "Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5d1d01fd199aff94240e7452e25e915cfa7b77e7",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26628": {
    "title": "What Does Your Face Sound Like? 3D Face Shape towards Voice",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "16f703e017b3e39c2aa52577a5a1882f68b2c0ef",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26629": {
    "title": "FiTs: Fine-Grained Two-Stage Training for Knowledge-Aware Question Answering",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "114655441607fbf58f5b174f2905a006b3853d91",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26630": {
    "title": "On the Calibration and Uncertainty with Plya-Gamma Augmentation for Dialog Retrieval Models",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "14b47cc6ce6bb154dbe0cf0416cf4e0272c7cd38",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26631": {
    "title": "Preserve Context Information for Extract-Generate Long-Input Summarization Framework",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "51f8bdac8ab7ebeb99106f5e57aa047e82e0e847",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26632": {
    "title": "Transferable Post-hoc Calibration on Pretrained Transformers in Noisy Text Classification",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "688baadc8b1902f524101a2231c6d4b58ee4bfd0",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26633": {
    "title": "Quantum-Inspired Representation for Long-Tail Senses of Word Sense Disambiguation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "d704aefcf01d67af12e4281909b71a28f96c0829",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26634": {
    "title": "MPMQA: Multimodal Question Answering on Product Manuals",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "5f93d785983a51efe1debf7793b02e27757d1bbd",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26635": {
    "title": "Exploring Self-Distillation Based Relational Reasoning Training for Document-Level Relation Extraction",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77afb7c2279a4a6d162810e863fdddff4c1555a8",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26636": {
    "title": "Multi-Action Dialog Policy Learning from Logged User Feedback",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "c9a37fb45b73fb167f2b598776b9ba51e1aaea79",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26637": {
    "title": "Improving End-to-End Speech Translation by Leveraging Auxiliary Speech and Text Data",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "7b16564559db7b03051fa7f80ad5669d30e72471",
    "citation_count": 4
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26638": {
    "title": "A Neural Span-Based Continual Named Entity Recognition Model",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "078de8a6e93c7679fd82bd4527681b2ff1963e25",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26639": {
    "title": "Language Model Pre-training on True Negatives",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "e8033d571c2120f59f21b253e54805b5a2c96c63",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26640": {
    "title": "MCL: Multi-Granularity Contrastive Learning Framework for Chinese NER",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "01881c011e7babc706bea37bfaaa1294dbdd77fa",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26641": {
    "title": "Knowledge-Bridged Causal Interaction Network for Causal Emotion Entailment",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "97ba54394f69d5e2157d5c3e2b058cfe7999b3c9",
    "citation_count": 9
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26642": {
    "title": "Query Your Model with Definitions in FrameNet: An Effective Method for Frame Semantic Role Labeling",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "0ef797cae9ae6eb1e49b10cab8ccabd2b09d276c",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26643": {
    "title": "Event Process Typing via Hierarchical Optimal Transport",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "77b8299c9455829db7f37116933e448255bd72d7",
    "citation_count": 0
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26644": {
    "title": "Improving Distantly Supervised Relation Extraction by Natural Language Inference",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "dc7a97da9d46e3f4a087ce404a19b8af03109bde",
    "citation_count": 1
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26645": {
    "title": "A Generative Approach for Script Event Prediction via Contrastive Fine-Tuning",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "2a34d4e279e8da66a5600b1943de07ac5ddee402",
    "citation_count": 2
  },
  "https://ojs.aaai.org/index.php/AAAI/article/view/26646": {
    "title": "KPT: Keyword-Guided Pre-training for Grounded Dialog Generation",
    "abstract": "Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets",
    "volume": "main",
    "checked": true,
    "id": "ef52ba73fbf41eed320a479f5736e127d3a06049",
    "citation_count": 1
  }
}