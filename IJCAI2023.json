{
  "https://www.ijcai.org/proceedings/2023/1": {
    "title": "Learning Dissemination Strategies for External Sources in Opinion Dynamic Models with Cognitive Biases",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/2": {
    "title": "Artificial Agents Inspired by Human Motivation Psychology for Teamwork in Hazardous Environments",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/3": {
    "title": "Proportionally Fair Online Allocation of Public Goods with Predictions",
    "abstract": "We design online algorithms for fair allocation of public goods to a set of N agents over a sequence of T rounds and focus on improving their performance using predictions. In the basic model, a public good arrives in each round, and every agent reveals their value for it upon arrival. The algorithm must irrevocably decide the investment in this good without exceeding a total budget of B across all rounds. The algorithm can utilize (potentially noisy) predictions of each agent’s total value for all remaining goods. The algorithm's performance is measured using a proportional fairness objective, which informally demands that every group of agents be rewarded proportional to its size and the cohesiveness of its preferences. We show that no algorithm can achieve better than Θ(T/B) proportional fairness without predictions. With reasonably accurate predictions, the situation improves significantly, and Θ(log(T/B)) proportional fairness is achieved. We also extend our results to a general setting wherein a batch of L public goods arrive in each round and O(log(min(N,L)T/B)) proportional fairness is achieved. Our exact bounds are parameterized as a function of the prediction error, with performance degrading gracefully with increasing errors",
    "volume": "main",
    "checked": true,
    "id": "0d36564938644acbfb2448b7bfe880684d7264d9",
    "citation_count": 5
  },
  "https://www.ijcai.org/proceedings/2023/4": {
    "title": "On the Role of Memory in Robust Opinion Dynamics",
    "abstract": "We investigate opinion dynamics in a fully-connected system, consisting of n agents, where one of the opinions, called correct, represents a piece of information to disseminate. \r\nOne source agent initially holds the correct opinion and remains with this opinion throughout the execution. The goal of the remaining agents is to quickly agree on this correct opinion. At each round, one agent chosen uniformly at random is activated: unless it is the source, the agent pulls the opinions of l random agents and then updates its opinion according to some rule. \r\nWe consider a restricted setting, in which agents have no memory and they only revise their opinions on the basis of those of the agents they currently sample. \r\nThis setting encompasses very popular opinion dynamics, such as the voter model and best-of-k majority rules. \r\n\r\nQualitatively speaking, we show that lack of memory prevents efficient  convergence. Specifically, we prove that any dynamics requires Omega(n^2) expected time, even under a strong version of the model in which activated agents have complete access to the current configuration of the entire system, i.e., the case l=n. Conversely, we prove that the simple voter model (in which l=1) correctly solves the problem, while almost matching the aforementioned lower bound. \r\n\r\nThese results suggest that, in contrast to symmetric consensus problems (that do not involve a notion of correct opinion), fast convergence on the correct opinion using stochastic opinion dynamics may require the use of memory",
    "volume": "main",
    "checked": true,
    "id": "0b3fed152c0d504c49db33d603e4c9f9e3df812a",
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/5": {
    "title": "On a Voter Model with Context-Dependent Opinion Adoption",
    "abstract": "Opinion diffusion is a crucial phenomenon in social networks, often underlying the way in which a collection of agents develops a consensus on relevant decisions.  Voter models are well-known theoretical models to study opinion spreading in social networks and structured populations. Their simplest version assumes that an updating agent will adopt the opinion of a neighboring agent chosen at random. These models allow us to study, for example, the probability that a certain opinion will fixate into a consensus opinion, as well as the expected time it takes for a consensus opinion to emerge. \r\n\r\nStandard voter models are oblivious to the opinions held by the agents involved in the opinion adoption process. We propose and study a context-dependent opinion spreading process on an arbitrary social graph, in which the probability that an agent abandons opinion a in favor of opinion b depends on both a and b. We discuss the relations of the model with existing voter models and then derive theoretical results for both the fixation probability and the expected consensus time for two opinions, for both the synchronous and the asynchronous update models",
    "volume": "main",
    "checked": true,
    "id": "985e9928658287c27131c2a8570f74f0efeffc11",
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/6": {
    "title": "Scalable Verification of Strategy Logic through Three-Valued Abstraction",
    "abstract": "The model checking problem for multi-agent systems against Strategy Logic specifications is known to be non-elementary. On this logic several fragments have been defined to tackle this issue but at the expense of expressiveness. In this paper, we propose a three-valued semantics for Strategy Logic upon which we define an abstraction method. We show that the latter semantics is an approximation of the classic two-valued one for Strategy Logic. Furthermore, we extend MCMAS, an open-source model checker for multi-agent specifications, to incorporate our abstraction method and present some promising experimental results",
    "volume": "main",
    "checked": false,
    "id": "1b481f376fbfe5939f6826497940ee4e958f53b5",
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/7": {
    "title": "Explainable Multi-Agent Reinforcement Learning for Temporal Queries",
    "abstract": "As multi-agent reinforcement learning (MARL) systems are increasingly deployed throughout society, it is imperative yet challenging for users to understand the emergent behaviors of MARL agents in complex environments. This work presents an approach for generating policy-level contrastive explanations for MARL to answer a temporal user query, which specifies a sequence of tasks completed by agents with possible cooperation. The proposed approach encodes the temporal query as a PCTL* logic formula and checks if the query is feasible under a given MARL policy via probabilistic model checking. Such explanations can help reconcile discrepancies between the actual and anticipated multi-agent behaviors. The proposed approach also generates correct and complete explanations to pinpoint reasons that make a user query infeasible. We have successfully applied the proposed approach to four benchmark MARL domains (up to 9 agents in one domain). Moreover, the results of a user study show that the generated explanations significantly improve user performance and satisfaction",
    "volume": "main",
    "checked": true,
    "id": "adec78228d27dae140da94e454294a552e22fcd4",
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/8": {
    "title": "Efficient and Equitable Deployment of Mobile Vaccine Distribution Centers",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/9": {
    "title": "Anticipatory Fictitious Play",
    "abstract": "Fictitious play is an algorithm for computing Nash equilibria of matrix games. Recently, machine learning variants of fictitious play have been successfully applied to complicated real-world games. This paper presents a simple modification of fictitious play which is a strict improvement over the original: it has the same theoretical worst-case convergence rate, is equally applicable in a machine learning context, and enjoys superior empirical performance. We conduct an extensive comparison of our algorithm with fictitious play, proving an optimal O(1/t) convergence rate for certain classes of games, demonstrating superior performance numerically across a variety of games, and concluding with experiments that extend these algorithms to the setting of deep multiagent reinforcement learning",
    "volume": "main",
    "checked": true,
    "id": "1d8c10f09a97b699706967d7315ce368b1047263",
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/10": {
    "title": "Safe Multi-agent Learning via Trapping Regions",
    "abstract": "One of the main challenges of multi-agent learning lies in establishing convergence of the algorithms, as, in general, a collection of individual, self-serving agents is not guaranteed to converge with their joint policy, when learning concurrently. This is in stark contrast to most single-agent environments, and sets a prohibitive barrier for deployment in practical applications, as it induces uncertainty in long term behavior of the system. In this work, we apply the concept of trapping regions, known from qualitative theory of dynamical systems, to create safety sets in the joint strategy space for decentralized learning. We propose a binary partitioning algorithm for verification that candidate sets form trapping regions in systems with known learning dynamics, and a heuristic sampling algorithm for scenarios where learning dynamics are not known. We demonstrate the applications to a regularized version of Dirac Generative Adversarial Network,  a four-intersection traffic control scenario run in a state of the art open-source microscopic traffic simulator SUMO, and a mathematical model of economic competition",
    "volume": "main",
    "checked": true,
    "id": "1f5656fc2ce1957c7c83c68aa10f9c05d63ff822",
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/11": {
    "title": "Multi-Agent Intention Recognition and Progression",
    "abstract": "For an agent in a multi-agent environment, it is often beneficial to be able to predict what other agents will do next when deciding how to act. Previous work in multi-agent intention scheduling assumes a priori knowledge of the current goals of other agents. In this paper, we present a new approach to multi-agent intention scheduling in which an agent uses online goal recognition to identify the goals currently being pursued by other agents while acting in pursuit of its own goals. We show how online goal recognition can be incorporated into an MCTS-based intention scheduler, and evaluate our approach in a range of scenarios. The results demonstrate that our approach can rapidly recognise the goals of other agents even when they are pursuing multiple goals concurrently, and has similar performance to agents which know the goals of other agents a priori",
    "volume": "main",
    "checked": false,
    "id": "765498735cba145a65910f59f3644bb3bafffa4b",
    "citation_count": 3
  },
  "https://www.ijcai.org/proceedings/2023/12": {
    "title": "Controlling Neural Style Transfer with Deep Reinforcement Learning",
    "abstract": "Controlling the degree of stylization in the Neural Style Transfer (NST) is a little tricky since it usually needs hand-engineering on hyper-parameters. In this paper, we propose the first deep Reinforcement Learning (RL) based architecture that splits one-step style transfer into a step-wise process for the NST task. Our RL-based method tends to preserve more details and structures of the content image in early steps, and synthesize more style patterns in later steps. It is a user-easily-controlled style-transfer method. Additionally, as our RL-based model performs the stylization progressively, it is lightweight and has lower computational complexity than existing one-step Deep Learning (DL) based models. Experimental results demonstrate the effectiveness and robustness of our method",
    "volume": "main",
    "checked": false,
    "id": "6d6eaca663fbcfbcc29eb749af1f6b19adeade88",
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/13": {
    "title": "Cross-community Adapter Learning (CAL) to Understand the Evolving Meanings of Norm Violation",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://www.ijcai.org/proceedings/2023/14": {
    "title": "Learning in Multi-Memory Games Triggers Complex Dynamics Diverging from Nash Equilibrium",
    "abstract": "Repeated games consider a situation where multiple agents are motivated by their independent rewards throughout learning. In general, the dynamics of their learning become complex. Especially when their rewards compete with each other like zero-sum games, the dynamics often do not converge to their optimum, i.e., the Nash equilibrium. To tackle such complexity, many studies have understood various learning algorithms as dynamical systems and discovered qualitative insights among the algorithms. However, such studies have yet to handle multi-memory games (where agents can memorize actions they played in the past and choose their actions based on their memories), even though memorization plays a pivotal role in artificial intelligence and interpersonal relationship. This study extends two major learning algorithms in games, i.e., replicator dynamics and gradient ascent, into multi-memory games. Then, we prove their dynamics are identical. Furthermore, theoretically and experimentally, we clarify that the learning dynamics diverge from the Nash equilibrium in multi-memory zero-sum games and reach heteroclinic cycles (sojourn longer around the boundary of the strategy space), providing a fundamental advance in learning in games",
    "volume": "main",
    "checked": true,
    "id": "561bfbb11123f4d1596d8f0fe1196eb6a607c195",
    "citation_count": 1
  }
}