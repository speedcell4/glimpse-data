{
  "https://openreview.net/forum?id=g85Vxlrq0O": {
    "title": "A Baseline Method for Removing Invisible Image Watermarks using Deep Image Prior",
    "volume": "main",
    "abstract": "Image watermarks have been considered a promising technique to help detect AI-generated content, which can be used to protect copyright or prevent fake image abuse. In this work, we present a black-box method for removing invisible image watermarks, without the need of any dataset of watermarked images or any knowledge about the watermark system. Our approach is simple to implement: given a single watermarked image, we regress it by deep image prior (DIP). We show that from the intermediate steps of DIP one can reliably find an evasion image that can remove invisible watermarks while preserving high image quality. Due to its unique working mechanism and practical effectiveness, we advocate including DIP as a baseline invasion method for benchmarking the robustness of watermarking systems. Finally, by showing the limited ability of DIP and other existing black-box methods in evading training-based visible watermarks, we discuss the positive implications on the practical use of training-based visible watermarks to prevent misinformation abuse",
    "checked": true,
    "id": "e9c5e2002443b969962f1564a4e8201f744c3852",
    "semantic_title": "a baseline method for removing invisible image watermarks using deep image prior",
    "citation_count": 1,
    "authors": [
      "Hengyue Liang",
      "Taihui Li",
      "Ju Sun"
    ]
  },
  "https://openreview.net/forum?id=3K1LRetR6Y": {
    "title": "Learning Federated Neural Graph Databases for Answering Complex Queries from Distributed Knowledge Graphs",
    "volume": "main",
    "abstract": "The increasing demand for deep learning-based foundation models has highlighted the importance of efficient data retrieval mechanisms. Neural graph databases (NGDBs) offer a compelling solution, leveraging neural spaces to store and query graph-structured data, thereby enabling LLMs to access precise and contextually relevant information. However, current NGDBs are constrained to single-graph operation, limiting their capacity to reason across multiple, distributed graphs. Furthermore, the lack of support for multi-source graph data in existing NGDBs hinders their ability to capture the complexity and diversity of real-world data. In many applications, data is distributed across multiple sources, and the ability to reason across these sources is crucial for making informed decisions. This limitation is particularly problematic when dealing with sensitive graph data, as directly sharing and aggregating such data poses significant privacy risks. As a result, many applications that rely on NGDBs are forced to choose between compromising data privacy or sacrificing the ability to reason across multiple graphs. To address these limitations, we propose to learn Federated Neural Graph DataBase (FedNGDB), a pioneering systematic framework that empowers privacy-preserving reasoning over multi-source graph data. FedNGDB leverages federated learning to collaboratively learn graph representations across multiple sources, enriching relationships between entities, and improving the overall quality of graph data. Unlike existing methods, FedNGDB can handle complex graph structures and relationships, making it suitable for various downstream tasks. We evaluate FedNGDBs on three real-world datasets, demonstrating its effectiveness in retrieving relevant information from multi-source graph data while keeping sensitive information secure on local devices. Our results show that FedNGDBs can efficiently retrieve answers to cross-graph queries, making it a promising approach for LLMs and other applications that rely on efficient data retrieval mechanisms",
    "checked": false,
    "id": "897f0a4aa81dac2ab2679541032fcdf7b8c7eff5",
    "semantic_title": "deep learning enabled graph database for complex queries",
    "citation_count": 0,
    "authors": [
      "Qi Hu",
      "Weifeng Jiang",
      "Haoran Li",
      "Zihao Wang",
      "Jiaxin Bai",
      "Qianren Mao",
      "Yangqiu Song",
      "Lixin Fan",
      "Jianxin Li"
    ]
  },
  "https://openreview.net/forum?id=2zEemRib3a": {
    "title": "Bayesian Neighborhood Adaptation for Graph Neural Networks",
    "volume": "main",
    "abstract": "The neighborhood scope (i.e., number of hops) where graph neural networks (GNNs) aggregate information to characterize a node's statistical property is critical to GNNs' performance. Two-stage approaches, training and validating GNNs for every pre-specified neighborhood scope to search for the best setting, is a time-consuming task and tends to be biased due to the search space design. How to adaptively determine proper neighborhood scopes for the aggregation process for both homophilic and heterophilic graphs remains largely unexplored. We thus propose to model the GNNs' message-passing behavior on a graph as a stochastic process by treating the number of hops as a beta process. This Bayesian framework allows us to infer the most plausible neighborhood scope for message aggregation simultaneously with the optimization of GNN parameters. Our theoretical analysis shows that the scope inference improves the expressivity of a GNN. Experiments on benchmark homophilic and heterophilic datasets show that the proposed method is compatible with state-of-the-art GNN variants, achieving competitive or superior performance on the node classification task, and providing well-calibrated predictions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paribesh Regmi",
      "Rui Li",
      "Kishan K C"
    ]
  },
  "https://openreview.net/forum?id=m6EQ6YdPXV": {
    "title": "Approximations to worst-case data dropping: unmasking failure modes",
    "volume": "main",
    "abstract": "A data analyst might worry about generalization if dropping a very small fraction of data points from a study could change its substantive conclusions. Checking this non-robustness directly poses a combinatorial optimization problem and is intractable even for simple models and moderate data sizes. Recently various authors have proposed a diverse set of approximations to detect this non-robustness. In the present work, we show that, even in a setting as simple as ordinary least squares (OLS) linear regression, many of these approximations can fail to detect (true) non-robustness in realistic data arrangements. We focus on OLS in the present work due its widespread use and since some approximations work only for OLS. Across our synthetic and real-world data sets, we find that a simple recursive greedy algorithm is the sole algorithm that does not fail any of our tests and also that it can be orders of magnitude faster to run than some competitors",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jenny Y. Huang",
      "David R. Burt",
      "Yunyi Shen",
      "Tin D. Nguyen",
      "Tamara Broderick"
    ]
  },
  "https://openreview.net/forum?id=WrWYChkyRI": {
    "title": "Large Language Model Confidence Estimation via Black-Box Access",
    "volume": "main",
    "abstract": "Estimating uncertainty or confidence in the responses of a model can be significant in evaluating trust not only in the responses, but also in the model as a whole. In this paper, we explore the problem of estimating confidence for responses of large language models (LLMs) with simply black-box or query access to them. We propose a simple and extensible framework where, we engineer novel features and train a (interpretable) model (viz. logistic regression) on these features to estimate the confidence. We empirically demonstrate that our simple framework is effective in estimating confidence of Flan-ul2, Llama-13b, Mistral-7b and GPT-4 on four benchmark Q&A tasks as well as of Pegasus-large and BART-large on two benchmark summarization tasks with it surpassing baselines by even over 10% (on AU-ROC) in some cases. Additionally, our interpretable approach provides insight into features that are predictive of confidence, leading to the interesting and useful discovery that our confidence models built for one LLM generalize zero-shot across others on a given dataset",
    "checked": true,
    "id": "306abfd0fec0cfe1b2c3960648a25f2d9efbe26a",
    "semantic_title": "large language model confidence estimation via black-box access",
    "citation_count": 5,
    "authors": [
      "Tejaswini Pedapati",
      "Amit Dhurandhar",
      "Soumya Ghosh",
      "Soham Dan",
      "Prasanna Sattigeri"
    ]
  },
  "https://openreview.net/forum?id=Mq59rTnIfE": {
    "title": "Combinatorial Multi-armed Bandits: Arm Selection via Group Testing",
    "volume": "main",
    "abstract": "This paper considers the problem of combinatorial multi-armed bandits with semi-bandit feedback and a cardinality constraint on the super-arm size. Existing algorithms for solving this problem typically involve two key sub-routines: (1) a *parameter estimation* routine that sequentially estimates a set of base-arm parameters, and (2) a *super-arm selection* policy for selecting a subset of base arms deemed optimal based on these parameters. State-of-the-art algorithms assume access to an *exact* oracle for super-arm selection with unbounded computational power. At each instance, this oracle evaluates a list of score functions, the number of which grows as low as linearly and as high as exponentially with the number of arms. This can be prohibitive in the regime of a large number of arms. This paper introduces a novel realistic alternative to the perfect oracle. This algorithm uses a combination of *group-testing* for selecting the super arms and *quantized* Thompson sampling for parameter estimation. Under a general separability assumption on the reward function, the proposed algorithm reduces the complexity of the super-arm-selection oracle to be *logarithmic* in the number of base arms while achieving the same regret order as the state-of-the-art algorithms that use exact oracles. This translates to *at least an exponential* reduction in complexity compared to the oracle-based approaches",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arpan Mukherjee",
      "Shashanka Ubaru",
      "Keerthiram Murugesan",
      "Karthikeyan Shanmugam",
      "Ali Tajer"
    ]
  },
  "https://openreview.net/forum?id=D3au9XkWuy": {
    "title": "Where to Intervene: Action Selection in Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "Deep reinforcement learning (RL) has gained widespread adoption in recent years but faces significant challenges, particularly in unknown and complex environments. Among these, high-dimensional action selection stands out as a critical problem. Existing works often require a sophisticated prior design to eliminate redundancy in the action space, relying heavily on domain expert experience or involving high computational complexity, which limits their generalizability across different RL tasks. In this paper, we address these challenges by proposing a general data-driven action selection approach with model-free and computationally friendly properties. Our method not only selects minimal sufficient actions but also controls the false discovery rate via knockoff sampling. More importantly, we seamlessly integrate the action selection into deep RL methods during online training. Empirical experiments validate the established theoretical guarantees, demonstrating that our method surpasses various alternative techniques in terms of both performance in variable selection and overall achieved rewards",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbo Zhang",
      "Hengrui Cai"
    ]
  },
  "https://openreview.net/forum?id=PEZz2i9kiP": {
    "title": "Counting Hours, Counting Losses: The Toll of Unpredictable Work Schedules on Financial Security",
    "volume": "main",
    "abstract": "Financial instability is a pressing concern in the United States, with drivers that include growing employment disparities and insufficient wages. While research typically focuses on financial aspects such as income inequality in precarious work environments, there is a tendency to overlook the time-related aspect of unstable work schedules. The inability to rely on a consistent work schedule not only leads to burnout and conflicts between work and family life but also results in financial shocks that directly impact workers' income and assets. Unforeseen fluctuations in earnings pose challenges in financial planning, affecting decisions regarding savings and spending, and ultimately undermining individuals' long-term financial stability and well-being. Our objective in this study is to understand how unforeseen fluctuations in earnings exacerbate financial fragility by investigating the extent to which individuals' financial management depends on their ability to anticipate and plan for future events. To answer this question, we present a computational framework to model real-time consumption decisions under income uncertainty, drawing on advances in online planning and reinforcement learning (RL) with lookahead. We introduce a novel online algorithm that enables utility-maximizing agents to dynamically adapt consumption choices in response to financial shocks, leveraging partial deterministic information about future income. This approach forms the basis of our simulation framework, which models how workers manage consumption in the face of variable work schedules and the imperative to avoid financial ruin. Through theoretical analysis, we quantify the utility advantage conferred by varying levels of lookahead. Empirical simulations demonstrate how increased lookahead improves financial utility. That is, with this framework, we demonstrate both theoretically and empirically how a worker's capacity to anticipate schedule changes enhances their long-term utility. Conversely, the inability to predict future events can worsen workers' financial instability. Moreover, our framework enables us to explore policy interventions aimed at mitigating the problem of schedule uncertainty. By modeling both individual behavior and potential policy interventions (e.g., advance scheduling regulations), our framework draws on ideas from machine learning and reinforcement learning to inform economic questions surrounding information access in financial planning",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pegah Nokhiz",
      "Aravinda Kanchana Ruwanpathirana",
      "Aditya Bhaskara",
      "Suresh Venkatasubramanian"
    ]
  },
  "https://openreview.net/forum?id=6DDaTwTvdE": {
    "title": "Does confidence calibration improve conformal prediction?",
    "volume": "main",
    "abstract": "Conformal prediction is an emerging technique for uncertainty quantification that constructs prediction sets guaranteed to contain the true label with a predefined probability. Previous works often employ temperature scaling to calibrate classifiers, assuming that confidence calibration benefits conformal prediction. However, the specific impact of confidence calibration on conformal prediction remains underexplored. In this work, we make two key discoveries about the impact of confidence calibration methods on adaptive conformal prediction. Firstly, we empirically show that current confidence calibration methods (e.g., temperature scaling) typically lead to larger prediction sets in adaptive conformal prediction. Secondly, by investigating the role of temperature value, we observe that high-confidence predictions can enhance the efficiency of adaptive conformal prediction. Theoretically, we prove that predictions with higher confidence result in smaller prediction sets on expectation. This finding implies that the rescaling parameters in these calibration methods, when optimized with cross-entropy loss, might counteract the goal of generating efficient prediction sets. To address this issue, we propose \\textbf{Conformal Temperature Scaling} (ConfTS), a variant of temperature scaling with a novel loss function designed to enhance the efficiency of prediction sets. This approach can be extended to optimize the parameters of other post-hoc methods of confidence calibration. Extensive experiments demonstrate that our method improves existing adaptive conformal prediction methods in both image and text classification tasks",
    "checked": true,
    "id": "e29a89a16bc5b6c80c40d98e4fae1cfa27799abf",
    "semantic_title": "does confidence calibration improve conformal prediction?",
    "citation_count": 6,
    "authors": [
      "HuaJun Xi",
      "Jianguo Huang",
      "Kangdao Liu",
      "Lei Feng",
      "Hongxin Wei"
    ]
  },
  "https://openreview.net/forum?id=Ycmz7qJxUQ": {
    "title": "Cluster and Predict Latents Patches for Improved Masked Image Modeling",
    "volume": "main",
    "abstract": "Masked Image Modeling (MIM) offers a promising approach to self-supervised representation learning, however existing MIM models still lag behind the state-of-the-art. In this paper, we systematically analyze target representations, loss functions, and architectures, to introduce CAPI -- a novel pure-MIM framework that relies on the prediction of latent clusterings. Our approach leverages a clustering-based loss, which is stable to train, and exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8\\% accuracy on ImageNet and 32.1\\% mIoU on ADE20K with simple linear probes, substantially outperforming previous MIM methods and approaching the performance of the current state-of-the-art, DINOv2",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Timothée Darcet",
      "Federico Baldassarre",
      "Maxime Oquab",
      "Julien Mairal",
      "Piotr Bojanowski"
    ]
  },
  "https://openreview.net/forum?id=gmflcWlVMl": {
    "title": "Fully Automatic Neural Network Reduction for Formal Verification",
    "volume": "main",
    "abstract": "Formal verification of neural networks is essential before their deployment in safety-critical applications. However, existing methods for formally verifying neural networks are not yet scalable enough to handle practical problems under strict time constraints. We address this challenge by introducing a fully automatic and sound reduction of neural networks using reachability analysis. The soundness ensures that the verification of the reduced network entails the verification of the original network. Our sound reduction approach is applicable to neural networks with any type of element-wise activation function, such as ReLU, sigmoid, and tanh. The network reduction is computed on the fly while simultaneously verifying the original network and its specification. All parameters are automatically tuned to minimize the network size without compromising verifiability. We further show the applicability of our approach to convolutional neural networks by explicitly exploiting similar neighboring pixels. Our evaluation shows that our approach reduces large neural networks to a fraction of the original number of neurons and thus shortens the verification time to a similar degree",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tobias Ladner",
      "Matthias Althoff"
    ]
  },
  "https://openreview.net/forum?id=9sbetmvNpW": {
    "title": "What Matters for Model Merging at Scale?",
    "volume": "main",
    "abstract": "Model merging aims to combine multiple expert models into a more capable single model, offering benefits such as reduced storage and serving costs, improved generalization, and support for decentralized model development. Despite its promise, previous studies have primarily focused on merging a few small models. This leaves many unanswered questions about the effect of scaling model size and how it interplays with other key factors—like the base model quality and number of expert models— to affect the merged model's performance. This work systematically evaluates the utility of model merging at scale for transformer based models to examine the impact of these different factors. We experiment with merging fully fine-tuned models using four popular merging methods—Averaging, Task Arithmetic, Dare-TIES, and TIES-Merging—across model sizes ranging from 1B to 64B parameters and merging up to 8 different expert models. We evaluate the merged models on both held-in tasks, i.e., the expert's training tasks, and zero-shot generalization to unseen held-out tasks. Our wide range of experiments provide several new insights about merging transformer based language models at scale and the interplay between different factors. First, we find that merging is more effective when experts are created from strong base models, i.e., models with good zero-shot performance, compared to pre-trained ones. Second, larger models perform better when merged. Third merging consistently improves generalization capabilities. Notably, when merging eight large expert models, the merged models often generalize better compared to the multitask trained models. Fourth, we can better merge more expert models when working with larger models. Fifth, different merging methods behave very similarly at larger scales. Overall, our findings shed light on some interesting properties of model merging while also highlighting some limitations",
    "checked": true,
    "id": "8be007b56c353108f0bb1c0797898def8ff64eaf",
    "semantic_title": "what matters for model merging at scale?",
    "citation_count": 22,
    "authors": [
      "Prateek Yadav",
      "Tu Vu",
      "Jonathan Lai",
      "Alexandra Chronopoulou",
      "Manaal Faruqui",
      "Mohit Bansal",
      "Tsendsuren Munkhdalai"
    ]
  },
  "https://openreview.net/forum?id=qjNdGpgpV8": {
    "title": "SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks",
    "volume": "main",
    "abstract": "Vision-Language Models (VLMs) have great potential in medical tasks, like Visual Question Answering (VQA), where they could act as interactive assistants for both patients and clinicians. Yet their robustness to distribution shifts on unseen data remains a key concern for safe deployment. Evaluating such robustness requires a controlled experimental setup that allows for systematic insights into the model's behavior. However, we demonstrate that current setups fail to offer sufficiently thorough evaluations. To address this gap, we introduce a novel framework, called SURE-VQA, centered around three key requirements to overcome current pitfalls and systematically analyze VLM robustness: 1) Since robustness on synthetic shifts does not necessarily translate to real-world shifts, it should be measured on real-world shifts that are inherent to the VQA data; 2) Traditional token-matching metrics often fail to capture underlying semantics, necessitating the use of large language models (LLMs) for more accurate semantic evaluation; 3) Model performance often lacks interpretability due to missing sanity baselines, thus meaningful baselines should be reported that allow assessing the multimodal impact on the VLM. To demonstrate the relevance of this framework, we conduct a study on the robustness of various Fine-Tuning (FT) methods across three medical datasets with four types of distribution shifts. Our study highlights key insights into robustness: 1) No FT method consistently outperforms others in robustness, and 2) robustness trends are more stable across FT methods than across distribution shifts. Additionally, we find that simple sanity baselines that do not use the image data can perform surprisingly well and confirm LoRA as the best-performing FT method on in-distribution data. Code is provided at https://github.com/IML-DKFZ/sure-vqa",
    "checked": true,
    "id": "819b1c348841ae1cde25796244c36fe75fd51de0",
    "semantic_title": "sure-vqa: systematic understanding of robustness evaluation in medical vqa tasks",
    "citation_count": 0,
    "authors": [
      "Kim-Celine Kahl",
      "Selen Erkan",
      "Jeremias Traub",
      "Carsten T. Lüth",
      "Klaus Maier-Hein",
      "Lena Maier-hein",
      "Paul F Jaeger"
    ]
  },
  "https://openreview.net/forum?id=Q1Cf07flwD": {
    "title": "Variance Dichotomy in Feature Spaces of Facial Recognition Systems is a Weak Defense against Simple Weight Manipulation Attacks",
    "volume": "main",
    "abstract": "We show that several leading pretrained facial recognition systems exhibit a variance dichotomy in their feature space. In other words, the feature vectors approximately lie in a lower dimensional linear subspace. We demonstrate that this variance dichotomy degrades the performance of an otherwise powerful scheme for anonymity/unlinkability and confusion attacks on facial recognition system devised by Zehavi et al. (2024), which is based on simple weight manipulations in only the last hidden layer. Lastly, we propose a method for the attacker to overcome this intrinsic defense of these pretrained facial recognition systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew Bowditch",
      "Mike Paterson",
      "Matthias Englert",
      "Ranko Lazic"
    ]
  },
  "https://openreview.net/forum?id=XNVBSbtcKB": {
    "title": "Learned-Database Systems Security",
    "volume": "main",
    "abstract": "A learned database system uses machine learning (ML) internally to improve performance. We can expect such systems to be vulnerable to some adversarial-ML attacks. Often, the learned component is shared between mutually-distrusting users or processes, much like microarchitectural resources such as caches, potentially giving rise to highly-realistic attacker models. However, compared to attacks on other ML-based systems, attackers face a level of indirection as they cannot interact directly with the learned model. Additionally, the difference between the attack surface of learned and non-learned versions of the same system is often subtle. These factors obfuscate the de-facto risks that the incorporation of ML carries. We analyze the root causes of potentially-increased attack surface in learned database systems and develop a framework for identifying vulnerabilities that stem from the use of ML. We apply our framework to a broad set of learned components currently being explored in the database community. To empirically validate the vulnerabilities surfaced by our framework, we choose 3 of them and implement and evaluate exploits against these. We show that the use of ML cause leakage of past queries in a database, enable a poisoning attack that causes exponential memory blowup in an index structure and crashes it in seconds, and enable index users to snoop on each others' key distributions by timing queries over their own keys. We find that adversarial ML is an universal threat against learned components in database systems, point to open research gaps in our understanding of learned-systems security, and conclude by discussing mitigations, while noting that data leakage is inherent in systems whose learned component is shared between multiple parties",
    "checked": false,
    "id": "8089ec5f563c33edbc9d088bce410565ef55dde1",
    "semantic_title": "the case for learned provenance graph storage systems",
    "citation_count": 12,
    "authors": [
      "Roei Schuster",
      "Jin Peng Zhou",
      "Thorsten Eisenhofer",
      "Paul Grubbs",
      "Nicolas Papernot"
    ]
  },
  "https://openreview.net/forum?id=B9fdU4qjpD": {
    "title": "Controlled Model Debiasing through Minimal and Interpretable Updates",
    "volume": "main",
    "abstract": "Traditional approaches to learning fair machine learning models often require rebuilding models from scratch, typically without considering potentially existing models. In a context where models need to be retrained frequently, this can lead to inconsistent model updates, as well as redundant and costly validation testing. To address this limitation, we introduce the notion of controlled model debiasing, a novel supervised learning task relying on two desiderata: that the differences between the new fair model and the existing one should be (i) minimal and (ii) interpretable. After providing theoretical guarantees to this new problem, we introduce a novel algorithm for algorithmic fairness, COMMOD, that is both model-agnostic and does not require the sensitive attribute at test time. In addition, our algorithm is explicitly designed to enforce minimal and interpretable changes between biased and debiased predictions in a binary classification task—a property that, while highly desirable in high-stakes applications, is rarely prioritized as an explicit objective in fairness literature. Our approach combines a concept-based architecture and adversarial learning and we demonstrate through empirical results that it achieves comparable performance to state-of-the-art debiasing methods while performing minimal and interpretable prediction changes",
    "checked": true,
    "id": "80857416ae7f417a1a9f1dbb04aa755c74e0ec18",
    "semantic_title": "controlled model debiasing through minimal and interpretable updates",
    "citation_count": 0,
    "authors": [
      "Federico Di Gennaro",
      "Thibault Laugel",
      "Vincent Grari",
      "Marcin Detyniecki"
    ]
  },
  "https://openreview.net/forum?id=LLiJ1WsL2e": {
    "title": "Fairness and Disentanglement: A Critical Review of Predominant Bias in Neural Networks",
    "volume": "main",
    "abstract": "Bias issues of neural networks garner significant attention along with their promising advancement. Among various bias issues, mitigating two predominant biases is crucial in advancing fair and trustworthy AI: (1) ensuring neural networks yield even performance across demographic groups, and (2) ensuring algorithmic decision-making does not rely on protected attributes. However, upon the investigation of 415 papers in the relevant literature, we find that there exists a persistent, extensive but under-explored confusion regarding these two types of biases. Furthermore, the confusion has already significantly hampered the clarity of the community and the subsequent development of debiasing methodologies. Thus, in this work, we aim to restore clarity by providing two mathematical definitions for these two predominant biases and leveraging these definitions to unify a comprehensive list of papers. Next, we highlight the common phenomena and the possible reasons for the existing confusion. To alleviate the confusion, we provide extensive experiments on synthetic, census, and image datasets to validate the distinct nature of these biases, distinguish their different real-world manifestations, and evaluate the effectiveness of a comprehensive list of bias assessment metrics in assessing the mitigation of these biases. Further, we compare these two types of biases from multiple dimensions, including the underlying causes, debiasing methods, evaluation protocol, prevalent datasets, and future directions. Last, we provide several suggestions aiming to guide researchers engaged in bias-related work to avoid confusion and further enhance clarity in the community",
    "checked": false,
    "id": "4e684e3475aa2a85559ea19a3c3cc3e774254b01",
    "semantic_title": "a critical review of predominant bias in neural networks",
    "citation_count": 0,
    "authors": [
      "Jiazhi Li",
      "Mahyar Khayatkhoei",
      "Jiageng Zhu",
      "Hanchen Xie",
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ]
  },
  "https://openreview.net/forum?id=uObs1YwXjQ": {
    "title": "Predictive Control and Regret Analysis of Non-Stationary MDP with Look-ahead Information",
    "volume": "main",
    "abstract": "Policy design in non-stationary Markov Decision Processes (MDPs) is inherently challenging due to the complexities introduced by time-varying system transition and reward, which make it difficult for learners to determine the optimal actions for maximizing cumulative future rewards. Fortunately, in many practical applications, such as energy systems, look-ahead predictions are available, including forecasts for renewable energy generation and demand. In this paper, we leverage these look-ahead predictions and propose an algorithm designed to achieve low regret in non-stationary MDPs by incorporating such predictions. Our theoretical analysis demonstrates that, under certain assumptions, the regret decreases exponentially as the look-ahead window expands. When the system prediction is subject to error, the regret does not explode even if the prediction error grows sub-exponentially as a function of the prediction horizon. We validate our approach through simulations and confirm its efficacy in non-stationary environments",
    "checked": true,
    "id": "242ecc3be65fc352806ac624b7edd6beb5e56bf4",
    "semantic_title": "predictive control and regret analysis of non-stationary mdp with look-ahead information",
    "citation_count": 1,
    "authors": [
      "Ziyi Zhang",
      "yorie nakahira",
      "Guannan Qu"
    ]
  },
  "https://openreview.net/forum?id=Na02hDWqkF": {
    "title": "On Efficient Bayesian Exploration in Model-Based Reinforcement Learning",
    "volume": "main",
    "abstract": "In this work, we address the challenge of data-efficient exploration in reinforcement learning by examining existing principled, information-theoretic approaches to intrinsic motivation. Specifically, we focus on a class of exploration bonuses that targets epistemic uncertainty rather than the aleatoric noise inherent in the environment. We prove that these bonuses naturally signal epistemic information gains and converge to zero once the agent becomes sufficiently certain about the environment's dynamics and rewards, thereby aligning exploration with genuine knowledge gaps. Our analysis provides formal guarantees for IG-based approaches, which previously lacked theoretical grounding. To enable practical use, we also discuss tractable approximations via sparse variational Gaussian Processes, Deep Kernels and Deep Ensemble models. We then outline a general framework — Predictive Trajectory Sampling with Bayesian Exploration (PTS-BE) — which integrates model-based planning with information-theoretic bonuses to achieve sample-efficient deep exploration. We empirically demonstrate that PTS-BE substantially outperforms other baselines across a variety of environments characterized by sparse rewards and/or purely exploratory tasks",
    "checked": false,
    "id": "10bf0451f152d7f89d29370b0dbb05dce5b52ff3",
    "semantic_title": "active exploration in bayesian model-based reinforcement learning for robot manipulation",
    "citation_count": 0,
    "authors": [
      "Alberto Caron",
      "Vasilios Mavroudis",
      "Chris Hicks"
    ]
  },
  "https://openreview.net/forum?id=Ht7rlkRCHq": {
    "title": "Batch Training for Streaming Time Series: A Transferable Augmentation Framework to Combat Distribution Shifts",
    "volume": "main",
    "abstract": "Multivariate time series forecasting, which predicts future dynamics by analyzing historical data, has become an essential tool in modern data analysis. With the development of deep models, batch-training based time series forecasting has made significant progress. However, in real-world applications, time series data is often collected incrementally in a streaming manner, with only a portion of the data available at each time step. As time progresses, distribution shifts in the data can occur, leading to a drastic decline in model performance. To address this challenge, online test-time adaptation and online time series forecasting have emerged as a promising solution. However, for the former, most online test-time adaptation methods are primarily designed for images and do not consider the specific characteristics of time series. As for the latter, online time series forecasting typically relies on updating the model with each newly collected sample individually, which may be problematic when the sample deviates significantly from the historical data distribution and contains noise, which may lead to a worse generalization performance. In this paper, we propose Batch Training with Transferable Online Augmentation (BTOA), which enhances model performance through three key ideas while enabling batch training. First, to fully leverage historical information, Transferable Historical Sample Selection (THSS) is proposed with theoretical guarantees to select historical samples that are most similar to the test-time distribution. Then, to mitigate the negative impact of distribution shifts through batch training and take advantage of the unique characteristics of time series, Transferable Online Augmentation (TOA) is proposed to augment the selected historical samples from the perspective of amplitude and phase in the frequency domain in a two-stream manner. Finally, a prediction module that utilizes a series decomposition module and a two-stream forecaster is employed to extract the complex patterns in time series, boosting the prediction performance. Moreover, BTOA is a general approach that is readily pluggable into any existing batch-training based deep models.Comprehensive experiments under both ideal and practice experimental settings demonstrate that the proposed method exhibits superior performance across all seven benchmark datasets. Compared to state-of-the-art approaches, our method reduces the Mean Squared Error (MSE) by up to 13.7\\%",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weiyang Zhang",
      "Xinyang Chen",
      "Yu Sun",
      "Weili Guan",
      "Liqiang Nie"
    ]
  },
  "https://openreview.net/forum?id=1fML4VF5FG": {
    "title": "Test-Time Fairness and Robustness in Large Language Models",
    "volume": "main",
    "abstract": "Frontier Large Language Models (LLMs) can be socially discriminatory or sensitive to spurious features of their inputs. Because only well-resourced corporations can train frontier LLMs, we need robust test-time strategies to control such biases. Existing solutions, which instruct the LLM to be fair or robust, rely on the model's implicit understanding of bias. Causality provides a rich formalism through which we can be explicit about our debiasing requirements. Yet, as we show, a naive application of the standard causal debiasing strategy, counterfactual data augmentation, fails to fulfill individual-level debiasing requirements at test time. To address this, we develop stratified invariance, a flexible debiasing notion that can capture a range of debiasing requirements, from population level to individual level, through an additional measurement that stratifies the predictions. We developed a complete test for this new approach and introduced a data augmentation strategy that guarantees stratified invariance at test time under suitable assumptions, together with a prompting strategy that encourages stratified invariance in LLMs. We show that our prompting strategy, unlike implicit instructions, consistently reduces the bias of frontier LLMs across a suite of synthetic and real-world benchmarks without requiring additional data, finetuning or pre-training",
    "checked": true,
    "id": "c9db178549df34ea26994753e3560afac761f39e",
    "semantic_title": "test-time fairness and robustness in large language models",
    "citation_count": 2,
    "authors": [
      "Leonardo Cotta",
      "Chris J. Maddison"
    ]
  },
  "https://openreview.net/forum?id=BukMU42P3G": {
    "title": "Collaboration with Dynamic Open Ad Hoc Team via Team State Modelling",
    "volume": "main",
    "abstract": "Open ad hoc teamwork presents the challenging problem of designing an autonomous agent that can rapidly adapt to collaborate with teammates without prior coordination in an open environment. Existing methods primarily rely on fixed, predefined teammate types, overlooking the fact that teammates may change dynamically. To address this limitation, we propose a novel reinforcement learning approach, the Open Online Teammate Adaptation Framework (Open-OTAF), which enables a controlled agent to collaborate with dynamic teammates in open ad hoc environments. To achieve this, the controlled agent employs a dual teamwork situation inference model to capture the current teamwork state, facilitating decision-making under partial observability. To handle the dynamic nature of teammate types, we first introduce a Chinese Restaurant Process-based model to categorize diverse teammate policies into distinct clusters, improving the efficiency of identifying teamwork situations. Next, to model heterogeneous agent relationships and accommodate a variable number of teammates, we represent the team as a heterogeneous graph and leverage heterogeneous graph attention neural networks to learn the representation of the teamwork situation. Extensive experiments across four challenging multi-agent benchmark tasks—Level-Based Foraging, Wolf-Pack, Cooperative Navigation, and FortAttack—demonstrate that our method successfully enables dynamic teamwork in open ad hoc settings. Open-OTAF outperforms state-of-the-art methods, achieving superior performance with faster convergence",
    "checked": true,
    "id": "c10052ebbc4803c52e114b5993f816a743bda0cf",
    "semantic_title": "collaboration with dynamic open ad hoc team via team state modelling",
    "citation_count": 0,
    "authors": [
      "Jing Sun",
      "Cong Zhang",
      "Zhiguang Cao"
    ]
  },
  "https://openreview.net/forum?id=4mCkRbUXOf": {
    "title": "Do Concept Bottleneck Models Respect Localities?",
    "volume": "main",
    "abstract": "Concept-based explainability methods use human-understandable intermediaries to produce explanations for machine learning models. These methods assume concept predictions can help understand a model's internal reasoning. In this work, we assess the degree to which such an assumption is true by analyzing whether concept predictors leverage \"relevant\" features to make predictions, a term we call locality. Concept-based models that fail to respect localities also fail to be explainable because concept predictions are based on spurious features, making the interpretation of the concept predictions vacuous. To assess whether concept-based models respect localities, we construct and use three metrics to characterize when models respect localities, complementing our analysis with theoretical results. Each of our metrics captures a different notion of perturbation and assess whether perturbing \"irrelevant\" features impacts the predictions made by a concept predictors. We find that many concept-based models used in practice fail to respect localities because concept predictors cannot always clearly distinguish distinct concepts. Based on these findings, we propose suggestions for alleviating this issue",
    "checked": true,
    "id": "e6ba1c35c1f1bd034960929471bcdd6090299a91",
    "semantic_title": "do concept bottleneck models respect localities?",
    "citation_count": 7,
    "authors": [
      "Naveen Janaki Raman",
      "Mateo Espinosa Zarlenga",
      "Juyeon Heo",
      "Mateja Jamnik"
    ]
  },
  "https://openreview.net/forum?id=dWvztQzfy4": {
    "title": "LC-PLM: Long-context Protein Language Modeling Using Bidirectional Mamba with Shared Projection Layers",
    "volume": "main",
    "abstract": "Self-supervised training of language models (LMs) has seen great success for protein sequences in learning meaningful representations and for generative drug design. Most protein LMs are based on the Transformer architecture trained on individual proteins with short context lengths. Such protein LMs cannot extrapolate to longer proteins and protein complexes well. They also fail to account for the underlying biological mechanisms carried out by biomolecular interactions and dynamics i.e., proteins often interact with other proteins, molecules, and pathways in complex biological systems. In this work, we propose LC-PLM based on an alternative protein LM architecture, BiMamba-S, built upon selective structured state-space models, to learn high-quality universal protein representations at the amino acid token level using masked language modeling. We also introduce its graph-contextual variant, LC-PLM, which contextualizes protein-protein interaction (PPI) graphs for a second stage of training. LC-PLM demonstrates favorable neural scaling laws, better length extrapolation capability, and up to 30% and 16% improvements on protein downstream tasks compared to Transformer-based ESM-2 when trained with 100B and 1T tokens, respectively. LC-PLM-G further trained within the context of PPI graphs shows promising results on protein structure and function prediction tasks. Our study demonstrates the benefit of increasing the context size with computationally efficient LM architecture (e.g., structured state space models) in learning universal protein representations and incorporating molecular interaction contexts contained in biological graphs. Model is available at github.com/amazon-science/LC-PLM",
    "checked": true,
    "id": "9b2bc18228dc1e3a36e168ad0e094d0d85cd2fab",
    "semantic_title": "lc-plm: long-context protein language modeling using bidirectional mamba with shared projection layers",
    "citation_count": 1,
    "authors": [
      "Yingheng Wang",
      "Zichen Wang",
      "Gil Sadeh",
      "Luca Zancato",
      "Alessandro Achille",
      "George Karypis",
      "Huzefa Rangwala"
    ]
  },
  "https://openreview.net/forum?id=SfqCaAOF1S": {
    "title": "DisDet: Exploring Detectability of Backdoor Attack on Diffusion Models",
    "volume": "main",
    "abstract": "In the exciting generative AI era, the diffusion model has emerged as a very powerful and widely adopted content-generation tool. Very recently, some pioneering works have shown the vulnerability of the diffusion model against backdoor attacks, calling for in-depth analysis and investigation of the security challenges. In this paper, we explore the detectability of the poisoned noise input for the backdoored diffusion models, an important performance metric yet little explored in the existing works. Starting from the perspective of a defender, we first analyze the distribution discrepancy of the trigger pattern in the existing diffusion backdoor attacks. Based on this finding, we propose a trigger detection mechanism that can effectively identify the poisoned input noise. Then, from the attack side, we propose a backdoor attack strategy that can learn the unnoticeable trigger to evade our proposed detection scheme. Our empirical evaluations across various diffusion models and datasets demonstrate the effectiveness of the proposed trigger detection and detection-evading attack strategy. For trigger detection, our distribution discrepancy-based solution can achieve a 100% detection rate for the Trojan triggers used in the existing works. For evading trigger detection, our proposed stealthy trigger design approach performs end-to-end learning to make the distribution of poisoned noise input approach that of benign noise, enabling nearly 100% detection pass rate with very high attack and benign performance for the backdoored diffusion models",
    "checked": true,
    "id": "03418873438932b542ab2e221f26bbc564fb5d0f",
    "semantic_title": "disdet: exploring detectability of backdoor attack on diffusion models",
    "citation_count": 13,
    "authors": [
      "Yang Sui",
      "Huy Phan",
      "Jinqi Xiao",
      "Tianfang Zhang",
      "Zijie Tang",
      "Cong Shi",
      "Yan Wang",
      "Yingying Chen",
      "Bo Yuan"
    ]
  },
  "https://openreview.net/forum?id=LNoFjcLywb": {
    "title": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum",
    "volume": "main",
    "abstract": "Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios. However, system and statistical challenges hinder its real-world applicability, requiring efficient learning from edge devices and robustness to data heterogeneity. Despite significant research efforts, existing approaches often degrade severely due to the joint effect of heterogeneity and partial client participation. In particular, while momentum appears as a promising approach for overcoming statistical heterogeneity, in current approaches its update is biased towards the most recently sampled clients. As we show in this work, this is the reason why it fails to outperform FedAvg, preventing its effective use in real-world large-scale scenarios. In this work, we propose a novel Generalized Heavy-Ball Momentum (GHBM) and theoretically prove it enables convergence under unbounded data heterogeneity in cyclic partial participation, thereby advancing the understanding of momentum's effectiveness in FL. We then introduce adaptive and communication-efficient variants of GHBM that match the communication complexity of FedAvg in settings where clients can be stateful. Extensive experiments on vision and language tasks confirm our theoretical findings, demonstrating that GHBM substantially improves state-of-the-art performance under random uniform client sampling, particularly in large-scale settings with high data heterogeneity and low client participation",
    "checked": true,
    "id": "52c6497d472bfef898e0ade820714e3dd7b3ce69",
    "semantic_title": "communication-efficient heterogeneous federated learning with generalized heavy-ball momentum",
    "citation_count": 2,
    "authors": [
      "Riccardo Zaccone",
      "Sai Praneeth Karimireddy",
      "Carlo Masone",
      "Marco Ciccone"
    ]
  },
  "https://openreview.net/forum?id=TZtpxselK2": {
    "title": "Are Convex Optimization Curves Convex?",
    "volume": "main",
    "abstract": "In this paper, we study when we might expect the optimization curve induced by gradient descent to be \\emph{convex} -- precluding, for example, an initial plateau followed by a sharp decrease, making it difficult to decide when optimization should stop. Although such undesirable behavior can certainly occur when optimizing general functions, might it also occur in the benign and well-studied case of smooth convex functions? As far as we know, this question has not been tackled in previous work. We show, perhaps surprisingly, that the answer crucially depends on the choice of the step size. In particular, for the range of step sizes which are known to result in monotonic convergence to an optimal value, we characterize a regime where the optimization curve will be provably convex, and a regime where the curve can be non-convex. We also extend our results to gradient flow, and to the closely-related but different question of whether the gradient norm decreases monotonically",
    "checked": true,
    "id": "5750ee11f5e61d28bf354988219560d81ee7fc0a",
    "semantic_title": "are convex optimization curves convex?",
    "citation_count": 0,
    "authors": [
      "Guy Barzilai",
      "Ohad Shamir",
      "Moslem Zamani"
    ]
  },
  "https://openreview.net/forum?id=UgZIR6TF5N": {
    "title": "Evolution guided generative flow networks",
    "volume": "main",
    "abstract": "Generative Flow Networks (GFlowNets) are a family of probabilistic generative models recently invented that learn to sample compositional objects proportional to their rewards. One big challenge of GFlowNets is training them effectively when dealing with long time horizons and sparse rewards. To address this, we propose Evolution guided generative flow networks (EGFN), a simple but powerful augmentation to the GFlowNets training using Evolutionary algorithms (EA). Our method can work on top of any GFlowNets training objective, by training a set of agent parameters using EA, storing the resulting trajectories in the prioritized replay buffer, and training the GFlowNets agent using the stored trajectories. We present a thorough investigation over a wide range of toy and real-world benchmark tasks showing the effectiveness of our method in handling long trajectories and sparse rewards. We release the code at http://github.com/zarifikram/egfn",
    "checked": true,
    "id": "1d430a53fc68b68043d50d746e3097903f04dc5a",
    "semantic_title": "evolution guided generative flow networks",
    "citation_count": 1,
    "authors": [
      "Zarif Ikram",
      "Ling Pan",
      "Dianbo Liu"
    ]
  },
  "https://openreview.net/forum?id=XK7cIdj6Fz": {
    "title": "Graph Fourier Neural ODEs: Modeling Spatial-temporal Multi-scales in Molecular Dynamics",
    "volume": "main",
    "abstract": "Accurately predicting long-horizon molecular dynamics (MD) trajectories remains a significant challenge, as existing deep learning methods often struggle to retain fidelity over extended simulations. We hypothesize that one key factor limiting accuracy is the difficulty of capturing interactions that span distinct spatial and temporal scales—ranging from high-frequency local vibrations to low-frequency global conformational changes. To address these limitations, we propose **Graph Fourier Neural ODEs (GF-NODE)**, integrating a graph Fourier transform for spatial frequency decomposition with a Neural ODE framework for continuous-time evolution. Specifically, GF-NODE first decomposes molecular configurations into multiple spatial frequency modes using the graph Laplacian, then evolves the frequency components in time via a learnable Neural ODE module that captures both local and global dynamics, and finally reconstructs the updated molecular geometry through an inverse graph Fourier transform. By explicitly modeling high- and low-frequency phenomena in this unified pipeline, GF-NODE more effectively captures long-range correlations and local fluctuations alike. We provide theoretical insight through heat equation analysis on a simplified diffusion model, demonstrating how graph Laplacian eigenvalues can determine temporal dynamics scales, and crucially validate this correspondence through comprehensive empirical analysis on real molecular dynamics trajectories showing quantitative spatial-temporal correlations across diverse molecular systems. Experimental results on challenging MD benchmarks, including MD17 and alanine dipeptide, demonstrate that GF-NODE achieves state-of-the-art accuracy while preserving essential geometrical features over extended simulations. These findings highlight the promise of bridging spectral decomposition with continuous-time modeling to improve the robustness and predictive power of MD simulations. Our implementation is publicly available at https://github.com/FrancoTSolis/GF-NODE-code",
    "checked": true,
    "id": "a9c8141e4394e7c5e91421082182e5693bc90958",
    "semantic_title": "graph fourier neural odes: modeling spatial-temporal multi-scales in molecular dynamics",
    "citation_count": 0,
    "authors": [
      "Fang Sun",
      "Zijie Huang",
      "Haixin Wang",
      "Huacong Tang",
      "Xiao Luo",
      "Wei Wang",
      "Yizhou Sun"
    ]
  },
  "https://openreview.net/forum?id=lyDRBhUjhv": {
    "title": "A Stochastic Polynomial Expansion for Uncertainty Propagation through Networks",
    "volume": "main",
    "abstract": "Network-based machine learning constructs are becoming more prevalent in sensing and decision-making systems. As these systems are implemented in safety-critical environments such as pedestrian detection and power management, it is crucial to evaluate confidence in their decisions. At the heart of this problem is a need to understand and characterize how errors at the input of networks become progressively expanded or contracted as signals move through layers, especially in light of the non-trivial nonlinearities manifest throughout modern machine learning architectures. When sampling methods become expensive due to network size or complexity, approximation is needed and popular methods include Jacobian (first order Taylor) linearization and stochastic linearization. However, despite computational tractability, the accuracy of these methods can break down in situations with moderate to high input uncertainty. Here, we present a generalized method of propagating variational multivariate Gaussian distributions through neural networks. We propose a modified Taylor expansion function for nonlinear transformation of Gaussian distributions, with an additional approximation in which the polynomial terms act on independent Gaussian random variables (which are identically distributed). With these approximated higher order terms (HOTs), we obtain significantly more accurate estimation of layer-wise distributions. Despite the introduction of the HOTs, this method can propagate a full covariance matrix with a complexity of $\\boldsymbol{O}(n^2)$ (and $\\boldsymbol{O}(n)$ if only propagating marginal variance), comparable to Jacobian linearization. Thus, our method finds a balance between efficiency and accuracy. We derived the closed form solutions for this approximate Stochastic Taylor expansion for seven commonly used nonlinearities and verified the effectiveness of our method in deep residual neural networks, Bayesian neural networks, and variational autoencoders. This general method can be integrated into use-cases such as Kalman filtering, adversarial training, and variational learning",
    "checked": false,
    "id": "2c8b496ea57da01dac830ec80929a6cb1ca15376",
    "semantic_title": "spectral propagation of uncertainty in water age",
    "citation_count": 0,
    "authors": [
      "Songhan Zhang",
      "ShiNung Ching"
    ]
  },
  "https://openreview.net/forum?id=T1NjRBI5xs": {
    "title": "Fair Online Influence Maximization",
    "volume": "main",
    "abstract": "Fair influence maximization in networks has been actively studied to ensure equity in fields like viral marketing and public health. Existing studies often assume an offline setting, meaning that the learner identifies a set of seed nodes with known per-edge activation probabilities. In this paper, we study the problem of fair online influence maximization, i.e., without knowing the ground-truth activation probabilities. The learner in this problem aims to maximally propagate the information among demographic groups, while interactively selecting seed nodes and observing the activation feedback on the fly. We propose Fair Online Influence Maximization (FOIM) framework that can solve the online influence maximization problem under a wide range of fairness notions. Given a fairness notion, FOIM solves the problem with a combinatorial multi-armed bandit algorithm for balancing exploration-exploitation and an offline fair influence maximization oracle for seed nodes selection. FOIM enjoys sublinear regret when the fairness notion satisfies two mild conditions, i.e., monotonicity and bounded smoothness. Our analyses show that common fairness notions, including maximin fairness, diversity fairness, and welfare function, all satisfy the condition, and we prove the corresponding regret upper bounds under these notions. Extensive empirical evaluations on three real-world networks demonstrate the efficacy of our proposed framework",
    "checked": false,
    "id": "e5e91c6c9dac1e3d8544bb62b0b3b2bc0818a463",
    "semantic_title": "scalable fair influence maximization",
    "citation_count": 8,
    "authors": [
      "Xiangqi Wang",
      "Shaokun Zhang",
      "Jose Efraim Aguilar Escamilla",
      "Qingyun Wu",
      "Xiangliang Zhang",
      "Jian Kang",
      "Huazheng Wang"
    ]
  },
  "https://openreview.net/forum?id=zNsfgCns7x": {
    "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach",
    "volume": "main",
    "abstract": "Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over five datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy",
    "checked": true,
    "id": "858d7e8d00b8704003909211be47138b843cc599",
    "semantic_title": "understanding and reducing the class-dependent effects of data augmentation with a two-player game approach",
    "citation_count": 0,
    "authors": [
      "Yunpeng Jiang",
      "Yutong Ban",
      "Paul Weng"
    ]
  },
  "https://openreview.net/forum?id=yngjRgVA5A": {
    "title": "Disobeying Directions: Switching Random Walk Filters for Unsupervised Node Embedding Learning on Directed Graphs",
    "volume": "main",
    "abstract": "Unsupervised learning of node embeddings for directed graphs (digraphs) requires careful handling to ensure unbiased modelling. This paper addresses two key challenges: (1) the obstruction of information propagation in random walk and message-passing methods due to local sinks, and (2) the representation of multiple multi-step directed neighbourhoods, arising from the distinction between in- and out-neighbours. These challenges are interconnected—local sinks can be mitigated by treating the graph as undirected, but this comes at the cost of discarding all directional information. We make two main contributions to unsupervised embedding learning for digraphs. First, we introduce ReachNEs (Reachability Node Embeddings), a general framework for analysing embedding models and diagnosing local sink behaviour on digraphs. ReachNEs defines the reachability filter, a matrix polynomial over normalized adjacency matrices that captures multi-step, direction-sensitive proximity. It unifies the analysis of message-passing and random walk models, making its insights applicable across a wide range of embedding methods. Second, we propose DirSwitch, a novel embedding model that resolves both local sink bias and neighbourhood multiplicity via switching random walks. These walks use directed edges for local steps, preserving directional structure, then switch to undirected edges for long-range transitions, enabling escape from local sinks and improving information dispersal. Empirical results on node classification benchmarks demonstrate that DirSwitch consistently outperforms state-of-the-art unsupervised digraph proximity embedding methods, and also serves as a flexible digraph extension for self-supervised graph neural networks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ciwan Ceylan",
      "Kambiz Ghoorchian",
      "Danica Kragic"
    ]
  },
  "https://openreview.net/forum?id=yNiBUc2hMW": {
    "title": "TRA: Better Length Generalisation with Threshold Relative Attention",
    "volume": "main",
    "abstract": "Transformers struggle with length generalisation, displaying poor performance even on basic tasks. We test whether these limitations can be explained through two key failures of the self-attention mechanism. The first is the inability to fully remove irrelevant information. The second is tied to position, even if the dot product between a key and query is highly negative (i.e. an irrelevant key) learned positional biases may unintentionally up-weight such information - dangerous when distances become out of distribution. Put together, these two failure cases lead to compounding generalisation difficulties. We test whether they can be mitigated through the combination of a) selective sparsity - completely removing irrelevant keys from the attention softmax and b) contextualised relative distance - distance is only considered as between the query and the keys that matter. We show how refactoring the attention mechanism with these two mitigations in place can substantially improve generalisation capabilities of decoder only transformers",
    "checked": true,
    "id": "abad5178463d5e34f233e746e22a164a47ae926d",
    "semantic_title": "tra: better length generalisation with threshold relative attention",
    "citation_count": 0,
    "authors": [
      "Mattia Opper",
      "Roland Fernandez",
      "Paul Smolensky",
      "Jianfeng Gao"
    ]
  },
  "https://openreview.net/forum?id=Gx8ujJTnG9": {
    "title": "Riemann-Lebesgue Forest for Regression",
    "volume": "main",
    "abstract": "We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for regression. The core idea in RLF is to mimic the way how a measurable function can be approximated by partitioning its range into a few intervals. With this idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree (RLT) which has a chance to perform ``Lebesgue'' type cutting,i.e., splitting the node from response Y at certain non-terminal nodes. In other words, we introduce the ``splitting type randomness'' in training our ensemble method. Since the information of Y is unavailable in the prediction step, weak local models such as small random forests or decision trees are fit in non-terminal nodes with ``Lebesgue'' type cutting to determine which child node should we proceed to. We show that the optimal ``Lebesgue'' type cutting results in larger variance reduction in response Y than ordinary CART cutting (an analogue of Riemann partition) in fitting a base tree. Such property is beneficial to the ensemble part of RLF, which is verified by extensive experiments. We also establish the asymptotic normality of RLF under different parameter settings. Two one-dimensional examples are provided to illustrate the flexibility of RLF. The competitive performance of RLF with small local random forests against original random forest (RF) and boosting methods such as XGboost is demonstrated by extensive experiments in simulation data and real-world datasets. Additional experiments further illustrate that RLF with local decision trees could achieve decent performance comparable to that of RF with less running time, especially in large datasets",
    "checked": true,
    "id": "3da88fefab4390e6f5fc59c01a4051f649a656f7",
    "semantic_title": "riemann-lebesgue forest for regression",
    "citation_count": 0,
    "authors": [
      "Tian Qin",
      "Wei-Min Huang"
    ]
  },
  "https://openreview.net/forum?id=cllm6SS354": {
    "title": "Distributional Reduction: Unifying Dimensionality Reduction and Clustering with Gromov-Wasserstein",
    "volume": "main",
    "abstract": "Unsupervised learning aims to capture the underlying structure of potentially large and high-dimensional datasets. Traditionally, this involves using dimensionality reduction (DR) methods to project data onto lower-dimensional spaces or organizing points into meaningful clusters (clustering). In this work, we revisit these approaches under the lens of optimal transport and exhibit relationships with the Gromov-Wasserstein problem. This unveils a new general framework, called distributional reduction, that recovers DR and clustering as special cases and allows addressing them jointly within a single optimization problem. We empirically demonstrate its relevance to the identification of low-dimensional prototypes representing data at different scales, across multiple image and genomic datasets",
    "checked": false,
    "id": "c51d60725510b036a2e3a220ff0466057b83a13d",
    "semantic_title": "distributional reduction: unifying dimensionality reduction and clustering with gromov-wasserstein projection",
    "citation_count": 5,
    "authors": [
      "Hugues Van Assel",
      "Cédric Vincent-Cuaz",
      "Nicolas Courty",
      "Rémi Flamary",
      "Pascal Frossard",
      "Titouan Vayer"
    ]
  },
  "https://openreview.net/forum?id=vvSHlH3a8V": {
    "title": "Adaptive Clipping for Differential Private Federated Learning in Interpolation Regimes",
    "volume": "main",
    "abstract": "We investigate improving the utility of standard differential private optimization algorithms by adaptively determining the clipping radius in federated learning. Our adaptive clipping radius is based on the root-mean-square of the gradient norms, motivated by the interpolation property and smoothness of the objectives. In addition to Renyi Differential Privacy (RDP) analysis, we conduct theoretical utility analysis of the proposed algorithm, showing that our method enhances utility compared to DP-SGD for smooth and non-strongly convex objectives. Numerical experiments confirm the superiority of our adaptive clipping algorithm over standard DP optimization with fixed clipping radius in federated learning settings",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Takumi Fukami",
      "Tomoya Murata",
      "Kenta Niwa"
    ]
  },
  "https://openreview.net/forum?id=SEJatSGZX8": {
    "title": "Unsupervised Panoptic Interpretation of Latent Spaces in GANs Using Space-Filling Vector Quantization",
    "volume": "main",
    "abstract": "Generative adversarial networks (GANs) learn a latent space whose samples can be mapped to real-world images. Such latent spaces are difficult to interpret. Some earlier supervised methods aim to create an interpretable latent space or discover interpretable directions, which requires exploiting data labels or annotated synthesized samples for training. However, we propose using a modification of vector quantization called space-filling vector quantization (SFVQ), which quantizes the data on a piece-wise linear curve. SFVQ can capture the underlying morphological structure of the latent space, making it interpretable. We apply this technique to model the latent space of pre-trained StyleGAN2 and BigGAN networks on various datasets. Our experiments show that the SFVQ curve yields a general interpretable model of the latent space such that it determines which parts of the latent space correspond to specific generative factors. Furthermore, we demonstrate that each line of the SFVQ curve can potentially refer to an interpretable direction for applying intelligible image transformations. We also demonstrate that the points located on an SFVQ line can be used for controllable data augmentation",
    "checked": true,
    "id": "860435f2ed29dc2faef5e5221fafb2c2f6c6c844",
    "semantic_title": "unsupervised panoptic interpretation of latent spaces in gans using space-filling vector quantization",
    "citation_count": 0,
    "authors": [
      "Mohammad Hassan Vali",
      "Tom Bäckström"
    ]
  },
  "https://openreview.net/forum?id=UkP4DhrJt1": {
    "title": "Accounting for AI and Users Shaping One Another: The Role of Mathematical Models",
    "volume": "main",
    "abstract": "As AI systems enter into a growing number of societal domains, these systems increasingly shape and are shaped by user preferences, opinions, and behaviors. However, the design of AI systems only sometimes accounts for how AI and users shape one another. In this survey paper, we discuss the development of formal interaction models which mathematically specify how AI and users shape one another. Formal interaction models can be leveraged to (1) specify interactions for implementation, (2) monitor interactions through empirical analysis, (3) anticipate societal impacts via counterfactual analysis, and (4) control societal impacts via interventions. The design space of formal interaction models is vast, and model design requires careful consideration of factors such as style, granularity, mathematical complexity, and measurability. Using content recommender systems as a case study, we critically examine the nascent literature of formal interaction models with respect to these use-cases and design axes. More broadly, we call for the community to leverage formal interaction models when designing, evaluating, or auditing any AI system which interacts with users",
    "checked": true,
    "id": "4a3510a89ce625dda4e38dbf64bf00b235e4df81",
    "semantic_title": "accounting for ai and users shaping one another: the role of mathematical models",
    "citation_count": 8,
    "authors": [
      "Sarah Dean",
      "Evan Dong",
      "Meena Jagadeesan",
      "Liu Leqi"
    ]
  },
  "https://openreview.net/forum?id=mNXCViKZbI": {
    "title": "UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs",
    "volume": "main",
    "abstract": "The key components of machine learning are data samples for training, model for learning patterns, and loss function for optimizing accuracy. Analogously, unlearning can potentially be achieved through anti-data-samples (or anti-samples), unlearning method, and reversed loss function. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. Although token based anti-samples have been previously introduced (Eldan & Russinovich (2023)), the use of reasoning-driven anti-samples—constructed with falsified answers and misleading rationales—remains unexplored. In this paper, we introduce UnStar: Unlearning with SelfTaught Anti-Sample Reasoning for large language models (LLMs). Our contributions are threefold: first, we propose a novel concept of reasoning-based anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge—something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification",
    "checked": true,
    "id": "764bc549261f09457992b109789d167c5a77eb20",
    "semantic_title": "unstar: unlearning with self-taught anti-sample reasoning for llms",
    "citation_count": 7,
    "authors": [
      "Yash Sinha",
      "Murari Mandal",
      "Mohan Kankanhalli"
    ]
  },
  "https://openreview.net/forum?id=VtSIjrpFwA": {
    "title": "Modularity aided consistent attributed graph clustering via coarsening",
    "volume": "main",
    "abstract": "Graph clustering is an unsupervised learning technique for partitioning graphs with attributes and detecting communities. However, current methods struggle to accurately capture true community structures and intra-cluster relations, be computationally efficient, and identify smaller communities. We address these challenges by integrating coarsening and modularity maximization, effectively leveraging both adjacency and node features to enhance clustering accuracy. We propose a loss function incorporating log-determinant, smoothness, and modularity components using a block majorization-minimization technique, resulting in superior clustering outcomes. The method is theoretically consistent under the Degree-Corrected Stochastic Block Model (DC-SBM), ensuring asymptotic error-free performance and complete label recovery. Our provably convergent and time-efficient algorithm seamlessly integrates with Graph Neural Networks (GNNs) and Variational Graph AutoEncoders (VGAEs) to learn enhanced node features and deliver exceptional clustering performance. Extensive experiments on benchmark datasets demonstrate its superiority over existing state-of-the-art methods for both attributed and non-attributed graphs",
    "checked": true,
    "id": "18e80ab5bd3b01e9ad3ed982f52c8f45afeaa1d6",
    "semantic_title": "modularity aided consistent attributed graph clustering via coarsening",
    "citation_count": 0,
    "authors": [
      "Yukti Makhija",
      "Samarth Bhatia",
      "Manoj Kumar",
      "Sandeep Kumar"
    ]
  },
  "https://openreview.net/forum?id=jxdnFIsjCb": {
    "title": "Unifying Generative and Dense Retrieval for Sequential Recommendation",
    "volume": "main",
    "abstract": "Sequential dense retrieval models utilize advanced sequence learning techniques to compute item and user representations, which are then used to rank relevant items for a user through inner product computation between the user and all item representations. While effective, these approaches incur high memory and computational costs due to the need to store and compare a unique embedding for each item--leading to lower resource efficiency. In contrast, the recently proposed generative retrieval paradigm offers a promising alternative by directly predicting item indices using a generative model trained on semantic IDs that encapsulate items' semantic information. Despite its potential for large-scale applications, a comprehensive comparison between generative retrieval and sequential dense retrieval under fair conditions is still lacking, leaving open questions regarding performance and resource efficiency trade-offs. To address this, we compare these two approaches under controlled conditions on academic benchmarks and observe performance gaps, with dense retrieval showing stronger ranking performance, while generative retrieval provides greater resource efficiency. Motivated by these observations, we propose LIGER (LeveragIng dense retrieval for GEnerative Retrieval), a hybrid model that combines the strengths of these two widely used approaches. LIGER integrates sequential dense retrieval into generative retrieval, mitigating performance differences between the two methods, and enhancing cold-start item recommendation in the evaluated datasets. This hybrid approach provides insight into the trade-offs between these approaches and demonstrates improvements in efficiency and effectiveness for recommendation systems in small-scale benchmarks",
    "checked": true,
    "id": "d34df5d9d9e84c3525c0c4023289eb43bd49f13c",
    "semantic_title": "unifying generative and dense retrieval for sequential recommendation",
    "citation_count": 6,
    "authors": [
      "Liu Yang",
      "Fabian Paischer",
      "Kaveh Hassani",
      "Jiacheng Li",
      "Shuai Shao",
      "Zhang Gabriel Li",
      "Yun He",
      "Xue Feng",
      "Nima Noorshams",
      "Sem Park",
      "Bo Long",
      "Robert D Nowak",
      "Xiaoli Gao",
      "Hamid Eghbalzadeh"
    ]
  },
  "https://openreview.net/forum?id=pSyUfV5BqA": {
    "title": "InkSight: Offline-to-Online Handwriting Conversion by Teaching Vision-Language Models to Read and Write",
    "volume": "main",
    "abstract": "Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in a vectorized form, known as digital ink. However, a substantial gap remains between this way of note-taking and traditional pen-and-paper note-taking, a practice that is still favored by a vast majority. Our work InkSight, aims to bridge the gap by empowering physical note-takers to effortlessly convert their work (offline handwriting) to digital ink (online handwriting), a process we refer to as derendering. Prior research on the topic has focused on the geometric properties of images, resulting in limited generalization beyond their training domains. Our approach combines reading and writing priors, allowing training a model in the absence of large amounts of paired samples, which are difficult to obtain. To our knowledge, this is the first work that effectively derenders handwritten text in arbitrary photos with diverse visual characteristics and backgrounds. Furthermore, it generalizes beyond its training domain into simple sketches. Our human evaluation reveals that 87% of the samples produced by our model on the challenging HierText dataset are considered as a valid tracing of the input image and 67% look like a pen trajectory traced by a human",
    "checked": true,
    "id": "1eb3b6d34cc439f261df4658f0d11fe9dd45f036",
    "semantic_title": "inksight: offline-to-online handwriting conversion by teaching vision-language models to read and write",
    "citation_count": 0,
    "authors": [
      "Blagoj Mitrevski",
      "Arina Rak",
      "Julian Schnitzler",
      "Chengkun Li",
      "Andrii Maksai",
      "Jesse Berent",
      "Claudiu Cristian Musat"
    ]
  },
  "https://openreview.net/forum?id=2eTsZBoU2W": {
    "title": "Interpretable LLM-based Table Question Answering",
    "volume": "main",
    "abstract": "Interpretability in Table Question Answering (Table QA) is critical, especially in high-stakes domains like finance and healthcare. While recent Table QA approaches based on Large Language Models (LLMs) achieve high accuracy, they often produce ambiguous explanations of how answers are derived. We propose Plan-of-SQLs (POS), a new Table QA method that makes the model's decision-making process interpretable. POS decomposes a question into a sequence of atomic steps, each directly translated into an executable SQL command on the table, thereby ensuring that every intermediate result is transparent. Through extensive experiments, we show that: First, POS generates the highest-quality explanations among compared methods, which markedly improves the users' ability to simulate and verify the model's decisions. Second, when evaluated on standard Table QA benchmarks (TabFact, WikiTQ, and FeTaQA), POS achieves QA accuracy that is competitive to existing methods, while also offering greater efficiency—requiring significantly fewer LLM calls and table database queries (up to 25x fewer)—and more robust performance on large-sized tables. Finally, we observe high agreement (up to 90.59% in forward simulation) between LLMs and human users when making decisions based on the same explanations, suggesting that LLMs could serve as an effective proxy for humans in evaluating Table QA explanations",
    "checked": true,
    "id": "fbcc06f1112861585bdc7f0a41b9865831022623",
    "semantic_title": "interpretable llm-based table question answering",
    "citation_count": 4,
    "authors": [
      "Giang Nguyen",
      "Ivan Brugere",
      "Shubham Sharma",
      "Sanjay Kariyappa",
      "Anh Totti Nguyen",
      "Freddy Lecue"
    ]
  },
  "https://openreview.net/forum?id=552tedTByb": {
    "title": "Disentangled Embedding through Style and Mutual Information for Domain Generalization",
    "volume": "main",
    "abstract": "Deep neural networks often experience performance degradation when faced with distributional shifts between training and testing data, a challenge referred to as domain shift. Domain Generalization (DG) addresses this issue by training models on multiple source domains, enabling the development of invariant representations that generalize to unseen distributions. While existing DG methods have achieved success by minimizing variations across source domains within a shared feature space, recent advances inspired by representation disentanglement have demonstrated improved performance by separating latent features into domain-specific and domain-invariant components. We propose two novel frameworks: Disentangled Embedding through Mutual Information (DETMI) and Disentangled Embedding through Style Information (DETSI). DETMI enforces disentanglement by employing a mutual information estimator, minimizing the mutual dependence between domain-agnostic and domain-specific embeddings. DETSI, on the other hand, achieves disentanglement through style extraction and perturbation, facilitating the learning of domain-invariant and domain-specific representations. Extensive experiments on the PACS, Office-Home, and VLCS datasets show that both frameworks outperform several state-of-the-art DG techniques",
    "checked": false,
    "id": "7504532c982906fefd684be85427728946f027e1",
    "semantic_title": "disentangled style domain for implicit z-watermark towards copyright protection",
    "citation_count": 3,
    "authors": [
      "Noaman Mehmood",
      "Kenneth Barner"
    ]
  },
  "https://openreview.net/forum?id=ul4W26KEKz": {
    "title": "Mixture of Cache-Conditional Experts for Efficient Mobile Device Inference",
    "volume": "main",
    "abstract": "Mixture of Experts (MoE) LLMs enhance performance by selectively activating specialized subnetworks (\"experts\") per input. While MoEs offer efficiency benefits through distributed inference in typical high-throughput settings, deploying them on memory-constrained devices remains challenging, particularly for sequential token generation with batch size one. In this work, we optimize MoE for such constrained environments, where only a subset of expert weights fit into DRAM. Through empirical analysis, we show MoEs can tolerate careful deviations in expert selection with minimal predictive performance loss. Inspired by this observation, we propose a novel cache-aware routing strategy that leverages expert reuse during token generation to significantly improve cache locality. Evaluating on language modeling, MMLU, and GSM8K benchmarks, our method reduces cache miss rates by over 50%, with negligible impact on perplexity (0.1%–3%) and downstream task accuracy (<0.1%). Unlike prior methods limited by the optimal oracle cache bound, our approach surpasses this theoretical limit by allowing slight flexibility in expert selection. Finally, we present on-device results demonstrating 2$\\times$ speedups on mobile hardware, offering a flexible and training-free solution to extend MoE's applicability across real-world applications",
    "checked": true,
    "id": "0790f66f56948017b66b4ee10279e35d641d9ba9",
    "semantic_title": "mixture of cache-conditional experts for efficient mobile device inference",
    "citation_count": 2,
    "authors": [
      "Andrii Skliar",
      "Ties van Rozendaal",
      "Romain Lepert",
      "Todor Boinovski",
      "Mart Van Baalen",
      "Markus Nagel",
      "Paul N. Whatmough",
      "Babak Ehteshami Bejnordi"
    ]
  },
  "https://openreview.net/forum?id=cSxDH7N3x9": {
    "title": "Entropy-Regularized Process Reward Model",
    "volume": "main",
    "abstract": "Large language models (LLMs) have shown promise in performing complex multi-step reasoning, yet they continue to struggle with mathematical reasoning, often making systematic errors. A promising solution is reinforcement learning (RL) guided by reward models, particularly those focusing on process rewards, which score each intermediate step rather than solely evaluating the final outcome. This approach is more effective at guiding policy models towards correct reasoning trajectories. In this work, we propose an entropy-regularized process reward model (ER-PRM) that integrates KL-regularized Markov Decision Processes (MDP) to balance policy optimization with the need to prevent the policy from shifting too far from its initial distribution. We derive a novel reward construction method based on the theoretical results. Our theoretical analysis shows that we could derive the optimal reward model from the initial policy sampling. Our empirical experiments on the MATH and GSM8K benchmarks demonstrate that ER-PRM consistently outperforms existing process reward models, achieving 1% improvement on GSM8K and 2-3% improvement on MATH under best-of-N evaluation, and more than 1% improvement under RLHF. These results highlight the efficacy of entropy-regularization in enhancing LLMs' reasoning capabilities",
    "checked": true,
    "id": "7a3b3ddf7303f6c59544d00757b60531c71be71c",
    "semantic_title": "entropy-regularized process reward model",
    "citation_count": 7,
    "authors": [
      "Hanning Zhang",
      "Pengcheng Wang",
      "Shizhe Diao",
      "Yong Lin",
      "Rui Pan",
      "Hanze Dong",
      "Dylan Zhang",
      "Pavlo Molchanov",
      "Tong Zhang"
    ]
  },
  "https://openreview.net/forum?id=YNKaDfYbY3": {
    "title": "Influential Bandits: Pulling an Arm May Change the Environment",
    "volume": "main",
    "abstract": "While classical formulations of multi-armed bandit problems assume that each arm's reward is independent and stationary, real-world applications often involve non-stationary environments and interdependencies between arms. In particular, selecting one arm may influence the future rewards of other arms, a scenario not adequately captured by existing models such as rotting bandits or restless bandits. To address this limitation, we propose the influential bandit problem, which models inter-arm interactions through an unknown, symmetric, positive semi-definite interaction matrix that governs the dynamics of arm losses. We formally define this problem and establish two regret lower bounds, including a superlinear $\\Omega(T^2 / \\log^2 T)$ bound for the standard LCB algorithm (loss minimization version of UCB) and an algorithm-independent $\\Omega(T)$ bound, which highlight the inherent difficulty of the setting. We then introduce a new algorithm based on a lower confidence bound (LCB) estimator tailored to the structure of the loss dynamics. Under mild assumptions, our algorithm achieves a regret of $O(KT \\log T)$, which is nearly optimal in terms of its dependence on the time horizon. The algorithm is simple to implement and computationally efficient. Empirical evaluations on both synthetic and real-world datasets demonstrate the presence of inter-arm influence and confirm the superior performance of our method compared to conventional bandit algorithms",
    "checked": true,
    "id": "6c246d3757b8ef859042c83d36036ef821566f63",
    "semantic_title": "influential bandits: pulling an arm may change the environment",
    "citation_count": 0,
    "authors": [
      "Ryoma Sato",
      "Shinji Ito"
    ]
  },
  "https://openreview.net/forum?id=cjK5ZvP4zZ": {
    "title": "Directed Exploration in Reinforcement Learning from Linear Temporal Logic",
    "volume": "main",
    "abstract": "Linear temporal logic (LTL) is a powerful language for task specification in reinforcement learning, as it allows describing objectives beyond the expressivity of conventional discounted return formulations. Nonetheless, recent works have shown that LTL formulas can be translated into a variable rewarding and discounting scheme, whose optimization produces a policy maximizing a lower bound on the probability of formula satisfaction. However, the synthesized reward signal remains fundamentally sparse, making exploration challenging. We aim to overcome this limitation, which can prevent current algorithms from scaling beyond low-dimensional, short-horizon problems. We show how better exploration can be achieved by further leveraging the LTL specification and casting its corresponding Limit Deterministic Büchi Automaton (LDBA) as a Markov reward process, thus enabling a form of high-level value estimation. By taking a Bayesian perspective over LDBA dynamics and proposing a suitable prior distribution, we show that the values estimated through this procedure can be treated as a shaping potential and mapped to informative intrinsic rewards. Empirically, we demonstrate applications of our method from tabular settings to high-dimensional continuous systems, which have so far represented a significant challenge for LTL-based reinforcement learning algorithms",
    "checked": true,
    "id": "46b6a615baf77306611f77ecf6dfe35d611eab59",
    "semantic_title": "directed exploration in reinforcement learning from linear temporal logic",
    "citation_count": 1,
    "authors": [
      "Marco Bagatella",
      "Andreas Krause",
      "Georg Martius"
    ]
  },
  "https://openreview.net/forum?id=lbrO3bGpeO": {
    "title": "EMMA: Efficient Visual Alignment in Multi-Modal LLMs",
    "volume": "main",
    "abstract": "Multi-modal Large Language Models (MLLMs) have recently exhibited impressive general- purpose capabilities by leveraging vision foundation models to encode the core concepts of images into representations. These are then combined with instructions and processed by the language model to generate high-quality responses. Despite significant progress in enhancing the language component, challenges persist in optimally fusing visual encodings within the language model for task-specific adaptability. Recent research has focused on improving this fusion through modality adaptation modules but at the cost of significantly increased model complexity and training data needs. In this paper, we propose EMMA (Efficient Multi-Modal Adaptation), a lightweight cross-modality module designed to efficiently fuse visual and textual encodings, generating instruction-aware visual representations for the language model. Our key contributions include: (1) an efficient early fusion mechanism that integrates vision and language representations with minimal added parameters (less than 0.2% increase in model size), (2) an in-depth interpretability analysis that sheds light on the internal mechanisms of the proposed method; (3) comprehensive experiments that demonstrate notable improvements on both specialized and general benchmarks for MLLMs. Empirical results show that EMMA boosts performance across multiple tasks by up to 9.3% while significantly improving robustness against hallucinations",
    "checked": true,
    "id": "03517a24b006e0796ebff02b25f0b90cd5a574b5",
    "semantic_title": "emma: efficient visual alignment in multi-modal llms",
    "citation_count": 2,
    "authors": [
      "Sara Ghazanfari",
      "Alexandre Araujo",
      "Prashanth Krishnamurthy",
      "Siddharth Garg",
      "Farshad Khorrami"
    ]
  },
  "https://openreview.net/forum?id=pT8sgtRVAf": {
    "title": "Scaling Channel-Adaptive Self-Supervised Learning",
    "volume": "main",
    "abstract": "Recent advances in self-supervised pre-training of foundation models for natural images have made them a popular choice for various visual systems and applications. Self-supervised strategies are also promising in non-RGB scientific imaging domains such as in biology, medical and satellite imagery, but their broader application is hampered by heterogeneity in channel composition and semantics between relevant datasets: two datasets may contain different numbers of channels, and these may reveal distinct aspects of an object or scene. Recent works on channel adaptive strategies report substantial advantages for those that account for variable channel compositions without sacrificing the ability to jointly encode channels; yet, how these strategies behave at scale remains unclear. We here show that, surprisingly, trained across large-scale datasets, independent-encoding of channels outperforms joint-encoding methods by a substantial margin. We validate this result along an extensive set of experiments on various datasets from cell microscopy to geospatial imagery. Our DINO BoC approach sets a new state-of-the-art across challenging benchmarks, including generalization to out-of-distribution tasks and unseen channel combinations at test time. We will open source the code, along with model weights that constitute a new general purpose feature extractor for fluorescent microscopy",
    "checked": true,
    "id": "808e5ffcf19771db45f61594edf6f5d017295b41",
    "semantic_title": "scaling channel-adaptive self-supervised learning",
    "citation_count": 0,
    "authors": [
      "Alice V. De Lorenci",
      "Seung Eun Yi",
      "Théo Moutakanni",
      "Piotr Bojanowski",
      "Camille Couprie",
      "Juan C. Caicedo",
      "Wolfgang Maximilian Anton Pernice"
    ]
  },
  "https://openreview.net/forum?id=fywo0eRzAu": {
    "title": "Seeing Beyond Labels: Source-Free Domain Adaptation via Hypothesis Consolidation of Prediction Rationale",
    "volume": "main",
    "abstract": "Source-Free Unsupervised Domain Adaptation (SFUDA) is a challenging task where a model needs to be adapted to a new domain without access to target domain labels or source domain data. The primary difficulty in this task is that the model's predictions may be inaccurate, and using these inaccurate predictions for model adaptation can lead to misleading results. To address this issue, this paper proposes a novel approach that considers multiple prediction hypotheses for each sample and investigates the rationale behind each hypothesis. By consolidating these hypothesis rationales, we identify the most likely correct hypotheses, which we then use as a pseudo-labeled set to support a semi-supervised learning procedure for model adaptation. This approach distinguishes itself from conventional semi-supervised learning by relying solely on pseudo-labels rather than ground-truth annotations. To achieve the optimal performance, we propose a three-step adaptation process: model pre-adaptation, hypothesis consolidation, and semi-supervised learning. Extensive experimental results demonstrate that our approach achieves state-of-the-art performance in the SFUDA task and can be easily integrated into existing approaches to improve their performance. The codes are available at \\url{https://github.com/GANPerf/HCPR}",
    "checked": true,
    "id": "e55718e3bc55f7f9dde19b4eb95fab6586005011",
    "semantic_title": "seeing beyond labels: source-free domain adaptation via hypothesis consolidation of prediction rationale",
    "citation_count": 0,
    "authors": [
      "Yangyang Shu",
      "Yuhang Liu",
      "Xiaofeng Cao",
      "Qi Chen",
      "Bowen Zhang",
      "Ziqin Zhou",
      "Anton van den Hengel",
      "Lingqiao Liu"
    ]
  },
  "https://openreview.net/forum?id=a0mLrqkWyx": {
    "title": "Gradient Inversion Attack on Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph federated learning is of essential importance for training over large graph datasets while protecting data privacy, where each client stores a subset of local graph data, while the server collects the local gradients and broadcasts only the aggregated gradients. Recent studies reveal that a malicious attacker can steal private image data from the gradient exchange of neural networks during federated learning. However, the vulnerability of graph data and graph neural networks under such attacks, i.e., reconstructing both node features and graph structure from gradients, remains largely underexplored. To answer this question, this paper studies the problem of whether private data can be reconstructed from leaked gradients in both node classification and graph classification tasks and proposes a novel attack named Graph Leakage from Gradients (GLG). Two widely used GNN frameworks are analyzed, namely GCN and GraphSAGE. The effects of different model settings on reconstruction are extensively discussed. Theoretical analysis and empirical validation demonstrate that, by leveraging the unique properties of graph data and GNNs, GLG achieves more accurate reconstruction of both nodal features and graph structure from gradients",
    "checked": true,
    "id": "ac4467cad450e7315bd40907fb3330eb20eb655b",
    "semantic_title": "gradient inversion attack on graph neural networks",
    "citation_count": 0,
    "authors": [
      "Divya Anand Sinha",
      "Yezi Liu",
      "Ruijie Du",
      "Athina Markopoulou",
      "Yanning Shen"
    ]
  },
  "https://openreview.net/forum?id=Q9AkJpfJks": {
    "title": "Theoretical Learning Performance of Graph Networks: the Impact of Jumping Connections and Layer-wise Sparsification",
    "volume": "main",
    "abstract": "Jumping connections enable Graph Convolutional Networks (GCNs) to overcome over-smoothing, while graph sparsification reduces computational demands by selecting a submatrix of the graph adjacency matrix during neighborhood aggregation. Learning GCNs with graph sparsification has shown empirical success across various applications, but a theoretical understanding of the generalization guarantees remains limited, with existing analyses ignoring either graph sparsification or jumping connections. This paper presents the first learning dynamics and generalization analysis of GCNs with jumping connections using graph sparsification. Our analysis demonstrates that the generalization accuracy of the learned model closely approximates the highest achievable accuracy within a broad class of target functions dependent on the proposed sparse effective adjacency matrix $A^*$. Thus, graph sparsification maintains generalization performance when $A^*$ accurately models data correlations. We reveal that jumping connections lead to different sparsification requirements across layers. In a two-hidden-layer GCN, the generalization is more affected by the sparsified matrix deviations from $A^*$ of the first layer than the second layer. To the best of our knowledge, this marks the first theoretical characterization of jumping connections' role in sparsification requirements. We validate our theoretical results on benchmark datasets in deep GCNs",
    "checked": true,
    "id": "6e2d1ce23c54a079fea2ff869c133b98d2cb545d",
    "semantic_title": "theoretical learning performance of graph networks: the impact of jumping connections and layer-wise sparsification",
    "citation_count": 0,
    "authors": [
      "Jiawei Sun",
      "Hongkang Li",
      "Meng Wang"
    ]
  },
  "https://openreview.net/forum?id=15keyzQj9h": {
    "title": "On the Generalizability of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals",
    "volume": "main",
    "abstract": "We present a reproduction study of \"Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals\" (Ortu et al., 2024), which investigates competition of mechanisms in language models between factual recall and counterfactual in-context repetition. Our study successfully reproduces their primary findings regarding the localization of factual and counterfactual information, the dominance of attention blocks in mechanism competition, and the specialization of attention heads in handling competing information. We reproduce their results on both GPT-2 (Radford et al., 2019) and Pythia 6.9B (Biderman et al., 2023). We extend their work in three significant directions. First, we explore the generalizability of these findings to even larger models by replicating the experiments on Llama 3.1 8B (Grattafiori et al., 2024), discovering greatly reduced attention head specialization. Second, we investigate the impact of prompt structure by introducing variations where we avoid repeating the counterfactual statement verbatim or we change the premise word, observing a marked decrease in the logit for the counterfactual token. Finally, we test the validity of the authors' claims for prompts of specific domains, discovering that certain categories of prompts skew the results by providing the factual prediction token as part of the subject of the sentence. Overall, we find that the attention head ablation proposed in Ortu et al. (2024) is ineffective for domains that are underrepresented in their dataset, and that the effectiveness varies based on model architecture, prompt structure, domain and task",
    "checked": true,
    "id": "cb8a34538460efdddd5f03e6cd211dfa272f8fb6",
    "semantic_title": "on the generalizability of \"competition of mechanisms: tracing how language models handle facts and counterfactuals",
    "citation_count": 0,
    "authors": [
      "Asen Dotsinski",
      "Udit Thakur",
      "Marko Ivanov",
      "Mohammad Hafeez Khan",
      "Maria Heuss"
    ]
  },
  "https://openreview.net/forum?id=5L90cl0xtf": {
    "title": "Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models",
    "volume": "main",
    "abstract": "Large Vision-Language Models (VLMs) have revolutionized computer vision, enabling tasks such as image classification, captioning, and visual question answering. However, they re- main highly vulnerable to adversarial attacks, particularly in scenarios where both visual and textual modalities can be manipulated. In this study, we conduct a comprehensive reproducibility study of \"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on Vision-Language Models\" validating the Cross-Prompt Attack (CroPA) and confirming its superior cross-prompt transferability compared to existing baselines. Be- yond replication we propose several key improvements: (1) A novel initialization strategy that significantly improves Attack Success Rate (ASR). (2) Investigate cross-image trans- ferability by learning universal perturbations. (3) A novel loss function targeting vision encoder attention mechanisms to improve generalization. Our evaluation across prominent VLMs—including Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on LLaVA validates the original results and demonstrates that our improvements consistently boost adversarial effectiveness. Our work reinforces the importance of studying adversarial vulnerabilities in VLMs and provides a more robust framework for generating transferable adversarial examples, with significant implications for understanding the security of VLMs in real-world applications",
    "checked": true,
    "id": "f0f4b80f173c1f4acc2fd641b61a81669533b416",
    "semantic_title": "revisiting cropa: a reproducibility study and enhancements for cross-prompt adversarial transferability in vision-language models",
    "citation_count": 0,
    "authors": [
      "Atharv Mittal",
      "Agam Pandey",
      "Amritanshu Tiwari",
      "Sukrit Jindal",
      "Swadesh Swain"
    ]
  },
  "https://openreview.net/forum?id=0CY5APFnFI": {
    "title": "Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) are notoriously vulnerable to adversarial input designs with limited noise budgets. While numerous successful attacks with subtle modifications to original input have been proposed, defense techniques against these attacks are relatively understudied. Existing defense approaches either focus on improving DNN robustness by negating the effects of perturbations or use a secondary model to detect adversarial data. Although equally important, the attack detection approach, which is studied in this work, provides a more practical defense compared to the robustness approach. We show that the existing detection methods are either ineffective against the state-of-the-art attack techniques or computationally inefficient for real-time processing. We propose a novel universal and efficient method to detect adversarial examples by analyzing the varying degrees of impact of attacks on different DNN layers. Our method trains a lightweight regression model that predicts deeper-layer features from early-layer features, and uses the prediction error to detect adversarial samples. Through theoretical arguments and extensive experiments, we demonstrate that our detection method is highly effective, computationally efficient for real-time processing, compatible with any DNN architecture, and applicable across different domains, such as image, video, and audio",
    "checked": true,
    "id": "41f5f1f8e72024d30278ad863f92b2627a8fa5bf",
    "semantic_title": "universal and efficient detection of adversarial data through nonuniform impact on network layers",
    "citation_count": 0,
    "authors": [
      "Furkan Mumcu",
      "Yasin Yilmaz"
    ]
  },
  "https://openreview.net/forum?id=ABT1XQLbOx": {
    "title": "Regularized Gradient Clipping Provably Trains Wide and Deep Neural Networks",
    "volume": "main",
    "abstract": "We present and analyze a novel regularized form of the gradient clipping algorithm, proving that it converges to global minima of the loss surface of deep neural networks under the squared loss, provided that the layers are of sufficient width. The algorithm presented here, dubbed $\\delta-$GClip, introduces a modification to gradient clipping that leads to a first-of-its-kind example of a step size scheduling for gradient descent that provably minimizes training losses of deep neural nets. We also present empirical evidence that our theoretically founded $\\delta-$GClip algorithm is competitive with the state-of-the-art deep learning heuristics on various neural architectures including modern transformer based architectures. The modification we do to standard gradient clipping is designed to leverage the PL* condition, a variant of the Polyak-Łojasiewicz inequality which was recently proven to be true for sufficiently wide neural networks at any depth within a neighbourhood of the initialization",
    "checked": true,
    "id": "757b1c8aa2b9b5fc586e313db53f519c8e8d6671",
    "semantic_title": "regularized gradient clipping provably trains wide and deep neural networks",
    "citation_count": 1,
    "authors": [
      "Matteo Tucat",
      "Anirbit Mukherjee",
      "Mingfei Sun",
      "Procheta Sen",
      "Omar Rivasplata"
    ]
  },
  "https://openreview.net/forum?id=t5WzHOniAF": {
    "title": "Enhancing Molecular Conformer Generation via Fragment- Augmented Diffusion Pretraining",
    "volume": "main",
    "abstract": "Recent advances in diffusion-based methods have shown promising results for molecular conformer generation, yet their performance remains constrained by training data scarcity---particularly for structurally complex molecules. In this work, we present Fragment-Augmented Diffusion (FragDiff), a data-centric augmentation strategy that incorporates chemical fragmentation techniques into the pre-training phase of modern diffusion-based generative models. Our key innovation lies in decomposing molecules into chemically meaningful fragments that serve as building blocks for systematic data augmentation, enabling the diffusion model to learn enhanced local geometry while maintaining global molecular topology. Unlike existing approaches that focus on complex architectural modifications, FragDiff adopts a data-centric paradigm orthogonal to model design. Comprehensive benchmarks show FragDiff's superior performance, especially in data-scarce scenarios. Notably, it achieves 12.2--13.4% performance improvement on molecules 3$\\times$ beyond training scale through pretraining on fragments. Overall, we establish a new paradigm integrating chemical fragmentations with diffusion models, advancing computational chemistry workflows. The code is available at https://github.com/ShawnKS/fragdiff",
    "checked": false,
    "id": "8b967982e5ac942bc0ec4868b227cd86e01f4e04",
    "semantic_title": "hybridlinker: topology-guided posterior sampling for enhanced diversity and validity in 3d molecular linker generation",
    "citation_count": 2,
    "authors": [
      "Xiaozhuang Song",
      "YUZHAO TU",
      "Tianshu Yu"
    ]
  },
  "https://openreview.net/forum?id=II9agMKTb1": {
    "title": "Beyond Parameter Count: Implicit Bias in Soft Mixture of Experts",
    "volume": "main",
    "abstract": "The traditional viewpoint on Sparse Mixture of Experts (MoE) models is that instead of training a single _large_ expert, which is computationally expensive, we can train many _small_ experts. The hope is that if the total parameter count of the small experts equals that of the singular large expert, then we retain the representation power of the large expert while gaining computational tractability and promoting expert specialization. The recently introduced Soft MoE replaces the Sparse MoE's discrete routing mechanism with a differentiable gating function that smoothly mixes tokens. While this smooth gating function successfully mitigates the various training instabilities associated with Sparse MoE, it is unclear whether it induces implicit biases that affect Soft MoE's representation power or potential for expert specialization. We prove that Soft MoE with a single arbitrarily powerful expert cannot represent simple convex functions. This justifies that Soft MoE's success cannot be explained by the traditional viewpoint of many small experts collectively mimicking the representation power of a single large expert, and that multiple experts are actually _necessary_ to achieve good representation power (even for a fixed total parameter count). Continuing along this line of investigation, we introduce a notion of expert specialization for Soft MoE, and while varying the number of experts yet fixing the total parameter count, we consider the following (computationally intractable) task. Given any input, how can we discover the expert subset that is specialized to predict this input's label? We empirically show that when there are many small experts, the architecture is implicitly biased in a fashion that allows us to efficiently approximate the specialized expert subset. Our method can be easily implemented to potentially reduce computation during inference. For example, using our method on ImageNet, one can perform inference using only $1/8$ of the experts and still retain $99$% of the test accuracy of using all experts",
    "checked": true,
    "id": "a72ff8d324a0bd8c8d5b74427e15870f1e3cfe25",
    "semantic_title": "beyond parameter count: implicit bias in soft mixture of experts",
    "citation_count": 0,
    "authors": [
      "Youngseog Chung",
      "Dhruv Malik",
      "Jeff Schneider",
      "Yuanzhi Li",
      "Aarti Singh"
    ]
  },
  "https://openreview.net/forum?id=W22g6Ksmbi": {
    "title": "AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability in Algorithmic Environments",
    "volume": "main",
    "abstract": "This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol — for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves considering the possible environmental feedback in the future steps. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 14 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show much stronger sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing in-context examples may inadvertently hurt few-shot performance in an interactive environment due to over-fitting to examples. (3) Instead of using optimal steps from another test case as the in-context example, a very limited number of predecessor steps in the current test case following the optimal policy can substantially boost small models' performance. (4) The performance gap between weak models and strong models is greatly due to the incapability of weak models to start well. (5) The scaling correlation between performance and model size is not always significant, sometimes even showcasing an inverse trend. We hope our study can catalyze future work on advancing the understanding and enhancement of LLMs' capabilities in sequential reasoning",
    "checked": true,
    "id": "b7cd1b6b89ff29b63a35d578899b7912195a4237",
    "semantic_title": "aqa-bench: an interactive benchmark for evaluating llms' sequential reasoning ability in algorithmic environments",
    "citation_count": 1,
    "authors": [
      "Siwei Yang",
      "Bingchen Zhao",
      "Cihang Xie"
    ]
  },
  "https://openreview.net/forum?id=R20kKdWmVZ": {
    "title": "ModernTCN Revisited: A Critical Look at the Experimental Setup in General Time Series Analysis",
    "volume": "main",
    "abstract": "While numerous time series models claim state-of-the-art performance, their evaluation often relies on flawed experimental setups, leading to questionable conclusions. This study provides a critical re-evaluation of this landscape, using ModernTCN as a case study. We conduct a rigorous and extended benchmark, correcting methodological issues related to data loading, validation, and evaluation methods, and show that performance claims are sensitive to these details. Additionally, we find that ModernTCN overlooks a line of research in global convolutional models, and our comparison reveals that despite claims of an enlarged effective receptive field (ERF), it falls short of these methods. More than a critique, we introduce an architectural innovation: by embedding irregularly sampled data with a continuous kernel convolution and processing it with the ModernTCN backbone, we achieve new state-of-the-art performance on the challenging PhysioNet 2019 dataset. This work not only provides a robust reassessment of ModernTCN but also serves as an audit of the commonly used general time series analysis experimental setup, which includes tasks such as forecasting, imputation, classification, and anomaly detection",
    "checked": true,
    "id": "8f4138dea805df632244267337d257a46099593a",
    "semantic_title": "moderntcn revisited: a critical look at the experimental setup in general time series analysis",
    "citation_count": 0,
    "authors": [
      "Önder Akacik",
      "Mark Hoogendoorn"
    ]
  },
  "https://openreview.net/forum?id=VqLe8tPbZn": {
    "title": "Synthesizing Minority Samples for Long-tailed Classification via Distribution Matching",
    "volume": "main",
    "abstract": "In many real-world applications, deep neural networks (DNNs) often perform poorly on datasets with long-tailed distributions. To address this issue, a promising approach is to propose an optimization objective to transform real majority samples into synthetic minority samples. However, this objective is designed only from the classification perspective. To this end, we propose a novel framework that synthesizes minority samples from the majority by considering both classification and distribution matching. Specifically, our method adjusts the distribution of synthetic minority samples to closely align with that of the true minority class, while enforcing the synthetic samples to learn more generalizable and discriminative features of the minority class. Experimental results on several standard benchmark datasets demonstrate the effectiveness of our method in both long-tailed classification and synthesizing high-quality synthetic minority samples",
    "checked": true,
    "id": "0f43f514441df2097971150738f525f1dfa93652",
    "semantic_title": "synthesizing minority samples for long-tailed classification via distribution matching",
    "citation_count": 0,
    "authors": [
      "Zhuo Li",
      "He Zhao",
      "Jinke Ren",
      "Anningzhe Gao",
      "Dandan Guo",
      "Xiang Wan",
      "Hongyuan Zha"
    ]
  },
  "https://openreview.net/forum?id=1PRBHKgQVM": {
    "title": "Cross-lingual Transfer in Programming Languages: An Extensive Empirical Study",
    "volume": "main",
    "abstract": "Large language models (LLMs) have achieved state-of-the-art performance in various software engineering tasks, including error detection, clone detection, and code translation, primarily leveraging high-resource programming languages like Python and Java. However, many critical languages, such as COBOL, as well as emerging languages, such as Rust and Swift, remain low-resource due to limited openly available code. This scarcity hampers the training and effectiveness of LLMs for these languages, increasing software maintenance costs and stifling innovation. Addressing this gap, we investigate the potential of transfer learning to enhance LLM performance on low-resource programming languages by leveraging data from high-resource counterparts. Our extensive empirical study evaluates transferability across 10 to 41 programming languages and five key tasks: code generation, clone detection, code repair, solution domain classification, and error detection. Additionally, we develop a performance prediction model to guess the best source languages for a given target and task, and analyze the features that influence transfer performance. We further replicate a representative subset of experiments with a larger model to test the generalizability of our conclusions to contemporary large‑scale LLMs. Our findings demonstrate that cross-lingual transfer significantly outperforms zero-shot learning, with effectiveness varying based on both source and target languages. Languages such as Java and Go emerge as the best targets, while Kotlin and JavaScript are excellent sources. Furthermore, our model reliably predicts successful transfer sources by considering linguistic and dataset-specific features, offering practical guidance for data acquisition and model training. This work contributes to the development of LLM-driven tools for low-resource programming languages and provides insights into the characteristics that facilitate transfer across language pairs",
    "checked": true,
    "id": "a5b58d50ba25ddaeaed71d2fc462cec9969f4b4d",
    "semantic_title": "cross-lingual transfer in programming languages: an extensive empirical study",
    "citation_count": 3,
    "authors": [
      "Razan Baltaji",
      "Saurabh Pujar",
      "Martin Hirzel",
      "Louis Mandel",
      "Luca Buratti",
      "Lav R. Varshney"
    ]
  },
  "https://openreview.net/forum?id=P02hoA7vln": {
    "title": "Neural varifolds: an aggregate representation for quantifying the geometry of point clouds",
    "volume": "main",
    "abstract": "Point clouds are popular 3D representations for real-life objects (such as in LiDAR and Kinect) due to their detailed and compact representation of surface-based geometry. Recent approaches characterise the geometry of point clouds by bringing deep learning based techniques together with geometric fidelity metrics such as optimal transportation costs (e.g., Chamfer and Wasserstein metrics). In this paper, we propose a new surface geometry characterisation within this realm, namely a neural varifold representation of point clouds. Here, the surface is represented as a measure/distribution over both point positions and tangent spaces of point clouds. The varifold representation quantifies not only the surface geometry of point clouds through the manifold-based representation, but also subtle geometric consistencies on the surface due to the combined product space. This study proposes neural varifold algorithms to compute the varifold norm between two point clouds using neural networks on point clouds and their neural tangent kernel representations. The proposed neural varifold is evaluated on three different sought-after tasks -- shape matching, few-shot shape classification, and shape reconstruction. Detailed evaluation and comparison to the state-of-the-art methods demonstrate that the proposed versatile neural varifold is superior in shape matching and few-shot shape classification, and is competitive for shape reconstruction",
    "checked": true,
    "id": "30547441c17c0c8972febacdb88b1af784939244",
    "semantic_title": "neural varifolds: an aggregate representation for quantifying the geometry of point clouds",
    "citation_count": 1,
    "authors": [
      "Juheon Lee",
      "Xiaohao Cai",
      "Carola-Bibiane Schönlieb",
      "Simon Masnou"
    ]
  },
  "https://openreview.net/forum?id=FO3IA4lUEY": {
    "title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey",
    "volume": "main",
    "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of these fields in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. Then, we highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection and related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude with open challenges and future directions. The resource is available at https://github.com/AtsuMiyai/Awesome-OOD-VLM",
    "checked": true,
    "id": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
    "semantic_title": "generalized out-of-distribution detection and beyond in vision language model era: a survey",
    "citation_count": 13,
    "authors": [
      "Atsuyuki Miyai",
      "Jingkang Yang",
      "Jingyang Zhang",
      "Yifei Ming",
      "Yueqian Lin",
      "Qing Yu",
      "Go Irie",
      "Shafiq Joty",
      "Yixuan Li",
      "Hai Helen Li",
      "Ziwei Liu",
      "Toshihiko Yamasaki",
      "Kiyoharu Aizawa"
    ]
  },
  "https://openreview.net/forum?id=XBL7xi5rt0": {
    "title": "GaussianFlow: Splatting Gaussian Dynamics for 4D Content Creation",
    "volume": "main",
    "abstract": "Creating 4D fields of Gaussian Splatting from images or videos is a challenging task due to its under-constrained nature. While the optimization can draw photometric reference from the input videos or be regulated by generative models, directly supervising Gaussian motions remains underexplored. In this paper, we introduce a novel concept, Gaussian flow, which connects the dynamics of 3D Gaussians and pixel velocities between consecutive frames. The Gaussian flow can be obtained efficiently by splatting Gaussian dynamics into the image space. This differentiable process enables direct dynamic supervision from optical flow. Our method significantly benefits 4D dynamic content generation and 4D novel view synthesis with Gaussian Splatting, especially for contents with rich motions that are hard to handle by existing methods. The common color drifting issue that occurs in 4D generation is also resolved with improved Guassian dynamics. Superior visual quality in extensive experiments demonstrates the effectiveness of our method. As shown in our evaluation, GaussianFlow can drastically improve both quantitative and qualitative results for 4D generation and 4D novel view synthesis",
    "checked": true,
    "id": "7c8336921d620d3ff5a21de33f9d2af59265235b",
    "semantic_title": "gaussianflow: splatting gaussian dynamics for 4d content creation",
    "citation_count": 55,
    "authors": [
      "Quankai Gao",
      "Qiangeng Xu",
      "Zhe Cao",
      "Ben Mildenhall",
      "Wenchao Ma",
      "Le Chen",
      "Danhang Tang",
      "Ulrich Neumann"
    ]
  },
  "https://openreview.net/forum?id=l5fXUKi8GO": {
    "title": "Reassessing Fairness: A Reproducibility Study of NIFA's Impact on GNN Models",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) have shown strong performance on graph-structured data but raise fairness concerns by amplifying existing biases. The Node Injection-based Fairness Attack (NIFA) (Luo et al., 2024) is a recently proposed gray-box attack that degrades group fairness while preserving predictive utility. In this study, we reproduce and evaluate NIFA across multiple datasets and GNN architectures. Our findings confirm that NIFA consistently degrades fairness—measured via Statistical Parity and Equal Opportunity—while maintaining utility on classical GNNs. However, claims of NIFA's superiority over existing fairness and utility attacks are only partially supported due to limitations in baseline reproducibility. We further extend NIFA to accommodate multi-class sensitive attributes and evaluate its behavior under varying levels of graph homophily. While NIFA remains effective in multi-class contexts, its impact is more sensitive in mixed and highly homophilic graphs. Although this is not a comprehensive validation of all NIFA claims, our work provides targeted insights into its reproducibility and generalizability across fairness-sensitive scenarios. The codebase is publicly available at: https://github.com/sjoerdgunneweg/Reassessing-NIFA",
    "checked": true,
    "id": "bb558f45fda803846f9bafe8a5ca9c7d795a2cb6",
    "semantic_title": "reassessing fairness: a reproducibility study of nifa's impact on gnn models",
    "citation_count": 0,
    "authors": [
      "Ruben Figge",
      "Sjoerd Gunneweg",
      "Aaron Kuin",
      "Mees Lindeman"
    ]
  },
  "https://openreview.net/forum?id=uMir8UIHST": {
    "title": "A Survey on Verifiable Cross-Silo Federated Learning",
    "volume": "main",
    "abstract": "Federated Learning (FL) is a widespread approach that allows training machine learning (ML) models with data distributed across multiple storage units. In cross-silo FL, which often appears in domains like healthcare or finance, the number of participants is moderate, and each party typically represents a well-known organization. For instance, in medicine data owners are often hospitals or data hubs which are well-established entities. However, malicious parties may still attempt to disturb the training procedure in order to obtain certain benefits, for example, a biased result or a reduction in computational load. While one can easily detect a malicious agent when data used for training is public, the problem becomes much more acute when it is necessary to maintain the privacy of the training dataset. To address this issue, there is recently growing interest in developing verifiable protocols, where one can check that parties do not deviate from the training procedure and perform computations correctly. In this paper, we present a survey on verifiable cross-silo FL. We analyze various protocols, fit them in a taxonomy, and compare their efficiency and threat models. We also analyze Zero-Knowledge Proof (ZKP) schemes and discuss how their overall cost in a FL context can be minimized. Lastly, we identify research gaps and discuss potential directions for future scientific work",
    "checked": true,
    "id": "e69443510dd93e63f3a7b7d4276c87534de15bc2",
    "semantic_title": "a survey on verifiable cross-silo federated learning",
    "citation_count": 0,
    "authors": [
      "Aleksei Korneev",
      "Jan Ramon"
    ]
  },
  "https://openreview.net/forum?id=BVH81SAAh2": {
    "title": "[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability and generalizability. We replicate the original experiments on additional models, and introduce additional metrics to verify negotiation quality and evenness of evaluation. Our findings reveal that while the benchmark is indeed complex, model comparison is ambiguous, raising questions about its objectivity. Furthermore, we identify limitations in the experimental setup, particularly in information leakage detection and thoroughness of the ablation study. By examining and analyzing the behavior of a wider range of models on an extended version of the benchmark, we reveal insights that provide additional context to potential users. Our results highlight the importance of context in model-comparative evaluations",
    "checked": true,
    "id": "df3175a6b1fa32e385095fbf3128629c5a2e79eb",
    "semantic_title": "[re] benchmarking llm capabilities in negotiation through scoreable games",
    "citation_count": 0,
    "authors": [
      "Jorge Carrasco Pollo",
      "Ioannis Kapetangeorgis",
      "Joshua Rosenthal",
      "John Hua Yao"
    ]
  },
  "https://openreview.net/forum?id=qgHq1NFUJk": {
    "title": "MagicPose4D: Crafting Articulated Models with Appearance and Motion Control",
    "volume": "main",
    "abstract": "With the success of 2D and 3D visual generative models, there is growing interest in generating 4D content. Existing methods primarily rely on text prompts to produce 4D content, but they often fall short of accurately defining complex or rare motions. To address this limitation, we propose MagicPose4D, a novel framework for refined control over both appearance and motion in 4D generation. Unlike current 4D generation methods, MagicPose4D accepts monocular videos or mesh sequences as motion prompts, enabling precise and customizable motion control. MagicPose4D comprises two key modules: (i) Dual-Phase 4D Reconstruction Module which operates in two phases. The first phase focuses on capturing the model's shape using accurate 2D supervision and less accurate but geometrically informative 3D pseudo-supervision without imposing skeleton constraints. The second phase extracts the 3D motion (skeleton poses) using more accurate pseudo-3D supervision, obtained in the first phase, and introduces kinematic chain-based skeleton constraints to ensure physical plausibility. Additionally, we propose a Global-local Chamfer loss that aligns the overall distribution of predicted mesh vertices with the supervision while maintaining part-level alignment without extra annotations. (ii) Cross-category Motion Transfer Module leverages the extracted motion from the 4D reconstruction module and uses a kinematic-chain-based skeleton to achieve cross-category motion transfer. It ensures smooth transitions between frames through dynamic rigidity, facilitating robust generalization without additional training. Through extensive experiments, we demonstrate that MagicPose4D significantly improves the accuracy and consistency of 4D content generation, outperforming existing methods in various benchmarks",
    "checked": true,
    "id": "9009075202066e9918078c9977b08f2fd5f1b6fb",
    "semantic_title": "magicpose4d: crafting articulated models with appearance and motion control",
    "citation_count": 8,
    "authors": [
      "Hao Zhang",
      "Di Chang",
      "Fang Li",
      "Mohammad Soleymani",
      "Narendra Ahuja"
    ]
  },
  "https://openreview.net/forum?id=vltzxxhzLU": {
    "title": "A reproducibility study of \"User-item fairness tradeoffs in recommendations",
    "volume": "main",
    "abstract": "Recommendation systems are necessary to filter the abundance of information presented in our everyday lives. A recommendation system could exclusively recommend items that users prefer the most, potentially resulting in certain items never getting recommended. Conversely, an exclusive focus on including all items could hurt overall recommendation quality. This gives rise to the challenge of balancing user and item fairness. The paper \"User-item fairness tradeoffs in recommendations\" by Greenwood et al. (2024) explores this tradeoff by developing a theoretical framework that optimizes for user-item fairness constraints. Their theoretical framework suggests that the cost of item fairness is low when users have varying preferences compared to each other, and may be high for users whose preferences are misestimated. They empirically measured these phenomena by creating their own recommendation system on arXiv preprints, and confirmed that the cost of item fairness is low when users have preferences that differ from one another. However, contrary to their theoretical expectations, misestimated users do not encounter a higher cost of item fairness. This study investigates the reproducibility of their research by replicating the empirical study. Additionally, we extend their research in two ways: (i) verifying the generalizability of their findings on a different dataset (Amazon books reviews), and (ii) analyzing the tradeoffs when recommending multiple items to a user instead of a single item. Our results further validate the claims made in the original paper. We concluded the claims hold true when recommending multiple items, with the cost of item fairness decreasing as more items are recommended",
    "checked": true,
    "id": "b1c62b5f592411e491086059f4531b4609f2454b",
    "semantic_title": "a reproducibility study of \"user-item fairness tradeoffs in recommendations",
    "citation_count": 0,
    "authors": [
      "Sander Honig",
      "Elyanne Oey",
      "Lisanne Wallaard",
      "Sharanda Suttorp",
      "Clara Rus"
    ]
  },
  "https://openreview.net/forum?id=jIAPLDdGVx": {
    "title": "Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks",
    "volume": "main",
    "abstract": "Generalization of machine learning models can be severely compromised by data poisoning, where adversarial changes are applied to the training data. This vulnerability has led to interest in certifying (i.e., proving) that such changes up to a certain magnitude do not affect test predictions. We, for the first time, certify Graph Neural Networks (GNNs) against poisoning attacks, including backdoors, targeting the node features of a given graph. Our certificates are white-box and based upon $(i)$ the neural tangent kernel, which characterizes the training dynamics of sufficiently wide networks; and $(ii)$ a novel reformulation of the bilevel optimization problem describing poisoning as a mixed-integer linear program. Consequently, we leverage our framework to provide fundamental insights into the role of graph structure and its connectivity on the worst-case robustness behavior of convolution-based and PageRank-based GNNs. We note that our framework is more general and constitutes the first approach to derive white-box poisoning certificates for NNs, which can be of independent interest beyond graph-related tasks",
    "checked": true,
    "id": "ef0f65831a690be5469f41fe78cd90f2e0184fd8",
    "semantic_title": "provable robustness of (graph) neural networks against data poisoning and backdoor attacks",
    "citation_count": 3,
    "authors": [
      "Lukas Gosch",
      "Mahalakshmi Sabanayagam",
      "Debarghya Ghoshdastidar",
      "Stephan Günnemann"
    ]
  },
  "https://openreview.net/forum?id=HiUZtgAPoH": {
    "title": "SynCode: LLM Generation with Grammar Augmentation",
    "volume": "main",
    "abstract": "LLMs are widely used in complex AI applications. These applications underscore the need for LLM outputs to adhere to a specific format, for their integration with other components in the systems. Typically the format rules – e.g., data serialization formats such as JSON, YAML, or Code in Programming Language – are expressed as context-free grammar (CFG). Due to the hallucinations and unreliability of LLMs, instructing LLMs to adhere to specified syntax becomes an increasingly important challenge. We present SynCode, a novel framework for efficient and general syntactical decoding with LLMs, to address this challenge. SynCode ensures soundness and completeness with respect to the CFG of a formal language, effectively retaining valid tokens while filtering out invalid ones. SynCode uses an offline-constructed, efficient lookup table, the DFA mask store, created from the DFA (Deterministic Finite Automaton) of the language's grammar for efficient generation. SynCode seamlessly integrates with any language defined by CFG, as evidenced by experiments focusing on generating JSON, SQL, Python, and Go outputs. Our experiments evaluating the effectiveness of SynCode for JSON generation demonstrate that SynCode eliminates all syntax errors and significantly outperforms state-of-the-art baselines. Furthermore, our results underscore how SynCode significantly reduces 96.07% of syntax errors in generated Python and Go code, showcasing its substantial impact on enhancing syntactical precision in LLM generation",
    "checked": true,
    "id": "46a41357eadac1459c81588136c5c053abfeefe4",
    "semantic_title": "syncode: llm generation with grammar augmentation",
    "citation_count": 16,
    "authors": [
      "Shubham Ugare",
      "Tarun Suresh",
      "Hangoo Kang",
      "Sasa Misailovic",
      "Gagandeep Singh"
    ]
  },
  "https://openreview.net/forum?id=8hAxEFRVQT": {
    "title": "Solving Multi-agent Path Finding as an LLM Benchmark: How, How Good and Why",
    "volume": "main",
    "abstract": "The rapid success of large language models (LLMs) has spurred extensive research into their ability to solve a wide range of tasks. However, their potential in multi-agent planning remains underexplored. Multi-agent planning presents unique challenges due to the combined complexity of coordination and long-horizon reasoning, often making it difficult to leverage external tools for assistance. In this paper, we introduce Multi-Agent Path Finding (MAPF), also known as multi-robot route planning, as a novel benchmark for evaluating the reasoning capabilities of LLMs. We first describe how the MAPF benchmark can be adapted for LLM-based evaluation, including dataset curation and an agentic workflow for LLMs. We show the motivating success of single-agent planning and multi-agent pathfinding in an empty room map without obstacles, then the failure to plan on the harder room map and maze map of the standard MAPF benchmark. We present our position on why directly solving MAPF with LLMs has not been successful yet, and we use various experiments to support our hypothesis. Based on our results, we discussed how researchers with different backgrounds could help with this problem from different perspectives",
    "checked": true,
    "id": "5e1e0cf1bb6c1c70149fcd88b0060ed881cc481e",
    "semantic_title": "solving multi-agent path finding as an llm benchmark: how, how good and why",
    "citation_count": 0,
    "authors": [
      "Weizhe Chen",
      "Sven Koenig",
      "Bistra Dilkina"
    ]
  },
  "https://openreview.net/forum?id=jVABSsD4Vf": {
    "title": "Towards Undistillable Models by Minimizing Conditional Mutual Information",
    "volume": "main",
    "abstract": "A deep neural network (DNN) is said to be undistillable if, when used as a black-box input- output teacher, it cannot be distilled through knowledge distillation (KD). In this case, the distilled student (referred to as the knockoff student) does not outperform a student trained independently with label smoothing (LS student) in terms of prediction accuracy. To protect intellectual property of DNNs, it is desirable to build undistillable DNNs. To this end, it is first observed that an undistillable DNN may have the trait that each cluster of its output probability distributions in response to all sample instances with the same label should be highly concentrated to the extent that each cluster corresponding to each label should ideally collapse into one probability distribution. Based on this observation and by measuring the concentration of each cluster in terms of conditional mutual information (CMI), a new training method called CMI minimized (CMIM) method is proposed, which trains a DNN by jointly minimizing the conventional cross entropy (CE) loss and the CMI values of all temperature scaled clusters across the entire temperature spectrum. The resulting CMIM model is shown, by extensive experiments, to be undistillable by all tested KD methods existing in the literature. That is, the knockoff students distilled by these KD methods from the CMIM model underperform the respective LS students. In addition, the CMIM model is also shown to performs better than the model trained with the CE loss alone in terms of their own prediction accuracy",
    "checked": true,
    "id": "9e1b92ad895ee4291782ff7d633ac9b34181f04f",
    "semantic_title": "towards undistillable models by minimizing conditional mutual information",
    "citation_count": 2,
    "authors": [
      "Linfeng Ye",
      "Shayan Mohajer Hamidi",
      "EN-HUI YANG"
    ]
  },
  "https://openreview.net/forum?id=Eu7XMLJqsC": {
    "title": "Distributionally Robust Coreset Selection under Covariate Shift",
    "volume": "main",
    "abstract": "Coreset selection, which involves selecting a small subset from an existing training dataset, is an approach to reducing training data, and various approaches have been proposed for this method. In practical situations where these methods are employed, it is often the case that the data distributions differ between the development phase and the deployment phase, with the latter being unknown. Thus, it is challenging to select an effective subset of training data that performs well across all deployment scenarios. We therefore propose Distributionally Robust Coreset Selection (DRCS). DRCS theoretically derives an estimate of the upper bound for the worst-case test error, assuming that the future covariate distribution may deviate within a defined range from the training distribution. Furthermore, by selecting instances in a way that suppresses the estimate of the upper bound for the worst-case test error, DRCS achieves distributionally robust training instance selection. This study is primarily applicable to convex training computation, but we demonstrate that it can also be applied to deep learning under appropriate approximations. In this paper, we focus on covariate shift, a type of data distribution shift, and demonstrate the effectiveness of DRCS through experiments",
    "checked": true,
    "id": "4705aec35e91cc52f2831f7ad84963c01026b3a0",
    "semantic_title": "distributionally robust coreset selection under covariate shift",
    "citation_count": 1,
    "authors": [
      "Tomonari Tanaka",
      "Hiroyuki Hanada",
      "Hanting Yang",
      "Aoyama Tatsuya",
      "Yu Inatsu",
      "Akahane Satoshi",
      "Yoshito Okura",
      "Noriaki Hashimoto",
      "Taro Murayama",
      "Hanju Lee",
      "Shinya Kojima",
      "Ichiro Takeuchi"
    ]
  },
  "https://openreview.net/forum?id=o6mnkDzVuc": {
    "title": "Thoughts and Lessons on Using Visual Foundation Models for Manipulation",
    "volume": "main",
    "abstract": "Training vision-based robotic systems from scratch is both computationally expensive and memory intensive. To mitigate these challenges, recent approaches forgo end-to-end training in favor of adopting visual representations from visual foundation models -- large scale models designed for broad task transferability. Recent years have seen numerous vision foundation models emerge, including several designed specifically for manipulation tasks. However, we still lack clear principles for what makes these models effective for robotics applications. To address this gap, we systematically evaluate vision foundation models to understand what makes them effective for offline robotic learning. We find that across eleven diverse vision encoders, a representation's ability to reconstruct edges and predict keypoints strongly correlates with its performance on manipulation tasks. Extensive correlation analysis across 21 manipulation tasks consistently shows that representations preserving edge and keypoint information achieve the highest environment success rates. These findings appear to challenge conventional wisdom about holistic reconstruction-based pretraining and offer a new lens for understanding what makes vision representations effective for robotics",
    "checked": true,
    "id": "17dd9894a0739cda47dce7ff9eaf3a3d3ee16897",
    "semantic_title": "thoughts and lessons on using visual foundation models for manipulation",
    "citation_count": 0,
    "authors": [
      "Ryan Chen",
      "Ziteng Pang",
      "Bradly C. Stadie"
    ]
  },
  "https://openreview.net/forum?id=bzk1sV1svm": {
    "title": "SR-Reward: Taking The Path More Traveled",
    "volume": "main",
    "abstract": "In this paper, we propose a novel method for learning reward functions directly from offline demonstrations. Unlike traditional inverse reinforcement learning (IRL), our approach decouples the reward function from the learner's policy, eliminating the adversarial interaction typically required between the two. This results in a more stable and efficient training process. Our reward module, \\textit{SR-Reward}, leverages successor representation (SR) to encode a state based on expected future states' visitation under the demonstration policy and transition dynamics. By utilizing the Bellman equation, SR-Reward can be learned concurrently with most reinforcement learning (RL) algorithms without altering the existing training pipeline. We also introduce a negative sampling strategy to mitigate overestimation errors by reducing rewards for out-of-distribution data, thereby enhancing robustness. This strategy introduces an inherent conservative bias into RL algorithms that employ the learned reward, encouraging them to stay close to the demonstrations where the consequences of the actions are better understood. We evaluate our method on D4RL as well as Maniskill Robot Manipulation environments, achieving competitive results compared to offline RL algorithms with access to true rewards and imitation learning (IL) techniques like behavioral cloning",
    "checked": true,
    "id": "049b75803aea2ac63e17fc4e645aaba03bb3aced",
    "semantic_title": "sr-reward: taking the path more traveled",
    "citation_count": 0,
    "authors": [
      "Seyed Mahdi B. Azad",
      "Zahra Padar",
      "Gabriel Kalweit",
      "Joschka Boedecker"
    ]
  },
  "https://openreview.net/forum?id=Zy4uFzMviZ": {
    "title": "AI Agents That Matter",
    "volume": "main",
    "abstract": "AI agents are an exciting new research direction, and agent development is driven by benchmarks. Our analysis of current agent benchmarks and evaluation practices reveals several shortcomings that hinder their usefulness in real-world applications. First, there is a narrow focus on accuracy without attention to other metrics. As a result, SOTA agents are needlessly complex and costly, and the community has reached mistaken conclusions about the sources of accuracy gains. Our focus on cost in addition to accuracy motivates the new goal of jointly optimizing the two metrics. We design and implement one such optimization, showing its potential to greatly reduce cost while maintaining accuracy. Second, the benchmarking needs of model and downstream developers have been conflated, making it hard to identify which agent would be best suited for a particular application. Third, many agent benchmarks have inadequate holdout sets, and sometimes none at all. This has led to agents that are fragile because they take shortcuts and overfit to the benchmark in various ways. We prescribe a principled framework for avoiding overfitting. Finally, there is a lack of standardization in evaluation practices, leading to a pervasive lack of reproducibility. We hope that the steps we introduce for addressing these shortcomings will spur the development of agents that are useful in the real world and not just accurate on benchmarks",
    "checked": true,
    "id": "edae954314571eb2913209a7e9825cdc14fd4c58",
    "semantic_title": "ai agents that matter",
    "citation_count": 43,
    "authors": [
      "Sayash Kapoor",
      "Benedikt Stroebl",
      "Zachary S Siegel",
      "Nitya Nadgir",
      "Arvind Narayanan"
    ]
  },
  "https://openreview.net/forum?id=J65NBLWrmh": {
    "title": "LASE: Learned Adjacency Spectral Embeddings",
    "volume": "main",
    "abstract": "We put forth a principled design of a neural architecture to learn nodal Adjacency Spectral Embeddings (ASE) from graph inputs. By bringing to bear the gradient descent (GD) method and leveraging the technique of algorithm unrolling, we truncate and re-interpret each GD iteration as a layer in a graph neural network (GNN) that is trained to approximate the ASE. Accordingly, we call the resulting embeddings and our parametric model Learned ASE (LASE), which is interpretable, parameter efficient, robust to inputs with unobserved edges, and offers controllable complexity during inference. LASE layers combine Graph Convolutional Network (GCN) and fully-connected Graph Attention Network (GAT) modules, which is intuitively pleasing since GCN-based local aggregations alone are insufficient to express the sought graph eigenvectors. We propose several refinements to the unrolled LASE architecture (such as sparse attention in the GAT module and decoupled layerwise parameters) that offer favorable approximation error versus computation tradeoffs; even outperforming heavily-optimized eigendecomposition routines from scientific computing libraries. Because LASE is a differentiable function with respect to its parameters as well as its graph input, we can seamlessly integrate it as a trainable module within a larger (semi-)supervised graph representation learning pipeline. The resulting end-to-end system effectively learns \"discriminative ASEs\" that exhibit competitive performance in supervised link prediction and node classification tasks, outperforming a GNN even when the latter is endowed with open loop, meaning task-agnostic, precomputed spectral positional encodings",
    "checked": true,
    "id": "a8ec7bf2e5a56272e8b5851633c085b657a26dec",
    "semantic_title": "lase: learned adjacency spectral embeddings",
    "citation_count": 0,
    "authors": [
      "María Sofía Pérez Casulo",
      "Marcelo Fiori",
      "Federico Larroca",
      "Gonzalo Mateos"
    ]
  },
  "https://openreview.net/forum?id=OMOFmb6ve7": {
    "title": "Optimization Guarantees for Square-Root Natural-Gradient Variational Inference",
    "volume": "main",
    "abstract": "Variational inference with natural-gradient descent often shows fast convergence in practice, but its theoretical convergence guarantees have been challenging to establish. This is true even for the simplest cases that involve concave log-likelihoods and use a Gaussian approximation. We show that the challenge can be circumvented for such cases using a square-root parameterization for the Gaussian covariance. This approach establishes novel convergence guarantees for natural-gradient variational-Gaussian inference and its continuous-time gradient flow. Our experiments demonstrate the effectiveness of natural gradient methods and highlight their advantages over algorithms that use Euclidean or Wasserstein geometries",
    "checked": true,
    "id": "60c2d6a8cab7edffd64570d38e5ae6f0caa4c582",
    "semantic_title": "optimization guarantees for square-root natural-gradient variational inference",
    "citation_count": 0,
    "authors": [
      "Navish Kumar",
      "Thomas Möllenhoff",
      "Mohammad Emtiyaz Khan",
      "Aurelien Lucchi"
    ]
  },
  "https://openreview.net/forum?id=dpcRp8ix5T": {
    "title": "Simple Calibration via Geodesic Kernels",
    "volume": "main",
    "abstract": "Deep discriminative approaches, such as decision forests and deep neural networks, have recently found applications in many important real-world scenarios. However, deploying these learning algorithms in safety-critical applications raises concerns, particularly when it comes to ensuring calibration for both in-distribution and out-of-distribution regions. Many popular methods for in-distribution (ID) calibration, such as isotonic and Platt's sigmoidal regression, exhibit adequate ID calibration performance. However, these methods are not calibrated for the entire feature space, leading to overconfidence in the out-of-distribution (OOD) region. Existing OOD calibration methods generally exhibit poor ID calibration. In this paper, we jointly address the ID and OOD problems. We leveraged the fact that deep models learn to partition feature space into a union of polytopes, that is, flat-sided geometric objects. We introduce a geodesic distance to measure the distance between these polytopes and further distinguish samples within the same polytope using a Gaussian kernel. Our experiments on both tabular and vision benchmarks show that the proposed approaches, namely Kernel Density Forest (KDF) and Kernel Density Network (KDN), obtain well-calibrated posteriors for both ID and OOD samples, while mostly preserving the classification accuracy and extrapolating beyond the training data to handle OOD inputs appropriately",
    "checked": false,
    "id": "deca8fb9b37b7868a7564ab198897a49a64a1601",
    "semantic_title": "smooth ece: principled reliability diagrams via kernel smoothing",
    "citation_count": 25,
    "authors": [
      "Jayanta Dey",
      "Haoyin Xu",
      "Ashwin De Silva",
      "Joshua T Vogelstein"
    ]
  },
  "https://openreview.net/forum?id=DCCw2CEVFS": {
    "title": "TapWeight: Reweighting Pretraining Objectives for Task-Adaptive Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "bef435366445c6f8b23bba00c4d674c8b5ab2855",
    "semantic_title": "tapweight: reweighting pretraining objectives for task-adaptive pretraining",
    "citation_count": 0,
    "authors": [
      "Ruiyi Zhang",
      "Sai Ashish Somayajula",
      "Pengtao Xie"
    ]
  },
  "https://openreview.net/forum?id=zx6QGmBL43": {
    "title": "Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "f15fa78bc0722b1cb1ab298e4c723981d49b6864",
    "semantic_title": "enhancing deep neural networks through complex-valued representations and kuramoto synchronization dynamics",
    "citation_count": 0,
    "authors": [
      "Sabine Muzellec",
      "Andrea Alamia",
      "Thomas Serre",
      "Rufin VanRullen"
    ]
  },
  "https://openreview.net/forum?id=xChvYjvXTp": {
    "title": "Large Language Model-Brained GUI Agents: A Survey",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0431f8eb62a8c455977e6d5d34a28932eecd68df",
    "semantic_title": "large language model-brained gui agents: a survey",
    "citation_count": 0,
    "authors": [
      "Chaoyun Zhang",
      "Shilin He",
      "Jiaxu Qian",
      "Bowen Li",
      "Liqun Li",
      "Si Qin",
      "Yu Kang",
      "Minghua Ma",
      "Guyue Liu",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ]
  },
  "https://openreview.net/forum?id=gJ1OknHV5e": {
    "title": "End-to-end Training for Text-to-Image Synthesis using Dual-Text Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "a9866321f7b8eea3cfac89d4620576937c345890",
    "semantic_title": "end-to-end training for text-to-image synthesis using dual-text embeddings",
    "citation_count": 0,
    "authors": [
      "Yeruru Asrar Ahmed",
      "Anurag Mittal"
    ]
  },
  "https://openreview.net/forum?id=KcR8ykFlHA": {
    "title": "State-Constrained Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "Traditional offline reinforcement learning (RL) methods predominantly operate in a batch-constrained setting. This confines the algorithms to a specific state-action distribution present in the dataset, reducing the effects of distributional shift but restricting the policy to seen actions. In this paper, we alleviate this limitation by introducing state-constrained offline RL, a novel framework that focuses solely on the dataset's state distribution. This approach allows the policy to take high-quality out-of-distribution actions that lead to in- distribution states, significantly enhancing learning potential. The proposed setting not only broadens the learning horizon but also improves the ability to combine different trajectories from the dataset effectively, a desirable property inherent in offline RL. Our research is underpinned by theoretical findings that pave the way for subsequent advancements in this area. Additionally, we introduce StaCQ, a deep learning algorithm that achieves state-of-the-art performance on the D4RL benchmark datasets and aligns with our theoretical propositions. StaCQ establishes a strong baseline for forthcoming explorations in this domain",
    "checked": true,
    "id": "699d6ba5a173b30df697bc7514b8b1b03d35d762",
    "semantic_title": "state-constrained offline reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Charles Alexander Hepburn",
      "Yue Jin",
      "Giovanni Montana"
    ]
  },
  "https://openreview.net/forum?id=nOL9M6D4oM": {
    "title": "Learning in complex action spaces without policy gradients",
    "volume": "main",
    "abstract": "While conventional wisdom holds that policy gradient methods are better suited to complex action spaces than action-value methods, foundational work has shown that the two paradigms are equivalent in small, finite action spaces (O'Donoghue et al., 2017; Schulman et al., 2017a). This raises the question of why their computational applicability and performance diverge as the complexity of the action space increases. We hypothesize that the apparent superiority of policy gradients in such settings stems not from intrinsic qualities of the paradigm but from universal principles that can also be applied to action-value methods, enabling similar functions. We identify three such principles and provide a framework for incorporating them into action-value methods. To support our hypothesis, we instantiate this framework in what we term QMLE, for Q-learning with maximum likelihood estimation. Our results show that QMLE can be applied to complex action spaces at a computational cost comparable to that of policy gradient methods, all without using policy gradients. Furthermore, QMLE exhibits strong performance on the DeepMind Control Suite, even when compared to state-of-the-art methods such as DMPO and D4PG",
    "checked": true,
    "id": "c230dbbad51264cdce9cc9d2f4b1f77101350ff1",
    "semantic_title": "learning in complex action spaces without policy gradients",
    "citation_count": 0,
    "authors": [
      "Arash Tavakoli",
      "Sina Ghiassian",
      "Nemanja Rakicevic"
    ]
  },
  "https://openreview.net/forum?id=iyfbGyAkKt": {
    "title": "Non asymptotic analysis of Adaptive stochastic gradient algorithms and applications",
    "volume": "main",
    "abstract": "In stochastic optimization, a widely used approach for handling large samples sequentially is the stochastic gradient algorithm (SGD). However, a key limitation of SGD is that its step size sequence remains uniform across all gradient directions, which can lead to poor performance in practice, particularly for ill-conditioned problems. To address this issue, adaptive gradient algorithms, such as Adagrad and stochastic Newton methods, have been developed. These algorithms adapt the step size to each gradient direction, providing significant advantages in such challenging settings. This paper focuses on the non-asymptotic analysis of these adaptive gradient algorithms for strongly convex objective functions. The theoretical results are further applied to practical examples, including linear regression and regularized generalized linear models, using both Adagrad and stochastic Newton algorithms",
    "checked": true,
    "id": "b2e7fbe58257e8bc7f2db5f1aa5dd0ebcedf6a62",
    "semantic_title": "non asymptotic analysis of adaptive stochastic gradient algorithms and applications",
    "citation_count": 5,
    "authors": [
      "Antoine Godichon-Baggioni",
      "Pierre Tarrago"
    ]
  },
  "https://openreview.net/forum?id=Al72Fp0rCg": {
    "title": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers: the Importance of 2D Representation, Positions, and Objects",
    "volume": "main",
    "abstract": "The Abstraction and Reasoning Corpus (ARC) is a popular benchmark focused on visual reasoning in the evaluation of Artificial Intelligence systems. In its original framing, an ARC task requires solving a program synthesis problem over small 2D images using a few input-output training pairs. In this work, we adopt the recently popular data-driven approach to the ARC and ask whether a Vision Transformer (ViT) can learn the implicit mapping, from input image to output image, that underlies the task. We show that a ViT—otherwise a state-of-the-art model for images—fails dra- matically on most ARC tasks even when trained on one million examples per task. This points to an inherent representational deficiency of the ViT architecture that makes it incapable of uncov- ering the simple structured mappings underlying the ARC tasks. Building on these insights, we propose VITARC, a ViT-style architecture that unlocks some of the visual reasoning capabilities re- quired by the ARC. Specifically, we use a pixel-level input representation, design a spatially-aware tokenization scheme, and introduce a novel object-based positional encoding that leverages auto- matic segmentation, among other enhancements. Our task-specific VITARC models achieve a test solve rate close to 100% on more than half of the 400 public ARC tasks strictly through supervised learning from input-output grids. This calls attention to the importance of imbuing the powerful (Vision) Transformer with the correct inductive biases for abstract visual reasoning that are critical even when the training data is plentiful and the mapping is noise-free. Hence, VITARC provides a strong foundation for future research in visual reasoning using transformer-based architectures",
    "checked": true,
    "id": "73d17906c62d3d32be9908b61007821cbc0756e8",
    "semantic_title": "tackling the abstraction and reasoning corpus with vision transformers: the importance of 2d representation, positions, and objects",
    "citation_count": 4,
    "authors": [
      "Wenhao Li",
      "Yudong Xu",
      "Scott Sanner",
      "Elias Boutros Khalil"
    ]
  },
  "https://openreview.net/forum?id=JlPq0LmApB": {
    "title": "Tackling Feature and Sample Heterogeneity in Decentralized Multi-Task Learning: A Sheaf-Theoretic Approach",
    "volume": "main",
    "abstract": "Federated multi-task learning (FMTL) aims to simultaneously learn multiple related tasks across clients without sharing sensitive raw data. However, in the decentralized setting, existing FMTL frameworks are limited in their ability to capture complex task relationships and handle feature and sample heterogeneity across clients. To address these challenges, we introduce a novel sheaf-theoretic-based approach for FMTL. By representing client relationships using cellular sheaves, our framework can flexibly model interactions between heterogeneous client models. We formulate the sheaf-based FMTL optimization problem using sheaf Laplacian regularization and propose the Sheaf-FMTL algorithm to solve it. We show that the proposed framework provides a unified view encompassing many existing federated learning (FL) and FMTL approaches. Furthermore, we prove that our proposed algorithm, Sheaf-FMTL, achieves a sublinear convergence rate in line with state-of-the-art decentralized FMTL algorithms. Extensive experiments show that although Sheaf-FMTL introduces computational and storage overhead due to the management of interaction maps, it achieves substantial communication savings in terms of transmitted bits when compared to decentralized FMTL baselines. This trade-off makes Sheaf-FMTL especially suitable for cross-silo FL scenarios, where managing model heterogeneity and ensuring communication efficiency are essential, and where clients have adequate computational resources",
    "checked": true,
    "id": "db540a8a4f52428bee0cf78832f36d6d0f2eaca4",
    "semantic_title": "tackling feature and sample heterogeneity in decentralized multi-task learning: a sheaf-theoretic approach",
    "citation_count": 3,
    "authors": [
      "Chaouki Ben Issaid",
      "Praneeth Vepakomma",
      "Mehdi Bennis"
    ]
  },
  "https://openreview.net/forum?id=6R3fRqFfhn": {
    "title": "GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity",
    "volume": "main",
    "abstract": "We study a class of distributed optimization algorithms that aim to alleviate high communication costs by allowing clients to perform multiple local gradient-type training steps before communication. In a recent breakthrough, Mishchenko et al. (2022) proved that local training, when properly executed, leads to provable communication acceleration, and this holds in the strongly convex regime without relying on any data similarity assumptions. However, their ProxSkip method requires all clients to take the same number of local training steps in each communication round. We propose a redesign of the ProxSkip method, allowing clients with ``less important'' data to get away with fewer local training steps without impacting the overall communication complexity of the method. In particular, we prove that our modified method, GradSkip, converges linearly under the same assumptions and has the same accelerated communication complexity, while the number of local gradient steps can be reduced relative to a local condition number. We further generalize our method by extending the randomness of probabilistic alternations to arbitrary unbiased compression operators and by considering a generic proximable regularizer. This generalization, which we call GradSkip+, recovers several related methods in the literature as special cases. Finally, we present an empirical study on carefully designed toy problems that confirm our theoretical claims",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arto Maranjyan",
      "Mher Safaryan",
      "Peter Richtárik"
    ]
  },
  "https://openreview.net/forum?id=DQqdjPcE6g": {
    "title": "Reconciling Privacy and Explainability in High-Stakes: A Systematic Inquiry",
    "volume": "main",
    "abstract": "Deep learning's preponderance across scientific domains has reshaped high-stakes decision-making, making it essential to follow rigorous operational frameworks that include both Right-to-Privacy (RTP) and Right-to-Explanation (RTE). This paper examines the complexities of combining these two requirements. For RTP, we focus on ‘Differential privacy' (DP), which is considered the current gold standard for privacy-preserving machine learning due to its strong quantitative guarantee of privacy. For RTE, we focus on post-hoc explainers: they are the go-to option for model auditing as they operate independently of model training. We formally investigate DP models and various commonly-used post-hoc explainers: how to evaluate these explainers subject to RTP, and analyze the intrinsic interactions between DP models and these explainers. Furthermore, our work throws light on how RTP and RTE can be effectively combined in high-stakes applications. Our study concludes by outlining an industrial software pipeline, with the example of a widely used use case, that respects both RTP and RTE requirements",
    "checked": true,
    "id": "ad3f8f07b72630fb7341c4ecb47b7928a3d676eb",
    "semantic_title": "reconciling privacy and explainability in high-stakes: a systematic inquiry",
    "citation_count": 0,
    "authors": [
      "Supriya Manna",
      "Niladri Sett"
    ]
  },
  "https://openreview.net/forum?id=gwUOzI4DuV": {
    "title": "MACCA: Offline Multi-agent Reinforcement Learning with Causal Credit Assignment",
    "volume": "main",
    "abstract": "Offline Multi-agent Reinforcement Learning (MARL) is valuable in scenarios where online interaction is impractical or risky. While independent learning in MARL offers flexibility and scalability, accurately assigning credit to individual agents in offline settings poses challenges because interactions with an environment are prohibited. In this paper, we propose a new framework, namely \\textbf{M}ulti-\\textbf{A}gent \\textbf{C}ausal \\textbf{C}redit \\textbf{A}ssignment (\\textbf{MACCA}), to address credit assignment in the offline MARL setting. Our approach, MACCA, characterizing the generative process as a Dynamic Bayesian Network, captures relationships between environmental variables, states, actions, and rewards. Estimating this model on offline data, MACCA can learn each agent's contribution by analyzing the causal relationship of their individual rewards, ensuring accurate and interpretable credit assignment. Additionally, the modularity of our approach allows it to integrate with various offline MARL methods seamlessly. Theoretically, we proved that under the setting of the offline dataset, the underlying causal structure and the function for generating the individual rewards of agents are identifiable, which laid the foundation for the correctness of our modeling. In our experiments, we demonstrate that MACCA not only outperforms state-of-the-art methods but also enhances performance when integrated with other backbones",
    "checked": true,
    "id": "80e2f19b543685bbcfc4137216ebe688060adf00",
    "semantic_title": "macca: offline multi-agent reinforcement learning with causal credit assignment",
    "citation_count": 4,
    "authors": [
      "Ziyan Wang",
      "Yali Du",
      "Yudi Zhang",
      "Meng Fang",
      "Biwei Huang"
    ]
  },
  "https://openreview.net/forum?id=9oToxYVOSW": {
    "title": "Efficient and Flexible Neural Network Training through Layer-wise Feedback Propagation",
    "volume": "main",
    "abstract": "Gradient-based optimization has been a cornerstone of machine learning that enabled the vast ad- vances of Artificial Intelligence (AI) development over the past decades. However, this type of optimization requires differentiation, and with recent evidence of the benefits of non-differentiable (e.g. neuromorphic) architectures over classical models w.r.t. efficiency, such constraints can be- come limiting in the future. We present Layer-wise Feedback Propagation (LFP), a novel training principle for neural network-like predictors that utilizes methods from the domain of explainability to decompose a reward to individual neurons based on their respective contributions. Leveraging these neuron-wise rewards, our method then implements a greedy approach reinforcing helpful parts of the network and weakening harmful ones. While having comparable computational complexity to gradient descent, LFP does not require gradient computation and generates sparse and thereby memory- and energy-efficient parameter updates and models. We establish the convergence of LFP theoretically and empirically, demonstrating its effectiveness on various models and datasets. Via two applications — neural network pruning and the approximation-free training of Spiking Neural Networks (SNNs) — we demonstrate that LFP combines increased efficiency in terms of computation and representation with flexibility w.r.t. choice of model architecture and objective function",
    "checked": true,
    "id": "c4277e841b27cf5b56ec08a820d0da601cf7f575",
    "semantic_title": "efficient and flexible neural network training through layer-wise feedback propagation",
    "citation_count": 2,
    "authors": [
      "Leander Weber",
      "Jim Berend",
      "Moritz Weckbecker",
      "Alexander Binder",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ]
  },
  "https://openreview.net/forum?id=Tnwci2kLna": {
    "title": "CXAD: Contrastive Explanations for Anomaly Detection: Algorithms, Complexity Results and Experiments",
    "volume": "main",
    "abstract": "Anomaly/Outlier detection (AD/OD) is often used in controversial applications to detect unusual behavior which is then further investigated or policed. This means an explanation of why something was predicted as an anomaly is desirable not only for individuals but also for the general population and policy-makers. However, existing explainable AI (XAI) methods are not well suited for Explainable Anomaly detection (XAD). In particular, most XAI methods provide instance-level explanations, whereas a model/global-level explanation is desirable for a complete understanding of the definition of normality or abnormality used by an AD algorithm. Further, existing XAI methods try to explain an algorithm's behavior by finding an explanation of why an instance belongs to a category. However, by definition, anomalies/outliers are chosen because they are different from the normal instances. We propose a new style of model agnostic explanation, called contrastive explanation, that is designed specifically for AD algorithms. It addresses the novel challenge of providing a model-agnostic and global-level explanation by finding contrasts between the outlier group of instances and the normal group. We propose three formulations: (i) Contrastive Explanation, (ii) Strongly Contrastive Explanation, and (iii) Multiple Strong Contrastive Explanations. The last formulation is specifically for the case where a given dataset is believed to have many types of anomalies. For the first two formulations, we show the underlying problem is in the computational class P by presenting linear and polynomial time exact algorithms. We show that the last formulation is computationally intractable, and we use an integer linear program for that version to generate experimental results. We demonstrate our work on several data sets such as the CelebA image data set, the HateXplain language data set, and the COMPAS dataset on fairness. These data sets are chosen as their ground truth explanations are clear or well-known",
    "checked": true,
    "id": "2a8e1ad2d22a9b2e1c6cf7b2108ba60c98314abf",
    "semantic_title": "cxad: contrastive explanations for anomaly detection: algorithms, complexity results and experiments",
    "citation_count": 0,
    "authors": [
      "Ian Davidson",
      "Nicolás Kennedy",
      "S. S. Ravi"
    ]
  },
  "https://openreview.net/forum?id=FPJKZDzdsW": {
    "title": "Fairness with respect to Stereotype Predictors: Impossibilities and Best Practices",
    "volume": "main",
    "abstract": "As AI systems increasingly influence decision-making from consumer recommendations to educational opportunities, their accountability becomes paramount. This need for oversight has driven extensive research into algorithmic fairness, a body of work that has examined both allocative and representational harms. However, numerous works examining representational harms such as stereotypes encompass many different concepts measured by different criteria, yielding many, potentially conflicting, characterizations of harm. The abundance of measurement approaches makes the mitigation of stereotypes in downstream machine learning models highly challenging. Our work introduces and unifies a broad class of auditors through the framework of \\textit{stereotype predictors}. We map notions of fairness with respect to these predictors to existing notions of group fairness. We give guidance, with theoretical foundations, for selecting one or a set of stereotype predictors and provide algorithms for achieving fairness with respect to stereotype predictors under various fairness notions. We demonstrate the effectiveness of our algorithms with different stereotype predictors in two empirical case studies",
    "checked": true,
    "id": "1a6e89353290708035c525a70a12b064009a5607",
    "semantic_title": "fairness with respect to stereotype predictors: impossibilities and best practices",
    "citation_count": 0,
    "authors": [
      "Inbal Rachel Livni Navon",
      "Omer Reingold",
      "Judy Hanwen Shen"
    ]
  },
  "https://openreview.net/forum?id=6Aj0aNXfRy": {
    "title": "Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) often suffer from performance degradation as the network depth increases. This paper addresses this issue by introducing initialization methods that enhance signal propagation (SP) within GNNs. We propose three key metrics for effective SP in GNNs: forward propagation, backward propagation, and graph embedding variation (GEV). While the first two metrics derive from classical SP theory, the third is specifically designed for GNNs. We theoretically demonstrate that a broad range of commonly used initialization methods for GNNs, which exhibit performance degradation with increasing depth, fail to control these three metrics simultaneously. To deal with this limitation, a direct exploitation of the SP analysis--searching for weight initialization variances that optimize the three metrics--is shown to significantly enhance the SP in deep GCNs. This approach is called \\textit{\\textbf{S}ignal \\textbf{P}ropagation \\textbf{o}n \\textbf{G}raph-guided \\textbf{Init}ialization (\\textbf{SPoGInit})}. Our experiments demonstrate that SPoGInit outperforms commonly used initialization methods on various tasks and architectures. Notably, SPoGInit enables performance improvements as GNNs deepen, which represents a significant advancement in addressing depth-related challenges and highlights the validity and effectiveness of the SP analysis framework",
    "checked": true,
    "id": "0fdbdf3508449c409776914a7fedd355023ebf36",
    "semantic_title": "exploring and improving initialization for deep graph neural networks: a signal propagation perspective",
    "citation_count": 0,
    "authors": [
      "Senmiao Wang",
      "Yupeng Chen",
      "Yushun Zhang",
      "Ruoyu Sun",
      "Tian Ding"
    ]
  },
  "https://openreview.net/forum?id=p0KTYl2B9T": {
    "title": "Spaced Scheduling for Large Language Model Training",
    "volume": "main",
    "abstract": "Recent breakthroughs in deep learning have accelerated progress toward increasingly capable large language models (LLMs), even sparking discussions about the path to Artificial General Intelligence (AGI). Yet, current LLM training pipelines continue to depend on heuristics and human-driven empirical analysis to curate data. In practice, more sophisticated data selection methods often incur high costs, exhibit limited adaptability, or do not consistently surpass simple random baselines across various models and datasets. In this work, we propose Spaced Scheduled Training (Sst), a novel adaptive data selection strategy that prioritizes training examples based solely on per-example perplexity computed from the model's own evolving parameters. By obviating the need for external reference models, Sst customizes data selection to the model's unique characteristics, including its pre-training data composition, and eliminates biases commonly introduced by these external models. Extensive experiments on seven LLMs (0.5B to 32B parameters) in the instruction-finetuning (IFT) setting show that Sst consistently outperforms representative state-of-the-art selection approaches like Deita and InsTag on the Open LLM Leaderboard. For instance, with Qwen2.5-32B and a 30k examples data budget, Sst achieved a 42.75% Open LLM Leaderboard score, exceeding a leading data-selection baseline (38.56%) and the full-100k dataset baseline (39.58%). We further present a theoretical framework to assess computational overhead of model-based selection methods, showing that Sst remains efficient in practical scenarios, and propose strategies to mitigate the overhead in worst-case scenarios. Our findings underscore the potential of model-informed dynamic data selection, offering an efficient, adaptable, and cost-effective approach. We release our training code, trained models, and data mixes in our public repository",
    "checked": true,
    "id": "443bdea030dbcba48c77beca48d678a471c9daca",
    "semantic_title": "spaced scheduling for large language model training",
    "citation_count": 0,
    "authors": [
      "Amine El hattami",
      "Nicolas Chapados",
      "Christopher Pal"
    ]
  },
  "https://openreview.net/forum?id=PMO30TLI4l": {
    "title": "Selective Concept Bottleneck Models Without Predefined Concepts",
    "volume": "main",
    "abstract": "Concept-based models like Concept Bottleneck Models (CBMs) have garnered significant interest for improving model interpretability by first predicting human-understandable concepts before mapping them to the output classes. Early approaches required costly concept annotations. To alleviate this, recent methods utilized large language models to automatically generate class-specific concept descriptions and learned mappings from a pretrained black-box model's raw features to these concepts using vision-language models. However, these approaches assume prior knowledge of which concepts the black-box model has learned. In this work, we discover the concepts encoded by the model through unsupervised concept discovery techniques instead. We further leverage a simple input-dependent concept selection mechanism that dynamically retains a sparse set of relevant concepts of each input, enhancing both sparsity and interpretability. Our approach not only improves downstream performance, but also needs significantly fewer concepts for accurate classification. Lastly, we show how large vision-language models can guide the editing of our models' weights to correct model errors",
    "checked": true,
    "id": "1ae701fedad1955b3e061bac42bc24c07bb670a6",
    "semantic_title": "selective concept bottleneck models without predefined concepts",
    "citation_count": 0,
    "authors": [
      "Simon Schrodi",
      "Julian Schur",
      "Max Argus",
      "Thomas Brox"
    ]
  },
  "https://openreview.net/forum?id=T49vPTkIt5": {
    "title": "Knowing What Not to Do: Leverage Language Model Insights for Action Space Pruning in Multi-agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Multi-agent reinforcement learning (MARL) is employed to develop autonomous agents that can learn to adopt cooperative or competitive strategies within complex environments. However, the linear increase in the number of agents leads to a combinatorial explosion of the action space, which always results in algorithmic instability, difficulty in convergence, or entrapment in local optima. While researchers have designed a variety of effective algorithms to compress the action space, these methods also introduce new challenges, such as the need for manually designed prior knowledge or reliance on the structure of the problem, which diminishes the applicability of these techniques. In this paper, we introduce \\textbf{E}volutionary action \\textbf{SPA}ce \\textbf{R}eduction with \\textbf{K}nowledge (eSpark), an exploration function generation framework driven by large language models (LLMs) to boost exploration and prune unnecessary actions in MARL. Using just a basic prompt that outlines the overall task and setting, eSpark is capable of generating exploration functions in a zero-shot manner, identifying and pruning redundant or irrelevant state-action pairs, and then achieving autonomous improvement from policy feedback. In reinforcement learning tasks involving inventory management and traffic light control encompassing a total of 15 scenarios, eSpark consistently outperforms the combined MARL algorithm in all scenarios, achieving an average performance gain of 34.4% and 9.9% in the two types of tasks respectively. Additionally, eSpark has proven to be capable of managing situations with a large number of agents, securing a 29.7% improvement in scalability challenges that featured over 500 agents. The code can be found in https://github.com/LiuZhihao2022/eSpark",
    "checked": true,
    "id": "d7a505964defe667f9c7aa8cb7b79f1caef89614",
    "semantic_title": "knowing what not to do: leverage language model insights for action space pruning in multi-agent reinforcement learning",
    "citation_count": 3,
    "authors": [
      "Zhihao Liu",
      "Xianliang Yang",
      "Zichuan Liu",
      "Yifan Xia",
      "Wei Jiang",
      "Yuanyu Zhang",
      "Lijuan Li",
      "Guoliang Fan",
      "Lei Song",
      "Jiang Bian"
    ]
  },
  "https://openreview.net/forum?id=kEUvWFHEsn": {
    "title": "[RE] GNNBoundary: Finding Boundaries and Going Beyond Them",
    "volume": "main",
    "abstract": "Graph classification models are becoming increasingly popular, while explainability methods face challenges due to the discrete nature of graphs and other factors. However, investigating model decision-making, such as through decision-boundary regions, helps prevent misclassification and improve model robustness. This study aims to reproduce the findings of GNNBoundary: Towards Explaining Graph Neural Networks Through the Lens of Decision Boundaries (Wang & Shen, 2024). Their work supports 3 main claims: (1) their proposed algorithm can identify adjacent class pairs reliably, (2) their GNNBoundary can effectively and consistently generate near-boundary graphs outperforming the cross entropy baseline and (3) the generated near-boundary graphs can be used to accurately assess key properties of the decision boundary; margin, thickness, and complexity. We reproduce the experiments on the same datasets and extended them to two additional real-world datasets. Beyond that, we test different boundary probability ranges and their effect on decision boundary metrics, develop an additional baseline, and conduct hyperparameter tuning. We confirm the first claim regarding the adjacency discovery as well as the second claim that GNNBoundary outperforms the cross-entropy baseline under the limitation that it requires intensive hyperparameter tuning for convergence. The third claim is partially accepted as we observe a high variance between reported and obtained results, disproving the reliability and precision of the boundary statistics. Code and instructions are available at: https://github.com/jhb300/re_gnnboundary",
    "checked": true,
    "id": "87c940bedfa5166e5933bf03c25f9edb3987d938",
    "semantic_title": "[re] gnnboundary: finding boundaries and going beyond them",
    "citation_count": 0,
    "authors": [
      "Jan Henrik Bertrand",
      "Lukas Bierling",
      "Ina Klaric",
      "Aron Wezenberg"
    ]
  },
  "https://openreview.net/forum?id=lTt2cTW8h1": {
    "title": "Return-Aligned Decision Transformer",
    "volume": "main",
    "abstract": "Traditional approaches in offline reinforcement learning aim to learn the optimal policy that maximizes the cumulative reward, also known as return. It is increasingly important to adjust the performance of AI agents to meet human requirements, for example, in applications like video games and education tools. Decision Transformer (DT) optimizes a policy that generates actions conditioned on the target return through supervised learning and includes a mechanism to control the agent's performance using the target return. However, the action generation is hardly influenced by the target return because DT's self-attention allocates scarce attention scores to the return tokens. In this paper, we propose Return-Aligned Decision Transformer (RADT), designed to more effectively align the actual return with the target return. RADT leverages features extracted by paying attention solely to the return, enabling action generation to consistently depend on the target return. Extensive experiments show that RADT significantly reduces the discrepancies between the actual return and the target return compared to DT-based methods",
    "checked": true,
    "id": "e578bea500991708759b68e1a48cc8102b456860",
    "semantic_title": "return-aligned decision transformer",
    "citation_count": 1,
    "authors": [
      "Tsunehiko Tanaka",
      "Kenshi Abe",
      "Kaito Ariu",
      "Tetsuro Morimura",
      "Edgar Simo-Serra"
    ]
  },
  "https://openreview.net/forum?id=R7QFlwvnne": {
    "title": "Unified Preference Optimization: Language Model Alignment Beyond the Preference Frontier",
    "volume": "main",
    "abstract": "For aligning large language models (LLMs), prior work has leveraged reinforcement learning via human feedback (RLHF) or variations of direct preference optimization (DPO). While DPO offers a simpler framework based on maximum likelihood estimation, it compromises on the ability to easily tune language models to maximize auxiliary, non-preferential objectives according to the LLM designer's preferences (e.g., tuning lexical style or minimizing specific kinds of harmful content). Critically, these designer objectives may not be amply human-labeled or represented in available data, align with user preferences, or even be able to be captured tractably by binary preference pairs. To leverage the simplicity and performance of DPO with the generality of RL, we propose a unified approach. Based on a simple decomposition of preference and auxiliary objectives, we allow for tuning LLMs to optimize user and designer preferences without any additional specialized or preference data, computational cost, stability \"tweaks\", hyperparameter tuning, or training instability. The proposed method, Unified Preference Optimization, shows the ability to effectively generalize to user preferences and auxiliary objectives, while preserving or surpassing alignment performance on challenging benchmarks across a range of model sizes",
    "checked": true,
    "id": "126900598c17b4149d4836652116d578507f5033",
    "semantic_title": "unified preference optimization: language model alignment beyond the preference frontier",
    "citation_count": 4,
    "authors": [
      "Anirudhan Badrinath",
      "Prabhat Agarwal",
      "Jiajing Xu"
    ]
  },
  "https://openreview.net/forum?id=Z0DhgU8fBt": {
    "title": "[Re] Improving Interpretation Faithfulness for Vision Transformers",
    "volume": "main",
    "abstract": "This work aims to reproduce the results of Faithful Vision Transformers (FViTs) proposed by Hu et al. (2024) alongside interpretability methods for Vision Transformers from Chefer et al. (2021) and Xu et al. (2022). We investigate claims made by Hu et al. (2024), namely that the usage of Diffusion Denoised Smoothing (DDS) improves interpretability robustness to (1) attacks in a segmentation task and (2) perturbation and attacks in a classification task. We also extend the original study by investigating the authors' claims that adding DDS to any interpretability method can improve its robustness under attack. This is tested on baseline methods and the recently proposed Attribution Rollout method. In addition, we measure the computational costs and environmental impact of obtaining an FViT through DDS. Our results broadly agree with the original study's findings, although minor discrepancies were found and discussed",
    "checked": true,
    "id": "9ee7ca6c2e7f32c664711d6ef1b306456260ddbf",
    "semantic_title": "[re] improving interpretation faithfulness for vision transformers",
    "citation_count": 0,
    "authors": [
      "Izabela Kurek",
      "Wojciech Trejter",
      "Stipe Frkovic",
      "Andro Erdelez"
    ]
  },
  "https://openreview.net/forum?id=y8VXikiIU0": {
    "title": "Enhancing Sample Generation of Diffusion Models using Noise Level Correction",
    "volume": "main",
    "abstract": "The denoising process of diffusion models can be interpreted as an approximate projection of noisy samples onto the data manifold. Moreover, the noise level in these samples approximates their distance to the underlying manifold. Building on this insight, we propose a novel method to enhance sample generation by aligning the estimated noise level with the true distance of noisy samples to the manifold. Specifically, we introduce a noise level correction network, leveraging a pre-trained denoising network, to refine noise level estimates during the denoising process. Additionally, we extend this approach to various image restoration tasks by integrating task-specific constraints, including inpainting, deblurring, super-resolution, colorization, and compressed sensing. Experimental results demonstrate that our method significantly improves sample quality in both unconstrained and constrained generation scenarios. Notably, the proposed noise level correction framework is compatible with existing denoising schedulers (e.g., DDIM), offering additional performance improvements",
    "checked": true,
    "id": "078d7454b99c9808fb1c6a803ec4abe581f43416",
    "semantic_title": "enhancing sample generation of diffusion models using noise level correction",
    "citation_count": 1,
    "authors": [
      "Abulikemu Abuduweili",
      "Chenyang Yuan",
      "Changliu Liu",
      "Frank Permenter"
    ]
  },
  "https://openreview.net/forum?id=YCBVcGSZeR": {
    "title": "Rational Tuning of LLM Cascades via Probabilistic Modeling",
    "volume": "main",
    "abstract": "Understanding the reliability of large language models (LLMs) has recently garnered significant attention. Given LLMs' propensity to hallucinate, as well as their high sensitivity to prompt design, it is already challenging to predict the performance of an individual LLM. However, the problem becomes more complex for compound LLM systems such as cascades, where in addition to each model's standalone performance, we must understand how the error rates of different models interact. In this paper, we present a probabilistic model for the joint performance distribution of a sequence of LLMs, which enables a framework for rationally tuning the confidence thresholds of a LLM cascade using continuous optimization. Compared to selecting confidence thresholds using Bayesian optimization, our parametric Markov-copula model yields more favorable error-cost trade-offs, improving the area under the error-cost curve by 4.3% on average for cascades with $k\\geq 3$ models. In the low-sample regime with $n \\leq 30$ training examples, the performance improvement widens to 10.2%, suggesting that our framework's inductive assumptions about the interactions between the error rates of different LLMs enhance sample efficiency. Overall, our Markov-copula model provides a rational basis for tuning LLM cascade performance and points to the potential of probabilistic methods in analyzing systems of LLMs",
    "checked": true,
    "id": "1b852535628b7fe93ee1233e107ccdeb67af3372",
    "semantic_title": "rational tuning of llm cascades via probabilistic modeling",
    "citation_count": 3,
    "authors": [
      "Michael J. Zellinger",
      "Matt Thomson"
    ]
  },
  "https://openreview.net/forum?id=WfVXe88oMh": {
    "title": "Proximal Policy Distillation",
    "volume": "main",
    "abstract": "We introduce Proximal Policy Distillation (PPD), a novel policy distillation method that integrates student-driven distillation and Proximal Policy Optimization (PPO) to increase sample efficiency and to leverage the additional rewards that the student policy collects during distillation. To assess the efficacy of our method, we compare PPD with two common alternatives, student-distill and teacher-distill, over a wide range of reinforcement learning environments that include discrete actions and continuous control (ATARI, Mujoco, and Procgen). For each environment and method, we perform distillation to a set of target student neural networks that are smaller, identical (self-distillation), or larger than the teacher network. Our findings indicate that PPD improves sample efficiency and produces better student policies compared to typical policy distillation approaches. Moreover, PPD demonstrates greater robustness than alternative methods when distilling policies from imperfect demonstrations. The code for the paper is released as part of a new Python library built on top of stable-baselines3 to facilitate policy distillation: <Anonymized GitHub Repository>",
    "checked": true,
    "id": "ab9a33bf7c10ed04b6e8a93cc97f59e234d700a6",
    "semantic_title": "proximal policy distillation",
    "citation_count": 1,
    "authors": [
      "Giacomo Spigler"
    ]
  },
  "https://openreview.net/forum?id=6RCs2tLsHq": {
    "title": "Metamorphic Forward Adaptation Network: Dynamically Adaptive and Modular Multi-layer Learning",
    "volume": "main",
    "abstract": "Back-propagation is a widely used algorithm for training neural networks by adjusting weights based on error gradients. However, back-propagation is biologically implausible with global derivative computation and lacks robustness in long-term dynamic learning. A previously proposed alternative to back-propagation is the Forward-Forward algorithm, which bypasses global gradient dependency and localises computations, making it a more biologically plausible approach. However, Forward-Forward has been evaluated in limited environments, does not yet match back-propagation's performance, and only supports classification, not regression. This research introduces the Metamorphic Forward Adaptation Network (MFAN), using a contrastive learning property as its core, and retaining the layer-wise architecture of the Forward-Forward algorithm. Compared to the Forward-Forward model being limited to discrete classification, MFAN can process discrete and continuous data, showing stability, adaptability, and the ability to handle evolving data. MFAN performs well in continuous data stream scenarios, demonstrating superior adaptability and robustness compared to back-propagation, particularly in tasks requiring dynamic, long-term learning",
    "checked": true,
    "id": "b25efdb1f526764bc6b703318df6a72090285316",
    "semantic_title": "metamorphic forward adaptation network: dynamically adaptive and modular multi-layer learning",
    "citation_count": 0,
    "authors": [
      "Yu Sun",
      "Vijja Wichitwechkarn",
      "Ronald Clark",
      "Mirko Kovac",
      "Basaran Bahadir Kocer"
    ]
  },
  "https://openreview.net/forum?id=rkfop9GyxB": {
    "title": "Lie Symmetry Net: Preserving Conservation Laws in Modelling Financial Market Dynamics via Differential Equations",
    "volume": "main",
    "abstract": "This paper employs a novel Lie symmetries-based framework to model the intrinsic symmetries within financial market. Specifically, we introduce Lie symmetry net (LSN), which characterises the Lie symmetries of the differential equations (DE) estimating financial market dynamics, such as the Black-Scholes equation. To simulate these differential equations in a symmetry-aware manner, LSN incorporates a Lie symmetry risk derived from the conservation laws associated with the Lie symmetry operators of the target differential equations. This risk measures how well the Lie symmetries are realised and guides the training of LSN under the structural risk minimisation framework. Extensive numerical experiments demonstrate that LSN effectively realises the Lie symmetries and achieves an error reduction of more than one order of magnitude compared to state-of-the-art methods. The code is available at https://github.com/Jxl163/LSN_code",
    "checked": true,
    "id": "294acdd4913ec02cf7a4ff8853ebd50843164a69",
    "semantic_title": "lie symmetry net: preserving conservation laws in modelling financial market dynamics via differential equations",
    "citation_count": 0,
    "authors": [
      "Xuelian Jiang",
      "Tongtian Zhu",
      "Yingxiang Xu",
      "Can Wang",
      "Yeyu Zhang",
      "Fengxiang He"
    ]
  },
  "https://openreview.net/forum?id=NbRybPuWCv": {
    "title": "A Framework for Finding Local Saddle Points in Two-Player Zero-Sum Black-Box Games",
    "volume": "main",
    "abstract": "Saddle point optimization is a critical problem employed in numerous real-world applications, including portfolio optimization, generative adversarial networks, and robotics. It has been extensively studied in cases where the objective function is known and differentiable. Existing work in black-box settings with unknown objectives that can only be sampled either assumes convexity-concavity in the objective to simplify the problem or operates with noisy gradient estimators. In contrast, we introduce a framework inspired by Bayesian optimization which utilizes Gaussian processes to model the unknown (potentially nonconvex-nonconcave) objective and requires only zeroth-order samples. Our approach frames the saddle point optimization problem as a two-level process which can flexibly leverage existing general-sum Nash game solvers to solve for saddle points of zero-sum games. The upper level of our framework produces a model of the objective function by sampling in promising locations, and the lower level of our framework uses the existing model to frame and solve a general-sum game to identify locations to sample. This lower level procedure can be designed in complementary ways, and we demonstrate the flexibility of our approach by introducing variants which appropriately trade off between factors like runtime, the cost of function evaluations, and the number of available initial samples. We experimentally demonstrate these algorithms on synthetic and realistic datasets in black-box nonconvex-nonconcave settings, showcasing their ability to efficiently locate local saddle points in these contexts",
    "checked": true,
    "id": "f1496bf0f1182376c322c6effae9961db1a17954",
    "semantic_title": "a framework for finding local saddle points in two-player zero-sum black-box games",
    "citation_count": 0,
    "authors": [
      "Shubhankar Agarwal",
      "Hamzah I Khan",
      "Sandeep P. Chinchali",
      "David Fridovich-Keil"
    ]
  },
  "https://openreview.net/forum?id=kK0WrBZAli": {
    "title": "Scalable Multi-Output Gaussian Processes with Stochastic Variational Inference",
    "volume": "main",
    "abstract": "The Multi-Output Gaussian Process (MOGP) is a popular tool for modelling data from multiple sources. A typical choice to build a covariance function for a MOGP is the Linear Model of Coregionalisation (LMC) which parametrically models the covariance between outputs. The Latent Variable MOGP (LV-MOGP) generalises this idea by modelling the covariance between outputs using a kernel applied to latent variables, one per output, leading to a flexible MOGP model that allows efficient generalisation to new outputs with few data points. The computational complexity in LV-MOGP grows linearly with the number of outputs, which makes it unsuitable for problems with a large number of outputs. In this paper, we propose a stochastic variational inference approach for the LV-MOGP that allows mini-batches for both inputs and outputs, making computational complexity per training iteration independent of the number of outputs. We demonstrate the performance of the model by benchmarking against some other MOGP models in several real-world datasets, including spatial-temporal climate modelling and spatial transcriptomics",
    "checked": true,
    "id": "3094b1bf913ab6af02a9d15235eb1658a73e6ba0",
    "semantic_title": "scalable multi-output gaussian processes with stochastic variational inference",
    "citation_count": 0,
    "authors": [
      "Xiaoyu Jiang",
      "Sokratia Georgaka",
      "Magnus Rattray",
      "Mauricio A Álvarez"
    ]
  },
  "https://openreview.net/forum?id=IGsEgWM4to": {
    "title": "CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) have revolutionized code generation but are require significant resources and tend to over-generalize, limiting their task-specific efficiency. Fine-tuning smaller, open-source LLMs is a cost-effective alternative, yet standard supervised approaches rely solely on correct examples, overlooking valuable insights from failures. We introduce CodeLutra, a new framework that leverages both correct and incorrect code attempts. Instead of purely instructing with correct solutions, CodeLutra uses iterative preference-based refinement, comparing successful and failed outputs to better approximate desired results. This process narrows the performance gap with state-of-the-art, larger models, without requiring massive datasets or auxiliary models. For example, on a challenging data science coding task, using only 500 samples improved Llama-3-8B's accuracy from 28.2% to 48.6%, approaching GPT-4's level. By capitalizing on both successes and mistakes, \\textsc{CodeLutra} offers a scalable, efficient path to high-quality code generation, making smaller open-source models more competitive with leading closed-source alternatives",
    "checked": true,
    "id": "86e360800ae21527ff1f32806b6f6755bae3af08",
    "semantic_title": "codelutra: boosting llm code generation via preference-guided refinement",
    "citation_count": 0,
    "authors": [
      "Leitian Tao",
      "Xiang Chen",
      "Tong Yu",
      "Tung Mai",
      "Ryan A. Rossi",
      "Yixuan Li",
      "Saayan Mitra"
    ]
  },
  "https://openreview.net/forum?id=bpaLYaf6Dp": {
    "title": "Disappearance of Timestep Embedding: A Case Study on Neural ODE and Diffusion Models",
    "volume": "main",
    "abstract": "Dynamical systems are often time-varying, whose modeling requires a function that evolves with respect to time. Recent studies such as the neural ordinary differential equation proposed a time-dependent neural network, which provides a neural network varying with respect to time. However, we claim that the architectural choice to build a time-dependent neural network significantly affects its time-awareness but still lacks sufficient validation in its current states. In this study, we conduct an in-depth analysis of the architecture of neural ordinary differential equations. Here, we report a vulnerability of vanishing timestep embedding, which disables the time-awareness of a time-dependent neural network. Specifically, we find that the ConcatConv operation, which is widely used in neural ordinary differential equations, causes an additive effect of timestep embedding, which is readily canceled out by the subsequent batch normalization. This vanishing timestep embedding also arises for group normalization and is analyzed thoroughly with respect to the number of channels, groups, and relative variance. Furthermore, we find that this vulnerability can also be observed in diffusion models because they employ a similar architecture that incorporates timestep embedding to discriminate between different timesteps during a diffusion process. Our analysis provides a detailed description of this phenomenon as well as several solutions to address the root cause. Through experiments on neural ordinary differential equations and diffusion models, we observed that ensuring alive time-awareness via proposed solutions boosted their performance, such as classification accuracy, FID, and inception score, which implies that their current implementations lack sufficient time-dependency",
    "checked": true,
    "id": "c5bdb357e024895ad0a03d2929ed9248897ba147",
    "semantic_title": "disappearance of timestep embedding: a case study on neural ode and diffusion models",
    "citation_count": 0,
    "authors": [
      "Bum Jun Kim",
      "Yoshinobu Kawahara",
      "Sang Woo Kim"
    ]
  },
  "https://openreview.net/forum?id=GtXSN52nIW": {
    "title": "Sparser, Better, Faster, Stronger: Sparsity Detection for Efficient Automatic Differentiation",
    "volume": "main",
    "abstract": "From implicit differentiation to probabilistic modeling, Jacobian and Hessian matrices have many potential use cases in Machine Learning (ML), but they are viewed as computationally prohibitive. Fortunately, these matrices often exhibit sparsity, which can be leveraged to speed up the process of Automatic Differentiation (AD). This paper presents advances in sparsity detection, previously the performance bottleneck of Automatic Sparse Differentiation (ASD). Our implementation of sparsity detection is based on operator overloading, able to detect both local and global sparsity patterns, and supports flexible index set representations. It is fully automatic and requires no modification of user code, making it compatible with existing ML codebases. Most importantly, it is highly performant, unlocking Jacobians and Hessians at scales where they were considered too expensive to compute. On real-world problems from scientific ML, graph neural networks and optimization, we show significant speed-ups of up to three orders of magnitude. Notably, using our sparsity detection system, ASD outperforms standard AD for one-off computations, without amortization of either sparsity detection or matrix coloring",
    "checked": true,
    "id": "c9eb671650d16a39c2705fd4d5adcc71db1008dc",
    "semantic_title": "sparser, better, faster, stronger: sparsity detection for efficient automatic differentiation",
    "citation_count": 2,
    "authors": [
      "Adrian Hill",
      "Guillaume Dalle"
    ]
  },
  "https://openreview.net/forum?id=IcOBCufqFO": {
    "title": "Harmony: A Joint Self-Supervised and Weakly-Supervised Framework for Learning General Purpose Visual Representations",
    "volume": "main",
    "abstract": "Vision-language contrastive learning frameworks such as CLIP enable learning representations from natural language supervision and provide strong zero-shot classification capabilities. However, due to the nature of the supervisory signal in these paradigms, they lack the ability to learn localized features, leading to degraded performance on dense prediction tasks such as segmentation and detection. On the other hand, self-supervised learning methods have shown the ability to learn granular representations, complementing the high-level features in vision-language training. In this work, we present Harmony, a framework that combines vision-language training with discriminative and generative self-supervision to learn visual features that can be generalized across different downstream vision tasks. Our framework is specifically designed to work on web-scraped data by not relying on negative examples in the self-supervised learning path and addressing the one-to-one correspondence issue using soft CLIP targets generated by an EMA model. Moreover, Harmony optimizes for five different objectives simultaneously, efficiently utilizing the supervision in each data example, making it even more suited in data-constrained settings. We comprehensively evaluate Harmony across various vision downstream tasks and find that it significantly outperforms the baseline CLIP and outperforms the previously leading joint self- and weakly supervised methods, SLIP, MaskCLIP, and DetailCLIP. Specifically, when compared against these methods, Harmony shows superior performance in linear-probing, fine-tuning, and zero-shot classification on ImageNet-1k, semantic segmentation on ADE20K, and both object detection and instance segmentation on MS-COCO, when pre-training a ViT-B on CC3M. We also show that Harmony outperforms SILC on detection, linear and fine-tuning classification, and outperforms other self-supervised learning methods like iBOT and MAE across all tasks evaluated. Our code is publicly available at https://github.com/MohammedSB/Harmony",
    "checked": true,
    "id": "15dcd0029e53c702152a1b657ab4bab3cf9300ff",
    "semantic_title": "harmony: a joint self-supervised and weakly-supervised framework for learning general purpose visual representations",
    "citation_count": 0,
    "authors": [
      "Mohammed Baharoon",
      "Jonathan Klein",
      "Dominik Michels"
    ]
  },
  "https://openreview.net/forum?id=3ECbEZg2If": {
    "title": "Full-Rank Unsupervised Node Embeddings for Directed Graphs via Message Aggregation",
    "volume": "main",
    "abstract": "Linear message-passing models have emerged as compelling alternatives to non-linear graph neural networks for unsupervised node embedding learning, due to their scalability and competitive performance on downstream tasks. However, we identify a fundamental flaw in recently proposed linear models that combine embedding aggregation with concatenation during each message-passing iteration: rank deficiency. A rank-deficient embedding matrix contains column vectors which take arbitrary values, leading to ill-conditioning that degrades downstream task accuracy, particularly in unsupervised tasks such as graph alignment. We deduce that repeated embedding aggregation and concatenation introduces linearly dependent features, causing rank deficiency. To address this, we propose ACC (Aggregate, Compress, Concatenate), a novel model that avoids redundant feature computation by applying aggregation to the messages from the previous iteration, rather than the embeddings. Consequently, ACC generates full-rank embeddings, significantly improving graph alignment accuracy from 10% to 60% compared to rank-deficient embeddings, while also being faster to compute. Additionally, ACC employs directed message-passing and achieves node classification accuracies comparable to state-of-the-art self-supervised graph neural networks on directed graph benchmarks, while also being over 70 times faster on graphs with over 1 million edges",
    "checked": true,
    "id": "a2a896c86ed393239370a51b5ca114d0857c0d9f",
    "semantic_title": "full-rank unsupervised node embeddings for directed graphs via message aggregation",
    "citation_count": 0,
    "authors": [
      "Ciwan Ceylan",
      "Kambiz Ghoorchian",
      "Danica Kragic"
    ]
  },
  "https://openreview.net/forum?id=u4YDVFodYX": {
    "title": "Prior Learning in Introspective VAEs",
    "volume": "main",
    "abstract": "Variational Autoencoders (VAEs) are a popular framework for unsupervised learning and data generation. A plethora of methods have been proposed focusing on improving VAEs, with the incorporation of adversarial objectives and the integration of prior learning mechanisms being prominent directions. When it comes to the former, an indicative instance is the recently introduced family of Introspective VAEs aiming at ensuring that a low likelihood is assigned to unrealistic samples. In this study, we focus on the Soft-IntroVAE (S-IntroVAE), one of only two members of the Introspective VAE family, the other being the original IntroVAE. We select S-IntroVAE for its state-of-the-art status and its training stability. In particular, we investigate the implication of incorporating a multimodal and trainable prior into this S-IntroVAE. Namely, we formulate the prior as a third player and show that when trained in cooperation with the decoder constitutes an effective way for prior learning, which shares the Nash Equilibrium with the vanilla S-IntroVAE. Furthermore, based on a modified formulation of the optimal ELBO in S-IntroVAE, we develop theoretically motivated regularizations, namely (i) adaptive variance clipping to stabilize training when learning the prior and (ii) responsibility regularization to discourage the formation of inactive prior modes. Finally, we perform a series of targeted experiments on a 2D density estimation benchmark and in an image generation setting comprised of the (F)-MNIST and CIFAR-10 datasets demonstrating the effect of prior learning in S-IntroVAE in generation and representation learning",
    "checked": true,
    "id": "f49c5f24c10bc543b751ab128710a0f37ee0c2f3",
    "semantic_title": "prior learning in introspective vaes",
    "citation_count": 0,
    "authors": [
      "Ioannis Athanasiadis",
      "Fredrik Lindsten",
      "Michael Felsberg"
    ]
  },
  "https://openreview.net/forum?id=EDQ8QOGqjr": {
    "title": "Learning Using a Single Forward Pass",
    "volume": "main",
    "abstract": "We propose a learning algorithm to overcome the limitations of traditional backpropagation in resource-constrained environments: Solo Pass Embedded Learning Algorithm (SPELA). SPELA operates with local loss functions to update weights, significantly saving on resources allocated to the propagation of gradients and storing computational graphs while being sufficiently accurate. Consequently, SPELA can closely match backpropagation using less memory. Moreover, SPELA can effectively fine-tune pre-trained image recognition models for new tasks. Further, SPELA is extended with significant modifications to train CNN networks, which we evaluate on CIFAR-10, CIFAR-100, and SVHN 10 datasets, showing equivalent performance compared to backpropagation. Our results indicate that SPELA, with its features such as local learning and early exit, is a potential candidate for learning in resource-constrained edge AI applications",
    "checked": true,
    "id": "52f29792f2901985bd44c78de09e16dcbd258836",
    "semantic_title": "learning using a single forward pass",
    "citation_count": 0,
    "authors": [
      "Aditya Somasundaram",
      "Pushkal Mishra",
      "Ayon Borthakur"
    ]
  },
  "https://openreview.net/forum?id=hQjwDqfSzj": {
    "title": "Multi-objective Bayesian optimization for Likelihood-Free inference in sequential sampling models of decision making",
    "volume": "main",
    "abstract": "Statistical models are often defined by a generative process for simulating synthetic data, but this can lead to intractable likelihoods. Likelihood free inference (LFI) methods enable Bayesian inference to be performed in this case. Extending a popular approach to simulation-efficient LFI for single-source data, we propose Multi-objective Bayesian Optimization for Likelihood Free Inference (MOBOLFI) to perform LFI using multi-source data. MOBOLFI models a multi-dimensional discrepancy between observed and simulated data, using a separate discrepancy for each data source. The use of a multivariate discrepancy allows for approximations to individual data source likelihoods in addition to the joint likelihood, enabling detection of conflicting information and deeper understanding of the importance of different data sources in estimating individual parameters. The adaptive choice of simulation parameters using multi-objective Bayesian optimization ensures simulation efficient approximation of likelihood components for all data sources. We illustrate our approach in sequential sampling models (SSMs), which are widely used in psychology and consumer-behavior modeling. SSMs are often fitted using multi-source data, such as choice and response time. The advantages of our approach are illustrated in comparison with a single discrepancy for an SSM fitted to data assessing preferences of ride-hailing drivers in Singapore to rent electric vehicles",
    "checked": true,
    "id": "ede1395863e3c9e8a41812b9589eff46b248dc27",
    "semantic_title": "multi-objective bayesian optimization for likelihood-free inference in sequential sampling models of decision making",
    "citation_count": 0,
    "authors": [
      "David Chen",
      "Xinwei Li",
      "Eui-Jin Kim",
      "Prateek Bansal",
      "David J Nott"
    ]
  },
  "https://openreview.net/forum?id=FNRdaHz3qN": {
    "title": "Change Point Detection in the Frequency Domain with Statistical Reliability",
    "volume": "main",
    "abstract": "Effective condition monitoring in complex systems requires identifying change points (CPs) in the frequency domain, as the structural changes often arise across multiple frequencies. This paper extends recent advancements in statistically significant CP detection, based on Selective Inference (SI), to the frequency domain. The proposed SI method quantifies the statistical significance of detected CPs in the frequency domain using $p$-values, ensuring that the detected changes reflect genuine structural shifts in the target system. We address two major technical challenges to achieve this. First, we extend the existing SI framework to the frequency domain by appropriately utilizing the properties of discrete Fourier transform (DFT). Second, we develop an SI method that provides valid $p$-values for CPs where changes occur across multiple frequencies. Experimental results demonstrate that the proposed method reliably identifies genuine CPs with strong statistical guarantees, enabling more accurate root-cause analysis in the frequency domain of complex systems",
    "checked": true,
    "id": "e8d2401dc2c1d1f0f8df6bd15cf1402c36343ec5",
    "semantic_title": "change point detection in the frequency domain with statistical reliability",
    "citation_count": 1,
    "authors": [
      "Akifumi Yamada",
      "Tomohiro Shiraishi",
      "Shuichi Nishino",
      "Teruyuki Katsuoka",
      "Kouichi Taji",
      "Ichiro Takeuchi"
    ]
  },
  "https://openreview.net/forum?id=HBZoXjUAqV": {
    "title": "Recall and Refine: A Simple but Effective Source-free Open- set Domain Adaptation Framework",
    "volume": "main",
    "abstract": "Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source domain to an unlabeled target domain, where novel classes — also referred to as target-private unknown classes — are present. Source-free Open-set Domain Adaptation (SF-OSDA) methods address OSDA without accessing labeled source data, making them particularly relevant under privacy constraints. However, SF-OSDA presents significant challenges due to distribution shifts and the introduction of novel classes. Existing SF-OSDA methods typically rely on thresholding the prediction entropy of a sample to identify it as either a known or unknown class, but fail to explicitly learn discriminative features for the target-private unknown classes. We propose Recall and Refine (RRDA), a novel SF-OSDA framework designed to address these limitations by explicitly learning features for target-private unknown classes. RRDA employs a two-stage process. First, we enhance the model's capacity to recognize unknown classes by training a target classifier with an additional decision boundary, guided by synthetic samples generated from target domain features. This enables the classifier to effectively separate known and unknown classes. Second, we adapt the entire model to the target domain, addressing both domain shifts and distinguishability to unknown classes. Any off-the-shelf source-free domain adaptation method (e.g.\\ SHOT, AaD) can be seamlessly integrated into our framework at this stage. Extensive experiments on three benchmark datasets demonstrate that RRDA significantly outperforms existing SF-OSDA and OSDA methods",
    "checked": true,
    "id": "c4ae20b4060e6022d29f865d219300039444b458",
    "semantic_title": "recall and refine: a simple but effective source-free open- set domain adaptation framework",
    "citation_count": 0,
    "authors": [
      "Ismail Nejjar",
      "Hao Dong",
      "Olga Fink"
    ]
  },
  "https://openreview.net/forum?id=ylUVRikhTL": {
    "title": "Mixed-View Panorama Synthesis using Geospatially Guided Diffusion",
    "volume": "main",
    "abstract": "We introduce the task of mixed-view panorama synthesis, where the goal is to synthesize a novel panorama given a small set of input panoramas and a satellite image of the area. This contrasts with previous work which only uses input panoramas (same-view synthesis), or an input satellite image (cross-view synthesis). We argue that the mixed-view setting is the most natural to support panorama synthesis for arbitrary locations worldwide. A critical challenge is that the spatial coverage of panoramas is uneven, with few panoramas available in many regions of the world. We introduce an approach that utilizes diffusion-based modeling and an attention-based architecture for extracting information from all available input imagery. Experimental results demonstrate the effectiveness of our proposed method. In particular, our model can handle scenarios when the available panoramas are sparse or far from the location of the panorama we are attempting to synthesize",
    "checked": true,
    "id": "9f52715bd5bf9328e0565e9fcbbed323278d596a",
    "semantic_title": "mixed-view panorama synthesis using geospatially guided diffusion",
    "citation_count": 1,
    "authors": [
      "Zhexiao Xiong",
      "Xin Xing",
      "Scott Workman",
      "Subash Khanal",
      "Nathan Jacobs"
    ]
  },
  "https://openreview.net/forum?id=S6fe4aH6YA": {
    "title": "Link Prediction with Relational Hypergraphs",
    "volume": "main",
    "abstract": "Link prediction with knowledge graphs has been thoroughly studied in graph machine learning, leading to a rich landscape of graph neural network architectures with successful applications. Nonetheless, it remains challenging to transfer the success of these architectures to inductive link prediction with relational hypergraphs, where the task is over $k$-ary relations, substantially harder than link prediction on knowledge graphs with binary relations only. In this paper, we propose a framework for link prediction with relational hypergraphs, empowering applications of graph neural networks on fully relational structures. Theoretically, we conduct a thorough analysis of the expressive power of the resulting model architectures via corresponding relational Weisfeiler-Leman algorithms and also via logical expressiveness. Empirically, we validate the power of the proposed model architectures on various relational hypergraph benchmarks. The resulting model architectures substantially outperform every baseline for inductive link prediction and also lead to competitive results for transductive link prediction",
    "checked": true,
    "id": "d5591f0ffa407eae914b45e5329768f8ce553862",
    "semantic_title": "link prediction with relational hypergraphs",
    "citation_count": 5,
    "authors": [
      "Xingyue Huang",
      "Miguel Romero Orth",
      "Pablo Barcelo",
      "Michael M. Bronstein",
      "Ismail Ilkan Ceylan"
    ]
  },
  "https://openreview.net/forum?id=DDUsc1lD27": {
    "title": "Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization",
    "volume": "main",
    "abstract": "In Reinforcement Learning (RL), agents have no incentive to exhibit predictable trajectories, and are often pushed (through e.g. policy entropy regularisation) to randomise their actions in favor of exploration. This lack of predictability awareness often makes it challenging for other agents and humans to predict an agent's trajectories, possibly triggering unsafe scenarios (e.g. in human-robot interaction). We propose a novel method to induce predictable trajectories in RL agents, termed Predictability-Aware RL (PARL), employing the agent's trajectory entropy rate to quantify predictability. Our method maximizes a linear combination of a standard discounted reward and the negative entropy rate, thus trading off optimality with predictability. We show how the entropy rate can be formally cast as an average reward, how entropy-rate value functions can be estimated from a learned model and incorporate this in policy-gradient algorithms, and demonstrate how this approach produces predictable (near-optimal) policies in tasks inspired by human-robot use-cases",
    "checked": true,
    "id": "8aaca0d0fff646acf187628d679844b4bbfeee70",
    "semantic_title": "predictable reinforcement learning dynamics through entropy rate minimization",
    "citation_count": 3,
    "authors": [
      "Daniel Jarne Ornia",
      "Giannis Delimpaltadakis",
      "Jens Kober",
      "Javier Alonso-Mora"
    ]
  },
  "https://openreview.net/forum?id=FVFqrxeF8e": {
    "title": "Efficient and Accurate Optimal Transport with Mirror Descent and Conjugate Gradients",
    "volume": "main",
    "abstract": "We propose Mirror Descent Optimal Transport (MDOT), a novel method for solving discrete optimal transport (OT) problems with high precision, by unifying temperature annealing in entropic-regularized OT (EOT) with mirror descent techniques. In this framework, temperature annealing produces a sequence of EOT dual problems, whose solution gradually gets closer to the solution of the original OT problem. We solve each problem efficiently using a GPU-parallel nonlinear conjugate gradients algorithm (PNCG) that outperforms traditional Sinkhorn iterations under weak regularization. Moreover, our investigation also reveals that the theoretical convergence rate of Sinkhorn iterations can exceed existing non-asymptotic bounds when its stopping criterion is tuned in a manner analogous to MDOT. Our comprehensive ablation studies of MDOT-PNCG affirm its robustness across a wide range of algorithmic parameters. Benchmarking on 24 problem sets of size $n=4096$ in a GPU environment demonstrate that our method attains high-precision, feasible solutions significantly faster than a representative set of existing OT solvers—including accelerated gradient methods and advanced Sinkhorn variants—in both wall-clock time and number of operations. Empirical convergence rates range between $O(n^2 \\varepsilon^{-1/4})$ and $O(n^2 \\varepsilon^{-1})$, where $\\varepsilon$ is the optimality gap. For problem sizes up to $n=16\\,384$, the empirical runtime scales as $\\widetilde{O}(n^2)$ for moderate precision and as $\\widetilde{O}(n^{5/2})$ at worst for high precision. These findings establish MDOT-PNCG as a compelling alternative to current OT solvers, particularly in challenging weak-regularization regimes",
    "checked": true,
    "id": "aeae241d9dbd868d00c1e982f6c8e9664cf31c38",
    "semantic_title": "efficient and accurate optimal transport with mirror descent and conjugate gradients",
    "citation_count": 3,
    "authors": [
      "Mete Kemertas",
      "Allan Douglas Jepson",
      "Amir-massoud Farahmand"
    ]
  },
  "https://openreview.net/forum?id=p7jQEf3wlh": {
    "title": "Efficient Hardware Scaling and Diminishing Returns in Large-Scale Training of Language Models",
    "volume": "main",
    "abstract": "To train the exceedingly large neural networks required in modern applications, such as large language models (LLMs), model training is distributed across tens of thousands of hardware accelerators (e.g. GPUs), requiring orchestration of computation and communication across large computing clusters. In this work, we demonstrate that careful consideration of hardware configuration and parallelization strategy is critical for effective (i.e. compute- and cost-efficient) scaling of model training. We conduct an extensive empirical study of the performance of large-scale LLM training workloads across model size, hardware configurations, and distributed parallelization strategies with current best practices. In experiments with model sizes up to 70B parameters and utilizing up to 2048 H100 GPUs, we demonstrate that: (1) Naive scale out with Fully Sharded Data Parallelism (FSDP) incurs communication overhead which leads parallelization strategies previously thought to be sub-optimal in fact become preferable; and (2) scaling the total number of accelerators for training quickly yields diminishing returns even when hardware and parallelization strategies are properly optimized, implying poor marginal performance per additional unit of power or GPU-hour",
    "checked": true,
    "id": "49819c58350056de622da083fdfb80d716c823a2",
    "semantic_title": "efficient hardware scaling and diminishing returns in large-scale training of language models",
    "citation_count": 0,
    "authors": [
      "Jared Fernandez",
      "Luca Wehrstedt",
      "Leonid Shamis",
      "Mostafa Elhoushi",
      "Kalyan Saladi",
      "Yonatan Bisk",
      "Emma Strubell",
      "Jacob Kahn"
    ]
  },
  "https://openreview.net/forum?id=cqDH0e6ak2": {
    "title": "Flow map matching with stochastic interpolants: A mathematical framework for consistency models",
    "volume": "main",
    "abstract": "Generative models based on dynamical equations such as flows and diffusions offer exceptional sample quality, but require computationally expensive numerical integration during inference. The advent of consistency models has enabled efficient one-step or few-step generation, yet despite their practical success, a systematic understanding of their design has been hindered by the lack of a comprehensive theoretical framework. Here we introduce Flow Map Matching (FMM), a principled framework for learning the two-time flow map of an underlying dynamical generative model, thereby providing this missing mathematical foundation. Leveraging stochastic interpolants, we propose training objectives both for distillation from a pre-trained velocity field and for direct training of a flow map over an interpolant or a forward diffusion process. Theoretically, we show that FMM unifies and extends a broad class of existing approaches for fast sampling, including consistency models, consistency trajectory models, and progressive distillation. Experiments on CIFAR-10 and ImageNet-32 highlight that our approach can achieve sample quality comparable to flow matching while reducing generation time by a factor of 10-20",
    "checked": true,
    "id": "38c3acbe4531a123acde40c9d93abc63d804c3f9",
    "semantic_title": "flow map matching with stochastic interpolants: a mathematical framework for consistency models",
    "citation_count": 6,
    "authors": [
      "Nicholas Matthew Boffi",
      "Michael Samuel Albergo",
      "Eric Vanden-Eijnden"
    ]
  },
  "https://openreview.net/forum?id=qVUEuhlaEa": {
    "title": "Explicit Personalization and Local Training: Double Communication Acceleration in Federated Learning",
    "volume": "main",
    "abstract": "Federated Learning is an evolving machine learning paradigm, in which multiple clients perform computations based on their individual private data, interspersed by communication with a remote server. A common strategy to curtail communication costs is Local Training, which consists in performing multiple local stochastic gradient descent steps between successive communication rounds. However, the conventional approach to local training overlooks the practical necessity for client-specific personalization, a technique to tailor local models to individual needs. We introduce Scafflix, a novel algorithm that efficiently integrates explicit personalization with local training. This innovative approach benefits from these two techniques, thereby achieving doubly accelerated communication, as we demonstrate both in theory and practice",
    "checked": true,
    "id": "4f736c051af928ef65cfef2ebc123071f781a37b",
    "semantic_title": "explicit personalization and local training: double communication acceleration in federated learning",
    "citation_count": 5,
    "authors": [
      "Kai Yi",
      "Laurent Condat",
      "Peter Richtárik"
    ]
  },
  "https://openreview.net/forum?id=z3RIiidJgD": {
    "title": "MemBench: Memorized Image Trigger Prompt Dataset for Diffusion Models",
    "volume": "main",
    "abstract": "Diffusion models have achieved remarkable success in Text-to-Image generation tasks, leading to the development of many commercial models. However, recent studies have reported that diffusion models often repeatedly generate memorized images in train data when triggered by specific prompts, potentially raising social issues ranging from copyright to privacy concerns. To sidestep the memorization, recent studies have been conducted to develop memorization mitigation methods for diffusion models. Nevertheless, the lack of benchmarks hinders the assessment of the true effectiveness of these methods. In this work, we present MemBench, the first benchmark for evaluating image memorization mitigation methods. Our benchmark includes a large number of memorized image trigger prompts in various Text-to-Image diffusion models. Furthermore, in contrast to the prior work evaluating mitigation performance only on trigger prompts, we present metrics evaluating on both trigger prompts and general prompts, so that we can see whether mitigation methods address the memorization issue while maintaining performance for general prompts. Through our MemBench evaluation, we revealed that existing memorization mitigation methods notably degrade the overall performance of diffusion models and need to be further developed",
    "checked": true,
    "id": "83607beffed18051b36610958602e217b54cb8c5",
    "semantic_title": "membench: memorized image trigger prompt dataset for diffusion models",
    "citation_count": 0,
    "authors": [
      "Chunsan Hong",
      "Tae-Hyun Oh",
      "Minhyuk Sung"
    ]
  },
  "https://openreview.net/forum?id=3HKNwejEEq": {
    "title": "NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document VQA",
    "volume": "main",
    "abstract": "The Privacy Preserving Federated Learning Document VQA (PFL-DocVQA) competition challenged the community to develop provably private and communication-efficient solutions in a federated setting for a real-life use case: invoice processing. The competition introduced a dataset of real invoice documents, along with associated questions and answers requiring information extraction and reasoning over the document images. Thereby, it brings together researchers and expertise from the document analysis, privacy, and federated learning communities. Participants fine-tuned a pre-trained, state-of-the-art Document Visual Question Answering model provided by the organizers for this new domain, mimicking a typical federated invoice processing setup. The base model is a multi-modal generative language model, and sensitive information could be exposed through either the visual or textual input modality. Participants proposed elegant solutions to reduce communication costs while maintaining a minimum utility threshold in track 1 and to protect all information from each document provider using differential privacy in track 2. The competition served as a new testbed for developing and testing private federated learning methods, simultaneously raising awareness about privacy within the document image analysis and recognition community. Ultimately, the competition analysis provides best practices and recommendations for successfully running privacy-focused federated learning challenges in the future",
    "checked": true,
    "id": "66aba2df8c6994aefe8136d98d93eba63f36f385",
    "semantic_title": "neurips 2023 competition: privacy preserving federated learning document vqa",
    "citation_count": 0,
    "authors": [
      "Marlon Tobaben",
      "Mohamed Ali Souibgui",
      "Rubèn Tito",
      "Khanh Nguyen",
      "Raouf Kerkouche",
      "Kangsoo Jung",
      "Joonas Jälkö",
      "Lei Kang",
      "Andrey Barsky",
      "Vincent Poulain d'Andecy",
      "Aurélie JOSEPH",
      "Aashiq Muhamed",
      "Kevin Kuo",
      "Virginia Smith",
      "Yusuke Yamasaki",
      "Takumi Fukami",
      "Kenta Niwa",
      "Iifan Tyou",
      "Hiro Ishii",
      "Rio Yokota",
      "Ragul N",
      "Rintu Kutum",
      "Josep Llados",
      "Ernest Valveny",
      "Antti Honkela",
      "Mario Fritz",
      "Dimosthenis Karatzas"
    ]
  },
  "https://openreview.net/forum?id=R2rasAEPVi": {
    "title": "Leopard: A Vision Language Model for Text-Rich Multi- Image Tasks",
    "volume": "main",
    "abstract": "Text-rich images, where text serves as the central visual element guiding the overall understanding, are prevalent in real-world applications, such as presentation slides, scanned documents, and webpage snapshots. Tasks involving multiple text-rich images are especially challenging, as they require not only understanding the content of individual images but reasoning about inter-relationships and logical flows across multiple visual inputs. Despite the importance of these scenarios, current multimodal large language models (MLLMs) struggle to handle such tasks due to two key challenges: (1) the scarcity of high-quality instruction tuning datasets for text-rich multi-image scenarios, and (2) the difficulty in balancing image resolution with visual feature sequence length. To address these challenges, we propose Leopard, a MLLM designed specifically for handling vision-language tasks involving multiple text-rich images. First, we curated about one million high-quality multimodal instruction-tuning data, tailored to text-rich, multi-image scenarios. Second, we proposed an adaptive high-resolution multi-image encoding module to dynamically optimize the allocation of visual sequence length based on the original aspect ratios and resolutions of images. Experiments on a diverse set of benchmarks reveal that our model consistently outperforms state-of-the-art systems, such as Llama-3.2 and Qwen2-VL, in challenging text-rich, multi-image evaluations. Remarkably, our approach achieves outstanding performance using only 1.2M fully open-sourced training instances, outperforming models that rely on large-scale in-house data, highlighting its efficiency and effectiveness. Our code and data are available at https://anonymous.4open.science/r/Leopard-908F",
    "checked": false,
    "id": "0db2af5b6cc74e5254c10c54f5ce9af67cbe491e",
    "semantic_title": "leopard: a vision language model for text-rich multi-image tasks",
    "citation_count": 7,
    "authors": [
      "Mengzhao Jia",
      "Wenhao Yu",
      "Kaixin Ma",
      "Tianqing Fang",
      "Zhihan Zhang",
      "Siru Ouyang",
      "Hongming Zhang",
      "Dong Yu",
      "Meng Jiang"
    ]
  },
  "https://openreview.net/forum?id=bAM8y3Hm0p": {
    "title": "Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity Resolution",
    "volume": "main",
    "abstract": "The entity resolution problem requires finding pairs across datasets that belong to different owners but refer to the same entity in the real world. To train and evaluate solutions (either rule-based or machine-learning-based) to the entity resolution problem, generating a ground truth dataset with entity pairs or clusters is needed. However, such a data annotation process involves humans as domain oracles to review the plaintext data for all candidate record pairs from different parties, which inevitably infringes the privacy of data owners, especially in privacy-sensitive cases like medical records. To the best of our knowledge, there is no prior work on privacy-preserving ground truth labeling in the context of entity resolution. We propose a novel blind annotation protocol based on homomorphic encryption that allows domain oracles to collaboratively label ground truth without sharing data in plaintext with other parties. In addition, we design a domain-specific, user-friendly language that conceals the complex underlying homomorphic encryption circuits, making it more accessible and easier for users to adopt this technique. The empirical experiments indicate the feasibility of our privacy-preserving protocol (f-measure on average achieves more than 90\\% compared with the real ground truth)",
    "checked": true,
    "id": "16e2a0710937c2068823b0df7bac1b1862f36519",
    "semantic_title": "labeling without seeing? blind annotation for privacy-preserving entity resolution",
    "citation_count": 1,
    "authors": [
      "Yixiang Yao",
      "Weizhao Jin",
      "Srivatsan Ravi"
    ]
  },
  "https://openreview.net/forum?id=B0E2yjrNb8": {
    "title": "Dynamic Schwartz-Fourier Neural Operator for Enhanced Expressive Power",
    "volume": "main",
    "abstract": "Recently, neural operators have emerged as a prevailing approach for learning discretization-invariant mappings between function spaces. A particular example is the Fourier Neural Operator (FNO), which constrains integral kernels to be convolutions and learns the kernel directly in the frequency domain. Due to the capacity of Fourier transforms to effectively reduce the dimensionality and preserve information, FNOs demonstrate superior performance in terms of both efficiency and accuracy. In FNOs, the convolution kernel is fixed as a point-wise multiplication in the frequency domain; however, these translation-invariant kernels might limit the expressiveness of FNOs. For instance, if the underlying system lacks translational symmetries, the kernels learned by the FNO will still exhibit translational invariance, thereby limiting the model's expressive power. We propose a dynamic Schwartz operator that induces interactions between modes to enhance the expressiveness of FNOs. In this work, we introduce a novel approach that equips FNOs with Schwartz operators to learn dynamic kernels, termed Dynamic Kernel Fourier Neural Operators (DSFNOs). By incorporating this dynamic mechanism, our model gains the ability to capture relevant frequency information patterns, facilitating a better understanding and representation of complex physical phenomena. Through experiments, we demonstrate that DSFNOs can improve FNOs on a range of tasks, highlighting the effectiveness of our proposed approach. The code is available at https://github.com/wenhangao21/TMLR25_DSFNO",
    "checked": true,
    "id": "3ead9181cfec415c12a66d7dca0d12f1e42c2bdf",
    "semantic_title": "dynamic schwartz-fourier neural operator for enhanced expressive power",
    "citation_count": 0,
    "authors": [
      "Wenhan Gao",
      "Jian Luo",
      "Ruichen Xu",
      "Yi Liu"
    ]
  },
  "https://openreview.net/forum?id=z27hb0rmLT": {
    "title": "Normality-Guided Distributional Reinforcement Learning for Continuous Control",
    "volume": "main",
    "abstract": "Learning a predictive model of the mean return, or value function, plays a critical role in many reinforcement learning algorithms. Distributional reinforcement learning (DRL) has been shown to improve performance by modeling the value distribution, not just the mean. We study the value distribution in several continuous control tasks and find that the learned value distribution is empirically quite close to normal. We design a method that exploits this property, employing variances predicted from a variance network, along with returns, to analytically compute target quantile bars representing a normal for our distributional value function. In addition, we propose a policy update strategy based on the correctness as measured by structural characteristics of the value distribution not present in the standard value function. The approach we outline is compatible with many DRL structures. We use two representative on-policy algorithms, PPO and TRPO, as testbeds. Our method yields statistically significant improvements in 10 out of 16 continuous task settings, while utilizing a reduced number of weights and achieving faster training time compared to an ensemble-based method for quantifying value distribution uncertainty",
    "checked": false,
    "id": "298c6554556788ee08b2baa3feeeeb8612c1936a",
    "semantic_title": "hierarchical reinforcement learning with uncertainty-guided diffusional subgoals",
    "citation_count": 0,
    "authors": [
      "Ju-Seung Byun",
      "Andrew Perrault"
    ]
  },
  "https://openreview.net/forum?id=VdW9SkALSd": {
    "title": "Mathematical Characterization of Better-than-Random Multiclass Models",
    "volume": "main",
    "abstract": "A binary supervised model outperforms chance if and only if the determinant of the confusion matrix is positive. This is equivalent to saying that the associated point in the ROC space is above the random guessing line. This also means that Youden's J, Cohen's $\\kappa$ and Matthews' correlation coefficient are positive. We extend these results to any number of classes: for a target variable with $m \\geq 2$ classes, we show that a model does better than chance if and only if the entries of the confusion matrix verify $m(m-1)$ homogeneous polynomial inequalities of degree 2, which can be expressed using generalized likelihood ratios. We also obtain a more theoretical formulation: a model does better than chance if and only if it is a maximum likelihood estimator of the target variable. When this is the case, we find that the multiclass versions of the previous metrics remain positive. If $m>2$, we notice that no-skill classifiers are only a small part of the topological boundary between better-than-random models and bad models. For $m=3$, we show that bad models occupy exactly 90\\% of the ROC space, far more than the 50\\% of the two-class problems. Finally, we propose to define weak multiclass classifiers by conditions on these generalized likelihood ratios",
    "checked": true,
    "id": "42b73c905d3487dda36a703d6c60351ef20da101",
    "semantic_title": "mathematical characterization of better-than-random multiclass models",
    "citation_count": 0,
    "authors": [
      "Sébastien Foulle"
    ]
  },
  "https://openreview.net/forum?id=3qmnxysNbi": {
    "title": "To Be Greedy, or Not to Be – That Is the Question for Population Based Training Variants",
    "volume": "main",
    "abstract": "Achieving excellent results with neural networks requires careful hyperparameter tuning, which can be automated via hyperparameter optimization algorithms such as Population Based Training (PBT). PBT stands out for its capability to efficiently optimize hyperparameter schedules in parallel and within the wall-clock time of training a single network. Several PBT variants have been proposed that improve performance in the experimental settings considered in the associated publications. However, the experimental settings and tasks vary across publications, while the best previous PBT variant is not always included in the comparisons, thus making the relative performance of PBT variants unclear. In this work, we empirically evaluate five single-objective PBT variants on a set of image classification and reinforcement learning tasks with different setups (such as increasingly large search spaces). We find that the Bayesian Optimization (BO) variants of PBT tend to behave greedier than the non-BO ones, which is beneficial when aggressively pursuing short-term gains improves long-term performance and harmful otherwise. This is a previously overlooked caveat to the reported improvements of the BO PBT variants. Examining their theoretical properties, we find that the returns of BO PBT variants are guaranteed to asymptotically approach the returns of the greedy hyperparameter schedule (rather than the optimal one, as claimed in prior work). Together with our empirical results, this leads us to conclude that there is currently no single best PBT variant capable of outperforming others both when pursuing short-term gains is helpful in the long term, and when it is harmful",
    "checked": false,
    "id": "e30597e72f806fe521e3d8c2d86d85ccc5d7bcec",
    "semantic_title": "to be greedy, or not to be - that is the question for population based training variants",
    "citation_count": 0,
    "authors": [
      "Alexander Chebykin",
      "Tanja Alderliesten",
      "Peter Bosman"
    ]
  },
  "https://openreview.net/forum?id=XPEEsKneKs": {
    "title": "Ensemble Kalman Diffusion Guidance: A Derivative-free Method for Inverse Problems",
    "volume": "main",
    "abstract": "When solving inverse problems, one increasingly popular approach is to use pre-trained diffusion models as plug-and-play priors. This framework can accommodate different forward models without re-training while preserving the generative capability of diffusion models. Despite their success in many imaging inverse problems, most existing methods rely on privileged information such as derivative, pseudo-inverse, or full knowledge about the forward model. This reliance poses a substantial limitation that restricts their use in a wide range of problems where such information is unavailable, such as in many scientific applications. We propose Ensemble Kalman Diffusion Guidance (EnKG), a derivative-free approach that can solve inverse problems by only accessing forward model evaluations and a pre-trained diffusion model prior. We study the empirical effectiveness of EnKG across various inverse problems, including scientific settings such as inferring fluid flows and astronomical objects, which are highly non-linear inverse problems that often only permit black-box access to the forward model. We open-source our code at https://github.com/devzhk/enkg-pytorch",
    "checked": true,
    "id": "ffde2508da9e9e1dc7e571c57c4f84005813265f",
    "semantic_title": "ensemble kalman diffusion guidance: a derivative-free method for inverse problems",
    "citation_count": 6,
    "authors": [
      "Hongkai Zheng",
      "Wenda Chu",
      "Austin Wang",
      "Nikola Borislavov Kovachki",
      "Ricardo Baptista",
      "Yisong Yue"
    ]
  },
  "https://openreview.net/forum?id=5EXrH2h3I5": {
    "title": "A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models",
    "volume": "main",
    "abstract": "Few-shot semantic segmentation (FSS) is a crucial challenge in computer vision, driving extensive research into a diverse range of methods, from advanced meta-learning techniques to simple transfer learning baselines. With the emergence of vision foundation models (VFM) serving as generalist feature extractors, we seek to explore the adaptation of these models for FSS. While current FSS benchmarks focus on adapting pre-trained models to new tasks with few images, they emphasize in-domain generalization, making them less suitable for VFM trained on large-scale web datasets. To address this, we propose a novel realistic benchmark with a simple and straightforward adaptation process tailored for this task. Using this benchmark, we conduct a comprehensive comparative analysis of prominent VFM and semantic segmentation models. To evaluate their effectiveness, we leverage various adaption methods, ranging from linear probing to parameter efficient fine-tuning (PEFT) and full fine-tuning. Our findings show that models designed for segmentation can be outperformed by self-supervised (SSL) models. On the other hand, while PEFT methods yields competitive performance, they provide little discrepancy in the obtained results compared to other methods, highlighting the critical role of the feature extractor in determining results. To our knowledge, this is the first study on the adaptation of VFM for FSS",
    "checked": true,
    "id": "83d98d263613df9dd78d66a289d5d849c71cb1f9",
    "semantic_title": "a novel benchmark for few-shot semantic segmentation in the era of foundation models",
    "citation_count": 7,
    "authors": [
      "Reda Bensaid",
      "Vincent Gripon",
      "François Leduc-Primeau",
      "Lukas Mauch",
      "Ghouthi BOUKLI HACENE",
      "Fabien Cardinaux"
    ]
  },
  "https://openreview.net/forum?id=7aJxaPg30d": {
    "title": "Extending Graph Condensation to Multi-Label Datasets: A Benchmark Study",
    "volume": "main",
    "abstract": "As graph data grows increasingly complicated, training graph neural networks (GNNs) on large-scale datasets presents significant challenges, including computational resource constraints, data redundancy, and transmission inefficiencies. While existing graph condensation techniques have shown promise in addressing these issues, they are predominantly designed for single-label datasets, where each node is associated with a single class label. However, many real-world applications, such as social network analysis and bioinformatics, involve multi-label graph datasets, where one node can have various related labels. To deal with this problem, we extend traditional graph condensation approaches to accommodate multi-label datasets by introducing modifications to synthetic dataset initialization and condensing optimization. Through experiments on eight real-world multi-label graph datasets, we prove the effectiveness of our method. In the experiment, the GCond framework, combined with K-Center initialization and binary cross-entropy loss (BCELoss), generally achieves the best performance. This benchmark for multi-label graph condensation not only enhances the scalability and efficiency of GNNs for multi-label graph data but also offers substantial benefits for diverse real-world applications",
    "checked": true,
    "id": "cd9a56e56f037bc962043448b3fe007f2f72a4ce",
    "semantic_title": "extending graph condensation to multi-label datasets: a benchmark study",
    "citation_count": 1,
    "authors": [
      "Liangliang Zhang",
      "Haoran Bao",
      "Yao Ma"
    ]
  },
  "https://openreview.net/forum?id=pvtgffHtJm": {
    "title": "Diffusion Model Predictive Control",
    "volume": "main",
    "abstract": "We propose Diffusion Model Predictive Control (D-MPC), a novel MPC approach that learns a multi-step action proposal and a multi-step dynamics model, both using diffusion models, and combines them for use in online MPC. On the popular D4RL benchmark, we show performance that is significantly better than existing model-based offline planning methods using MPC (e.g. MBOP) and competitive with state-of-the-art (SOTA) model-based and model-free reinforcement learning methods. We additionally illustrate D-MPC's ability to optimize novel reward functions at run time and adapt to novel dynamics, and highlight its advantages compared to existing diffusion-based planning baselines",
    "checked": true,
    "id": "36bef66e80409f033c07df3c9d973cf03f76b922",
    "semantic_title": "diffusion model predictive control",
    "citation_count": 12,
    "authors": [
      "Guangyao Zhou",
      "Sivaramakrishnan Swaminathan",
      "Rajkumar Vasudeva Raju",
      "J Swaroop Guntupalli",
      "Wolfgang Lehrach",
      "Joseph Ortiz",
      "Antoine Dedieu",
      "Miguel Lazaro-Gredilla",
      "Kevin Patrick Murphy"
    ]
  },
  "https://openreview.net/forum?id=aFAMPSmNHR": {
    "title": "Do Think Tags Really Help LLMs Plan? A Critical Evaluation of ReAct-Style Prompting",
    "volume": "main",
    "abstract": "The reasoning abilities of Large Language Models (LLMs) remain a topic of considerable interest and debate. Among the original papers arguing for emergent reasoning abilities of LLMs, ReAct became particularly popular by claiming to tease out LLM reasoning abilities with special prompting involving \"interleaving reasoning trace with action execution\". In this paper, we critically examine the claims of ReAct style prompting for planning and sequential decision-making problems. By introducing systematic variations to the input prompt, we perform a sensitivity analysis along the original claims of ReAct. Our experiments in AlfWorld and WebShop, domains that were used in the original ReAct work, show that the performance is minimally influenced by the interleaved reasoning trace or by the content of these generated reasoning traces. Instead, the performance of LLMs is primarily driven by the unreasonably high degree of similarity between input example tasks and queries, with shockingly little ability to generalize. In addition to raising questions on claims about reasoning abilities, this lack of generalization also implicitly forces the prompt designer to provide instance-specific examples, significantly increasing the cognitive burden on the human. Our empirical results show that the perceived reasoning abilities of LLMs stem from the exemplar-query similarity and approximate retrieval rather than any inherent reasoning abilities, thereby leading to severe lack of generalization beyond the few-shot examples given in the prompts. Our code and prompt settings can be found here on GitHub",
    "checked": true,
    "id": "1fd6c7bba05cde0a9c7f7898a56e7b5ecfdbd684",
    "semantic_title": "do think tags really help llms plan? a critical evaluation of react-style prompting",
    "citation_count": 1,
    "authors": [
      "Siddhant Bhambri",
      "Mudit Verma",
      "Subbarao Kambhampati"
    ]
  },
  "https://openreview.net/forum?id=3q1bUIHTJK": {
    "title": "Multi-Attribute Constraint Satisfaction via Language Model Rewriting",
    "volume": "main",
    "abstract": "Obeying precise constraints on top of multiple external attributes is a common computational problem underlying seemingly different domains, from controlled text generation to protein engineering. Existing language model (LM) controllability methods for multi-attribute constraint satisfaction often rely on specialized architectures or gradient-based classifiers, limiting their flexibility to work with arbitrary black-box evaluators and pretrained models. Current general-purpose large language models, while capable, cannot achieve fine-grained multi-attribute control over external attributes. Thus, we create Multi-Attribute Constraint Satisfaction (MACS), a generalized method capable of finetuning language models on any sequential domain to satisfy user-specified constraints on multiple external real-value attributes. Our method trains LMs as editors by sampling diverse multi-attribute edit pairs from an initial set of paraphrased outputs. During inference, LM iteratively improves upon its previous solution to satisfy constraints for all attributes by leveraging our designed constraint satisfaction reward. We additionally experiment with reward-weighted behavior cloning to further improve the constraint satisfaction rate of LMs. To evaluate our approach, we present a new Fine-grained Constraint Satisfaction (FineCS) benchmark, featuring two challenging tasks: (1) Text Style Transfer, where the goal is to simultaneously modify the sentiment and complexity of reviews, and (2) Protein Design, focusing on modulating fluorescence and stability of Green Fluorescent Proteins (GFP). Our empirical results show that MACS achieves the highest threshold satisfaction in both FineCS tasks, outperforming strong domain-specific baselines. Our work opens new avenues for generalized and real-value multi-attribute control, with implications for diverse applications spanning natural language processing and bioinformatics",
    "checked": true,
    "id": "49028e5441fdedd27b50b1c71eb8c48cba28d56c",
    "semantic_title": "multi-attribute constraint satisfaction via language model rewriting",
    "citation_count": 0,
    "authors": [
      "Ashutosh Baheti",
      "Debanjana Chakraborty",
      "Faeze Brahman",
      "Ronan Le Bras",
      "Ximing Lu",
      "Nouha Dziri",
      "Yejin Choi",
      "Mark Riedl",
      "Maarten Sap"
    ]
  },
  "https://openreview.net/forum?id=0jhoriH9yA": {
    "title": "AttentionSmithy: A Modular Framework for Rapid Transformer Development",
    "volume": "main",
    "abstract": "Transformer architectures have revolutionized a broad spectrum of AI applications by leveraging attention mechanisms for parallelized and long-range sequence processing. Despite their remarkable success, building and customizing transformers remains prohibitively complex for many domain experts who lack deep knowledge of low-level implementations. We introduce AttentionSmithy, a modular software package that lowers the barrier to transformer innovation by decomposing key components---attention modules, feed-forward networks, normalization layers, and positional encodings---into reusable building blocks. By disentangling architectural elements into well-defined interfaces, users can rapidly prototype, adapt, and evaluate transformer variants without extensive coding overhead. Our framework currently supports four distinct positional encoding strategies (sinusoidal, learned, rotary, and ALiBi), offers modular integration of multiple attention methods (including standard attention, Longformer, and Linformer), and integrates seamlessly with neural architecture search (NAS) for automated design exploration. The system is designed to support future extensions with minimal overhead. We validate AttentionSmithy by replicating the original ``Attention Is All You Need'' transformer under resource constraints, demonstrating robust performance on a machine translation task. Leveraging the package's integrated NAS capability, we identified an optimized model configuration that outperformed our baseline, demonstrating the framework's effectiveness for automated architecture search and model improvement. We further illustrate AttentionSmithy's adaptability through gene-specific modeling, where a variant of a BERT-style architecture achieves over 95\\% accuracy on downstream cell type classification tasks using ranked transcriptomic data. These case studies underscore AttentionSmithy's core advantage: enabling specialized experimentation across diverse application domains---from natural language processing to genomic analysis---by obviating the need for labor-intensive, low-level framework manipulation. We anticipate that AttentionSmithy will serve as a foundation for creative transformer-based solutions, expediting research and development in numerous scientific and industrial fields",
    "checked": false,
    "id": "ab55b33bb9794ad7a138518324442bce51e95e3b",
    "semantic_title": "attentionsmithy: a modular framework for rapid transformer development and customization",
    "citation_count": 0,
    "authors": [
      "Caleb Cranney",
      "Jesse G Meyer"
    ]
  },
  "https://openreview.net/forum?id=JzmXo0rfry": {
    "title": "Evaluating explainability techniques on discrete-time graph neural networks",
    "volume": "main",
    "abstract": "Discrete-time temporal Graph Neural Networks (GNNs) are powerful tools for modeling evolving graph-structured data and are widely used in decision-making processes across domains such as social network analysis, financial systems, and collaboration networks. Explaining the predictions of these models is an important research area due to the critical role their decisions play in building trust in social or financial systems. However, the explainability of Temporal Graph Neural Networks remains a challenging and relatively unexplored field. Hence, in this work, we propose a novel framework to evaluate explainability techniques tailored for discrete-time temporal GNNs. Our framework introduces new training and evaluation settings that capture the evolving nature of temporal data, defines metrics to assess the temporal aspects of explanations, and establishes baselines and models specific to discrete-time temporal networks. Through extensive experiments, we outline the best explainability techniques for discrete-time GNNs in terms of fidelity, efficiency, and human-readability trade-offs. By addressing the unique challenges of temporal graph data, our framework sets the stage for future advancements in explaining discrete-time GNNs",
    "checked": true,
    "id": "5bd852ca2d945335c90d719dd0bce4d914646eda",
    "semantic_title": "evaluating explainability techniques on discrete-time graph neural networks",
    "citation_count": 0,
    "authors": [
      "Manuel Dileo",
      "Matteo Zignani",
      "Sabrina Tiziana Gaito"
    ]
  },
  "https://openreview.net/forum?id=Q70C1HQ0VO": {
    "title": "Alternators For Sequence Modeling",
    "volume": "main",
    "abstract": "This paper introduces alternators, a novel family of non-Markovian dynamical models for sequences. An alternator features two neural networks: the observation trajectory network (OTN) and the feature trajectory network (FTN). The OTN and the FTN work in conjunction, alternating between outputting samples in the observation space and some feature space, respectively. The parameters of the OTN and the FTN are not time-dependent and are learned via a minimum cross-entropy criterion over the trajectories. Alternators are versatile. They can be used as dynamical latent-variable generative models or as sequence-to-sequence predictors. Alternators can uncover the latent dynamics underlying complex sequential data, accurately forecast and impute missing data, and sample new trajectories. We showcase the capabilities of alternators in three applications. We first used alternators to model the Lorenz equations, often used to describe chaotic behavior. We then applied alternators to Neuroscience to map brain activity to physical activity. Finally, we applied alternators to Climate Science, focusing on sea-surface temperature forecasting. In all our experiments, we found alternators are stable to train, fast to sample from, yield high-quality generated samples and latent variables, and often outperform strong baselines such as Mambas, neural ODEs, and diffusion models in the domains we studied",
    "checked": true,
    "id": "b82554a8e084b487ded937ee84d493d4e6271977",
    "semantic_title": "alternators for sequence modeling",
    "citation_count": 2,
    "authors": [
      "Mohammad Reza Rezaei",
      "Adji Bousso Dieng"
    ]
  },
  "https://openreview.net/forum?id=yzACI2vFaX": {
    "title": "Evaluating Long Range Dependency Handling in Code Generation LLMs",
    "volume": "main",
    "abstract": "As language models support larger and larger context sizes, evaluating their ability to make effective use of that context becomes increasingly important. We analyze the ability of several code generation models to handle long range dependencies using a suite of multi-step key retrieval tasks in context windows up to 8k tokens in length. The tasks progressively increase in difficulty and allow more nuanced evaluation of model capabilities than tests like the popular needle-in-the-haystack test. We find that performance degrades significantly for many models (up to 2x) when a function references another function that is defined later in the prompt. We also observe that models that use sliding window attention mechanisms have difficulty handling references further than the size of a single window. We perform simple prompt modifications using call graph information to improve multi-step retrieval performance up to 3x. Our analysis highlights ways that long-context performance needs deeper consideration beyond retrieval of single facts within a document",
    "checked": true,
    "id": "36a0165666bec13f3dde0b27ad88cf87d105c6c1",
    "semantic_title": "evaluating long range dependency handling in code generation llms",
    "citation_count": 1,
    "authors": [
      "Yannick Assogba",
      "Donghao Ren"
    ]
  },
  "https://openreview.net/forum?id=FHkWY4aGsN": {
    "title": "CLImage: Human-Annotated Datasets for Complementary-Label Learning",
    "volume": "main",
    "abstract": "Complementary-label learning (CLL) is a weakly-supervised learning paradigm that aims to train a multi-class classifier using only complementary labels, which indicate classes to which an instance does not belong. Despite numerous algorithmic proposals for CLL, their practical applicability remains unverified for two reasons. Firstly, these algorithms often rely on assumptions about the generation of complementary labels, and it is not clear how far the assumptions are from reality. Secondly, their evaluation has been limited to synthetically labeled datasets. To gain insights into the real-world performance of CLL algorithms, we developed a protocol to collect complementary labels from human annotators. Our efforts resulted in the creation of four datasets: CLCIFAR10, CLCIFAR20, CLMicroImageNet10, and CLMicroImageNet20, derived from well-known classification datasets CIFAR10, CIFAR100, and TinyImageNet200. These datasets represent the very first real-world CLL datasets, namely CLImage, which are publicly available at: https://github.com/ntucllab/CLImage_Dataset. Through extensive benchmark experiments, we discovered a notable decrease in performance when transitioning from synthetically labeled datasets to real-world datasets. We investigated the key factors contributing to the decrease with a thorough dataset-level ablation study. Our analyses highlight annotation noise as the most influential factor in the real-world datasets. In addition, we discover that the biased-nature of human-annotated complementary labels and the difficulty to validate with only complementary labels are two outstanding barriers to practical CLL. These findings suggest that the community focus more research efforts on developing CLL algorithms and validation schemes that are robust to noisy and biased complementary-label distributions",
    "checked": true,
    "id": "c33575e887fd4db6b25f0f754ee5969e2df7f85b",
    "semantic_title": "climage: human-annotated datasets for complementary-label learning",
    "citation_count": 2,
    "authors": [
      "Hsiu-Hsuan Wang",
      "Mai Tan Ha",
      "Nai-Xuan Ye",
      "Wei-I Lin",
      "Hsuan-Tien Lin"
    ]
  },
  "https://openreview.net/forum?id=amUisgrmte": {
    "title": "ViewFusion: Learning Composable Diffusion Models for Novel View Synthesis",
    "volume": "main",
    "abstract": "Deep learning is providing a wealth of new approaches to the problem of novel view synthesis, from Neural Radiance Field (NeRF) based approaches to end-to-end style architectures. Each approach offers specific strengths but also comes with limitations in their applicability. This work introduces ViewFusion, an end-to-end generative approach to novel view synthesis with unparalleled flexibility. ViewFusion consists in simultaneously applying a diffusion denoising step to any number of input views of a scene, then combining the noise gradients obtained for each view with an (inferred) pixel-weighting mask, ensuring that for each region of the target view only the most informative input views are taken into account. Our approach resolves several limitations of previous approaches by (1) being trainable and generalizing across multiple scenes and object classes, (2) adaptively taking in a variable number of pose-free views at both train and test time, (3) generating plausible views even in severely underdetermined conditions (thanks to its generative nature)---all while generating views of quality on par or even better than comparable methods. Limitations include not generating a 3D embedding of the scene, resulting in a relatively slow inference speed, and our method only being tested on the relatively small Neural 3D Mesh Renderer dataset. Code is available",
    "checked": true,
    "id": "6894de4cda5041788af72452cc159858db91b177",
    "semantic_title": "viewfusion: learning composable diffusion models for novel view synthesis",
    "citation_count": 2,
    "authors": [
      "Bernard Spiegl",
      "Andrea Perin",
      "Stephane Deny",
      "Alexander Ilin"
    ]
  },
  "https://openreview.net/forum?id=tXnVRpRlR8": {
    "title": "Learning Actionable Counterfactual Explanations in Large State Spaces",
    "volume": "main",
    "abstract": "Recourse generators provide actionable insights, often through feature-based counterfactual explanations (CFEs), to help negatively classified individuals understand how to adjust their input features to achieve a positive classification. These feature-based CFEs, which we refer to as \\emph{low-level} CFEs, are overly specific (e.g., coding experience: \\(4 \\to 5+\\) years) and often recommended in a feature space that doesn't straightforwardly align with real-world actions. To bridge this gap, we introduce three novel recourse types grounded in real-world actions: high-level continuous (\\emph{hl-continuous}), high-level discrete (\\emph{hl-discrete}), and high-level ID (\\emph{hl-id}) CFEs. We formulate single-agent CFE generation methods for hl-discrete and hl-continuous CFEs. For the hl-discrete CFE, we cast the task as a weighted set cover problem that selects the least cost set of hl-discrete actions that satisfy the eligibility of features, and model the hl-continuous CFE as a solution to an integer linear program that identifies the least cost set of hl-continuous actions capable of favorably altering the prediction of a linear classifier. Since these methods require costly optimization per agent, we propose data-driven CFE generation approaches that, given instances of agents and their optimal CFEs, learn a CFE generator that quickly provides optimal CFEs for new agents. This approach, also viewed as one of learning an optimal policy in a family of large but deterministic MDPs, considers several problem formulations, including formulations in which the actions and their effects are unknown, and therefore addresses informational and computational challenges. We conduct extensive empirical evaluations using publicly available healthcare datasets (BRFSS, Foods, and NHANES) and fully-synthetic data. For negatively classified agents identified by linear and threshold-based binary classifiers, we compare the proposed forms of recourse to low-level CFEs, which suggest how the agent can transition from state \\(\\mathbf{x}\\) to a new state \\(\\mathbf{x}'\\) where the model prediction is desirable. We also extensively evaluate the effectiveness of our neural network-based, data-driven CFE generation approaches. Empirical results show that the proposed data-driven CFE generators are accurate and resource-efficient, and the proposed forms of recourse offer various advantages over the low-level CFEs",
    "checked": true,
    "id": "1942d245a3deb92ef63bd56251f2d1b6977f4699",
    "semantic_title": "learning actionable counterfactual explanations in large state spaces",
    "citation_count": 0,
    "authors": [
      "Keziah Naggita",
      "Matthew Walter",
      "Avrim Blum"
    ]
  },
  "https://openreview.net/forum?id=9M4NKMZOPu": {
    "title": "Learning distributed representations with efficient SoftMax normalization",
    "volume": "main",
    "abstract": "Learning distributed representations, or embeddings, that encode the relational similarity patterns among objects is a relevant task in machine learning. A popular method to learn the embedding matrices $X, Y$ is optimizing a loss function of the term ${\\rm SoftMax}(XY^T)$. The complexity required to calculate this term, however, runs quadratically with the problem size, making it a computationally heavy solution. In this article, we propose a linear-time heuristic approximation to compute the normalization constants of ${\\rm SoftMax}(XY^T)$ for embedding vectors with bounded norms. We show on some pre-trained embedding datasets that the proposed estimation method achieves higher or comparable accuracy with competing methods. From this result, we design an efficient and task-agnostic algorithm that learns the embeddings by optimizing the cross entropy between the softmax and a set of probability distributions given as inputs. The proposed algorithm is interpretable and easily adapted to arbitrary embedding problems. We consider a few use cases and observe similar or higher performances and a lower computational time than similar ``2Vec'' algorithms",
    "checked": true,
    "id": "0b8342baa903c8cb14d6a7806f9a5c386da720c6",
    "semantic_title": "learning distributed representations with efficient softmax normalization",
    "citation_count": 1,
    "authors": [
      "Lorenzo Dall'Amico",
      "Enrico Maria Belliardo"
    ]
  },
  "https://openreview.net/forum?id=QQZ8uPxFb3": {
    "title": "Explaining Node Embeddings",
    "volume": "main",
    "abstract": "Node embedding algorithms produce low-dimensional latent representations of nodes in a graph. These embeddings are often used for downstream tasks, such as node classification and link prediction. In this paper, we investigate the following two questions: (Q1) Can we explain each embedding dimension with human-understandable graph features (e.g. degree, clustering coefficient and PageRank). (Q2) How can we modify existing node embedding algorithms to produce embeddings that can be easily explained by human-understandable graph features? We find that the answer to Q1 is yes and introduce a new framework called XM (short for eXplain eMbedding) to answer Q2. A key aspect of XM involves minimizing the nuclear norm of the generated explanations. We show that by minimizing the nuclear norm, we minimize the lower bound on the entropy of the generated explanations. We test XM on a variety of real-world graphs and show that XM not only preserves the performance of existing node embedding methods, but also enhances their explainability",
    "checked": true,
    "id": "29977715c0f556cbf2274a409a3beb879987306c",
    "semantic_title": "explaining node embeddings",
    "citation_count": 0,
    "authors": [
      "Zohair Shafi",
      "Ayan Chatterjee",
      "Tina Eliassi-Rad"
    ]
  },
  "https://openreview.net/forum?id=F42CRfcp3D": {
    "title": "Diversity-Driven View Subset Selection for Indoor Novel View Synthesis",
    "volume": "main",
    "abstract": "Novel view synthesis of indoor scenes can be achieved by capturing a monocular video sequence of the environment. However, redundant information caused by artificial movements in the input video data reduces the efficiency of scene modeling. To address this, we formulate the problem as a combinatorial optimization task for view subset selection. In this work, we propose a novel subset selection framework that integrates a comprehensive diversity-based measurement with well-designed utility functions. We provide a theoretical analysis of these utility functions and validate their effectiveness through extensive experiments. Furthermore, we introduce IndoorTraj, a novel dataset designed for indoor novel view synthesis, featuring complex and extended trajectories that simulate intricate human behaviors. Experiments on IndoorTraj show that our framework consistently outperforms baseline strategies while using only 5–20% of the data, highlighting its remarkable efficiency and effectiveness",
    "checked": true,
    "id": "4a98275fb83f105a50624b82ebde7ce655ff19cc",
    "semantic_title": "diversity-driven view subset selection for indoor novel view synthesis",
    "citation_count": 0,
    "authors": [
      "Zehao Wang",
      "Han Zhou",
      "Matthew B. Blaschko",
      "Tinne Tuytelaars",
      "Minye Wu"
    ]
  },
  "https://openreview.net/forum?id=Q2M4yijKSo": {
    "title": "Flexible Infinite-Width Graph Convolutional Neural Networks",
    "volume": "main",
    "abstract": "A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed. This is known as a neural network Gaussian process (NNGP). However, the NNGP kernel is fixed and tunable only through a small number of hyperparameters, thus eliminating the possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well because they are able to flexibly learn representations for the task at hand. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of node classification tasks on graphs. We develop a precise tool for this task, the graph convolutional deep kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a \"knob\" to control the amount of flexibility and hence representation learning. We found that representation learning gives noticeable performance improvements for heterophilous node classification tasks, but less so for homophilous node classification tasks",
    "checked": true,
    "id": "ec7f05134de1c35b79afae15890ad345dadf181a",
    "semantic_title": "flexible infinite-width graph convolutional neural networks",
    "citation_count": 0,
    "authors": [
      "Ben Anson",
      "Edward Milsom",
      "Laurence Aitchison"
    ]
  },
  "https://openreview.net/forum?id=QI0l842vSq": {
    "title": "GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) learn to represent nodes by aggregating information from their neighbors. As GNNs increase in depth, their receptive field grows exponentially, leading to high memory costs. Several works in the literature proposed to address this shortcoming by sampling subgraphs, or by using historical embeddings. These methods have mostly focused on benchmarks of single-label node classification on homophilous graphs, where neighboring nodes often share the same label. However, most of these methods rely on static heuristics that may not generalize across different graphs or tasks. We argue that the sampling method should be adaptive, adjusting to the complex structural properties of each graph. To this end, we introduce GRAPES, an adaptive sampling method that learns to identify the set of nodes crucial for training a GNN. GRAPES trains a second GNN to predict node sampling probabilities by optimizing the downstream task objective. We evaluate GRAPES on various node classification benchmarks involving homophilous as well as heterophilous graphs. We demonstrate GRAPES' effectiveness in accuracy and scalability, particularly in multi-label heterophilous graphs. Additionally, GRAPES uses orders of magnitude less GPU memory than a strong baseline based on historical embeddings. Unlike other sampling methods, GRAPES maintains high accuracy even with smaller sample sizes and, therefore, can scale to massive graphs. Our implementation is publicly available online",
    "checked": true,
    "id": "0e98e6bf270463cd2b5841a669b34a90494441d5",
    "semantic_title": "grapes: learning to sample graphs for scalable graph neural networks",
    "citation_count": 6,
    "authors": [
      "Taraneh Younesian",
      "Daniel Daza",
      "Emile van Krieken",
      "Thiviyan Thanapalasingam",
      "Peter Bloem"
    ]
  },
  "https://openreview.net/forum?id=zo5b60AuAH": {
    "title": "Local Differential Privacy-Preserving Spectral Clustering for General Graphs",
    "volume": "main",
    "abstract": "Spectral clustering is a widely used algorithm to find clusters in networks. Several researchers have studied the stability of spectral clustering under local differential privacy with the additional assumption that the underlying networks are generated from the stochastic block model (SBM). However, we argue that this assumption is too restrictive since social networks do not originate from the SBM. Thus, we delve into an analysis for general graphs in this work. Our primary focus is the edge flipping method -- a common technique for protecting local differential privacy. We show that, when the edges of an $n$-vertex graph satisfying some reasonable well-clustering assumptions are flipped with a probability of $O(\\log n/n)$, the clustering outcomes are largely consistent. Empirical tests further corroborate these theoretical findings. Conversely, although clustering outcomes have been stable for non-sparse and well-clustered graphs produced from the SBM, we show that in general, spectral clustering may yield highly erratic results on certain graphs when the flipping probability is $\\omega(\\log n/n)$. This indicates that the best privacy budget obtainable for general graphs is $\\Theta(\\log n)$",
    "checked": true,
    "id": "50808d60fed0c31674cb813365533a8b57e00032",
    "semantic_title": "local differential privacy-preserving spectral clustering for general graphs",
    "citation_count": 1,
    "authors": [
      "Sayan Mukherjee",
      "Vorapong Suppakitpaisarn"
    ]
  },
  "https://openreview.net/forum?id=WzS33L1iPC": {
    "title": "Visually Descriptive Language Model for Vector Graphics Reasoning",
    "volume": "main",
    "abstract": "Despite significant advancements, current large multimodal models (LMMs) struggle to bridge the gap between low-level visual perception—focusing on shapes, sizes, and layouts—and high-level language reasoning involving semantics, events, and logic. This limitation becomes evident in tasks requiring precise visual perception, such as comparing geometric properties or solving visual algorithmic reasoning problems. To study this failure mode, we focus on an important visual domain: vector graphics —images composed purely of 2D objects and shapes, which are prevalent in Web, PC, and Mobile environments. Importantly, we consider rasterized vector graphics without assuming access to their underlying vector code. We identify two key research questions: how can we enable precise visual perception, and how can we facilitate high-level reasoning based on such low-level perceptions? To accurately capture low-level visual details, we explore using SVG for the precise encoding of visual scenes. However, SVGs are not readily interpretable by LLMs or LMMs in a zero-shot manner. To address this challenge, we propose the Visually Descriptive Language Model (VDLM) to build a bridge between low-level visual perception and high-level language reasoning. VDLM learns an intermediate symbolic representation called Primal Visual Description (PVD), which translates raw SVGs into a higher-level abstraction comprising primitive attributes. This abstraction allows for direct interpretation by foundation models for zero-shot generalization to different reasoning tasks. Without any human-annotated data, VDLM leads to significant improvements in state-of-the-art LMMs, such as GPT-4o, across various low-level multimodal perception and reasoning tasks on rasterized vector graphics. Additionally, we provide extensive analyses of VDLM's performance, showing that our framework offers improved interpretability due to its disentangled perception and reasoning processes. As the first attempt to construct a descriptive intermediate representation for low-level visual reasoning, we also conduct an in-depth error analysis, highlighting remaining limitations and suggesting directions for future research",
    "checked": true,
    "id": "6fde101147cf3b1980f1ac54a45026dddf110f3a",
    "semantic_title": "visually descriptive language model for vector graphics reasoning",
    "citation_count": 4,
    "authors": [
      "Zhenhailong Wang",
      "Joy Hsu",
      "Xingyao Wang",
      "Kuan-Hao Huang",
      "Manling Li",
      "Jiajun Wu",
      "Heng Ji"
    ]
  },
  "https://openreview.net/forum?id=PPGJ3EvENv": {
    "title": "Unsupervised Anomaly Detection through Mass Repulsing Optimal Transport",
    "volume": "main",
    "abstract": "Detecting anomalies in datasets is a longstanding problem in machine learning. In this context, anomalies are defined as a sample that significantly deviates from the remaining data. Meanwhile, Optimal Transport (OT) is a field of mathematics concerned with the transportation, between two probability distribution, at least effort. In classical OT, the optimal transportation strategy of a distribution to itself is the identity, i.e., each sample keeps its mass. In this paper, we tackle anomaly detection by forcing samples to displace its mass, while keeping the least effort objective. We call this new transportation problem Mass Repulsing Optimal Transport (MROT). Naturally, samples lying in low density regions of space will be forced to displace mass very far, incurring a higher transportation cost. In contrast, samples on high density regions are able to send their mass just outside an \\emph{exclusion zone}. We use these concepts to design a new anomaly score. Through a series of experiments in existing benchmarks, and fault detection problems, we show that our algorithm improves over existing methods. Our code is publicly available at https://github.com/eddardd/MROT",
    "checked": true,
    "id": "90fda71788307ea96e198939231b24874ac935f2",
    "semantic_title": "unsupervised anomaly detection through mass repulsing optimal transport",
    "citation_count": 0,
    "authors": [
      "Eduardo Fernandes Montesuma",
      "EL HABAZI Adel",
      "Fred Maurice NGOLE MBOULA"
    ]
  },
  "https://openreview.net/forum?id=Xmk1or5eH8": {
    "title": "Algorithm Configuration for Structured Pfaffian Settings",
    "volume": "main",
    "abstract": "Data-driven algorithm design uses historical problem instances to automatically adjust and optimize algorithms to their application domain, typically by selecting algorithms from parameterized families. While the approach has been highly successful in practice, providing theoretical guarantees for several algorithmic families remains challenging. This is due to the intricate dependence of the algorithmic performance on the parameters, often exhibiting a piecewise discontinuous structure. In this work, we present new frameworks for providing learning guarantees for parameterized data-driven algorithm design problems in both statistical and online learning settings. For the statistical learning setting, we introduce the Pfaffian GJ framework, an extension of the classical Goldberg-Jerrum (GJ) framework (Bartlett et al., 2022; Goldberg & Jerrum, 1993), that is capable of providing learning guarantees for function classes for which the computation involves Pfaffian functions. Unlike the GJ framework, which is limited to function classes with computation characterized by rational functions (quotients of two polynomials), our proposed framework can deal with function classes involving Pfaffian functions, which are much more general and widely applicable. We then show that for many parameterized algorithms of interest, their utility function possesses a refined piecewise structure, which automatically translates to learning guarantees using our proposed framework. For the online learning setting, we provide a new tool for verifying the dispersion property of a sequence of loss functions, a sufficient condition that allows no-regret learning for sequences of piecewise structured loss functions where the piecewise structure involves Pfaffian transition boundaries. We use our framework to provide novel learning guarantees for many challenging data-driven design problems of interest, including data-driven linkage-based clustering, graph-based semi-supervised learning, and regularized logistic regression",
    "checked": true,
    "id": "bd060781042b776f1ea0299155c4fb9c88d4d74b",
    "semantic_title": "algorithm configuration for structured pfaffian settings",
    "citation_count": 1,
    "authors": [
      "Maria Florina Balcan",
      "Anh Tuan Nguyen",
      "Dravyansh Sharma"
    ]
  },
  "https://openreview.net/forum?id=zF9IrMTjCC": {
    "title": "Generalizable Representation Learning for fMRI-based Neurological Disorder Identification",
    "volume": "main",
    "abstract": "Despite the impressive advances achieved using deep learning for functional brain activity analysis, the heterogeneity of functional patterns and the scarcity of imaging data still pose challenges in tasks such as identifying neurological disorders. For functional Magnetic Resonance Imaging (fMRI), while data may be abundantly available from healthy controls, clinical data is often scarce, especially for rare diseases, limiting the ability of models to identify clinically-relevant features. We overcome this limitation by introducing a novel representation learning strategy integrating meta-learning with self-supervised learning to improve the generalization from normal to clinical features. This approach enables generalization to challenging clinical tasks featuring scarce training data. We achieve this by leveraging self-supervised learning on the control dataset to focus on inherent features that are not limited to a particular supervised task and incorporating meta-learning to improve the generalization across domains. To explore the generalizability of the learned representations to unseen clinical applications, we apply the model to four distinct clinical datasets featuring scarce and heterogeneous data for neurological disorder classification. Results demonstrate the superiority of our representation learning strategy on diverse clinically-relevant tasks",
    "checked": true,
    "id": "49b19aa2e30e295344c2bcf6b317ec5b1e9eb520",
    "semantic_title": "generalizable representation learning for fmri-based neurological disorder identification",
    "citation_count": 0,
    "authors": [
      "Wenhui Cui",
      "Haleh Akrami",
      "Anand Joshi",
      "Richard Leahy"
    ]
  },
  "https://openreview.net/forum?id=Uz9J77Riul": {
    "title": "Information Theoretic Guarantees For Policy Alignment In Large Language Models",
    "volume": "main",
    "abstract": "Policy alignment of large language models refers to constrained policy optimization, where the policy is optimized to maximize a reward while staying close to a reference policy based on an $f$-divergence like $\\mathsf{KL}$ divergence. The best of $n$ alignment policy selects the sample with the highest reward from $n$ independent samples. Recent work shows that the reward improvement of the aligned policy scales as $\\sqrt{\\mathsf{KL}}$, with an explicit bound on the $\\mathsf{KL}$ for best of $n$ policies. We show that this $\\sqrt{\\mathsf{KL}}$ bound holds if the reference policy's reward has sub-gaussian tails. For best of $n$ policies, the $\\mathsf{KL}$ bound applies to any $f$-divergence through a reduction to exponential order statistics using the Rényi representation. Tighter control can be achieved with Rényi divergence if additional tail information is known. Finally, we demonstrate how these bounds transfer to golden rewards, resulting in decreased golden reward improvement due to proxy reward overestimation and approximation errors",
    "checked": true,
    "id": "5bf9ff4358cd7c7204583e62a1d429a440763c84",
    "semantic_title": "information theoretic guarantees for policy alignment in large language models",
    "citation_count": 8,
    "authors": [
      "Youssef Mroueh",
      "Apoorva Nitsure"
    ]
  },
  "https://openreview.net/forum?id=o6ukhJLzMQ": {
    "title": "Augmented Invertible Koopman Autoencoder for long-term time series forecasting",
    "volume": "main",
    "abstract": "Following the introduction of Dynamic Mode Decomposition and its numerous extensions, many neural autoencoder-based implementations of the Koopman operator have recently been proposed. This class of methods appears to be of interest for modeling dynamical systems, either through direct long-term prediction of the evolution of the state or as a powerful embedding for downstream methods. In particular, a recent line of work has developed invertible Koopman autoencoders (IKAEs), which provide an exact reconstruction of the input state thanks to their analytically invertible encoder, based on coupling layer normalizing flow models. We identify that the conservation of the dimension imposed by the normalizing flows is a limitation for the IKAE models, and thus we propose to augment the latent state with a second, non-invertible encoder network. This results in our new model: the Augmented Invertible Koopman AutoEncoder (AIKAE). We demonstrate the relevance of the AIKAE through a series of long-term time series forecasting experiments, on satellite image time series as well as on a benchmark involving predictions based on a large lookback window of observations",
    "checked": true,
    "id": "cd3605f0d7bc3be82c84d22e2fdcb3b2585dd714",
    "semantic_title": "augmented invertible koopman autoencoder for long-term time series forecasting",
    "citation_count": 0,
    "authors": [
      "Anthony Frion",
      "Lucas Drumetz",
      "Mauro Dalla Mura",
      "Guillaume Tochon",
      "Abdeldjalil AISSA EL BEY"
    ]
  },
  "https://openreview.net/forum?id=wyOv4kGkbU": {
    "title": "Test-time Contrastive Concepts for Open-world Semantic Segmentation with Vision-Language Models",
    "volume": "main",
    "abstract": "Recent CLIP-like Vision-Language Models (VLMs), pre-trained on large amounts of image-text pairs to align both modalities with a simple contrastive objective, have paved the way to open-vocabulary semantic segmentation. Given an arbitrary set of textual queries, image pixels are assigned the closest query in feature space. However, this works well when a user exhaustively lists all possible visual concepts in an image that contrast against each other for the assignment. This corresponds to the current evaluation setup in the literature, which relies on having access to a list of in-domain relevant concepts, typically classes of a benchmark dataset. Here, we consider the more challenging (and realistic) scenario of segmenting a single concept, given a textual prompt and nothing else. To achieve good results, besides contrasting with the generic \"background\" text, we propose two different approaches to automatically generate, at test time, query-specific textual contrastive concepts. We do so by leveraging the distribution of texts in the VLM's training set or crafted LLM prompts. We also propose a metric designed to evaluate this scenario and show the relevance of our approach on commonly used datasets",
    "checked": true,
    "id": "fe211dee9eecc45974b179c68c54f7c9bad70d78",
    "semantic_title": "test-time contrastive concepts for open-world semantic segmentation with vision-language models",
    "citation_count": 1,
    "authors": [
      "Monika Wysoczańska",
      "Antonin Vobecky",
      "Amaia Cardiel",
      "Tomasz Trzcinski",
      "Renaud Marlet",
      "Andrei Bursuc",
      "Oriane Siméoni"
    ]
  },
  "https://openreview.net/forum?id=qmHlTkLdbL": {
    "title": "Online Bandit Nonlinear Control with Dynamic Batch Length and Adaptive Learning Rate",
    "volume": "main",
    "abstract": "This paper is concerned with the online bandit nonlinear control, which aims to learn the best stabilizing controller from a pool of stabilizing and destabilizing controllers of unknown types for a given nonlinear dynamical system. We develop an algorithm, named Dynamic Batch length and Adaptive learning Rate (DBAR), and study its stability and regret. Unlike the existing Exp3 algorithm requiring an exponentially stabilizing controller, DBAR only needs a significantly weaker notion of controller stability, in which case substantial time may be required to certify the system stability. Dynamic batch length in DBAR effectively addresses this issue and enables the system to attain asymptotic stability, where the algorithm behaves as if there were no destabilizing controllers. Moreover, adaptive learning rate in DBAR only uses the state norm information to achieve a tight regret bound even when none of the stabilizing controllers in the pool are exponentially stabilizing",
    "checked": true,
    "id": "b55d6accd08ac7026e304c04fd8f81aa0771601d",
    "semantic_title": "online bandit nonlinear control with dynamic batch length and adaptive learning rate",
    "citation_count": 1,
    "authors": [
      "Jihun Kim",
      "Javad Lavaei"
    ]
  },
  "https://openreview.net/forum?id=L33DSu3zvq": {
    "title": "Tighter sparse variational Gaussian processes",
    "volume": "main",
    "abstract": "Sparse variational Gaussian process (GP) approximations based on inducing points have become the de facto standard for scaling GPs to large datasets, owing to their theoretical elegance, computational efficiency, and ease of implementation. This paper introduces a provably tighter variational approximation by relaxing the standard assumption that the conditional approximate posterior given the inducing points must match that in the prior. The key innovation is to modify the conditional posterior to have smaller variances than that of the prior at the training points. We derive the collapsed bound for the regression case, describe how to use the proposed approximation in large data settings, and discuss its application to handle orthogonally structured inducing points and GP latent variable models. Extensive experiments on regression benchmarks, classification, and latent variable models demonstrate that the proposed approximation consistently matches or outperforms standard sparse variational GPs while maintaining the same computational cost",
    "checked": true,
    "id": "e9cc920e077366ee63e5d28a1a6daf599d72125e",
    "semantic_title": "tighter sparse variational gaussian processes",
    "citation_count": 1,
    "authors": [
      "Thang D Bui",
      "Matthew Ashman",
      "Richard E. Turner"
    ]
  },
  "https://openreview.net/forum?id=BbwlJpNXgW": {
    "title": "RESTOR: Knowledge Recovery in Machine Unlearning",
    "volume": "main",
    "abstract": "Large language models trained on web-scale corpora can memorize undesirable data containing misinformation, copyrighted material, or private or sensitive information. Recently, several machine unlearning algorithms have been proposed to eliminate the effect of such datapoints from trained models-- that is, to approximate *a model that had never been trained on these datapoints in the first place*. However, evaluating the effectiveness of unlearning algorithms remains an open challenge. Previous work has relied on heuristics-- such as verifying that the model can no longer reproduce the specific information targeted for removal while maintaining accuracy on unrelated test data. These approaches inadequately capture the complete effect of reversing the influence of datapoints on a trained model. In this work, we propose the RESTOR framework for machine unlearning evaluation, which assesses the ability of unlearning algorithms for targeted data erasure, by evaluating the ability of models to forget the knowledge introduced in these datapoints, while simultaneously recovering the model's knowledge state had it never encountered these datapoints. RESTOR helps uncover several novel insights about popular unlearning algorithms, and the mechanisms through which they operate-- for instance, identifying that some algorithms merely emphasize forgetting but not recovering knowledge, and that localizing unlearning targets can enhance unlearning performance",
    "checked": true,
    "id": "507d3a2290f6827942dc8c39832a672964bdda7f",
    "semantic_title": "restor: knowledge recovery in machine unlearning",
    "citation_count": 0,
    "authors": [
      "Keivan Rezaei",
      "Khyathi Chandu",
      "Soheil Feizi",
      "Yejin Choi",
      "Faeze Brahman",
      "Abhilasha Ravichander"
    ]
  },
  "https://openreview.net/forum?id=fuOHI59rUW": {
    "title": "MarDini: Masked Auto-regressive Diffusion for Video Generation at Scale",
    "volume": "main",
    "abstract": "We introduce MarDini, a new family of video diffusion models that integrate the advantages of masked auto-regression (MAR) into a unified diffusion model (DM) framework. Here, MAR handles temporal planning, while DM focuses on spatial generation in an asymmetric network design: i) a MAR-based planning model containing most of the parameters generates planning signals for each masked frame using low-resolution input; ii) a lightweight generation model uses these signals to produce high-resolution frames via diffusion de-noising. MarDini's MAR enables video generation conditioned on any number of masked frames at any frame positions: a single model can handle video interpolation (e.g., masking middle frames), image-to-video generation (e.g., masking from the second frame onward), and video expansion (e.g., masking half the frames). The efficient design allocates most of the computational resources to the low-resolution planning model, making computationally expensive but important spatio-temporal attention feasible at scale. MarDini sets a new state-of-the-art for video interpolation; meanwhile, within few inference steps, it efficiently generates videos on par with those of much more expensive advanced image-to-video models",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haozhe Liu",
      "Shikun Liu",
      "Zijian Zhou",
      "Mengmeng Xu",
      "Yanping Xie",
      "Xiao Han",
      "Juan Camilo Perez",
      "Ding Liu",
      "Kumara Kahatapitiya",
      "Menglin Jia",
      "Jui-Chieh Wu",
      "Sen He",
      "Tao Xiang",
      "Jürgen Schmidhuber",
      "Juan-Manuel Perez-Rua"
    ]
  },
  "https://openreview.net/forum?id=LLWJkR6gaI": {
    "title": "Responsive Noise-Relaying Diffusion Policy: Responsive and Efficient Visuomotor Control",
    "volume": "main",
    "abstract": "Imitation learning is an efficient method for teaching robots a variety of tasks. Diffusion Policy, which uses a conditional denoising diffusion process to generate actions, has demonstrated superior performance, particularly in learning from multi-modal demonstrates. However, it relies on executing multiple actions predicted from the same inference step to retain performance and prevent mode bouncing, which limits its responsiveness, as actions are not conditioned on the most recent observations. To address this, we introduce Responsive Noise-Relaying Diffusion Policy (RNR-DP), which maintains a noise-relaying buffer with progressively increasing noise levels and employs a sequential denoising mechanism that generates immediate, noise-free actions at the head of the sequence, while appending noisy actions at the tail. This ensures that actions are responsive and conditioned on the latest observations, while maintaining motion consistency through the noise-relaying buffer. This design enables the handling of tasks requiring responsive control, and accelerates action generation by reusing denoising steps. Experiments on response-sensitive tasks demonstrate that, compared to Diffusion Policy, ours achieves 18% improvement in success rate. Further evaluation on regular tasks demonstrates that RNR-DP also exceeds the best acceleration method (DDIM) by 6.9% in success rate, highlighting its computational efficiency advantage in scenarios where responsiveness is less critical",
    "checked": true,
    "id": "4883db672052b2538e648e1c0505ee380b154600",
    "semantic_title": "responsive noise-relaying diffusion policy: responsive and efficient visuomotor control",
    "citation_count": 1,
    "authors": [
      "Zhuoqun Chen",
      "Xiu Yuan",
      "Tongzhou Mu",
      "Hao Su"
    ]
  },
  "https://openreview.net/forum?id=Ed1DBB3sBQ": {
    "title": "Conformal Prediction: A Theoretical Note and Benchmarking Transductive Node Classification in Graphs",
    "volume": "main",
    "abstract": "Conformal prediction has become increasingly popular for quantifying the uncertainty associated with machine learning models. Recent work in graph uncertainty quantification has built upon this approach for conformal graph prediction. The nascent nature of these explorations has led to conflicting choices for implementations, baselines, and method evaluation. In this work, we analyze the design choices made in the literature and discuss the tradeoffs associated with existing methods. Building on the existing implementations for existing methods, we introduce techniques to scale existing methods to large-scale graph datasets without sacrificing performance. Our theoretical and empirical results justify our recommendations for future scholarship in graph conformal prediction",
    "checked": true,
    "id": "bee6768e7c5fde8e1e0385d2fb085c584f0ed61a",
    "semantic_title": "conformal prediction: a theoretical note and benchmarking transductive node classification in graphs",
    "citation_count": 0,
    "authors": [
      "Pranav Maneriker",
      "Aditya T. Vadlamani",
      "Anutam Srinivasan",
      "Yuntian He",
      "Ali Payani",
      "srinivasan parthasarathy"
    ]
  },
  "https://openreview.net/forum?id=A4RLpHPXCu": {
    "title": "Offset Unlearning for Large Language Models",
    "volume": "main",
    "abstract": "Despite the strong capabilities of Large Language Models (LLMs) to acquire knowledge from their training corpora, the memorization of sensitive information in the corpora such as copyrighted, biased, and private content has led to ethical and legal concerns. In response to these challenges, unlearning has emerged as a potential remedy for LLMs affected by problematic training data. However, previous unlearning techniques are either not applicable to black-box LLMs due to required access to model internal weights, or violate data protection principles by retaining sensitive data for inference-time correction. We propose $\\delta$-unlearning, an offset unlearning framework for black-box LLMs. Instead of tuning the black-box LLM itself, $\\delta$-unlearning learns the logit offset needed for unlearning by contrasting the logits from a pair of smaller models. Experiments demonstrate that $\\delta$-unlearning can effectively unlearn target data while maintaining similar or even stronger performance on general out-of-forget-scope tasks. $\\delta$-unlearning also effectively incorporates different unlearning algorithms, making our approach a versatile solution to adapting various existing unlearning algorithms to black-box LLMs",
    "checked": true,
    "id": "72010b7fe48301a38e8063109b8ef8fcfd573e05",
    "semantic_title": "offset unlearning for large language models",
    "citation_count": 14,
    "authors": [
      "James Y. Huang",
      "Wenxuan Zhou",
      "Fei Wang",
      "Fred Morstatter",
      "Sheng Zhang",
      "Hoifung Poon",
      "Muhao Chen"
    ]
  },
  "https://openreview.net/forum?id=oYmRiWCQ1W": {
    "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
    "volume": "main",
    "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 492 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) reference-matching bias, where raters are unduly influenced by the human reference, and (ii) judgement ambiguity, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 246,000 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems",
    "checked": true,
    "id": "d6424cf3871eecd8034748501ebaa0d98a275552",
    "semantic_title": "rethinking mushra: addressing modern challenges in text-to-speech evaluation",
    "citation_count": 2,
    "authors": [
      "Praveen Srinivasa Varadhan",
      "amogh gulati",
      "Ashwin Sankar",
      "Srija Anand",
      "Anirudh Gupta",
      "Anirudh Mukherjee",
      "Shiva Kumar Marepally",
      "Ankur Bhatia",
      "Saloni Jaju",
      "Suvrat Bhooshan",
      "Mitesh M Khapra"
    ]
  },
  "https://openreview.net/forum?id=cCQKwd5MFP": {
    "title": "Part-aware Prompted Segment Anything Model for Adaptive Segmentation",
    "volume": "main",
    "abstract": "Precision medicine, such as patient-adaptive treatments assisted by medical image analysis, poses new challenges for image segmentation algorithms due to the large variability across different patients and the limited availability of annotated data for each patient. In this work, we propose a data-efficient segmentation method to address these challenges, namely $\\textit{\\textbf{P}art-aware}$ $\\textit{\\textbf{P}rompted}$ $\\textit{\\textbf{S}egment}$ $\\textit{\\textbf{A}nything}$ $\\textit{\\textbf{M}odel}$ ($\\mathbf{{P}^{2}SAM}$). Without any model fine-tuning, $\\text{P}^2\\text{SAM}$ enables seamless adaptation to any new patients relying only on one-shot patient-specific data. We introduce a novel part-aware prompt mechanism to select multiple-point prompts based on part-level features of the one-shot data, which can be extensively integrated into different promptable segmentation models, such as SAM and SAM 2. To further promote the robustness of the part-aware prompt mechanism, we propose a distribution-guided retrieval approach to determine the optimal number of part-level features for a specific case. $\\text{P}^2\\text{SAM}$ improves the performance by $\\texttt{+} 8.0\\%$ and $\\texttt{+} 2.0\\%$ mean Dice score for two different patient-adaptive segmentation applications, respectively. In addition, $\\text{P}^2\\text{SAM}$ also exhibits impressive generalizability in other adaptive segmentation tasks in the natural image domain, $\\textit{e.g.}$, $\\texttt{+} 6.4\\%$ mIoU within personalized object segmentation task. Code will be released upon acceptance",
    "checked": true,
    "id": "470cacf502daf31e7da621666eb012ffa49305c1",
    "semantic_title": "part-aware prompted segment anything model for adaptive segmentation",
    "citation_count": 3,
    "authors": [
      "Chenhui Zhao",
      "Liyue Shen"
    ]
  },
  "https://openreview.net/forum?id=kY2fKLOGkI": {
    "title": "On the Utility of Existing Fine-Tuned Models on Data-Scarce Domains",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) have been observed to perform well on a wide range of downstream tasks when fine-tuned on domain-specific data. However, such data may not be readily available in many applications, motivating zero-shot or few-shot approaches using existing domain or task adjacent (fine-tuned) models, which we call DAFT. While several fine-tuned models for various tasks are available, finding one appropriate DAFT model for a given task is often not straight forward. In this paper, we explore different utilization techniques of these existing DAFT models for data-scarce problems, i.e., tasks for which data is not available or limited. We observe that for zero-shot problems, ensembling of DAFT models provides an accuracy performance close to that of the single best model. With few-shot problems (few data from target domain available), this performance can be improved further by picking or putting more weights to the DAFT models that are expected to perform better on the target task",
    "checked": true,
    "id": "2abf7bd98138a35eb377babfcf04c067e437f7af",
    "semantic_title": "on the utility of existing fine-tuned models on data-scarce domains",
    "citation_count": 0,
    "authors": [
      "Md Ibrahim Ibne Alam",
      "Parikshit Ram",
      "Soham Dan",
      "Horst Samulowitz",
      "Koushik Kar"
    ]
  },
  "https://openreview.net/forum?id=k8x44wVIs1": {
    "title": "Group Fair Federated Learning via Stochastic Kernel Regularization",
    "volume": "main",
    "abstract": "Ensuring \\textbf{group fairness} in federated learning (FL) presents unique challenges due to data heterogeneity and communication constraints. We propose Kernel Fair Federated Learning (\\texttt{KFFL}), a novel framework that incorporates group fairness into FL models using the Kernel Hilbert-Schmidt Independence Criterion (KHSIC) as a fairness regularizer. To address scalability, \\texttt{KFFL} approximates KHSIC with Random Feature Maps (RFMs), significantly reducing computational and communication overhead while achieving \\textit{group fairness}. To address the resulting non-convex optimization problem, we propose \\texttt{FedProxGrad}, a federated proximal gradient algorithm that guarantees convergence. Through experiments on standard benchmark datasets across both IID and Non-IID settings for regression and classification tasks, \\texttt{KFFL} demonstrates its ability to balance accuracy and fairness effectively, outperforming existing methods by comprehensively exploring the Pareto Frontier. Furthermore, we introduce \\texttt{KFFL-TD}, a time-delayed variant that further reduces communication rounds, enhancing efficiency in decentralized environments",
    "checked": true,
    "id": "cd93a479edee050a9bd14e5289552d7826994d61",
    "semantic_title": "group fair federated learning via stochastic kernel regularization",
    "citation_count": 0,
    "authors": [
      "Huzaifa Arif",
      "Pin-Yu Chen",
      "Keerthiram Murugesan",
      "Alex Gittens"
    ]
  },
  "https://openreview.net/forum?id=quE8gDDegf": {
    "title": "Exploring Weak-to-Strong Generalization for CLIP-based Classification",
    "volume": "main",
    "abstract": "Aligning large-scale commercial models with user intent is crucial to preventing harmful outputs. Current methods rely on human supervision but become impractical as model complexity increases. When models surpass human knowledge, providing accurate feedback becomes challenging and inefficient. A novel solution proposed recently is using a weaker model to supervise a stronger model. This concept leverages the ability of weaker models to perform evaluations, thereby reducing the workload on human supervisors. Previous work has shown the effectiveness of weak-to-strong generalization in the context of language-only models. Extending this concept to vision-language models leverages these insights, adapting the proven benefits to a multi-modal context. In our study, we explore weak-to-strong generalization for CLIP-based classification. We propose a method, \\emph{class prototype learning} (CPL), which aims to enhance the classification capabilities of the CLIP model, by learning more representative prototypes for each category. Our findings indicate that, despite using a simple loss function under weak supervision, CPL yields robust improvements in targeted scenarios, particularly when pretraining is limited. Extensive experiments demonstrate that our approach is effective under these settings, achieving a 3.67\\% improvement over strong baseline methods",
    "checked": true,
    "id": "4a3cda4ee6bcb5d40604d93cb37c3a82b89c2bee",
    "semantic_title": "exploring weak-to-strong generalization for clip-based classification",
    "citation_count": 0,
    "authors": [
      "Jinhao Li",
      "Sarah Monazam Erfani",
      "Lei Feng",
      "James Bailey",
      "Feng Liu"
    ]
  },
  "https://openreview.net/forum?id=OjWB2671AR": {
    "title": "Deep Augmentation: Dropout as Augmentation for Self-Supervised Learning",
    "volume": "main",
    "abstract": "Despite dropout's ubiquity in machine learning, its effectiveness as a form of data augmentation remains under-explored. We address two key questions: (i) When is dropout effective as an augmentation strategy? (ii) Is dropout uniquely effective under these conditions? To explore these questions, we propose Deep Augmentation, a network- and modality-agnostic method that applies dropout or PCA transformations to targeted layers in neural networks. Through extensive experiments on contrastive learning tasks in NLP, computer vision, and graph learning, we find that uniformly applying dropout across layers does not consistently improve performance. Instead, dropout proves most beneficial in deeper layers and can be matched by alternative augmentations (e.g., PCA). We also show that a stop-gradient operation is critical for ensuring dropout functions effectively as an augmentation, and that performance trends invert when moving from contrastive tasks to supervised tasks. Our analysis suggests that Deep Augmentation helps mitigate inter-layer co-adaptation---a notable issue in self-supervised learning due to the absence of labeled data. Drawing on these insights, we outline a procedure for selecting the optimal augmentation layer and demonstrate that Deep Augmentation can outperform traditional input-level augmentations. This simple yet powerful approach can be seamlessly integrated into a wide range of architectures and modalities, yielding notable gains in both performance and generalization",
    "checked": true,
    "id": "1869e4b3ec0a248c6ba360bf17706621207d310e",
    "semantic_title": "deep augmentation: dropout as augmentation for self-supervised learning",
    "citation_count": 0,
    "authors": [
      "Rickard Brüel Gabrielsson",
      "Tongzhou Wang",
      "Manel Baradad",
      "Justin Solomon"
    ]
  },
  "https://openreview.net/forum?id=haf78jerSt": {
    "title": "Forecasting Company Fundamentals",
    "volume": "main",
    "abstract": "Company fundamentals are key to assessing companies' financial and overall success and stability. Forecasting them is important in multiple fields, including investing and econometrics. While statistical and contemporary machine learning methods have been applied to many time series tasks, there is a lack of comparison of these approaches on this particularly challenging data regime. To this end, we try to bridge this gap and thoroughly evaluate the theoretical properties and practical performance of 24 deterministic and probabilistic company fundamentals forecasting models on real company data. We observe that deep learning models provide superior forecasting performance to classical models, in particular when considering uncertainty estimation. To validate the findings, we compare them to human analyst expectations and find that their accuracy is comparable to the automatic forecasts. We further show how these high-quality forecasts can benefit automated stock allocation. We close by presenting possible ways of integrating domain experts to further improve performance and increase reliability",
    "checked": true,
    "id": "cef84fc1987e0e6fa3f675c2eefb68061445ba60",
    "semantic_title": "forecasting company fundamentals",
    "citation_count": 0,
    "authors": [
      "Felix Divo",
      "Eric Endress",
      "Kevin Endler",
      "Kristian Kersting",
      "Devendra Singh Dhami"
    ]
  },
  "https://openreview.net/forum?id=6g1WJ55N51": {
    "title": "ETGL-DDPG: A Deep Deterministic Policy Gradient Algorithm for Sparse Reward Continuous Control",
    "volume": "main",
    "abstract": "We consider deep deterministic policy gradient (DDPG) in the context of reinforcement learning with sparse rewards. To enhance exploration, we introduce a search procedure, \\emph{${\\epsilon}{t}$-greedy}, which generates exploratory options for exploring less-visited states. We prove that search using $\\epsilon t$-greedy has polynomial sample complexity under mild MDP assumptions. To more efficiently use the information provided by rewarded transitions, we develop a new dual experience replay buffer framework, \\emph{GDRB}, and implement \\emph{longest n-step returns}. The resulting algorithm, \\emph{ETGL-DDPG}, integrates all three techniques: \\bm{$\\epsilon t$}-greedy, \\textbf{G}DRB, and \\textbf{L}ongest $n$-step, into DDPG. We evaluate ETGL-DDPG on standard benchmarks and demonstrate that it outperforms DDPG, as well as other state-of-the-art methods, across all tested sparse-reward continuous environments. Ablation studies further highlight how each strategy individually enhances the performance of DDPG in this setting",
    "checked": true,
    "id": "331586853f0b2f45d66fa8bde7bdc5dde07725cf",
    "semantic_title": "etgl-ddpg: a deep deterministic policy gradient algorithm for sparse reward continuous control",
    "citation_count": 1,
    "authors": [
      "Ehsan Futuhi",
      "Shayan Karimi",
      "Chao Gao",
      "Martin Müller"
    ]
  },
  "https://openreview.net/forum?id=kHl4JzyNzF": {
    "title": "Music Foundation Model as Generic Booster for Music Downstream Tasks",
    "volume": "main",
    "abstract": "We demonstrate the efficacy of using intermediate representations from a single foundation model to enhance various music downstream tasks. We introduce SoniDo, a music foundation model (MFM) designed to extract hierarchical features from target music samples. By leveraging hierarchical intermediate features, SoniDo constrains the information granularity, leading to improved performance across various downstream tasks including both understanding and generative tasks. We specifically evaluated this approach on representative tasks such as music tagging, music transcription, music source separation, and music mixing. Our results reveal that the features extracted from foundation models provide valuable enhancements in training downstream task models. This highlights the capability of using features extracted from music foundation models as a booster for downstream tasks. Our approach not only benefits existing task-specific models but also supports music downstream tasks constrained by data scarcity. This paves the way for more effective and accessible music processing solutions",
    "checked": true,
    "id": "fa689259129b052f5f97934128d476f7c82d4a23",
    "semantic_title": "music foundation model as generic booster for music downstream tasks",
    "citation_count": 1,
    "authors": [
      "Wei-Hsiang Liao",
      "Yuhta Takida",
      "Yukara Ikemiya",
      "Zhi Zhong",
      "Chieh-Hsin Lai",
      "Giorgio Fabbro",
      "Kazuki Shimada",
      "Keisuke Toyama",
      "Kin Wai Cheuk",
      "Marco A. Martínez-Ramírez",
      "Shusuke Takahashi",
      "Stefan Uhlich",
      "Taketo Akama",
      "Woosung Choi",
      "Yuichiro Koyama",
      "Yuki Mitsufuji"
    ]
  },
  "https://openreview.net/forum?id=pdC092Nn8N": {
    "title": "Studying Exploration in RL: An Optimal Transport Analysis of Occupancy Measure Trajectories",
    "volume": "main",
    "abstract": "The rising successes of RL are propelled by combining smart algorithmic strategies and deep architectures to optimize the distribution of returns and visitations over the state-action space. A quantitative framework to compare the learning processes of these eclectic RL algorithms is currently absent but desired in practice. We address this gap by representing the learning process of an RL algorithm as a sequence of policies generated during training, and then studying the policy trajectory induced in the manifold of state-action occupancy measures. Using an optimal transport-based metric, we measure the length of the paths induced by the policy sequence yielded by an RL algorithm between an initial policy and a final optimal policy. Hence, we first define the Effort of Sequential Learning (ESL). ESL quantifies the relative distance that an RL algorithm travels compared to the shortest path from the initial to the optimal policy. Furthermore, we connect the dynamics of policies in the occupancy measure space and regret (another metric to understand the suboptimality of an RL algorithm), by defining the Optimal Movement Ratio (OMR). OMR assesses the fraction of movements in the occupancy measure space that effectively reduce an analogue of regret. Finally, we derive approximation guarantees to estimate ESL and OMR with a finite number of samples and without access to an optimal policy. Through empirical analyses across various environments and algorithms, we demonstrate that ESL and OMR provide insights into the exploration processes of RL algorithms and the hardness of different tasks in discrete and continuous MDPs",
    "checked": true,
    "id": "04632d9d03d403371fece40a123c50fe7c246380",
    "semantic_title": "studying exploration in rl: an optimal transport analysis of occupancy measure trajectories",
    "citation_count": 1,
    "authors": [
      "Reabetswe M. Nkhumise",
      "Debabrota Basu",
      "Tony J. Prescott",
      "Aditya Gilra"
    ]
  },
  "https://openreview.net/forum?id=gG8sQUUtN7": {
    "title": "LASP: Linear Attention Sequence Parallelism",
    "volume": "main",
    "abstract": "Sequence parallelism (SP) serves as a prevalent strategy to handle long sequences that exceed the memory limit of a single device. However, for linear sequence modeling methods like linear attention, existing SP approaches do not take advantage of their right-product-first feature, resulting in sub-optimal communication efficiency and usability. In this paper, we introduce Linear Attention Sequence Parallelism (LASP), an efficient SP approach designed for linear attention-based transformer models. Specifically, we design an efficient point-to-point ring-style communication mechanism to leverage the right-product kernel trick of linear attention, which sharply decreases the communication overhead, comparing with existing SP methods. We enhance the computation efficiency of LASP by performing kernel fusion and intermediate state caching, making the implementation of LASP hardware-friendly on GPUs. Furthermore, we meticulously ensure the compatibility of sequence-level LASP with all types of batch-level data parallel methods, which is vital for distributed training on large clusters with very-long sequences. We also discuss the generalization of LASP on other linear sequence modeling methods. Extensive experiments on linear attention-based models are conducted with varying sequence lengths from 2K to 4096K. LASP scales sequence length up to 4096K on 128 GPUs, which is 8$\\times$ longer than existing SP methods. Code is available at: \\url{https://github.com/OpenNLPLab/LASP}",
    "checked": false,
    "id": "660d80773f55c5dc889de3ce93b71672133a91bc",
    "semantic_title": "linear attention sequence parallelism",
    "citation_count": 2,
    "authors": [
      "Weigao Sun",
      "Zhen Qin",
      "Dong Li",
      "Xuyang Shen",
      "Yu Qiao",
      "Yiran Zhong"
    ]
  },
  "https://openreview.net/forum?id=PHsfZnF2FC": {
    "title": "MOORL: A Framework for Integrating Offline-Online Reinforcement Learning",
    "volume": "main",
    "abstract": "Sample efficiency and exploration remain critical challenges in Deep Reinforcement Learning (DRL), particularly in complex domains. Offline RL, which enables agents to learn optimal policies from static, pre-collected datasets, has emerged as a promising alternative. However, offline RL is constrained by issues such as out-of-distribution (OOD) actions that limit policy performance and generalization. To overcome these limitations, we propose Meta Offline-Online Reinforcement Learning (MOORL), a hybrid framework that unifies offline and online RL for efficient and scalable learning. While previous hybrid methods rely on extensive design choices and added complexity to utilize offline data effectively, MOORL introduces a meta-policy that seamlessly adapts across offline and online trajectories. This enables the agent to leverage offline data for robust initialization while utilizing online interactions to drive efficient exploration. Importantly, MOORL addresses the key challenges of hybrid RL in terms of being design-free. Our theoretical analysis demonstrates that the hybrid approach enhances exploration by effectively combining the complementary strengths of offline and online data. Furthermore, we demonstrate that MOORL learns a stable Q-function without relying on extensive design choices. Extensive experiments on 28 tasks from the D4RL and V-D4RL benchmarks validate its effectiveness, showing consistent improvements over state-of-the-art offline and hybrid RL baselines. With minimal computational overhead, MOORL achieves strong performance, underscoring its potential for practical applications in real-world scenarios",
    "checked": true,
    "id": "37483be6933d29635e6a5483ba3f1ee2b3dcafc8",
    "semantic_title": "moorl: a framework for integrating offline-online reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Gaurav Chaudhary",
      "Washim Uddin Mondal",
      "Laxmidhar Behera"
    ]
  },
  "https://openreview.net/forum?id=2NSb3cJE03": {
    "title": "Time-Uniform Confidence Spheres for Means of Random Vectors",
    "volume": "main",
    "abstract": "We study sequential mean estimation in $\\mathbb{R}^d$. In particular, we derive time-uniform confidence spheres---\\emph{confidence sphere sequences} (CSSs)---which contain the mean of random vectors with high probability simultaneously across all sample sizes. Our results include a dimension-free CSS for log-concave random vectors, a dimension-free CSS for sub-Gaussian random vectors, and CSSs for sub-$\\psi$ random vectors (which includes sub-gamma, and sub-exponential distributions). Many of our results are optimal. For sub-Gaussian distributions we also provide a CSS which tracks a time-varying mean, generalizing Robbins' mixture approach to the multivariate setting. Finally, we provide several CSSs for heavy-tailed random vectors (two moments only). Our bounds hold under a martingale assumption on the mean and do not require that the observations be iid. Our work is based on PAC-Bayesian theory and inspired by an approach of Catoni and Giulini",
    "checked": true,
    "id": "bae0a4cff6524737f0d519cc22db8cc13752d745",
    "semantic_title": "time-uniform confidence spheres for means of random vectors",
    "citation_count": 5,
    "authors": [
      "Ben Chugg",
      "Hongjian Wang",
      "Aaditya Ramdas"
    ]
  },
  "https://openreview.net/forum?id=6BlOCx5c5T": {
    "title": "How far away are truly hyperparameter-free learning algorithms?",
    "volume": "main",
    "abstract": "Despite major advances in methodology, hyperparameter tuning remains a crucial (and expensive) part of the development of machine learning systems. Even ignoring architectural choices, deep neural networks have a large number of optimization and regularization hyperparameters that need to be tuned carefully per workload in order to obtain the best results. In a perfect world, training algorithms would not require workload-specific hyperparameter tuning, but would instead have default settings that performed well across many workloads. Recently, there has been a growing literature on optimization methods which attempt to reduce the number of hyperparameters---particularly the learning rate and its accompanying schedule. Given these developments, how far away is the dream of neural network training algorithms that completely obviate the need for painful tuning? In this paper, we evaluate the potential of learning-rate-free methods as components of hyperparameter-free methods. We freeze their (non-learning rate) hyperparameters to default values, and score their performance using the recently-proposed AlgoPerf: Training Algorithms benchmark. We found that literature-supplied default settings performed poorly on the benchmark, so we performed a search for hyperparameter configurations that performed well across all workloads simultaneously. The best \"algoperf-calibrated\" learning-rate-free methods had much improved performance but still lagged slightly behind a similarly calibrated NadamW baseline in overall benchmark score. Our results suggest that there is still much room for improvement for learning-rate-free methods, and that testing against a strong, workload-agnostic baseline is important to improve hyperparameter reduction techniques",
    "checked": true,
    "id": "eb917217a143ceb9059bbf6659020741a1fba00e",
    "semantic_title": "how far away are truly hyperparameter-free learning algorithms?",
    "citation_count": 0,
    "authors": [
      "Priya Kasimbeg",
      "Vincent Roulet",
      "Naman Agarwal",
      "Sourabh Medapati",
      "Fabian Pedregosa",
      "Atish Agarwala",
      "George E. Dahl"
    ]
  },
  "https://openreview.net/forum?id=VTgixSbrJI": {
    "title": "Hitchhiker's guide on the relation of Energy-Based Models with other generative models, sampling and statistical physics: a comprehensive review",
    "volume": "main",
    "abstract": "Energy-Based Models (EBMs) have emerged as a powerful framework in the realm of generative modeling, offering a unique perspective that aligns closely with principles of statistical mechanics. This review aims to provide physicists with a comprehensive understanding of EBMs, delineating their connection to other generative models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Normalizing Flows. We explore the sampling techniques crucial for EBMs, including Markov Chain Monte Carlo (MCMC) methods, and draw parallels between EBM concepts and statistical mechanics, highlighting the significance of energy functions and partition functions. Furthermore, we delve into state-of-the-art training methodologies for EBMs, covering recent advancements and their implications for enhanced model performance and efficiency. This review is designed to clarify the often complex interconnections between these models, which can be challenging due to the diverse communities working on the topic",
    "checked": true,
    "id": "6d9a3d849928c1e569a5fc10ff72241edfe42b15",
    "semantic_title": "hitchhiker's guide on the relation of energy-based models with other generative models, sampling and statistical physics: a comprehensive review",
    "citation_count": 1,
    "authors": [
      "Davide Carbone"
    ]
  },
  "https://openreview.net/forum?id=VPl3T43Hxb": {
    "title": "A Local Polyak-Łojasiewicz and Descent Lemma of Gradient Descent For Overparametrized Linear Models",
    "volume": "main",
    "abstract": "Most prior work on the convergence of gradient descent (GD) for overparameterized neural networks relies on strong assumptions on the step size (infinitesimal), the hidden-layer width (infinite), or the initialization (large, spectral, balanced). Recent efforts to relax these assumptions focus on two-layer linear networks trained with the squared loss. In this work, we derive a linear convergence rate for training two-layer linear neural networks with GD for general losses and under relaxed assumptions on the step size, width, and initialization. A key challenge in deriving this result is that classical ingredients for deriving convergence rates for nonconvex problems, such as the Polyak-Łojasiewicz (PL) condition and Descent Lemma, do not hold globally for overparameterized neural networks. Here, we prove that these two conditions hold locally with local constants that depend on the weights. Then, we provide bounds on these local constants, which depend on the initialization of the weights, the current loss, and the global PL and smoothness constants of the non-overparameterized model. Based on these bounds, we derive a linear convergence rate for GD. Our convergence analysis not only improves upon prior results but also suggests a better choice for the step size, as verified through our numerical experiments",
    "checked": false,
    "id": "ad848a24708cf438340f97023c091908789c94db",
    "semantic_title": "a local polyak-lojasiewicz and descent lemma of gradient descent for overparametrized linear models",
    "citation_count": 0,
    "authors": [
      "Ziqing Xu",
      "Hancheng Min",
      "Salma Tarmoun",
      "Enrique Mallada",
      "Rene Vidal"
    ]
  },
  "https://openreview.net/forum?id=p499xXaclC": {
    "title": "Pruning Feature Extractor Stacking for Cross-domain Few-shot Learning",
    "volume": "main",
    "abstract": "Combining knowledge from source domains to learn efficiently from a few labelled instances in a target domain is a transfer learning problem known as cross-domain few-shot learning (CDFSL). Feature extractor stacking (FES) is a state-of-the-art CDFSL method that maintains a collection of source domain feature extractors instead of a single universal extractor. FES uses stacked generalisation to build an ensemble from extractor snapshots saved during target domain fine-tuning. It outperforms several contemporary universal model-based CDFSL methods in the Meta-Dataset benchmark. However, it incurs higher storage cost because it saves a snapshot for every fine-tuning iteration for every extractor. In this work, we propose a bidirectional snapshot selection strategy for FES, leveraging its cross-validation process and the ordered nature of its snapshots, and demonstrate that a 95% snapshot reduction can be achieved while retaining the same level of accuracy",
    "checked": true,
    "id": "6ed6f78ce0411a6f2bbf374741ffacc3d2e97f86",
    "semantic_title": "pruning feature extractor stacking for cross-domain few-shot learning",
    "citation_count": 0,
    "authors": [
      "Hongyu Wang",
      "Eibe Frank",
      "Bernhard Pfahringer",
      "Geoff Holmes"
    ]
  },
  "https://openreview.net/forum?id=nuN1mRrrjX": {
    "title": "Cometh: A continuous-time discrete-state graph diffusion model",
    "volume": "main",
    "abstract": "Discrete-state denoising diffusion models led to state-of-the-art performance in graph generation, especially in the molecular domain. Recently, they have been transposed to continuous time, allowing more flexibility in the reverse process and a better trade-off between sampling efficiency and quality. Here, to leverage the benefits of both approaches, we propose Cometh, a continuous-time discrete-state graph diffusion model, tailored to the specificities of graph data. In addition, we also successfully replaced the set of structural encodings previously used in the discrete graph diffusion model with a single random-walk-based encoding, providing a simple and principled way to boost the model's expressive power. Empirically, we show that integrating continuous time leads to significant improvements across various metrics over state-of-the-art discrete-state diffusion models on a large set of molecular and non-molecular benchmark datasets. In terms of VUN samples, Cometh obtains a near-perfect performance of 99.5% on the planar graph dataset and outperforms DiGress by 12.6% on the large GuacaMol dataset",
    "checked": true,
    "id": "4f31bcb88a7e6f50c308bb5cf2ea808a115af93e",
    "semantic_title": "cometh: a continuous-time discrete-state graph diffusion model",
    "citation_count": 6,
    "authors": [
      "Antoine Siraudin",
      "Fragkiskos D. Malliaros",
      "Christopher Morris"
    ]
  },
  "https://openreview.net/forum?id=LDBjgS5Ez7": {
    "title": "Uniform Noise Distribution and Compact Clusters: Unveiling the Success of Self-Supervised Learning in Label Noise",
    "volume": "main",
    "abstract": "Label noise is ubiquitous in real-world datasets, posing significant challenges to machine learning models. While self-supervised learning (SSL) algorithms have empirically demonstrated effectiveness in learning noisy labels, the theoretical understanding of their effectiveness remains underexplored. In this paper, we present a theoretical framework to understand how SSL methods enhance learning with noisy labels, especially for the instance-dependent label noise. We reveal that the uniform and compact cluster structures induced by contrastive SSL play a crucial role in mitigating the adverse effects of label noise. Specifically, we theoretically show that a classifier trained on SSL-learned representations significantly outperforms one trained using traditional supervised learning methods. This results from two key merits of SSL representations over label noise: 1. Uniform Noise Distribution: Label noise becomes uniformly distributed over SSL representations with respect to the true class labels, rather than the noisy ones, leading to an easier learning task. 2. Enhanced Cluster Structure: SSL enhances the formation of well-separated and compact categorical clusters, increasing inter-class distances while tightening intra-class clusters. We further theoretically justify the benefits of training a classifier on such structured representations, demonstrating that it encourages the classifier trained on noisy data to be aligned with the optimal classifier. Extensive experiments validate the robustness of SSL representations in combating label noise, confirming the practical values of our theoretical findings",
    "checked": true,
    "id": "b0b2f4ee06f222b7530ce9987ace66924364a1be",
    "semantic_title": "uniform noise distribution and compact clusters: unveiling the success of self-supervised learning in label noise",
    "citation_count": 0,
    "authors": [
      "Pengcheng Xu",
      "Li Yi",
      "Gezheng Xu",
      "Xi Chen",
      "Ian McLeod",
      "Charles Ling",
      "Boyu Wang"
    ]
  },
  "https://openreview.net/forum?id=S6JpSsYBDZ": {
    "title": "RefinedFields: Radiance Fields Refinement for Planar Scene Representations",
    "volume": "main",
    "abstract": "Planar scene representations have recently witnessed increased interests for modeling scenes from images, as their lightweight planar structure enables compatibility with image-based models. Notably, K-Planes have gained particular attention as they extend planar scene representations to support in-the-wild scenes, in addition to object-level scenes. However, their visual quality has recently lagged behind that of state-of-the-art techniques. To reduce this gap, we propose RefinedFields, a method that leverages pre-trained networks to refine K-Planes scene representations via optimization guidance using an alternating training procedure. We carry out extensive experiments and verify the merit of our method on synthetic data and real tourism photo collections. RefinedFields enhances rendered scenes with richer details and improves upon its base representation on the task of novel view synthesis. Our project page can be found at https://refinedfields.github.io",
    "checked": true,
    "id": "70920c90e1290a0d9363d65b940511b682bdf715",
    "semantic_title": "refinedfields: radiance fields refinement for planar scene representations",
    "citation_count": 0,
    "authors": [
      "Karim Kassab",
      "Antoine Schnepf",
      "Jean-Yves Franceschi",
      "Laurent Caraffa",
      "Jeremie Mary",
      "Valerie Gouet-Brunet"
    ]
  },
  "https://openreview.net/forum?id=NeQYi56MFj": {
    "title": "M3CoL: Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification",
    "volume": "main",
    "abstract": "Deep multimodal learning has shown remarkable success by leveraging contrastive learning to capture explicit one-to-one relations across modalities. However, real-world data often exhibits shared relations beyond simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive Learning approach to capture nuanced shared relations inherent in multimodal data. Our key contribution is a Mixup-based contrastive loss that learns robust representations by aligning mixed samples from one modality with their corresponding samples from other modalities thereby capturing shared relations between them. For multimodal classification tasks, we introduce a framework that integrates a fusion module with unimodal prediction modules for auxiliary supervision during training, complemented by our proposed Mixup-based contrastive loss. Through extensive experiments on diverse datasets (N24News, ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures shared multimodal relations and generalizes across domains. It outperforms state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving comparable performance on Food-101. Our work highlights the significance of learning shared relations for robust multimodal learning, opening up promising avenues for future research",
    "checked": false,
    "id": "baa3f5de929e76427312ae2c13d7d42444c355ca",
    "semantic_title": "harnessing shared relations via multimodal mixup contrastive learning for multimodal classification",
    "citation_count": 0,
    "authors": [
      "Raja Kumar",
      "Raghav Singhal",
      "Pranamya Prashant Kulkarni",
      "Deval Mehta",
      "Kshitij Sharad Jadhav"
    ]
  },
  "https://openreview.net/forum?id=N2rWhTgits": {
    "title": "Guided Discrete Diffusion for Electronic Health Record Generation",
    "volume": "main",
    "abstract": "Electronic health records (EHRs) are a pivotal data source that enables numerous applications in computational medicine, e.g., disease progression prediction, clinical trial design, and health economics and outcomes research. Despite wide usability, their sensitive nature raises privacy and confidentially concerns, which limit potential use cases. To tackle these challenges, we explore the use of generative models to synthesize artificial, yet realistic EHRs. While diffusion-based methods have recently demonstrated state-of-the-art performance in generating other data modalities and overcome the training instability and mode collapse issues that plague previous GAN-based approaches, their applications in EHR generation remain underexplored. The discrete nature of tabular medical code data in EHRs poses challenges for high-quality data generation, especially for continuous diffusion models. To this end, we introduce a novel tabular EHR generation method, EHR-D3PM, which enables both unconditional and conditional generation using the discrete diffusion model. Our experiments demonstrate that EHR-D3PM significantly outperforms existing generative baselines on comprehensive fidelity and utility metrics while maintaining less attribute and membership vulnerability risks. Furthermore, we show EHR-D3PM is effective as a data augmentation method and enhances performance on downstream tasks when combined with real data",
    "checked": true,
    "id": "3643812e72325a7d92e57b21ad2cb24faf563f30",
    "semantic_title": "guided discrete diffusion for electronic health record generation",
    "citation_count": 7,
    "authors": [
      "Jun Han",
      "Zixiang Chen",
      "Yongqian Li",
      "Yiwen Kou",
      "Eran Halperin",
      "Robert E. Tillman",
      "Quanquan Gu"
    ]
  },
  "https://openreview.net/forum?id=sq5AJvVuha": {
    "title": "DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models",
    "volume": "main",
    "abstract": "Learning useful representations for continuous-time dynamic graphs (CTDGs) is challenging, due to the concurrent need to span long node interaction histories and grasp nuanced temporal details. In particular, two problems emerge: (1) Encoding longer histories requires more computational resources, making it crucial for CTDG models to maintain low computational complexity to ensure efficiency; (2) Meanwhile, more powerful models are needed to identify and select the most critical temporal information within the extended context provided by longer histories. To address these problems, we propose a CTDG representation learning model named DyGMamba, originating from the popular Mamba state space model (SSM). DyGMamba first leverages a node-level SSM to encode the sequence of historical node interactions. Another time-level SSM is then employed to exploit the temporal patterns hidden in the historical graph, where its output is used to dynamically select the critical information from the interaction history. We validate DyGMamba experimentally on the dynamic link prediction task. The results show that our model achieves state-of-the-art in most cases. DyGMamba also maintains high efficiency in terms of computational resources, making it possible to capture long temporal dependencies with a limited computation budget",
    "checked": true,
    "id": "aeb6fbef9a2f455a71773488e09f1c4f6686ac55",
    "semantic_title": "dygmamba: efficiently modeling long-term temporal dependency on continuous-time dynamic graphs with state space models",
    "citation_count": 3,
    "authors": [
      "Zifeng Ding",
      "Yifeng Li",
      "Yuan He",
      "Antonio Norelli",
      "Jingcheng Wu",
      "Volker Tresp",
      "Michael M. Bronstein",
      "Yunpu Ma"
    ]
  },
  "https://openreview.net/forum?id=5f7YlSKG1l": {
    "title": "Towards identifiability of micro total effects in summary causal graphs with latent confounding: extension of the front-door criterion",
    "volume": "main",
    "abstract": "Conducting experiments to estimate total effects can be challenging due to cost, ethical concerns, or practical limitations. As an alternative, researchers often rely on causal graphs to determine whether these effects can be identified from observational data. Identifying total effects in fully specified causal graphs has received considerable attention, with Pearl's front-door criterion enabling the identification of total effects in the presence of latent confounding even when no variable set is sufficient for adjustment. However, specifying a complete causal graph is challenging in many domains. Extending these identifiability results to partially specified graphs is crucial, particularly in dynamic systems where causal relationships evolve over time. This paper addresses the challenge of identifying total effects using a specific and well-known partially specified graph in dynamic systems called a summary causal graph, which does not specify the temporal lag between causal relations and can contain cycles. In particular, this paper presents sufficient graphical conditions for identifying total effects from observational data, even in the presence of cycles and latent confounding, and when no variable set is sufficient for adjustment",
    "checked": true,
    "id": "3c5e09eeb9360cbeb8999f5ddde3f9bf0a9e57cd",
    "semantic_title": "towards identifiability of micro total effects in summary causal graphs with latent confounding: extension of the front-door criterion",
    "citation_count": 2,
    "authors": [
      "Charles K. Assaad"
    ]
  },
  "https://openreview.net/forum?id=ZrqLpXbXvA": {
    "title": "Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning",
    "volume": "main",
    "abstract": "Causal approaches to post-hoc explainability for black-box prediction models (e.g., deep neural networks trained on image pixel data) have become increasingly popular. However, existing approaches have two important shortcomings: (i) the \"explanatory units\" are micro-level inputs into the relevant prediction model, e.g., image pixels, rather than interpretable macro-level features that are more useful for understanding how to possibly change the algorithm's behavior, and (ii) existing approaches assume there exists no unmeasured confounding between features and target model predictions, which fails to hold when the explanatory units are macro-level variables. Our focus is on the important setting where the analyst has no access to the inner workings of the target prediction algorithm, rather only the ability to query the output of the model in response to a particular input. To provide causal explanations in such a setting, we propose to learn causal graphical representations that allow for arbitrary unmeasured confounding among features. We demonstrate the resulting graph can differentiate between interpretable features that causally influence model predictions versus those that are merely associated with model predictions due to confounding. Our approach is motivated by a counterfactual theory of causal explanation wherein good explanations point to factors that are \"difference-makers\" in an interventionist sense",
    "checked": false,
    "id": "6e2836fc572ef2f9d2965e64ef5ba17d7eb48d03",
    "semantic_title": "petrophysical prediction of oil reservoirs using explainable artificial intelligence",
    "citation_count": 0,
    "authors": [
      "Numair Sani",
      "Daniel Malinsky",
      "Ilya Shpitser"
    ]
  },
  "https://openreview.net/forum?id=z3JZzu9EA3": {
    "title": "A Survey on Large Language Model Acceleration based on KV Cache Management",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) have revolutionized a wide range of domains such as natural language processing, computer vision, and multi-modal tasks due to their ability to comprehend context and perform logical reasoning. However, the computational and memory demands of LLMs, particularly during inference, pose significant challenges when scaling them to real-world, long-context, and real-time applications. Key-Value (KV) cache management has emerged as a critical optimization technique for accelerating LLM inference by reducing redundant computations and improving memory utilization. This survey provides a comprehensive overview of KV cache management strategies for LLM acceleration, categorizing them into token-level, model-level, and system-level optimizations. Token-level strategies include KV cache selection, budget allocation, merging, quantization, and low-rank decomposition, while model-level optimizations focus on architectural innovations and attention mechanisms to enhance KV reuse. System-level approaches address memory management, scheduling, and hardware-aware designs to improve efficiency across diverse computing environments. Additionally, the survey provides an overview of both text and multimodal datasets and benchmarks used to evaluate these strategies. By presenting detailed taxonomies and comparative analyses, this work aims to offer useful insights for researchers and practitioners to support the development of efficient and scalable KV cache management techniques, contributing to the practical deployment of LLMs in real-world applications",
    "checked": true,
    "id": "6bcd708d2e49b34f34f157daa6bf1c3e062f57c5",
    "semantic_title": "a survey on large language model acceleration based on kv cache management",
    "citation_count": 20,
    "authors": [
      "Haoyang LI",
      "Yiming Li",
      "Anxin Tian",
      "Tianhao Tang",
      "Zhanchao Xu",
      "Xuejia Chen",
      "Nicole HU",
      "Wei Dong",
      "Li Qing",
      "Lei Chen"
    ]
  },
  "https://openreview.net/forum?id=CkVlt2Qgdb": {
    "title": "Investigating the Effects of Fairness Interventions Using Pointwise Representational Similarity",
    "volume": "main",
    "abstract": "Machine learning (ML) algorithms can often exhibit discriminatory behavior, negatively affecting certain populations across protected groups. To address this, numerous debiasing methods, and consequently evaluation measures, have been proposed. Current evaluation measures for debiasing methods suffer from two main limitations: (1) they primarily provide a global estimate of unfairness, failing to provide a more fine-grained analysis, and (2) they predominantly analyze the model output on a specific task, failing to generalize the findings to other tasks. In this work, we introduce Pointwise Normalized Kernel Alignment (PNKA), a pointwise representational similarity measure that addresses these limitations by measuring how debiasing measures affect the intermediate representations of individuals. On tabular data, the use of PNKA reveals previously unknown insights: while group fairness predominantly influences a small subset of the population, maintaining high representational similarity for the majority, individual fairness constraints uniformly impact representations across the entire population, altering nearly every data point. We show that by evaluating representations using PNKA, we can reliably predict the behavior of ML models trained on these representations. Moreover, applying PNKA to language embeddings shows that existing debiasing methods may not perform as intended, failing to remove biases from stereotypical words and sentences. Our findings suggest that current evaluation measures for debiasing methods are insufficient, highlighting the need for a deeper understanding of the effects of debiasing methods, and show how pointwise representational similarity metrics can help with fairness audits",
    "checked": true,
    "id": "8868ef9a05d5064e66ca9818ff0605b4a1e41567",
    "semantic_title": "investigating the effects of fairness interventions using pointwise representational similarity",
    "citation_count": 1,
    "authors": [
      "Camila Kolling",
      "Till Speicher",
      "Vedant Nanda",
      "Mariya Toneva",
      "Krishna P. Gummadi"
    ]
  },
  "https://openreview.net/forum?id=ZgjhykPSdU": {
    "title": "Statistical Error Bounds for GANs with Nonlinear Objective Functionals",
    "volume": "main",
    "abstract": "Generative adversarial networks (GANs) are unsupervised learning methods for training a generator distribution to produce samples that approximate those drawn from a target distribution. Many such methods can be formulated as minimization of a metric or divergence between probability distributions. Recent works have derived statistical error bounds for GANs that are based on integral probability metrics (IPMs), e.g., WGAN which is based on the 1-Wasserstein metric. In general, IPMs are defined by optimizing a linear functional (difference of expectations) over a space of discriminators. A much larger class of GANs, which we here call $(f,\\Gamma)$-GANs, can be constructed using $f$-divergences (e.g., Jensen-Shannon, KL, or $\\alpha$-divergences) together with a regularizing discriminator space $\\Gamma$ (e.g., $1$-Lipschitz functions). These GANs have nonlinear objective functions, depending on the choice of $f$, and have been shown to exhibit improved performance in a number of applications. In this work we derive statistical error bounds for $(f,\\Gamma)$-GANs for general classes of $f$ and $\\Gamma$ in the form of finite-sample concentration inequalities. These results prove the statistical consistency of $(f,\\Gamma)$-GANs and reduce to the known results for IPM-GANs in the appropriate limit. Our results use novel Rademacher complexity bounds which provide new insight into the performance of IPM-GANs for distributions with unbounded support and have application to statistical learning tasks beyond GANs",
    "checked": true,
    "id": "53dae7b4af66074490adcc15f27a9444673faad4",
    "semantic_title": "statistical error bounds for gans with nonlinear objective functionals",
    "citation_count": 0,
    "authors": [
      "Jeremiah Birrell"
    ]
  },
  "https://openreview.net/forum?id=JkMifr17wc": {
    "title": "Closed-Form Diffusion Models",
    "volume": "main",
    "abstract": "Score-based generative models (SGMs) sample from a target distribution by iteratively transforming noise using the score function of the perturbed target. For any finite training set, this score function can be evaluated in closed form, but the resulting SGM memorizes its training data and does not generate novel samples. In practice, one approximates the score by training a neural network via score-matching. The error in this approximation promotes generalization, but neural SGMs are costly to train and sample, and the effective regularization this error provides is not well-understood theoretically. In this work, we instead explicitly smooth the closed-form score to obtain an SGM that generates novel samples without training. We analyze our model and propose an efficient nearest-neighbor-based estimator of its score function. Using this estimator, our method achieves competitive sampling times while running on consumer-grade CPUs",
    "checked": true,
    "id": "1242e11e676fe238157127ef2825b89c50d99d10",
    "semantic_title": "closed-form diffusion models",
    "citation_count": 12,
    "authors": [
      "Christopher Scarvelis",
      "Haitz Sáez de Ocáriz Borde",
      "Justin Solomon"
    ]
  },
  "https://openreview.net/forum?id=Oyueig10Ed": {
    "title": "Policy Optimization via Adv2: Adversarial Learning on Advantage Functions",
    "volume": "main",
    "abstract": "We revisit the reduction of learning in adversarial Markov decision processes [MDPs] to adversarial learning based on $Q$--values; this reduction has been considered in a number of recent articles as one building block to perform policy optimization. Namely, we first consider and extend this reduction in an ideal setting where an oracle provides value functions: it may involve any adversarial learning strategy (not just exponential weights) and it may be based indifferently on $Q$--values or on advantage functions. We then present two extensions: on the one hand, convergence of the last iterate for a vast class of adversarial learning strategies (again, not just exponential weights), satisfying a property called monotonicity of weights; on the other hand, stronger regret criteria for learning in MDPs, inherited from the stronger regret criteria of adversarial learning called strongly adaptive regret and tracking regret. Third, we demonstrate how adversarial learning, also referred to as aggregation of experts, relates to aggregation (orchestration) of expert policies: we obtain stronger forms of performance guarantees in this setting than existing ones, via yet another, simple reduction. Finally, we discuss the impact of the reduction of learning in adversarial MDPs to adversarial learning in the practical scenarios where transition kernels are unknown and value functions must be learned. In particular, we review the literature and note that many strategies for policy optimization feature a policy-improvement step based on exponential weights with estimated $Q$--values. Our main message is that this step may be replaced by the application of any adversarial learning strategy on estimated $Q$--values or on estimated advantage functions. We leave the empirical evaluation of these twists for future research",
    "checked": true,
    "id": "2c860df4131cb10fb94821cec993699fd2d46f50",
    "semantic_title": "policy optimization via adv2: adversarial learning on advantage functions",
    "citation_count": 2,
    "authors": [
      "Matthieu Jonckheere",
      "Chiara Mignacco",
      "Gilles Stoltz"
    ]
  },
  "https://openreview.net/forum?id=4xXJDO8Bvu": {
    "title": "Node Classification With Reject Option",
    "volume": "main",
    "abstract": "One of the key tasks in graph learning is node classification. While Graph neural networks have been used for various applications, their adaptivity to reject option settings has not been previously explored. In this paper, we propose NCwR, a novel approach to node classification in Graph Neural Networks (GNNs) with an integrated reject option. This allows the model to abstain from making predictions for samples with high uncertainty. We propose cost-based and coverage-based methods for classification with abstention in node classification settings using GNNs. We perform experiments using our method on standard citation network datasets Cora, CiteSeer, PubMed and ogbn-arxiv. We also model the Legal judgment prediction problem on the ILDC dataset as a node classification problem, where nodes represent legal cases and edges represent citations. We further interpret the model by analyzing the cases in which it abstains from predicting and visualizing which part of the input features influenced this decision",
    "checked": true,
    "id": "7be8668a9dfc33278b868b3fa4176f01e11185ae",
    "semantic_title": "node classification with reject option",
    "citation_count": 0,
    "authors": [
      "Uday Bhaskar Kuchipudi",
      "Jayadratha Gayen",
      "Charu Sharma",
      "Naresh Manwani"
    ]
  },
  "https://openreview.net/forum?id=xT8BEgXmVc": {
    "title": "Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models",
    "volume": "main",
    "abstract": "Learning a world model for model-free Reinforcement Learning (RL) agents can significantly improve the sample efficiency by learning policies in imagination. However, building a world model for Multi-Agent RL (MARL) can be particularly challenging due to the scalability issue across different number of agents in a centralized architecture, and also the non-stationarity issue in a decentralized architecture stemming from the inter-dependency among agents. To address both challenges, we propose a novel world model for MARL that learns decentralized local dynamics for scalability, combined with a centralized representation aggregation from all agents. We cast the dynamics learning as an auto-regressive sequence modeling problem over discrete tokens by leveraging the expressive Transformer architecture, in order to model complex local dynamics across different agents and provide accurate and consistent long-term imaginations. As the first pioneering Transformer-based world model for multi-agent systems, we introduce a Perceiver Transformer as an effective solution to enable centralized representation aggregation within this context. Extensive results on Starcraft Multi-Agent Challenge (SMAC) and MAMujoco demonstrate superior sample efficiency and overall performance compared to strong model-free approaches and existing model-based methods",
    "checked": true,
    "id": "ba5420997282c19fa04db9cbe8d9e877ef4f73c4",
    "semantic_title": "decentralized transformers with centralized aggregation are sample-efficient multi-agent world models",
    "citation_count": 2,
    "authors": [
      "Yang Zhang",
      "Chenjia Bai",
      "Bin Zhao",
      "Junchi Yan",
      "Xiu Li",
      "Xuelong Li"
    ]
  },
  "https://openreview.net/forum?id=3cnpZ5SIjU": {
    "title": "Hard-Negative Sampling for Contrastive Learning: Optimal Representation Geometry and Neural- vs Dimensional-Collapse",
    "volume": "main",
    "abstract": "For a widely-studied data model and general loss and sample-hardening functions we prove that the losses of Supervised Contrastive Learning (SCL), Hard-SCL (HSCL), and Unsupervised Contrastive Learning (UCL) are minimized by representations that exhibit Neural-Collapse (NC), i.e., the class means form an Equiangular Tight Frame (ETF) and data from the same class are mapped to the same representation. We also prove that for any representation mapping, the HSCL and Hard-UCL (HUCL) losses are lower bounded by the corresponding SCL and UCL losses. In contrast to existing literature, our theoretical results for SCL do not require class-conditional independence of augmented views and work for a general loss function class that includes the widely used InfoNCE loss function. Moreover, our proofs are simpler, compact, and transparent. Similar to existing literature, our theoretical claims also hold for the practical scenario where batching is used for optimization. We empirically demonstrate, for the first time, that Adam optimization (with batching) of HSCL and HUCL losses with random initialization and suitable hardness levels can indeed converge to the NC-geometry if we incorporate unit-ball or unit-sphere feature normalization. Without incorporating hard-negatives or feature normalization, however, the representations learned via Adam suffer from Dimensional-Collapse (DC) and fail to attain the NC-geometry. These results exemplify the role of hard-negative sampling in contrastive representation learning and we conclude with several open theoretical problems for future work. The code can be found at https://github.com/rjiang03/HCL/tree/main",
    "checked": true,
    "id": "d97fda96d01250760a192547e2dd1357f1c40d3a",
    "semantic_title": "hard-negative sampling for contrastive learning: optimal representation geometry and neural- vs dimensional-collapse",
    "citation_count": 2,
    "authors": [
      "Ruijie Jiang",
      "Thuan Nguyen",
      "Shuchin Aeron",
      "Prakash Ishwar"
    ]
  },
  "https://openreview.net/forum?id=Ckh17xN2R2": {
    "title": "Infrastructure for AI Agents",
    "volume": "main",
    "abstract": "\\textbf{AI agents} plan and execute interactions in open-ended environments. For example, OpenAI's Operator can use a web browser to do product comparisons and buy online goods. To facilitate beneficial interactions and mitigate harmful ones, much research focuses on directly modifying agent behaviour. For example, developers can train agents to follow user instructions. This focus on direct modifications is useful, but insufficient. We will also need external protocols and systems that shape how agents interact with institutions and other actors. For instance, agents will need more efficient protocols to communicate with each other and form agreements. In addition, attributing an agent's actions to a particular human or other legal entity can help to establish trust, and also disincentivize misuse. Given this motivation, we propose the concept of \\textbf{agent infrastructure}: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Just as the Internet relies on protocols like HTTPS, our work argues that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents' interactions; and 3) detecting and remedying harmful actions from agents. We provide an incomplete catalog of research directions for such functions. For each direction, we include analysis of use cases, infrastructure adoption, relationships to existing (internet) infrastructure, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents",
    "checked": true,
    "id": "9504e2f28fd2316124d45bdb216f58781e1b81b6",
    "semantic_title": "infrastructure for ai agents",
    "citation_count": 3,
    "authors": [
      "Alan Chan",
      "Kevin Wei",
      "Sihao Huang",
      "Nitarshan Rajkumar",
      "Elija Perrier",
      "Seth Lazar",
      "Gillian K Hadfield",
      "Markus Anderljung"
    ]
  },
  "https://openreview.net/forum?id=WADLPccB6o": {
    "title": "Conformal Bounds on Full-Reference Image Quality for Imaging Inverse Problems",
    "volume": "main",
    "abstract": "In imaging inverse problems, we would like to know how close the recovered image is to the true image in terms of full-reference image quality (FRIQ) metrics like PSNR, SSIM, LPIPS, etc. This is especially important in safety-critical applications like medical imaging, where knowing that, say, the SSIM was poor could potentially avoid a costly misdiagnosis. But since we don't know the true image, computing FRIQ is non-trivial. In this work, we combine conformal prediction with approximate posterior sampling to construct bounds on FRIQ that are guaranteed to hold up to a user-specified error probability. We demonstrate our approach on image denoising and accelerated magnetic resonance imaging (MRI) problems",
    "checked": true,
    "id": "15c5ada80de939768177c5d13614f2de8f4abe5b",
    "semantic_title": "conformal bounds on full-reference image quality for imaging inverse problems",
    "citation_count": 0,
    "authors": [
      "Jeffrey Wen",
      "Rizwan Ahmad",
      "Philip Schniter"
    ]
  },
  "https://openreview.net/forum?id=k1eYngOvf0": {
    "title": "G-RepsNet: A Lightweight Construction of Equivariant Networks for Arbitrary Matrix Groups",
    "volume": "main",
    "abstract": "Group equivariance is a strong inductive bias useful in a wide range of deep learning tasks. However, constructing efficient equivariant networks for general groups and domains is difficult. Recent work by Finzi et al. directly solves the equivariance constraint for arbitrary matrix groups to obtain equivariant MLPs (EMLPs). But this method does not scale well and scaling is crucial in deep learning. Here, we introduce Group Representation Networks (G-RepsNets), a lightweight equivariant network for arbitrary matrix groups with features represented using tensor polynomials. The key insight in our design is that using tensor representations in the hidden layers of a neural network along with simple inexpensive tensor operations leads to scalable equivariant networks. Further, these networks are universal approximators of functions equivariant to orthogonal groups. We find G-RepsNet to be competitive to EMLP on several tasks with group symmetries such as $O(5)$, $O(1, 3)$, and $O(3)$ with scalars, vectors, and second-order tensors as data types. On image classification tasks, we find that G-RepsNet using second-order representations is competitive and often even outperforms sophisticated state-of-the-art equivariant models such as GCNNs and $E(2)$-CNNs. To further illustrate the generality of our approach, we show that G-RepsNet is competitive to G-FNO and EGNN on N-body predictions and solving PDEs respectively, while being efficient",
    "checked": true,
    "id": "9f24687521c534aaa822970176d6ea7e3cd2b164",
    "semantic_title": "g-repsnet: a lightweight construction of equivariant networks for arbitrary matrix groups",
    "citation_count": 0,
    "authors": [
      "Sourya Basu",
      "Suhas Lohit",
      "Matthew Brand"
    ]
  },
  "https://openreview.net/forum?id=4uPJN6yfY1": {
    "title": "Retrieve, Merge, Predict: Augmenting Tables with Data Lakes",
    "volume": "main",
    "abstract": "Machine-learning from a disparate set of tables, a data lake, requires assembling features by merging and aggregating tables. Data discovery can extend autoML to data tables by automating these steps. We present an in-depth analysis of such automated table augmentation for machine learning tasks, analyzing different methods for the three main steps: retrieving joinable tables, merging information, and predicting with the resultant table. We use two data lakes: Open Data US, a well-referenced real data lake, and a novel semi-synthetic dataset, YADL (Yet Another Data Lake), which we developed as a tool for benchmarking this data discovery task. Systematic exploration on both lakes outlines 1) the importance of accurately retrieving join candidates, 2) the efficiency of simple merging methods, and 3) the resilience of tree-based learners to noisy conditions. Our experimental environment is easily reproducible and based on open data, to foster more research on feature engineering, autoML, and learning in data lakes",
    "checked": true,
    "id": "33c4cea9159564a7bc4239f183c7b0bf6ecc4fff",
    "semantic_title": "retrieve, merge, predict: augmenting tables with data lakes",
    "citation_count": 4,
    "authors": [
      "Riccardo Cappuzzo",
      "Aimee Coelho",
      "Félix Lefebvre",
      "Paolo Papotti",
      "Gaël Varoquaux"
    ]
  },
  "https://openreview.net/forum?id=55593xywWG": {
    "title": "Foundation Models Meet Federated Learning: A One-shot Feature-sharing Method with Privacy and Performance Guarantees",
    "volume": "main",
    "abstract": "Adapting foundation models for downstream tasks via Federated Learning (FL) is a promising strategy for protecting privacy while leveraging the capability of foundation models. However, FL's iterative training and model transmission result in high communication costs and GPU memory demands, making large foundation models impractical for FL. This paper introduces a one-shot FL method with a server-side performance bound to enable foundation models by reducing communication costs and GPU memory requirements. Our approach, FedPFT (FL with Parametric Feature Transfer), involves clients learning and transferring parametric models for features extracted from frozen foundation models in a single round. Parametric models are then used to generate synthetic features at the server to train a classifier head. We evaluate FedPFT across eight vision datasets using three vision foundation models. Our findings demonstrate that FedPFT is agnostic to data heterogeneity and network topology and it enhances the communication-accuracy frontier up to 7.8\\%. Finally, we show FedPFT's compatibility with differential privacy and its resilience against reconstruction attacks. Our work highlights the capability of private, feature-sharing methods for one-shot knowledge transfer using foundation models",
    "checked": true,
    "id": "5742a26c384f25c507b1ef60b356b5021ba54c8b",
    "semantic_title": "foundation models meet federated learning: a one-shot feature-sharing method with privacy and performance guarantees",
    "citation_count": 0,
    "authors": [
      "Mahdi Beitollahi",
      "Alex Bie",
      "Sobhan Hemati",
      "Leo Maxime Brunswic",
      "Xu Li",
      "Xi Chen",
      "Guojun Zhang"
    ]
  },
  "https://openreview.net/forum?id=XHXAvACdgv": {
    "title": "NITO: Neural Implicit Fields for Resolution-free and Domain-Adaptable Topology Optimization",
    "volume": "main",
    "abstract": "Structural topology optimization plays a crucial role in engineering by determining the optimal material layout within a design space to maximize performance under given constraints. We introduce Neural Implicit Topology Optimization (NITO), a deep learning regression approach to accelerate topology optimization tasks. We demonstrate that, compared to state-of-the-art diffusion models, NITO generates structures that are under 15% as structurally sub-optimal and does so ten times faster. Furthermore, we show that NITO is entirely resolution-free and domain-agnostic, offering a more scalable solution than the current fixed-resolution and domain-specific diffusion models. To achieve this state-of-the-art performance, NITO combines three key innovations. First, we introduce the Boundary Point Order-Invariant MLP (BPOM), which represents loads and supports in a sparse and domain-agnostic manner, allowing NITO to train on variable conditioning, domain shapes, and mesh resolutions. Second, we adopt a neural implicit field representation, which allows NITO to synthesize topologies of any shape or resolution. Finally, we propose an inference-time refinement step using a few steps of gradient-based optimization to enable NITO to achieve results comparable to direct optimization methods. These three innovations empower NITO with a precision and versatility that is currently unparalleled among competing deep learning approaches for topology optimization. Code & Data: https://github.com/ahnobari/NITO_Public",
    "checked": true,
    "id": "c2d3f7cd3f62e967c3513dbe5d818394e445d5c2",
    "semantic_title": "nito: neural implicit fields for resolution-free and domain-adaptable topology optimization",
    "citation_count": 0,
    "authors": [
      "Amin Heyrani Nobari",
      "Lyle Regenwetter",
      "Giorgio Giannone",
      "Faez Ahmed"
    ]
  },
  "https://openreview.net/forum?id=tYjoHjShxF": {
    "title": "An Empirical Study of Pre-trained Model Selection for Out-of-Distribution Generalization and Calibration",
    "volume": "main",
    "abstract": "In out-of-distribution (OOD) generalization tasks, fine-tuning pre-trained models has become a prevalent strategy. Different from most prior work that has focused on advancing learning algorithms, we systematically examined how pre-trained model size, pre-training dataset size, and training strategies impact generalization and uncertainty calibration on downstream tasks. We evaluated 100 models across diverse pre-trained model sizes, five pre-training datasets, and five data augmentations through extensive experiments on four distribution shift datasets totaling over 120,000 GPU hours. Our results demonstrate the significant impact of pre-trained model selection, with optimal choices substantially improving OOD accuracy over algorithm improvement alone. Additionally, we find that larger models and bigger pre-training datasets not only enhance OOD performance but also improve calibration, helping to mitigate overconfidence, contrary to some prior studies that found modern deep networks to calibrate worse than classical shallow models. Our work underscores the overlooked importance of pre-trained model selection for out-of-distribution generalization and calibration",
    "checked": true,
    "id": "37f729f59495f001cee0eff1637afdb92f1ab3e7",
    "semantic_title": "an empirical study of pre-trained model selection for out-of-distribution generalization and calibration",
    "citation_count": 3,
    "authors": [
      "Hiroki Naganuma",
      "Ryuichiro Hataya",
      "Kotaro Yoshida",
      "Ioannis Mitliagkas"
    ]
  },
  "https://openreview.net/forum?id=Hy2KAldqAo": {
    "title": "Robust Offline Imitation Learning from Diverse Auxiliary Data",
    "volume": "main",
    "abstract": "Offline imitation learning enables learning a policy solely from a set of expert demonstrations, without any environment interaction. To alleviate the issue of distribution shift arising due to the small amount of expert data, recent works incorporate large numbers of auxiliary demonstrations alongside the expert data. However, the performance of these approaches rely on assumptions about the quality and composition of the auxiliary data, and they are rarely successful when those assumptions do not hold. To address this limitation, we propose Robust Offline Imitation from Diverse Auxiliary Data (ROIDA). ROIDA first identifies high-quality transitions from the entire auxiliary dataset using a learned reward function. These high-reward samples are combined with the expert demonstrations for weighted behavioral cloning. For lower-quality samples, ROIDA applies temporal difference learning to steer the policy towards high-reward states, improving long-term returns. This two-pronged approach enables our framework to effectively leverage both high and low-quality data without any assumptions. Extensive experiments validate that ROIDA achieves robust and consistent performance across multiple auxiliary datasets with diverse ratios of expert and non-expert demonstrations. ROIDA effectively leverages unlabeled auxiliary data, outperforming prior methods reliant on specific data assumptions",
    "checked": true,
    "id": "a2fcaf0e11b80e431e2e8bbac2916c29702a4402",
    "semantic_title": "robust offline imitation learning from diverse auxiliary data",
    "citation_count": 1,
    "authors": [
      "Udita Ghosh",
      "Dripta S. Raychaudhuri",
      "Jiachen Li",
      "Konstantinos Karydis",
      "Amit Roy-Chowdhury"
    ]
  },
  "https://openreview.net/forum?id=7KkytYYhMv": {
    "title": "Rethinking the Value of Training-Free Structured Pruning of LLMs",
    "volume": "main",
    "abstract": "This paper investigates the effectiveness of training-free structured pruning techniques for Large Language Models (LLMs), with a particular focus on depth and width pruning strategies. Through an extensive empirical evaluation across a diverse range of tasks, datasets and modalities, we reveal critical limitations in current pruning methods. While some tasks exhibit minimal performance degradation, others face significant deterioration, even at low pruning rates, contradicting prior findings that often rely on selective benchmarks. Our analysis also finds that depth pruning, despite its simplicity, usually outperforms the more granular width pruning approaches in maintaining downstream task performance. Our findings highlight that existing evaluations of pruned LLMs often overstate their effectiveness due to incomplete or limited evaluation tasks, necessitating a critical reassessment of the true value of pruning and emphasizing the need to explore more robust pruning algorithms",
    "checked": true,
    "id": "b25aa26caaaf5b1a048dc12309bf1e0085e80e4e",
    "semantic_title": "rethinking the value of training-free structured pruning of llms",
    "citation_count": 0,
    "authors": [
      "Nahush Lele",
      "Arnav Chavan",
      "Aryamaan Thakur",
      "Deepak Gupta"
    ]
  },
  "https://openreview.net/forum?id=Qhfw5CUVd7": {
    "title": "FGAIF: Aligning Large Vision-Language Models with Fine-grained AI Feedback",
    "volume": "main",
    "abstract": "Large Vision-Language Models (LVLMs) have demonstrated proficiency in tackling a variety of visual-language tasks. However, current LVLMs suffer from misalignment between text and image modalities which causes three kinds of hallucination problems, i.e., object existence, object attribute, and object relationship. To tackle this issue, existing methods mainly utilize Reinforcement Learning (RL) to align modalities in LVLMs. However, they still suffer from three main limitations: (1) General feedback can not indicate the hallucination type contained in the response; (2) Sparse rewards only give the sequence-level reward for the whole response; and (3)Annotation cost is time-consuming and labor-intensive. To handle these limitations, we propose an innovative method to align modalities in LVLMs through \\textbf{F}ine-\\textbf{G}rained \\textbf{A}rtificial \\textbf{I}ntelligence \\textbf{F}eedback (\\textbf{\\ours}), which mainly consists of three steps: AI-based Feedback Collection, Fine-grained Reward Model Training, and Reinforcement Learning with Fine-grained Reward. Finally, a novel fine-grained feedback module is integrated into the Proximal Policy Optimization (PPO) algorithm. Extensive experiments are conducted on hallucination and general benchmarks, demonstrating the superior performance of our proposed method. Notably, compared with previous models trained with the RL-based aligning method, our proposed method is effective even with fewer parameters",
    "checked": true,
    "id": "fa84ef486184eb1c3d63949b700342bbcaf7b0c7",
    "semantic_title": "fgaif: aligning large vision-language models with fine-grained ai feedback",
    "citation_count": 18,
    "authors": [
      "Liqiang Jing",
      "Xinya Du"
    ]
  },
  "https://openreview.net/forum?id=OE4P1tW8iQ": {
    "title": "Noise-free Loss Gradients: A Surprisingly Effective Baseline for Coreset Selection",
    "volume": "main",
    "abstract": "The exponential rise in size and complexity of deep learning models and datasets have resulted in a considerable demand for computational resources. Coreset selection is one of the methods to alleviate this rising demand. The goal is to select a subset from a large dataset to train a model that performs almost at par with the one trained on the large dataset while reducing computational time and resource requirements. Existing approaches either attempt to identify remarkable samples (e.g., Forgetting, Adversarial Deepfool, EL2N, etc.) that stand out from the rest or solve complex optimization (e.g., submodular maximization, OMP) problems to compose the coresets. This paper proposes a novel and intuitive approach to efficiently select a coreset based on the similarity of loss gradients. Our method works on the hypothesis that gradients of samples belonging to a given class will point in similar directions during the early training phase. Samples with most neighbours that produce similar gradient directions, in other words, that produce noise-free gradients, will represent that class. Through extensive experimentation, we have demonstrated the effectiveness of our approach in out-performing state-of-the-art coreset selection algorithms on a range of benchmark datasets from CIFAR-10 to ImageNet with architectures of varied complexity (ResNet-18, ResNet-50, VGG-16, ViT).We have also demonstrated the effectiveness of our approach in Generative Modelling by implementing coreset selection to reduce training time for various GAN models (DCGAN, MSGAN, SAGAN, SNGAN) for different datasets (CIFAR-10, CIFAR-100, Tiny ImageNet) while not impacting the performance metrics significantly. Source code is provided at URL",
    "checked": true,
    "id": "fb4620696cdeeb75bd305fbc0ac824fa51353022",
    "semantic_title": "noise-free loss gradients: a surprisingly effective baseline for coreset selection",
    "citation_count": 0,
    "authors": [
      "Saumyaranjan Mohanty",
      "Chimata Anudeep",
      "Konda Reddy Mopuri"
    ]
  },
  "https://openreview.net/forum?id=BDPvuD5FTg": {
    "title": "Graph-based Confidence Calibration for Large Language Models",
    "volume": "main",
    "abstract": "Reliable confidence estimation is essential for enhancing the trustworthiness of large language models (LLMs), especially in high-stakes scenarios. Despite its importance, accurately estimating confidence in LLM responses remains a significant challenge. In this work, we propose using an auxiliary learning model to assess response correctness based on the self-consistency of multiple outputs generated by the LLM. Our method builds a consistency graph to represent the agreement among multiple responses and uses a graph neural network (GNN) to estimate the likelihood that each response is correct. Experiments demonstrate that this method has strong calibration performance on various benchmark datasets and generalizes well to out-of-domain cases",
    "checked": true,
    "id": "e1536547084406d9f9864cc2dc08ca46add4a30b",
    "semantic_title": "graph-based confidence calibration for large language models",
    "citation_count": 2,
    "authors": [
      "Yukun Li",
      "Sijia Wang",
      "Lifu Huang",
      "Liping Liu"
    ]
  },
  "https://openreview.net/forum?id=mjsoESaWDH": {
    "title": "Preferential Multi-Objective Bayesian Optimization",
    "volume": "main",
    "abstract": "Preferential Bayesian optimization (PBO) is a framework for optimizing a decision-maker's latent preferences over available design choices. While real-world problems often involve multiple conflicting objectives, existing PBO methods assume that preferences can be encoded by a single objective function. For instance, in the customization of robotic assistive devices, technicians aim to maximize user comfort while minimizing energy consumption to extend battery life. Likewise, in autonomous driving policy design, stakeholders must evaluate safety and performance trade-offs before committing to a policy. To bridge this gap, we introduce the first framework for PBO with multiple objectives. Within this framework, we propose dueling scalarized Thompson sampling (DSTS), a multi-objective generalization of the popular dueling Thompson sampling algorithm, which may also be of independent interest beyond our setting. We evaluate DSTS across four synthetic test functions and two simulated tasks—exoskeleton personalization and driving policy design—demonstrating that it outperforms several benchmarks. Finally, we prove that DSTS is asymptotically consistent. Along the way, we provide, to our knowledge, the first convergence guarantee for dueling Thompson sampling in single-objective PBO",
    "checked": true,
    "id": "e6280a37ab1adb45fadd03e38bc00d9f0e3d0536",
    "semantic_title": "preferential multi-objective bayesian optimization",
    "citation_count": 2,
    "authors": [
      "Raul Astudillo",
      "Kejun Li",
      "Maegan Tucker",
      "Chu Xin Cheng",
      "Aaron Ames",
      "Yisong Yue"
    ]
  },
  "https://openreview.net/forum?id=xVEHiAZ7uR": {
    "title": "Adam-family Methods with Decoupled Weight Decay in Deep Learning",
    "volume": "main",
    "abstract": "In this paper, we investigate the convergence properties of a wide class of Adam-family methods for minimizing quadratically regularized nonsmooth nonconvex optimization problems, especially in the context of training nonsmooth neural networks with weight decay. Motivated by AdamW, we propose a novel framework for Adam-family methods with decoupled weight decay. Within our framework, the estimators for the first-order and second-order moments of stochastic subgradients are updated independently of the weight decay term. Under mild assumptions and with non-diminishing stepsizes for updating the primary optimization variables, we establish the convergence properties of our proposed framework. In addition, we show that our proposed framework encompasses a wide variety of well-known Adam-family methods, hence offering convergence guarantees for these methods in the training of nonsmooth neural networks. More importantly, compared to the existing results on the choices of the parameters for the moment terms in Adam, we show that our proposed framework provides more flexibility for these parameters. As a practical application of our proposed framework, we propose a novel Adam-family method named Adam with Decoupled Weight Decay (AdamD), and establish its convergence properties under mild conditions. Numerical experiments demonstrate that AdamD outperforms Adam and is comparable to AdamW, in the aspects of both generalization performance and efficiency",
    "checked": true,
    "id": "b4e7f304bfc61a4679961de80e37d1c6f53be90d",
    "semantic_title": "adam-family methods with decoupled weight decay in deep learning",
    "citation_count": 3,
    "authors": [
      "Kuangyu Ding",
      "Nachuan Xiao",
      "Kim-chuan Toh"
    ]
  },
  "https://openreview.net/forum?id=lmHh4FmPWZ": {
    "title": "Generalized Compressed Sensing for Image Reconstruction with Diffusion Probabilistic Models",
    "volume": "main",
    "abstract": "We examine the problem of selecting a small set of linear measurements for reconstructing high-dimensional signals. Well-established methods for optimizing such measurements include principal component analysis (PCA), independent component analysis (ICA) and compressed sensing (CS) based on random projections, all of which rely on axis- or subspace-aligned statistical characterization of the signal source. However, many naturally occurring signals, including photographic images, contain richer statistical structure. To exploit such structure, we introduce a general method for obtaining an optimized set of linear measurements for efficient image reconstruction, where the signal statistics are expressed by the prior implicit in a neural network trained to perform denoising (known as a ``diffusion model''). We demonstrate that the optimal measurements derived for two natural image datasets differ from those of PCA, ICA, or CS, and result in substantially lower mean squared reconstruction error. Interestingly, the marginal distributions of the measurement values are asymmetrical (skewed), substantially more so than those of previous methods. We also find that optimizing with respect to perceptual loss, as quantified by structural similarity (SSIM), leads to measurements different from those obtained when optimizing for MSE. Our results highlight the importance of incorporating the specific statistical regularities of natural signals when designing effective linear measurements",
    "checked": true,
    "id": "7ebf1eb74d4dae3e9bf91e5a34e1bef1f68c0645",
    "semantic_title": "generalized compressed sensing for image reconstruction with diffusion probabilistic models",
    "citation_count": 0,
    "authors": [
      "Ling-Qi Zhang",
      "Zahra Kadkhodaie",
      "Eero P Simoncelli",
      "David H. Brainard"
    ]
  },
  "https://openreview.net/forum?id=0c6iG28rRl": {
    "title": "Towards Better Understanding of In-Context Learning Ability from In-Context Uncertainty Quantification",
    "volume": "main",
    "abstract": "Predicting simple function classes has been widely used as a testbed for developing theory and understanding of the trained Transformer's in-context learning (ICL) ability. In this paper, we revisit the training of Transformers on linear regression tasks, and different from all the existing literature, we consider a bi-objective prediction task of predicting both the conditional expectation $\\mathbb{E}[Y|X]$ and the conditional variance Var$(Y|X)$. This additional uncertainty quantification objective provides a handle to (i) better design out-of-distribution experiments to distinguish ICL from in-weight learning (IWL) and (ii) make a better separation between the algorithms with and without using the prior information of the training distribution. Theoretically, we show that the trained Transformer reaches near Bayes optimum, suggesting the usage of the information of the training distribution. Our method can be extended to other cases. Specifically, with the Transformer's context window $S$, we prove a generalization bound of $\\tilde{\\mathcal{O}}(\\sqrt{\\min\\{S, T\\}/(n T)})$ on $n$ tasks with sequences of length $T$, providing sharper analysis compared to previous results of $\\tilde{\\mathcal{O}}(\\sqrt{1/n})$. Empirically, we illustrate that while the trained Transformer behaves as the Bayes-optimal solution as a natural consequence of supervised training in distribution, it does not necessarily perform a Bayesian inference when facing task shifts, in contrast to the \\textit{equivalence} between these two proposed in many existing literature. We also demonstrate the trained Transformer's ICL ability over covariate shift and prompt-length shift and interpret them as a generalization over a meta distribution",
    "checked": true,
    "id": "97417c75b2c8c54780d25c46ca06de1b2a320ddf",
    "semantic_title": "towards better understanding of in-context learning ability from in-context uncertainty quantification",
    "citation_count": 1,
    "authors": [
      "Shang Liu",
      "Zhongze Cai",
      "Guanting Chen",
      "Xiaocheng Li"
    ]
  },
  "https://openreview.net/forum?id=qRAjZuf48S": {
    "title": "A Theoretical Study of Neural Network Expressive Power via Manifold Topology",
    "volume": "main",
    "abstract": "A prevalent assumption regarding real-world data is that it lies on or close to a low-dimensional manifold. When deploying a neural network on data manifolds, the required size, i.e., the number of neurons of the network, heavily depends on the intricacy of the underlying latent manifold. While significant advancements have been made in understanding the geometric attributes of manifolds, it's essential to recognize that topology, too, is a fundamental characteristic of manifolds. In this study, we investigate network expressive power in terms of the latent data manifold. Integrating both topological and geometric facets of the data manifold, we present a size upper bound of ReLU neural networks",
    "checked": true,
    "id": "87fcdc4c168ace7d72b64c4e7448ceed3e806ee1",
    "semantic_title": "a theoretical study of neural network expressive power via manifold topology",
    "citation_count": 0,
    "authors": [
      "Jiachen Yao",
      "Lingjie Yi",
      "Mayank Goswami",
      "Chao Chen"
    ]
  },
  "https://openreview.net/forum?id=Gl6dF9soQo": {
    "title": "UniZero: Generalized and Efficient Planning with Scalable Latent World Models",
    "volume": "main",
    "abstract": "Learning predictive world models is crucial for enhancing the planning capabilities of reinforcement learning (RL) agents. Recently, MuZero-style algorithms, leveraging the value equivalence principle and Monte Carlo Tree Search (MCTS), have achieved superhuman performance in various domains. However, these methods struggle to scale in heterogeneous scenarios with diverse dependencies and task variability. To overcome these limitations, we introduce UniZero, a novel approach that employs a transformer-based world model to effectively learn a shared latent space. By concurrently predicting latent dynamics and decision-oriented quantities conditioned on the learned latent history, UniZero enables joint optimization of the long-horizon world model and policy, facilitating broader and more efficient planning in the latent space. We show that UniZero significantly outperforms existing baselines in benchmarks that require long-term memory. Additionally, UniZero demonstrates superior scalability in multitask learning experiments conducted on Atari benchmarks. In standard single-task RL settings, such as Atari and DMControl, UniZero matches or even surpasses the performance of current state-of-the-art methods. Finally, extensive ablation studies and visual analyses validate the effectiveness and scalability of UniZero's design choices. Our code is available at \\textcolor{magenta}{https://github.com/opendilab/LightZero}",
    "checked": true,
    "id": "efbba49eb8faa538d7ddfce93680379e20861b2f",
    "semantic_title": "unizero: generalized and efficient planning with scalable latent world models",
    "citation_count": 2,
    "authors": [
      "Yuan Pu",
      "Yazhe Niu",
      "Zhenjie Yang",
      "Jiyuan Ren",
      "Hongsheng Li",
      "Yu Liu"
    ]
  },
  "https://openreview.net/forum?id=WvgoxpGpuU": {
    "title": "T2L: Efficient Zero-Shot Action Recognition with Temporal Token Learning",
    "volume": "main",
    "abstract": "Recent advancements in large-scale pre-training of visual-language models on paired image-text data have demonstrated impressive generalization capabilities for zero-shot tasks. Building on this success, efforts have been made to adapt these image-based visual-language models, such as CLIP, for videos extending their zero-shot capabilities to the video domain. While these adaptations have shown promising results, they come at a significant computational cost and struggle with effectively modeling the temporal aspects inherent to the video domain. In this study, we present Efficient Zero-Shot Action Recognition with Temporal Token Learning(T2L), a simple and efficient adaptation of CLIP that addresses these challenges. T2L leverages Temporal Token Learning (TTL) for seamless temporal adaptation, requiring no fundamental changes to the core CLIP architecture while preserving its remarkable generalization abilities. TTL relies on temporal feature diversity (TFD), a novel learning objective, which guides TTL to focus on capturing motion, thereby enhancing its learning capabilities from videos. We perform extensive experiments on nine different benchmark datasets, thoroughly evaluating T2L for zero-shot learning and base-to-novel video action recognition, and also demonstrating its potential for few-shot generalization. Impressively, with merely 5.2 million learnable parameters, T2L can be efficiently trained on a single GPU (with 25x less learnable parameters, 3x reduction in GFLOPs, and 4x improvement in throughput when compared with prior best model), outperforming existing approaches in several evaluations",
    "checked": true,
    "id": "14193486de7c29741863c2936d2b51846c3dad35",
    "semantic_title": "t2l: efficient zero-shot action recognition with temporal token learning",
    "citation_count": 0,
    "authors": [
      "Shahzad Ahmad",
      "Sukalpa Chanda",
      "Yogesh S Rawat"
    ]
  },
  "https://openreview.net/forum?id=BMGikHBjlx": {
    "title": "Ctrl-V: Higher Fidelity Autonomous Vehicle Video Generation with Bounding-Box Controlled Object Motion",
    "volume": "main",
    "abstract": "Controllable video generation has attracted significant attention, largely due to advances in video diffusion models. In domains such as autonomous driving, developing highly accurate predictions for object motions is essential. This paper addresses the key challenge of enabling fine-grained control over object motion in the context of driving video synthesis. To accomplish this, we 1) employ a distinct, specialized model to forecast the trajectories of object bounding boxes, 2) adapt and enhance a separate video diffusion network to create video content conditioned on these high-quality trajectory forecasts, and 3) we are able to exert precise control over object position/movements using bounding boxes in both 2D and 3D spaces. Our method, Ctrl-V, leverages modified and fine-tuned Stable Video Diffusion (SVD) models to solve both trajectory and video generation. Extensive experiments conducted on the KITTI, Virtual-KITTI 2, BDD100k, and nuScenes datasets validate the effectiveness of our approach in producing realistic and controllable video generation. Project page: \\url{https://oooolga.github.io/ctrl-v.github.io/}",
    "checked": true,
    "id": "b756d04e6e410aff8506677084636652ad4648fc",
    "semantic_title": "ctrl-v: higher fidelity autonomous vehicle video generation with bounding-box controlled object motion",
    "citation_count": 1,
    "authors": [
      "Ge Ya Luo",
      "ZhiHao Luo",
      "Anthony Gosselin",
      "Alexia Jolicoeur-Martineau",
      "Christopher Pal"
    ]
  },
  "https://openreview.net/forum?id=Teu1Blr2YJ": {
    "title": "Node Feature Forecasting in Temporal Graphs: an Interpretable Online Algorithm",
    "volume": "main",
    "abstract": "In this paper, we propose an online algorithm mspace for forecasting node features in temporal graphs, which captures spatial cross-correlation among different nodes as well as the temporal auto-correlation within a node. The algorithm can be used for both probabilistic and deterministic multi-step forecasting, making it applicable for estimation and generation tasks. Evaluations against various baselines, including temporal graph neural network (TGNN) models and classical Kalman filters, demonstrate that mspace performs comparably to the state-of-the-art and even surpasses them on some datasets. Importantly, mspace demonstrates consistent performance across datasets with varying training sizes, a notable advantage over TGNN models that require abundant training samples to effectively learn the spatiotemporal trends in the data. Therefore, employing mspace is advantageous in scenarios where the training sample availability is limited. Additionally, we establish theoretical bounds on multi-step forecasting error of mspace and show that it scales linearly with the number of forecast steps $q$ as $\\mathcal{O}(q)$. For an asymptotically large number of nodes $n$, and timesteps $T$, the computational complexity of mspace grows linearly with both \\$n\\$ and \\$T\\$, i.e., $\\mathcal{O}(nT)$, while its space complexity remains constant $\\mathcal{O}(1)$. We compare the performance of various mspace variants against ten recent TGNN baselines and two classical baselines, ARIMA and the Kalman filter, across ten real-world datasets. Lastly, we have investigated the interpretability of different mspace variants by analyzing model parameters alongside dataset characteristics to jointly derive model-centric and data-centric insights",
    "checked": true,
    "id": "bc273c281f1df1aa246c3359d2656c2c0922b826",
    "semantic_title": "node feature forecasting in temporal graphs: an interpretable online algorithm",
    "citation_count": 0,
    "authors": [
      "Aniq Ur Rahman",
      "Justin Coon"
    ]
  },
  "https://openreview.net/forum?id=Reh1S8rxfh": {
    "title": "Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach",
    "volume": "main",
    "abstract": "In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is important for reasonable causal models reflecting the broad knowledge of domain experts, despite the challenges in the systematic acquisition of background knowledge. To overcome these challenges, this paper proposes a novel method for causal inference, in which SCD and knowledge-based causal inference (KBCI) with a large language model (LLM) are synthesized through ``statistical causal prompting (SCP)'' for LLMs and prior knowledge augmentation for SCD. The experiments in this work have revealed that the results of LLM-KBCI and SCD augmented with LLM-KBCI approach the ground truths, more than the SCD result without prior knowledge. These experiments have also revealed that the SCD result can be further improved if the LLM undergoes SCP. Furthermore, with an unpublished real-world dataset, we have demonstrated that the background knowledge provided by the LLM can improve the SCD on this dataset, even if this dataset has never been included in the training data of the LLM. For future practical application of this proposed method across important domains such as healthcare, we also thoroughly discuss the limitations, risks of critical errors, expected improvement of techniques around LLMs, and realistic integration of expert checks of the results into this automatic process, with SCP simulations under various conditions both in successful and failure scenarios. The careful and appropriate application of the proposed approach in this work, with improvement and customization for each domain, can thus address challenges such as dataset biases and limitations, illustrating the potential of LLMs to improve data-driven causal inference across diverse scientific domains. The code used in this work is publicly available at: https://github.com/mas-takayama/LLM-and-SCD",
    "checked": true,
    "id": "c213737923f58ad6c4cd18a8c17bca6522d7f4c6",
    "semantic_title": "integrating large language models in causal discovery: a statistical causal approach",
    "citation_count": 21,
    "authors": [
      "MASAYUKI TAKAYAMA",
      "Tadahisa OKUDA",
      "Thong Pham",
      "Tatsuyoshi Ikenoue",
      "Shingo Fukuma",
      "Shohei Shimizu",
      "Akiyoshi Sannai"
    ]
  },
  "https://openreview.net/forum?id=72YVabBErN": {
    "title": "Efficient Open Set Single Image Test Time Adaptation of Vision Language Models",
    "volume": "main",
    "abstract": "Adapting models to dynamic, real-world environments characterized by shifting data distributions and unseen test scenarios is a critical challenge in deep learning. In this paper, we consider a realistic and challenging Test-Time Adaptation setting, where a model must continuously adapt to test samples that arrive sequentially, one at a time, while distinguishing between known and unknown classes. Current Test-Time Adaptation methods operate under closed-set assumptions or batch processing, differing from the real-world open-set scenarios. We address this limitation by establishing a comprehensive benchmark for Open-set Single-image Test-Time Adaptation using Vision-Language Models. Furthermore, we propose ROSITA, a novel framework that leverages dynamically updated feature banks to identify reliable test samples and employs a contrastive learning objective to improve the separation between known and unknown classes. Our approach effectively adapts models to domain shifts for known classes while rejecting unfamiliar samples. Extensive experiments across diverse real-world benchmarks demonstrate that ROSITA sets a new state-of-the-art in open-set TTA, achieving both strong performance and computational efficiency for real-time deployment. The code is released at https://github.com/manogna-s/ROSITA.git",
    "checked": true,
    "id": "f21359cb435f678b5474f9f7ad287b29c8942509",
    "semantic_title": "efficient open set single image test time adaptation of vision language models",
    "citation_count": 0,
    "authors": [
      "Manogna Sreenivas",
      "Soma Biswas"
    ]
  },
  "https://openreview.net/forum?id=eQeYyup1tm": {
    "title": "Bridging Lottery Ticket and Grokking: Understanding Grokking from Inner Structure of Networks",
    "volume": "main",
    "abstract": "Grokking is an intriguing phenomenon of delayed generalization, where neural networks initially memorize training data with perfect accuracy but exhibit poor generalization, subsequently transitioning to a generalizing solution with continued training. While factors such as weight norms and sparsity have been proposed to explain this delayed generalization, the influence of network structure remains underexplored. In this work, we link the grokking phenomenon to the lottery ticket hypothesis to investigate the impact of internal network structures. We demonstrate that utilizing lottery tickets obtained during the generalizing phase (termed grokked tickets) significantly reduces delayed generalization across various tasks, including multiple modular arithmetic operations, polynomial regression, sparse parity, and MNIST classification. Through controlled experiments, we show that the mitigation of delayed generalization is not due solely to reduced weight norms or increased sparsity, but rather to the discovery of good subnetworks. Furthermore, we find that grokked tickets exhibit periodic weight patterns and undergo rapid structural changes that coincide with improvements in generalization. Additionally, pruning techniques like the edge-popup algorithm can identify these effective structures without modifying the weights, thereby transforming memorizing networks into generalizing ones. These results underscore the novel insight that structural exploration plays a pivotal role in understanding grokking",
    "checked": true,
    "id": "325e649380a0d6bc10f51dda6679e39a26851e68",
    "semantic_title": "bridging lottery ticket and grokking: understanding grokking from inner structure of networks",
    "citation_count": 1,
    "authors": [
      "Gouki Minegishi",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ]
  },
  "https://openreview.net/forum?id=6o3vVBWYis": {
    "title": "Language Models Are Good Tabular Learners",
    "volume": "main",
    "abstract": "Transformer-based language models have become the de facto standard in natural language processing. However, they underperform in the tabular data domain compared to traditional tree-based methods. We posit that current models fail to achieve the full potential of language models due to (i) heterogeneity of tabular data; and (ii) challenges faced by the model in interpreting numerical values. Based on this hypothesis, we propose the Tabular Domain Transformer (TDTransformer) framework. TDTransformer has distinct embedding processes for different types of columns. The alignment layers for different column-types transform these embeddings to a common space. Besides, TDTransformer adapts piece-wise linear encoding for numerical values for better performance. We test the proposed method on 76 real-world tabular classification datasets from the OpenML benchmark. Extensive experiments indicate that TDTransformer significantly improves the state-of-the-art methods",
    "checked": true,
    "id": "2517c035aeffdc8f5039a23f29322e890dec426c",
    "semantic_title": "language models are good tabular learners",
    "citation_count": 1,
    "authors": [
      "Zhenhan Huang",
      "Kavitha Srinivas",
      "Horst Samulowitz",
      "Niharika S. D'Souza",
      "Charu C. Aggarwal",
      "Pin-Yu Chen",
      "Jianxi Gao"
    ]
  },
  "https://openreview.net/forum?id=vc7poEYOFK": {
    "title": "Learning Energy-Based Generative Models via Potential Flow: A Variational Principle Approach to Probability Density Homotopy Matching",
    "volume": "main",
    "abstract": "Energy-based models (EBMs) are a powerful class of probabilistic generative models due to their flexibility and interpretability. However, relationships between potential flows and explicit EBMs remain underexplored, while contrastive divergence training via implicit Markov chain Monte Carlo (MCMC) sampling is often unstable and expensive in high-dimensional settings. In this paper, we propose Variational Potential (VAPO) Flow Bayes, a new energy-based generative framework that eliminates the need for implicit MCMC sampling and does not rely on auxiliary networks or cooperative training. VAPO learns an energy-parameterized potential flow by constructing a flow-driven density homotopy that is matched to the data distribution through a variational loss minimizing the Kullback-Leibler divergence between the flow-driven and marginal homotopies. This principled formulation enables robust and efficient generative modeling while preserving the interpretability of EBMs. Experimental results on image generation, interpolation, out-of-distribution detection, and compositional generation confirm the effectiveness of VAPO, showing that our method performs competitively with existing approaches in terms of sample quality and versatility across diverse generative modeling tasks",
    "checked": true,
    "id": "ab8f30257748b2830dca3930d6a613c054de7ad9",
    "semantic_title": "learning energy-based generative models via potential flow: a variational principle approach to probability density homotopy matching",
    "citation_count": 0,
    "authors": [
      "Junn Yong Loo",
      "Leong Fang Yu",
      "Michelle Adeline",
      "Julia K. Lau",
      "Hwa Hui Tew",
      "Arghya Pal",
      "VISHNU MONN BASKARAN",
      "Chee-Ming Ting",
      "Raphael CW Phan"
    ]
  },
  "https://openreview.net/forum?id=lyxRBPmmnV": {
    "title": "Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations",
    "volume": "main",
    "abstract": "Several accounts of human cognition posit that our intelligence is rooted in our ability to form abstract composable concepts, ground them in our environment, and reason over these grounded entities. This trifecta of human thought has remained elusive in modern intelligent machines. In this work, we investigate whether slot representations extracted from visual scenes serve as appropriate compositional abstractions for grounding and reasoning. We present the Neural Slot Interpreter (NSI), which learns to ground object semantics in slots. At the core of NSI is a nested schema that uses simple syntax rules to organize the object semantics of a scene into object-centric schema primitives. Then, the NSI metric learns to ground primitives into slots through a structured contrastive learning objective that reasons over the intermodal alignment. Experiments with a bi-modal object-property and scene retrieval task demonstrate the grounding efficacy and interpretability of correspondences learned by NSI. From a scene representation standpoint, we find that emergent NSI slots that move beyond the image grid by binding to spatial objects facilitate improved visual grounding compared to conventional bounding-box-based approaches. From a data efficiency standpoint, we empirically validate that NSI learns more generalizable representations from a fixed amount of annotation data than the traditional approach. We also show that the grounded slots surpass unsupervised slots in real-world object discovery and scale with scene complexity. Finally, we investigate the downstream efficacy of the grounded slots. Vision Transformers trained on grounding-aware NSI tokenizers using as few as ten tokens outperform patch-based tokens on challenging few-shot classification tasks",
    "checked": true,
    "id": "934152abcb942dadffb0c34aea1e55d947efc91d",
    "semantic_title": "neural slot interpreters: grounding object semantics in emergent slot representations",
    "citation_count": 1,
    "authors": [
      "Bhishma Dedhia",
      "Niraj Jha"
    ]
  },
  "https://openreview.net/forum?id=FEo55EIvGI": {
    "title": "Cross Entropy versus Label Smoothing: A Neural Collapse Perspective",
    "volume": "main",
    "abstract": "Label smoothing loss is a widely adopted technique to mitigate overfitting in deep neural networks. This paper studies label smoothing from the perspective of Neural Collapse (NC), a powerful empirical and theoretical framework which characterizes model behavior during the terminal phase of training. We first show empirically that models trained with label smoothing converge faster to neural collapse solutions and attain a stronger level of neural collapse compared to those trained with cross-entropy loss. Furthermore, we show that at the same level of NC1, models under label smoothing loss exhibit intensified NC2. These findings provide valuable insights into the impact of label smoothing on model performance and calibration. Then, leveraging the unconstrained feature model, we derive closed-form solutions for the global minimizers under both label smoothing and cross-entropy losses. We show that models trained with label smoothing have a lower conditioning number and, therefore, theoretically converge faster. Our study, combining empirical evidence and theoretical results, not only provides nuanced insights into the differences between label smoothing and cross-entropy losses, but also serves as an example of how the powerful neural collapse framework can be used to improve our understanding of DNNs",
    "checked": true,
    "id": "08901f2f5b363f28660f401afafccc2e6c9373d5",
    "semantic_title": "cross entropy versus label smoothing: a neural collapse perspective",
    "citation_count": 9,
    "authors": [
      "Li Guo",
      "George Andriopoulos",
      "Zifan Zhao",
      "Zixuan Dong",
      "Shuyang Ling",
      "Keith W. Ross"
    ]
  },
  "https://openreview.net/forum?id=3Jm4dbrKGZ": {
    "title": "Lurie Networks with Robust Convergent Dynamics",
    "volume": "main",
    "abstract": "The Lurie network is a novel and unifying time-invariant neural ODE. Many existing continuous-time models, including recurrent neural networks and neural oscillators, are special cases of the Lurie network in this context. Mild constraints on the weights and biases of the Lurie network are derived to ensure a generalised concept of stability is guaranteed. This generalised stability measure is that of k-contraction which permits global convergence to a point, line or plane in the neural state-space. This includes global convergence to one of multiple equilibrium points or limit cycles as observed in many dynamical systems including associative and working memory. Weights and biases of the Lurie network, which satisfy the k-contraction constraints, are encoded through unconstrained parametrisations. The novel stability results and parametrisations provide a toolset for training over the space of k-contracting Lurie network's using standard optimisation algorithms. These results are also leveraged to construct and train a graph Lurie network satisfying the same convergence properties. Empirical results show the improvement in prediction accuracy, generalisation and robustness on a range of simulated dynamical systems, when the graph structure and k-contraction conditions are introduced. These results also compare favourably against other well known stability-constrained models and an unconstrained neural ODE",
    "checked": true,
    "id": "d7714d5e003d84b8fef1dc9734b0724c5ad7eac4",
    "semantic_title": "lurie networks with robust convergent dynamics",
    "citation_count": 0,
    "authors": [
      "Carl R Richardson",
      "Matthew C. Turner",
      "Steve R. Gunn"
    ]
  },
  "https://openreview.net/forum?id=hMPzJ3qKpf": {
    "title": "LocalFormer: Mitigating Over-Globalising in Transformers on Graphs with Localised Training",
    "volume": "main",
    "abstract": "As Transformers become more popular for graph machine learning, a significant issue has recently been observed. Their global attention mechanisms tend to overemphasize distant vertices, leading to the phenomenon of ``over-globalising.'' This phenomenon often results in the dilution of essential local information, particularly in graphs where local neighbourhoods carry significant predictive power. Existing methods often struggle with rigidity in their local processing, where tightly coupled operations limit flexibility and adaptability in diverse graph structures. Additionally, these methods can overlook critical structural nuances, resulting in an incomplete integration of local and global contexts. This paper addresses these issues by proposing LocalFormer, a novel framework, to effectively localise a transformer model by integrating a distinct local module and a complementary module that integrates global information. The local module focuses on capturing and preserving fine-grained, neighbourhood-specific patterns, ensuring that the model maintains sensitivity to critical local structures. In contrast, the complementary module dynamically integrates broader context without overshadowing the localised information, offering a balanced approach to feature aggregation across different scales of the graph. Through collaborative and warm-up training strategies, these modules work synergistically to mitigate the adverse effects of over-globalising, leading to improved empirical performance. Our experimental results demonstrate the effectiveness of LocalFormer compared to state-of-the-art baselines on vertex-classification tasks",
    "checked": true,
    "id": "bf20280d048093fd352ba30dec4883f80a3ba4b6",
    "semantic_title": "localformer: mitigating over-globalising in transformers on graphs with localised training",
    "citation_count": 1,
    "authors": [
      "Naganand Yadati"
    ]
  },
  "https://openreview.net/forum?id=UcrVnXBdZI": {
    "title": "On the effectiveness of Rotation-Equivariance in U-Net: A Benchmark for Image Segmentation",
    "volume": "main",
    "abstract": "Numerous studies have recently focused on incorporating different variations of equivariance in Convolutional Neural Networks (CNNs). In particular, rotation-equivariance has gathered significant attention due to its relevance in many applications related to medical imaging, microscopic imaging, satellite imaging, industrial tasks, etc. While prior research has primarily focused on enhancing classification tasks with rotation equivariant CNNs, their impact on more complex architectures, such as U-Net for image segmentation, remains scarcely explored. Indeed, previous work interested in integrating rotation-equivariance into U-Net architecture have focused on solving specific applications with a limited scope. In contrast, this paper aims to provide a more exhaustive evaluation of rotation equivariant U-Net for image segmentation across a broader range of tasks. We benchmark their effectiveness against standard U-Net architectures, assessing improvements in terms of performance and sustainability (i.e., computational cost). Our evaluation focuses on datasets whose orientation of objects of interest is arbitrary in the image (e.g., Kvasir-SEG), but also on more standard segmentation datasets (such as COCO-Stuff) as to explore the wider applicability of rotation equivariance beyond tasks undoubtedly concerned by rotation equivariance. The main contribution of this work is to provide insights into the trade-offs and advantages of integrating rotation equivariance for segmentation tasks",
    "checked": true,
    "id": "898ad18bf8e4f858502177ee4465f0c6a9476720",
    "semantic_title": "on the effectiveness of rotation-equivariance in u-net: a benchmark for image segmentation",
    "citation_count": 0,
    "authors": [
      "Robin Ghyselinck",
      "Valentin Delchevalerie",
      "Bruno Dumas",
      "Benoit Frenay"
    ]
  },
  "https://openreview.net/forum?id=J6oxTJPOyN": {
    "title": "LEGO-Learn: Label-Efficient Graph Open-Set Learning",
    "volume": "main",
    "abstract": "How can we train graph-based models to recognize unseen classes while keeping labeling costs low? Graph open-set learning (GOL) and out-of-distribution (OOD) detection aim to address this challenge by training models that can accurately classify known, in-distribution (ID) classes while identifying and handling previously unseen classes during inference. It is critical for high-stakes, real-world applications where models frequently encounter unexpected data, including finance, security, and healthcare. However, current GOL methods assume access to a large number of labeled ID samples, which is unrealistic for large-scale graphs due to high annotation costs. In this paper, we propose LEGO-Learn (Label-Efficient Graph Open-set Learning), a novel framework that addresses open-set node classification on graphs within a given label budget by selecting the most informative ID nodes. LEGO-Learn employs a GNN-based filter to identify and exclude potential OOD nodes and then selects highly informative ID nodes for labeling using the K-Medoids algorithm. To prevent the filter from discarding valuable ID examples, we introduce a classifier that differentiates between the $C$ known ID classes and an additional class representing OOD nodes (hence, a $C+1$ classifier). This classifier utilizes a weighted cross-entropy loss to balance the removal of OOD nodes while retaining informative ID nodes. Experimental results on four real-world datasets demonstrate that LEGO-Learn significantly outperforms leading methods, achieving up to a $6.62\\%$ improvement in ID classification accuracy and a $7.49\\%$ increase in AUROC for OOD detection",
    "checked": true,
    "id": "f1861e3438c986382aac6ec4a6d1bbde5560c52d",
    "semantic_title": "lego-learn: label-efficient graph open-set learning",
    "citation_count": 6,
    "authors": [
      "Haoyan Xu",
      "Kay Liu",
      "Zhengtao Yao",
      "Philip S. Yu",
      "Mengyuan Li",
      "Kaize Ding",
      "Yue Zhao"
    ]
  },
  "https://openreview.net/forum?id=VlwqIz41Hp": {
    "title": "Generalized Prediction Set with Bandit Feedback",
    "volume": "main",
    "abstract": "In high-stakes environments where uncertainties abound, set-valued prediction offers a cautious and robust mechanism by presenting multiple potential labels as the prediction for each test instance to mitigate the potential risk associated with prediction errors. Yet, integrating this paradigm with out-of-distribution (OOD) detection remains scarcely explored in such settings as online learning with bandit feedback. The bandit feedback mechanism informs the learner about the correctness of the pulled arm/action instead of the explicit ground truth label, leaving the true class label unknown when an incorrect action is taken. To address this challenge, we introduce BanditGPS which conducts set-valued prediction with OOD detection in the bandit feedback setting, using an estimation to the ground truth of class labels. BanditGPS achieves three objectives: render small/informative prediction sets, enhance the OOD detection performance, and control the recall for all normal classes to meet prescribed requirements. Our approach is characterized by the loss function, which trades off between high OOD detection and small prediction sets. Theoretically, we prove that the convergence rate of the regret is $\\tilde{\\mathcal{O}}(T^{-1/2})$. The empirical results further show that BanditGPS effectively controls the recalls with promising performances on OOD detection and informative prediction",
    "checked": true,
    "id": "00e5d6266ba1cffe90b4e11d8a385c7ed5c84d2e",
    "semantic_title": "generalized prediction set with bandit feedback",
    "citation_count": 0,
    "authors": [
      "Zhou Wang",
      "Xingye Qiao"
    ]
  },
  "https://openreview.net/forum?id=mk1YIkVvTQ": {
    "title": "Is What You Ask For What You Get? Investigating Concept Associations in Text-to-Image Models",
    "volume": "main",
    "abstract": "Text-to-image (T2I) models are increasingly used in impactful real-life applications. As such, there is a growing need to audit these models to ensure that they generate desirable, task-appropriate images. However, systematically inspecting the associations between prompts and generated content in a human-understandable way remains challenging. To address this, we propose \\emph{Concept2Concept}, a framework where we characterize conditional distributions of vision language models using interpretable concepts and metrics that can be defined in terms of these concepts. This characterization allows us to use our framework to audit models and prompt-datasets. To demonstrate, we investigate several case studies of conditional distributions of prompts, such as user-defined distributions or empirical, real-world distributions. Lastly, we implement Concept2Concept as an open-source interactive visualization tool to facilitate use by non-technical end-users. A demo is available at https://tinyurl.com/Concept2ConceptDemo. Warning: This paper contains discussions of harmful content, including CSAM and NSFW material, which may be disturbing to some readers",
    "checked": true,
    "id": "08996dc073af3767e8d5669d2c3d308795d175c0",
    "semantic_title": "is what you ask for what you get? investigating concept associations in text-to-image models",
    "citation_count": 0,
    "authors": [
      "Salma Abdel Magid",
      "Weiwei Pan",
      "Simon Warchol",
      "Grace Guo",
      "Junsik Kim",
      "Mahia Rahman",
      "Hanspeter Pfister"
    ]
  },
  "https://openreview.net/forum?id=VuLEOyTiPO": {
    "title": "GeNIe: Generative Hard Negative Images Through Diffusion",
    "volume": "main",
    "abstract": "Data augmentation is crucial in training deep models, preventing them from overfitting to limited data. Recent advances in generative AI, e.g., diffusion models, have enabled more sophisticated augmentation techniques that produce data resembling natural images. We introduce $\\texttt{GeNIe}$ a novel augmentation method which leverages a latent diffusion model conditioned on a text prompt to combine two contrasting data points (an image from the source category and a text prompt from the target category) to generate challenging augmentations. To achieve this, we adjust the noise level (equivalently, number of diffusion iterations) to ensure the generated image retains low-level and background features from the source image while representing the target category, resulting in a hard negative sample for the source category. We further automate and enhance $\\texttt{GeNIe}$ by adaptively adjusting the noise level selection on a per image basis (coined as $\\texttt{GeNIe-Ada}$), leading to further performance improvements. Our extensive experiments, in both few-shot and long-tail distribution settings, demonstrate the effectiveness of our novel augmentation method and its superior performance over the prior art. Our code is available at https://github.com/UCDvision/GeNIe",
    "checked": true,
    "id": "7f0e374f1920d962359d7e9ccb7a7d7e2d18e6f4",
    "semantic_title": "genie: generative hard negative images through diffusion",
    "citation_count": 4,
    "authors": [
      "Soroush Abbasi Koohpayegani",
      "Anuj Singh",
      "Navaneet K L",
      "Hamed Pirsiavash",
      "Hadi J. Rad"
    ]
  },
  "https://openreview.net/forum?id=FFnRLvWefK": {
    "title": "System-Aware Neural ODE Processes for Few-Shot Bayesian Optimization",
    "volume": "main",
    "abstract": "We consider the problem of optimizing initial conditions and termination time in dynamical systems governed by unknown ordinary differential equations (ODEs), where evaluating different initial conditions is costly and the state's value can not be measured in real-time but only with a delay while the measuring device processes the sample. To identify the optimal conditions in limited trials, we introduce a few-shot Bayesian Optimization (BO) framework based on the system's prior information. At the core of our approach is the System-Aware Neural ODE Processes (SANODEP), an extension of Neural ODE Processes (NODEP) designed to meta-learn ODE systems from multiple trajectories using a novel context embedding block. We further develop a two-stage BO framework to effectively incorporate search space constraints, enabling efficient optimization of both initial conditions and observation timings. We conduct extensive experiments showcasing SANODEP's potential for few-shot BO within dynamical systems. We also explore SANODEP's adaptability to varying levels of prior information, highlighting the trade-off between prior flexibility and model fitting accuracy",
    "checked": true,
    "id": "fcc3aee3d63369b46495f52c938226e7f6a37977",
    "semantic_title": "system-aware neural ode processes for few-shot bayesian optimization",
    "citation_count": 3,
    "authors": [
      "Jixiang Qing",
      "Rebecca D. Langdon",
      "Robert Matthew Lee",
      "Behrang Shafei",
      "Mark van der Wilk",
      "Calvin Tsay",
      "Ruth Misener"
    ]
  },
  "https://openreview.net/forum?id=x9VQFjtOPS": {
    "title": "A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks",
    "volume": "main",
    "abstract": "LLM test-time compute (or LLM inference) via search has emerged as a promising research area with rapid developments. However, current frameworks often adopt distinct perspectives on three key aspects—task definition, LLM profiling, and search procedures—making direct comparisons challenging. Moreover, the search algorithms employed often diverge from standard implementations, and their specific characteristics are not thoroughly specified. This survey aims to provide a comprehensive but integrated technical review on existing LIS frameworks. Specifically, we unify task definitions under Markov Decision Process (MDP) and provides modular definitions of LLM profiling and search procedures. The definitions enable precise comparisons of various LLM inference frameworks while highlighting their departures from conventional search algorithms. We also discuss the applicability, performance, and efficiency of these methods. For ongoing paper updates, please refer to our GitHub repository: https://github.com/xinzhel/LLM-Search",
    "checked": true,
    "id": "c52045988ba4b6cedabeea93ac4b03c5d7a79a85",
    "semantic_title": "a survey on llm test-time compute via search: tasks, llm profiling, search algorithms, and relevant frameworks",
    "citation_count": 8,
    "authors": [
      "Xinzhe Li"
    ]
  },
  "https://openreview.net/forum?id=bCmEP1Ltwq": {
    "title": "Neural Deconstruction Search for Vehicle Routing Problems",
    "volume": "main",
    "abstract": "Autoregressive construction approaches generate solutions to vehicle routing problems in a step-by-step fashion, leading to high-quality solutions that are nearing the performance achieved by handcrafted operations research techniques. In this work, we challenge the conventional paradigm of sequential solution construction and introduce an iterative search framework where solutions are instead deconstructed by a neural policy. Throughout the search, the neural policy collaborates with a simple greedy insertion algorithm to rebuild the deconstructed solutions. Our approach matches or surpasses the performance of state-of-the-art operations research methods across three challenging vehicle routing problems of various problem sizes",
    "checked": true,
    "id": "f0a50c531fff4a7fdd7715fe20d2ade10f438fb4",
    "semantic_title": "neural deconstruction search for vehicle routing problems",
    "citation_count": 1,
    "authors": [
      "André Hottung",
      "Paula Wong-Chung",
      "Kevin Tierney"
    ]
  },
  "https://openreview.net/forum?id=IbQTE24aZw": {
    "title": "Deflated Dynamics Value Iteration",
    "volume": "main",
    "abstract": "The Value Iteration (VI) algorithm is an iterative procedure to compute the value function of a Markov decision process, and is the basis of many reinforcement learning (RL) algorithms as well. As the error convergence rate of VI as a function of iteration $k$ is $O(\\gamma^k)$, it is slow when the discount factor $\\gamma$ is close to $1$. To accelerate the computation of the value function, we propose Deflated Dynamics Value Iteration (DDVI). DDVI uses matrix splitting and matrix deflation techniques to effectively remove (deflate) the top $s$ dominant eigen-structure of the transition matrix $\\mathcal{P}^\\pi$. We prove that this leads to a $\\tilde{O}(\\gamma^k |\\lambda_{s+1}|^k)$ convergence rate, where $\\lambda_{s+1}$ is the $(s+1)$-th largest eigenvalue of the dynamics matrix. We also extend DDVI to the RL setting and present Deflated Dynamics Temporal Difference (DDTD) algorithm. We empirically show the effectiveness of the proposed algorithms",
    "checked": true,
    "id": "345355d4fa7424f81b30e10129f50de73216cdbb",
    "semantic_title": "deflated dynamics value iteration",
    "citation_count": 2,
    "authors": [
      "Jongmin Lee",
      "Amin Rakhsha",
      "Ernest K. Ryu",
      "Amir-massoud Farahmand"
    ]
  },
  "https://openreview.net/forum?id=zVo6PfBa0K": {
    "title": "Generating Symbolic World Models via Test-time Scaling of Large Language Models",
    "volume": "main",
    "abstract": "Solving complex planning problems requires Large Language Models (LLMs) to explicitly model the state transition to avoid rule violations, comply with constraints, and ensure optimality—a task hindered by the inherent ambiguity of natural language. To overcome such ambiguity, Planning Domain Definition Language (PDDL) is leveraged as a planning abstraction that enables precise and formal state descriptions. With PDDL, we can generate a symbolic world model where classic searching algorithms, such as A*, can be seamlessly applied to find optimal plans. However, directly generating PDDL domains with current LLMs remains an open challenge due to the lack of PDDL training data. To address this challenge, we propose to scale up the test-time computation of LLMs to enhance their PDDL reasoning capabilities, thereby enabling the generation of high-quality PDDL domains. Specifically, we introduce a simple yet effective algorithm, which first employs a Best-of-N sampling approach to improve the quality of the initial solution and then refines the solution in a fine-grained manner with verbalized machine learning. Our method outperforms o1-mini by a considerable margin in the generation of PDDL domains, achieving over 50% success rate on two tasks (i.e., generating PDDL domains from natural language description or PDDL problems). This is done without requiring additional training. By taking advantage of PDDL as state abstraction, our method is able to outperform the current state-of-the-art methods on almost all competition-level planning tasks",
    "checked": true,
    "id": "4435bc3de88b489a7ad20374db6af7f05926d371",
    "semantic_title": "generating symbolic world models via test-time scaling of large language models",
    "citation_count": 3,
    "authors": [
      "Zhouliang Yu",
      "Yuhuan Yuan",
      "Tim Z. Xiao",
      "Fuxiang Frank Xia",
      "Jie Fu",
      "Ge Zhang",
      "Ge lin",
      "Weiyang Liu"
    ]
  },
  "https://openreview.net/forum?id=JyjTJAG9yZ": {
    "title": "Personalized Layer Selection for Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) combine node attributes over a fixed granularity of the local graph structure around a node to predict its label. However, different nodes may relate to a node-level property with a different granularity of its local neighborhood, and using the same level of smoothing for all nodes can be detrimental to their classification. In this work, we challenge the common fact that a single GNN layer can classify all nodes of a graph by training GNNs with a distinct personalized layer for each node. Inspired by metric learning, we propose a novel algorithm, MetSelect, to select the optimal representation layer to classify each node. In particular, we identify a prototype representation of each class in a transformed GNN layer and then, classify using the layer where the distance is smallest to a class prototype after normalizing with that layer's variance. Results on 10 datasets and 3 different GNNs show that we significantly improve the node classification accuracy of GNNs in a plug-and-play manner. We also find that using variable layers for prediction enables GNNs to be deeper and more robust to poisoning attacks. We hope this work can inspire future works to learn more adaptive and personalized graph representations",
    "checked": true,
    "id": "9a9d7f314dc374edbe7f72831fd63a8e029448fb",
    "semantic_title": "personalized layer selection for graph neural networks",
    "citation_count": 0,
    "authors": [
      "Kartik Sharma",
      "Vineeth Rakesh",
      "Yingtong Dou",
      "Srijan Kumar",
      "Mahashweta Das"
    ]
  },
  "https://openreview.net/forum?id=WgJgIULL9Q": {
    "title": "HyperVQ: MLR-based Vector Quantization in Hyperbolic Space",
    "volume": "main",
    "abstract": "The success of models operating on tokenized data has heightened the need for effective tokenization methods, particularly in vision and auditory tasks where inputs are naturally continuous. A common solution is to employ Vector Quantization (VQ) within VQ Variational Autoencoders (VQVAEs), transforming inputs into discrete tokens by clustering embeddings in Euclidean space. However, Euclidean embeddings not only suffer from inefficient packing and limited separation—due to their polynomial volume growth—but are also prone to codebook collapse, where only a small subset of codebook vectors are effectively utilized. To address these limitations, we introduce HyperVQ, a novel approach that formulates VQ as a hyperbolic Multinomial Logistic Regression (MLR) problem, leveraging the exponential volume growth in hyperbolic space to mitigate collapse and improve cluster separability. Additionally, HyperVQ represents codebook vectors as geometric representatives of hyperbolic decision hyperplanes, encouraging disentangled and robust latent representations. Our experiments demonstrate that HyperVQ matches traditional VQ in generative and reconstruction tasks, while surpassing it in discriminative performance and yielding a more efficient and disentangled codebook",
    "checked": true,
    "id": "61613785fe09423e8df112ea726bb1195bc2575c",
    "semantic_title": "hypervq: mlr-based vector quantization in hyperbolic space",
    "citation_count": 4,
    "authors": [
      "Nabarun Goswami",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ]
  },
  "https://openreview.net/forum?id=1weZ9Wsajk": {
    "title": "Optimizing Cycle Life Prediction of Lithium-ion Batteries via a Physics-Informed Model",
    "volume": "main",
    "abstract": "Accurately measuring the cycle lifetime of commercial lithium-ion batteries is crucial for performance and technology development. We introduce a novel hybrid approach combining a physics-based equation with a self-attention model to predict the cycle lifetimes of commercial lithium iron phosphate graphite cells via early-cycle data. After fitting capacity loss curves to this physics-based equation, we then use a self-attention layer to reconstruct entire battery capacity loss curves. Our model exhibits comparable performances to existing models while predicting more information: the entire capacity loss curve instead of cycle life. This provides more robustness and interpretability: our model does not need to be retrained for a different notion of end-of-life and is backed by physical intuition",
    "checked": true,
    "id": "2ea1a0f132357e236e9ab3c199280eac5ba9caed",
    "semantic_title": "optimizing cycle life prediction of lithium-ion batteries via a physics-informed model",
    "citation_count": 0,
    "authors": [
      "Nathan Sun",
      "Daniel Nicolae",
      "Sara Sameer",
      "Karena Yan"
    ]
  },
  "https://openreview.net/forum?id=WOwQKguWT0": {
    "title": "When SNN meets ANN: Error-Free ANN-to-SNN Conversion for Extreme Edge Efficiency",
    "volume": "main",
    "abstract": "Spiking Neural Networks (SNN) are now demonstrating comparable accuracy to convolutional neural networks (CNN), thanks to advanced ANN-to-SNN conversion techniques, all while delivering remarkable energy and latency efficiency when deployed on neuromorphic hardware. However, these conversion techniques incur a large number of time steps, and consequently, high spiking activity. In this paper, we propose a novel ANN-to-SNN conversion framework, that incurs an exponentially lower number of time steps compared to that required in the existing conversion approaches. Our framework modifies the standard integrate-and-fire (IF) neuron model used in SNNs with no change in computational complexity and shifts the bias term of each batch normalization (BN) layer in the trained ANN. To reduce spiking activity, we propose training the source ANN with a fine-grained $\\ell_1$ regularizer with surrogate gradients that encourages high spike sparsity in the converted SNN. Our proposed framework thus yields lossless SNNs with low latency, low compute energy, thanks to the low time steps and high spike sparsity, and high test accuracy, for example, $75.12$% with only $4$ time steps on the ImageNet dataset. Codes will be made available. Code is available at https://github.com/godatta/SNN_meets_ANN",
    "checked": true,
    "id": "1138d51f4658754ebf0a2f07388a4d9dd406c344",
    "semantic_title": "when snn meets ann: error-free ann-to-snn conversion for extreme edge efficiency",
    "citation_count": 0,
    "authors": [
      "Gourav Datta",
      "Zeyu Liu",
      "James Diffenderfer",
      "Bhavya Kailkhura",
      "Peter Anthony Beerel"
    ]
  },
  "https://openreview.net/forum?id=fqSVqPcaVi": {
    "title": "ASTRA: A Scene-aware Transformer-based Model for Trajectory Prediction",
    "volume": "main",
    "abstract": "We present ASTRA (A Scene-aware Transformer-based model for trajectory prediction), a light-weight pedestrian trajectory forecasting model that integrates the scene context, spatial dynamics, social inter-agent interactions and temporal progressions for precise forecasting. We utilised a U-Net-based feature extractor, via its latent vector representation, to capture scene representations and a graph-aware transformer encoder for capturing social interactions. These components are integrated to learn an agent-scene aware embedding, enabling the model to learn spatial dynamics and forecast the future trajectory of pedestrians. The model is designed to produce both deterministic and stochastic outcomes, with the stochastic predictions being generated by incorporating a Conditional Variational Auto-Encoder (CVAE). ASTRA also proposes a simple yet effective weighted penalty loss function, which helps to yield predictions that outperform a wide array of state-of-the-art deterministic and generative models. ASTRA demonstrates an average improvement of 27%/10% in deterministic/stochastic settings on the ETH-UCY dataset, and 26% improvement on the PIE dataset, respectively, along with seven times fewer parameters than the existing state-of-the-art model (see Figure 1). Additionally, the model's versatility allows it to generalize across different perspectives, such as Bird's Eye View (BEV) and Ego-Vehicle View (EVV)",
    "checked": true,
    "id": "9f53e2f70504462f90676d3ec83e3cfade71a9a8",
    "semantic_title": "astra: a scene-aware transformer-based model for trajectory prediction",
    "citation_count": 1,
    "authors": [
      "Izzeddin Teeti",
      "Aniket Thomas",
      "Munish Monga",
      "Sachin Kumar Giroh",
      "Uddeshya Singh",
      "Andrew Bradley",
      "Biplab Banerjee",
      "Fabio Cuzzolin"
    ]
  },
  "https://openreview.net/forum?id=78N9tCL6Ly": {
    "title": "Leveraging Unlabeled Data Sharing through Kernel Function Approximation in Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "Offline reinforcement learning (RL) learns policies from a fixed dataset, but often requires large amounts of data. The challenge arises when labeled datasets are expensive, especially when rewards have to be provided by human labelers for large datasets. In contrast, unlabelled data tends to be less expensive. This situation highlights the importance of finding effective ways to use unlabelled data in offline RL, especially when labelled data is limited or expensive to obtain. In this paper, we present the algorithm to utilize the unlabeled data in the offline RL method with kernel function approximation and give the theoretical guarantee. We present various eigenvalue decay conditions of $\\mathcal{H}_k$ which determine the complexity of the algorithm. In summary, our work provides a promising approach for exploiting the advantages offered by unlabeled data in offline RL, whilst maintaining theoretical assurances",
    "checked": true,
    "id": "c7fe09b6c8f067e0ed97401fbac56242d77371ef",
    "semantic_title": "leveraging unlabeled data sharing through kernel function approximation in offline reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Yen Ru Lai",
      "Fu-Chieh Chang",
      "Pei-Yuan Wu"
    ]
  },
  "https://openreview.net/forum?id=xu4ATNjcdy": {
    "title": "Variational Stochastic Gradient Descent for Deep Neural Networks",
    "volume": "main",
    "abstract": "Optimizing deep neural networks is one of the main tasks in successful deep learning. Current state-of-the-art optimizers are adaptive gradient-based optimization methods such as Adam. Recently, there has been an increasing interest in formulating gradient-based optimizers in a probabilistic framework for better modeling the uncertainty of the gradients. Here, we propose to combine both approaches, resulting in the Variational Stochastic Gradient Descent (VSGD) optimizer. We model gradient updates as a probabilistic model and utilize stochastic variational inference (SVI) to derive an efficient and effective update rule. Further, we show how our VSGD method relates to other adaptive gradient-based optimizers like Adam. Lastly, we carry out experiments on two image classification datasets and four deep neural network architectures, where we show that VSGD outperforms Adam and SGD",
    "checked": true,
    "id": "9501deace2f45582a3a10a7700ada2a0918a2eb4",
    "semantic_title": "variational stochastic gradient descent for deep neural networks",
    "citation_count": 0,
    "authors": [
      "Anna Kuzina",
      "Haotian Chen",
      "Babak Esmaeili",
      "Jakub M. Tomczak"
    ]
  },
  "https://openreview.net/forum?id=2e1aZZd88C": {
    "title": "Non-Myopic Multi-Objective Bayesian Optimization",
    "volume": "main",
    "abstract": "We consider the problem of finite-horizon sequential experimental design to solve multi-objective optimization (MOO) of expensive black-box objective functions. This problem arises in many real-world applications, including materials design, where we have a small resource budget to make and evaluate candidate materials in the lab. We solve this problem using the framework of Bayesian optimization (BO) and propose the first set of non-myopic methods for MOO problems. Prior work on non-myopic BO for single-objective problems relies on the Bellman optimality principle to handle the lookahead reasoning process. However, this principle does not hold for most MOO problems because the reward function needs to satisfy some conditions: scalar variable, monotonicity, and additivity. We address this challenge by using hypervolume improvement (HVI) as our scalarization approach, which allows us to use a lower-bound on the Bellman equation to approximate the finite-horizon using a batch expected hypervolume improvement (EHVI) acquisition function (AF) for MOO. Our formulation naturally allows us to use other improvement-based scalarizations and compare their efficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF, which is based on the exact computation of the lower bound, 2) the Joint AF, which is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast and approximate variant based on batch multi-objective acquisition functions. Our experiments on multiple diverse real-world MO problems demonstrate that our non-myopic AFs substantially improve performance over the existing myopic AFs for MOBO",
    "checked": true,
    "id": "561b1857598dec8935322c0fde2da06bd240bf27",
    "semantic_title": "non-myopic multi-objective bayesian optimization",
    "citation_count": 0,
    "authors": [
      "Syrine Belakaria",
      "Alaleh Ahmadian",
      "Barbara E Engelhardt",
      "Stefano Ermon",
      "Jana Doppa"
    ]
  },
  "https://openreview.net/forum?id=aKjJoEVKgO": {
    "title": "Investigating Continual Pretraining in Large Language Models: Insights and Implications",
    "volume": "main",
    "abstract": "Continual learning (CL) in large language models (LLMs) is an evolving domain that focuses on developing efficient and sustainable training strategies to adapt models to emerging knowledge and achieve robustness in dynamic environments. Our primary emphasis is on continual domain-adaptive pretraining, a process designed to equip LLMs with the ability to integrate new information from various domains while retaining previously learned knowledge. Since existing works concentrate mostly on continual fine-tuning for a limited selection of downstream tasks or training domains, we introduce a new benchmark designed to measure the adaptability of LLMs to changing pretraining data landscapes. We further examine the impact of model size on learning efficacy and forgetting, as well as how the progression and similarity of emerging domains affect the knowledge transfer within these models. Our findings uncover several key insights: (i) continual pretraining consistently improves <1.5B models studied in this work and is also superior to domain adaptation, (ii) larger models always achieve better perplexity than smaller ones when continually pretrained on the same corpus, (iii) smaller models are particularly sensitive to continual pretraining, showing the most significant rates of both learning and forgetting, (iv) continual pretraining boosts downstream task performance of GPT-2 family, (v) continual pretraining enables LLMs to specialize better when the sequence of domains shows semantic similarity while randomizing training domains leads to better transfer and final performance otherwise. We posit that our research establishes a new benchmark for CL in LLMs, providing a more realistic evaluation of knowledge retention and transfer across diverse domains",
    "checked": true,
    "id": "12358df20ccf4085e6c8a45d3ab5fa15714abcd6",
    "semantic_title": "investigating continual pretraining in large language models: insights and implications",
    "citation_count": 31,
    "authors": [
      "Çağatay Yıldız",
      "Nishaanth Kanna Ravichandran",
      "Nitin Sharma",
      "Matthias Bethge",
      "Beyza Ermis"
    ]
  },
  "https://openreview.net/forum?id=XofMHO5yVY": {
    "title": "A Gold Standard Dataset for the Reviewer Assignment Problem",
    "volume": "main",
    "abstract": "Many peer-review venues are using algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the \"similarity score'' — a numerical estimate of the expertise of a reviewer in reviewing a paper — and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it difficult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms currently employed in computer science conferences and come up with recommendations for stakeholders. Our four main findings are: - All algorithms make a non-trivial amount of error. For the task of ordering two papers in terms of their relevance for a reviewer, the error rates range from 12%-30% in easy cases to 36%-43% in hard cases, thereby highlighting the vital need for more research on the similarity-computation problem. - Most specialized algorithms are designed to work with titles and abstracts of papers, and in this regime the Specter2 algorithm performs best. - The classical TF-IDF algorithm which can use full texts of papers is on par with Specter2 that uses only titles and abstracts. - The performance of off-the-shelf LLMs is worse than the specialized algorithms. We encourage researchers to participate in our survey and contribute their data to the dataset here: https://forms.gle/SP1Rh8eivGz54xR37",
    "checked": true,
    "id": "5ea8eedcb31859c5730dd1da3804e1be529ffabb",
    "semantic_title": "a gold standard dataset for the reviewer assignment problem",
    "citation_count": 16,
    "authors": [
      "Ivan Stelmakh",
      "John Frederick Wieting",
      "Yang Xi",
      "Graham Neubig",
      "Nihar B Shah"
    ]
  },
  "https://openreview.net/forum?id=NUV8THrLZC": {
    "title": "Efficient Exploration in Multi-Agent Reinforcement Learning via Farsighted Self-Direction",
    "volume": "main",
    "abstract": "Multi-agent reinforcement learning faces greater challenges with efficient exploration compared to single-agent counterparts, primarily due to the exponential growth in state and action spaces. Methods based on intrinsic rewards have been proven to enhance exploration efficiency in multi-agent scenarios effectively. However, these methods are plagued by instability during training and biases in exploration direction. To address these challenges, we propose Farsighted Self-Direction (FSD), a novel model-free method that utilizes a long-term exploration bonus to achieve coordinated exploration. Since prediction error against individual Q-values indicates a potential bonus for committed exploration, it is taken into account in action selection to directly guide the coordinated exploration. Further, we also use clipped double Q-learning to reduce noise in prediction error. We validate the method on didactic examples and demonstrate the outperformance of our method on challenging StarCraft II micromanagement tasks",
    "checked": true,
    "id": "f8564d05a3bf9a178849ed60ae523e3b07f50363",
    "semantic_title": "efficient exploration in multi-agent reinforcement learning via farsighted self-direction",
    "citation_count": 0,
    "authors": [
      "Tiancheng Lao",
      "Xudong Guo",
      "Mengge Liu",
      "Junjie Yu",
      "Yi Liu",
      "Wenhui Fan"
    ]
  },
  "https://openreview.net/forum?id=8otbGorZK2": {
    "title": "Semantic-Syntactic Discrepancy in Images (SSDI): Learning Meaning and Order of Features from Natural Images",
    "volume": "main",
    "abstract": "Despite considerable progress in image classification tasks, classification models seem unaffected by the images that significantly deviate from those that appear natural to human eyes. Specifically, while human perception can easily identify abnormal appearances or compositions in images, classification models overlook any alterations in the arrangement of object parts as long as they are present in any order, even if unnatural. Hence, this work exposes the vulnerability of having semantic and syntactic discrepancy in images (SSDI) in the form of corruptions that remove or shuffle image patches or present images in the form of puzzles. To address this vulnerability, we propose the concept of \"image grammar\", comprising \"image semantics\" and \"image syntax\". Image semantics pertains to the interpretation of parts or patches within an image, whereas image syntax refers to the arrangement of these parts to form a coherent object. We present a semi-supervised two-stage method for learning the image grammar of visual elements and environments solely from natural images. While the first stage learns the semantic meaning of individual object parts, the second stage learns how their relative arrangement constitutes an entire object. The efficacy of the proposed approach is then demonstrated by achieving SSDI detection rates ranging from 70% to 90% on corruptions generated from CelebA and SUN-RGBD datasets. Code is publicly available at: https://github.com/ChunTao1999/SSDI/",
    "checked": true,
    "id": "e7d88f9a88db846629893e2606ca724f4847cd8d",
    "semantic_title": "semantic-syntactic discrepancy in images (ssdi): learning meaning and order of features from natural images",
    "citation_count": 1,
    "authors": [
      "Chun Tao",
      "Timur Ibrayev",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=sSAp8ITBpC": {
    "title": "Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)",
    "volume": "main",
    "abstract": "Creating secure and resilient applications with large language models (LLM) requires anticipating, adjusting to, and countering unforeseen threats. Red-teaming has emerged as a critical technique for identifying vulnerabilities in real-world LLM implementations. This paper presents a detailed threat model and provides a systematization of knowledge (SoK) of red-teaming attacks on LLMs. We develop a taxonomy of attacks based on the stages of the LLM development and deployment process and extract various insights from previous research. In addition, we compile methods for defense and practical red-teaming strategies for practitioners. By delineating prominent attack motifs and shedding light on various entry points, this paper provides a framework for improving the security and robustness of LLM-based systems",
    "checked": true,
    "id": "9fa830e5c3a108f13cdb25c05a9e6107e365ad83",
    "semantic_title": "operationalizing a threat model for red-teaming large language models (llms)",
    "citation_count": 15,
    "authors": [
      "Apurv Verma",
      "Satyapriya Krishna",
      "Sebastian Gehrmann",
      "Madhavan Seshadri",
      "Anu Pradhan",
      "John A. Doucette",
      "David Rabinowitz",
      "Leslie Barrett",
      "Tom Ault",
      "Hai Phan"
    ]
  },
  "https://openreview.net/forum?id=bXUipBbZDA": {
    "title": "Reinforcement Learning from Bagged Reward",
    "volume": "main",
    "abstract": "In Reinforcement Learning (RL), it is commonly assumed that an immediate reward signal is generated for each action taken by the agent, helping the agent maximize cumulative rewards to obtain the optimal policy. However, in many real-world scenarios, designing immediate reward signals is difficult; instead, agents receive a single reward that is contingent upon a partial sequence or a complete trajectory. In this work, we define this challenging problem as RL from Bagged Reward (RLBR), where sequences of data are treated as bags with non-Markovian bagged rewards, leading to the formulation of Bagged Reward Markov Decision Processes (BRMDPs). Theoretically, we demonstrate that RLBR can be addressed by solving a standard MDP with properly redistributed bagged rewards allocated to each instance within a bag. Empirically, we find that reward redistribution becomes more challenging as the bag length increases, due to reduced informational granularity. Existing reward redistribution methods are insufficient to address these challenges. Therefore, we propose a novel reward redistribution method equipped with a bidirectional attention mechanism, enabling the accurate interpretation of contextual nuances and temporal dependencies within each bag. We experimentally demonstrate that the proposed method consistently outperforms existing approaches",
    "checked": false,
    "id": "6f9dbae279fa0c3a90d12f3b0f271dc8e6274817",
    "semantic_title": "a survey of reinforcement learning from human feedback",
    "citation_count": 142,
    "authors": [
      "Yuting Tang",
      "Xin-Qiang Cai",
      "Yao-Xiang Ding",
      "Qiyu Wu",
      "Guoqing Liu",
      "Masashi Sugiyama"
    ]
  },
  "https://openreview.net/forum?id=AcLlg4J52H": {
    "title": "RS-Reg: Probabilistic and Robust Certified Regression through Randomized Smoothing",
    "volume": "main",
    "abstract": "Randomized smoothing has shown promising certified robustness against adversaries in classification tasks. Despite such success with only zeroth-order access to base models, randomized smoothing has not been extended to a general form of regression. By defining robustness in regression tasks flexibly through probabilities, we demonstrate how to establish upper bounds on input data point perturbation (using the $\\ell_2$ norm) for a user-specified probability of observing valid outputs. Furthermore, we showcase the asymptotic property of a basic averaging function in scenarios where the regression model operates without any constraint. We then derive a certified upper bound of the input perturbations when dealing with a family of regression models where the outputs are bounded. Our simulations verify the validity of the theoretical results and reveal the advantages and limitations of simple smoothing functions, i.e., averaging, in regression tasks. The code is publicly available at \\url{https://github.com/arekavandi/Certified_Robust_Regression}",
    "checked": true,
    "id": "66925c3184e9e17980df8395fd8c5f293028e60b",
    "semantic_title": "rs-reg: probabilistic and robust certified regression through randomized smoothing",
    "citation_count": 1,
    "authors": [
      "Aref Miri Rekavandi",
      "Olga Ohrimenko",
      "Benjamin I. P. Rubinstein"
    ]
  },
  "https://openreview.net/forum?id=qahoztvThX": {
    "title": "A functional framework for nonsmooth autodiff with {\\it maxpooling} functions",
    "volume": "main",
    "abstract": "We make a comment on the recent work by Boustany, by showing that the Murat-TrombettiTheorem provides a simple and efficient mathematical framework for nonsmooth automatic differentiation of {\\it maxpooling} functions. In particular it gives a the chain rule formula which correctly defines the composition of Lipschitz-continuous functions which are piecewise $C^1$. The formalism is applied to four basic examples, with some tests in PyTorch. A self contained proof of an important Stampacchia formula is in the appendix",
    "checked": false,
    "id": "5d82215d767396a6a38bf3f6128a2d118d2496b5",
    "semantic_title": "a functional framework for nonsmooth autodiff with maxpooling functions",
    "citation_count": 0,
    "authors": [
      "Bruno Després"
    ]
  },
  "https://openreview.net/forum?id=ubrOSWyTS8": {
    "title": "∇QDARTS: Quantization as an Elastic Dimension to Differentiable NAS",
    "volume": "main",
    "abstract": "Differentiable Neural Architecture Search methods efficiently find high-accuracy architectures using gradient-based optimization in a continuous domain, saving computational resources. Mixed-precision search helps optimize precision within a fixed architecture. However, applying it to a NAS-generated network does not assure optimal performance as the optimized quantized architecture may not emerge from a standalone NAS method. In light of these considerations, this paper introduces ∇QDARTS, a novel approach that combines differentiable NAS with mixed-precision search for both weight and activation. ∇QDARTS aims to identify the optimal mixed-precision neural architecture capable of achieving remarkable accuracy while operating with minimal computational requirements in a single-shot, end-to-end differentiable framework, obviating the need for pretraining and proxy methods. Compared to fp32, ∇QDARTS shows impressive performance on CIFAR10 with (2,4) bit precision, reducing bit operations by 160× with a slight 1.57% accuracy drop. Increasing the capacity enables ∇QDARTS to match fp32 accuracy while reducing bit operations by 18×. For the ImageNet dataset, with just (2,4) bit precision, ∇QDARTS outperforms state-of-the-art methods such as APQ, SPOS, OQA, and MNAS by 2.3%, 2.9%, 0.3%, and 2.7% in terms of accuracy. By incorporating (2,4,8) bit precision, ∇QDARTS further minimizes the accuracy drop to 1% compared to fp32, alongside a substantial reduction of 17× in required bit operations and 2.6× in memory footprint. In terms of bit-operation (memory footprint) ∇QDARTS excels over APQ, SPOS, OQA, and MNAS with similar accuracy by 2.3× (12×), 2.4× (3×), 13% (6.2×), 3.4× (37%), for bit-operation (memory footprint), respectively. ∇QDARTS enhances the overall search and training efficiency, achieving a 3.1× and 1.54× improvement over APQ and OQA, respectively",
    "checked": true,
    "id": "fccc100c6e1839a847e35ecf2030f483b6f1481c",
    "semantic_title": "∇qdarts: quantization as an elastic dimension to differentiable nas",
    "citation_count": 0,
    "authors": [
      "Payman Behnam",
      "Uday Kamal",
      "Sanjana Vijay Ganesh",
      "Zhaoyi Li",
      "Michael Andrew Jurado",
      "Alind Khare",
      "Igor Fedorov",
      "Gaowen Liu",
      "Alexey Tumanov"
    ]
  },
  "https://openreview.net/forum?id=sTdVnDW0HX": {
    "title": "Piecewise Constant Spectral Graph Neural Network",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) have achieved significant success across various domains by leveraging graph structures in data. Existing spectral GNNs, which use low-degree polynomial filters to capture graph spectral properties, may not fully identify the graph's spectral characteristics because of the polynomial's small degree. However, increasing the polynomial degree is computationally expensive and beyond certain thresholds leads to performance plateaus or degradation. In this paper, we introduce the Piecewise Constant Spectral Graph Neural Network(PieCoN) to address these challenges. PieCoN combines constant spectral filters with polynomial filters to provide a more flexible way to leverage the graph structure. By adaptively partitioning the spectrum into intervals, our approach increases the range of spectral properties that can be effectively learned. Experiments on nine benchmark datasets, including both homophilic and heterophilic graphs, demonstrate that PieCoN is particularly effective on heterophilic datasets, highlighting its potential for a wide range of applications",
    "checked": true,
    "id": "ac91583c081a69ab96702b35d72fc90d39b4b7ae",
    "semantic_title": "piecewise constant spectral graph neural network",
    "citation_count": 0,
    "authors": [
      "Vahan Martirosyan",
      "Jhony H. Giraldo",
      "Fragkiskos D. Malliaros"
    ]
  },
  "https://openreview.net/forum?id=KQzJYI6eo0": {
    "title": "Global Graph Counterfactual Explanation: A Subgraph Mapping Approach",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) have been widely deployed in various real-world applications. However, most GNNs are black-box models that lack explanations. One strategy to explain GNNs is through counterfactual explanation, which aims to find minimum perturbations on input graphs that change the GNN predictions. Existing works on GNN counterfactual explanations primarily concentrate on the local-level perspective (i.e., generating counterfactuals for each individual graph), which suffers from information overload and lacks insights into the broader cross-graph relationships. To address such issues, we propose GlobalGCE, a novel global-level graph counterfactual explanation method. GlobalGCE aims to identify a collection of subgraph mapping rules as counterfactual explanations for the target GNN. According to these rules, substituting certain significant subgraphs with their counterfactual subgraphs will change the GNN prediction to the desired class for most graphs (i.e., maximum coverage). Methodologically, we design a significant subgraph generator and a counterfactual subgraph autoencoder in our GlobalGCE, where the subgraphs and the rules can be effectively generated. Extensive experiments demonstrate the superiority of our GlobalGCE compared to existing baselines. Our code can be found at \\url{https://github.com/YinhanHe123/GlobalGCE}",
    "checked": true,
    "id": "745e233c29fedbf002b31a3987ce614178106eb8",
    "semantic_title": "global graph counterfactual explanation: a subgraph mapping approach",
    "citation_count": 0,
    "authors": [
      "Yinhan He",
      "Wendy Zheng",
      "Yaochen Zhu",
      "Jing Ma",
      "Saumitra Mishra",
      "Natraj Raman",
      "Ninghao Liu",
      "Jundong Li"
    ]
  },
  "https://openreview.net/forum?id=F6l3BBPElY": {
    "title": "Speech Synthesis By Unrolling Diffusion Process using Neural Network Layers",
    "volume": "main",
    "abstract": "This work proposes a novel setup where a neural network is trained to predict multiple steps of the reverse diffusion process in an unrolled manner, with successive layers corresponding to equally spaced steps in the diffusion schedule. Each layer progressively denoises the input during the reverse process until the final layer estimates the original input, $x_0$. Additionally, we introduce a new learning target by using latent variables, rather than the conventional approach of predicting the original input $x_0$ or source error $\\epsilon_0$. In speech synthesis, using $x_0$ or $\\epsilon_0$ often leads to large prediction errors in the early stages of the denoising process, causing distortion in the recovered speech. Our method mitigates this issue and, through extensive evaluation, demonstrates the generation of high-fidelity speech in competitive time, outperforming current state-of-the-art techniques. Moreover, the proposed approach generalizes well to unseen speech. Sample audio is available at \\url{https://onexpeters.github.io/UDPNet/}",
    "checked": true,
    "id": "47df6a7118baa441598e69e1cb5a3bd41cec97f6",
    "semantic_title": "speech synthesis by unrolling diffusion process using neural network layers",
    "citation_count": 0,
    "authors": [
      "Peter Ochieng"
    ]
  },
  "https://openreview.net/forum?id=goe6fv6iSh": {
    "title": "Gaussian Pre-Activations in Neural Networks: Myth or Reality?",
    "volume": "main",
    "abstract": "The study of feature propagation at initialization in neural networks lies at the root of numerous initialization designs. A very common assumption is that the pre-activations are Gaussian. Although this convenient *Gaussian hypothesis* can be justified when the number of neurons per layer tends to infinity, it is challenged by both theoretical and experimental work for finite-width neural networks. Our main contribution is to construct a family of pairs of activation functions and initialization distributions that ensure that the pre-activations remain Gaussian throughout the network depth, even in narrow neural networks, under the assumption that the pre-activations are independent. In the process, we discover a set of constraints that a neural network should satisfy to ensure Gaussian pre-activations. In addition, we provide a critical review of the claims of the Edge of Chaos line of work and construct a non-asymptotic Edge of Chaos analysis. We also propose a unified view on the propagation of pre-activations, encompassing the framework of several well-known initialization procedures. More generally, our work provides a principled framework for addressing the much-debated question: is it desirable to initialize the training of a neural network whose pre-activations are guaranteed to be Gaussian? Our code is available on GitHub: https://github.com/p-wol/gaussian-preact/",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pierre Wolinski",
      "Julyan Arbel"
    ]
  },
  "https://openreview.net/forum?id=akumIxQjNN": {
    "title": "ReDistill: Residual Encoded Distillation for Peak Memory Reduction of CNNs",
    "volume": "main",
    "abstract": "The expansion of neural network sizes and the enhanced resolution of modern image sensors result in heightened memory and power demands to process modern computer vision models. In order to deploy these models in extremely resource-constrained edge devices, it is crucial to reduce their peak memory, which is the maximum memory consumed during the execution of a model. A naive approach to reducing peak memory is aggressive down-sampling of feature maps via pooling with large stride, which often results in unacceptable degradation in network performance. To mitigate this problem, we propose residual encoded distillation (ReDistill) for peak memory reduction in a teacher-student framework, in which a student network with less memory is derived from the teacher network using aggressive pooling. We apply our distillation method to multiple problems in computer vision, including image classification and diffusion-based image generation. For image classification, our method yields 4x-5x theoretical peak memory reduction with less degradation in accuracy for most CNN-based architectures. For diffusion-based image generation, our proposed distillation method yields a denoising network with 4x lower theoretical peak memory while maintaining decent diversity and fidelity for image generation. Experiments demonstrate our method's superior performance compared to other feature-based and response-based distillation methods when applied to the same student network. The code is available at https://github.com/mengtang-lab/ReDistill",
    "checked": false,
    "id": "7012a749533b2c30c3c633844008134fe73968cf",
    "semantic_title": "redistill: residual encoded distillation for peak memory reduction",
    "citation_count": 1,
    "authors": [
      "Fang Chen",
      "Gourav Datta",
      "Mujahid Al Rafi",
      "Hyeran Jeon",
      "Meng Tang"
    ]
  },
  "https://openreview.net/forum?id=9fPinz1iH2": {
    "title": "Heterophily-informed Message Passing",
    "volume": "main",
    "abstract": "Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due to their implicit homophily assumption. We mitigate this problem with a novel scheme that regulates the aggregation of messages, modulating the type and extent of message passing locally thereby preserving both the low and high-frequency components of information. Our approach relies solely on learnt embeddings, obviating the need for auxiliary labels, thus extending the benefits of heterophily-aware embeddings to broader applications, e.g. generative modelling. Our experiments, conducted across various data sets and GNN architectures, demonstrate performance enhancements and reveal heterophily patterns across standard classification benchmarks. Furthermore, application to molecular generation showcases notable performance improvements on chemoinformatics benchmarks",
    "checked": true,
    "id": "a642b5644af6305dc3c274efc7064d655c40ae84",
    "semantic_title": "heterophily-informed message passing",
    "citation_count": 0,
    "authors": [
      "Haishan Wang",
      "Arno Solin",
      "Vikas K Garg"
    ]
  },
  "https://openreview.net/forum?id=AIby9MQXbu": {
    "title": "Robust Model Selection of Gaussian Graphical Models",
    "volume": "main",
    "abstract": "In Gaussian graphical model selection, noise-corrupted samples present significant challenges. It is known that even minimal amounts of noise can obscure the underlying structure, leading to fundamental identifiability issues. A recent line of work addressing this \"robust model selection\" problem narrows its focus to tree-structured graphical models. Even within this specific class of models, exact structure recovery is shown to be impossible. However, several algorithms have been developed that are known to provably recover the underlying tree-structure up to an (unavoidable) equivalence class. In this paper, we extend these results beyond tree-structured graphs. We first characterize the equivalence class up to which general graphs can be recovered in the presence of noise. Despite the inherent ambiguity (which we prove is unavoidable), the structure that can be recovered reveals local clustering information and global connectivity patterns in the underlying model. Such information is useful in a range of real-world problems, including power grids, social networks, protein-protein interactions, and neural structures. We then propose an algorithm which provably recovers the underlying graph up to the identified ambiguity. We further provide finite sample guarantees in the high-dimensional regime for our algorithm and validate our results through numerical simulations",
    "checked": false,
    "id": "6447ffa996c21d26af441f33d06bc6773e4002c6",
    "semantic_title": "a simple method for estimating gaussian graphical models",
    "citation_count": 0,
    "authors": [
      "Abrar Zahin",
      "Rajasekhar Anguluri",
      "Lalitha Sankar",
      "Oliver Kosut",
      "Gautam Dasarathy"
    ]
  },
  "https://openreview.net/forum?id=h434zx5SX0": {
    "title": "Sample, estimate, aggregate: A recipe for causal discovery foundation models",
    "volume": "main",
    "abstract": "Causal discovery, the task of inferring causal structure from data, has the potential to uncover mechanistic insights from biological experiments, especially those involving perturbations. However, causal discovery algorithms over larger sets of variables tend to be brittle against misspecification or when data are limited. For example, single-cell transcriptomics measures thousands of genes, but the nature of their relationships is not known, and there may be as few as tens of cells per intervention setting. To mitigate these challenges, we propose a foundation model-inspired approach: a supervised model trained on large-scale, synthetic data to predict causal graphs from summary statistics — like the outputs of classical causal discovery algorithms run over subsets of variables and other statistical hints like inverse covariance. Our approach is enabled by the observation that typical errors in the outputs of a discovery algorithm remain comparable across datasets. Theoretically, we show that the model architecture is well-specified, in the sense that it can recover a causal graph consistent with graphs over subsets. Empirically, we train the model to be robust to misspecification and distribution shift using diverse datasets. Experiments on biological and synthetic data confirm that this model generalizes well beyond its training set, runs on graphs with hundreds of variables in seconds, and can be easily adapted to different underlying data assumptions",
    "checked": true,
    "id": "a8232bcaaff260e8b61e51253bf5cedbd08cc89a",
    "semantic_title": "sample, estimate, aggregate: a recipe for causal discovery foundation models",
    "citation_count": 7,
    "authors": [
      "Menghua Wu",
      "Yujia Bao",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ]
  },
  "https://openreview.net/forum?id=IizmQoF86Y": {
    "title": "A Learning-Based Framework for Fair and Scalable Solution Generation in Kidney Exchange Problems",
    "volume": "main",
    "abstract": "Reinforcement learning and Generative Flow Networks, known as GFlowNets, present an exciting possibility for neural networks to model distributions across various data structures. In this paper, we broaden their applicability to data structures consisting of optimal solutions for a combinatorial problem. Concretely, we propose using Q-learning and various policy gradient methods, as well as GFlowNets to learn the distribution of optimal solutions for kidney exchange problems (KEPs). This could provide a useful tool for decision-making authorities, policymakers and clinicians, as it offers them multiple optimal or near-optimal solutions, and provides a complementary landscape to their traditional integer programming-based toolbox for promoting fairness and societal benefits. Our reinforcement learning-based framework trained on KEP instances provides an effective addition to computationally expensive exact approaches, notably mixed-integer programming. Our experiments thoroughly evaluate the quality of the solution sets sampled from the trained neural networks in terms of optimality, their scalability when dealing with real-sized KEP instances, and their capability to generate a diverse pool of solutions. We also cover the use of their efficient solution generation capabilities to improve fairness and simulate the evolution of the KEP pool in a dynamic setting. Our contribution is thus: 1) methodological, as it introduces a novel setting for reinforcement learning in addition to GFlowNets, 2) implementational, as it delves beyond the theory and details how to use conditional information, and 3) of practical significance, as it considers a specific combinatorial problem in the healthcare domain",
    "checked": true,
    "id": "0214f08c7764551ff4afb3a4e46b5c407bb899cc",
    "semantic_title": "a learning-based framework for fair and scalable solution generation in kidney exchange problems",
    "citation_count": 0,
    "authors": [
      "William St-Arnaud",
      "Margarida Carvalho",
      "Golnoosh Farnadi"
    ]
  },
  "https://openreview.net/forum?id=HRvHCd03HM": {
    "title": "Double Horizon Model-Based Policy Optimization",
    "volume": "main",
    "abstract": "Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long ``distribution rollout'' (DR) and a short ``training rollout'' (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime",
    "checked": true,
    "id": "e93307c72940db3ca2f2926f1d36a3daa078c702",
    "semantic_title": "double horizon model-based policy optimization",
    "citation_count": 0,
    "authors": [
      "Akihiro Kubo",
      "Paavo Parmas",
      "Shin Ishii"
    ]
  },
  "https://openreview.net/forum?id=vPVqQmjCy8": {
    "title": "LLM-TS Integrator: Integrating LLM for Enhanced Time Series Modeling",
    "volume": "main",
    "abstract": "Time series~(TS) modeling is essential in dynamic systems like weather prediction and anomaly detection. Recent studies utilize Large Language Models (LLMs) for TS modeling, leveraging their powerful pattern recognition capabilities. These methods primarily position LLMs as the predictive backbone, often omitting the mathematical modeling within traditional TS models, such as periodicity. However, disregarding the potential of LLMs also overlooks their pattern recognition capabilities. To address this gap, we introduce \\textit{LLM-TS Integrator}, a novel framework that effectively integrates the capabilities of LLMs into traditional TS modeling. Central to this integration is our \\textit{mutual information} module. The core of this \\textit{mutual information} module is a traditional TS model enhanced with LLM-derived insights for improved predictive abilities. This enhancement is achieved by maximizing the mutual information between traditional model's TS representations and LLM's textual representation counterparts, bridging the two modalities. Moreover, we recognize that samples vary in importance for two losses: traditional prediction and mutual information maximization. To address this variability, we introduce the \\textit{sample reweighting} module to improve information utilization. This module assigns dual weights to each sample: one for prediction loss and another for mutual information loss, dynamically optimizing these weights via bi-level optimization. Our method achieves state-of-the-art or comparable performance across five mainstream TS tasks, including short-term and long-term forecasting, imputation, classification, and anomaly detection. Our code is available at: \\url{https://anonymous.4open.science/r/llm_ts_anonymous-F07D/README.MD}",
    "checked": true,
    "id": "013fefa7c76d4f07cd5b40bb12553cb17be9e98c",
    "semantic_title": "llm-ts integrator: integrating llm for enhanced time series modeling",
    "citation_count": 2,
    "authors": [
      "Can Chen",
      "Gabriel L. Oliveira",
      "Hossein Sharifi-Noghabi",
      "Tristan Sylvain"
    ]
  },
  "https://openreview.net/forum?id=beqSqPgE33": {
    "title": "Covariate-dependent Graphical Model Estimation via Neural Networks with Statistical Guarantees",
    "volume": "main",
    "abstract": "Graphical models are widely used in diverse application domains to model the conditional dependencies amongst a collection of random variables. In this paper, we consider settings where the graph structure is covariate-dependent, and investigate a deep neural network-based approach to estimate it. The method allows for flexible functional dependency on the covariate, and fits the data reasonably well in the absence of a Gaussianity assumption. Theoretical results with PAC guarantees are established for the method, under assumptions commonly used in an Empirical Risk Minimization framework. The performance of the proposed method is evaluated on several synthetic data settings and benchmarked against existing approaches. The method is further illustrated on real datasets involving data from neuroscience and finance, respectively, and produces interpretable results",
    "checked": true,
    "id": "f94e7f3658b928895c03be91b72d7b0e0a24f87b",
    "semantic_title": "covariate-dependent graphical model estimation via neural networks with statistical guarantees",
    "citation_count": 0,
    "authors": [
      "Jiahe Lin",
      "Yikai Zhang",
      "George Michailidis"
    ]
  },
  "https://openreview.net/forum?id=X6IY04Akw1": {
    "title": "Generalizable and Robust Spectral Method for Multi-view Representation Learning",
    "volume": "main",
    "abstract": "Multi-view representation learning (MvRL) has garnered substantial attention in recent years, driven by the increasing demand for applications that can effectively process and analyze data from multiple sources. In this context, graph Laplacian-based MvRL methods have demonstrated remarkable success in representing multi-view data. However, these methods often struggle with generalization to new data and face challenges with scalability. Moreover, in many practical scenarios, multi-view data is contaminated by noise or outliers. In such cases, modern deep-learning-based MvRL approaches that rely on alignment or contrastive objectives present degraded performance in downstream tasks, as they may impose incorrect consistency between clear and corrupted data sources. We introduce *SpecRaGE*, a novel fusion-based framework that integrates the strengths of graph Laplacian methods with the power of deep learning to overcome these challenges. SpecRage uses neural networks to learn parametric mapping that approximates a joint diagonalization of graph Laplacians. This solution bypasses the need for alignment while enabling generalizable and scalable learning of informative and meaningful representations. Moreover, it incorporates a meta-learning fusion module that dynamically adapts to data quality, ensuring robustness against outliers and noisy views. Our extensive experiments demonstrate that SpecRaGE outperforms state-of-the-art methods, particularly in scenarios with data contamination, paving the way for more reliable and efficient multi-view learning. Our code will be made publicly available upon acceptance",
    "checked": true,
    "id": "1faa5623932d4ee1b87780d086f87aa42583e402",
    "semantic_title": "generalizable and robust spectral method for multi-view representation learning",
    "citation_count": 1,
    "authors": [
      "Amitai Yacobi",
      "Ofir Lindenbaum",
      "Uri Shaham"
    ]
  },
  "https://openreview.net/forum?id=5qo8MF3QU1": {
    "title": "Out-of-Distribution Learning with Human Feedback",
    "volume": "main",
    "abstract": "Out-of-distribution (OOD) learning often relies on strong statistical assumptions or predefined OOD data distributions, limiting its effectiveness in real-world deployment for both OOD generalization and detection, especially when human inspection is minimal. This paper introduces a novel framework for OOD learning that integrates human feedback to enhance model adaptation and reliability. Our approach leverages freely available unlabeled data in the wild, which naturally captures environmental test-time OOD distributions under both covariate and semantic shifts. To effectively utilize such data, we propose selectively acquiring human feedback to label a small subset of informative samples. These labeled samples are then used to train both a multi-class classifier and an OOD detector. By incorporating human feedback, our method significantly improves model robustness and precision in handling OOD scenarios. We provide theoretical insights by establishing generalization error bounds for our algorithm. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods by a significant margin. Code is publicly available at https://github.com/HaoyueBaiZJU/ood-hf",
    "checked": true,
    "id": "04bf3cb0a104edd715d7ba639822174a86af7c11",
    "semantic_title": "out-of-distribution learning with human feedback",
    "citation_count": 5,
    "authors": [
      "Haoyue Bai",
      "Xuefeng Du",
      "Katie Rainey",
      "Shibin Parameswaran",
      "Yixuan Li"
    ]
  },
  "https://openreview.net/forum?id=B9BHjTN4z6": {
    "title": "RLeXplore: Accelerating Research in Intrinsically-Motivated Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "769d8fdf6520c52e8767ee6d54f6417cf6e7904e",
    "semantic_title": "rlexplore: accelerating research in intrinsically-motivated reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Mingqi Yuan",
      "Roger Creus Castanyer",
      "Bo Li",
      "Xin Jin",
      "Wenjun Zeng",
      "Glen Berseth"
    ]
  },
  "https://openreview.net/forum?id=hiiRCXmbAz": {
    "title": "Hyperparameters in Continual Learning: A Reality Check",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "49ac5cef911a64d47322aaf02c6e7bea05e8da87",
    "semantic_title": "hyperparameters in continual learning: a reality check",
    "citation_count": 6,
    "authors": [
      "Sungmin Cha",
      "Kyunghyun Cho"
    ]
  },
  "https://openreview.net/forum?id=Ucpfdn66k2": {
    "title": "When Are Bias-Free ReLU Networks Effectively Linear Networks?",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "929e9a89b82c95f52eb23c7b932c1969487a5238",
    "semantic_title": "when are bias-free relu networks effectively linear networks?",
    "citation_count": 0,
    "authors": [
      "Yedi Zhang",
      "Andrew M Saxe",
      "Peter E. Latham"
    ]
  },
  "https://openreview.net/forum?id=nannw4SGfS": {
    "title": "Accelerating Learned Image Compression Through Modeling Neural Training Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6abeb9b5b6ad6c3f6ea2b5fb6a0f0b2ddff59f49",
    "semantic_title": "accelerating learned image compression through modeling neural training dynamics",
    "citation_count": 0,
    "authors": [
      "Yichi Zhang",
      "Zhihao Duan",
      "Yuning Huang",
      "Fengqing Zhu"
    ]
  },
  "https://openreview.net/forum?id=BaRD2Nfj41": {
    "title": "Overcoming Knowledge Barriers: Online Imitation Learning from Visual Observation with Pretrained World Models",
    "volume": "main",
    "abstract": "Pretraining and finetuning models has become increasingly popular in decision-making. But there are still serious impediments in Imitation Learning from Observation (ILfO) with pretrained models. This study identifies two primary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB). The EKB emerges due to the pretrained models' limitations in handling novel observations, which leads to inaccurate action inference. Conversely, the DKB stems from the reliance on limited demonstration datasets, restricting the model's adaptability across diverse scenarios. We propose separate solutions to overcome each barrier and apply them to Action Inference by Maximising Evidence (AIME), a state-of-the-art algorithm. This new algorithm, AIME-NoB, integrates online interactions and a data-driven regulariser to mitigate the EKB. Additionally, it uses a surrogate reward function to broaden the policy's supported states, addressing the DKB. Our experiments on vision-based control tasks from the DeepMind Control Suite and MetaWorld benchmarks show that AIME-NoB significantly improves sample efficiency and converged performance, presenting a robust framework for overcoming the challenges in ILfO with pretrained models. Code available at https://github.com/IcarusWizard/AIME-NoB",
    "checked": true,
    "id": "a8ad39fc162c238b5c126a2d350d00dd7ab1ba87",
    "semantic_title": "overcoming knowledge barriers: online imitation learning from visual observation with pretrained world models",
    "citation_count": 0,
    "authors": [
      "Xingyuan Zhang",
      "Philip Becker-Ehmck",
      "Patrick van der Smagt",
      "Maximilian Karl"
    ]
  },
  "https://openreview.net/forum?id=yGGoOVpBVP": {
    "title": "Connecting Parameter Magnitudes and Hessian Eigenspaces at Scale using Sketched Methods",
    "volume": "main",
    "abstract": "Recently, it has been observed that when training a deep neural net with SGD, the majority of the loss landscape's curvature quickly concentrates in a tiny *top* eigenspace of the loss Hessian, which remains largely stable thereafter. Independently, it has been shown that successful magnitude pruning masks for deep neural nets emerge early in training and remain stable thereafter. In this work, we study these two phenomena jointly and show that they are connected: We develop a methodology to measure the similarity between arbitrary parameter masks and Hessian eigenspaces via Grassmannian metrics. We identify *overlap* as the most useful such metric due to its interpretability and stability. To compute *overlap*, we develop a matrix-free algorithm based on sketched SVDs that allows us to compute over 1000 Hessian eigenpairs for nets with over 10M parameters --an unprecedented scale by several orders of magnitude. Our experiments reveal an *overlap* between magnitude parameter masks and top Hessian eigenspaces consistently higher than chance-level, and that this effect gets accentuated for larger network sizes. This result indicates that *top Hessian eigenvectors tend to be concentrated around larger parameters*, or equivalently, that *larger parameters tend to align with directions of larger loss curvature*. Our work provides a methodology to approximate and analyze deep learning Hessians at scale, as well as a novel insight on the structure of their eigenspace",
    "checked": true,
    "id": "9ad03b95335af5b64e86fbe666f0516711b99524",
    "semantic_title": "connecting parameter magnitudes and hessian eigenspaces at scale using sketched methods",
    "citation_count": 0,
    "authors": [
      "Andres Fernandez",
      "Frank Schneider",
      "Maren Mahsereci",
      "Philipp Hennig"
    ]
  },
  "https://openreview.net/forum?id=mvbZBaqSXo": {
    "title": "Dimension reduction via score ratio matching",
    "volume": "main",
    "abstract": "Gradient-based dimension reduction decreases the cost of Bayesian inference and probabilistic modeling by identifying maximally informative (and informed) low-dimensional projections of the data and parameters, allowing high-dimensional problems to be reformulated as cheaper low-dimensional problems. A broad family of such techniques identify these projections and provide error bounds on the resulting posterior approximations, via eigendecompositions of certain diagnostic matrices. Yet these matrices require gradients or even Hessians of the log-likelihood, excluding the purely data-driven setting and many problems of simulation-based inference. We propose a framework, derived from score-matching, to extend gradient-based dimension reduction to problems where gradients are unavailable. Specifically, we formulate an objective function to directly learn the score ratio function needed to compute the diagnostic matrices, propose a tailored parameterization for the score ratio network, and introduce regularization methods that capitalize on the hypothesized low-dimensional structure. We also introduce a novel algorithm to iteratively identify the low-dimensional reduced basis vectors more accurately with limited data based on eigenvalue deflation methods. We show that our approach outperforms standard score-matching for problems with low-dimensional structure, and demonstrate its effectiveness for PDE-constrained Bayesian inverse problems and conditional generative modeling",
    "checked": true,
    "id": "b9018ae0afe7f92707f5cdcb2b95e1b831d343a7",
    "semantic_title": "dimension reduction via score ratio matching",
    "citation_count": 1,
    "authors": [
      "Ricardo Baptista",
      "Michael Brennan",
      "Youssef Marzouk"
    ]
  },
  "https://openreview.net/forum?id=eIPwJgadfZ": {
    "title": "Convex Relaxation for Solving Large-Margin Classifiers in Hyperbolic Space",
    "volume": "main",
    "abstract": "Hyperbolic spaces have increasingly been recognized for their outstanding performance in handling data with inherent hierarchical structures compared to their Euclidean counterparts. However, learning in hyperbolic spaces poses significant challenges. In particular, extending support vector machines to hyperbolic spaces is in general a constrained non-convex optimization problem. Previous and popular attempts to solve hyperbolic SVMs, primarily using projected gradient descent, are generally sensitive to hyperparameters and initializations, often leading to suboptimal solutions. In this work, by first rewriting the problem into a polynomial optimization, we apply semidefinite relaxation and sparse moment-sum-of-squares relaxation to effectively approximate the optima. From extensive empirical experiments, these methods are shown to achieve better classification accuracies than the projected gradient descent approach in most of the synthetic and real two-dimensional hyperbolic embedding dataset under the one-vs-rest multiclass-classification scheme",
    "checked": true,
    "id": "56ad3d35be28e983c6fd632fd7ef92a346e7241d",
    "semantic_title": "convex relaxation for solving large-margin classifiers in hyperbolic space",
    "citation_count": 0,
    "authors": [
      "Sheng Yang",
      "Peihan Liu",
      "Cengiz Pehlevan"
    ]
  },
  "https://openreview.net/forum?id=MbF1gYfIlY": {
    "title": "Can Kernel Methods Explain How the Data Affects Neural Collapse?",
    "volume": "main",
    "abstract": "A vast amount of literature has recently focused on the \"Neural Collapse\" (NC) phenomenon, which emerges when training neural network (NN) classifiers beyond the zero training error point. The core component of NC is the decrease in the within-class variability of the network's deepest features, dubbed as NC1. The theoretical works that study NC are typically based on simplified unconstrained features models (UFMs) that mask any effect of the data on the extent of collapse. To address this limitation of UFMs, this paper explores the possibility of analyzing NC1 using kernels associated with shallow NNs. We begin by formulating an NC1 metric as a function of the kernel. Then, we specialize it to the NN Gaussian Process kernel (NNGP) and the Neural Tangent Kernel (NTK), associated with wide networks at initialization and during gradient-based training with a small learning rate, respectively. As a key result, we show that the NTK does not represent more collapsed features than the NNGP for Gaussian data of arbitrary dimensions. This showcases the limitations of data-independent kernels such as NTK in approximating the NC behavior of NNs. As an alternative to NTK, we then empirically explore a recently proposed data-aware Gaussian Process kernel, which generalizes NNGP to model feature learning. We show that this kernel yields lower NC1 than NNGP but may not follow the trends of the shallow NN. Our study demonstrates that adaptivity to data may allow kernel-based analysis of NC, though further advancements in this area are still needed. A nice byproduct of our study is showing both theoretically and empirically that the choice of nonlinear activation function affects NC1 (with ERF yielding lower values than ReLU)",
    "checked": true,
    "id": "c45d749646b4312a58564209172192e2ff5f7a4f",
    "semantic_title": "can kernel methods explain how the data affects neural collapse?",
    "citation_count": 3,
    "authors": [
      "Vignesh Kothapalli",
      "Tom Tirer"
    ]
  },
  "https://openreview.net/forum?id=CovLQwu611": {
    "title": "ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization",
    "volume": "main",
    "abstract": "Parameter-efficient fine-tuning (PEFT) enables creation of specialized language models for diverse tasks, resulting in numerous expert modules. In many practical use cases, these expert PEFT modules are integrated into a single model that answers arbitrary queries by routing queries to different experts. However, only a few experts can be kept in GPU memory due to memory constraints. Consequently, expert modules are frequently loaded and offloaded between CPU/GPU memory or disk storage. This frequent swapping dramatically increases communication overhead, leading unacceptable latency and degrading user experience. The large size of modern PEFT modules further exacerbates this latency. For example, QLoRA experts for 65B LLaMA are 3.2GB, making swapping a major communication bottleneck, particularly in memory-constrained environments. To address these issues, we present ComPEFT (compressed PEFT), a novel method for compressing fine-tuning residuals (task vectors) of PEFT models. Reducing expert PEFT module size effectively addresses both memory and communication limitations, facilitating faster swapping and enabling a higher density of experts within a given memory footprint. ComPEFT employs sparsification and ternary quantization to reduce PEFT module size without any additional training while preserving or enhancing model performance. Extensive evaluation across T5, T0, and LLaMA-based models with 200M − 65B parameters, ComPEFT achieves compression ratios of 8x − 50x. Specifically, we show that ComPEFT improves with scale – stronger models exhibit higher compressibility and better performance. We show ComPEFT applied to LLaMA − 65B outperforms QLoRA by 4.16% on MMLU with a 26x storage size reduction. Additionally, compressed experts produced by ComPEFT maintain few-shot compositional generalization capabilities, facilitate efficient communication and computation, and exhibit enhanced performance when merged. Lastly, we provide an analysis of different method components, compare ComPEFT with other PEFT methods, and test its efficacy for compressing full finetuning residual",
    "checked": true,
    "id": "dff9b29918369f2ce7c06d13258ffad5c644788a",
    "semantic_title": "compeft: compression for communicating parameter efficient updates via sparsification and quantization",
    "citation_count": 14,
    "authors": [
      "Prateek Yadav",
      "Leshem Choshen",
      "Colin Raffel",
      "Mohit Bansal"
    ]
  },
  "https://openreview.net/forum?id=322PpCGAX8": {
    "title": "MaxCutBench: Revisiting and Benchmarking Graph Neural Networks for Maximum Cut",
    "volume": "main",
    "abstract": "Recently, there has been much work on designing general heuristics for graph-based, combinatorial optimization problems via the incorporation of Graph Neural Networks (GNNs) to learn distribution-specific solution structures. However, there is a lack of consistency in evaluating these heuristics in terms of the baselines and instances chosen, making it difficult to assess the relative performance of the algorithms. In this paper, we introduce \\textbf{MaxCutBench}—an open-source benchmark suite dedicated to the NP-hard Maximum Cut problem. The suite offers a unified interface for $16$ algorithms, both traditional and machine-learning-based. Using our benchmark, we conduct an in-depth analysis of the implemented algorithms on a carefully selected set of hard instances from diverse graph datasets. Our main finding is that classical local search heuristics can outperform several highly cited learning-based approaches, including S2V-DQN (Khalil et al., 2017), ECO-DQN (Barrett et al., 2020), among others, in terms of objective value, generalization, inference time, and scalability. Additionally, we find that the performance of ECO-DQN either remains the same or improves when the GNN is replaced by simple linear regression. We hope our benchmark will contribute to the efforts of the community to standardize the evaluation of learned heuristics for combinatorial optimization. Code, data, and pre-trained models are available at: \\url{https://github.com/ankurnath/MaxCut-Bench}",
    "checked": true,
    "id": "e315b73b783eed4b628d6aa7692f13db5c201e54",
    "semantic_title": "maxcutbench: revisiting and benchmarking graph neural networks for maximum cut",
    "citation_count": 0,
    "authors": [
      "Ankur Nath",
      "Alan Kuhnle"
    ]
  },
  "https://openreview.net/forum?id=YBPbMKJbLd": {
    "title": "Future-aware Safe Active Learning of Time Varying Systems using Gaussian Processes",
    "volume": "main",
    "abstract": "Experimental exploration of high-cost systems with safety constraints, common in engineering applications, is a challenging endeavor. Data-driven models offer a promising solution, but acquiring the requisite data remains expensive and is potentially unsafe. Safe active learning techniques prove essential, enabling the learning of high-quality models with minimal expensive data points and high safety. This paper introduces a safe active learning framework tailored for time-varying systems, addressing drift, seasonal changes, and complexities due to dynamic behavior. The proposed Time-aware Integrated Mean Squared Prediction Error (T-IMSPE) method minimizes posterior variance over current and future states, optimizing information gathering also in the time domain. Empirical results highlight T-IMSPE's advantages in model quality through synthetic and real-world examples. State of the art Gaussian processes are compatible with T-IMSPE. Our theoretical contributions include a clear delineation which Gaussian process kernels, domains, and weighting measures are suitable for T-IMSPE and even beyond for its non-time aware predecessor IMSPE",
    "checked": false,
    "id": "fdc69c043851bacf57ed840d930609bdfdfe09f5",
    "semantic_title": "future aware safe active learning of time varying systems using gaussian processes",
    "citation_count": 0,
    "authors": [
      "Markus Lange-Hegermann",
      "Christoph Zimmer"
    ]
  },
  "https://openreview.net/forum?id=CgWkVb2lHB": {
    "title": "VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models",
    "volume": "main",
    "abstract": "Vision language models (VLMs) have shown promising reasoning capabilities across various benchmarks; however, our understanding of their visual perception remains limited. In this work, we propose an eye examination process to investigate how a VLM perceives images, focusing on key aspects of visual recognition, ranging from basic color and shape to semantic understanding. We introduce a dataset, LENS, to guide VLMs to follow the examination and check its readiness. Once the model is ready, we conduct the examination. We quantify and visualize VLMs' sensitivities to color and shape, and semantic matching. Our findings reveal that VLMs have varying sensitivity to different colors while consistently showing insensitivity to green across different VLMs. Also, we found different shape sensitivity and semantic recognition depending on LLM's capacity despite using the same fixed visual encoder. Our analyses and findings have the potential to inspire the design of VLMs and the pre-processing of visual input to VLMs for improving application performance",
    "checked": true,
    "id": "698bdd195324d52b3998541015bd0fe3db3ffef7",
    "semantic_title": "vlm's eye examination: instruct and inspect visual competency of vision language models",
    "citation_count": 3,
    "authors": [
      "Nam Hyeon-Woo",
      "Moon Ye-Bin",
      "Wonseok Choi",
      "Lee Hyun",
      "Tae-Hyun Oh"
    ]
  },
  "https://openreview.net/forum?id=jdvnaki7ZY": {
    "title": "Jet: A Modern Transformer-Based Normalizing Flow",
    "volume": "main",
    "abstract": "In the past, normalizing generative flows have emerged as a promising class of generative models for natural images. This type of model has many modeling advantages: the ability to efficiently compute log-likelihood of the input data, fast generation, and simple overall structure. Normalizing flows remained a topic of active research but later fell out of favor, as visual quality of the samples was not competitive with other model classes, such as GANs, VQ-VAE-based approaches or diffusion models. In this paper we revisit the design of coupling-based normalizing flow models by carefully ablating prior design choices and using computational blocks based on the Vision Transformer architecture, not convolutional neural networks. As a result, we achieve a much simpler architecture that matches existing normalizing flow models and improves over them when paired with pretraining. While the overall visual quality is still behind the current state-of-the-art models, we argue that strong normalizing flow models can help advancing the research frontier by serving as building components of more powerful generative models",
    "checked": true,
    "id": "0dc3ce7fa1ad45e39367da7118ce0947e69c5a0d",
    "semantic_title": "jet: a modern transformer-based normalizing flow",
    "citation_count": 3,
    "authors": [
      "Alexander Kolesnikov",
      "André Susano Pinto",
      "Michael Tschannen"
    ]
  },
  "https://openreview.net/forum?id=j6Rm6T2lFU": {
    "title": "Deep Koopman Learning using Noisy Data",
    "volume": "main",
    "abstract": "This paper proposes a data-driven framework to learn a finite-dimensional approximation of a Koopman operator for approximating the state evolution of a dynamical system under noisy observations. To this end, our proposed solution has two main advantages. First, the proposed method only requires the measurement noise to be bounded. Second, the proposed method modifies the existing deep Koopman operator formulations by characterizing the effect of the measurement noise on the Koopman operator learning and then mitigating it by updating the tunable parameter of the observable functions of the Koopman operator, making it easy to implement. The performance of the proposed method is demonstrated on several standard benchmarks. We then compare the presented method with similar methods proposed in the latest literature on Koopman learning",
    "checked": true,
    "id": "5bc265f53c81ec928310b65900e92560fac36da5",
    "semantic_title": "deep koopman learning using noisy data",
    "citation_count": 0,
    "authors": [
      "Wenjian Hao",
      "Devesh Upadhyay",
      "Shaoshuai Mou"
    ]
  },
  "https://openreview.net/forum?id=DqPCWMiMU0": {
    "title": "CoDe: Blockwise Control for Denoising Diffusion Models",
    "volume": "main",
    "abstract": "Aligning diffusion models to downstream tasks often requires finetuning new models or gradient-based guidance at inference time to enable sampling from the reward-tilted posterior. In this work, we explore a simple inference-time gradient-free guidance approach, called controlled denoising (CoDe), that circumvents the need for differentiable guidance functions and model finetuning. CoDe is a blockwise sampling method applied during intermediate denoising steps, allowing for alignment with downstream rewards. Our experiments demonstrate that, despite its simplicity, CoDe offers a favorable trade-off between reward alignment, prompt instruction following, and inference cost, achieving a competitive performance against the state-of-the-art baselines}. Our code is available at https://github.com/anujinho/code",
    "checked": true,
    "id": "72a2e7333f432ba2dde838d33f249d8a251a002c",
    "semantic_title": "code: blockwise control for denoising diffusion models",
    "citation_count": 5,
    "authors": [
      "Anuj Singh",
      "Sayak Mukherjee",
      "Ahmad Beirami",
      "Hadi J. Rad"
    ]
  },
  "https://openreview.net/forum?id=7rqV7Cb67L": {
    "title": "Fairness-Aware Dense Subgraph Discovery",
    "volume": "main",
    "abstract": "Dense subgraph discovery (DSD) is a key graph mining primitive with myriad applications including finding densely connected communities which are diverse in their vertex composition. In such a context, it is desirable to extract a dense subgraph that provides fair representation of the diverse subgroups that constitute the vertex set while incurring a small loss in terms of subgraph density. Existing methods for promoting fairness in DSD have important limitations - the associated formulations are NP-hard in the worst case and they do not provide flexible notions of fairness, making it non-trivial to analyze the inherent trade-off between density and fairness. In this paper, we introduce two tractable formulations for fair DSD, each offering a different notion of fairness. Our methods provide a structured and flexible approach to incorporate fairness, accommodating varying fairness levels. We introduce the fairness-induced relative loss in subgraph density as a price of fairness measure to quantify the associated trade-off. We are the first to study such a notion in the context of detecting fair dense subgraphs. Extensive experiments on real-world datasets demonstrate that our methods not only match but frequently outperform existing solutions, sometimes incurring even less than half the subgraph density loss compared to prior art, while achieving the target fairness levels. Importantly, they excel in scenarios that previous methods fail to adequately handle, i.e., those with extreme subgroup imbalances, highlighting their effectiveness in extracting fair and dense solutions",
    "checked": true,
    "id": "9b431a2c06e2d8414def6bbb3819e3a9506f7194",
    "semantic_title": "fairness-aware dense subgraph discovery",
    "citation_count": 1,
    "authors": [
      "Emmanouil Kariotakis",
      "Nicholas D Sidiropoulos",
      "Aritra Konar"
    ]
  },
  "https://openreview.net/forum?id=jXcx2oAIbw": {
    "title": "LLM-Guided Self-Supervised Tabular Learning With Task-Specific Pre-text Tasks",
    "volume": "main",
    "abstract": "One of the most common approaches for self-supervised representation learning is defining pre-text tasks to learn data representations. Existing works determine pre-text tasks in a \"task-agnostic'' way, without considering the forthcoming downstream tasks. This offers an advantage of broad applicability across tasks, but can also lead to a mismatch between task objectives, potentially degrading performance on downstream tasks. In this paper, we introduce TST-LLM, a framework that effectively reduces this mismatch when the natural language-based description of the downstream task is given without any ground-truth labels. TST-LLM instructs the LLM to use the downstream task's description and meta-information of data to discover features relevant to the target task. These discovered features are then treated as ground-truth labels to define \"target-specific'' pre-text tasks. TST-LLM consistently outperforms contemporary baselines, such as STUNT and LFR, with win ratios of 95% and 81%, when applied to 22 benchmark tabular datasets, including binary and multi-class classification, and regression tasks",
    "checked": true,
    "id": "74eee20f8b512f505d38d1bf73decd32b4fcd9ca",
    "semantic_title": "llm-guided self-supervised tabular learning with task-specific pre-text tasks",
    "citation_count": 0,
    "authors": [
      "Sungwon Han",
      "Seungeon Lee",
      "Meeyoung Cha",
      "Sercan O Arik",
      "Jinsung Yoon"
    ]
  },
  "https://openreview.net/forum?id=9aiuB3kIjd": {
    "title": "FragFormer: A Fragment-based Representation Learning Framework for Molecular Property Prediction",
    "volume": "main",
    "abstract": "Molecular representation learning is central to molecular property prediction, which is a vital component in drug discovery. Existing methods, which mainly focus on the atom-level molecular graphs, often find it challenging to directly model the relation between fragment (substructure) and function of molecules, largely due to insufficient fragment priors. In this work, we propose a molecular self-supervised learning framework \\textbf{FragFormer}, which aims to learn the representation of fragments and their contextual relationships. Given the prior that an atom can be part of multiple functional groups, we develop $k$-\\textbf{D}egree \\textbf{Ove}rlapping fragmentation (\\textbf{DOVE}), which generates overlapping fragment graph by employing the iterative line graph. Besides, DOVE can preserve the connection information during the fragmentation phase compared to non-overlapping fragmentation. In the pre-training stage, we design a \\textit{nested masked fragment prediction} objective, to capture the hierarchical nature of fragments, namely that larger fragments can encompass multiple smaller ones. Based on FragFormer, we introduce a simple yet efficient \\textit{fragment-level} interpretation method \\textbf{FragCAM} for the molecular property prediction results with greater accuracy. Moreover, thanks to the fragment modeling, our model is more capable of processing large molecule, such as peptides, and capturing the long-range interactions inside molecules. Our approach achieves state-of-the-art (SOTA) performance on eight out of eleven molecular property prediction datasets on PharmaBench. On long-range biological benchmark with peptide data, FragFormer can beat strong baselines by a clear margin, which shows the model's potential to generalize to larger molecules. Finally, we demonstrate that our model can effectively identify decisive fragments for prediction results on a real-world dataset\\footnote{Our code is available at \\url{https://github.com/wjxts/FragFormer/}}",
    "checked": true,
    "id": "67f3d24314df085802b78a62526afd6afe7332c9",
    "semantic_title": "fragformer: a fragment-based representation learning framework for molecular property prediction",
    "citation_count": 0,
    "authors": [
      "Jiaxi Wang",
      "Yaosen Min",
      "Miao Li",
      "Ji Wu"
    ]
  },
  "https://openreview.net/forum?id=spqbyeGyLR": {
    "title": "When resampling/reweighting improves feature learning in imbalanced classification? A toy-model study",
    "volume": "main",
    "abstract": "A toy model of binary classification is studied with the aim of clarifying the class-wise resampling/reweighting effect on the feature learning performance under the presence of class imbalance. In the analysis, a high-dimensional limit of the input space is taken while keeping the ratio of the dataset size against the input dimension finite and the non-rigorous replica method from statistical mechanics is employed. The result shows that there exists a case in which the no resampling/reweighting situation gives the best feature learning performance irrespectively of the choice of losses or classifiers, supporting recent findings in~\\citet{kang2019decoupling,cao2019learning}. It is also revealed that the key of the result is the symmetry of the loss and the problem setting. Inspired by this, we propose a further simplified model exhibiting the same property in the multiclass setting. These clarify when the class-wise resampling/reweighting becomes effective in imbalanced classification",
    "checked": false,
    "id": "f7b392ec3a91d64f448f25a61f5d143008d5d79f",
    "semantic_title": "when resampling/reweighting improves feature learning in imbalanced classification?: a toy-model study",
    "citation_count": 0,
    "authors": [
      "Tomoyuki Obuchi",
      "Toshiyuki Tanaka"
    ]
  },
  "https://openreview.net/forum?id=Gdf4P7sEzE": {
    "title": "HyperMagNet: A Magnetic Laplacian based Hypergraph Neural Network",
    "volume": "main",
    "abstract": "In data science, hypergraphs are natural models for data exhibiting multi-way or group relationships in contrast to graphs which only model pairwise relationships. Nonetheless, many proposed hypergraph neural networks effectively reduce hypergraphs to undirected graphs via symmetrized matrix representations, potentially losing important multi-way or group information. We propose an alternative approach to hypergraph neural networks in which the hypergraph is represented as a non-reversible Markov chain. We use this Markov chain to construct a complex Hermitian Laplacian matrix — the magnetic Laplacian — which serves as the input to our proposed hypergraph neural network. We study $\\textit{HyperMagNet}$ for the task of node classification, and demonstrate its effectiveness over graph-reduction based hypergraph neural networks",
    "checked": true,
    "id": "aea584bbd3cc1946df0f31654b070b3b5e5261b8",
    "semantic_title": "hypermagnet: a magnetic laplacian based hypergraph neural network",
    "citation_count": 3,
    "authors": [
      "Tatyana Benko",
      "Martin Buck",
      "Ilya Amburg",
      "Stephen J. Young",
      "Sinan Guven Aksoy"
    ]
  },
  "https://openreview.net/forum?id=TWOTKhwU5n": {
    "title": "ODEStream: A Buffer-Free Online Learning Framework with ODE-based Adaptor for Streaming Time Series Forecasting",
    "volume": "main",
    "abstract": "Addressing the challenges of irregularity and concept drift in streaming time series is crucial for real-world predictive modelling. Previous studies in time series continual learning often propose models that require buffering long sequences, potentially restricting the responsiveness of the inference system. Moreover, these models are typically designed for regularly sampled data, an unrealistic assumption in real-world scenarios. This paper introduces ODEStream, a novel buffer-free continual learning framework that incorporates a temporal isolation layer to capture temporal dependencies within the data. Simultaneously, it leverages the capability of neural ordinary differential equations to process irregular sequences and generate a continuous data representation, enabling seamless adaptation to changing dynamics in a data streaming scenario. Our approach focuses on learning how the dynamics and distribution of historical data change over time, facilitating direct processing of streaming sequences. Evaluations on benchmark real-world datasets demonstrate that ODEStream outperforms the state-of-the-art online learning and streaming analysis baseline models, providing accurate predictions over extended periods while minimising performance degradation over time by learning how the sequence dynamics change. The implementation of ODEStream is available at: \\url{https://github.com/FtoonAbushaqra/ODEStream.git}",
    "checked": true,
    "id": "cb27eb74f02cfb6861c40faba43b7e5046bba5a9",
    "semantic_title": "odestream: a buffer-free online learning framework with ode-based adaptor for streaming time series forecasting",
    "citation_count": 0,
    "authors": [
      "Futoon M. Abushaqra",
      "Hao Xue",
      "Yongli Ren",
      "Flora D. Salim"
    ]
  },
  "https://openreview.net/forum?id=n4AaKOBWbB": {
    "title": "Amphibian: A Meta-Learning Framework for Rehearsal-Free, Fast Online Continual Learning",
    "volume": "main",
    "abstract": "Online continual learning is challenging as it requires fast adaptation over a stream of data in a non-stationary environment without forgetting the knowledge acquired in the past. To address this challenge, in this paper, we introduce Amphibian - a gradient-based meta-learner that learns to scale the direction of gradient descent to achieve the desired balance between fast learning and continual learning. For this purpose, using only the current batch of data, Amphibian minimizes a meta-objective that encourages alignments of gradients among given data samples along selected basis directions in the gradient space. From this objective, it learns a diagonal scale matrix in each layer that accumulates the history of such gradient alignments. Using these scale matrices Amphibian updates the model online only in the directions having positive cumulative gradient alignments among the data observed so far. With evaluation on standard continual image classification benchmarks, we show that such meta-learned scaled gradient descent in Amphibian achieves better accuracy in online continual learning than relevant baselines while enabling fast learning with less data and few-shot knowledge transfer to new tasks. We also introduce Amphibian-$\\beta$ a unified and principled framework for analyzing and understanding the fast learning and continual learning dynamics. Additionally, with loss landscape visualizations, we show such gradient updates incur minimum loss to the old task enabling fast continual learning in Amphibian",
    "checked": true,
    "id": "9881df6ea3a242f94d3669760ba3e63b4a1cb183",
    "semantic_title": "amphibian: a meta-learning framework for rehearsal-free, fast online continual learning",
    "citation_count": 0,
    "authors": [
      "Gobinda Saha",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=qvJraN50DT": {
    "title": "Sample-efficient decoding of visual stimuli from fMRI through inter-individual functional alignment",
    "volume": "main",
    "abstract": "Deep learning is leading to major advances in the realm of brain decoding from functional Magnetic Resonance Imaging (fMRI). However, the large inter-individual variability in brain characteristics has constrained most studies to train models on one participant at a time. This limitation hampers the training of deep learning models, which typically requires very large datasets. Here, we propose to boost brain decoding of videos and static images across participants by aligning brain responses of training and left-out participants. Evaluated on a retrieval task, compared to the anatomically-aligned baseline, our method halves the median rank in out-of-subject setups. It also outperforms classical within-subject approaches when fewer than 100 minutes of data is available for the tested participant. Furthermore, we show that our alignment framework handles multiple subjects, which improves accuracy upon classical single-subject approaches. Finally, we show that this method aligns neural representations in accordance with brain anatomy. Overall, this study lays the foundations for leveraging extensive neuroimaging datasets and enhancing the decoding of individual brains when a limited amount of brain-imaging data is available",
    "checked": true,
    "id": "3fdb5ff93c2afc62736f3f93b8ef986fd64b1a92",
    "semantic_title": "sample-efficient decoding of visual stimuli from fmri through inter-individual functional alignment",
    "citation_count": 0,
    "authors": [
      "Alexis Thual",
      "Yohann Benchetrit",
      "Felix Geilert",
      "Jérémy Rapin",
      "Iurii Makarov",
      "Stanislas Dehaene",
      "Bertrand Thirion",
      "Hubert Banville",
      "Jean-Remi King"
    ]
  },
  "https://openreview.net/forum?id=16f7ea1N3p": {
    "title": "LLM-Select: Feature Selection with Large Language Models",
    "volume": "main",
    "abstract": "In this paper, we demonstrate a surprising capability of large language models (LLMs): given only input feature names and a description of a prediction task, they are capable of selecting the most predictive features, with performance rivaling the standard tools of data science. Remarkably, these models exhibit this capacity across various query mechanisms. For example, we zero-shot prompt an LLM to output a numerical importance score for a feature (e.g., ``blood pressure'') in predicting an outcome of interest (e.g., ``heart failure''), with no additional context. In particular, we find that the latest models, such as GPT-4, can consistently identify the most predictive features regardless of the query mechanism and across various prompting strategies. We illustrate these findings through extensive experiments on real-world data, where we show that LLM-based feature selection consistently achieves strong performance competitive with data-driven methods such as the LASSO, despite never having looked at the downstream training data. Our findings suggest that LLMs may be useful not only for selecting the best features for training \\textit{but also for deciding which features to collect in the first place}. This could potentially benefit practitioners in domains like healthcare and the social sciences, where collecting high-quality data comes at a high cost",
    "checked": true,
    "id": "d26e7c47e07d277a075ff765c196cfa1732a5ac2",
    "semantic_title": "llm-select: feature selection with large language models",
    "citation_count": 0,
    "authors": [
      "Daniel P Jeong",
      "Zachary Chase Lipton",
      "Pradeep Kumar Ravikumar"
    ]
  },
  "https://openreview.net/forum?id=MTrhFmkC45": {
    "title": "Reproducibility Study of \"Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation",
    "volume": "main",
    "abstract": "This paper presents a reproducibility study and extension of \"Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation.\" We validate the original findings using a range of open-weight models (1.5B-70B parameters), GPT-4, and GPT-4o Mini while introducing several novel contributions. We analyze the Pareto front of the games, propose a communication-free baseline to test whether successful negotiations are possible without agent interaction, evaluate recent small language models' performance, analyze structural information leakage in model responses, and implement an inequality metric to assess negotiation fairness. Our results demonstrate that smaller models (<10B parameters) struggle with format adherence and coherent responses, but larger open-weight models can approach proprietary model performance. Additionally, in many scenarios, single-agent approaches can achieve comparable results to multi-agent negotiations, challenging assumptions about the necessity of agent communication to perform well on the benchmark. This work also provides insights into accessibility, fairness, environmental impact, and privacy considerations of LLM-based negotiation systems",
    "checked": false,
    "id": "9cf6d9d629937ba5c1fc88fb1e0035b68870601a",
    "semantic_title": "reproducibility study of cooperation, competition, and maliciousness: llm-stakeholders interactive negotiation",
    "citation_count": 0,
    "authors": [
      "Jose L. Garcia",
      "Karolina Hajkova",
      "Maria Marchenko",
      "Carlos Miguel Patiño"
    ]
  },
  "https://openreview.net/forum?id=DVeFqV56Iz": {
    "title": "Change Point Detection in Dynamic Graphs with Decoder-only Latent Space Model",
    "volume": "main",
    "abstract": "This manuscript studies the unsupervised change point detection problem in time series of graphs using a decoder-only latent space model. The proposed framework consists of learnable prior distributions for low-dimensional graph representations and of a decoder that bridges the observed graphs and latent representations. The prior distributions of the latent spaces are learned from the observed data as empirical Bayes to assist change point detection. Specifically, the model parameters are estimated via maximum approximate likelihood, with a Group Fused Lasso regularization imposed on the prior parameters. The augmented Lagrangian is solved via Alternating Direction Method of Multipliers, and Langevin Dynamics are recruited for posterior inference. Simulation studies show good performance of the latent space model in supporting change point detection and real data experiments yield change points that align with significant events",
    "checked": true,
    "id": "fc1b8630b6cfc1a81c3c9669015a79c9a6f331bf",
    "semantic_title": "change point detection in dynamic graphs with decoder-only latent space model",
    "citation_count": 0,
    "authors": [
      "Yik Lun Kei",
      "Jialiang Li",
      "Hangjian Li",
      "Yanzhen Chen",
      "OSCAR HERNAN MADRID PADILLA"
    ]
  },
  "https://openreview.net/forum?id=OPFnpl7KiF": {
    "title": "Design Editing for Offline Model-based Optimization",
    "volume": "main",
    "abstract": "Offline model-based optimization (MBO) aims to maximize a black-box objective function using only an offline dataset of designs and scores. These tasks span various domains, such as robotics, material design, and protein and molecular engineering. A common approach involves training a surrogate model using existing designs and their corresponding scores, and then generating new designs through gradient-based updates with respect to the surrogate model. This method suffers from the out-of-distribution issue, where the surrogate model may erroneously predict high scores for unseen designs. To address this challenge, we introduce a novel method, Design Editing for Offline Model-based Optimization} (DEMO), which leverages a diffusion prior to calibrate overly optimized designs. DEMO first generates pseudo design candidates by performing gradient ascent with respect to a surrogate model. While these pseudo design candidates contain information beyond the offline dataset, they might be invalid or have erroneously high predicted scores. Therefore, to address this challenge while utilizing the information provided by pseudo design candidates, we propose an editing process to refine these pseudo design candidates. We introduce noise to the pseudo design candidates and subsequently denoise them with a diffusion prior trained on the offline dataset, ensuring they align with the distribution of valid designs. Empirical evaluations on seven offline MBO tasks show that, with properly tuned hyperparamters, DEMO's score is competitive with the best previously reported scores in the literature",
    "checked": true,
    "id": "6149eb22d397dc2af7bff916420382bfed921893",
    "semantic_title": "design editing for offline model-based optimization",
    "citation_count": 5,
    "authors": [
      "Ye Yuan",
      "Youyuan Zhang",
      "Can Chen",
      "Haolun Wu",
      "Melody Zixuan Li",
      "Jianmo Li",
      "James J. Clark",
      "Xue Liu"
    ]
  },
  "https://openreview.net/forum?id=8L3khbpUJL": {
    "title": "Referential communication in heterogeneous communities of pre-trained visual deep networks",
    "volume": "main",
    "abstract": "As large pre-trained image-processing neural networks are being embedded in autonomous agents such as self-driving cars or robots, the question arises of how such systems can communicate with each other about the surrounding world, despite their different architectures and training regimes. As a first step in this direction, we systematically explore the task of referential communication in a community of heterogeneous state-of-the-art pre-trained visual networks, showing that they can develop, in a self-supervised way, a shared protocol to refer to a target object among a set of candidates. This shared protocol can also be used, to some extent, to communicate about previously unseen object categories of different granularity. Moreover, a visual network that was not initially part of an existing community can learn the community's protocol with remarkable ease. Finally, we study, both qualitatively and quantitatively, the properties of the emergent protocol, providing some evidence that it is capturing high-level semantic features of objects",
    "checked": true,
    "id": "2516cd37eecbc2d1490af3e2eaad5d8fc50bde67",
    "semantic_title": "referential communication in heterogeneous communities of pre-trained visual deep networks",
    "citation_count": 7,
    "authors": [
      "Matéo Mahaut",
      "Roberto Dessi",
      "Francesca Franzon",
      "Marco Baroni"
    ]
  },
  "https://openreview.net/forum?id=dghM7sOudh": {
    "title": "MemLLM: Finetuning LLMs to Use Explicit Read-Write Memory",
    "volume": "main",
    "abstract": "While current large language models (LLMs) perform well on many knowledge-related tasks, they are limited by relying on their parameters as an implicit storage mechanism. As a result, they struggle with memorizing rare events and with updating their memory as facts change over time. In addition, the uninterpretable nature of parametric memory makes it challenging to prevent hallucination. Model editing and augmenting LLMs with parameters specialized for memory are only partial solutions. In this paper, we introduce MemLLM, a novel method of enhancing LLMs by integrating a structured and explicit read-and-write memory module. MemLLM tackles the aforementioned challenges by enabling dynamic interaction with the memory and improving the LLM's capabilities in using stored knowledge. Our experiments indicate that MemLLM enhances the LLM's performance and interpretability, in language modeling in general and knowledge-intensive tasks in particular. We see MemLLM as an important step towards making LLMs more grounded and factual through memory augmentation. The project repository is publicly available at: https://github.com/amodaresi/MemLLM",
    "checked": false,
    "id": "47c8f0d7232f52f1a48e933e32309dc35ad85f49",
    "semantic_title": "memllm: finetuning llms to use an explicit read-write memory",
    "citation_count": 11,
    "authors": [
      "Ali Modarressi",
      "Abdullatif Köksal",
      "Ayyoob Imani",
      "Mohsen Fayyaz",
      "Hinrich Schuetze"
    ]
  },
  "https://openreview.net/forum?id=UdcF3JbSKb": {
    "title": "Accelerating Non-Conjugate Gaussian Processes By Trading Off Computation For Uncertainty",
    "volume": "main",
    "abstract": "Non-conjugate Gaussian processes (NCGPs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in NCGPs is prohibitively expensive for large datasets, thus requiring approximations in practice. The approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. We introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for NCGPs. As we demonstrate on large-scale classification problems, our method significantly accelerates posterior inference compared to competitive baselines by trading off reduced computation for increased uncertainty",
    "checked": true,
    "id": "cbd66e7f8f2db171eb108328d1a7bd5667a8ff12",
    "semantic_title": "accelerating non-conjugate gaussian processes by trading off computation for uncertainty",
    "citation_count": 3,
    "authors": [
      "Lukas Tatzel",
      "Jonathan Wenger",
      "Frank Schneider",
      "Philipp Hennig"
    ]
  },
  "https://openreview.net/forum?id=B4SyciDyIh": {
    "title": "Optimal Embedding Guided Negative Sample Generation for Knowledge Graph Link Prediction",
    "volume": "main",
    "abstract": "Knowledge graph embedding (KGE) models encode the structural information of knowledge graphs to predicting new links. Effective training of these models requires distinguishing between positive and negative samples with high precision. Although prior research has shown that improving the quality of negative samples can significantly enhance model accuracy, identifying high-quality negative samples remains a challenging problem. This paper theoretically investigates the condition under which negative samples lead to optimal KG embedding and identifies a sufficient condition for an effective negative sample distribution. Based on this theoretical foundation, we propose \\textbf{E}mbedding \\textbf{MU}tation (\\textsc{EMU}), a novel framework that \\emph{generates} negative samples satisfying this condition, in contrast to conventional methods that focus on \\emph{identifying} challenging negative samples within the training data. Importantly, the simplicity of \\textsc{EMU} ensures seamless integration with existing KGE models and negative sampling methods. To evaluate its efficacy, we conducted comprehensive experiments across multiple datasets. The results consistently demonstrate significant improvements in link prediction performance across various KGE models and negative sampling methods. Notably, \\textsc{EMU} enables performance improvements comparable to those achieved by models with embedding dimension five times larger. An implementation of the method and experiments are available at \\url{https://github.com/nec-research/EMU-KG}",
    "checked": true,
    "id": "a18c375afa74642140215fc95ec9a3eeb0006668",
    "semantic_title": "optimal embedding guided negative sample generation for knowledge graph link prediction",
    "citation_count": 0,
    "authors": [
      "Makoto Takamoto",
      "Daniel Onoro Rubio",
      "Wiem Ben Rim",
      "Takashi Maruyama",
      "Bhushan Kotnis"
    ]
  },
  "https://openreview.net/forum?id=muWEt1TOyo": {
    "title": "SE3Set: Harnessing Equivariant Hypergraph Neural Networks for Molecular Representation Learning",
    "volume": "main",
    "abstract": "In this paper, we develop SE3Set, an SE(3) equivariant hypergraph neural network architecture tailored for advanced molecular representation learning. Hypergraphs are not merely an extension of traditional graphs; they are pivotal for modeling high-order relationships, a capability that conventional equivariant graph-based methods lack due to their inherent limitations in representing intricate many-body interactions. To achieve this, we first construct hypergraphs by proposing a new fragmentation method that considers both chemical and three-dimensional spatial information of the molecular system. We then design SE3Set, which incorporates equivariance into the hypergraph neural network. This ensures that the learned molecular representations are invariant to spatial transformations, thereby providing robustness essential for the accurate prediction of molecular properties. SE3Set has shown performance on par with state-of-the-art (SOTA) models for small molecule datasets like QM9 and MD17. It demonstrates outstanding performance on the MD22 dataset, achieving a remarkable ~20\\% improvement in accuracy across all molecules. Furthermore, on the OE62 dataset, SE3Set outperforms all short-range models. We also conducted a detailed analysis of OE62, highlighting the prevalence of complex many-body interactions in large molecules. This exceptional performance of SE3Set across diverse molecular structures underscores its transformative potential in computational chemistry, offering a route to more accurate and physically nuanced modeling. The code of this work is available at https://github.com/Navantock/SE3Set",
    "checked": true,
    "id": "0befffb1194cc1d76e8fd93ebc32e412167282b1",
    "semantic_title": "se3set: harnessing equivariant hypergraph neural networks for molecular representation learning",
    "citation_count": 2,
    "authors": [
      "Hongfei Wu",
      "Lijun Wu",
      "Guoqing Liu",
      "Zhirong Liu",
      "Bin Shao",
      "Zun Wang"
    ]
  },
  "https://openreview.net/forum?id=l4Qnj4tHBx": {
    "title": "Oblique Bayesian Additive Regression Trees",
    "volume": "main",
    "abstract": "Current implementations of Bayesian Additive Regression Trees (BART) are based on axis-aligned decision rules that recursively partition the feature space using a single feature at a time. Several authors have demonstrated that oblique trees, whose decision rules are based on linear combinations of features, can sometimes yield better predictions than axis-aligned trees and exhibit excellent theoretical properties. We develop an oblique version of BART that leverages a data-adaptive decision rule prior that recursively partitions the feature space along random hyperplanes. Using several synthetic and real-world benchmark datasets, we systematically compared our oblique BART implementation to axis-aligned BART and other tree ensemble methods, finding that oblique BART was competitive with --- and sometimes much better than --- those methods",
    "checked": true,
    "id": "5f0bcec2e82bce511c432018dd160079608e599a",
    "semantic_title": "oblique bayesian additive regression trees",
    "citation_count": 0,
    "authors": [
      "Paul-Hieu V. Nguyen",
      "Ryan Yee",
      "Sameer Deshpande"
    ]
  },
  "https://openreview.net/forum?id=FIWHRSuoos": {
    "title": "Leveraging Gradients for Unsupervised Accuracy Estimation under Distribution Shift",
    "volume": "main",
    "abstract": "Estimating the test performance of a model, possibly under distribution shift, without having access to the ground-truth labels is a challenging, yet very important problem for the safe deployment of machine learning algorithms in the wild. Existing works mostly rely on information from either the outputs or the extracted features of neural networks to estimate a score that correlates with the ground-truth test accuracy. In this paper, we investigate -- both empirically and theoretically -- how the information provided by the gradients can be predictive of the ground-truth test accuracy even under distribution shifts. More specifically, we use the norm of classification-layer gradients, backpropagated from the cross-entropy loss after only one gradient step over test data. Our intuition is that these gradients should be of higher magnitude when the model generalizes poorly. We provide the theoretical insights behind our approach and the key ingredients that ensure its empirical success. Extensive experiments conducted with various architectures on diverse distribution shifts demonstrate that our method significantly outperforms current state-of-the-art approaches. The code is available at \\url{https://github.com/Renchunzi-Xie/GdScore}",
    "checked": true,
    "id": "46a7fa6de644147ae3f1cc8ce4670a5314a82483",
    "semantic_title": "leveraging gradients for unsupervised accuracy estimation under distribution shift",
    "citation_count": 1,
    "authors": [
      "RENCHUNZI XIE",
      "Ambroise Odonnat",
      "Vasilii Feofanov",
      "Ievgen Redko",
      "Jianfeng Zhang",
      "Bo An"
    ]
  },
  "https://openreview.net/forum?id=PJUbMDkQVY": {
    "title": "Scaling Laws for Predicting Downstream Performance in LLMs",
    "volume": "main",
    "abstract": "Precise estimation of downstream performance in large language models (LLMs) prior to training is essential for guiding their development process. Scaling laws analysis utilizes the statistics of a series of significantly smaller sampling language models (LMs) to predict the performance of the target LLM. For downstream performance prediction, the critical challenge lies in the emergent abilities in LLMs that occur beyond task-specific computational thresholds. In this work, we focus on the pre-training loss as a more computation-efficient metric for performance estimation. Our two-stage approach FLP consists of first estimating a function that maps computational resources (e.g., FLOPs) to the pre-training Loss using a series of sampling models, followed by mapping the pre-training loss to downstream task Performance after the critical \"emergent phase\". In our experiments, this FLP solution accurately predicts the performance of LLMs with 7B and 13B parameters using a series of sampling LMs up to 3B, achieving error margins of 5% and 10%, respectively, and significantly outperforming the FLOPs-to-Performance approach. Further, we present FLP-M, a fundamental approach for performance prediction that addresses the practical need to integrate datasets from multiple sources during pre-training, specifically blending general corpus with code data to accurately represent the common necessity. FLP-M extends the power law analytical function to predict domain-specific pre-training loss based on FLOPs across data sources, and employs a two-layer neural network to model the non-linear relationship between multiple domain-specific loss and downstream performance. By utilizing a 3B LLM trained on a specific ratio and a series of smaller sampling LMs, FLP-M can effectively forecast the performance of 3B and 7B LLMs across various data mixtures for most benchmarks within 10% error margins",
    "checked": true,
    "id": "fa2a637f6532562a9eff1f5e9fef4438aae3f28b",
    "semantic_title": "scaling laws for predicting downstream performance in llms",
    "citation_count": 12,
    "authors": [
      "Yangyi Chen",
      "Binxuan Huang",
      "Yifan Gao",
      "Zhengyang Wang",
      "Jingfeng Yang",
      "Heng Ji"
    ]
  },
  "https://openreview.net/forum?id=c7vkDg558Z": {
    "title": "EDM-TTS: Efficient Dual-Stage Masked Modeling for Alignment-Free Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "Tokenized speech modeling has significantly advanced zero-shot text-to-speech (TTS) capabilities. The most de facto approach involves a dual-stage process: text-to-semantic (T2S) followed by semantic-to-acoustic (S2A) generation. Several auto-regressive (AR) and non-autoregressive (NAR) methods have been explored in literature for both the stages. While AR models achieve state-of-the-art performance, its token-by-token generation causes inference inefficiencies, while NAR methods while being more efficient, require explicit alignment for upsampling intermediate representations, which constrains the model's capability for more natural prosody. To overcome these issues, we propose an **E**fficient **D**ual-stage **M**asked **TTS** (EDM-TTS) model that employs an alignment-free masked generative approach for the T2S stage that overcomes the constrains of an explicit aligner, while retaining the efficiency of NAR methods. For the S2A stage, we introduce an innovative NAR approach using a novel Injection Conformer architecture, that effectively models the conditional dependence among different acoustic quantization levels, optimized by a masked language modeling objective, enabling zero-shot speech generation. Our evaluations demonstrated not only the superior inference efficiency of EDM-TTS, but also its state-of-the-art high-quality zero-shot speech quality, naturalness and speaker similarity",
    "checked": true,
    "id": "bd19fa64781ac277872c429969d39b175d014aa6",
    "semantic_title": "edm-tts: efficient dual-stage masked modeling for alignment-free text-to-speech synthesis",
    "citation_count": 1,
    "authors": [
      "Nabarun Goswami",
      "Hanqin Wang",
      "Tatsuya Harada"
    ]
  },
  "https://openreview.net/forum?id=B6y12Ot0cP": {
    "title": "Formal Verification of Graph Convolutional Networks with Uncertain Node Features and Uncertain Graph Structure",
    "volume": "main",
    "abstract": "Graph neural networks are becoming increasingly popular in the field of machine learning due to their unique ability to process data structured in graphs. They have also been applied in safety-critical environments where perturbations inherently occur. However, these perturbations require us to formally verify neural networks before their deployment in safety-critical environments as neural networks are prone to adversarial attacks. While there exists research on the formal verification of neural networks, there is no work verifying the robustness of generic graph convolutional network architectures with uncertainty in the node features and in the graph structure over multiple message-passing steps. This work addresses this research gap by explicitly preserving the non-convex dependencies of all elements in the underlying computations through reachability analysis with (matrix) polynomial zonotopes. We demonstrate our approach on three popular benchmark datasets",
    "checked": true,
    "id": "f94c8d22f66a1306595c5aa5dfe94da89dbf65b3",
    "semantic_title": "formal verification of graph convolutional networks with uncertain node features and uncertain graph structure",
    "citation_count": 0,
    "authors": [
      "Tobias Ladner",
      "Michael Eichelbeck",
      "Matthias Althoff"
    ]
  },
  "https://openreview.net/forum?id=J5IRyTKZ9s": {
    "title": "An Adversarial Perspective on Machine Unlearning for AI Safety",
    "volume": "main",
    "abstract": "Large language models are finetuned to refuse questions about hazardous knowledge, but these protections can often be bypassed. Unlearning methods aim at completely removing hazardous capabilities from models and make them inaccessible to adversaries. This work challenges the fundamental differences between unlearning and traditional safety post-training from an adversarial perspective. We demonstrate that existing jailbreak methods, previously reported as ineffective against unlearning, can be successful when applied carefully. Furthermore, we develop a variety of adaptive methods that recover most supposedly unlearned capabilities. For instance, we show that finetuning on 10 unrelated examples or removing specific directions in the activation space can recover most hazardous capabilities for models edited with RMU, a state-of-the-art unlearning method. Our findings challenge the robustness of current unlearning approaches and question their advantages over safety training",
    "checked": true,
    "id": "492f432fbfefe7ac0458c842b17acf1bd4675cb5",
    "semantic_title": "an adversarial perspective on machine unlearning for ai safety",
    "citation_count": 53,
    "authors": [
      "Jakub Łucki",
      "Boyi Wei",
      "Yangsibo Huang",
      "Peter Henderson",
      "Florian Tramèr",
      "Javier Rando"
    ]
  },
  "https://openreview.net/forum?id=GaUtrgXMHe": {
    "title": "Bayesian Transferability Assessment for Spiking Neural Networks",
    "volume": "main",
    "abstract": "Brain-inspired spiking neural networks (SNNs) attract broad interest in neuromorphic computing but suffer the problem of being difficult to optimize. Concurrently, pre-trained models (PTMs) have become a foundation for developing and applying artificial intelligence. Therefore, it is expected that pre-trained SNNs can alleviate the optimization difficulty of training from scratch. However, with a lot of PTMs available in the model hubs, effectively selecting the most appropriate PTM for a given task remains a significant challenge, often necessitating exhaustive fine-tuning and grid-searching. While several solutions to this challenge have been proposed for the mainstream artificial neural network (ANNs), aimed at developing efficient methods to assess the transferability of PTMs on target tasks, the realm of SNNs remains unexplored. The currently most used transferability assessment method for ANNs predicts transferability in a Bayesian perspective. Feature maps extracted by the PTM backbone on the target task are used to calculate the maximum model evidence as the indicator of transferability. However, ANNs and SNNs differ in architecture, rendering the existing Bayesian method incompatible with SNNs. To solve this problem, this paper introduces a novel approach to using the feature maps averaged over the time domain to calculate maximum evidence. Our proposed $\\textbf{M}$aximum $\\textbf{E}$vidence method with $\\textbf{A}$veraged $\\textbf{F}$eatures (MEAF) demonstrates effectiveness for SNNs. Additionally, the current algorithm calculates maximum evidence in an iterative way. To accelerate the selection of PTMs, an approximation method is proposed to avoid iteration in the calculation of maximum evidence, significantly reducing time consumption. It is shown through experiment that the proposed MEAF method is effective for the transferability assessment of SNNs. MEAF outperforms information theory-based assessment methods such as LEEP and NCE, which can directly adapt to SNNs on neuromorphic datasets, underscoring its potential to streamline PTM selection and application in the realm of SNNs",
    "checked": false,
    "id": "63e8662a74045cc793de52df3eda52b4e8f38eb3",
    "semantic_title": "a reliability assessment approach for a lif neurons based spiking neural network circuit",
    "citation_count": 2,
    "authors": [
      "Haiqing Hao",
      "Wenhui Wang"
    ]
  },
  "https://openreview.net/forum?id=vttqWoSJIW": {
    "title": "Relative Phase Equivariant Deep Neural Systems for Physical Layer Communications",
    "volume": "main",
    "abstract": "In the era of telecommunications, the increasing demand for complex and specialized communication systems has led to a focus on improving physical layer communications. Artificial intelligence (AI) has emerged as a promising solution avenue for doing so. Deep neural receivers have already shown significant promise in improving the performance of communications systems. However, a major challenge lies in developing deep neural receivers that match the energy efficiency and speed of traditional receivers. This work investigates the incorporation of inductive biases in the physical layer using group-equivariant deep learning to improve the parameter efficiency of deep neural receivers. We do so by constructing a deep neural receiver that is equivariant with respect to the phase of arrival. We show that the inclusion of relative phase equivariance significantly reduces the error rate of deep neural receivers at similar model sizes. Thus, we show the potential of group-equivariant deep learning in the domain of physical layer communications",
    "checked": true,
    "id": "4e0b8872853c0112e3ad87c17b4491a034ef4a92",
    "semantic_title": "relative phase equivariant deep neural systems for physical layer communications",
    "citation_count": 0,
    "authors": [
      "Arwin Gansekoele",
      "Sandjai Bhulai",
      "Mark Hoogendoorn",
      "Rob van der Mei"
    ]
  },
  "https://openreview.net/forum?id=D2PjEPGXgh": {
    "title": "Multi-Bellman operator for convergence of $Q$-learning with linear function approximation",
    "volume": "main",
    "abstract": "We investigate the convergence of $Q$-learning with linear function approximation and introduce the multi-Bellman operator, an extension of the traditional Bellman operator. By analyzing the properties of this operator, we identify conditions under which the projected multi-Bellman operator becomes a contraction, yielding stronger fixed-point guarantees compared to the original Bellman operator. Building on these insights, we propose the multi-$Q$-learning algorithm, which achieves convergence and approximates the optimal solution with arbitrary precision. This contrasts with traditional $Q$-learning, which lacks such convergence guarantees. Finally, we empirically validate our theoretical results",
    "checked": false,
    "id": "ee959afb069392c5a36831b88f9b3ddcd333647b",
    "semantic_title": "multi-bellman operator for convergence of q-learning with linear function approximation",
    "citation_count": 1,
    "authors": [
      "Diogo S. Carvalho",
      "Pedro A. Santos",
      "Francisco S. Melo"
    ]
  },
  "https://openreview.net/forum?id=laPAh2hRFC": {
    "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks",
    "volume": "main",
    "abstract": "Despite efforts to align large language models (LLMs) with human intentions, widely-used LLMs such as GPT, Llama, and Claude are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, an algorithm designed to mitigate jailbreaking attacks. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. Across a range of popular LLMs, SmoothLLM offers improved robustness against the GCG, PAIR, RandomSearch, and AmpleGCG jailbreaks. SmoothLLM is also resistant against adaptive GCG attacks, exhibits a small, though non-negligible trade-off between robustness and nominal performance, and is compatible with any LLM",
    "checked": true,
    "id": "8cf9b49698fdb1b754df2556576412a7b44929f6",
    "semantic_title": "smoothllm: defending large language models against jailbreaking attacks",
    "citation_count": 260,
    "authors": [
      "Alexander Robey",
      "Eric Wong",
      "Hamed Hassani",
      "George J. Pappas"
    ]
  },
  "https://openreview.net/forum?id=haP586YomL": {
    "title": "Reward Distance Comparisons Under Transition Sparsity",
    "volume": "main",
    "abstract": "Reward comparisons are vital for evaluating differences in agent behaviors induced by a set of reward functions. Most conventional techniques utilize the input reward functions to learn optimized policies, which are then used to compare agent behaviors. However, learning these policies can be computationally expensive and can also raise safety concerns. Direct reward comparison techniques obviate policy learning but suffer from transition sparsity, where only a small subset of transitions are sampled due to data collection challenges and feasibility constraints. Existing state-of-the-art direct reward comparison methods are ill-suited for these sparse conditions since they require high transition coverage, where the majority of transitions from a given coverage distribution are sampled. When this requirement is not satisfied, a distribution mismatch between sampled and expected transitions can occur, leading to significant errors. This paper introduces the Sparsity Resilient Reward Distance (SRRD) pseudometric, designed to eliminate the need for high transition coverage by accommodating diverse sample distributions, which are common under transition sparsity. We provide theoretical justification for SRRD's robustness and conduct experiments to demonstrate its practical efficacy across multiple domains",
    "checked": true,
    "id": "afd7357264fb5d689402dd7e74bcb0603c73c7f2",
    "semantic_title": "reward distance comparisons under transition sparsity",
    "citation_count": 0,
    "authors": [
      "Clement Nyanhongo",
      "Bruno Miranda Henrique",
      "Eugene Santos"
    ]
  },
  "https://openreview.net/forum?id=sNzBi8rZTy": {
    "title": "Reinforcement Learning for Causal Discovery without Acyclicity Constraints",
    "volume": "main",
    "abstract": "Recently, reinforcement learning (RL) has proved a promising alternative for conventional local heuristics in score-based approaches to learning directed acyclic causal graphs (DAGs) from observational data. However, the intricate acyclicity constraint still challenges the efficient exploration of the vast space of DAGs in existing methods. In this study, we introduce ALIAS (reinforced dAg Learning wIthout Acyclicity conStraints), a novel approach to causal discovery powered by the RL machinery. Our method features an efficient policy for generating DAGs in just a single step with an optimal quadratic complexity, fueled by a novel parametrization of DAGs that directly translates a continuous space to the space of all DAGs, bypassing the need for explicitly enforcing acyclicity constraints. This approach enables us to navigate the search space more effectively by utilizing policy gradient methods and established scoring functions. In addition, we provide compelling empirical evidence for the strong performance of ALIAS in comparison with state-of-the-arts in causal discovery over increasingly difficult experiment conditions on both synthetic and real datasets. Our implementation is provided at https://github.com/baosws/ALIAS",
    "checked": true,
    "id": "70073cba96d7fc4073951eb8b2c0e1b1dac22bd0",
    "semantic_title": "reinforcement learning for causal discovery without acyclicity constraints",
    "citation_count": 1,
    "authors": [
      "Bao Duong",
      "Hung Le",
      "Biwei Huang",
      "Thin Nguyen"
    ]
  },
  "https://openreview.net/forum?id=TR6iUG8i6Z": {
    "title": "Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs",
    "volume": "main",
    "abstract": "Graph Neural Network (GNN) research is rapidly advancing due to GNNs' capacity to learn distributed representations from graph-structured data. However, centralizing large volumes of real-world graph data for GNN training is often impractical due to privacy concerns, regulatory restrictions, and commercial competition. Federated learning (FL), a distributed learning paradigm, offers a solution by preserving data privacy with collaborative model training. Despite progress in training huge vision and language models, federated learning for GNNs remains underexplored. To address this challenge, we present a novel method for federated learning on GNNs based on spectral GNNs equipped with neural ordinary differential equations (ODE) for better information capture, showing promising results across both homophilic and heterophilic graphs. Our approach effectively handles non-Independent and Identically Distributed (non-IID) data, while also achieving performance comparable to existing methods that only operate on IID data. It is designed to be privacy-preserving and bandwidth-optimized, making it suitable for real-world applications such as social network analysis, recommendation systems, and fraud detection, which often involve complex, non-IID, and heterophilic graph structures. Our results in the area of federated learning on non-IID heterophilic graphs demonstrate significant improvements, while also achieving better performance on homophilic graphs. This work highlights the potential of federated learning in diverse and challenging graph settings",
    "checked": true,
    "id": "f6f60652475e8f61b129f0e3b972ba6c239bdb4b",
    "semantic_title": "federated spectral graph transformers meet neural ordinary differential equations for non-iid graphs",
    "citation_count": 0,
    "authors": [
      "Kishan Gurumurthy",
      "Himanshu Pal",
      "Charu Sharma"
    ]
  },
  "https://openreview.net/forum?id=z37LCgSIzI": {
    "title": "ResiDual Transformer Alignment with Spectral Decomposition",
    "volume": "main",
    "abstract": "When examined through the lens of their residual streams, a puzzling property emerges in transformer networks: residual contributions (e.g., attention heads) sometimes specialize in specific tasks or input attributes. In this paper, we analyze this phenomenon in vision transformers, focusing on the spectral geometry of residuals, and explore its implications for modality alignment in vision-language models. First, we link it to the intrinsically low-dimensional structure of visual head representations, zooming into their principal components and showing that they encode specialized roles across a wide variety of input data distributions. Then, we analyze the effect of head specialization in multimodal models, focusing on how improved alignment between text and specialized heads impacts zero-shot classification performance. This specialization-performance link consistently holds across diverse pre-training data, network sizes, and objectives, demonstrating a powerful new mechanism for boosting zero-shot classification through targeted alignment. Ultimately, we translate these insights into actionable terms by introducing ResiDual, a technique for spectral alignment of the residual stream. Much like panning for gold, it lets the noise from irrelevant unit principal components (i.e., attributes) wash away to amplify task-relevant ones. Remarkably, this dual perspective on modality alignment yields fine-tuning level performance on different data distributions while modelling an extremely interpretable and parameter-efficient transformation, as we extensively show on 70 pre-trained network-dataset combinations (7 models, 10 datasets)",
    "checked": true,
    "id": "2fd960af0cdeafc3d3933623e95f4a71b995b5e0",
    "semantic_title": "residual transformer alignment with spectral decomposition",
    "citation_count": 2,
    "authors": [
      "Lorenzo Basile",
      "Valentino Maiorca",
      "Luca Bortolussi",
      "Emanuele Rodolà",
      "Francesco Locatello"
    ]
  },
  "https://openreview.net/forum?id=uKZ0R4IQaO": {
    "title": "Dynamic Pricing in the Linear Valuation Model using Shape Constraints",
    "volume": "main",
    "abstract": "We propose a shape-constrained approach to dynamic pricing for censored data in the linear valuation model eliminating the need for tuning parameters commonly required by existing methods. Previous works have addressed the challenge of unknown market noise distribution $F_0$ using strategies ranging from kernel methods to reinforcement learning algorithms, such as bandit techniques and upper confidence bounds (UCB), under the assumption that $F_0$ satisfies Lipschitz (or stronger) conditions. In contrast, our method relies on isotonic regression under the weaker assumption that $F_0$ is $\\alpha$-H\\\"older continuous for some $\\alpha \\in (0,1]$, for which we derive a regret upper bound. Simulations and experiments with real-world data obtained by Welltower Inc (a major healthcare Real Estate Investment Trust) consistently demonstrate that our method attains lower empirical regret in comparison to several existing methods in the literature while offering the advantage of being tuning-parameter free",
    "checked": true,
    "id": "8e9541327a293fa72d43c2ec2f2b0e0bfb66349b",
    "semantic_title": "dynamic pricing in the linear valuation model using shape constraints",
    "citation_count": 1,
    "authors": [
      "Daniele Bracale",
      "Moulinath Banerjee",
      "Yuekai Sun",
      "Salam Turki",
      "Kevin Stoll"
    ]
  },
  "https://openreview.net/forum?id=9Xj5w4DX0t": {
    "title": "Rank Suggestion in Non-negative Matrix Factorization: Residual Sensitivity to Initial Conditions (RSIC)",
    "volume": "main",
    "abstract": "Determining the appropriate rank in Non-negative Matrix Factorization (NMF) is a critical challenge that often requires extensive parameter tuning and domain-specific knowledge. Traditional methods for rank determination focus on identifying a single optimal rank, which may not capture the complex structure inherent in real-world datasets. In this study, we introduce a novel approach called Residual Sensitivity to Intial Conditions (RSIC) that suggests potentially multiple ranks of interest by analyzing the sensitivity of the relative residuals (e.g., relative reconstruction error) to different initializations. By computing the Mean Coordinatewise Interquartile Range (MCI) of the residuals across multiple random initializations, our method identifies regions where the NMF solutions are less sensitive to initial conditions and potentially more meaningful. We evaluate RSIC on a diverse set of datasets, including single-cell gene expression data, image data, and text data, and compare it against current state-of-the-art rank determination methods. Our experiments demonstrate that RSIC effectively identifies relevant ranks consistent with the underlying structure of the data, outperforming traditional methods in scenarios where they are computationally infeasible or less accurate. This approach provides a more scalable and generalizable solution for rank determination in NMF that does not rely on domain-specific knowledge or assumptions",
    "checked": true,
    "id": "ef655348d40b0fc09f1b126af8d822476bb07f3c",
    "semantic_title": "rank suggestion in non-negative matrix factorization: residual sensitivity to initial conditions (rsic)",
    "citation_count": 0,
    "authors": [
      "Marc A. Tunnell",
      "Zachary DeBruine",
      "Erin Carrier"
    ]
  },
  "https://openreview.net/forum?id=cFmmaxkD5A": {
    "title": "Downstream Task Guided Masking Learning in Masked Autoencoders Using Multi-Level Optimization",
    "volume": "main",
    "abstract": "Masked Autoencoder (MAE) is a notable method for self-supervised pretraining in visual representation learning. It operates by randomly masking image patches and reconstructing these masked patches using the unmasked ones. A key limitation of MAE lies in its disregard for the varying informativeness of different patches, as it uniformly selects patches to mask. To overcome this, some approaches propose masking based on patch informativeness. However, these methods often do not consider the specific requirements of downstream tasks, potentially leading to suboptimal representations for these tasks. In response, we introduce the Multi-level Optimized Mask Autoencoder (MLO-MAE), a novel framework that leverages end-to-end feedback from downstream tasks to learn an optimal masking strategy during pretraining. Our experimental findings highlight MLO-MAE's significant advancements in visual representation learning. Compared to existing methods, it demonstrates remarkable improvements across diverse datasets and tasks, showcasing its adaptability and efficiency. Our code is available at https://github.com/Alexiland/MLO-MAE",
    "checked": true,
    "id": "3b8fc96f41c8ce86b2b8b3b872407e8d1644c944",
    "semantic_title": "downstream task guided masking learning in masked autoencoders using multi-level optimization",
    "citation_count": 0,
    "authors": [
      "Han Guo",
      "Ramtin Hosseini",
      "Ruiyi Zhang",
      "Sai Ashish Somayajula",
      "Ranak Roy Chowdhury",
      "Rajesh K. Gupta",
      "Pengtao Xie"
    ]
  },
  "https://openreview.net/forum?id=ntGPYNUF3t": {
    "title": "Latte: Latent Diffusion Transformer for Video Generation",
    "volume": "main",
    "abstract": "We propose Latte, a novel Latent Diffusion Transformer for video generation. Latte first extracts spatio-temporal tokens from input videos and then adopts a series of Transformer blocks to model video distribution in the latent space. In order to model a substantial number of tokens extracted from videos, four efficient variants are introduced from the perspective of decomposing the spatial and temporal dimensions of input videos. To improve the quality of generated videos, we determine the best practices of Latte through rigorous experimental analysis, including video clip patch embedding, model variants, timestep-class information injection, temporal positional embedding, and learning strategies. Our comprehensive evaluation demonstrates that Latte achieves state-of-the-art performance across four standard video generation datasets, \\textit{i.e.}, FaceForensics, SkyTimelapse, UCF101, and Taichi-HD. In addition, we extend Latte to the text-to-video generation (T2V) task, where Latte achieves results that are competitive with recent T2V models. We strongly believe that Latte provides valuable insights for future research on incorporating Transformers into diffusion models for video generation",
    "checked": true,
    "id": "e0eac8c64be3313e581c28a495bec192e7e67284",
    "semantic_title": "latte: latent diffusion transformer for video generation",
    "citation_count": 279,
    "authors": [
      "Xin Ma",
      "Yaohui Wang",
      "Xinyuan Chen",
      "Gengyun Jia",
      "Ziwei Liu",
      "Yuan-Fang Li",
      "Cunjian Chen",
      "Yu Qiao"
    ]
  },
  "https://openreview.net/forum?id=LJHVPWNnV6": {
    "title": "Graph Potential Field Neural Network for Massive Agents Group-wise Path Planning",
    "volume": "main",
    "abstract": "Multi-agent path planning is important in both multi-agent path finding and multi-agent reinforcement learning areas. However, continual group-wise multi-agent path planning that requires the agents to perform as a team to pursue high team scores instead of individually is less studied. To address this problem, we propose a novel graph potential field-based neural network (GPFNN), which models a valid potential field map for path planning. Our GPFNN unfolds the T-step iterative optimization of the potential field maps as a T-layer feedforward neural network. Thus, a deeper GPFNN leads to more precise potential field maps without the over-smoothing issue. A potential field map inherently provides a monotonic potential flow from any source node to the target nodes to construct the optimal path (w.r.t. the potential decay), equipping our GPFNN with an elegant planning ability. Moreover, we incorporate dynamically updated boundary conditions into our GPFNN to address group-wise multi-agent path planning that supports both static targets and dynamic moving targets. Empirically, experiments on three different-sized mazes (up to $1025 \\times 1025$ sized mazes) with up to 1,000 agents demonstrate the planning ability of our GPFNN to handle both static and dynamic moving targets. Experiments on extensive graph node classification tasks on six graph datasets (up to millions of nodes) demonstrate the learning ability of our GPFNN",
    "checked": true,
    "id": "b45988904c84d27db3db036367f476ecd5e78990",
    "semantic_title": "graph potential field neural network for massive agents group-wise path planning",
    "citation_count": 0,
    "authors": [
      "Yueming Lyu",
      "Xiaowei Zhou",
      "Xingrui Yu",
      "Ivor Tsang"
    ]
  },
  "https://openreview.net/forum?id=JT2KMuo2BV": {
    "title": "Rethinking Patch Dependence for Masked Autoencoders",
    "volume": "main",
    "abstract": "In this work, we examine the impact of inter-patch dependencies in the decoder of masked autoencoders (MAE) on representation learning. We decompose the decoding mechanism for masked reconstruction into self-attention between mask tokens and cross-attention between masked and visible tokens. Our findings reveal that MAE reconstructs coherent images from visible patches not through interactions between patches in the decoder but by learning a global representation within the encoder. This discovery leads us to propose a simple visual pretraining framework: cross-attention masked autoencoders (CrossMAE). This framework employs only cross-attention in the decoder to independently read out reconstructions for a small subset of masked patches from encoder outputs. This approach achieves comparable or superior performance to traditional MAE across models ranging from ViT-S to ViT-H and significantly reduces computational requirements. By its design, CrossMAE challenges the necessity of interaction between mask tokens for effective masked pretraining. Code and models are publicly available: https://crossmae.github.io/",
    "checked": true,
    "id": "e884a40f0f5c287b6165f14a14f76c3e66664c35",
    "semantic_title": "rethinking patch dependence for masked autoencoders",
    "citation_count": 16,
    "authors": [
      "Letian Fu",
      "Long Lian",
      "Renhao Wang",
      "Baifeng Shi",
      "XuDong Wang",
      "Adam Yala",
      "Trevor Darrell",
      "Alexei A Efros",
      "Ken Goldberg"
    ]
  },
  "https://openreview.net/forum?id=FkKBxp0FhR": {
    "title": "A Systematic Evaluation of the Planning and Scheduling Abilities of the Reasoning Model o1",
    "volume": "main",
    "abstract": "OpenAI claims that their recent o1 (Strawberry) model has been specifically constructed and trained to escape the normal limitations of autoregressive Large Language Models (LLMs)–making it a new kind of model: a Large Reasoning Model (LRM)–and be generally capable of tackling procedural reasoning tasks. We present the first comprehensive evaluation of these models on the fundamental tasks of planning and scheduling. Previous research attempted to use LLMs' expressive generation capabilities to solve these problems, but met with only limited success. We fill in the gaps in this literature by testing a larger suite of state-of-the-art LLMs on a set of large benchmarks, and then use this as a baseline to evaluate o1-preview and o1-mini. We see that while they can offer significant accuracy improvements over LLMs, this single metric is misleading and incomplete, as LRM queries demand large and unpredictable costs and take significant amounts of time to complete. We provide a case study demonstrating that, at those same price points, other methods of inference time scaling can do just as well. We also show that, contrary to OpenAI's injunctions, o1's performance can be improved further by embedding it in compound systems that separately, but complementarily, scale inference time further. Finally, while the paper is focused on o1, we provide similar evaluations of a more recent (and open-weight) LRM -- DeepSeek R1",
    "checked": true,
    "id": "6d123c345139523cd0a7b67c0722b6266c345b53",
    "semantic_title": "a systematic evaluation of the planning and scheduling abilities of the reasoning model o1",
    "citation_count": 2,
    "authors": [
      "Karthik Valmeekam",
      "Kaya Stechly",
      "Atharva Gundawar",
      "Subbarao Kambhampati"
    ]
  },
  "https://openreview.net/forum?id=7bIfe2I7bK": {
    "title": "Evaluating Compositional Scene Understanding in Multimodal Generative Models",
    "volume": "main",
    "abstract": "The visual world is fundamentally compositional. Visual scenes are defined by the composition of objects and their relations. Hence, it is essential for computer vision systems to reflect and exploit this compositionality to achieve robust and generalizable scene understanding. While major strides have been made toward the development of general-purpose, multimodal generative models, including both text-to-image models and multimodal vision-language models, it remains unclear whether these systems are capable of accurately generating and interpreting scenes involving the composition of multiple objects and relations. In this work, we present an evaluation of the compositional visual processing capabilities in the current generation of text-to-image (DALL-E 3) and multimodal vision-language models (GPT-4V, GPT-4o, Claude Sonnet 3.5, QWEN2-VL-72B, and InternVL2.5-38B), and compare the performance of these systems to human participants. The results suggest that these systems display some ability to solve compositional and relational tasks, showing notable improvements over the previous generation of multimodal models, but with performance nevertheless well below the level of human participants, particularly for more complex scenes involving many (>5) objects and multiple relations. These results highlight the need for further progress toward compositional understanding of visual scenes",
    "checked": true,
    "id": "670aed8dcbd20ed5f8c8228497f434e191106228",
    "semantic_title": "evaluating compositional scene understanding in multimodal generative models",
    "citation_count": 2,
    "authors": [
      "Shuhao Fu",
      "Andrew Jun Lee",
      "Yixin Anna Wang",
      "Ida Momennejad",
      "Trevor Bihl",
      "Hongjing Lu",
      "Taylor Whittington Webb"
    ]
  },
  "https://openreview.net/forum?id=3jdI0aEW3k": {
    "title": "Distributed and Secure Kernel-Based Quantum Machine Learning",
    "volume": "main",
    "abstract": "Quantum computing promises to revolutionize machine learning, offering significant efficiency gains for tasks such as clustering and distance estimation. Additionally, it provides enhanced security through fundamental principles like the measurement postulate and the no-cloning theorem, enabling secure protocols such as quantum teleportation and quantum key distribution. While advancements in secure quantum machine learning are notable, the development of secure and distributed quantum analogs of kernel-based machine learning techniques remains underexplored. In this work, we present a novel approach for securely computing three commonly used kernels: the polynomial, radial basis function (RBF), and Laplacian kernels, when data is distributed, using quantum feature maps. Our methodology formalizes a robust framework that leverages quantum teleportation to enable secure and distributed kernel learning. The proposed architecture is validated using IBM's Qiskit Aer Simulator on various public datasets",
    "checked": true,
    "id": "764cfd1d64a18a869b41942b7bc64cc518cc8799",
    "semantic_title": "distributed and secure kernel-based quantum machine learning",
    "citation_count": 0,
    "authors": [
      "Arjhun Swaminathan",
      "Mete Akgün"
    ]
  },
  "https://openreview.net/forum?id=X3gSvQjShh": {
    "title": "An Embedding is Worth a Thousand Noisy Labels",
    "volume": "main",
    "abstract": "The performance of deep neural networks scales with dataset size and label quality, rendering the efficient mitigation of low-quality data annotations crucial for building robust and cost-effective systems. Existing strategies to address label noise exhibit severe limitations due to computational complexity and application dependency. In this work, we propose WANN, a Weighted Adaptive Nearest Neighbor approach that builds on self-supervised feature representations obtained from foundation models. To guide the weighted voting scheme, we introduce a reliability score $\\eta$, which measures the likelihood of a data label being correct. WANN outperforms reference methods, including a linear layer trained with robust loss functions, on diverse datasets of varying size and under various noise types and severities. WANN also exhibits superior generalization on imbalanced data compared to both Adaptive-NNs (ANN) and fixed k-NNs. Furthermore, the proposed weighting scheme enhances supervised dimensionality reduction under noisy labels. This yields a significant boost in classification performance with 10x and 100x smaller image embeddings, minimizing latency and storage requirements. Our approach, emphasizing efficiency and explainability, emerges as a simple, robust solution to overcome inherent limitations of deep neural network training",
    "checked": true,
    "id": "614d89e5c8839291270eb8ff0ed2e9bbadf49957",
    "semantic_title": "an embedding is worth a thousand noisy labels",
    "citation_count": 0,
    "authors": [
      "Francesco Di Salvo",
      "Sebastian Doerrich",
      "Ines Rieger",
      "Christian Ledig"
    ]
  },
  "https://openreview.net/forum?id=gxUp2d4JTw": {
    "title": "LTL-Constrained Policy Optimization with Cycle Experience Replay",
    "volume": "main",
    "abstract": "Linear Temporal Logic (LTL) offers a precise means for constraining the behavior of reinforcement learning agents. However, in many settings where both satisfaction and optimality conditions are present, LTL is insufficient to capture both. Instead, LTL-constrained policy optimization, where the goal is to optimize a scalar reward under LTL constraints, is needed. This constrained optimization problem proves difficult in deep Reinforcement Learning (DRL) settings, where learned policies often ignore the LTL constraint due to the sparse nature of LTL satisfaction. To alleviate the sparsity issue, we introduce Cycle Experience Replay (CyclER), a novel reward shaping technique that exploits the underlying structure of the LTL constraint to guide a policy towards satisfaction by encouraging partial behaviors compliant with the constraint. We provide a theoretical guarantee that optimizing CyclER will achieve policies that satisfy the LTL constraint with near-optimal probability. We evaluate CyclER in three continuous control domains. Our experimental results show that optimizing CyclER in tandem with the existing scalar reward outperforms existing reward-shaping methods at finding performant LTL-satisfying policies",
    "checked": true,
    "id": "ac80c658a9e1d428734ec0848b2ad7099d8cb110",
    "semantic_title": "ltl-constrained policy optimization with cycle experience replay",
    "citation_count": 1,
    "authors": [
      "Ameesh Shah",
      "Cameron Voloshin",
      "Chenxi Yang",
      "Abhinav Verma",
      "Swarat Chaudhuri",
      "Sanjit A. Seshia"
    ]
  },
  "https://openreview.net/forum?id=I1gALvbRxj": {
    "title": "Bézier Flow: a Surface-wise Gradient Descent Method for Multi-objective Optimization",
    "volume": "main",
    "abstract": "This paper proposes a framework to construct a multi-objective optimization algorithm from a single-objective optimization algorithm by using the Bézier simplex model. Additionally, we extend the stability of optimization algorithms in the sense of Probably Approximately Correct (PAC) learning and define the PAC stability. We prove that it leads to an upper bound on the generalization error with high probability. Furthermore, we show that multi-objective optimization algorithms derived from a gradient descent-based single-objective optimization algorithm are PAC stable. We conducted numerical experiments with synthetic and real multi-objective optimization problem instances and demonstrated that our method achieved lower generalization errors than the existing multi-objective optimization algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Akiyoshi Sannai",
      "Yasunari Hikima",
      "Ken Kobayashi",
      "Akinori Tanaka",
      "Naoki Hamada"
    ]
  },
  "https://openreview.net/forum?id=SBM9yeNZz5": {
    "title": "Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning",
    "volume": "main",
    "abstract": "Meta-learning is an effective method to handle imbalanced and noisy-label learning, but it generally depends on a clean validation set. Unfortunately, this validation set has poor scalability when the number of classes increases, as traditionally these samples need to be randomly selected, manually labelled and balanced-distributed. This problem therefore has motivated the development of meta-learning methods to automatically select validation samples that are likely to have clean labels and balanced class distribution. Unfortunately, a common missing point of existing meta-learning methods for noisy label learning is the lack of consideration for data informativeness when constructing the validation set. The construction of an informative validation set requires hard samples, i.e., samples that the model has low confident prediction, but these samples are more likely to be noisy, which can degrade the meta reweighting process. Therefore, the balance between sample informativeness and cleanness is an important criteria for validation set optimization. In this paper, we propose new criteria to characterise the utility of such meta-learning validation sets, based on: 1) sample informativeness; 2) balanced class distribution; and 3) label cleanliness. We also introduce a new imbalanced noisy-label meta-learning (INOLML) algorithm that auto- matically builds a validation set by maximising such utility criteria. The proposed method shows state-of-the-art (SOTA) results compared to previous meta-learning and noisy-label learning approaches on several noisy-label learning benchmarks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hoang Anh Dung",
      "Cuong C. Nguyen",
      "Vasileios Belagiannis",
      "Thanh-Toan Do",
      "Gustavo Carneiro"
    ]
  },
  "https://openreview.net/forum?id=sSOxuUjE2o": {
    "title": "Controlled Training Data Generation with Diffusion Models",
    "volume": "main",
    "abstract": "We present a method to control a text-to-image generative model to produce training data useful for supervised learning. Unlike previous works that employ an open-loop approach via pre-defined prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system that involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model to find adversarial prompts that result in generated images that maximize the model's loss and, consequently, expose its vulnerabilities. While these adversarial prompts generate training examples curated for improving the given model, they are not curated for a specific target distribution of interest, which can be inefficient. Therefore, we introduce the second feedback mechanism that can optionally guide the generation process towards a desirable target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. The proposed closed-loop system allows us to control the training data generation for a given model and target image distribution. We evaluate on different tasks, datasets, and architectures, with different types of distribution shifts (corruptions, spurious correlations, unseen domains) and illustrate the advantages of the proposed feedback mechanisms compared to open-loop approaches",
    "checked": true,
    "id": "45f9ca4f97fadf37fb7276f26a1d35905077be49",
    "semantic_title": "controlled training data generation with diffusion models",
    "citation_count": 6,
    "authors": [
      "Teresa Yeo",
      "Andrei Atanov",
      "Harold Luc Benoit",
      "Aleksandr Alekseev",
      "Ruchira Ray",
      "Pooya Esmaeil Akhoondi",
      "Amir Zamir"
    ]
  },
  "https://openreview.net/forum?id=Okxp1W8If0": {
    "title": "(Accelerated) Noise-adaptive Stochastic Heavy-Ball Momentum",
    "volume": "main",
    "abstract": "Stochastic heavy ball momentum (SHB) is commonly used to train machine learning models, and often provides empirical improvements over stochastic gradient descent. By primarily focusing on strongly-convex quadratics, we aim to better understand the theoretical advantage of SHB and subsequently improve the method. For strongly-convex quadratics, Kidambi et al. (2018) show that SHB (with a mini-batch of size $1$) cannot attain accelerated convergence, and hence has no theoretical benefit over SGD. They conjecture that the practical gain of SHB is a by-product of using larger mini-batches. We first substantiate this claim by showing that SHB can attain an accelerated rate when the mini-batch size is larger than a threshold $b^*$ that depends on the condition number $\\kappa$. Specifically, we prove that with the same step-size and momentum parameters as in the deterministic setting, SHB with a sufficiently large mini-batch size results in an $O\\left(\\exp(-\\frac{T}{\\sqrt{\\kappa}}) + \\sigma \\right)$ convergence when measuring the distance to the optimal solution in the $\\ell_2$ norm, where $T$ is the number of iterations and $\\sigma^2$ is the variance in the stochastic gradients. We prove a lower-bound which demonstrates that a $\\kappa$ dependence in $b^*$ is necessary. To ensure convergence to the minimizer, we design a noise-adaptive multi-stage algorithm that results in an $O\\left(\\exp\\left(-\\frac{T}{\\sqrt{\\kappa}}\\right) + \\frac{\\sigma}{\\sqrt{T}}\\right)$ rate when measuring the distance to the optimal solution in the $\\ell_2$ norm. We also consider the general smooth, strongly-convex setting and propose the first noise-adaptive SHB variant that converges to the minimizer at an $O(\\exp(-\\frac{T}{\\kappa}) + \\frac{\\sigma^2}{T})$ rate when measuring the distance to the optimal solution in the squared $\\ell_2$ norm. We empirically demonstrate the effectiveness of the proposed algorithms",
    "checked": true,
    "id": "f340532ef3da3400b4310531ec549b1767bba953",
    "semantic_title": "(accelerated) noise-adaptive stochastic heavy-ball momentum",
    "citation_count": 0,
    "authors": [
      "Anh Quang Dang",
      "Reza Babanezhad Harikandeh",
      "Sharan Vaswani"
    ]
  },
  "https://openreview.net/forum?id=nWk5OtZ7ze": {
    "title": "Quantile Activation: Correcting a failure mode of traditional ML models",
    "volume": "main",
    "abstract": "Standard ML models fail to infer the context distribution and suitably adapt. For instance, the learning fails when the underlying distribution is actually a mixture of distributions with contradictory labels. Learning also fails if there is a shift between train and test distributions. Standard neural network architectures like MLPs or CNNs are not equipped to handle this. In this article, we propose a simple activation function, quantile activation (QAct), that addresses this problem without significantly increasing computational costs. The core idea is to \"adapt\" the outputs of each neuron to its context distribution. The proposed quantile activation (QAct) outputs the relative quantile position of neuron activations within their context distribution, diverging from the direct numerical outputs common in traditional networks. A specific case of the above failure mode is when there is an inherent distribution shift, i.e the test distribution differs slightly from the train distribution. We validate the proposed activation function under covariate shifts, using datasets designed to test robustness against distortions. Our results demonstrate significantly better generalisation across distortions compared to conventional classifiers and other adaptive methods, across various architectures. Although this paper presents a proof of concept, we find that this approach unexpectedly outperforms DINOv2 (small), despite DINOv2 being trained with a much larger network and dataset",
    "checked": false,
    "id": "451d57bf84f776b631fddaf05127169838e71051",
    "semantic_title": "quantile activation: correcting a failure mode of ml models",
    "citation_count": 0,
    "authors": [
      "Aditya Challa",
      "Sravan Danda",
      "Laurent Najman",
      "Snehanshu Saha"
    ]
  },
  "https://openreview.net/forum?id=hCyT4RsF27": {
    "title": "GOTHAM: Graph Class Incremental Learning Framework under Weak Supervision",
    "volume": "main",
    "abstract": "Graphs are growing rapidly and so are the number of different categories associated with it. Applications like e-commerce, healthcare, recommendation systems, and various social media platforms are rapidly moving towards graph representation of data due to their ability to capture both structural and attribute information. One crucial task in graph analysis is node classification, where unlabeled nodes are categorized into predefined classes. In practice, novel classes appear incrementally sometimes with just a few labels (seen classes) or even without any labels (unseen classes), either because they are new or haven't been explored much. Traditional methods assume abundant labeled data for training, which isn't always feasible. We investigate a broader objective: Graph Class Incremental Learning under Weak Supervision (GCL), addressing this challenge by meta-training on base classes with limited labeled instances. During the incremental streams, novel classes can have few-shot or zero-shot representation. Our proposed framework GOTHAM efficiently accommodates these unlabeled nodes by finding the closest prototype representation, serving as class representatives in the attribute space. For Text-Attributed Graphs (TAGs), our framework additionally incorporates semantic information to enhance the representation. By employing teacher-student knowledge distillation to mitigate forgetting, GOTHAM achieves promising results across various tasks. Experiments on datasets such as Cora-ML, Amazon, and OBGN-Arxiv showcase the effectiveness of our approach in handling evolving graph data under limited supervision",
    "checked": true,
    "id": "4f4b5bcb828c5e8171092c48a56780c7d2113e90",
    "semantic_title": "gotham: graph class incremental learning framework under weak supervision",
    "citation_count": 0,
    "authors": [
      "Aditya Hemant Shahane",
      "Prathosh AP",
      "Sandeep Kumar"
    ]
  },
  "https://openreview.net/forum?id=dNWaTuKV9M": {
    "title": "Bayesian Learning-driven Prototypical Contrastive Loss for Class-Incremental Learning",
    "volume": "main",
    "abstract": "The primary objective of methods in continual learning is to learn tasks in a sequential manner over time (sometimes from a stream of data), while mitigating the detrimental phenomenon of catastrophic forgetting. This paper proposes a method to learn an effective representation between previous and newly encountered class prototypes. We propose a prototypical network with a Bayesian learning-driven contrastive loss (BLCL), tailored specifically for class-incremental learning scenarios. We introduce a contrastive loss that incorporates novel classes into the latent representation by reducing intra-class and increasing inter-class distance. Our approach dynamically adapts the balance between the cross-entropy and contrastive loss functions with a Bayesian learning technique. Experimental results conducted on the CIFAR-10, CIFAR-100, and ImageNet100 datasets for image classification and images of a GNSS-based dataset for interference classification validate the efficacy of our method, showcasing its superiority over existing state-of-the-art approaches",
    "checked": true,
    "id": "655b66f54d2a9ce2f5c0e66db1fdacdad06aa9f9",
    "semantic_title": "bayesian learning-driven prototypical contrastive loss for class-incremental learning",
    "citation_count": 9,
    "authors": [
      "Nisha L. Raichur",
      "Lucas Heublein",
      "Tobias Feigl",
      "Alexander Rügamer",
      "Christopher Mutschler",
      "Felix Ott"
    ]
  },
  "https://openreview.net/forum?id=s1zfBJysbI": {
    "title": "Enhancing Temporal Consistency in Video Editing by Reconstructing Videos with 3D Gaussian Splatting",
    "volume": "main",
    "abstract": "Recent advancements in zero-shot video diffusion models have shown promise for text-driven video editing, but challenges remain in achieving high temporal consistency. To address this, we introduce Video-3DGS, a 3D Gaussian Splatting (3DGS)-based video refiner designed to enhance temporal consistency in zero-shot video editors. Our approach utilizes a two-stage 3D Gaussian optimizing process tailored for editing dynamic monocular videos. In the first stage, Video-3DGS employs an improved version of COLMAP, referred to as MC-COLMAP, which processes original videos using a Masked and Clipped approach. For each video clip, MC-COLMAP generates the point clouds for dynamic foreground objects and complex backgrounds. These point clouds are utilized to initialize two sets of 3D Gaussians (Frg-3DGS and Bkg-3DGS) aiming to represent foreground and background views. Both foreground and background views are then merged with a 2D learnable parameter map to reconstruct full views. In the second stage, we leverage the reconstruction ability developed in the first stage to impose the temporal constraints on the video diffusion model. This approach ensures the temporal consistency in the edited videos while maintaining high fidelity to the editing text prompt. We further propose a recursive and ensembled refinement by revisiting the denoising step and guidance scale used in video diffusion process with Video-3DGS. To demonstrate the efficacy of Video-3DGS on both stages, we conduct extensive experiments across two related tasks: Video Reconstruction and Video Editing. Video-3DGS trained with 3k iterations significantly improves video reconstruction quality (+3 PSNR, +7 PSNR increase) and training efficiency (×1.9, ×4.5 times faster) over NeRF-based and 3DGS-based state-of-art methods on DAVIS dataset, respectively. Moreover, it enhances video editing by ensuring temporal consistency across 58 dynamic monocular videos",
    "checked": true,
    "id": "4437854b36a71d150cda9812c2e9f337f60f457d",
    "semantic_title": "enhancing temporal consistency in video editing by reconstructing videos with 3d gaussian splatting",
    "citation_count": 1,
    "authors": [
      "Inkyu Shin",
      "Qihang Yu",
      "Xiaohui Shen",
      "In So Kweon",
      "Kuk-Jin Yoon",
      "Liang-Chieh Chen"
    ]
  },
  "https://openreview.net/forum?id=GXlsrvOGIK": {
    "title": "On Learning Representations for Tabular Data Distillation",
    "volume": "main",
    "abstract": "Dataset distillation generates a small set of information-rich instances from a large dataset, resulting in reduced storage requirements, privacy or copyright risks, and computational costs for downstream modeling, though much of the research has focused on the image data modality. We study tabular data distillation, which brings in novel challenges such as the inherent feature heterogeneity and the common use of non-differentiable learning models (such as decision tree ensembles and nearest-neighbor predictors). To mitigate these challenges, we present $\\texttt{TDColER}$, a tabular data distillation framework via column embeddings-based representation learning. To evaluate this framework, we also present a tabular data distillation benchmark, ${{\\sf \\small TDBench}}$. Based on an elaborate evaluation on ${{\\sf \\small TDBench}}$, resulting in 226,200 distilled datasets and 541,980 models trained on them, we demonstrate that $\\texttt{TDColER}$ is able to boost the distilled data quality of off-the-shelf distillation schemes by 0.5-143% across 7 different tabular learning models. All of the code used in the experiments can be found in http://github.com/inwonakng/tdbench",
    "checked": true,
    "id": "7978a8bdb10a1eadd9a3ab772d6fc8be4f961e4e",
    "semantic_title": "on learning representations for tabular data distillation",
    "citation_count": 0,
    "authors": [
      "Inwon Kang",
      "Parikshit Ram",
      "Yi Zhou",
      "Horst Samulowitz",
      "Oshani Seneviratne"
    ]
  },
  "https://openreview.net/forum?id=baZLwdphqw": {
    "title": "Stabilizing the Kumaraswamy Distribution",
    "volume": "main",
    "abstract": "Large-scale latent variable models require expressive continuous distributions that support efficient sampling and low-variance differentiation, achievable through the reparameterization trick. The Kumaraswamy (KS) distribution is both expressive and supports the reparameterization trick with a simple closed-form inverse CDF. Yet, its adoption remains limited. We identify and resolve numerical instabilities in the log-pdf, CDF, and inverse CDF, exposing issues in libraries like PyTorch and TensorFlow. We then introduce simple and scalable latent variable models to address exploration-exploitation trade-offs in contextual multi-armed bandits and facilitate uncertainty quantification for link prediction with graph neural networks. We find these models to be most performant when paired with the stable KS. Our results support the stabilized KS distribution as a core component in scalable variational models for bounded latent variables",
    "checked": true,
    "id": "aba259db543fd9c00a7884eb73efab1aa4ac6c91",
    "semantic_title": "stabilizing the kumaraswamy distribution",
    "citation_count": 0,
    "authors": [
      "Max Wasserman",
      "Gonzalo Mateos"
    ]
  },
  "https://openreview.net/forum?id=AHTz2mTlKk": {
    "title": "Empirical Bayes Trend Filtering Through a Variational Inference Framework",
    "volume": "main",
    "abstract": "This paper introduces a novel framework for Bayesian trend filtering using an empirical Bayes approach and a variational inference algorithm. Trend filtering is a nonparametric regression technique that has gained popularity for its simple formulation and local adaptability. Bayesian adaptations of trend filtering have been proposed as an alternative method, while they often rely on computationally intensive sampling-based methods for posterior inference. We propose an empirical Bayes trend filtering (EBTF) that leverages shrinkage priors, estimated through an empirical Bayes procedure by maximizing the marginal likelihood. To address the computational challenges posed by large datasets, we implement a variational inference algorithm for posterior computation, ensuring scalability and efficiency. Our framework is flexible, allowing the incorporation of various shrinkage priors, and optimizes the level of smoothness directly from the data. We also discuss alternative formulations of the EBTF model, along with their pros and cons. We demonstrate the performance of our EBTF method through comprehensive simulations and real-world data applications, highlighting its ability to maintain computational efficiency while providing accurate trend estimation",
    "checked": true,
    "id": "3a66c8a6926a4e01e26a92a15c2205d031e76b53",
    "semantic_title": "empirical bayes trend filtering through a variational inference framework",
    "citation_count": 0,
    "authors": [
      "Dongyue Xie"
    ]
  },
  "https://openreview.net/forum?id=MJOKrHqiV1": {
    "title": "Multi-Output Distributional Fairness via Post-Processing",
    "volume": "main",
    "abstract": "The post-processing approaches are becoming prominent techniques to enhance machine learning models' fairness because of their intuitiveness, low computational cost, and excellent scalability. However, most existing post-processing methods are designed for task-specific fairness measures and are limited to single-output models. In this paper, we introduce a post-processing method for multi-output models, such as the ones used for multi-task/multi-class classification and representation learning, to enhance a model's distributional parity, a task-agnostic fairness measure. Existing methods for achieving distributional parity rely on the (inverse) cumulative density function of a model's output, restricting their applicability to single-output models. Extending previous works, we propose to employ optimal transport mappings to move a model's outputs across different groups towards their empirical Wasserstein barycenter. An approximation technique is applied to reduce the complexity of computing the exact barycenter and a kernel regression method is proposed to extend this process to out-of-sample data. Our empirical studies evaluate the proposed approach against various baselines on multi-task/multi-class classification and representation learning tasks, demonstrating the effectiveness of the proposed approach",
    "checked": true,
    "id": "b5025e687cb2001e92ea2872d1e9d9db6e4179c1",
    "semantic_title": "multi-output distributional fairness via post-processing",
    "citation_count": 0,
    "authors": [
      "Gang Li",
      "Qihang Lin",
      "Ayush Ghosh",
      "Tianbao Yang"
    ]
  },
  "https://openreview.net/forum?id=uJELgNGiMW": {
    "title": "Meta-Learning to Teach Semantic Prompts for Open Domain Generalization in Vision-Language Models",
    "volume": "main",
    "abstract": "Open Domain Generalization (ODG) addresses the challenges posed by domain and category shifts between labeled training sources and unlabeled target domains. Current state-of-the-art methods struggle with the limitations of traditional CNN backbones, leading to reduced generalization and increased error rates in detecting target open samples without prior knowledge. Additionally, recent CLIP-based prompt learning approaches fail to distinguish between known and unknown classes effectively, resulting in suboptimal performance. To address these challenges, we propose MetaPrompt, which leverages the semantic strengths of the vision-language model CLIP and the ''learning-to-learn'' capabilities of Meta-Learning to achieve robust generalization across domain and category shifts. Our framework introduces three key innovations: First, we approach ODG as a multi-class classification problem that includes both known and novel categories, designing novel prompts capable of detecting unknown class samples across multiple domains. These prompts are trained using Meta-Learning with momentum updates, enabling smooth and accurate differentiation between known and unknown classes. Second, we introduce a novel domain-agnostic semantic attention-based prompt alongside domain-focused prompts to enhance robustness in classifying unknown classes across various domains. Finally, we incorporate an unsupervised contrastive loss during episodic Meta-Training, which reinforces the boundaries in the metric space between known and unknown classes, thereby enhancing ''unknown'' class awareness in the prompts. MetaPrompt has demonstrated its superiority through extensive testing on diverse datasets, excelling in both closed and open-set DG scenarios and consistently outperforming existing solutions",
    "checked": true,
    "id": "b75ff9f243a4be3714ed384946de6dc21401ff38",
    "semantic_title": "meta-learning to teach semantic prompts for open domain generalization in vision-language models",
    "citation_count": 0,
    "authors": [
      "Shirsha Bose",
      "Mainak Singha",
      "Ankit Jha",
      "Souradeep Mukhopadhyay",
      "Biplab Banerjee"
    ]
  },
  "https://openreview.net/forum?id=nay3Kvw8BD": {
    "title": "An Efficient Training Algorithm for Models with Block-wise Sparsity",
    "volume": "main",
    "abstract": "Large-scale machine learning (ML) models are increasingly being used in critical domains like education, lending, recruitment, healthcare, criminal justice, etc. However, the training, deployment, and utilization of these models demand substantial computational resources. To decrease computation and memory costs, machine learning models with sparse weight matrices are widely used in the literature. Among sparse models, those with special sparse structures (e.g., models with block-wise sparse weight matrices) fit better with the hardware accelerators and can decrease the memory and computation costs during the inference. Unfortunately, while there are several efficient training methods, none of them are designed to train a block-wise sparse model efficiently. As a result, the current methods for training block-wise sparse models start with full and dense models leading to inefficient training. In this work, we focus on training models with \\textit{block-wise sparse matrices} and propose an efficient training algorithm to decrease both computation and memory costs during training and inference. In addition, we will show that our proposed method enables us to efficiently find the right block size for the sparsity pattern during the training process. Our extensive empirical and theoretical analyses show that our algorithms can decrease the computation and memory costs significantly without a performance drop compared to baselines",
    "checked": true,
    "id": "df5f3641603273efdeedbed9052fa558c383d2b2",
    "semantic_title": "an efficient training algorithm for models with block-wise sparsity",
    "citation_count": 0,
    "authors": [
      "Ding Zhu",
      "Zhiqun Zuo",
      "Mohammad Mahdi Khalili"
    ]
  },
  "https://openreview.net/forum?id=OTwnNBxZFB": {
    "title": "Almost Sure Convergence of Stochastic Gradient Methods under Gradient Domination",
    "volume": "main",
    "abstract": "Stochastic gradient methods are among the most important algorithms in training machine learning problems. While classical assumptions such as strong convexity allow a simple analysis they are rarely satisfied in applications. In recent years, global and local gradient domination properties have shown to be a more realistic replacement of strong convexity. They were proved to hold in diverse settings such as (simple) policy gradient methods in reinforcement learning and training of deep neural networks with analytic activation functions. We prove almost sure convergence rates $f(X_n)-f^*\\in o\\big( n^{-\\frac{1}{4\\beta-1}+\\epsilon}\\big)$ of the last iterate for stochastic gradient descent (with and without momentum) under global and local $\\beta$-gradient domination assumptions. The almost sure rates get arbitrarily close to recent rates in expectation. Finally, we demonstrate how to apply our results to the training task in both supervised and reinforcement learning",
    "checked": true,
    "id": "466a489d9f21a64f331120660b6a5c8c456192cf",
    "semantic_title": "almost sure convergence of stochastic gradient methods under gradient domination",
    "citation_count": 2,
    "authors": [
      "Simon Weissmann",
      "Sara Klein",
      "Waïss Azizian",
      "Leif Döring"
    ]
  },
  "https://openreview.net/forum?id=WfAvMdwiE8": {
    "title": "Consistency-Guided Asynchronous Contrastive Tuning for Few-Shot Class-Incremental Tuning of Foundation Models",
    "volume": "main",
    "abstract": "We propose Consistency-guided Asynchronous Contrastive Tuning (CoACT), a novel method for continuously tuning foundation models to learn new classes in few-shot settings. CoACT consists of three key components: (i) asynchronous contrastive tuning, which learns new classes by including LoRA modules in the pre-trained encoder while enforcing consistency between two asynchronous encoders; (ii) controlled fine-tuning, which facilitates effective tuning of a subset of the foundation model; and (iii) consistency-guided incremental tuning, which enforces additional regularization during later sessions to reduce forgetting of the learned classes. We evaluate our proposed solution on Few-Shot Class-Incremental Learning (FSCIL) as well as a new and more challenging setup called Few-Shot Class-Incremental Tuning (FSCIT), which facilitates the continual tuning of vision foundation models to learn new classes with only a few samples per class. Unlike traditional FSCIL, FSCIT does not require a large in-distribution base session for initial fully supervised training prior to the incremental few-shot sessions. We conduct extensive evaluations across 16 diverse datasets, demonstrating the effectiveness of CoACT in both FSCIL and FSCIT setups. CoACT outperforms existing methods by up to 5.02% in FSCIL and up to 12.51% in FSCIT for individual datasets, with an average improvement of 2.47%. Furthermore, CoACT exhibits reduced forgetting and enhanced robustness in low-shot experiments. Detailed ablation and sensitivity studies highlight the contribution of each component of CoACT. We make our code publicly available at https://github.com/ShuvenduRoy/CoACT-FSCIL",
    "checked": true,
    "id": "a30c3e02307682c3274036e8be41bada4442a163",
    "semantic_title": "consistency-guided asynchronous contrastive tuning for few-shot class-incremental tuning of foundation models",
    "citation_count": 1,
    "authors": [
      "Shuvendu Roy",
      "Elham Dolatabadi",
      "Arash Afkanpour",
      "Ali Etemad"
    ]
  },
  "https://openreview.net/forum?id=heeJqQXKg7": {
    "title": "LitLLMs, LLMs for Literature Review: Are we there yet?",
    "volume": "main",
    "abstract": "Literature reviews are an essential component of scientific research, but they remain time-intensive and challenging to write, especially due to the recent influx of research papers. This paper explores the zero-shot abilities of recent Large Language Models (LLMs) in assisting with the writing of literature reviews based on an abstract. We decompose the task into two components: (1) Retrieving related works given a query abstract and (2) Writing a literature review based on the retrieved results. We analyze how effective LLMs are for both components. For retrieval, we introduce a novel two-step search strategy that first uses an LLM to extract meaningful keywords from the abstract of a paper and then retrieves potentially relevant papers by querying an external knowledge base. Additionally, we study a prompting-based re-ranking mechanism with attribution and show that re-ranking doubles the normalized recall compared to naive search methods while providing insights into the LLM's decision-making process. In the generation phase, we propose a two-step approach that first outlines a plan for the review and then executes steps in the plan to generate the actual review. To evaluate different LLM-based literature review methods, we create test sets from arXiv papers using a protocol designed for rolling use with newly released LLMs to avoid test set contamination in zero-shot evaluations. We release this evaluation protocol to promote additional research and development in this regard. Our empirical results suggest that LLMs show promising potential for writing literature reviews when the task is decomposed into smaller components of retrieval and planning. Particularly, we find that combining keyword-based and document-embedding-based search improves precision and recall during retrieval by 10% and 30%, respectively, compared to using either of the methods in isolation. Further, we demonstrate that our planning-based approach achieves higher-quality reviews by minimizing hallucinated references in the generated review by 18-26% compared to existing simpler LLM-based generation methods. Our project page including a demonstration system and toolkit can be accessed here: https://litllm.github.io",
    "checked": true,
    "id": "3bf29a0420b1042f5e0a319c27cb32d46d9cde3e",
    "semantic_title": "litllms, llms for literature review: are we there yet?",
    "citation_count": 2,
    "authors": [
      "Shubham Agarwal",
      "Gaurav Sahu",
      "Abhay Puri",
      "Issam H. Laradji",
      "Krishnamurthy Dj Dvijotham",
      "Jason Stanley",
      "Laurent Charlin",
      "Christopher Pal"
    ]
  },
  "https://openreview.net/forum?id=M62P7iOT7d": {
    "title": "DeformTime: capturing variable dependencies with deformable attention for time series forecasting",
    "volume": "main",
    "abstract": "In multivariable time series (MTS) forecasting, existing state-of-the-art deep learning approaches tend to focus on autoregressive formulations and often overlook the potential of using exogenous variables in enhancing the prediction of the target endogenous variable. To address this limitation, we present DeformTime, a neural network architecture that attempts to capture correlated temporal patterns from the input space, and hence, improve forecasting accuracy. It deploys two core operations performed by deformable attention blocks (DABs): learning dependencies across variables from different time steps (variable DAB), and preserving temporal dependencies in data from previous time steps (temporal DAB). Input data transformation is explicitly designed to enhance learning from the deformed series of information while passing through a DAB. We conduct extensive experiments on 6 MTS data sets, using previously established benchmarks as well as challenging infectious disease modelling tasks with more exogenous variables. The results demonstrate that DeformTime improves accuracy against previous competitive methods across the vast majority of MTS forecasting tasks, reducing the mean absolute error by 7.2% on average. Notably, performance gains remain consistent across longer forecasting horizons",
    "checked": true,
    "id": "6c5ad359f1ca77ebaca62cae8263c48864b786d4",
    "semantic_title": "deformtime: capturing variable dependencies with deformable attention for time series forecasting",
    "citation_count": 2,
    "authors": [
      "Yuxuan Shu",
      "Vasileios Lampos"
    ]
  },
  "https://openreview.net/forum?id=9kFlOyLwyf": {
    "title": "Latent Covariate Shift: Unlocking Partial Identifiability for Multi-Source Domain Adaptation",
    "volume": "main",
    "abstract": "Multi-source domain adaptation (MSDA) addresses the challenge of learning a label prediction function for an unlabeled target domain by leveraging both the labeled data from multiple source domains and the unlabeled data from the target domain. Conventional MSDA approaches often rely on covariate shift or conditional shift paradigms, which assume a consistent label distribution across domains. However, this assumption proves limiting in practical scenarios where label distributions do vary across domains, diminishing its applicability in real-world settings. For example, animals from different regions exhibit diverse characteristics due to varying diets and genetics. Motivated by this, we propose a novel paradigm called latent covariate shift (LCS), which introduces significantly greater variability and adaptability across domains. Notably, it provides a theoretical assurance for recovering the latent cause of the label variable, which we refer to as the latent content variable. Within this new paradigm, we present an intricate causal generative model by introducing latent noises across domains, along with a latent content variable and a latent style variable to achieve more nuanced rendering of observational data. We demonstrate that the latent content variable can be identified up to block identifiability due to its versatile yet distinct causal structure. We anchor our theoretical insights into a novel MSDA method, which learns the label distribution conditioned on the identifiable latent content variable, thereby accommodating more substantial distribution shifts. The proposed approach showcases exceptional performance and efficacy on both simulated and real-world datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Mingming Gong",
      "Biwei Huang",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ]
  },
  "https://openreview.net/forum?id=Wj8yFjIpom": {
    "title": "$f$-Divergence Policy Optimization in Fully Decentralized Cooperative MARL",
    "volume": "main",
    "abstract": "Independent learning is a straightforward solution for fully decentralized learning in cooperative multi-agent reinforcement learning (MARL). The study of independent learning has a history of decades, and the representatives, such as independent Q-learning and independent PPO, can achieve good performances on several benchmarks. However, most independent learning algorithms lack convergence guarantees or theoretical support. In this paper, we propose a general formulation of independent policy optimization, $f$-divergence policy optimization. We hope that a more general policy optimization formulation will provide deeper insights into fully decentralized learning. We demonstrate the generality of this formulation and analyze its limitations. Based on this formulation, we further propose a novel independent learning algorithm, TVPO, which theoretically guarantees convergence. Empirically, we demonstrate that TVPO outperforms state-of-the-art fully decentralized learning methods on three popular cooperative MARL benchmarks, thereby verifying the efficacy of TVPO",
    "checked": false,
    "id": "702bad3444bd87ad0c9a9d54462fab25fb657478",
    "semantic_title": "f-divergence policy optimization in fully decentralized cooperative marl",
    "citation_count": 1,
    "authors": [
      "Kefan Su",
      "Zongqing Lu"
    ]
  },
  "https://openreview.net/forum?id=vQDKYYuqWA": {
    "title": "Vision-Language Models Provide Promptable Representations for Reinforcement Learning",
    "volume": "main",
    "abstract": "Humans can quickly learn new behaviors by leveraging background world knowledge. In contrast, agents trained with reinforcement learning (RL) typically learn behaviors from scratch. We thus propose a novel approach that uses the vast amounts of general and indexable world knowledge encoded in vision-language models (VLMs) pre-trained on Internet-scale data for embodied RL. We initialize policies with VLMs by using them as promptable representations: embeddings that encode semantic features of visual observations based on the VLM's internal knowledge and reasoning capabilities, as elicited through prompts that provide task context and auxiliary information. We evaluate our approach on visually-complex, long horizon RL tasks in Minecraft and robot navigation in Habitat. We find that our policies trained on embeddings from off-the-shelf, general-purpose VLMs outperform equivalent policies trained on generic, non-promptable image embeddings. We also find our approach outperforms instruction-following methods and performs comparably to domain-specific embeddings. Finally, we show that our approach can use chain-of-thought prompting to produce representations of common-sense semantic reasoning, improving policy performance in novel scenes by 1.5 times",
    "checked": true,
    "id": "4b1278b2266ce5009e70f2efe85ccff87350de9c",
    "semantic_title": "vision-language models provide promptable representations for reinforcement learning",
    "citation_count": 27,
    "authors": [
      "William Chen",
      "Oier Mees",
      "Aviral Kumar",
      "Sergey Levine"
    ]
  },
  "https://openreview.net/forum?id=pKilnjQsb0": {
    "title": "Implicit Bias and Fast Convergence Rates for Self-attention",
    "volume": "main",
    "abstract": "We study the fundamental optimization principles of self-attention, the defining mechanism of transformers, by analyzing the implicit bias of gradient-based optimizers in training a self-attention layer with a linear decoder in binary classification. Building on prior studies in linear logistic regression, recent findings demonstrate that the key-query matrix $W_t$ from gradient-descent (GD) converges in direction towards $W_{mm}$, which maximizes the margin between optimal and non-optimal tokens across sequences. However, this convergence is local, dependent on initial conditions, only holds asymptotically as the number of iterations increases, and leaves questions about the potential benefits of adaptive step-size rules unaddressed. To bridge this gap, we first establish scenarios for which convergence is provably global. We then analyze two adaptive step-size strategies: normalized GD and Polyak step-size, demonstrating finite-time convergence rates for $W_t$ to $W_{mm}$, and quantifying the sparsification rate of the attention map. These findings not only show that these strategies can accelerate parameter convergence over standard GD in a non-convex setting but also deepen the understanding of the implicit bias in self-attention, linking it more closely to the phenomena observed in linear logistic regression despite its intricate non-convex nature",
    "checked": true,
    "id": "621fed685b47d70d2b3bf4ed6c7c7c623b5e715d",
    "semantic_title": "implicit bias and fast convergence rates for self-attention",
    "citation_count": 21,
    "authors": [
      "Bhavya Vasudeva",
      "Puneesh Deora",
      "Christos Thrampoulidis"
    ]
  },
  "https://openreview.net/forum?id=sXq3Wb3vef": {
    "title": "Decomposing The Dark Matter of Sparse Autoencoders",
    "volume": "main",
    "abstract": "Sparse autoencoders (SAEs) are a promising technique for decomposing language model activations into interpretable linear features. However, current SAEs fall short of completely explaining model performance, resulting in ``dark matter'': unexplained variance in activations. This work investigates dark matter as an object of study in its own right. Surprisingly, we find that much of SAE dark matter---about half of the error vector itself and $>90\\% $ of its norm---can be linearly predicted from the initial activation vector. Additionally, we find that the scaling behavior of SAE error norms at a per token level is remarkably predictable: larger SAEs mostly struggle to reconstruct the same contexts as smaller SAEs. We build on the linear representation hypothesis to propose models of activations that might lead to these observations, including postulating a new type of ``introduced error''; these insights imply that the part of the SAE error vector that cannot be linearly predicted (``nonlinear'' error) might be fundamentally different from the linearly predictable component. To validate this hypothesis, we empirically analyze nonlinear SAE error and show that 1) it contains fewer not yet learned features, 2) SAEs trained on it are quantitatively worse, 3) it helps predict SAE per-token scaling behavior, and 4) it is responsible for a proportional amount of the downstream increase in cross entropy loss when SAE activations are inserted into the model. Finally, we examine two methods to reduce nonlinear SAE error: inference time gradient pursuit, which leads to a very slight decrease in nonlinear error, and linear transformations from earlier layer SAE outputs, which leads to a larger reduction",
    "checked": true,
    "id": "74485409331b414368616c5acdcaced4f1b4506b",
    "semantic_title": "decomposing the dark matter of sparse autoencoders",
    "citation_count": 16,
    "authors": [
      "Joshua Engels",
      "Logan Riggs Smith",
      "Max Tegmark"
    ]
  },
  "https://openreview.net/forum?id=Mae23iEqPS": {
    "title": "Predicting sub-population specific viral evolution",
    "volume": "main",
    "abstract": "Forecasting the change in the distribution of viral variants is crucial for therapeutic design and disease surveillance. This task poses significant modeling challenges due to the sharp differences in virus distributions across sub-populations (e.g., countries) and their dynamic interactions. Existing machine learning approaches that model the variant distribution as a whole are incapable of making location-specific predictions and ignore transmissions that shape the viral landscape. In this paper, we propose a sub-population specific protein evolution model, which predicts the time-resolved distributions of viral proteins in different locations. The algorithm explicitly models the transmission rates between sub-populations and learns their interdependence from data. The change in protein distributions across all sub-populations is defined through a linear ordinary differential equation (ODE) parametrized by transmission rates. Solving this ODE yields the likelihood of a given protein occurring in particular sub-populations. Multi-year evaluation on both SARS-CoV-2 and influenza A/H3N2 demonstrates that our model outperforms baselines in accurately predicting distributions of viral proteins across continents and countries. We also find that the transmission rates learned from data are consistent with the transmission pathways discovered by retrospective phylogenetic analysis",
    "checked": true,
    "id": "9e552f28fccc526cad55a876a3b8613b6a925804",
    "semantic_title": "predicting sub-population specific viral evolution",
    "citation_count": 0,
    "authors": [
      "Wenxian Shi",
      "Menghua Wu",
      "Regina Barzilay"
    ]
  },
  "https://openreview.net/forum?id=SB7JzhDG45": {
    "title": "Simulation-based Bayesian Inference from Privacy Protected Data",
    "volume": "main",
    "abstract": "Many modern statistical analysis and machine learning applications require training models on sensitive user data. Under a formal definition of privacy protection, differentially private algorithms inject calibrated noise into the confidential data or during the data analysis process to produce privacy-protected datasets or queries. However, restricting access to only privatized data during statistical analysis makes it computationally challenging to make valid statistical inferences. In this work, we propose simulation-based inference methods from privacy-protected datasets. In addition to sequential Monte Carlo approximate Bayesian computation, we adopt neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and with ordinary linear regression models. Illustrating the privacy-utility trade-off, our experiments and analysis demonstrate the necessity and feasibility of designing valid statistical inference procedures to correct for biases introduced by the privacy-protection mechanisms",
    "checked": true,
    "id": "08cb14d5314dbe317fdb3e2b7dec0a7b7e151745",
    "semantic_title": "simulation-based bayesian inference from privacy protected data",
    "citation_count": 1,
    "authors": [
      "Yifei Xiong",
      "Nianqiao Ju",
      "Sanguo Zhang"
    ]
  },
  "https://openreview.net/forum?id=0AOUWC4ss8": {
    "title": "Illustrated Landmark Graphs for Long-horizon Policy Learning",
    "volume": "main",
    "abstract": "Applying learning-based approaches to long-horizon sequential decision-making tasks requires a human teacher to carefully craft reward functions or curate demonstrations to elicit desired behaviors. To simplify this, we first introduce an alternative form of task-specification, Illustrated Landmark Graph (ILG), that represents the task as a directed graph where each vertex corresponds to a region of the state space (a landmark), and each edge represents an easier to achieve sub-task. A landmark in the ILG is conveyed to the agent through a few illustrative examples grounded in the agent's observation space. Second, we propose ILG-Learn, a human in the loop algorithm that interleaves planning over the ILG and sub-task policy learning. ILG-Learn adaptively plans through the ILG by relying on the human teacher's feedback to estimate the success rates of learned policies. We conduct experiments on long-horizon block stacking and point maze navigation tasks, and find that our approach achieves considerably higher success rates (~ 50% improvement) compared to hierarchical reinforcement learning and imitation learning baselines. Additionally, we highlight how the flexibility of the ILG specification allows the agent to learn a sequence of sub-tasks that is better suited to its limited capabilities",
    "checked": true,
    "id": "0a653ecb7cab770a3eddf270864aabc1cc05dd47",
    "semantic_title": "illustrated landmark graphs for long-horizon policy learning",
    "citation_count": 0,
    "authors": [
      "Christopher Watson",
      "Arjun Krishna",
      "Rajeev Alur",
      "Dinesh Jayaraman"
    ]
  },
  "https://openreview.net/forum?id=Rwf31BYTAU": {
    "title": "Adaptive Incentive Design for Markov Decision Processes with Unknown Rewards",
    "volume": "main",
    "abstract": "Incentive design, also known as model design or environment design for Markov decision processes(MDPs), refers to a class of problems in which a leader can incentivize his follower by modifying the follower's reward function, in anticipation that the follower's optimal policy in the resulting MDP can be desirable for the leader's objective. In this work, we propose gradient-ascent algorithms to compute the leader's optimal incentive design, despite the lack of knowledge about the follower's reward function. First, we formulate the incentive design problem as a bi-level optimization problem and demonstrate that, by the softmax temporal consistency between the follower's policy and value function, the bi-level optimization problem can be reduced to single-level optimization, for which a gradient-based algorithm can be developed to optimize the leader's objective. We establish several key properties of incentive design in MDPs and prove the convergence of the proposed gradient-based method. Next, we show that the gradient terms can be estimated from observations of the follower's best response policy, enabling the use of a stochastic gradient-ascent algorithm to compute a locally optimal incentive design without knowing or learning the follower's reward function. Finally, we analyze the conditions under which an incentive design remains optimal for two different rewards which are policy invariant. The effectiveness of the proposed algorithm is demonstrated using a small probabilistic transition system and a stochastic gridworld",
    "checked": true,
    "id": "31c85aa0d48a8249b15876501f7c1e2105fe699a",
    "semantic_title": "adaptive incentive design for markov decision processes with unknown rewards",
    "citation_count": 0,
    "authors": [
      "Haoxiang Ma",
      "Shuo Han",
      "Ahmed Hemida",
      "Charles A kamhoua",
      "Jie Fu"
    ]
  },
  "https://openreview.net/forum?id=tUnyInYbjK": {
    "title": "Influence Learning in Complex Systems",
    "volume": "main",
    "abstract": "High sample complexity hampers the successful application of reinforcement learning methods, especially in real-world problems where simulating complex dynamics is computationally demanding. Influence-based abstraction (IBA) was proposed to mitigate this issue by breaking down the global model of large-scale distributed systems, such as traffic control problems, into small local sub-models. Each local model includes only a few state variables and a representation of the influence exerted by the external portion of the system. This approach allows converting a complex simulator into local lightweight simulators, enabling more effective applications of planning and reinforcement learning methods. However, the effectiveness of IBA critically depends on the ability to accurately approximate the influence of each local model. While there are a few examples showing promising results in benchmark problems, the question of whether this approach is feasible in more practical scenarios remains open. In this work, we take steps towards addressing this question by conducting an extensive empirical study of learning models for influence approximations in various realistic domains, and evaluating how these models generalize over long horizons. We find that learning the influence is often a manageable learning task, even for complex and large systems. Additionally, we demonstrate the efficacy of the approximation models for long-horizon problems. By using short trajectories, we can learn accurate influence approximations for much longer horizons",
    "checked": true,
    "id": "3499e4f9ed483674c9b2c2b7170f05ce8d6773a8",
    "semantic_title": "influence learning in complex systems",
    "citation_count": 0,
    "authors": [
      "Elena Congeduti",
      "Roberto Rocchetta",
      "Frans A Oliehoek"
    ]
  },
  "https://openreview.net/forum?id=t1utIThKHD": {
    "title": "An Information Theoretic Approach to Machine Unlearning",
    "volume": "main",
    "abstract": "To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. We explore unlearning from an information theoretic perspective, connecting the influence of a sample to the information gain a model receives by observing it. From this, we derive a simple but principled zero-shot unlearning method based on the geometry of the model. Our approach takes the form of minimising the gradient of a learned function with respect to a small neighbourhood around a target forget point. This induces a smoothing effect, causing forgetting by moving the boundary of the classifier. We explore the intuition behind why this approach can jointly unlearn forget samples while preserving general model performance through a series of low-dimensional experiments. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method is competitive with state-of-the-art performance under the strict constraints of zero-shot unlearning",
    "checked": true,
    "id": "385f2bdc5cb58d83dd4878cac771f6961933411d",
    "semantic_title": "an information theoretic approach to machine unlearning",
    "citation_count": 6,
    "authors": [
      "Jack Foster",
      "Kyle Fogarty",
      "Stefan Schoepf",
      "Zack Dugue",
      "Cengiz Oztireli",
      "Alexandra Brintrup"
    ]
  },
  "https://openreview.net/forum?id=JhYbGiFn3Y": {
    "title": "Emergent representations in networks trained with the Forward-Forward algorithm",
    "volume": "main",
    "abstract": "The Backpropagation algorithm has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, the recently introduced Forward-Forward algorithm replaces the forward and backward passes of Backpropagation with two forward passes. In this work, we show that the internal representations obtained by the Forward-Forward algorithm can organise into category-specific ensembles exhibiting high sparsity -- composed of a low number of active units. This situation is reminiscent of what has been observed in cortical sensory areas, where neuronal ensembles are suggested to serve as the functional building blocks for perception and action. Interestingly, while this sparse pattern does not typically arise in models trained with standard Backpropagation, it can emerge in networks trained with Backpropagation on the same objective proposed for the Forward-Forward algorithm",
    "checked": true,
    "id": "5c3de66ded77aefa17bf77d12f0130fc4a383628",
    "semantic_title": "emergent representations in networks trained with the forward-forward algorithm",
    "citation_count": 9,
    "authors": [
      "Niccolo Tosato",
      "Lorenzo Basile",
      "Emanuele Ballarin",
      "Giuseppe De Alteriis",
      "Alberto Cazzaniga",
      "Alessio ansuini"
    ]
  },
  "https://openreview.net/forum?id=ZfPbCFZQbx": {
    "title": "Robust Symbolic Regression for Dynamical System Identification",
    "volume": "main",
    "abstract": "Real-world complex systems often miss high-fidelity physical descriptions and are typically subject to partial observability. Learning the dynamics of such systems is a challenging and ubiquitous problem, encountered in diverse critical applications which require interpretability and qualitative guarantees.Our paper addresses this problem in the case of sparsely observed probability distribution flows, governed by ODEs. Specifically, we devise a {\\it white box} approach -dubbed Symbolic Distribution Flow Learner (\\texttt{SDFL})- leveraging symbolic search with a Wasserstein-based loss function, resulting in a robust model-recovery scheme which naturally lends itself to cope with partial observability. Additionally, we furnish the proposed framework with theoretical guarantees on the number of required {\\it snapshots} to achieve a certain level of fidelity in the model-discovery. We illustrate the performance of the proposed scheme on the prototypical problem of Kuramoto networks and a standard benchmark of single-cell RNA sequence trajectory data. The numerical experiments demonstrate the competitive performance of \\texttt{SDFL} in comparison to the state-of-the-art",
    "checked": true,
    "id": "23fc1e9f5b28138fa74c42690bc57cdd37ec480a",
    "semantic_title": "robust symbolic regression for dynamical system identification",
    "citation_count": 0,
    "authors": [
      "Ramzi Dakhmouche",
      "Ivan Lunati",
      "Hossein Gorji"
    ]
  },
  "https://openreview.net/forum?id=0yPWtbR3MC": {
    "title": "Show or Tell? Effectively prompting Vision-Language Models for semantic segmentation",
    "volume": "main",
    "abstract": "Large Vision-Language Models (VLMs) are increasingly being regarded as foundation models that can be instructed to solve diverse tasks by prompting, without task-specific training. We examine the seemingly obvious question: \\emph{how to effectively prompt VLMs for semantic segmentation}. To that end, we systematically evaluate the segmentation performance of several recent models guided by either text or visual prompts on the out-of-distribution MESS dataset collection. We introduce a scalable prompting scheme, \\emph{few-shot prompted semantic segmentation}, inspired by open-vocabulary segmentation and few-shot learning. It turns out that VLMs lag far behind specialist models trained for a specific segmentation task, by about 30\\% on average on the Intersection-over-Union metric. Moreover, we find that text prompts and visual prompts are complementary: each one of the two modes fails on many examples that the other one can solve. Our analysis suggests that being able to anticipate the most effective prompt modality can lead to a 11\\% improvement in performance. Motivated by our findings, we propose PromptMatcher, a remarkably simple training-free baseline that combines both text and visual prompts, achieving state-of-the-art results outperforming the best text-prompted VLM by 2.5\\%, and the top visual-prompted VLM by 3.5\\% on few-shot prompted semantic segmentation",
    "checked": true,
    "id": "b6dfc7d08361e1626bc6453fc687dfb8aa27e4c0",
    "semantic_title": "show or tell? effectively prompting vision-language models for semantic segmentation",
    "citation_count": 1,
    "authors": [
      "Niccolò Avogaro",
      "Thomas Frick",
      "Mattia Rigotti",
      "Andrea Bartezzaghi",
      "Filip Janicki",
      "A. Cristiano I. Malossi",
      "Konrad Schindler",
      "Roy Assaf"
    ]
  },
  "https://openreview.net/forum?id=gangoPXSRw": {
    "title": "Probabilistic neural operators for functional uncertainty quantification",
    "volume": "main",
    "abstract": "Neural operators aim to approximate the solution operator of a system of differential equations purely from data. They have shown immense success in modeling complex dynamical systems across various domains. However, the occurrence of uncertainties inherent in both model and data has so far rarely been taken into account\\textemdash{}a critical limitation in complex, chaotic systems such as weather forecasting. In this paper, we introduce the probabilistic neural operator (PNO), a framework for learning probability distributions over the output function space of neural operators. PNO extends neural operators with generative modeling based on strictly proper scoring rules, integrating uncertainty information directly into the training process. We provide a theoretical justification for the approach and demonstrate improved performance in quantifying uncertainty across different domains and with respect to different baselines. Furthermore, PNO requires minimal adjustment to existing architectures, shows improved performance for most probabilistic prediction tasks, and leads to well-calibrated predictive distributions and adequate uncertainty representations even for long dynamical trajectories. Implementing our approach into large-scale models for physical applications can lead to improvements in corresponding uncertainty quantification and extreme event identification, ultimately leading to a deeper understanding of the prediction of such surrogate models",
    "checked": true,
    "id": "c98c3cae4c1cf4281962822079995b5f59809a5b",
    "semantic_title": "probabilistic neural operators for functional uncertainty quantification",
    "citation_count": 1,
    "authors": [
      "Christopher Bülte",
      "Philipp Scholl",
      "Gitta Kutyniok"
    ]
  },
  "https://openreview.net/forum?id=A6tOXkkE4Z": {
    "title": "Decision-Focused Surrogate Modeling for Mixed-Integer Linear Optimization",
    "volume": "main",
    "abstract": "Mixed-integer optimization is at the core of many online decision-making systems that demand frequent updates of decisions in real time. However, due to their combinatorial nature, mixed-integer linear programs (MILPs) can be difficult to solve, rendering them often unsuitable for time-critical online applications. To address this challenge, we develop a data-driven approach for constructing surrogate optimization models in the form of linear programs (LPs) that can be solved much more efficiently than the corresponding MILPs. We train these surrogate LPs in a decision-focused manner such that for different model inputs, they achieve the same or close to the same optimal solutions as the original MILPs. One key advantage of the proposed method is that it allows the incorporation of all of the original MILP's linear constraints, which significantly increases the likelihood of obtaining feasible predicted solutions. Results from two computational case studies indicate that this decision-focused surrogate modeling approach is highly data-efficient and provides very accurate predictions of the optimal solutions. In these examples, the resulting surrogate LPs outperform state-of-the-art neural-network-based optimization proxies",
    "checked": true,
    "id": "670b6e19dae39f03a0f1c91734502f1bddaf6fbd",
    "semantic_title": "decision-focused surrogate modeling for mixed-integer linear optimization",
    "citation_count": 0,
    "authors": [
      "Shivi Dixit",
      "Rishabh Gupta",
      "Qi Zhang"
    ]
  },
  "https://openreview.net/forum?id=4ZJjr9YbBw": {
    "title": "A Vector Bernstein Inequality for Self-Normalized Martingales",
    "volume": "main",
    "abstract": "We prove a Bernstein inequality for vector-valued self-normalized martingales. We first give an alternative perspective of the corresponding sub-Gaussian bound due to Abbasi-Yadkori et al. via a PAC-Bayesian argument with Gaussian priors. By instantiating this argument to priors drawn uniformly over well-chosen ellipsoids, we obtain a Bernstein bound",
    "checked": true,
    "id": "e595a287eeca558c7e40bdd036ca4f0f95fd2f3f",
    "semantic_title": "a vector bernstein inequality for self-normalized martingales",
    "citation_count": 1,
    "authors": [
      "Ingvar Ziemann"
    ]
  },
  "https://openreview.net/forum?id=Cw2xlg0e46": {
    "title": "Long-context LLMs Struggle with Long In-context Learning",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) have made significant strides in handling long sequences. Some models like Gemini could even be capable of dealing with millions of tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their true abilities in more challenging, real-world scenarios. We introduce a benchmark (LongICLBench) for long in-context learning in extreme-label classification using six datasets with 28 to 174 classes and input lengths from 2K to 50K tokens. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct predictions. We evaluate on 15 long-context LLMs and find that they perform well on less challenging classification tasks with smaller label space and shorter demonstrations. However, they struggle with more challenging task like Discovery with 174 labels, suggesting a gap in their ability to process long, context-rich sequences. Further analysis reveals a bias towards labels presented later in the sequence and a need for improved reasoning over multiple pieces of information. Our study reveals that long context understanding and reasoning is still a challenging task for the existing LLMs. We believe LongICLBench could serve as a more realistic evaluation for the future long-context LLMs",
    "checked": true,
    "id": "2717e5c7384ec12cfd6cf9c34897c6adad3230ed",
    "semantic_title": "long-context llms struggle with long in-context learning",
    "citation_count": 193,
    "authors": [
      "Tianle Li",
      "Ge Zhang",
      "Quy Duc Do",
      "Xiang Yue",
      "Wenhu Chen"
    ]
  },
  "https://openreview.net/forum?id=d9htascfP8": {
    "title": "Meta-learning Population-based Methods for Reinforcement Learning",
    "volume": "main",
    "abstract": "Reinforcement learning (RL) algorithms are highly sensitive to their hyperparameter settings. Recently, numerous methods have been proposed to dynamically optimize these hyperparameters. One prominent approach is Population-Based Bandits (PB2), which uses time-varying Gaussian processes (GP) to dynamically optimize hyperparameters with a population of parallel agents. Despite its strong overall performance, PB2 experiences slow starts due to the GP initially lacking sufficient information. To mitigate this issue, we propose four different methods that utilize meta-data from various environments. These approaches are novel in that they adapt meta-learning methods to accommodate the time-varying setting. Among these approaches, MultiTaskPB2, which uses meta-learning for the surrogate model, stands out as the most promising approach. It outperforms PB2 and other baselines in both anytime and final performance across two RL environment families",
    "checked": true,
    "id": "1090b0bd3c8734e571b126f8403128f2d8c7d9ef",
    "semantic_title": "meta-learning population-based methods for reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Johannes Hog",
      "Raghu Rajan",
      "André Biedenkapp",
      "Noor Awad",
      "Frank Hutter",
      "Vu Nguyen"
    ]
  },
  "https://openreview.net/forum?id=kd6CfmdPfX": {
    "title": "Posterior Sampling for Reinforcement Learning on Graphs",
    "volume": "main",
    "abstract": "Many Markov Decision Processes (MDPs) exhibit structure in their state and action spaces that is not exploited. We consider the case where the structure can be modelled using a directed acyclic graph (DAG) composed of nodes and edges. In this case, each node has a state, and the state transition dynamics are influenced by the states and actions at its parent nodes. We propose an MDP framework, \\emph{Directed Acyclic Markov Decision Process} (DAMDP) that formalises this problem, and we develop algorithms to perform planning and learning. Crucially, DAMDPs retain many of the benefits of MDPs, as we can show that Dynamic Programming can find the optimal policy in known DAMDPs. We also demonstrate how to perform Reinforcement Learning in DAMDPs when the transition probabilities and the reward function are unknown. To this end, we derive a posterior sampling-based algorithm that is able to leverage the graph structure to boost learning efficiency. Moreover, we obtain a theoretical bound on the Bayesian regret for this algorithm, which directly shows the efficiency gain from considering the graph structure. We then conclude by empirically demonstrating that by harnessing the DAMDP, our algorithm outperforms traditional posterior sampling for Reinforcement Learning in both a maximum flow problem and a real-world wind farm optimisation task",
    "checked": true,
    "id": "4beb1431996c747357a408f0f0b0abf96727ce29",
    "semantic_title": "posterior sampling for reinforcement learning on graphs",
    "citation_count": 0,
    "authors": [
      "Arnaud Robert",
      "Aldo A. Faisal",
      "Ciara Pike-Burke"
    ]
  },
  "https://openreview.net/forum?id=wPHVijYksq": {
    "title": "A limitation on black-box dynamics approaches to Reinforcement Learning",
    "volume": "main",
    "abstract": "We prove a fundamental limitation on the computational efficiency of a large class of Reinforcement Learning (RL) methods. This limitation applies to model-free RL methods as well as some model-based methods, such as AlphaZero. We provide a formalism that describes this class and present a family of RL problems provably intractable for these methods. Conversely, the problems in the family can be efficiently solved by toy methods. We identify several types of algorithms proposed in the literature that can avoid our limitation, including algorithms that construct an inverse dynamics model, and planning algorithms that leverage an explicit model of the dynamics",
    "checked": true,
    "id": "f2fc4c68f9a79f512f9821625627a0fbf8c41d72",
    "semantic_title": "a limitation on black-box dynamics approaches to reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Brieuc Pinon",
      "Raphael Jungers",
      "Jean-Charles Delvenne"
    ]
  },
  "https://openreview.net/forum?id=w4nd5695sq": {
    "title": "Salsa Fresca: Angular Embeddings and Pre-Training for ML Attacks on Learning With Errors",
    "volume": "main",
    "abstract": "Learning with Errors (LWE) is a hard math problem underlying recently standardized post-quantum cryptography (PQC) systems for key exchange and digital signatures. Prior work proposed new machine learning (ML)-based attacks on LWE problems with small, sparse secrets, but these attacks require millions of LWE samples to train on and take days to recover secrets. We propose three key methods---better preprocessing, angular embeddings and model pre-training---to improve these attacks, speeding up preprocessing by $25\\times$ and improving model sample efficiency by $10\\times$. We demonstrate for the first time that pre-training improves and reduces the cost of ML attacks on LWE. Our architecture improvements enable scaling to larger-dimension LWE problems: this work is the first instance of ML attacks recovering sparse binary secrets in dimension $n=1024$, the smallest dimension used in practice for homomorphic encryption applications of LWE where sparse binary secrets are proposed, albeit for larger modulus $q$. Our ML-based approach is the only attack which has successfully recovered secrets for these parameters",
    "checked": true,
    "id": "d9e76ae6480114d81da2e9eb98f848df120be057",
    "semantic_title": "salsa fresca: angular embeddings and pre-training for ml attacks on learning with errors",
    "citation_count": 7,
    "authors": [
      "Samuel Stevens",
      "Emily Wenger",
      "Cathy Yuanchen Li",
      "Niklas Nolte",
      "Eshika Saxena",
      "Francois Charton",
      "Kristin E. Lauter"
    ]
  },
  "https://openreview.net/forum?id=xBbj46Y2fN": {
    "title": "What's Left After Distillation? How Knowledge Transfer Impacts Fairness and Bias",
    "volume": "main",
    "abstract": "Knowledge Distillation is a commonly used Deep Neural Network (DNN) compression method, which often maintains overall generalization performance. However, we show that even for balanced image classification datasets, such as CIFAR-100, Tiny ImageNet and ImageNet, as many as 41% of the classes are statistically significantly affected by distillation when comparing class-wise accuracy (i.e. class bias) between a teacher/distilled student or distilled student/non-distilled student model. Changes in class bias are not necessarily an undesirable outcome when considered outside of the context of a model's usage. Using two common fairness metrics, Demographic Parity Difference (DPD) and Equalized Odds Difference (EOD) on models trained with the CelebA, Trifeature, and HateXplain datasets, our results suggest that increasing the distillation temperature improves the distilled student model's fairness, and the distilled student fairness can even surpass the fairness of the teacher model at high temperatures. Additionally, we examine individual fairness, ensuring similar instances receive similar predictions. Our results confirm that higher temperatures also improve the distilled student model's individual fairness. This study highlights the uneven effects of distillation on certain classes and its potentially significant role in fairness, emphasizing that caution is warranted when using distilled models for sensitive application domains",
    "checked": false,
    "id": "7235f2e446d470920d2063796baeaa2f0b5e1c74",
    "semantic_title": "what is left after distillation? how knowledge transfer impacts fairness and bias",
    "citation_count": 1,
    "authors": [
      "Aida Mohammadshahi",
      "Yani Ioannou"
    ]
  },
  "https://openreview.net/forum?id=CeNNIQ8GJf": {
    "title": "Efficient Multi-Agent Cooperation Learning through Teammate Lookahead",
    "volume": "main",
    "abstract": "Cooperative Multi-Agent Reinforcement Learning (MARL) is a rapidly growing research field that has achieved outstanding results across a variety of challenging cooperation tasks. However, existing MARL algorithms typically overlook the concurrent updates of teammate agents. An agent always learns from the data that it cooperates with one set of (current) teammates, but then practices with another set of (updated) teammates. This phenomenon, termed as ``teammate delay'', leads to a discrepancy between the agent's learning objective and the actual evaluation scenario, which can degrade learning stability and efficiency. In this paper, we tackle this challenge by introducing a lookahead strategy that enables agents to learn to cooperate with predicted future teammates, allowing the explicit awareness of concurrent teammate updates. This lookahead strategy is designed to seamlessly integrate with existing policy-gradient-based MARL methods, enhancing their performance without significant modifications to their underlying structures. The extensive experiments demonstrate the effectiveness of this approach, showing that the lookahead strategy can enhance the cooperation learning efficiency and achieve superior performance over the state-of-the-art MARL algorithms",
    "checked": true,
    "id": "69b3592be220e5641eeeca96b70427615d428a93",
    "semantic_title": "efficient multi-agent cooperation learning through teammate lookahead",
    "citation_count": 1,
    "authors": [
      "Feng Chen",
      "Xinwei Chen",
      "Rong-Jun Qin",
      "Cong Guan",
      "Lei Yuan",
      "Zongzhang Zhang",
      "Yang Yu"
    ]
  },
  "https://openreview.net/forum?id=DcIW0idrg8": {
    "title": "Memory-Modular Classification: Learning to Generalize with Memory Replacement",
    "volume": "main",
    "abstract": "We propose a novel memory-modular learner for image classification that separates knowledge memorization from reasoning. Our model enables effective generalization to new classes by simply replacing the memory contents, without the need for model retraining. Unlike traditional models that encode both world knowledge and task-specific skills into their weights during training, our model stores knowledge in the external memory of web-crawled image and text data. At inference time, the model dynamically selects relevant content from the memory based on the input image, allowing it to adapt to arbitrary classes by simply replacing the memory contents. The key differentiator that our learner meta-learns to perform classification tasks with noisy web data from unseen classes, resulting in robust performance across various classification scenarios. Experimental results demonstrate the promising performance and versatility of our approach in handling diverse classification tasks, including zero-shot/few-shot classification of unseen classes, fine-grained classification, and class-incremental classification",
    "checked": true,
    "id": "04e3f0005e1c3aff8d1c9c56843bb9aaef517f3b",
    "semantic_title": "memory-modular classification: learning to generalize with memory replacement",
    "citation_count": 0,
    "authors": [
      "Dahyun Kang",
      "Ahmet Iscen",
      "Eunchan Jo",
      "Sua Choi",
      "Minsu Cho",
      "Cordelia Schmid"
    ]
  },
  "https://openreview.net/forum?id=HJbcwRbMQQ": {
    "title": "Efficient Training of Multi-task Neural Solver for Combinatorial Optimization",
    "volume": "main",
    "abstract": "Efficiently training a multi-task neural solver for various combinatorial optimization problems (COPs) has been less studied so far. Naive application of conventional multi-task learning approaches often falls short in delivering a high-quality, unified neural solver. This deficiency primarily stems from the significant computational demands and a lack of adequate consideration for the complexities inherent in COPs. In this paper, we propose a general and efficient training paradigm to deliver a unified combinarotial multi-task neural solver. To this end, we resort to the theoretical loss decomposition for multiple tasks under an encoder-decoder framework, which enables more efficient training via proper bandit task-sampling algorithms through an intra-task influence matrix. By employing theoretically grounded approximations, our method significantly enhances overall performance, regardless of whether it is within constrained training budgets, across equivalent training epochs, or in terms of generalization capabilities, when compared to conventional training schedules. On the real-world datasets of TSPLib and CVRPLib, our method also achieved the best results compared to single task learning and multi-task learning approaches. Additionally, the influence matrix provides empirical evidence supporting common practices in the field of learning to optimize, further substantiating the effectiveness of our approach. Our code is open-sourced and available at \\url{https://github.com/LOGO-CUHKSZ/MTL-COP}",
    "checked": true,
    "id": "bb3794057dac136aa9eddcc7a26af94c00cf883a",
    "semantic_title": "efficient training of multi-task neural solver for combinatorial optimization",
    "citation_count": 0,
    "authors": [
      "Chenguang Wang",
      "Zhang-Hua Fu",
      "Pinyan Lu",
      "Tianshu Yu"
    ]
  },
  "https://openreview.net/forum?id=B1q9po4LPl": {
    "title": "Uncovering Strong Lottery Tickets in Graph Transformers: A Path to Memory Efficient and Robust Graph Learning",
    "volume": "main",
    "abstract": "Graph Transformers (GTs) have recently demonstrated strong capabilities for capturing complex relationships in graph-structured data using global self-attention mechanisms. On the other hand, their high memory requirements during inference remain a challenge for practical deployment. In this study, we investigate the existence of strong lottery tickets (SLTs) — subnetworks within randomly initialized neural networks that can attain competitive accuracy without weight training — in GTs. Previous studies have explored SLTs in message-passing neural networks (MPNNs), showing that SLTs not only exist in MPNNs but also help mitigate over-smoothing problems and improve robustness. However, the potential of SLTs in GTs remains unexplored. With GTs having 4.5$\\times$ more parameters than MPNNs, SLTs hold even greater application value in this context. We find that fixed random weights with a traditional SLT search method cannot adapt to imbalances of features in GTs, leading to highly biased attention that destabilizes model performance. To overcome this issue and efficiently search for SLTs, we introduce a novel approach called Adaptive Scaling. We empirically confirm the existence of SLTs within GTs and demonstrate their versatility through extensive experiments across different GT architectures, including NodeFormer, GRIT, and GraphGPS. Our findings demonstrate that SLTs achieve comparable accuracy while reducing memory usage by 2--32$\\times$, effectively generalize to out-of-distribution data, and enhance robustness against adversarial perturbations. This work highlights that SLTs offer a resource-efficient approach to improving the scalability, efficiency, and robustness of GTs, with broad implications for applications involving graph data",
    "checked": true,
    "id": "605358e411f6dda7c52b34dec718924468bb9f94",
    "semantic_title": "uncovering strong lottery tickets in graph transformers: a path to memory efficient and robust graph learning",
    "citation_count": 0,
    "authors": [
      "Hiroaki Ito",
      "Jiale Yan",
      "Hikari Otsuka",
      "Kazushi Kawamura",
      "Masato Motomura",
      "Thiem Van Chu",
      "Daichi Fujiki"
    ]
  },
  "https://openreview.net/forum?id=MKCwO34oIq": {
    "title": "FRAP: Faithful and Realistic Text-to-Image Generation with Adaptive Prompt Weighting",
    "volume": "main",
    "abstract": "Text-to-image (T2I) diffusion models have demonstrated impressive capabilities in generating high-quality images given a text prompt. However, ensuring the prompt-image alignment remains a considerable challenge, i.e., generating images that faithfully align with the prompt's semantics. Recent works attempt to improve the faithfulness by optimizing the latent code, which potentially could cause the latent code to go out-of-distribution and thus produce unrealistic images. In this paper, we propose FRAP, a simple, yet effective approach based on adaptively adjusting the per-token prompt weights to improve prompt-image alignment and authenticity of the generated images. We design an online algorithm to adaptively update each token's weight coefficient, which is achieved by minimizing a unified objective function that encourages object presence and the binding of object-modifier pairs. Through extensive evaluations, we show FRAP generates images with significantly higher prompt-image alignment to prompts from complex datasets, while having a lower average latency compared to recent latent code optimization methods, e.g., 4 seconds faster than D&B on the COCO-Subject dataset. Furthermore, through visual comparisons and evaluation of the CLIP-IQA-Real metric, we show that FRAP not only improves prompt-image alignment but also generates more authentic images with realistic appearances. We also explore combining FRAP with prompt rewriting LLM to recover their degraded prompt-image alignment, where we observe improvements in both prompt-image alignment and image quality. We release the code at the following link: https://github.com/LiyaoJiang1998/FRAP/",
    "checked": true,
    "id": "62607e5ec6cd338f30b040a98d7eaf297a25f83c",
    "semantic_title": "frap: faithful and realistic text-to-image generation with adaptive prompt weighting",
    "citation_count": 2,
    "authors": [
      "Liyao Jiang",
      "Negar Hassanpour",
      "Mohammad Salameh",
      "Mohan Sai Singamsetti",
      "Fengyu Sun",
      "Wei Lu",
      "Di Niu"
    ]
  },
  "https://openreview.net/forum?id=4zGPT0ZwnU": {
    "title": "Theoretical Insights into Overparameterized Models in Multi-Task and Replay-Based Continual Learning",
    "volume": "main",
    "abstract": "Multi-task learning (MTL) is a machine learning paradigm that aims to improve the generalization performance of a model on multiple related tasks by training it simultaneously on those tasks. Unlike MTL, where the model has instant access to the training data of all tasks, continual learning (CL) involves adapting to new sequentially arriving tasks over time without forgetting the previously acquired knowledge. Despite the wide practical adoption of CL and MTL and extensive literature on both areas, there remains a gap in the theoretical understanding of these methods when used with overparameterized models such as deep neural networks. This paper studies the overparameterized linear models as a proxy for more complex models. We develop theoretical results describing the effect of various system parameters on the model's performance in an MTL setup. Specifically, we study the impact of model size, dataset size, and task similarity on the generalization error and knowledge transfer. Additionally, we present theoretical results to characterize the performance of replay-based CL models. Our results reveal the impact of buffer size and model capacity on the forgetting rate in a CL setup and help shed light on some of the state-of-the-art CL methods. Finally, through extensive empirical evaluations, we demonstrate that our theoretical findings are also applicable to deep neural networks, offering valuable guidance for designing MTL and CL models in practice",
    "checked": true,
    "id": "684f55d1ce1c31d8ce6f9cf97b502341024c49f5",
    "semantic_title": "theoretical insights into overparameterized models in multi-task and replay-based continual learning",
    "citation_count": 4,
    "authors": [
      "Mohammadamin Banayeeanzade",
      "Mahdi Soltanolkotabi",
      "Mohammad Rostami"
    ]
  },
  "https://openreview.net/forum?id=a6WthNFhL2": {
    "title": "FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning",
    "volume": "main",
    "abstract": "Federated Learning (FL) has emerged as a pivotal framework for the development of effective global models (global FL) or personalized models (personalized FL) across clients with heterogeneous, non-iid data distribution. A key challenge in FL is client drift, where data heterogeneity impedes the aggregation of scattered knowledge. Recent studies have tackled the client drift issue by identifying significant divergence in the last linear (classifier) layer. To mitigate this divergence, strategies such as freezing the classifier weights and aligning the feature extractor accordingly have proven effective. Although the local alignment between classifier and feature extractor has been studied as a crucial factor in FL, we observe that it may lead the model to overemphasize the observed classes and underestimate the unobserved classes within each client. Therefore, our goals are twofold: (1) improving local alignment and (2) maintaining the representation of unseen class samples, ensuring that the solution seamlessly incorporates knowledge from individual clients, thus enhancing performance in both global and personalized FL. To achieve this, we introduce a novel algorithm named FedDr+, which empowers local model alignment using dot-regression loss. FedDr+ freezes the classifier as a simplex ETF to align the features and improves aggregated global models by employing a feature distillation mechanism to retain information about unseen/missing classes. Our empirical results demonstrate that FedDr+ not only outperforms methods with a frozen classifier but also surpasses other state-of-the-art approaches, ensuring robust performance across diverse data distributions",
    "checked": true,
    "id": "78075eb3bf179e5126200e546829557629ec4544",
    "semantic_title": "feddr+: stabilizing dot-regression with global feature distillation for federated learning",
    "citation_count": 0,
    "authors": [
      "Seongyoon Kim",
      "Minchan Jeong",
      "Sungnyun Kim",
      "Sungwoo Cho",
      "Sumyeong Ahn",
      "Se-Young Yun"
    ]
  },
  "https://openreview.net/forum?id=G1p0YwrX8X": {
    "title": "Sparsified State-Space Models are Efficient Highway Networks",
    "volume": "main",
    "abstract": "State-space models (SSMs) offer a promising architecture for sequence modeling, providing an alternative to Transformers by replacing expensive self-attention with linear recurrences. In this paper, we propose a simple yet effective trick to enhance SSMs within given computational budgets by sparsifying them. Our intuition is that tokens in SSMs are highly redundant due to gradual recurrent updates, and dense recurrence operations block the delivery of past information. In particular, we observe that upper layers of SSMs tend to be more redundant as they encode global information, while lower layers encode local information. Motivated by this, we introduce Simba, a hierarchical sparsification method for SSMs based on token pruning. Simba sparsifies upper layers more than lower layers, encouraging the upper layers to behave like highways. To achieve this, we propose a novel token pruning criterion for SSMs, measuring the global impact of tokens on the final output by accumulating local recurrences. We demonstrate that Simba outperforms the baseline model, Mamba, with the same FLOPS in various natural language tasks. Moreover, we illustrate the effect of highways, showing that Simba not only enhances efficiency but also improves the information flow across long sequences. Code is available at https://github.com/woominsong/Simba",
    "checked": true,
    "id": "cfc50299a3bbc9a28c57d2bc22384237bf564df9",
    "semantic_title": "sparsified state-space models are efficient highway networks",
    "citation_count": 0,
    "authors": [
      "Woomin Song",
      "Jihoon Tack",
      "Sangwoo Mo",
      "Seunghyuk Oh",
      "Jinwoo Shin"
    ]
  },
  "https://openreview.net/forum?id=BvKYsaOVEn": {
    "title": "Removing Structured Noise using Diffusion Models",
    "volume": "main",
    "abstract": "Solving ill-posed inverse problems requires careful formulation of prior beliefs over the signals of interest and an accurate description of their manifestation into noisy measurements. Handcrafted signal priors based on e.g. sparsity are increasingly replaced by data-driven deep generative models, and several groups have recently shown that state-of-the-art score-based diffusion models yield particularly strong performance and flexibility. In this paper, we show that the powerful paradigm of posterior sampling with diffusion models can be extended to include rich, structured, noise models. To that end, we propose a joint conditional reverse diffusion process with learned scores for the noise and signal-generating distribution. We demonstrate strong performance gains across various inverse problems with structured noise, outperforming competitive baselines using normalizing flows, adversarial networks and various posterior sampling methods for diffusion models. This opens up new opportunities and relevant practical applications of diffusion modeling for inverse problems in the context of non-Gaussian measurement models",
    "checked": true,
    "id": "e81f2796c4d0d4fe29bcd0f38ad81e4e70f8bc76",
    "semantic_title": "removing structured noise using diffusion models",
    "citation_count": 2,
    "authors": [
      "Tristan Stevens",
      "Hans van Gorp",
      "Faik C Meral",
      "Junseob Shin",
      "Jason Yu",
      "Jean-luc Robert",
      "Ruud Van Sloun"
    ]
  },
  "https://openreview.net/forum?id=UaaT2fI9DC": {
    "title": "On Using Certified Training towards Empirical Robustness",
    "volume": "main",
    "abstract": "Adversarial training is arguably the most popular way to provide empirical robustness against specific adversarial examples. While variants based on multi-step attacks incur significant computational overhead, single-step variants are vulnerable to a failure mode known as catastrophic overfitting, which hinders their practical utility for large perturbations. A parallel line of work, certified training, has focused on producing networks amenable to formal guarantees of robustness against any possible attack. However, the wide gap between the best-performing empirical and certified defenses has severely limited the applicability of the latter. Inspired by recent developments in certified training, which rely on a combination of adversarial attacks with network over-approximations, and by the connections between local linearity and catastrophic overfitting, we present experimental evidence on the practical utility and limitations of using certified training towards empirical robustness. We show that, when tuned for the purpose, a recent certified training algorithm can prevent catastrophic overfitting on single-step attacks, and that it can bridge the gap to multi-step baselines under appropriate experimental settings. Finally, we present a conceptually simple regularizer for network over-approximations that can achieve similar effects while markedly reducing runtime",
    "checked": true,
    "id": "a9e7ac965872fab42f25fa6ac952818aa03bb0f9",
    "semantic_title": "on using certified training towards empirical robustness",
    "citation_count": 1,
    "authors": [
      "Alessandro De Palma",
      "Serge Durand",
      "Zakaria Chihani",
      "François Terrier",
      "Caterina Urban"
    ]
  },
  "https://openreview.net/forum?id=Nu6N69i8SB": {
    "title": "Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models",
    "volume": "main",
    "abstract": "The development of large language models (LLMs) has expanded to multi-modal systems capable of processing text, images, and speech within a unified framework. Training these models demands significantly larger datasets and computational resources compared to text-only LLMs. To address the scaling challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal transformer architecture that significantly reduces pretraining computational costs. MoT decouples non-embedding parameters of the model by modality -- including feed-forward networks, attention matrices, and layer normalization -- enabling modality-specific processing with global self-attention over the full input sequence. We evaluate MoT across multiple settings and model scales. In the Chameleon 7B setting (autoregressive text-and-image generation), MoT matches the dense baseline's performance using only 55.8% of the FLOPs. When extended to include speech, MoT reaches speech performance comparable to the dense baseline with only 37.2% of the FLOPs. In the Transfusion setting, where text and image are trained with different objectives, a 7B MoT model matches the image modality performance of the dense baseline with one third of the FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image generation metrics. System profiling further highlights MoT's practical benefits, achieving dense baseline image quality in 47.2% of the wall-clock time and text quality in 75.6% of the wall-clock time (measured on AWS p4de.24xlarge instances with NVIDIA A100 GPUs)",
    "checked": true,
    "id": "18ea06ae95cad35d3c79610d16dd2a3c9ee208a5",
    "semantic_title": "mixture-of-transformers: a sparse and scalable architecture for multi-modal foundation models",
    "citation_count": 10,
    "authors": [
      "Weixin Liang",
      "LILI YU",
      "Liang Luo",
      "Srini Iyer",
      "Ning Dong",
      "Chunting Zhou",
      "Gargi Ghosh",
      "Mike Lewis",
      "Wen-tau Yih",
      "Luke Zettlemoyer",
      "Xi Victoria Lin"
    ]
  },
  "https://openreview.net/forum?id=nMCJ8bFq4B": {
    "title": "Multiplayer Information Asymmetric Contextual Bandits",
    "volume": "main",
    "abstract": "Single-player contextual bandits are a well-studied problem in reinforcement learning that has seen applications in various fields such as advertising, healthcare, and finance. In light of the recent work on information asymmetric bandits, we propose a novel multiplayer information asymmetric contextual bandit framework where there are multiple players each with their own set of actions. At every round, they observe the same context vectors and simultaneously take an action from their own set of actions, giving rise to a joint action. However, upon taking this action the players are subjected to information asymmetry in (1) actions and/or (2) rewards. We designed an algorithm mLinUCB by modifying the classical single-player algorithm LinUCB in \\cite{chu2011contextual} to achieve the optimal regret $O(\\sqrt{T})$ when only one kind of asymmetry is present. We then propose a novel algorithm ETC that is built on explore-then-commit principles to achieve the same optimal regret when both types of asymmetry are present",
    "checked": true,
    "id": "2cc51e146691094cb41b88b79872af3c5e480122",
    "semantic_title": "multiplayer information asymmetric contextual bandits",
    "citation_count": 0,
    "authors": [
      "William Chang",
      "Yuanhao Lu"
    ]
  },
  "https://openreview.net/forum?id=pqZ6nOm3WF": {
    "title": "Relationship between Batch Size and Number of Steps Needed for Nonconvex Optimization of Stochastic Gradient Descent using Armijo-Line-Search Learning Rate",
    "volume": "main",
    "abstract": "While stochastic gradient descent (SGD) can use various learning rates, such as constant or diminishing rates, previous numerical results showed that SGD performs better than other deep-learning optimizers when it uses learning rates given by line search methods. In this paper, we perform a convergence analysis on SGD with a learning rate given by an Armijo line search for nonconvex optimization indicating that the upper bound of the expectation of the squared norm of the full gradient becomes small when the number of steps and the batch size are large. Next, we show that, for SGD with the Armijo-line-search learning rate, the number of steps needed for nonconvex optimization is a monotone decreasing convex function of the batch size; that is, the number of steps needed for nonconvex optimization decreases as the batch size increases. Furthermore, we show that the stochastic first-order oracle (SFO) complexity, which is the stochastic gradient computation cost, is a convex function of the batch size; that is, there exists a critical batch size that minimizes the SFO complexity. Finally, we provide numerical results that support our theoretical results",
    "checked": false,
    "id": "e42975390268b311e6225f32b701a7cc6135b4ae",
    "semantic_title": "relationship between batch size and number of steps needed for nonconvex optimization of stochastic gradient descent using armijo line search",
    "citation_count": 0,
    "authors": [
      "Yuki Tsukada",
      "Hideaki Iiduka"
    ]
  },
  "https://openreview.net/forum?id=OGCuDFab4b": {
    "title": "Daphne: Multi-Pass Compilation of Probabilistic Programs into Graphical Models and Neural Networks",
    "volume": "main",
    "abstract": "Daphne is a probabilistic programming system that provides an expressive syntax to denote a large, but restricted, class of probabilistic models. Programs written in the Daphne language can be compiled into a general graph data structure of a corresponding probabilistic graphical model with simple link functions that can easily be implemented in a wide range of programming environments. Alternatively Daphne can also further compile such a graphical model into understandable and vectorized PyTorch code that can be used to train neural networks for inference. The Daphne compiler is structured in a layered multi-pass compiler framework that allows independent and easy extension of the syntax by adding additional passes. It leverages extensive partial evaluation to reduce all syntax extensions to the graphical model at compile time",
    "checked": true,
    "id": "5e904805337cd6eecc54c1e5a77f607e68e2b5ed",
    "semantic_title": "daphne: multi-pass compilation of probabilistic programs into graphical models and neural networks",
    "citation_count": 0,
    "authors": [
      "Christian Dietrich Weilbach",
      "Frank Wood"
    ]
  },
  "https://openreview.net/forum?id=ELtNtkGXoK": {
    "title": "Cluster Tree for Nearest Neighbor Search",
    "volume": "main",
    "abstract": "Tree-based algorithms are an important and widely used class of algorithms for Nearest Neighbor Search (NNS) with random partition (RP) tree being arguably the most well studied. However, in spite of possessing theoretical guarantees and strong practical performance, a major drawback of the RP tree is its lack of adaptability to the input dataset. Inspired by recent theoretical and practical works for NNS, we attempt to remedy this by introducing *ClusterTree*, a new tree based algorithm. Our approach utilizes randomness as in RP trees while adapting to the underlying cluster structure of the dataset to create well-balanced and meaningful partitions. Experimental evaluations on real world datasets demonstrate improvements over RP trees and other tree based methods for NNS while maintaining efficient construction time. In addition, we show theoretically and empirically that *ClusterTree* finds partitions which are superior to those found by RP trees in preserving the cluster structure of the input dataset",
    "checked": true,
    "id": "e706a5a27815c9053f5dee5e79fff886ab6abc41",
    "semantic_title": "cluster tree for nearest neighbor search",
    "citation_count": 0,
    "authors": [
      "Dan Kushnir",
      "Sandeep Silwal"
    ]
  },
  "https://openreview.net/forum?id=UWNa9Pv6qA": {
    "title": "Neuron-based explanations of neural networks sacrifice completeness and interpretability",
    "volume": "main",
    "abstract": "High quality explanations of neural networks (NNs) should exhibit two key properties. Completeness ensures that they accurately reflect a network's function and interpretability makes them understandable to humans. Many existing methods provide explanations of individual neurons within a network. In this work we provide evidence that for AlexNet pretrained on ImageNet, neuron-based explanation methods sacrifice both completeness and interpretability compared to activation principal components. Neurons are a poor basis for AlexNet embeddings because they don't account for the distributed nature of these representations. By examining two quantitative measures of completeness and conducting a user study to measure interpretability, we show the most important principal components provide more complete and interpretable explanations than the most important neurons. Much of the activation variance may be explained by examining relatively few high-variance PCs, as opposed to studying every neuron. These principal components also strongly affect network function, and are significantly more interpretable than neurons. Our findings suggest that explanation methods for networks like AlexNet should avoid using neurons as a basis for embeddings and instead choose a basis, such as principal components, which accounts for the high dimensional and distributed nature of a network's internal representations. Interactive demo and code available at https://ndey96.github.io/neuron-explanations-sacrifice",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nolan Simran Dey",
      "Eric Taylor",
      "Alexander Wong",
      "Bryan P. Tripp",
      "Graham W. Taylor"
    ]
  },
  "https://openreview.net/forum?id=vRYt8QLKqK": {
    "title": "Building Blocks for Robust and Effective Semi-Supervised Real-World Object Detection",
    "volume": "main",
    "abstract": "Semi-supervised object detection (SSOD) based on pseudo-labeling significantly reduces dependence on large labeled datasets by effectively leveraging both labeled and unlabeled data. However, real-world applications of SSOD often face critical challenges, including class imbalance, label noise, and labeling errors. We present an in-depth analysis of SSOD under real-world conditions, uncovering causes of suboptimal pseudo-labeling and key trade-offs between label quality and quantity. Based on our findings, we propose four building blocks that can be seamlessly integrated into an SSOD framework. Rare Class Collage (RCC): a data augmentation method that enhances the representation of rare classes by creating collages of rare objects. Rare Class Focus (RCF): a stratified batch sampling strategy that ensures a more balanced representation of all classes during training. Ground Truth Label Correction (GLC): a label refinement method that identifies and corrects false, missing, and noisy ground truth labels by leveraging the consistency of teacher model predictions. Pseudo-Label Selection (PLS): a selection method for removing low-quality pseudo-labeled images, guided by a novel metric estimating the missing detection rate while accounting for class rarity. We validate our methods through comprehensive experiments on autonomous driving datasets, resulting in up to 6% increase in SSOD performance. Overall, our investigation and novel, data-centric, and broadly applicable building blocks enable robust and effective SSOD in complex, real-world scenarios. Code is available at https://mos-ks.github.io/publications",
    "checked": true,
    "id": "697452342af59669949f3f774513844426f1c8b3",
    "semantic_title": "building blocks for robust and effective semi-supervised real-world object detection",
    "citation_count": 0,
    "authors": [
      "Moussa Kassem Sbeyti",
      "Nadja Klein",
      "Azarm Nowzad",
      "Fikret Sivrikaya",
      "Sahin Albayrak"
    ]
  },
  "https://openreview.net/forum?id=msI02LXVJX": {
    "title": "Compositionality in Time Series: A Proof of Concept using Symbolic Dynamics and Compositional Data Augmentation",
    "volume": "main",
    "abstract": "This work investigates whether time series of natural phenomena can be understood as being generated by sequences of latent states which are ordered in systematic and regular ways. We focus on clinical time series and ask whether clinical measurements can be interpreted as being generated by meaningful physiological states whose succession follows systematic principles. Uncovering the underlying compositional structure will allow us to create synthetic data to alleviate the notorious problem of sparse and low-resource data settings in clinical time series forecasting, and deepen our understanding of clinical data. We start by conceptualizing compositionality for time series as a property of the data generation process, and then study data-driven procedures that can reconstruct the elementary states and composition rules of this process. We evaluate the success of this methods using two empirical tests originating from a domain adaptation perspective. Both tests infer the similarity of the original time series distribution and the synthetic time series distribution from the similarity of expected risk of time series forecasting models trained and tested on original and synthesized data in specific ways. Our experimental results show that the test set performance achieved by training on compositionally synthesized data is comparable to training on original clinical time series data, and that evaluation of models on compositionally synthesized test data shows similar results to evaluating on original test data. In both experiments, performance based on compositionally synthesized data by far surpasses that based on synthetic data that were created by randomization-based data augmentation. An additional downstream evaluation of the prediction task of sequential organ failure assessment (SOFA) scores shows significant performance gains when model training is entirely based on compositionally synthesized data compared to training on original data, with improvements increasing with the size of the synthesized training set",
    "checked": true,
    "id": "19e119666dd6282d2a4639acedcec84c2a992486",
    "semantic_title": "compositionality in time series: a proof of concept using symbolic dynamics and compositional data augmentation",
    "citation_count": 0,
    "authors": [
      "Michael Hagmann",
      "Michael Staniek",
      "Stefan Riezler"
    ]
  },
  "https://openreview.net/forum?id=oAzu0gzUUb": {
    "title": "Understanding and Robustifying Sub-domain Alignment for Domain Adaptation",
    "volume": "main",
    "abstract": "In unsupervised domain adaptation (UDA), aligning source and target domains improves the predictive performance of learned models on the target domain. A common methodological improvement in alignment methods is to divide the domains and align sub-domains instead. These sub-domain-based algorithms have demonstrated great empirical success but lack theoretical support. In this work, we establish a rigorous theoretical understanding of the advantages of these methods that have the potential to enhance their overall impact on the field. Our theory uncovers that sub-domain-based methods optimize an error bound that is at least as strong as non-sub-domain-based error bounds and is empirically verified to be much stronger. Furthermore, our analysis indicates that when the marginal weights of sub-domains shift between source and target tasks, the performance of these methods may be compromised. We therefore implement an algorithm to robustify sub-domain alignment for domain adaptation under sub-domain shift, offering a valuable adaptation strategy for future sub-domain-based methods. Empirical experiments across various benchmarks validate our theoretical insights, prove the necessity for the proposed adaptation strategy, and demonstrate the algorithm's competitiveness in handling label shift",
    "checked": true,
    "id": "c54418014d008a30d9ce42cdc7d072c19b379d34",
    "semantic_title": "understanding and robustifying sub-domain alignment for domain adaptation",
    "citation_count": 0,
    "authors": [
      "Yiling Liu",
      "Juncheng Dong",
      "Ziyang Jiang",
      "Ahmed Aloui",
      "Keyu Li",
      "Michael Hunter Klein",
      "Vahid Tarokh",
      "David Carlson"
    ]
  },
  "https://openreview.net/forum?id=hDywd5AbIM": {
    "title": "SAFE-NID: Self-Attention with Normalizing-Flow Encodings for Network Intrusion Detection",
    "volume": "main",
    "abstract": "Machine learning models are increasingly adopted to monitor network traffic and detect intrusions. In this work, we introduce SAFE-NID, a novel machine learning approach for real-time packet-level traffic monitoring and intrusion detection that includes a safeguard to detect zero day attacks as out-of-distribution inputs. Unlike traditional models, which falter against zero-day attacks and concept drift, SAFE-NID leverages a lightweight encoder-only transformer architecture combined with a novel normalizing flows-based safeguard. This safeguard not only quantifies uncertainty but also identifies out-of-distribution (OOD) inputs, enabling robust performance in dynamic threat landscapes. Our generative model learns class-conditional representations of the internal features of the deep neural network. We demonstrate the effectiveness of our approach by converting publicly available network flow-level intrusion datasets into packet-level ones. We release the labeled packet-level versions of these datasets with over 50 million packets each and describe the challenges in creating these datasets. We withhold from the training data certain attack categories to simulate zero-day attacks. Existing deep learning models, which achieve an accuracy of over 99% when detecting known attacks, only correctly classify 1% of the novel attacks. Our proposed transformer architecture with normalizing flows model safeguard achieves an area under the receiver operating characteristic curve of over 0.97 in detecting these novel inputs, outperforming existing combinations of neural architectures and model safeguards. The additional latency in processing each packet by the safeguard is a small fraction of the overall inference task. This dramatic improvement in detecting zero-day attacks and distribution shifts emphasizes SAFE-NID's novelty and utility as a reliable and efficient safety monitoring tool for real-world network intrusion detection",
    "checked": true,
    "id": "70bac818c9e83d47950f52b285c09ac96a91d8aa",
    "semantic_title": "safe-nid: self-attention with normalizing-flow encodings for network intrusion detection",
    "citation_count": 0,
    "authors": [
      "Brian Matejek",
      "Ashish Gehani",
      "Nathaniel D. Bastian",
      "Daniel J Clouse",
      "Bradford J Kline",
      "Susmit Jha"
    ]
  },
  "https://openreview.net/forum?id=aPyJilTiIb": {
    "title": "A Unified View of Double-Weighting for Marginal Distribution Shift",
    "volume": "main",
    "abstract": "Supervised classification traditionally assumes that training and testing samples are drawn from the same underlying distribution. However, practical scenarios are often affected by distribution shifts, such as covariate and label shifts. Most existing techniques for correcting distribution shifts are based on a reweighted approach that weights training samples, assigning lower relevance to the samples that are unlikely at testing. However, these methods may achieve poor performance when the weights obtained take large values at certain training samples. In addition, in multi-source cases, existing methods do not exploit complementary information among sources, and equally combine sources for all instances. In this paper, we establish a unified learning framework for distribution shift adaptation. We present a double-weighting approach to deal with distribution shifts, considering weight functions associated with both training and testing samples. For the multi-source case, the presented methods assign source-dependent weights for training and testing samples, where weights are obtained jointly using information from all sources. We also present generalization bounds for the proposed methods that show a significant increase in the effective sample size compared with existing approaches. Empirically, the proposed methods achieve enhanced classification performance in both synthetic and empirical experiments",
    "checked": true,
    "id": "cd8a7cfcaa121cd540dec04e70dec80565e9fd2e",
    "semantic_title": "a unified view of double-weighting for marginal distribution shift",
    "citation_count": 0,
    "authors": [
      "José I. Segovia-Martín",
      "Santiago Mazuelas",
      "Anqi Liu"
    ]
  },
  "https://openreview.net/forum?id=qsipSdfWeV": {
    "title": "Distilling Datasets Into Less Than One Image",
    "volume": "main",
    "abstract": "Dataset distillation aims to compress a dataset into a much smaller one so that a model trained on the distilled dataset achieves high accuracy. Current methods frame this as maximizing the distilled classification accuracy for a budget of K distilled images-per-class, where K is a positive integer. In this paper, we push the boundaries of dataset distillation, compressing the dataset into less than an image-per-class. It is important to realize that the meaningful quantity is not the number of distilled images-per-class but the number of distilled pixels-per-dataset. We therefore, propose Poster Dataset Distillation (PoDD), a new approach that distills the entire original dataset into a single poster. The poster approach motivates new technical solutions for creating training images and learnable labels. Our method can achieve comparable or better performance with less than an image-per-class compared to existing methods that use one image-per-class. Specifically, our method establishes a new state-of-the-art performance on CIFAR-10, CIFAR-100, and CUB200 on the well established 1 IPC benchmark, while using as little as 0.3 images-per-class",
    "checked": true,
    "id": "c911985d5882cf9f6c0f6212afd9fbba9e7a0453",
    "semantic_title": "distilling datasets into less than one image",
    "citation_count": 2,
    "authors": [
      "Asaf Shul",
      "Eliahu Horwitz",
      "Yedid Hoshen"
    ]
  },
  "https://openreview.net/forum?id=uxyWlXPuIg": {
    "title": "On Using Secure Aggregation in Differentially Private Federated Learning with Multiple Local Steps",
    "volume": "main",
    "abstract": "Federated learning is a distributed learning setting where the main aim is to train machine learning models without having to share raw data but only what is required for learning. To guarantee training data privacy and high-utility models, differential privacy and secure aggregation techniques are often combined with federated learning. However, with fine-grained protection granularities, e.g., with the common sample-level protection, the currently existing techniques generally require the parties to communicate for each local optimization step, if they want to fully benefit from the secure aggregation in terms of the resulting formal privacy guarantees. In this paper, we show how a simple new analysis allows the parties to perform multiple local optimization steps while still benefiting from using secure aggregation. We show that our analysis enables higher utility models with guaranteed privacy protection under limited number of communication rounds",
    "checked": true,
    "id": "1c1fd6b10cc266fd2c81b0361252b92e9b56772f",
    "semantic_title": "on using secure aggregation in differentially private federated learning with multiple local steps",
    "citation_count": 1,
    "authors": [
      "Mikko A. Heikkilä"
    ]
  },
  "https://openreview.net/forum?id=XVSQnnf7QT": {
    "title": "Which Backbone to Use: A Resource-efficient Domain Specific Comparison for Computer Vision",
    "volume": "main",
    "abstract": "For computer vision applications on small, niche, and proprietary datasets, fine-tuning a neural network (NN) backbone that is pre-trained on a large dataset, such as the ImageNet, is a common practice. However, it is unknown whether the backbones that perform well on large datasets, such as vision transformers, are also the right choice for fine-tuning on smaller custom datasets. The present comprehensive analysis aims to aid machine learning practitioners in selecting the most suitable backbone for their specific problem. We systematically evaluated multiple lightweight, pre-trained backbones under consistent training settings across a variety of domains spanning natural, medical, deep space, and remote sensing images. We found that even though attention-based architectures are gaining popularity, they tend to perform poorly compared to CNNs when fine-tuned on small amounts of domain-specific data. We also observed that certain CNN architectures consistently perform better than others when controlled for network size. Our findings provide actionable insights into the performance trade-offs and effectiveness of different backbones for a broad spectrum of computer vision domains",
    "checked": true,
    "id": "d19547be89a5b3acad6087ed65c62286d855e14a",
    "semantic_title": "which backbone to use: a resource-efficient domain specific comparison for computer vision",
    "citation_count": 5,
    "authors": [
      "Pranav Jeevan P",
      "Amit Sethi"
    ]
  },
  "https://openreview.net/forum?id=tIfS6jyO9f": {
    "title": "Enhancing Maritime Trajectory Forecasting via H3 Index and Causal Language Modelling (CLM)",
    "volume": "main",
    "abstract": "The prediction of ship trajectories is a growing field of study in artificial intelligence. Traditional methods rely on the use of LSTM, GRU networks, and even Transformer architectures for the prediction of spatio-temporal series. This study proposes a viable alternative for predicting these trajectories using only GNSS positions. It considers this spatio-temporal problem as a natural language processing problem. The latitude/longitude coordinates of AIS messages are transformed into cell identifiers using the H3 index. Thanks to the pseudo-octal representation, it becomes easier for language models to learn the spatial hierarchy of the H3 index. The method is qualitatively compared to a classical Kalman filter and quantitatively to Seq2Seq and TrAISformer models. The Fréchet distance is introduced as the main evaluation metric for these comparisons. We show that it is possible to predict ship trajectories quite precisely up to 8 hours ahead with 30 minutes of context, using solely GNSS positions, without relying on any additional information such as speed, course, or external conditions — unlike many traditional methods. We demonstrate that this alternative works well enough to predict trajectories worldwide",
    "checked": true,
    "id": "5edac0ff5c13118de4d32272a08c3b8c7bd1d1b5",
    "semantic_title": "enhancing maritime trajectory forecasting via h3 index and causal language modelling (clm)",
    "citation_count": 3,
    "authors": [
      "Nicolas Drapier",
      "Aladine Chetouani",
      "Aurélien Chateigner"
    ]
  },
  "https://openreview.net/forum?id=EoiuRII7MQ": {
    "title": "Lower Ricci Curvature for Efficient Community Detection",
    "volume": "main",
    "abstract": "This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and scale-free discrete curvature designed to enhance community detection in networks. Addressing the computational challenges posed by existing curvature-based methods, LRC offers a streamlined approach with linear computational complexity, which makes it well suited for large-scale network analysis. We further develop an LRC-based preprocessing method that effectively augments popular community detection algorithms. Through applications on multiple real-world datasets, including the NCAA football league network, the DBLP collaboration network, the Amazon product co-purchasing network, and the YouTube social network, we demonstrate the efficacy of our method in significantly improving the performance of various community detection algorithms",
    "checked": true,
    "id": "65a946778a04c325034f07836861baf06e65327f",
    "semantic_title": "lower ricci curvature for efficient community detection",
    "citation_count": 2,
    "authors": [
      "Yun Jin Park",
      "Didong Li"
    ]
  },
  "https://openreview.net/forum?id=uRbf9ANAns": {
    "title": "Meta-learning Optimizers for Communication-Efficient Learning",
    "volume": "main",
    "abstract": "Communication-efficient variants of SGD, specifically local SGD, have received a great deal of interest in recent years. These approaches compute multiple gradient steps locally on each worker, before averaging model parameters, helping relieve the critical communication bottleneck in distributed deep learning training. Although many variants of these approaches have been proposed, they can sometimes lag behind state-of-the-art adaptive optimizers for deep learning. In this work, we investigate if the recent progress in the emerging area of learned optimizers can potentially close this gap in homogeneous data and homogeneous device settings while remaining communication-efficient. Specifically, we meta-learn how to perform global updates given an update from local SGD iterations. Our results demonstrate that learned optimizers can substantially outperform local SGD and its sophisticated variants while maintaining their communication efficiency. Our learned optimizers can even generalize to unseen and much larger datasets and architectures, including ImageNet and ViTs, and to unseen modalities such as language modeling. We therefore show the potential of learned optimizers for improving communication-efficient distributed learning",
    "checked": true,
    "id": "4ff9ae519bd9084af922479955b53674afcdb3fb",
    "semantic_title": "meta-learning optimizers for communication-efficient learning",
    "citation_count": 2,
    "authors": [
      "Charles-Étienne Joseph",
      "Benjamin Thérien",
      "Abhinav Moudgil",
      "Boris Knyazev",
      "Eugene Belilovsky"
    ]
  },
  "https://openreview.net/forum?id=HTpMOl6xSI": {
    "title": "Towards Efficient Mixture of Experts: A Holistic Study of Compression Techniques",
    "volume": "main",
    "abstract": "Scaling large language models has driven remarkable advancements across various domains, yet the continual increase in model size presents significant challenges for real-world deployment. The Mixture of Experts (MoE) architecture offers a promising solution by dynamically selecting and activating only a subset of experts during inference, thus substantially reducing computational costs while preserving high performance. Despite these benefits, MoE introduces new inefficiencies, such as excessive parameters and communication overhead. In this work, we present a holistic study of compression techniques for Mixture of Experts to enhance both efficiency and scalability. While recent efforts have focused on Expert Trimming, which reduces the number of experts, these approaches still suffer from considerable communication and computational costs. To address this, we propose more aggressive strategies, such as Layer Drop, which removes entire MoE layers, and Block Drop, which eliminates transformer blocks. Surprisingly, these aggressive pruning techniques not only preserve model performance but also substantially improve computation and memory efficiency. Furthermore, beyond Expert Trimming, we also introduce Expert Slimming, which compresses individual experts to further boost performance and can be seamlessly integrated with Expert Trimming. Extensive experimental results demonstrate the effectiveness of our proposed methods—Layer Drop and Block Drop—along with the comprehensive recipe that integrates Expert Slimming and Expert Trimming, achieving a 6.05× speedup with 77.1% reduced memory usage while maintaining over 92% of performance on Mixtral-8×7B. Our code is released at https://github.com/CASE-Lab-UMD/Unified-MoE-Compression",
    "checked": true,
    "id": "4d0ee7bca07af07e319add08efcdd403e215abff",
    "semantic_title": "towards efficient mixture of experts: a holistic study of compression techniques",
    "citation_count": 8,
    "authors": [
      "Shwai He",
      "Daize Dong",
      "Liang Ding",
      "Ang Li"
    ]
  },
  "https://openreview.net/forum?id=MGdydNfWzQ": {
    "title": "Ensemble and Mixture-of-Experts DeepONets For Operator Learning",
    "volume": "main",
    "abstract": "We present a novel deep operator network (DeepONet) architecture for operator learning, the ensemble DeepONet, that allows for enriching the trunk network of a single DeepONet with multiple distinct trunk networks. This trunk enrichment allows for greater expressivity and generalization capabilities over a range of operator learning problems. We also present a spatial mixture-of-experts (MoE) DeepONet trunk network architecture that utilizes a partition-of-unity (PoU) approximation to promote spatial locality and model sparsity in the operator learning problem. We first prove that both the ensemble and PoU-MoE DeepONets are universal approximators. We then demonstrate that ensemble DeepONets containing a trunk ensemble of a standard trunk, the PoU-MoE trunk, and/or a proper orthogonal decomposition (POD) trunk can achieve 2-4x lower relative $\\ell_2$ errors than standard DeepONets and POD-DeepONets on both standard and challenging new operator learning problems involving partial differential equations (PDEs) in two and three dimensions. Our new PoU-MoE formulation provides a natural way to incorporate spatial locality and model sparsity into any neural network architecture, while our new ensemble DeepONet provides a powerful and general framework for incorporating basis enrichment in scientific machine learning architectures for operator learning",
    "checked": true,
    "id": "c14ce2ad7c54b3f1c9c4ab53c5ae375d5a594f08",
    "semantic_title": "ensemble and mixture-of-experts deeponets for operator learning",
    "citation_count": 0,
    "authors": [
      "Ramansh Sharma",
      "Varun Shankar"
    ]
  },
  "https://openreview.net/forum?id=56EBglCFvx": {
    "title": "HARE: Human-in-the-Loop Algorithmic Recourse",
    "volume": "main",
    "abstract": "Machine learning models are seeing increasing use as decision making systems in domains such as education, finance and healthcare. It is desirable that these models are trustworthy to the end-user, by ensuring fairness, transparency and reliability of decisions. In this work, we consider a key aspect of responsible and transparent AI models -- actionable explanations, viz. the ability of such models to provide recourse to end users adversely affected by their decisions. While algorithmic recourse has seen a variety of efforts in recent years, there have been very few efforts on exploring personalized recourse for a given user. Two users with the same feature profile may prefer vastly different recourses. The limited work in this direction hitherto rely on one-time feature preferences provided by a user. Instead, we present a human-in-the-loop formulation of algorithmic recourse that can incorporate both relative and absolute human feedback for a given test instance. We show that our formulation can extend any existing recourse generating method, enabling the generation of recourses that are satisfactory to the user. We perform experiments on 3 benchmark datasets on top of 6 popular baseline recourse methods where we observe that our framework performs significantly better on simulated user preferences",
    "checked": true,
    "id": "23ff34777e3ae9a4ebffc473e4092b0e05bde183",
    "semantic_title": "hare: human-in-the-loop algorithmic recourse",
    "citation_count": 0,
    "authors": [
      "Sai Srinivas Kancheti",
      "Rahul Vigneswaran",
      "Bamdev Mishra",
      "Vineeth N. Balasubramanian"
    ]
  },
  "https://openreview.net/forum?id=nNN1pPJRVL": {
    "title": "Domain Generalization for Time Series: Enhancing Drilling Regression Models for Stick-Slip Index Prediction",
    "volume": "main",
    "abstract": "This paper provides a comprehensive comparison of domain generalization techniques applied to time series data within a drilling context, focusing on the prediction of a continuous Stick-Slip Index (SSI), a critical metric for assessing torsional downhole vibrations at the drill bit. The study aims to develop a robust regression model that can generalize across domains by training on $60$~ second labeled sequences of $1$~Hz surface drilling data to predict the SSI. The model is tested in wells that are different from those used during training. To fine-tune the model architecture, a grid search approach is employed to optimize key hyperparameters. A comparative analysis of the Adversarial Domain Generalization (ADG), Invariant Risk Minimization (IRM) and baseline models is presented, along with an evaluation of the effectiveness of transfer learning (TL) in improving model performance. The ADG and IRM models achieve performance improvements of $10\\%$ and $8\\%$, respectively, over the baseline model. Most importantly, severe events are detected $60\\%$ of the time, against $20\\%$ for the baseline model. Overall, the results indicate that both ADG and IRM models surpass the baseline, with the ADG model exhibiting a slight advantage over the IRM model. Additionally, applying TL to a pre-trained model further improves performance. Our findings demonstrate the potential of domain generalization approaches in drilling applications, with ADG emerging as the most effective approach",
    "checked": true,
    "id": "e53b8fedc66a121e88a02b726613dd5770971af7",
    "semantic_title": "domain generalization for time series: enhancing drilling regression models for stick-slip index prediction",
    "citation_count": 0,
    "authors": [
      "Hana YAHIA",
      "Bruno Figliuzzi",
      "Florent Di Meglio",
      "Gerbaud",
      "Stephane Menand",
      "Mohamed MAHJOUB"
    ]
  },
  "https://openreview.net/forum?id=VNM6V1gi3k": {
    "title": "Early Directional Convergence in Deep Homogeneous Neural Networks for Small Initializations",
    "volume": "main",
    "abstract": "This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. It is shown here that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in (Euclidean) norm and approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of the recently introduced neural correlation function. Additionally, this paper also studies the KKT points of the neural correlation function for feed-forward networks with (Leaky) ReLU and polynomial (Leaky) ReLU activations, deriving necessary and sufficient conditions for rank-one KKT points",
    "checked": true,
    "id": "d9e2b6247c0a53aef00fae47f698aa7489014b65",
    "semantic_title": "early directional convergence in deep homogeneous neural networks for small initializations",
    "citation_count": 4,
    "authors": [
      "Akshay Kumar",
      "Jarvis Haupt"
    ]
  },
  "https://openreview.net/forum?id=HaAg9RN7Hi": {
    "title": "Unlabelled Compressive Sensing under Sparse Permutation and Prior Information",
    "volume": "main",
    "abstract": "In this paper, we study the problem of unlabelled compressed sensing, where the correspondence between the measurement values and the rows of the sensing matrix is lost, the number of measurements is less than the dimension of the regression vector, and the regression vector is sparse in the identity basis. Additionally, motivated by practical situations, we assume that we accurately know a small number of correspondences between the rows of the measurement matrix and the measurement vector. We propose a tractable estimator, based on a modified form of the \\textsc{Lasso}, to estimate the regression vector, and we derive theoretical error bounds for the estimate. This is unlike previous approaches to unlabelled compressed sensing, which either do not produce theoretical bounds or which produce bounds for intractable estimators. We show that our algorithm outperforms a hard thresholding pursuit (\\textsc{Htp}) approach and an $\\ell_1$-norm estimator used to solve a similar problem across diverse regimes. We also propose a modified \\textsc{Htp} based estimator which has superior properties to the baseline \\textsc{Htp} estimator. Lastly, we show an application of unlabelled compressed sensing in image registration, demonstrating the utility of a few known point correspondences",
    "checked": true,
    "id": "70ac6832ed9aec4b15c8ff9bbe2916a3c0eb3b30",
    "semantic_title": "unlabelled compressive sensing under sparse permutation and prior information",
    "citation_count": 0,
    "authors": [
      "Garweet Sresth",
      "Satish Mulleti",
      "Ajit Rajwade"
    ]
  },
  "https://openreview.net/forum?id=osesw2V10u": {
    "title": "A unifying framework for generalised Bayesian online learning in non-stationary environments",
    "volume": "main",
    "abstract": "We propose a unifying framework for methods that perform probabilistic online learning in non-stationary environments. We call the framework BONE, which stands for generalised (B)ayesian (O)nline learning in (N)on-stationary (E)nvironments. BONE provides a common structure to tackle a variety of problems, including online continual learning, prequential forecasting, and contextual bandits. The framework requires specifying three modelling choices: (i) a model for measurements (e.g., a neural network), (ii) an auxiliary process to model non-stationarity (e.g., the time since the last changepoint), and (iii) a conditional prior over model parameters (e.g., a multivariate Gaussian). The framework also requires two algorithmic choices, which we use to carry out approximate inference under this framework: (i) an algorithm to estimate beliefs (posterior distribution) about the model parameters given the auxiliary variable, and (ii) an algorithm to estimate beliefs about the auxiliary variable. We show how the modularity of our framework allows for many existing methods to be reinterpreted as instances of BONE, and it allows us to propose new methods. We compare experimentally existing methods with our proposed new method on several datasets, providing insights into the situations that make each method more suitable for a specific task. We provide a Jax open source library to facilitate the adoption of this framework",
    "checked": true,
    "id": "c4d64a922168e2918377fa6effcf81f593be9a60",
    "semantic_title": "a unifying framework for generalised bayesian online learning in non-stationary environments",
    "citation_count": 2,
    "authors": [
      "Gerardo Duran-Martin",
      "Leandro Sánchez-Betancourt",
      "Alex Shestopaloff",
      "Kevin Patrick Murphy"
    ]
  },
  "https://openreview.net/forum?id=GEilvtsFNV": {
    "title": "Variational Neural Stochastic Differential Equations with Change Points",
    "volume": "main",
    "abstract": "In this work, we explore modeling change points in time-series data using neural stochastic differential equations (neural SDEs). We propose a novel model formulation and training procedure based on the variational autoencoder (VAE) framework for modeling time-series as a neural SDE. Unlike existing algorithms training neural SDEs as VAEs, our proposed algorithm only necessitates a Gaussian prior of the initial state of the latent stochastic process, rather than a Wiener process prior on the entire latent stochastic process. We develop two methodologies for modeling and estimating change points in time-series data with distribution shifts. Our iterative algorithm alternates between updating neural SDE parameters and updating the change points based on either a maximum likelihood-based approach or a change point detection algorithm using the sequential likelihood ratio test. We also discuss theoretical implications of the proposed change point detection scheme. Finally, we present an empirical evaluation that demonstrates the expressive power of our proposed model, showing that it can effectively model both classical parametric SDEs and some real datasets with distribution shifts",
    "checked": true,
    "id": "33e8721b7eaef68fd59847b3921b8467ef332097",
    "semantic_title": "variational neural stochastic differential equations with change points",
    "citation_count": 1,
    "authors": [
      "Yousef El-Laham",
      "Zhongchang Sun",
      "Haibei Zhu",
      "Tucker Balch",
      "Svitlana Vyetrenko"
    ]
  },
  "https://openreview.net/forum?id=y5Hf0otJLk": {
    "title": "Respecting the limit: Bayesian optimization with a bound on the optimal value",
    "volume": "main",
    "abstract": "In many real-world optimization problems, we have prior information about what objective function values are achievable. In this paper, we study the scenario that we have either exact knowledge of the minimum value or a, possibly inexact, lower bound on its value. We propose bound-aware Bayesian optimization (BABO), a Bayesian optimization method that uses a new surrogate model and acquisition function to utilize such prior information. We present SlogGP, a new surrogate model that incorporates bound information and adapts the Expected Improvement (EI) acquisition function accordingly. Empirical results on a variety of benchmarks demonstrate the benefit of taking prior information about the optimal value into account, and that the proposed approach significantly outperforms existing techniques. Furthermore, we notice that even in the absence of prior information on the bound, the proposed SlogGP surrogate model still performs better than the standard GP model in most cases, which we explain by its larger expressiveness",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanyang Wang",
      "Juergen Branke",
      "Matthias Poloczek"
    ]
  },
  "https://openreview.net/forum?id=dg1tqNIWg3": {
    "title": "Rethinking Knowledge Transfer in Learning Using Privileged Information",
    "volume": "main",
    "abstract": "In supervised machine learning, privileged information (PI) is information that is unavailable at inference, but is accessible during training time. Research on learning using privileged information (LUPI) aims to transfer the knowledge captured in PI onto a model that can perform inference without PI. It seems that this extra bit of information ought to make the resulting model better. However, finding conclusive theoretical or empirical evidence that supports the ability to transfer knowledge using PI has been challenging. In this paper, we critically examine the assumptions underlying existing theoretical analyses and argue that there is little theoretical justification for when LUPI should work. We analyze two main LUPI methods - generalized distillation and marginalization with weight sharing - and reveal that apparent improvements in empirical risk may not directly result from PI. Instead, these improvements often stem from dataset anomalies or modifications in model design misguidedly attributed to PI. Our experiments for a wide variety of application domains further demonstrate that state-of-the-art LUPI approaches fail to effectively transfer knowledge from PI. Thus, we advocate for practitioners to exercise caution when working with PI to avoid unintended inductive biases",
    "checked": true,
    "id": "c9a9a006dbfd58509fc80857d258868d3ddcbe6f",
    "semantic_title": "rethinking knowledge transfer in learning using privileged information",
    "citation_count": 0,
    "authors": [
      "Danil Provodin",
      "Bram van den Akker",
      "Christina Katsimerou",
      "Maurits Clemens Kaptein",
      "Mykola Pechenizkiy"
    ]
  },
  "https://openreview.net/forum?id=FecsgPCOHk": {
    "title": "Causal Discovery over High-Dimensional Structured Hypothesis Spaces with Causal Graph Partitioning",
    "volume": "main",
    "abstract": "The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way---without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of Directed Acyclic Graphs (DAG), to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees under the Maximal Ancestral Graph (MAG) class. We leverage the idea of a superstructure---a set of learned or existing candidate hypotheses---to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces",
    "checked": true,
    "id": "a0c0df87cabaf2893a90dd45ef1e30c632a703ff",
    "semantic_title": "causal discovery over high-dimensional structured hypothesis spaces with causal graph partitioning",
    "citation_count": 1,
    "authors": [
      "Ashka Shah",
      "Adela Frances DePavia",
      "Nathaniel C Hudson",
      "Ian Foster",
      "Rick Stevens"
    ]
  },
  "https://openreview.net/forum?id=uafxqhImPM": {
    "title": "On the Robustness of Kolmogorov-Arnold Networks: An Adversarial Perspective",
    "volume": "main",
    "abstract": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a novel paradigm for function approximation by leveraging univariate spline-based decompositions inspired by the Kolmogorov–Arnold theorem. Despite their theoretical appeal---particularly the potential for inducing smoother decision boundaries and lower effective Lipschitz constants---their adversarial robustness remains largely unexplored. In this work, we conduct the first comprehensive evaluation of KAN robustness in adversarial settings, focusing on both fully connected (FCKANs) and convolutional (CKANs) instantiations for image classification tasks. Across a wide range of benchmark datasets (MNIST, FashionMNIST, KMNIST, CIFAR-10, SVHN, and a subset of ImageNet), we compare KANs against conventional architectures using an extensive suite of attacks, including white-box methods (FGSM, PGD, C\\&W, MIM), black-box approaches (Square Attack, SimBA, NES), and ensemble attacks (AutoAttack). Our experiments reveal that while small- and medium-scale KANs are not consistently more robust than their standard counterparts, large-scale KANs exhibit markedly enhanced resilience against adversarial perturbations. An ablation study further demonstrates that critical hyperparameters---such as number of knots and spline order---significantly influence robustness. Moreover, adversarial training experiments confirm the inherent safety advantages of KAN-based architectures. Overall, our findings provide novel insights into the adversarial behavior of KANs and lay a rigorous foundation for future research on robust, interpretable network designs",
    "checked": true,
    "id": "1c80805893b30d2d779ecfbe236c2a1c32290dd8",
    "semantic_title": "on the robustness of kolmogorov-arnold networks: an adversarial perspective",
    "citation_count": 6,
    "authors": [
      "Tal Alter",
      "Raz Lapid",
      "Moshe Sipper"
    ]
  },
  "https://openreview.net/forum?id=uA19Xo1o31": {
    "title": "CroissantLLM: A Truly Bilingual French-English Language Model",
    "volume": "main",
    "abstract": "We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, and training steps, as well as fine-tuned Chat models, and strong translation models. We evaluate our model through the FMTI framework, and validate 81 % of the transparency criteria, far beyond the scores of even most open initiatives. This work enriches the NLP landscape, breaking away from previous English-centric work in order to strengthen our understanding of multilinguality in language models",
    "checked": true,
    "id": "341103678d9def1add23ad12a28e31a985ea50cd",
    "semantic_title": "croissantllm: a truly bilingual french-english language model",
    "citation_count": 37,
    "authors": [
      "Manuel Faysse",
      "Patrick Fernandes",
      "Nuno M Guerreiro",
      "António Loison",
      "Duarte Miguel Alves",
      "Caio Corro",
      "Nicolas Boizard",
      "João Alves",
      "Ricardo Rei",
      "Pedro Henrique Martins",
      "Antoni Bigata Casademunt",
      "François Yvon",
      "Andre Martins",
      "Gautier Viaud",
      "CELINE HUDELOT",
      "Pierre Colombo"
    ]
  },
  "https://openreview.net/forum?id=uPCvfyr2KP": {
    "title": "Reheated Gradient-based Discrete Sampling for Combinatorial Optimization",
    "volume": "main",
    "abstract": "Recently, gradient-based discrete sampling has emerged as a highly efficient, general-purpose solver for various combinatorial optimization (CO) problems, achieving performance comparable to or surpassing the popular data-driven approaches. However, we identify a critical issue in these methods, which we term ``wandering in contours''. This behavior refers to sampling new different solutions that share very similar objective values for a long time, leading to computational inefficiency and suboptimal exploration of potential solutions. In this paper, we introduce a novel reheating mechanism inspired by the concept of critical temperature and specific heat in physics, aimed at overcoming this limitation. Empirically, our method demonstrates superiority over existing sampling-based and data-driven algorithms across a diverse array of CO problems",
    "checked": true,
    "id": "8220e420f1db6f2e7ce0a38ea2cdb33759752862",
    "semantic_title": "reheated gradient-based discrete sampling for combinatorial optimization",
    "citation_count": 1,
    "authors": [
      "Muheng Li",
      "Ruqi Zhang"
    ]
  },
  "https://openreview.net/forum?id=5zRs34Ls3C": {
    "title": "Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement",
    "volume": "main",
    "abstract": "Graph anomaly detection (GAD) is becoming increasingly crucial in various applications, ranging from financial fraud detection to fake news detection. However, current GAD methods largely overlook the fairness problem, which might result in discriminatory decisions skewed toward certain demographic groups defined on sensitive attributes (e.g., gender). This greatly limits the applicability of these methods in real-world scenarios in light of societal and ethical restrictions. To address this critical gap, we make the first attempt to integrate fairness with utility in GAD decision-making. Specifically, we devise a novel DisEntangle-based FairnEss-aware aNomaly Detection framework on the attributed graph, named DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative yet sensitive-irrelevant node representations, effectively reducing bias inherent in graphrepresentation learning. Besides, to alleviate discriminatory bias in evaluating anomalies, DEFEND adopts a reconstruction-based method, which concentrates solely on node attributes and avoids incorporating biased graph topology. Additionally, given the inherent association between sensitive-relevant and -irrelevant attributes, DEFEND further constrains the correlation between the reconstruction error and predicted sensitive attributes. Empirical evaluations on real-world datasets reveal that DEFEND performs effectively in GAD and significantly enhances fairness compared to state-of-the-art baselines. Our code is available at https://github.com/AhaChang/DEFEND",
    "checked": true,
    "id": "9664162cf0b6411f53b680a7c7e4221d8b9ab9c4",
    "semantic_title": "enhancing fairness in unsupervised graph anomaly detection through disentanglement",
    "citation_count": 2,
    "authors": [
      "Wenjing Chang",
      "Kay Liu",
      "Philip S. Yu",
      "Jianjun Yu"
    ]
  },
  "https://openreview.net/forum?id=Xv3ZrFayIO": {
    "title": "Attention Overlap Is Responsible for The Entity Missing Problem in Text-to-image Diffusion Models!",
    "volume": "main",
    "abstract": "Text-to-image diffusion models such as Stable Diffusion and DALL-E have exhibited impressive capabilities in producing high-quality, diverse, and realistic images based on textual prompts. Nevertheless, a common issue arises where these models encounter difficulties in faithfully generating every entity specified in the prompt, leading to a recognized challenge known as entity missing in visual compositional generation. While previous studies indicated that actively adjusting cross-attention maps during inference could potentially resolve the issue, there has been a lack of systematic investigation into the specific objective function required for this task. In this work, we thoroughly investigate three potential causes of entity missing from the perspective of cross-attention maps: insufficient attention intensity, excessive attention spread, and significant overlap between attention maps of different entities. Through comprehensive empirical analysis, we found that optimizing metrics that quantify the overlap between attention maps of entities is highly effective at mitigating entity missing. We hypothesize that during the denoising process, entity-related tokens engage in a form of competition for attention toward specific regions through the cross-attention mechanism. This competition may result in the attention of a spatial location being divided among multiple tokens, leading to difficulties in accurately generating the entities associated with those tokens. Building on this insight, we propose four overlap-based loss functions that can be used to implicitly manipulate the latent embeddings of the diffusion model during inference: Intersection over union (IoU), center-of-mass (CoM) distance, Kullback–Leibler (KL) divergence, and clustering compactness (CC). Extensive experiments on a diverse set of prompts demonstrate that our proposed training-free methods substantially outperform previous approaches on a range of compositional alignment metrics, including visual question-answering, captioning score, CLIP similarity, and human evaluation. Notably, our method outperforms the best baseline by $9\\%$ in human evaluation",
    "checked": true,
    "id": "074dad74f5089af7186cabe9bf7fd91f96d9d7a4",
    "semantic_title": "attention overlap is responsible for the entity missing problem in text-to-image diffusion models!",
    "citation_count": 3,
    "authors": [
      "Arash Mari Oriyad",
      "Mohammadali Banayeeanzade",
      "Reza Abbasi",
      "Mohammad Hossein Rohban",
      "Mahdieh Soleymani Baghshah"
    ]
  },
  "https://openreview.net/forum?id=iHYCdTAOqF": {
    "title": "The Time-Energy Model: Selective Time-Series Forecasting Using Energy-Based Models",
    "volume": "main",
    "abstract": "Time-series forecasting is an important task in many domains, including finance, weather prediction, and energy consumption forecasting, and deep learning methods have emerged as the best-performing time-series forecasting methods over the last few years. However, most proposed time-series forecasting models are deterministic and are prone to errors when deployed in production, potentially causing significant losses and penalties when making predictions with low confidence. In this paper, we propose the Time-Energy Model (TEM), a framework that introduces so-called selective time-series forecasting using energy-based models. Selective forecasting estimates model confidence and allows the end-user to selectively reject forecasts while maintaining a desired target coverage. TEM is model-agnostic and can be used to improve forecasting accuracy of any encoder-decoder deterministic time-series forecasting model. TEM is trained using a combination of supervised and self-supervised learning, leveraging excellent single-point prediction accuracy while maintaining the ability to reject forecasts based on model confidence. Experimental results indicate that TEM generalizes well across 5 state-of-the-art deterministic time-series forecasting models and 5 benchmark time-series forecasting datasets. Using selective forecasting, TEM reduces prediction error by up to $49.1\\%$ over 5 state-of-the-art deterministic models. Furthermore, TEM has up to $87.0\\%$ lower error than selected baseline EBM models, and achieves significantly better performance than state-of-the-art selective deep learning models. Code for the proposed TEM framework is available at https://github.com/JonasBrusokas/Time-Energy-Model",
    "checked": true,
    "id": "d2269f4429cc99d82ec9b4479e92a4b0d95103e4",
    "semantic_title": "the time-energy model: selective time-series forecasting using energy-based models",
    "citation_count": 1,
    "authors": [
      "Jonas Brusokas",
      "Seshu Tirupathi",
      "Dalin Zhang",
      "Torben Bach Pedersen"
    ]
  },
  "https://openreview.net/forum?id=Is9APiPg4V": {
    "title": "Characterizing the Convergence of Game Dynamics via Potentialness",
    "volume": "main",
    "abstract": "Understanding the convergence landscape of multi-agent learning is a fundamental problem of great practical relevance in many applications of artificial intelligence and machine learning. While it is known that learning dynamics converge to Nash equilibrium in potential games, the behavior of dynamics in many important classes of games that do not admit a potential is poorly understood. To measure how ``close'' a game is to being potential, we consider a distance function, that we call ``potentialness'', and which relies on a strategic decomposition of games introduced by Candogan et al. (2011). We introduce a numerical framework enabling the computation of this metric, which we use to calculate the degree of ``potentialness'' in generic matrix games, as well as (non-generic) games that are important in economic applications, namely auctions and contests. Understanding learning in the latter games has become increasingly important due to the wide-spread automation of bidding and pricing with no-regret learning algorithms. We empirically show that potentialness decreases and concentrates with an increasing number of agents or actions; in addition, potentialness turns out to be a good predictor for the existence of pure Nash equilibria and the convergence of no-regret learning algorithms in matrix games. In particular, we observe that potentialness is very low for complete-information models of the all-pay auction where no pure Nash equilibrium exists, and much higher for Tullock contests, first-, and second-price auctions, explaining the success of learning in the latter. In the incomplete-information version of the all-pay auction, a pure Bayes-Nash equilibrium exists and it can be learned with gradient-based algorithms. Potentialness nicely characterizes these differences to the complete-information version",
    "checked": true,
    "id": "323bfa1c6bcc8a84f12ae41216616d0033ec99f8",
    "semantic_title": "characterizing the convergence of game dynamics via potentialness",
    "citation_count": 0,
    "authors": [
      "Martin Bichler",
      "Davide Legacci",
      "Panayotis Mertikopoulos",
      "Matthias Oberlechner",
      "Bary Pradelski"
    ]
  },
  "https://openreview.net/forum?id=OGifiton47": {
    "title": "Active Diffusion Subsampling",
    "volume": "main",
    "abstract": "Subsampling is commonly used to mitigate costs associated with data acquisition, such as time or energy requirements, motivating the development of algorithms for estimating the fully-sampled signal of interest $x$ from partially observed measurements $y$. In maximum- entropy sampling, one selects measurement locations that are expected to have the highest entropy, so as to minimize uncertainty about $x$. This approach relies on an accurate model of the posterior distribution over future measurements, given the measurements observed so far. Recently, diffusion models have been shown to produce high-quality posterior samples of high-dimensional signals using guided diffusion. In this work, we propose Active Diffusion Subsampling (ADS), a method for designing intelligent subsampling masks using guided dif- fusion in which the model tracks a distribution of beliefs over the true state of $x$ throughout the reverse diffusion process, progressively decreasing its uncertainty by actively choosing to acquire measurements with maximum expected entropy, ultimately producing the pos- terior distribution $p(x | y)$. ADS can be applied using pre-trained diffusion models for any subsampling rate, and does not require task-specific retraining – just the specification of a measurement model. Furthermore, the maximum entropy sampling policy employed by ADS is interpretable, enhancing transparency relative to existing methods using black-box policies. Experimentally, we show that through designing informative subsampling masks, ADS significantly improves reconstruction quality compared to fixed sampling strategies on the MNIST and CelebA datasets, as measured by standard image quality metrics, includ- ing PSNR, SSIM, and LPIPS. Furthermore, on the task of Magnetic Resonance Imaging acceleration, we find that ADS performs competitively with existing supervised methods in reconstruction quality while using a more interpretable acquisition scheme design procedure. Code is available at https://active-diffusion-subsampling.github.io/",
    "checked": true,
    "id": "4402553023146bad8400732eac9d8366cac1e604",
    "semantic_title": "active diffusion subsampling",
    "citation_count": 3,
    "authors": [
      "Oisín Nolan",
      "Tristan Stevens",
      "Wessel L. van Nierop",
      "Ruud Van Sloun"
    ]
  },
  "https://openreview.net/forum?id=XosdLS7KVE": {
    "title": "Mixed Sparsity Training: Achieving 4$\\times$ FLOP Reduction for Transformer Pretraining",
    "volume": "main",
    "abstract": "Large language models (LLMs) have made significant strides in complex tasks, yet their widespread adoption is impeded by substantial computational demands. With hundreds of billion parameters, transformer-based LLMs necessitate months of pretraining across a high-end GPU cluster. However, this paper reveals a compelling finding: transformers exhibit considerable redundancy in pretraining computations, which motivates our proposed solution, Mixed Sparsity Training (MST), an efficient pretraining method that can reduce about $75$% of Floating Point Operations (FLOPs) while maintaining performance. MST integrates dynamic sparse training (DST) with Sparsity Variation (SV) and Hybrid Sparse Attention (HSA) during pretraining, involving three distinct phases: warm-up, ultra-sparsification, and restoration. The warm-up phase transforms the dense model into a sparse one, and the restoration phase reinstates connections. Throughout these phases, the model is trained with a dynamically evolving sparse topology and an HSA mechanism to maintain performance and minimize training FLOPs concurrently. Our experiment on GPT-2 showcases a FLOP reduction of $4\\times$ without compromising performance",
    "checked": false,
    "id": "1fcff55bc2d3c2013a6f10dc48ab6768a657baa2",
    "semantic_title": "mixed sparsity training: achieving 4× flop reduction for transformer pretraining",
    "citation_count": 0,
    "authors": [
      "Pihe Hu",
      "Shaolong Li",
      "Xun Wang",
      "Longbo Huang"
    ]
  },
  "https://openreview.net/forum?id=LDzvZEVl5H": {
    "title": "Online Control-Informed Learning",
    "volume": "main",
    "abstract": "This paper proposes an Online Control-Informed Learning (OCIL) framework, which employs the well-established optimal control and state estimation techniques in the field of control to solve a broad class of learning tasks in an online fashion. This novel integration effectively handles practical issues in machine learning such as noisy measurement data, online learning, and data efficiency. By considering any robot as a tunable optimal control system, we propose an online parameter estimator based on extended Kalman filter (EKF) to incrementally tune the system in an online fashion, enabling it to complete designated learning or control tasks. The proposed method also improves the robustness in learning by effectively managing noise in the data. Theoretical analysis is provided to demonstrate the convergence of OCIL. Three learning modes of OCIL, i.e. Online Imitation Learning, Online System Identification, and Policy Tuning On-the-fly, are investigated via experiments, which validate their effectiveness",
    "checked": true,
    "id": "4ce0358920dd394751a1bae16ac6f1b005e619c2",
    "semantic_title": "online control-informed learning",
    "citation_count": 1,
    "authors": [
      "Zihao Liang",
      "Tianyu Zhou",
      "Zehui Lu",
      "Shaoshuai Mou"
    ]
  },
  "https://openreview.net/forum?id=D3DA7pgpvn": {
    "title": "Visual Privacy Auditing with Diffusion Models",
    "volume": "main",
    "abstract": "Data reconstruction attacks on machine learning models pose a substantial threat to privacy, potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) provides theoretical guarantees, determining appropriate DP parameters remains challenging. Current formal guarantees on the success of data reconstruction suffer from overly stringent assumptions regarding adversary knowledge about the target data, particularly in the image domain, raising questions about their real-world applicability. In this work, we empirically investigate this discrepancy by introducing a reconstruction attack based on diffusion models (DMs) that only assumes adversary access to real-world image priors and specifically targets the DP defense. We find that (1) real-world data priors significantly influence reconstruction success, (2) current reconstruction bounds do not model the risk posed by data priors well, and (3) DMs can serve as heuristic auditing tools for visualizing privacy leakage",
    "checked": true,
    "id": "1a8a9077972e849b8d307674c2ecbb9e305752b9",
    "semantic_title": "visual privacy auditing with diffusion models",
    "citation_count": 0,
    "authors": [
      "Kristian Schwethelm",
      "Johannes Kaiser",
      "Moritz Knolle",
      "Sarah Lockfisch",
      "Daniel Rueckert",
      "Alexander Ziller"
    ]
  },
  "https://openreview.net/forum?id=nuIUTHGlM5": {
    "title": "Calibrated Probabilistic Forecasts for Arbitrary Sequences",
    "volume": "main",
    "abstract": "Real-world data streams can change unpredictably due to distribution shifts, feedback loops and adversarial actors, which challenges the validity of forecasts. We present a forecasting framework ensuring valid uncertainty estimates regardless of how data evolves. Leveraging the concept of Blackwell approachability from game theory, we introduce a forecasting framework that guarantees calibrated uncertainties for outcomes in any compact space (e.g., classification or bounded regression). We extend this framework to recalibrate existing forecasters, guaranteeing calibration without sacrificing predictive performance. We implement both general-purpose gradient-based algorithms and algorithms optimized for popular special cases of our framework. Empirically, our algorithms improve calibration and downstream decision-making for energy systems",
    "checked": true,
    "id": "966eec92c6edae037f21be7cb4f7faa29a462435",
    "semantic_title": "calibrated probabilistic forecasts for arbitrary sequences",
    "citation_count": 1,
    "authors": [
      "Charles Marx",
      "Volodymyr Kuleshov",
      "Stefano Ermon"
    ]
  },
  "https://openreview.net/forum?id=QlBaDKb370": {
    "title": "State space models can express $n$-gram languages",
    "volume": "main",
    "abstract": "Recent advancements in recurrent neural networks (RNNs) have reinvigorated interest in their application to natural language processing tasks, particularly with the development of more efficient and parallelizable variants known as state space models (SSMs), which have shown competitive performance against transformer models while maintaining a lower memory footprint. While RNNs and SSMs (e.g., Mamba) have been empirically more successful than rule-based systems based on $n$-gram models, a rigorous theoretical explanation for this success has not yet been developed, as it is unclear how these models encode the combinatorial rules that govern the next-word prediction task. In this paper, we construct state space language models that can solve the next-word prediction task for languages generated from $n$-gram rules, thereby showing that the former are more expressive. Our proof shows how SSMs can encode $n$-gram rules using new theoretical results on their memorization capacity, and demonstrates how their context window can be controlled by restricting the spectrum of the state transition matrix. We conduct experiments with a small dataset generated from $n$-gram rules to show how our framework can be applied to SSMs and RNNs obtained through gradient-based optimization",
    "checked": false,
    "id": "7417f274a7740b2f608ae2beccb857096eb71afb",
    "semantic_title": "state space models can express n-gram languages",
    "citation_count": 1,
    "authors": [
      "Vinoth Nandakumar",
      "Qiang Qu",
      "Peng Mi",
      "Tongliang Liu"
    ]
  },
  "https://openreview.net/forum?id=VxC4PZ71Ym": {
    "title": "Unlearning Personal Data from a Single Image",
    "volume": "main",
    "abstract": "Machine unlearning aims to erase data from a model as if the latter never saw them during training. While existing approaches unlearn information from complete or partial access to the training data, this access can be limited over time due to privacy regulations. Currently, no setting or benchmark exists to probe the effectiveness of unlearning methods in such scenarios. To fill this gap, we propose a novel task we call One-Shot Unlearning of Personal Identities (1-SHUI) that evaluates unlearning models when the training data is not available. We focus on unlearning identity data, which is specifically relevant due to current regulations requiring personal data deletion after training. To cope with data absence, we expect users to provide a portraiting picture to aid unlearning. We design requests on CelebA, CelebA-HQ, and MUFAC with different unlearning set sizes to evaluate applicable methods in 1-SHUI. Moreover, we propose MetaUnlearn, an effective method that meta-learns to forget identities from a single image. Our findings indicate that existing approaches struggle when data availability is limited, especially when there is a dissimilarity between the provided samples and the training data",
    "checked": true,
    "id": "be6f26385375491918addcc0a20830ab0e5a514f",
    "semantic_title": "unlearning personal data from a single image",
    "citation_count": 2,
    "authors": [
      "Thomas De Min",
      "Massimiliano Mancini",
      "Stéphane Lathuilière",
      "Subhankar Roy",
      "Elisa Ricci"
    ]
  },
  "https://openreview.net/forum?id=pF2ukh7HxA": {
    "title": "FlashAttention on a Napkin: A Diagrammatic Approach to Deep Learning IO-Awareness",
    "volume": "main",
    "abstract": "Optimizing deep learning algorithms currently requires slow, manual derivation, potentially leaving much performance untapped. Methods like FlashAttention have achieved a x6 performance improvement over native PyTorch by avoiding unnecessary data transfers, but required three iterations over three years to be developed. Automated compiled methods have consistently lagged behind. This paper extends Neural Circuit Diagrams for deep learning models to consider resource usage and the distribution of tasks across a GPU hierarchy. We show how diagrams can use simple relabellings to derive high-level streaming and tiling optimization strategies along with performance models. We show how this high-level performance model allows the effects of quantization and multi-level GPU hierarchies to be readily considered. We develop a methodology for representing intermediate-level pseudocode with diagrams, allowing hardware-aware algorithms to be derived step-by-step. Finally, we show how our methodology can be used to better understand existing techniques like FlashAttention. This work uses a theoretical framework to link assumptions about GPU behaviour to claims about performance. We aim to lay the groundwork for a scientific approach to GPU optimization where experiments can address clear hypotheses rather than post-hoc rationalizations",
    "checked": true,
    "id": "1bbc5c11837214a20da68d2842143f6970dc4f7d",
    "semantic_title": "flashattention on a napkin: a diagrammatic approach to deep learning io-awareness",
    "citation_count": 0,
    "authors": [
      "Vincent Abbott",
      "Gioele Zardini"
    ]
  },
  "https://openreview.net/forum?id=EEeVYfXor5": {
    "title": "Out of Spuriousity: Improving Robustness to Spurious Correlations without Group Annotations",
    "volume": "main",
    "abstract": "Machine learning models are known to learn spurious correlations, i.e., features that have strong correlations with class labels but no causal relationship. Relying on these correlations leads to poor performance in data groups that do not contain these correlations, and poor generalization. Approaches to mitigate spurious correlations either rely on the availability of group annotations or require access to different model checkpoints to approximate these group annotations. We propose PruSC, a method for extracting a spurious-free subnetwork from a dense network. PruSC does not require prior knowledge of the spurious correlations and is able to mitigate the effect of multiple spurious attributes. Specifically, we observe that ERM training leads to clusters in representation space that are induced by spurious correlations. We then define a supervised contrastive loss to extract a subnetwork that distorts such clusters, forcing the model to learn only class-specific clusters, rather than attribute-class specific clusters. Our method outperforms all annotation-free methods, achieves worst-group accuracy competitive with methods that require annotations and can mitigate the effect of multiple spurious correlations. Our results show that in a fully trained dense network, there exists a subnetwork that uses only invariant features in classification tasks, thereby eliminating the influence of spurious features",
    "checked": true,
    "id": "472870875e5140d96e70b924c3bd54b18d117025",
    "semantic_title": "out of spuriousity: improving robustness to spurious correlations without group annotations",
    "citation_count": 2,
    "authors": [
      "Phuong Quynh Le",
      "Jörg Schlötterer",
      "Christin Seifert"
    ]
  },
  "https://openreview.net/forum?id=5PPbvCExZs": {
    "title": "No Need for Ad-hoc Substitutes: The Expected Cost is a Principled All-purpose Classification Metric",
    "volume": "main",
    "abstract": "The expected cost (EC) is one of the main classification metrics introduced in statistical and machine learning books. It is based on the assumption that, for a given application of interest, each decision made by the system has a corresponding cost which depends on the true class of the sample. An evaluation metric can then be defined by taking the expectation of the cost over the data. Two special cases of the EC are widely used in the machine learning literature: the error rate (one minus the accuracy) and the balanced error rate (one minus the balanced accuracy or unweighted average recall). Other instances of the EC can be useful for applications in which some types of errors are more severe than others, or when the prior probabilities of the classes differ between the evaluation data and the use-case scenario. Surprisingly, the general form for the EC is rarely used in the machine learning literature. Instead, alternative ad-hoc metrics like the F-beta score and the Matthews correlation coefficient (MCC) are used for many applications. In this work, we argue that the EC is superior to these alternative metrics, being more general, interpretable, and adaptable to any application scenario. We provide both theoretically-motivated discussions as well as examples to illustrate the behavior of the different metrics",
    "checked": true,
    "id": "7374b213570dba10ee5374673ff69a3b92d50739",
    "semantic_title": "no need for ad-hoc substitutes: the expected cost is a principled all-purpose classification metric",
    "citation_count": 0,
    "authors": [
      "Luciana Ferrer"
    ]
  },
  "https://openreview.net/forum?id=HOnL5hjaIt": {
    "title": "Generalized Tangent Kernel: A Unified Geometric Foundation for Natural Gradient and Standard Gradient",
    "volume": "main",
    "abstract": "Natural gradients have been widely studied from both theoretical and empirical perspectives, and it is commonly believed that natural gradients have advantages over standard (Euclidean) gradients in capturing the intrinsic geometric structure of the underlying function space and being invariant under reparameterization. However, for function optimization, a fundamental theoretical issue regarding the existence of natural gradients on the function space remains underexplored. We address this issue by providing a geometric perspective and mathematical framework for studying both natural gradient and standard gradient that is more complete than existing studies. The key tool that unifies natural gradient and standard gradient is a generalized form of the Neural Tangent Kernel (NTK), which we name the Generalized Tangent Kernel (GTK). Using a novel orthonormality property of GTK, we show that for a fixed parameterization, GTK determines a Riemannian metric on the entire function space which makes the standard gradient as \"natural\" as the natural gradient in capturing the intrinsic structure of the parameterized function space. Many aspects of this approach relate to RKHS theory. For the practical side of this theory paper, we showcase that our framework motivates new solutions to the non-immersion/degenerate case of natural gradient and leads to new families of natural/standard gradient descent methods",
    "checked": true,
    "id": "e4df394e7d365e1d08d5272d765a112a0127de5a",
    "semantic_title": "generalized tangent kernel: a unified geometric foundation for natural gradient and standard gradient",
    "citation_count": 0,
    "authors": [
      "Qinxun Bai",
      "Steven Rosenberg",
      "Wei Xu"
    ]
  },
  "https://openreview.net/forum?id=Yk7GUlJwGa": {
    "title": "GeoMask3D: Geometrically Informed Mask Selection for Self-Supervised Point Cloud Learning in 3D",
    "volume": "main",
    "abstract": "We introduce a novel approach to self-supervised learning for point clouds, employing a geometrically informed mask selection strategy called GeoMask3D (GM3D) to boost the efficiency of Masked Auto Encoders (MAE). Unlike the conventional method of random masking, our technique utilizes a teacher-student model to focus on intricate areas within the data, guiding the model's focus toward regions with higher geometric complexity. This strategy is grounded in the hypothesis that concentrating on harder patches yields a more robust feature representation, as evidenced by the improved performance on downstream tasks. Our method also presents a feature-level knowledge distillation technique designed to guide the prediction of geometric complexity, which utilizes a comprehensive context from feature-level information. Extensive experiments confirm our method's superiority over State-Of-The-Art (SOTA) baselines, demonstrating marked improvements in classification, segmentation, and few-shot tasks",
    "checked": true,
    "id": "f47ed8b34a9dcfa71cda5e5c903e3e2723b83d47",
    "semantic_title": "geomask3d: geometrically informed mask selection for self-supervised point cloud learning in 3d",
    "citation_count": 2,
    "authors": [
      "Ali Bahri",
      "Moslem Yazdanpanah",
      "Mehrdad Noori",
      "Milad Cheraghalikhani",
      "Gustavo Adolfo Vargas Hakim",
      "David OSOWIECHI",
      "Farzad Beizaee",
      "Ismail Ben Ayed",
      "Christian Desrosiers"
    ]
  },
  "https://openreview.net/forum?id=FoQK84nwY3": {
    "title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment",
    "volume": "main",
    "abstract": "Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed dataset, online feedback collection from humans or AI on model generations typically leads to more capable reward models and better-aligned LLMs through an iterative process. However, achieving a globally accurate reward model requires systematic exploration to generate diverse responses that span the vast space of natural language. Random sampling from standard reward-maximizing LLMs alone is insufficient to fulfill this requirement. To address this issue, we propose a bilevel objective optimistically biased towards potentially high-reward responses to actively explore out-of-distribution regions. By solving the inner-level problem with the reparameterized reward function, the resulting algorithm, named Self-Exploring Language Models (SELM), eliminates the need for a separate RM and iteratively updates the LLM with a straightforward objective. Compared to Direct Preference Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen extrapolations and enhances exploration efficiency. Our experimental results demonstrate that when fine-tuned on Zephyr-7B-SFT and Llama-3-8B-Instruct models, SELM significantly boosts the performance on instruction-following benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard academic benchmarks in different settings",
    "checked": true,
    "id": "30ef6a82ac5aa80f2eea02aebeee2b98ca8ba290",
    "semantic_title": "self-exploring language models: active preference elicitation for online alignment",
    "citation_count": 38,
    "authors": [
      "Shenao Zhang",
      "Donghan Yu",
      "Hiteshi Sharma",
      "Han Zhong",
      "Zhihan Liu",
      "Ziyi Yang",
      "Shuohang Wang",
      "Hany Hassan Awadalla",
      "Zhaoran Wang"
    ]
  },
  "https://openreview.net/forum?id=RXoSmiyObR": {
    "title": "Path-Specific Counterfactual Fairness via Dividend Correction",
    "volume": "main",
    "abstract": "Counterfactual fairness is a fundamental principle in machine learning that allows the analysis of the effects of sensitive attributes in each individual decision by integrating the knowledge of causal graphs. An issue in dealing with counterfactual fairness is that unfair causal effects are often context-specific, influenced by religious, cultural, and national differences, making it difficult to create a universally applicable model. This leads to the challenge of dealing with frequent adaptation to changes in fairness assessments when localizing a model. Thus, applicability across a variety of models and efficiency becomes necessary to meet this challenge. We propose the first efficient post-process approach to achieve path-specific counterfactual fairness by adjusting a model's outputs based on a given causal graph. This approach is model-agnostic, prioritizing on flexibility and generalizability to deliver robust results across various domains and model architectures. By means of the mathematical tools in cooperative game, the Möbius inversion formula and dividends, we demonstrate that our post-process approach can be executed efficiently. We empirically show that proposed algorithm outperforms existing in-process approaches for path-specific counterfactual fairness and a post-process approach for counterfactual fairness",
    "checked": true,
    "id": "197367ee337e8838fd2ef1a887101ddc84eb0612",
    "semantic_title": "path-specific counterfactual fairness via dividend correction",
    "citation_count": 0,
    "authors": [
      "Daisuke Hatano",
      "Satoshi Hara",
      "Hiromi Arai"
    ]
  },
  "https://openreview.net/forum?id=03UB1MCAMr": {
    "title": "KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning",
    "volume": "main",
    "abstract": "In recent years, Graph Neural Networks (GNNs) have become the de facto tool for learning node and graph representations. Most GNNs typically consist of a sequence of neighborhood aggregation (a.k.a., message-passing) layers, within which the representation of each node is updated based on those of its neighbors. The most expressive message-passing GNNs can be obtained through the use of the sum aggregator and of MLPs for feature transformation, thanks to their universal approximation capabilities. However, the limitations of MLPs recently motivated the introduction of another family of universal approximators, called Kolmogorov-Arnold Networks (KANs) which rely on a different representation theorem. In this work, we compare the performance of KANs against that of MLPs on graph learning tasks. We implement three new KAN-based GNN layers, inspired respectively by the GCN, GAT and GIN layers. We evaluate two different implementations of KANs using two distinct base families of functions, namely B-splines and radial basis functions. We perform extensive experiments on node classification, link prediction, graph classification and graph regression datasets. Our results indicate that KANs are on-par with or better than MLPs on all tasks studied in this paper. We also show that the size and training speed of RBF-based KANs is only marginally higher than for MLPs, making them viable alternatives. Code available at https://github.com/RomanBresson/KAGNN",
    "checked": true,
    "id": "78167a0578e995148dac629768e9495113c8babd",
    "semantic_title": "kagnns: kolmogorov-arnold networks meet graph learning",
    "citation_count": 51,
    "authors": [
      "Roman Bresson",
      "Giannis Nikolentzos",
      "George Panagopoulos",
      "Michail Chatzianastasis",
      "Jun Pang",
      "Michalis Vazirgiannis"
    ]
  },
  "https://openreview.net/forum?id=Xz5IcOizQ6": {
    "title": "Buffer-based Gradient Projection for Continual Federated Learning",
    "volume": "main",
    "abstract": "Continual Federated Learning (CFL) is essential for enabling real-world applications where multiple decentralized clients adaptively learn from continuous data streams. A significant challenge in CFL is mitigating catastrophic forgetting, where models lose previously acquired knowledge when learning new information. Existing approaches often face difficulties due to the constraints of device storage capacities and the heterogeneous nature of data distributions among clients. While some CFL algorithms have addressed these challenges, they frequently rely on unrealistic assumptions about the availability of task boundaries (i.e., knowing when new tasks begin). To address these limitations, we introduce Fed-A-GEM, a federated adaptation of the A-GEM method, which employs a buffer-based gradient projection approach. Fed-A-GEM alleviates catastrophic forgetting by leveraging local buffer samples and aggregated buffer gradients, thus preserving knowledge across multiple clients. Our method is combined with existing CFL techniques, enhancing their performance in the CFL context. Our experiments on standard benchmarks show consistent performance improvements across diverse scenarios. For example, in a task-incremental learning scenario using the CIFAR-100 dataset, our method can increase the accuracy by up to 27%. Our code is available at https://github.com/shenghongdai/Fed-A-GEM",
    "checked": true,
    "id": "b941f38d44f7556cf905fa9c21c4dc021d47aa21",
    "semantic_title": "buffer-based gradient projection for continual federated learning",
    "citation_count": 2,
    "authors": [
      "Shenghong Dai",
      "Jy-yong Sohn",
      "Yicong Chen",
      "S M Iftekharul Alam",
      "Ravikumar Balakrishnan",
      "Suman Banerjee",
      "Nageen Himayat",
      "Kangwook Lee"
    ]
  },
  "https://openreview.net/forum?id=38cwP8xVxD": {
    "title": "The 2024 Foundation Model Transparency Index",
    "volume": "main",
    "abstract": "Foundation models are increasingly consequential yet extremely opaque. To characterize the status quo, the Foundation Model Transparency Index was launched in October 2023 to measure the transparency of leading foundation model developers. The October 2023 Index (v1.0) assessed 10 major foundation model developers (e.g. OpenAI, Google) on 100 transparency indicators (e.g. does the developer disclose the wages it pays for data labor?). At the time, developers publicly disclosed very limited information with the average score being 37 out of 100. To understand how the status quo has changed, we conduct a follow-up study (v1.1) after 6 months: we score 14 developers against the same 100 indicators. While in v1.0 we searched for publicly available information, in v1.1 developers submit reports on the 100 transparency indicators, potentially including information that was not previously public. We find that developers now score 58 out of 100 on average, a 21 point improvement over v1.0. Much of this increase is driven by developers disclosing information during the v1.1 process: on average, developers disclosed information related to 16.6 indicators that was not previously public. We observe regions of sustained (i.e. across v1.0 and v1.1) and systemic (i.e. across most or all developers) opacity such as on copyright status, data access, data labor, and downstream impact. We publish transparency reports for each developer that consolidate information disclosures: these reports are based on the information disclosed to us via developers. Our findings demonstrate that transparency can be improved in this nascent ecosystem, the Foundation Model Transparency Index likely contributes to these improvements, and policymakers should consider interventions in areas where transparency has not improved",
    "checked": true,
    "id": "3ae2822fcaa5a0054cc450d3209c7493a0ebeac2",
    "semantic_title": "the 2024 foundation model transparency index",
    "citation_count": 10,
    "authors": [
      "Rishi Bommasani",
      "Kevin Klyman",
      "Sayash Kapoor",
      "Shayne Longpre",
      "Betty Xiong",
      "Nestor Maslej",
      "Percy Liang"
    ]
  },
  "https://openreview.net/forum?id=dczXe0S1oL": {
    "title": "How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning",
    "volume": "main",
    "abstract": "Many real-world applications require machine-learning models to be able to deal with non-stationary data distributions and thus learn autonomously over an extended period of time, often in an online setting. One of the main challenges in this scenario is the so-called catastrophic forgetting (CF) for which the learning model tends to focus on the most recent tasks while experiencing predictive degradation on older ones. In the online setting, the most effective solutions employ a fixed-size memory buffer to store old samples used for replay when training on new tasks. Many approaches have been presented to tackle this problem and conflicting strategies are proposed to populate the memory. Are the easiest-to-forget or the easiest-to-remember samples more effective in combating CF? Furthermore, it is not clear how predictive uncertainty information for memory management can be leveraged in the most effective manner. Starting from the intuition that predictive uncertainty provides an idea of the samples' location in the decision space, this work presents an in-depth analysis of different uncertainty estimates and strategies for populating the memory. The investigation provides a better understanding of the characteristics data points should have for alleviating CF. Then, we propose an alternative method for estimating predictive uncertainty via the generalised variance induced by the negative log-likelihood. Finally, we demonstrate that the use of predictive uncertainty measures helps in reducing CF in different settings",
    "checked": true,
    "id": "05a91c7f3dfe394ffc0501f6ee8ce2747c752043",
    "semantic_title": "how to leverage predictive uncertainty estimates for reducing catastrophic forgetting in online continual learning",
    "citation_count": 2,
    "authors": [
      "Giuseppe Serra",
      "Ben Werner",
      "Florian Buettner"
    ]
  },
  "https://openreview.net/forum?id=ZInwrlkQ3f": {
    "title": "An elementary concentration bound for Gibbs measures arising in statistical learning theory",
    "volume": "main",
    "abstract": "We present an elementary concentration bound for Gibbs measures whose log-likelihood is a function of the empirical risk. This bound controls the distance between samples from the (random) Gibbs measure and the minimizers of the population risk function. This bound is a generalization of a recent inequality developed by Ramsay et al., 2024. As a corollary, we obtain sample complexity bounds and bounds on the inverse temperature so that the samples are within a prescribed error of the population value. The latter bound on the inverse temperature is essentially sharp. We demonstrate our work on three canonical classes of examples: classification of two component mixture models, robust regression, and spiked matrix and tensor models",
    "checked": true,
    "id": "ab204993d306b808a27296eae9157c5d6f2aabdf",
    "semantic_title": "an elementary concentration bound for gibbs measures arising in statistical learning theory",
    "citation_count": 0,
    "authors": [
      "Kelly Ramsay",
      "Aukosh Jagannath",
      "Shojaeddin Chenouri"
    ]
  },
  "https://openreview.net/forum?id=tSFpsfndE7": {
    "title": "Random Walk Diffusion for Efficient Large-Scale Graph Generation",
    "volume": "main",
    "abstract": "Graph generation addresses the problem of generating new graphs that have a data distribution similar to real-world graphs. While previous diffusion-based graph generation methods have shown promising results, they often struggle to scale to large graphs. In this work, we propose ARROW-Diff (AutoRegressive RandOm Walk Diffusion), a novel random walk-based diffusion approach for efficient large-scale graph generation. Our method encompasses two components in an iterative process of random walk sampling and graph pruning. We demonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing other baseline methods in terms of both generation time and multiple graph statistics, reflecting the high quality of the generated graphs",
    "checked": true,
    "id": "fde9f622cdaf72b5b0462ce1781a8470575fda02",
    "semantic_title": "random walk diffusion for efficient large-scale graph generation",
    "citation_count": 1,
    "authors": [
      "Tobias Bernecker",
      "Ghalia Rehawi",
      "Francesco Paolo Casale",
      "Janine Knauer-Arloth",
      "Annalisa Marsico"
    ]
  },
  "https://openreview.net/forum?id=N28FdYO2sH": {
    "title": "Learning Linear Polytree Structural Equation Model",
    "volume": "main",
    "abstract": "We are interested in the problem of learning the directed acyclic graph (DAG) when data are generated from a linear structural equation model (SEM) and the causal structure can be characterized by a polytree. Under the Gaussian polytree models, we study sufficient conditions on the sample sizes for the well-known Chow-Liu algorithm to exactly recover both the skeleton and the equivalence class of the polytree, which is uniquely represented by a CPDAG. On the other hand, necessary conditions on the required sample sizes for both skeleton and CPDAG recovery are also derived in terms of information-theoretic lower bounds, which match the respective sufficient conditions and thereby give a sharp characterization of the difficulty of these tasks. We also consider the problem of inverse correlation matrix estimation under the linear polytree models, and establish the estimation error bound in terms of the dimension and the total number of v-structures. We also consider an extension of group linear polytree models, in which each node represents a group of variables. Our theoretical findings are illustrated by comprehensive numerical simulations, and experiments on benchmark data also demonstrate the robustness of polytree learning when the true graphical structures can only be approximated by polytrees",
    "checked": false,
    "id": "2da7c097897b70a375c345e4234ece25c1ad0b6f",
    "semantic_title": "using sympy (symbolic python) for understanding structural equation modeling",
    "citation_count": 1,
    "authors": [
      "Xingmei Lou",
      "Yu Hu",
      "Xiaodong Li"
    ]
  },
  "https://openreview.net/forum?id=6nBIweDYzZ": {
    "title": "DP-2Stage: Adapting Language Models as Differentially Private Tabular Data Generators",
    "volume": "main",
    "abstract": "Generating tabular data under differential privacy (DP) protection ensures theoretical privacy guarantees but poses challenges for training machine learning models, primarily due to the need to capture complex structures under noisy supervision signals. Recently, pre-trained Large Language Models (LLMs) -- even those at the scale of GPT-2 -- have demonstrated great potential in synthesizing tabular data. However, their applications under DP constraints remain largely unexplored. In this work, we address this gap by applying DP techniques to the generation of synthetic tabular data. Our findings shows that LLMs face difficulties in generating coherent text when fine-tuned with DP, as privacy budgets are inefficiently allocated to non-private elements like table structures. To overcome this, we propose DP-2Stage, a two-stage fine-tuning framework for differentially private tabular data generation. The first stage involves non-private fine-tuning on a pseudo dataset, followed by DP fine-tuning on a private dataset. Our empirical results show that this approach improves performance across various settings and metrics compared to directly fine-tuned LLMs in DP contexts. We release our code and setup at https://github.com/tejuafonja/DP-2Stage",
    "checked": true,
    "id": "f5349256ac4563b46793ddb1ee903861bfb46075",
    "semantic_title": "dp-2stage: adapting language models as differentially private tabular data generators",
    "citation_count": 2,
    "authors": [
      "Tejumade Afonja",
      "Hui-Po Wang",
      "Raouf Kerkouche",
      "Mario Fritz"
    ]
  },
  "https://openreview.net/forum?id=BPDVZajOW5": {
    "title": "Optimizing Estimators of Squared Calibration Errors in Classification",
    "volume": "main",
    "abstract": "In this work, we propose a mean-squared error-based risk that enables the comparison and optimization of estimators of squared calibration errors in practical settings. Improving the calibration of classifiers is crucial for enhancing the trustworthiness and interpretability of machine learning models, especially in sensitive decision-making scenarios. Although various calibration (error) estimators exist in the current literature, there is a lack of guidance on selecting the appropriate estimator and tuning its hyperparameters. By leveraging the bilinear structure of squared calibration errors, we reformulate calibration estimation as a regression problem with independent and identically distributed (i.i.d.) input pairs. This reformulation allows us to quantify the performance of different estimators even for the most challenging calibration criterion, known as canonical calibration. Our approach advocates for a training-validation-testing pipeline when estimating a calibration error on an evaluation dataset. We demonstrate the effectiveness of our pipeline by optimizing existing calibration estimators and comparing them with novel kernel ridge regression-based estimators on standard image classification tasks",
    "checked": true,
    "id": "a5e75b07c5784490905884f05a893ba8b7f9d89e",
    "semantic_title": "optimizing estimators of squared calibration errors in classification",
    "citation_count": 2,
    "authors": [
      "Sebastian Gregor Gruber",
      "Francis R. Bach"
    ]
  },
  "https://openreview.net/forum?id=ZdMIXltJzK": {
    "title": "Reset-free Reinforcement Learning with World Models",
    "volume": "main",
    "abstract": "Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent's own autonomously acquired experience. However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments. To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision. We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance. MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states. It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision. Our findings suggest model-based methods hold significant promise for reducing human effort in RL. Website: https://yangzhao-666.github.io/morefree",
    "checked": true,
    "id": "783045d6f5577c715b9096a798b0e13b27d98033",
    "semantic_title": "reset-free reinforcement learning with world models",
    "citation_count": 0,
    "authors": [
      "Zhao Yang",
      "Thomas M. Moerland",
      "Mike Preuss",
      "Aske Plaat",
      "Edward S. Hu"
    ]
  },
  "https://openreview.net/forum?id=QIzRdjIWnS": {
    "title": "Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance",
    "volume": "main",
    "abstract": "This paper provides the first tight convergence analyses for RMSProp and Adam for non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. RMSProp is firstly analyzed, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to the dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\\epsilon$-stationary point with an iteration complexity of $\\mathcal O(\\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and the first-order momentum. We develop a new upper bound on the first-order term in the descent lemma, which is also a function of the gradient norm. We show that Adam with proper hyperparameters converges to an $\\epsilon$-stationary point with an iteration complexity of $\\mathcal O(\\epsilon^{-4})$. Our complexity results for both RMSProp and Adam match with the complexity lower bound established in Arjevani et al. (2023)",
    "checked": true,
    "id": "0891042c92766de7b962e8b4d80085b934e639ed",
    "semantic_title": "convergence guarantees for rmsprop and adam in generalized-smooth non-convex optimization with affine noise variance",
    "citation_count": 7,
    "authors": [
      "Qi Zhang",
      "Yi Zhou",
      "Shaofeng Zou"
    ]
  },
  "https://openreview.net/forum?id=UV58hNygne": {
    "title": "HoSNNs: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds",
    "volume": "main",
    "abstract": "While spiking neural networks (SNNs) offer a promising neurally-inspired model of computation, they are vulnerable to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to design a threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model and utilize TA-LIF neurons to construct the adversarially robust homeostatic SNNs (HoSNNs) for improved robustness. The TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, offering a local feedback control solution to the minimization of each neuron's membrane potential error caused by adversarial disturbance. Theoretical analysis demonstrates favorable dynamic properties of TA-LIF neurons in terms of the bounded-input bounded-output stability and suppressed time growth of membrane potential error, underscoring their superior robustness compared with the standard LIF neurons. When trained with weak FGSM attacks (\\(\\epsilon = 2/255\\)), our HoSNNs significantly outperform conventionally trained LIF-based SNNs across multiple datasets. Furthermore, under significantly stronger PGD7 attacks (\\(\\epsilon = 8/255\\)), HoSNN achieves notable improvements in accuracy, increasing from 30.90% to 74.91% on FashionMNIST, 0.44% to 36.82% on SVHN, 0.54% to 43.33% on CIFAR10, and 0.04% to 16.66% on CIFAR100",
    "checked": false,
    "id": "9025ffd1fd220cbbf4a91aa758662d17716dd345",
    "semantic_title": "hosnn: adversarially-robust homeostatic spiking neural networks with adaptive firing thresholds",
    "citation_count": 3,
    "authors": [
      "Hejia Geng",
      "Peng Li"
    ]
  },
  "https://openreview.net/forum?id=8Q4qxe9a9Z": {
    "title": "A Self-Explainable Heterogeneous GNN for Relational Deep Learning",
    "volume": "main",
    "abstract": "Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node's class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model's reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenarios",
    "checked": true,
    "id": "c253896381b6763981e83dc67a726b6e5e1b6d8f",
    "semantic_title": "a self-explainable heterogeneous gnn for relational deep learning",
    "citation_count": 3,
    "authors": [
      "Francesco Ferrini",
      "Antonio Longa",
      "Andrea Passerini",
      "Manfred Jaeger"
    ]
  },
  "https://openreview.net/forum?id=9NVJ0ZgEfT": {
    "title": "Long Short-Term Imputer: Handling Consecutive Missing Values in Time Series",
    "volume": "main",
    "abstract": "Encountered frequently in time series data, missing values can significantly impede time-series analysis. With the progression of deep learning, advanced imputation models delve into the temporal dependencies inherent in time series data, showcasing remarkable performance. This positions them as intuitive selections for time series imputation tasks which assume ``Miss Completely at Random''. Nonetheless, long-interval consecutive missing values may obstruct the model's ability to grasp long-term temporal dependencies, consequently hampering the efficacy of imputation performance. To tackle this challenge, we propose Long Short-term Imputer (LSTI) to impute consecutive missing values with different length of intervals. Long-term Imputer is designed using the idea of bi-directional autoregression. A forward prediction model and a backward prediction model are trained with a consistency regularization, which is designed to capture long-time dependency and can adapt to long-interval consecutive missing values. Short-term Imputer is designed to capture short-time dependency and can impute the short-interval consecutive missing values effectively. A meta-weighting network is then proposed to take advantage of the strengths of two imputers. As a result, LSTI can impute consecutive missing values with different intervals effectively. Experiments demonstrate that our approach, on average, reduces the error by 57.4% compared to state-of-the-art deep models across five datasets",
    "checked": true,
    "id": "6cc8979eea8ff9e93506e9344edb7bfdc5028053",
    "semantic_title": "long short-term imputer: handling consecutive missing values in time series",
    "citation_count": 0,
    "authors": [
      "Jiacheng You",
      "Xinyang Chen",
      "Yu Sun",
      "Weili Guan",
      "Liqiang Nie"
    ]
  },
  "https://openreview.net/forum?id=58gPkcVbFL": {
    "title": "Evolution of Discriminator and Generator Gradients in GAN Training: From Fitting to Collapse",
    "volume": "main",
    "abstract": "Generative Adversarial Networks (GANs) are powerful generative models but often suffer from mode mixture and mode collapse. We propose a perspective that views GAN training as a two-phase progression from fitting to collapse, where mode mixture and mode collapse are treated as inter-connected. Inspired by the particle model interpretation of GANs, we leverage the discriminator gradient to analyze particle movement and the generator gradient, specifically \"steepness,\" to quantify the severity of mode mixture by measuring the generator's sensitivity to changes in the latent space. Using these theoretical insights into evolution of gradients, we design a specialized metric that integrates both gradients to detect the transition from fitting to collapse. This metric forms the basis of an early stopping algorithm, which stops training at a point that retains sample quality and diversity. Experiments on synthetic and real-world datasets, including MNIST, Fashion MNIST, and CIFAR-10, validate our theoretical findings and demonstrate the effectiveness of the proposed algorithm",
    "checked": true,
    "id": "5bdea04f711d4eba59454025f1d262ef874b9c75",
    "semantic_title": "evolution of discriminator and generator gradients in gan training: from fitting to collapse",
    "citation_count": 0,
    "authors": [
      "Weiguo Gao",
      "Ming Li"
    ]
  },
  "https://openreview.net/forum?id=GkYOcbNLaW": {
    "title": "Cycle Conditioning for Robust Representation Learning from Categorical Data",
    "volume": "main",
    "abstract": "This paper introduces a novel diffusion-based method for learning representations from categorical data. Conditional diffusion models have demonstrated their potential to extract meaningful representations from input samples. However, they often struggle to yield versatile, general-purpose information, limiting their adaptability to unforeseen tasks. To address this, we propose a cycle conditioning approach for diffusion models, designed to capture expressive information from conditioning samples. However, cycle conditioning alone can be insufficient. Diffusion models may ignore conditioning samples that vary across training iterations, an issue that occurs within cycle conditioning. To counter this limitation, we introduce additional \"spelling\" information to guide the conditioning process, ensuring that the conditioning sample remains influential during denoising. While this supervision enhances the generalizability of extracted representations, it is constrained by the sparse nature of spelling information in categorical data, leading to sparse latent conditions. This sparsity reduces the robustness of the extracted representations for downstream tasks or as effective guidance in the diffusion process. To overcome this challenge, we propose a linear navigation strategy within the latent space of conditioning samples, allowing dense representations to be extracted even with sparse supervision. Our experiments demonstrate that our method achieves at least a 1.42\\% improvement in AUROC and a 4.12\\% improvement in AUCPR over the best results from existing state-of-the-art methods",
    "checked": true,
    "id": "a294fdf4cf109397ad4774c8a78f9d4f9d269581",
    "semantic_title": "cycle conditioning for robust representation learning from categorical data",
    "citation_count": 0,
    "authors": [
      "Mohsen Tabejamaat",
      "Farzaneh Etminani",
      "Mattias Ohlsson"
    ]
  },
  "https://openreview.net/forum?id=CrKMqRAhBo": {
    "title": "A Lean Dataset for International Math Olympiad: Small Steps towards Writing Math Proofs for Hard Problems",
    "volume": "main",
    "abstract": "Using AI to write formal proofs for mathematical problems is a challenging task that has seen some advancements in recent years. Automated systems such as Lean can verify the correctness of proofs written in formal language, yet writing the proofs in formal language can be challenging for humans and machines. The miniF2F benchmark has 20 IMO problems in its test set, yet formal proofs are available only for 6 of these problems (3 of which are only written by mathematicians). The model with best accuracy can only prove 2 of these 20 IMO problems, from 1950s and 60s, while its training set is a secret. In this work, we write complete, original formal proofs for the remaining IMO problems in Lean along with 3 extra problems from IMO 2022 and 2023. This effort expands the availability of proof currently in the public domain by creating 5,880 lines of Lean proof. The goal of the paper is to pave the way for developing AI models that can automatically write the formal proofs for all the IMO problems in miniF2F and beyond by providing an evaluation benchmark. In this pursuit, we devise a method to decompose the proofs of these problems into their building blocks, constructing a dataset of 1,329 lemmas with more than 40k lines of Lean code. These lemmas are not trivial, yet they are approachable, providing the opportunity to evaluate and diagnose the failures and successes of AI models. We evaluate the ability of the SOTA LLMs on our dataset and analyze their success and failure modes from different perspectives. Our dataset and code is available at: https://github.com/roozbeh-yz/IMO-Steps",
    "checked": true,
    "id": "616739238dbd02e4e748025a2d52044ad7865d36",
    "semantic_title": "a lean dataset for international math olympiad: small steps towards writing math proofs for hard problems",
    "citation_count": 3,
    "authors": [
      "Roozbeh Yousefzadeh",
      "Xuenan Cao"
    ]
  },
  "https://openreview.net/forum?id=HkmymFPODz": {
    "title": "Deep Active Learning in the Open World",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "9708fd28cd47d29bb5787c2fc0ec9714b17683c8",
    "semantic_title": "deep active learning in the open world",
    "citation_count": 3,
    "authors": [
      "Tian Xie",
      "Jifan Zhang",
      "Haoyue Bai",
      "Robert D Nowak"
    ]
  },
  "https://openreview.net/forum?id=J7cY9Jr9WM": {
    "title": "A Fused Gromov-Wasserstein Approach to Subgraph Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "d8e48c9295cfc1dd18b361d5ced7c7109e18fb50",
    "semantic_title": "a fused gromov-wasserstein approach to subgraph contrastive learning",
    "citation_count": 1,
    "authors": [
      "Amadou Siaka SANGARE",
      "Nicolas Dunou",
      "Jhony H. Giraldo",
      "Fragkiskos D. Malliaros"
    ]
  },
  "https://openreview.net/forum?id=bqMJToTkvT": {
    "title": "QPO: Query-dependent Prompt Optimization via Multi-Loop Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5ffa572d5126166a04b21ebb4e462016192297f3",
    "semantic_title": "qpo: query-dependent prompt optimization via multi-loop offline reinforcement learning",
    "citation_count": 2,
    "authors": [
      "Yilun Kong",
      "Hangyu Mao",
      "Zhao Qi",
      "Bin Zhang",
      "Jingqing Ruan",
      "Li Shen",
      "Yongzhe Chang",
      "Xueqian Wang",
      "Rui Zhao",
      "Dacheng Tao"
    ]
  },
  "https://openreview.net/forum?id=jRbKsQ3sYO": {
    "title": "Combating Inter-Task Confusion and Catastrophic Forgetting by Metric Learning and Re-Using a Past Trained Model",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "32be4582898f649a23bce8ccd9da78e5d6fcff54",
    "semantic_title": "combating inter-task confusion and catastrophic forgetting by metric learning and re-using a past trained model",
    "citation_count": 0,
    "authors": [
      "Sayedmoslem Shokrolahi",
      "IL MIN KIM"
    ]
  },
  "https://openreview.net/forum?id=prVLANCshF": {
    "title": "AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation",
    "volume": "main",
    "abstract": "This paper studies the vulnerabilities of transformer-based Large Language Models (LLMs) to jailbreaking attacks, focusing specifically on the optimization-based Greedy Coordinate Gradient (GCG) strategy. We first observe a positive correlation between the effectiveness of attacks and the internal behaviors of the models. For instance, attacks tend to be less effective when models pay more attention to system prompts designed to ensure LLM safety alignment. Building on this discovery, we introduce an enhanced method that manipulates models' attention scores to facilitate LLM jailbreaking, which we term AttnGCG. Empirically, AttnGCG shows consistent improvements in attack efficacy across diverse LLMs, achieving an average increase of ~7% in the Llama-2 series and ~10% in the Gemma series. Our strategy also demonstrates robust attack transferability against both unseen harmful goals and black-box LLMs like GPT-3.5 and GPT-4. Moreover, we note our attention-score visualization is more interpretable, allowing us to gain better insights into how our targeted attention manipulation facilitates more effective jailbreaking. We release the code at https://github.com/UCSC-VLAA/AttnGCG-attack",
    "checked": true,
    "id": "0d57a75e910ff4161da920f49a99ae703f947c61",
    "semantic_title": "attngcg: enhancing jailbreaking attacks on llms with attention manipulation",
    "citation_count": 9,
    "authors": [
      "Zijun Wang",
      "Haoqin Tu",
      "Jieru Mei",
      "Bingchen Zhao",
      "Yisen Wang",
      "Cihang Xie"
    ]
  },
  "https://openreview.net/forum?id=IaUh7CSD3k": {
    "title": "Metalearning Continual Learning Algorithms",
    "volume": "main",
    "abstract": "General-purpose learning systems should improve themselves in open-ended fashion in ever-changing environments. Conventional learning algorithms for neural networks, however, suffer from catastrophic forgetting (CF), i.e., previously acquired skills are forgotten when a new task is learned. Instead of hand-crafting new algorithms for avoiding CF, we propose Automated Continual Learning (ACL) to train self-referential neural networks to metalearn their own in-context continual (meta)learning algorithms. ACL encodes continual learning (CL) desiderata---good performance on both old and new tasks---into its metalearning objectives. Our experiments demonstrate that ACL effectively resolves \"in-context catastrophic forgetting,\" a problem that naive in-context learning algorithms suffer from; ACL learned algorithms outperform both hand-crafted learning algorithms and popular meta-continual learning methods on the Split-MNIST benchmark in the replay-free setting, and enables continual learning of diverse tasks consisting of multiple standard image classification datasets. We also discuss the current limitations of in-context CL by comparing ACL with state-of-the-art CL methods that leverage pre-trained models. Overall, we bring several novel perspectives into the long-standing problem of CL",
    "checked": true,
    "id": "087bca53cc05ccdba9b481cbfb11569ca80f32f4",
    "semantic_title": "metalearning continual learning algorithms",
    "citation_count": 3,
    "authors": [
      "Kazuki Irie",
      "Róbert Csordás",
      "Jürgen Schmidhuber"
    ]
  },
  "https://openreview.net/forum?id=CAkt3DsAZs": {
    "title": "Meta-Learning for Graphs with Heterogeneous Node Attribute Spaces for Few-Shot Edge Predictions",
    "volume": "main",
    "abstract": "Prediction of edges between nodes in graph data is useful for many applications, such as social network analysis and knowledge graph completion. Existing graph neural network-based approaches have achieved notable advancements, but encounter significant difficulty in building an effective model when there is an insufficient number of known edges in graphs. Although some meta-learning approaches were introduced to solve this problem, having an assumption that the nodes of training graphs and test graphs are in homogeneous attribute spaces, which limits the flexibility of applications. In this paper, we proposed a meta-learning method for edge prediction that can learn from graphs with nodes in heterogeneous attribute spaces. The proposed model consists of attribute-wise message-passing networks that transform information between connected nodes for each attribute, resulting in attribute-specific node embeddings. The node embeddings are obtained by calculating the mean of the attribute-specific node embeddings.The encoding operation can be repeated multiple times to capture complex patterns. The attribute-wise message-passing networks are shared across all graphs, allowing knowledge transfer between different graphs.The probabilities of edges are estimated by the Euclidian distance between node embeddings. Experimental results on 14 real-world data sets demonstrate that the proposed method outperforms existing methods in edge prediction problems with sparse edge information",
    "checked": true,
    "id": "3eeb187ff516fb8b1dd6b13fd79ec2f0382bf4b9",
    "semantic_title": "meta-learning for graphs with heterogeneous node attribute spaces for few-shot edge predictions",
    "citation_count": 0,
    "authors": [
      "Zhong Chuang",
      "Yusuke Tanaka",
      "Tomoharu Iwata"
    ]
  },
  "https://openreview.net/forum?id=jJOVpnNrEp": {
    "title": "Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics",
    "volume": "main",
    "abstract": "Natural language is often the easiest and most convenient modality for humans to specify tasks for robots. However, learning to ground language to behavior typically requires impractical amounts of diverse, language-annotated demonstrations collected on each target robot. In this work, we aim to separate the problem of what to accomplish from how to accomplish it, as the former can benefit from substantial amounts of external observation-only data, and only the latter depends on a specific robot embodiment. To this end, we propose Video-Language Critic, a reward model that can be trained on readily available cross-embodiment data using contrastive learning and a temporal ranking objective, and use it to score behavior traces from a separate actor. When trained on Open X-Embodiment data, our reward model enables 2x more sample-efficient policy training on Meta-World tasks than a sparse reward only, despite a significant domain gap. Using in-domain data but in a challenging task generalization setting on Meta-World, we further demonstrate more sample-efficient training than is possible with prior language-conditioned reward models that are either trained with binary classification, use static images, or do not leverage the temporal information present in video data",
    "checked": true,
    "id": "b96d979e0a4c3127907c5dba170a3470f9ff8956",
    "semantic_title": "video-language critic: transferable reward functions for language-conditioned robotics",
    "citation_count": 1,
    "authors": [
      "Minttu Alakuijala",
      "Reginald McLean",
      "Isaac Woungang",
      "Nariman Farsad",
      "Samuel Kaski",
      "Pekka Marttinen",
      "Kai Yuan"
    ]
  },
  "https://openreview.net/forum?id=2Zan4ATYsh": {
    "title": "DivIL: Unveiling and Addressing Over-Invariance for Out-of- Distribution Generalization",
    "volume": "main",
    "abstract": "Out-of-distribution generalization is a common problem that expects the model to perform well in the different distributions even far from the train data. A popular approach to addressing this issue is invariant learning (IL), in which the model is compiled to focus on invariant features instead of spurious features by adding strong constraints during training. However, there are some potential pitfalls of strong invariant constraints. Due to the limited number of diverse environments and over-regularization in the feature space, it may lead to a loss of important details in the invariant features while alleviating the spurious correlations, namely the over-invariance, which can also degrade the generalization performance. We theoretically define the over-invariance and observe that this issue occurs in various classic IL methods. To alleviate this issue, we propose a simple approach Diverse Invariant Learning (DivIL) by adding the unsupervised contrastive learning and the random masking mechanism compensatory for the invariant constraints, which can be applied to various IL methods. Furthermore, we conduct experiments across multiple modalities across 12 datasets and 6 classic models, verifying our over-invariance insight and the effectiveness of our DivIL framework. Our code is available at https://github.com/kokolerk/DivIL",
    "checked": true,
    "id": "d410f37fcb58d4b2712aeffc02a876a0e1d04aaa",
    "semantic_title": "divil: unveiling and addressing over-invariance for out-of- distribution generalization",
    "citation_count": 1,
    "authors": [
      "Jiaqi WANG",
      "Yuhang Zhou",
      "Zhixiong Zhang",
      "Qiguang Chen",
      "Yongqiang Chen",
      "James Cheng"
    ]
  },
  "https://openreview.net/forum?id=k4AxEwTaHq": {
    "title": "FaAlGrad: Fairness through Alignment of Gradients across Different Subpopulations",
    "volume": "main",
    "abstract": "The growing deployment of Machine Learning systems has increased interest in systems optimized for other important criteria along with the expected task performance. For instance, machine learning models often exhibit biases that lead to unfair outcomes for certain protected subpopulations. This work aims to handle the bias in machine learning models and enhance their fairness by aligning the loss gradients. Specifically, leveraging the meta-learning technique, we propose a novel training framework that aligns the gradients computed across different subpopulations for learning fair classifiers. Aligning the gradients enables our framework to regularize the training process, thereby prioritizing fairness over predictive accuracy. Our experiments on multiple benchmark datasets demonstrate significant improvements in fairness metrics without having any exclusive regularizers for fairness. Thus our work contributes to developing fairer machine learning models with broader societal benefits",
    "checked": true,
    "id": "3980bd94e9e1f54c0366a4ef003b4866cb2b44f0",
    "semantic_title": "faalgrad: fairness through alignment of gradients across different subpopulations",
    "citation_count": 1,
    "authors": [
      "Nikita Malik",
      "Konda Reddy Mopuri"
    ]
  },
  "https://openreview.net/forum?id=xXs2GKXPnH": {
    "title": "Faster Diffusion Through Temporal Attention Decomposition",
    "volume": "main",
    "abstract": "We explore the role of the attention mechanism during inference in text-conditional diffusion models. Empirical observations suggest that cross-attention outputs converge to a fixed point after several inference steps. The convergence time naturally divides the entire inference process into two phases: an initial phase for planning text-oriented visual semantics, which are then translated into images in a subsequent fidelity-improving phase. Cross-attention is essential in the initial phase but almost irrelevant thereafter. Self-attention, however, initially plays a minor role but becomes increasingly important in the second phase. These findings yield a simple and training-free method called TGATE which efficiently generates images by caching and reusing attention outputs at scheduled time steps. Experiments show TGATE's broad applicability to various existing text-conditional diffusion models which it speeds up by 10-50%. The code of TGATE is available at https://github.com/HaozheLiu-ST/T-GATE",
    "checked": true,
    "id": "94f79284e6e867bacf82c072f65ac57d3ce0df4c",
    "semantic_title": "faster diffusion through temporal attention decomposition",
    "citation_count": 2,
    "authors": [
      "Haozhe Liu",
      "Wentian Zhang",
      "Jinheng Xie",
      "Francesco Faccio",
      "Mengmeng Xu",
      "Tao Xiang",
      "Mike Zheng Shou",
      "Juan-Manuel Perez-Rua",
      "Jürgen Schmidhuber"
    ]
  },
  "https://openreview.net/forum?id=Za9Tm07fig": {
    "title": "TACO Vision Models Can Be Efficiently Specialized via Few-Shot Task-Aware Compression",
    "volume": "main",
    "abstract": "Recent vision architectures and self-supervised training methods have enabled training computer vision models that are extremely accurate, but come with massive computational costs. In settings such as identifying species in camera traps in the field, users have limited resources, and may fine-tune a pretrained model on (often limited) data from a small set of specific categories of interest. Such users may still wish to make use of highly-accurate large models, but are often constrained by the computational cost. To address this, we ask: can we quickly compress generalist models into accurate and efficient specialists given a small amount of data? Towards this goal, we propose a simple and versatile technique, which we call Few-Shot Task-Aware COmpression (TACO). Given a general-purpose model pretrained on a broad task, such as classification on ImageNet or iNaturalist datasets with thousands of categories, TACO produces a much smaller model that is accurate on specialized tasks, such as classifying across vehicle types or animal species, based only on a few examples from each target class. The method is based on two key insights - 1) a powerful specialization effect for data-aware compression, which we showcase for the first time; 2) a dedicated finetuning procedure with knowledge distillation, which prevents overfitting even in scenarios where data is very scarce. Specifically, TACO is applied in few-shot fashion, i.e. only a few task-specific samples are used for compression, and the procedure has low computational overhead. We validate this approach experimentally using highly-accurate ResNet, ViT/DeiT, and ConvNeXt models, originally trained on ImageNet and iNaturalist datasets, which we specialize and compress to a diverse set of ``downstream'' subtasks, with notable computational speedups on both CPU and GPU",
    "checked": true,
    "id": "39a722d27959221fb35b3993d45b266895630fea",
    "semantic_title": "taco vision models can be efficiently specialized via few-shot task-aware compression",
    "citation_count": 0,
    "authors": [
      "Denis Kuznedelev",
      "Soroush Tabesh",
      "Kimia Noorbakhsh",
      "Elias Frantar",
      "Sara Beery",
      "Eldar Kurtic",
      "Dan Alistarh"
    ]
  },
  "https://openreview.net/forum?id=XPREcQlAM0": {
    "title": "Global Convergence Rate of Deep Equilibrium Models with General Activations",
    "volume": "main",
    "abstract": "In a recent paper, Ling et al. investigated the over-parametrized Deep Equilibrium Model (DEQ) with ReLU activation. They proved that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. This paper shows that this fact still holds for DEQs with any general activation that has bounded first and second derivatives. Since the new activation function is generally non-homogeneous, bounding the least eigenvalue of the Gram matrix of the equilibrium point is particularly challenging. To accomplish this task, we need to create a novel population Gram matrix and develop a new form of dual activation with Hermite polynomial expansion",
    "checked": true,
    "id": "b508a57b7faf7fb92f05636fd748326ac085ca5a",
    "semantic_title": "global convergence rate of deep equilibrium models with general activations",
    "citation_count": 2,
    "authors": [
      "Lan V. Truong"
    ]
  },
  "https://openreview.net/forum?id=ZckLMG00sO": {
    "title": "Stability-Aware Training of Machine Learning Force Fields with Differentiable Boltzmann Estimators",
    "volume": "main",
    "abstract": "Machine learning force fields (MLFFs) are an attractive alternative to ab-initio methods for molecular dynamics (MD) simulations. However, they can produce unstable simulations, limiting their ability to model phenomena occurring over longer timescales and compromising the quality of estimated observables. To address these challenges, we present Stability-Aware Boltzmann Estimator (StABlE) Training, a multi-modal training procedure which leverages joint supervision from reference quantum-mechanical calculations and system observables. StABlE Training iteratively runs many MD simulations in parallel to seek out unstable regions, and corrects the instabilities via supervision with a reference observable. We achieve efficient end-to-end automatic differentiation through MD simulations using our Boltzmann Estimator, a generalization of implicit differentiation techniques to a broader class of stochastic algorithms. Unlike existing techniques based on active learning, our approach requires no additional ab-initio energy and forces calculations to correct instabilities. We demonstrate our methodology across organic molecules, tetrapeptides, and condensed phase systems, using three modern MLFF architectures. StABlE-trained models achieve significant improvements in simulation stability, data efficiency, and agreement with reference observables. Crucially, the stability improvements cannot be matched by simply reducing the simulation timestep, meaning that StABlE Training effectively allows for larger timesteps in MD simulations. By incorporating observables into the training process alongside first-principles calculations, StABlE Training can be viewed as a general semi-empirical framework applicable across MLFF architectures and systems. This makes it a powerful tool for training stable and accurate MLFFs, particularly in the absence of large reference datasets. Our code is publicly available at https://github.com/ASK-Berkeley/StABlE-Training",
    "checked": true,
    "id": "93d6ac8afaf3ff7832e0011511aacc15a980e6e4",
    "semantic_title": "stability-aware training of machine learning force fields with differentiable boltzmann estimators",
    "citation_count": 5,
    "authors": [
      "Sanjeev Raja",
      "Ishan Amin",
      "Fabian Pedregosa",
      "Aditi S. Krishnapriyan"
    ]
  },
  "https://openreview.net/forum?id=6jTQrr3APY": {
    "title": "Fair principal component analysis (PCA): minorization-maximization algorithms for Fair PCA, Fair Robust PCA and Fair Sparse PCA",
    "volume": "main",
    "abstract": "In this paper we propose a new iterative algorithm to solve the fair PCA (FPCA) problem. We start with the max-min fair PCA formulation originally proposed in \\cite{samadi1} and derive a simple and efficient iterative algorithm which is based on the minorization-maximization (MM) approach. The proposed algorithm relies on the relaxation of a semi-orthogonality constraint which is proved to be tight at every iteration of the algorithm. The vanilla version of the proposed algorithm requires solving a semi-definite program (SDP) at every iteration, which can be further simplified to a quadratic program by formulating the dual of the surrogate maximization problem. We also propose two important reformulations of the fair PCA problem: a) fair robust PCA - which can handle outliers in the data, and b) fair sparse PCA - which can enforce sparsity on the estimated fair principal components. The proposed algorithms are computationally efficient and monotonically increase their respective design objectives at every iteration. An added feature of the proposed algorithms is that they do not require the selection of any hyperparameter (except for the fair sparse PCA case where a penalty parameter that controls the sparsity has to be chosen by the user). We numerically compare the performance of the proposed methods with two of the state-of-the-art approaches on synthetic data sets and real-life data sets",
    "checked": true,
    "id": "001301f34e79cca46f56bc203f80889fd54757df",
    "semantic_title": "fair principal component analysis (pca): minorization-maximization algorithms for fair pca, fair robust pca and fair sparse pca",
    "citation_count": 5,
    "authors": [
      "Prabhu babu",
      "Petre Stoica",
      "Astha Saini"
    ]
  },
  "https://openreview.net/forum?id=EWT4GxjGDS": {
    "title": "Producers Equilibria and Dynamics in Engagement-Driven Recommender Systems",
    "volume": "main",
    "abstract": "Online platforms such as YouTube, Instagram heavily rely on recommender systems to decide what content to present to users. Producers, in turn, often create content that is likely to be recommended to users and have users engage with it. To do so, producers try to align their content with the preferences of their targeted user base. In this work, we explore the equilibrium behavior of producers who are interested in maximizing user engagement. We study two variants of the content-serving rule for the platform's recommender system, and provide a structural characterization of producer behavior at equilibrium: namely, each producer chooses to focus on a single embedded feature. We further show that specialization, defined as different producers optimizing for distinct types of content, naturally emerges from the competition among producers trying to maximize user engagement. We provide a heuristic for computing equilibria of our engagement game, and evaluate it experimentally. We highlight i) the performance and convergence of our heuristic, ii) the degree of producer specialization, and iii) the impact of the content-serving rule on producer and user utilities at equilibrium and provide guidance on how to set the content-serving rule",
    "checked": true,
    "id": "647a71fe805d06f96f510a2653aa96edb459c849",
    "semantic_title": "producers equilibria and dynamics in engagement-driven recommender systems",
    "citation_count": 3,
    "authors": [
      "Krishna Acharya",
      "Juba Ziani",
      "Jingyan Wang",
      "Varun Vangala"
    ]
  },
  "https://openreview.net/forum?id=dvRysCqmYQ": {
    "title": "Balanced Mixed-Type Tabular Data Synthesis with Diffusion Models",
    "volume": "main",
    "abstract": "Diffusion models have emerged as a robust framework for various generative tasks, including tabular data synthesis. However, current tabular diffusion models tend to inherit bias in the training dataset and generate biased synthetic data, which may influence discriminatory actions. In this research, we introduce a novel tabular diffusion model that incorporates sensitive guidance to generate fair synthetic data with balanced joint distributions of the target label and sensitive attributes, such as sex and race. The empirical results demonstrate that our method effectively mitigates bias in training data while maintaining the quality of the generated samples. Furthermore, we provide evidence that our approach outperforms existing methods for synthesizing tabular data on fairness metrics such as demographic parity ratio and equalized odds ratio, achieving improvements of over $10\\%$. Our implementation is available at https://github.com/comp-well-org/fair-tab-diffusion",
    "checked": true,
    "id": "3e8add053702c5b12a337a16af9a81631e310082",
    "semantic_title": "balanced mixed-type tabular data synthesis with diffusion models",
    "citation_count": 10,
    "authors": [
      "Zeyu Yang",
      "Han Yu",
      "Peikun Guo",
      "Khadija Zanna",
      "Xiaoxue Yang",
      "Akane Sano"
    ]
  },
  "https://openreview.net/forum?id=zSK81A2hxQ": {
    "title": "A Neural Material Point Method for Particle-based Emulation",
    "volume": "main",
    "abstract": "Mesh-free Lagrangian methods are widely used for simulating fluids, solids, and their complex interactions due to their ability to handle large deformations and topological changes. These physics simulators, however, require substantial computational resources for accurate simulations. To address these issues, deep learning emulators promise faster and scalable simulations, yet they often remain expensive and difficult to train, limiting their practical use. Inspired by the Material Point Method (MPM), we present NeuralMPM, a neural framework for particle-based emulation. NeuralMPM interpolates Lagrangian particles onto a fixed-size grid, computes updates on grid nodes using image-to-image neural networks, and interpolates back to the particles. Similarly to MPM, NeuralMPM benefits from the regular voxelized representation to simplify the computation of the state dynamics, while avoiding the drawbacks of mesh-based Eulerian methods. We demonstrate the advantages of NeuralMPM on 6 datasets, including fluid dynamics and fluid-solid interactions simulated with MPM and Smoothed Particles Hydrodynamics (SPH). Compared to GNS and DMCF, NeuralMPM reduces training time from 10 days to 15 hours, memory consumption by 10x-100x, and increases inference speed by 5x-10x, while achieving comparable or superior long-term accuracy, making it a promising approach for practical forward and inverse problems. A project page is available at https://neuralmpm.isach.be/",
    "checked": false,
    "id": "abde52d8d682cbbeae4fd8232751ae415144b21f",
    "semantic_title": "a neural material point method for particle-based simulations",
    "citation_count": 1,
    "authors": [
      "Omer Rochman-Sharabi",
      "Sacha Lewin",
      "Gilles Louppe"
    ]
  },
  "https://openreview.net/forum?id=0RJvZY0h6O": {
    "title": "Lognormal Mutations and their Use in Detecting Surreptitious Fake Images",
    "volume": "main",
    "abstract": "In many cases, adversarial attacks against fake detectors employ algorithms specifically crafted for automatic image classifiers. These algorithms perform well, thanks to an excellent ad hoc distribution of initial attacks. However, these attacks are easily detected due to their specific initial distribution. Consequently, we explore alternative black-box attacks inspired by generic black-box optimization tools, particularly focusing on the \\lognormal{} algorithm that we successfully extend to attack fake detectors. Moreover, we demonstrate that this attack evades detection by neural networks trained to flag classical adversarial examples. Therefore, we train more general models capable of identifying a broader spectrum of attacks, including classical black-box attacks designed for images, black-box attacks driven by classical optimization, and no-box attacks. By integrating these attack detection capabilities with fake detectors, we develop more robust and effective fake detection systems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Olivier Teytaud",
      "Mariia Zameshina",
      "Tom Sander",
      "Pierre Fernandez",
      "Furong Ye",
      "Laurent Najman",
      "Thomas Bäck",
      "Ismail Labiad"
    ]
  },
  "https://openreview.net/forum?id=k3Ab6RuJE9": {
    "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models",
    "volume": "main",
    "abstract": "Motivated by the progress of large language models (LLMs), we introduce the framework of verbalized machine learning (VML). In contrast to conventional machine learning (ML) models that are typically optimized over a continuous parameter space, VML constrains the parameter space to be human-interpretable natural language. Such a constraint leads to a new perspective of function approximation, where an LLM with a text prompt can be viewed as a function parameterized by the text prompt. Guided by this perspective, we revisit classical ML problems, such as regression and classification, and find that these problems can be solved by an LLM-parameterized learner and optimizer. The major advantages of VML include (1) easy encoding of inductive bias: prior knowledge about the problem and hypothesis class can be encoded in natural language and fed into the LLM-parameterized learner; (2) automatic model class selection: the optimizer can automatically select a model class based on data and verbalized prior knowledge, and it can update the model class during training; and (3) interpretable learner updates: the LLM-parameterized optimizer can provide explanations for why an update is performed. We empirically verify the effectiveness of VML, and hope that VML can serve as a stepping stone to stronger interpretability",
    "checked": true,
    "id": "1d25d6245b30a5437ec98f923e104f81923e8115",
    "semantic_title": "verbalized machine learning: revisiting machine learning with language models",
    "citation_count": 0,
    "authors": [
      "Tim Z. Xiao",
      "Robert Bamler",
      "Bernhard Schölkopf",
      "Weiyang Liu"
    ]
  },
  "https://openreview.net/forum?id=fC4bh1PmZr": {
    "title": "Counterfactual Learning of Stochastic Policies with Continuous Actions",
    "volume": "main",
    "abstract": "Counterfactual reasoning from logged data has become increasingly important for many applications such as web advertising or healthcare. In this paper, we address the problem of learning stochastic policies with continuous actions from the viewpoint of counterfactual risk minimization (CRM). While the CRM framework is appealing and well studied for discrete actions, the continuous action case raises new challenges about modelization, optimization, and~offline model selection with real data which turns out to be particularly challenging. Our paper contributes to these three aspects of the CRM estimation pipeline. First, we introduce a modelling strategy based on a joint kernel embedding of contexts and actions, which overcomes the shortcomings of previous discretization approaches. Second, we empirically show that the optimization aspect of counterfactual learning is important, and we demonstrate the benefits of proximal point algorithms and smooth estimators. Finally, we propose an evaluation protocol for offline policies in real-world logged systems, which is challenging since policies cannot be replayed on test data, and we release a new large-scale dataset along with multiple synthetic, yet realistic, evaluation setups",
    "checked": false,
    "id": "09903d22a0f8197dde0e85431d67b9f889833ad9",
    "semantic_title": "acter: diverse and actionable counterfactual sequences for explaining and diagnosing rl policies",
    "citation_count": 2,
    "authors": [
      "Houssam Zenati",
      "Alberto Bietti",
      "Matthieu Martin",
      "Eustache Diemert",
      "Pierre Gaillard",
      "Julien Mairal"
    ]
  },
  "https://openreview.net/forum?id=Vwgjk5ysWn": {
    "title": "Why is constrained neural language generation particularly challenging?",
    "volume": "main",
    "abstract": "Recent advances in deep neural language models combined with the capacity of large scale datasets have accelerated the development of natural language generation systems that produce fluent and coherent texts (to various degrees of success) in a multitude of tasks and application contexts. However, controlling the output of these models for desired user and task needs is still an open challenge. This is crucial not only to customizing the content and style of the generated language, but also to their safe and reliable deployment in the real world. We present an extensive survey on the emerging topic of constrained neural language generation in which we formally define and categorize the problems of natural language generation by distinguishing between conditions and constraints (the latter being testable conditions on the output text instead of the input), present constrained text generation tasks, and review existing methods and evaluation metrics for constrained text generation. Our aim is to highlight recent progress and trends in this emerging field, informing on the most promising directions and limitations towards advancing the state-of-the-art of constrained neural language generation research",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cristina Garbacea",
      "Qiaozhu Mei"
    ]
  },
  "https://openreview.net/forum?id=K6CvWPtF62": {
    "title": "Provable Quantum Algorithm Advantage for Gaussian Process Quadrature",
    "volume": "main",
    "abstract": "The aim of this paper is to develop novel quantum algorithms for Gaussian process quadrature methods. Gaussian process quadratures are numerical integration methods where Gaussian processes are used as functional priors for the integrands to capture the uncertainty arising from the sparse function evaluations. Quantum computers have emerged as potential replacements for classical computers, offering exponential reductions in the computational complexity of machine learning tasks. In this paper, we combine Gaussian process quadrature and quantum computing by proposing a quantum low-rank Gaussian process quadrature method based on a Hilbert space approximation of the Gaussian process kernel and enhancing the quadrature using a quantum circuit. The method combines the quantum phase estimation algorithm with the quantum principal component analysis technique to extract information up to a desired rank. Then, Hadamard and SWAP tests are implemented to find the expected value and variance that determines the quadrature. We use numerical simulations of a quantum computer to demonstrate the effectiveness of the method. Furthermore, we provide a theoretical complexity analysis that shows a polynomial advantage over classical Gaussian process quadrature methods. The code is available at https://github.com/cagalvisf/Quantum_HSGPQ",
    "checked": true,
    "id": "53b7d61455f132662dcf7d151326702aea4ee03a",
    "semantic_title": "provable quantum algorithm advantage for gaussian process quadrature",
    "citation_count": 0,
    "authors": [
      "Cristian A. Galvis-Florez",
      "Ahmad Farooq",
      "Simo Särkkä"
    ]
  },
  "https://openreview.net/forum?id=ojeCoOKwWp": {
    "title": "Differentially Private Source-Target Clustering",
    "volume": "main",
    "abstract": "We consider a new private variant of the Source-Target Clustering (STC) setting, which was introduced by de Mathelin et al. (2022). In STC, there is a target dataset that needs to be clustered by selecting centers, in addition to centers that are already provided in a separate source dataset. The goal is to select centers from the target, such that the target clustering cost given the additional source centers is minimized. We consider private STC, in which the source dataset is private and should only be used under the constraint of differential privacy. This is motivated by scenarios in which the existing centers are private, for instance because they represent individuals in a social network. We derive lower bounds for the private STC objective, illustrating the theoretical limitations on worst-case guarantees for this setting. We then present a differentially private algorithm with asymptotically advantageous results under a data-dependent analysis, in which the guarantee depends on properties of the dataset, as well as more practical variants. We demonstrate in experiments the reduction in clustering cost that is obtained by our practical algorithms compared to baseline approaches",
    "checked": true,
    "id": "05b0b6ec3e56878b8a804af59be3fabeaae1f943",
    "semantic_title": "differentially private source-target clustering",
    "citation_count": 0,
    "authors": [
      "Shachar Schnapp",
      "Sivan Sabato"
    ]
  },
  "https://openreview.net/forum?id=WxHTSPS2pi": {
    "title": "Uncertainty-Based Experience Replay for Task-Agnostic Continual Reinforcement Learning",
    "volume": "main",
    "abstract": "Model-based reinforcement learning uses a learned dynamics model to imagine actions and select those with the best expected outcomes. An experience replay buffer collects the outcomes of all actions executed in the environment, which is then used to iteratively train the dynamics model. However, as the complexity and scale of tasks increase, training times and memory requirements can grow drastically without necessarily retaining useful experiences. Continual learning proposes a more realistic scenario where tasks are learned in sequence, and the replay buffer can help mitigate catastrophic forgetting. However, it is not realistic to expect the buffer to infinitely grow as the sequence advances. Furthermore, storing every single experience executed in the environment does not necessarily provide a more accurate model. We argue that the replay buffer needs to have the minimal necessary size to retain relevant experiences that cover both common and rare states. Therefore, we propose using an uncertainty-based replay buffer filtering to enable an effective implementation of continual learning agents using model-based reinforcement learning. We show that the combination of the proposed strategies leads to reduced training times, smaller replay buffer size, and less catastrophic forgetting, all while maintaining performance",
    "checked": true,
    "id": "f69f38c22d38f913e96ac316006d8f74917c98e3",
    "semantic_title": "uncertainty-based experience replay for task-agnostic continual reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Adrian Remonda",
      "Cole Corbitt Terrell",
      "Eduardo E. Veas",
      "Marc Masana"
    ]
  },
  "https://openreview.net/forum?id=E2zKNuwNDc": {
    "title": "Robust Preference Optimization through Reward Model Distillation",
    "volume": "main",
    "abstract": "Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations. Direct Preference Optimization (DPO) is a popular offline alignment method that trains a policy directly on preference data without the need to train a reward model or apply reinforcement learning. However, the empirical evidence suggests that DPO typically assigns implicit rewards that overfit, and trend towards infinite magnitude. This frequently leads to degenerate policies, sometimes causing even the probabilities of the preferred generations to go to zero. In this work, we analyze this phenomenon and use distillation to get a better proxy for the true preference distribution over generation pairs: we train the LM such that its induced implicit reward, i.e., the scaled log-likelihood ratio of the model to the reference model, matches an explicit reward model trained on the preference data. Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models that, as a whole, is likely to include at least one reasonable proxy for the preference distribution. Our results show that distilling from such a family of reward models leads to improved robustness to distribution shift in preference annotations, while preserving the simple supervised nature of DPO",
    "checked": true,
    "id": "5c9eec060bd9b7af1b8f71a18c0402de3dc98388",
    "semantic_title": "robust preference optimization through reward model distillation",
    "citation_count": 37,
    "authors": [
      "Adam Fisch",
      "Jacob Eisenstein",
      "Vicky Zayats",
      "Alekh Agarwal",
      "Ahmad Beirami",
      "Chirag Nagpal",
      "Peter Shaw",
      "Jonathan Berant"
    ]
  },
  "https://openreview.net/forum?id=6LO1y8ZE0F": {
    "title": "SimPLR: A Simple and Plain Transformer for Efficient Object Detection and Segmentation",
    "volume": "main",
    "abstract": "The ability to detect objects in images at varying scales has played a pivotal role in the design of modern object detectors. Despite considerable progress in removing hand-crafted components and simplifying the architecture with transformers, multi-scale feature maps and pyramid designs remain a key factor for their empirical success. In this paper, we show that shifting the multiscale inductive bias into the attention mechanism can work well, resulting in a plain detector ‘SimPLR' whose backbone and detection head are both non-hierarchical and operate on single-scale features. We find through our experiments that SimPLR with scale-aware attention is plain and simple architecture, yet competitive with multi-scale vision transformer alternatives. Compared to the multi-scale and single-scale state-of-the-art, our model scales better with bigger capacity (self-supervised) models and more pre-training data, allowing us to report a consistently better accuracy and faster runtime for object detection, instance segmentation, as well as panoptic segmentation. Code is released at \\url{https://github.com/kienduynguyen/SimPLR}",
    "checked": true,
    "id": "58dca97fc9ae4b701669d07e921fd2bfd91582e8",
    "semantic_title": "simplr: a simple and plain transformer for efficient object detection and segmentation",
    "citation_count": 0,
    "authors": [
      "Duy Kien Nguyen",
      "Martin R. Oswald",
      "Cees G. M. Snoek"
    ]
  },
  "https://openreview.net/forum?id=TnT59yz7lc": {
    "title": "Exploiting Benford's Law for Weight Regularization of Deep Neural Networks",
    "volume": "main",
    "abstract": "Stochastic learning of Deep Neural Network (DNN) parameters is highly sensitive to training strategy, hyperparameters, and available training data. Many state-of-the-art solutions use weight regularization to adjust parameter distributions, prevent overfitting, and support generalization of DNNs. None of the existing regularization techniques have ever exploited a typical distribution of numerical datasets with respect to the first non-zero (or significant) digit, called Benford's Law (BL). In this paper, we show that the deviation of the significant digit distribution of the DNN weights from BL is closely related to the generalization of the DNN. In particular, when the DNN is presented with limited training data. To take advantage of this finding, we use BL to target the weight regularization of DNNs. Extensive experiments are performed on image, table, and speech data, considering convolutional (CNN) and Transformer-based neural network architectures with varying numbers of parameters. We show that the performance of DNNs is improved by minimizing the distance between the significant digit distributions of the DNN weights and the BL distribution along with L2 regularization. The improvements depend on the network architecture and how it deals with limited data. However, the proposed penalty term improves consistently and some CNN-based architectures gain up to $15\\%$ test accuracy over the default training scheme with L2 regularization on subsets of CIFAR 100",
    "checked": true,
    "id": "6a3ca23d87b7864b02616f6ce13c7cc976e4c6d6",
    "semantic_title": "exploiting benford's law for weight regularization of deep neural networks",
    "citation_count": 0,
    "authors": [
      "Julius Ott",
      "Huawei Sun",
      "Enrico Rinaldi",
      "Gianfranco Mauro",
      "Lorenzo Servadei",
      "Robert Wille"
    ]
  },
  "https://openreview.net/forum?id=rWSiBknwQa": {
    "title": "Are Large Language Models Really Robust to Word-Level Perturbations?",
    "volume": "main",
    "abstract": "The swift advancement in the scales and capabilities of Large Language Models (LLMs) positions them as promising tools for a variety of downstream tasks. In addition to the pursuit of better performance and the avoidance of violent feedback on a certain prompt, to ensure the responsibility of the LLMs, much attention is drawn to the robustness of LLMs. However, existing evaluation methods mostly rely on traditional question answering datasets with predefined supervised labels, potentially ignoring the superior generation capabilities of contemporary LLMs. To investigate the robustness of LLMs while using their generation ability, we propose a novel rational evaluation pipeline that leverages reward models as diagnostic tools to evaluate the long conversation generated from more challenging open questions by LLMs, which we refer to as the Reward Model for Reasonable Robustness Evaluation (TREvaL). Longer conversations manifest the comprehensive grasp of language models in terms of their proficiency in understanding questions, a capability not entirely encompassed by individual words or letters.Our extensive empirical experiments demonstrate that TREvaL provides an identification for the lack of robustness of nowadays LLMs.Notably, we are surprised to discover that robustness tends to decrease as fine-tuning (SFT and RLHF) is conducted, calling for more attention on the robustness during alignment process",
    "checked": true,
    "id": "57207b935fc3484d175f5e9e2980d73ca793f994",
    "semantic_title": "are large language models really robust to word-level perturbations?",
    "citation_count": 24,
    "authors": [
      "Haoyu Wang",
      "Guozheng Ma",
      "Cong Yu",
      "Ning Gui",
      "Linrui Zhang",
      "Zhiqi Huang",
      "Suwei Ma",
      "Yongzhe Chang",
      "Sen Zhang",
      "Li Shen",
      "Xueqian Wang",
      "Peilin Zhao",
      "Dacheng Tao"
    ]
  },
  "https://openreview.net/forum?id=42v6I5Ut9a": {
    "title": "Single-pass Detection of Jailbreaking Input in Large Language Models",
    "volume": "main",
    "abstract": "Defending aligned Large Language Models (LLMs) against jailbreaking attacks is a challenging problem, with existing approaches requiring multiple requests or even queries to auxiliary LLMs, making them computationally heavy. Instead, we focus on detecting jailbreaking input in a single forward pass. Our method, called SPD, leverages the information carried by the logits to predict whether the output sentence will be harmful. This allows us to defend in just a forward pass. SPD can not only detect attacks effectively on open-source models, but also minimizes the misclassification of harmless inputs. Furthermore, we show that SPD remains effective even without complete logit access in GPT-3.5 and GPT-4. We believe that our proposed method offers a promising approach to efficiently safeguard LLMs against adversarial attacks",
    "checked": true,
    "id": "57404457c52bbaead08adef52eba2fc7e161b492",
    "semantic_title": "single-pass detection of jailbreaking input in large language models",
    "citation_count": 0,
    "authors": [
      "Leyla Naz Candogan",
      "Yongtao Wu",
      "Elias Abad Rocamora",
      "Grigorios Chrysos",
      "Volkan Cevher"
    ]
  },
  "https://openreview.net/forum?id=pSk5qyt1ob": {
    "title": "On Training-Conditional Conformal Prediction and Binomial Proportion Confidence Intervals",
    "volume": "main",
    "abstract": "Estimating the expectation of a Bernoulli random variable based on $N$ independent trials is a classical problem in statistics, typically addressed using Binomial Proportion Confidence Intervals (BPCI). In the control systems community, many critical tasks—such as certifying the statistical safety of dynamical systems—can be formulated as BPCI problems. Conformal Prediction (CP), a distribution-free technique for uncertainty quantification, has gained significant attention in recent years and has been applied to various control systems problems, particularly to address uncertainties in learned dynamics or controllers. A variant known as training-conditional CP was recently employed to tackle the problem of safety certification. In this note, we highlight that the use of training-conditional CP in this context does not provide valid safety guarantees. We demonstrate why CP is unsuitable for BPCI problems and argue that traditional BPCI methods are better suited for statistical safety certification",
    "checked": true,
    "id": "96eda85cd91da0eb1f3d08dadb53196ca0e4a3e4",
    "semantic_title": "on training-conditional conformal prediction and binomial proportion confidence intervals",
    "citation_count": 0,
    "authors": [
      "Rudi Coppola",
      "Manuel Mazo Espinosa"
    ]
  },
  "https://openreview.net/forum?id=EcMVskXo1n": {
    "title": "Generative Risk Minimization for Out-of-Distribution Generalization on Graphs",
    "volume": "main",
    "abstract": "Out-of-distribution (OOD) generalization on graphs aims at dealing with scenarios where the test graph distribution differs from the training graph distributions. Compared to i.i.d. data like images, the OOD generalization problem on graph-structured data remains challenging due to the non-i.i.d. property and complex structural information on graphs. Recently, several works on graph OOD generalization have explored extracting invariant subgraphs that share crucial classification information across different distributions. Nevertheless, such a strategy could be suboptimal for entirely capturing the invariant information, as the extraction of discrete structures could potentially lead to the loss of invariant information or the involvement of spurious information. In this paper, we propose an innovative framework, named Generative Risk Minimization (GRM), designed to generate an invariant subgraph for each input graph to be classified, instead of extraction. To address the challenge of optimization in the absence of optimal invariant subgraphs (i.e., ground truths), we derive a tractable form of the proposed GRM objective by introducing a latent causal variable, and its effectiveness is validated by our theoretical analysis. We further conduct extensive experiments across a variety of real-world graph datasets for both node-level and graph-level OOD generalization, and the results demonstrate the superiority of our framework GRM",
    "checked": true,
    "id": "b700791efdb5e8202f1d05d1cf6269e56618d4f3",
    "semantic_title": "generative risk minimization for out-of-distribution generalization on graphs",
    "citation_count": 0,
    "authors": [
      "Song Wang",
      "Zhen Tan",
      "Yaochen Zhu",
      "Chuxu Zhang",
      "Jundong Li"
    ]
  },
  "https://openreview.net/forum?id=69RntSRF5K": {
    "title": "An Analytical Model for Overparameterized Learning Under Class Imbalance",
    "volume": "main",
    "abstract": "We study class-imbalanced linear classification in a high-dimensional Gaussian mixture model. We develop a tight, closed form approximation for the test error of several practical learning methods, including logit adjustment and class dependent temperature. Our approximation allows us to analytically tune and compare these methods, highlighting how and when they overcome the pitfalls of standard cross-entropy minimization. We test our theoretical findings on simulated data and imbalanced CIFAR10, MNIST and FashionMNIST datasets",
    "checked": true,
    "id": "5725bc29995bb5643753fcbb5485059a5917b674",
    "semantic_title": "an analytical model for overparameterized learning under class imbalance",
    "citation_count": 1,
    "authors": [
      "Eliav Mor",
      "Yair Carmon"
    ]
  },
  "https://openreview.net/forum?id=t5cy5v9wph": {
    "title": "Evaluating the Robustness of Analogical Reasoning in Large Language Models",
    "volume": "main",
    "abstract": "Large language models (LLMs) have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities. However, there is debate on the extent to which they are performing general abstract reasoning versus employing shortcuts or other non-robust processes, such as ones that overly rely on similarity to what has been seen in their training data. Here we investigate the robustness of analogy-making abilities previously claimed for LLMs on three of four domains studied by Webb et al. (2023): letter-string analogies, digit matrices, and story analogies. For each of these domains we test humans and GPT models on robustness to variants of the original analogy problems—versions that test the same abstract reasoning abilities but that are likely dissimilar from tasks in the pre-training data. The performance of a system that uses robust abstract reasoning should not decline substantially on these variants. On simple letter-string analogies, we find that while the performance of humans remains high for two types of variants we tested, the GPT models' performance declines sharply. This pattern is less pronounced as the complexity of these analogy problems is increased, as both humans and GPT models perform poorly on both the original and variant problems requiring more complex analogies. On digit-matrix problems, we find a similar pattern but only on one out of the two types of variants we tested. Lastly, we assess the robustness of humans and GPT models on story-based analogy problems, finding that, unlike humans, the performance of GPT models are susceptible to answer-order effects, and that GPT models also may be more sensitive than humans to paraphrasing. This work provides evidence that, despite previously reported successes of LLMs on zero-shot analogical reasoning, these models often lack the robustness of zero-shot human analogy- making, exhibiting brittleness on most of the variations we tested. More generally, this work points to the importance of carefully evaluating AI systems not only for accuracy but also robustness when testing their cognitive capabilities. Code, data, and results for all experiments is available at https://github.com/marthaflinderslewis/robust-analogy",
    "checked": true,
    "id": "60077c7c4df14380085dbb9a0e97416854551683",
    "semantic_title": "evaluating the robustness of analogical reasoning in large language models",
    "citation_count": 0,
    "authors": [
      "Martha Lewis",
      "Melanie Mitchell"
    ]
  },
  "https://openreview.net/forum?id=adhsMqURI1": {
    "title": "Comparing the information content of probabilistic representation spaces",
    "volume": "main",
    "abstract": "Probabilistic representation spaces convey information about a dataset and are shaped by factors such as the training data, network architecture, and loss function. Comparing the information content of such spaces is crucial for understanding the learning process, yet most existing methods assume point-based representations, neglecting the distributional nature of probabilistic spaces. To address this gap, we propose two information-theoretic measures to compare general probabilistic representation spaces by extending classic methods to compare the information content of hard clustering assignments. Additionally, we introduce a lightweight method of estimation that is based on fingerprinting a representation space with a sample of the dataset, designed for scenarios where the communicated information is limited to a few bits. We demonstrate the utility of these measures in three case studies. First, in the context of unsupervised disentanglement, we identify recurring information fragments within individual latent dimensions of VAE and InfoGAN ensembles. Second, we compare the full latent spaces of models and reveal consistent information content across datasets and methods, despite variability during training. Finally, we leverage the differentiability of our measures to perform model fusion, synthesizing the information content of weak learners into a single, coherent representation. Across these applications, the direct comparison of information content offers a natural basis for characterizing the processing of information",
    "checked": true,
    "id": "46a6550903bd997bfc933c172fd15e415689a26b",
    "semantic_title": "comparing the information content of probabilistic representation spaces",
    "citation_count": 1,
    "authors": [
      "Kieran A. Murphy",
      "Sam Dillavou",
      "Danielle Bassett"
    ]
  },
  "https://openreview.net/forum?id=jAHEBivObO": {
    "title": "Adapt then Unlearn: Exploring Parameter Space Semantics for Unlearning in Generative Adversarial Networks",
    "volume": "main",
    "abstract": "Owing to the growing concerns about privacy and regulatory compliance, it is desirable to regulate the output of generative models. To that end, the objective of this work is to prevent the generation of outputs containing undesired features from a pre-trained Generative Adversarial Network (GAN) where the underlying training data set is inaccessible. Our approach is inspired by the observation that the parameter space of GANs exhibits meaningful directions that can be leveraged to suppress specific undesired features. However, such directions usually result in the degradation of the quality of generated samples. Our proposed two-stage method, known as 'Adapt-then-Unlearn,' excels at unlearning such undesirable features while also maintaining the quality of generated samples. In the initial stage, we adapt a pre-trained GAN on a set of negative samples (containing undesired features) provided by the user. Subsequently, we train the original pre-trained GAN using positive samples, along with a repulsion regularizer. This regularizer encourages the learned model parameters to move away from the parameters of the adapted model (first stage) while not degrading the generation quality. We provide theoretical insights into the proposed method. To the best of our knowledge, our approach stands as the first method addressing unlearning within the realm of high-fidelity GANs (such as StyleGAN). We validate the effectiveness of our method through comprehensive experiments, encompassing both class-level unlearning on the MNIST and AFHQ dataset and feature-level unlearning tasks on the CelebA-HQ dataset. Our code and implementation is available at: https://github.com/atriguha/Adapt_Unlearn",
    "checked": false,
    "id": "c7c1c0af884e769fad57149c5028f9e8133a0346",
    "semantic_title": "adapt then unlearn: exploiting parameter space semantics for unlearning in generative adversarial networks",
    "citation_count": 9,
    "authors": [
      "Piyush Tiwary",
      "Atri Guha",
      "Subhodip Panda",
      "Prathosh AP"
    ]
  },
  "https://openreview.net/forum?id=D3DBqvSDbj": {
    "title": "On Memorization in Diffusion Models",
    "volume": "main",
    "abstract": "Due to their capacity to generate novel and high-quality samples, diffusion models have attracted significant research interest in recent years. Notably, the typical training objective of diffusion models, i.e., denoising score matching, has a closed-form optimal solution that can only generate training-data replicating samples. This indicates that a memorization behavior is theoretically expected, which contradicts the common generalization ability of state-of-the-art diffusion models, and thus calls for a deeper understanding. Looking into this, we first observe that memorization behaviors tend to occur on smaller-sized datasets, which motivates our definition of effective model memorization (EMM), a metric measuring the maximum size of training data at which a model approximates its theoretical optimum. Then, we quantify the impact of the influential factors on these memorization behaviors in terms of EMM, focusing primarily on data distribution, model configuration, and training procedure. Besides comprehensive empirical results identifying the influential factors, we surprisingly find that conditioning training data on uninformative random labels can significantly trigger the memorization in diffusion models. Our study holds practical significance for diffusion model users and offers clues to theoretical research in deep generative models",
    "checked": true,
    "id": "122a7e217fe70d5a1a44a6e2b67e859d1fc8e28d",
    "semantic_title": "on memorization in diffusion models",
    "citation_count": 55,
    "authors": [
      "Xiangming Gu",
      "Chao Du",
      "Tianyu Pang",
      "Chongxuan Li",
      "Min Lin",
      "Ye Wang"
    ]
  },
  "https://openreview.net/forum?id=dNJmJ8bh1M": {
    "title": "The Sparse Matrix-Based Random Projection: A Study of Binary and Ternary Quantization",
    "volume": "main",
    "abstract": "Random projection is a simple yet effective technique for dimension reduction, widely used in various machine learning tasks. Following the projection step, quantization is often applied to further reduce the complexity of projected data. In general, quantized projections are expected to approximately preserve the pairwise distances between the original data points, to avoid significant performance degradation in subsequent tasks. While this distance preservation property has been investigated for Gaussian matrices, our work further extends the analysis to hardware-friendly $\\{0,1\\}$-binary matrices, particularly focusing on cases where the projections are quantized into two types of low bit-width codes: $\\{0,1\\}$-binary codes and $\\{0,\\pm1\\}$-ternary codes. It is found that the distance preservation property tends to be better maintained, when the binary projection matrices exhibit sparse structures. This is validated through classification and clustering experiments, where extremely sparse binary matrices, with only one nonzero entry per column, achieve superior or comparable performance to other denser binary matrices and Gaussian matrices. This presents an opportunity to significantly reduce the computational and storage complexity of the quantized random projection model, without compromising, and potentially even improving its performance",
    "checked": true,
    "id": "47b3005a2f8b52c74739bb3e6ea4c6e0f6816b40",
    "semantic_title": "the sparse matrix-based random projection: a study of binary and ternary quantization",
    "citation_count": 0,
    "authors": [
      "Weizhi Lu",
      "Zhongzheng Li",
      "Mingrui Chen",
      "Weiyu Li"
    ]
  },
  "https://openreview.net/forum?id=Sx1khIIi95": {
    "title": "Over-parameterised Shallow Neural Networks with Asymmetrical Node Scaling: Global Convergence Guarantees and Feature Learning",
    "volume": "main",
    "abstract": "We consider gradient-based optimisation of wide, shallow neural networks, where the output of each hidden node is scaled by a positive parameter. The scaling parameters are non-identical, differing from the classical Neural Tangent Kernel (NTK) parameterisation. We prove that for large such neural networks, with high probability, gradient flow and gradient descent converge to a global minimum and can learn features in some sense, unlike in the NTK parameterisation. We perform experiments illustrating our theoretical results and discuss the benefits of such scaling in terms of prunability and transfer learning",
    "checked": true,
    "id": "d0290fefeeee18c05357e8d32c5801c34a01ec77",
    "semantic_title": "over-parameterised shallow neural networks with asymmetrical node scaling: global convergence guarantees and feature learning",
    "citation_count": 2,
    "authors": [
      "Francois Caron",
      "Fadhel Ayed",
      "Paul Jung",
      "Hoil Lee",
      "Juho Lee",
      "Hongseok Yang"
    ]
  },
  "https://openreview.net/forum?id=rfPns0WJyg": {
    "title": "Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability",
    "volume": "main",
    "abstract": "Optimal decision-making under partial observability requires reasoning about the uncertainty of the environment's hidden state. However, most reinforcement learning architectures handle partial observability with sequence models that have no internal mechanism to incorporate uncertainty in their hidden state representation, such as recurrent neural networks, deterministic state-space models and transformers. Inspired by advances in probabilistic world models for reinforcement learning, we propose a standalone Kalman filter layer that performs closed-form Gaussian inference in linear state-space models and train it end-to-end within a model-free architecture to maximize returns. Similar to efficient linear recurrent layers, the Kalman filter layer processes sequential data using a parallel scan, which scales logarithmically with the sequence length. By design, Kalman filter layers are a drop-in replacement for other recurrent layers in standard model-free architectures, but importantly they include an explicit mechanism for probabilistic filtering of the latent state representation. Experiments in a wide variety of tasks with partial observability show that Kalman filter layers excel in problems where uncertainty reasoning is key for decision-making, outperforming other stateful models",
    "checked": true,
    "id": "b10e24c77899616e25c7033de4e8f474cd9b1b4e",
    "semantic_title": "uncertainty representations in state-space layers for deep reinforcement learning under partial observability",
    "citation_count": 1,
    "authors": [
      "Carlos E. Luis",
      "Alessandro Giacomo Bottero",
      "Julia Vinogradska",
      "Felix Berkenkamp",
      "Jan Peters"
    ]
  },
  "https://openreview.net/forum?id=hCxtlfvL22": {
    "title": "Latent Space Energy-based Neural ODEs",
    "volume": "main",
    "abstract": "This paper introduces novel deep dynamical models designed to represent continuous-time sequences. Our approach employs a neural emission model to generate each data point in the time series through a non-linear transformation of a latent state vector. The evolution of these latent states is implicitly defined by a neural ordinary differential equation (ODE), with the initial state drawn from an informative prior distribution parameterized by an Energy-based model (EBM). This framework is extended to disentangle dynamic states from underlying static factors of variation, represented as time-invariant variables in the latent space. We train the model using maximum likelihood estimation with Markov chain Monte Carlo (MCMC) in an end-to-end manner. Experimental results on oscillating systems, videos and real-world state sequences (MuJoCo) demonstrate that our model with the learnable energy-based prior outperforms existing counterparts, and can generalize to new dynamic parameterization, enabling long-horizon predictions",
    "checked": true,
    "id": "5de4f6b678bde02a1c2c7b2c6eed09c64b3dd6b2",
    "semantic_title": "latent space energy-based neural odes",
    "citation_count": 1,
    "authors": [
      "Sheng Cheng",
      "Deqian Kong",
      "Jianwen Xie",
      "Kookjin Lee",
      "Ying Nian Wu",
      "Yezhou Yang"
    ]
  },
  "https://openreview.net/forum?id=U8EMkndyq4": {
    "title": "Using representation balancing to learn conditional-average dose responses from clustered data",
    "volume": "main",
    "abstract": "Estimating the response to an intervention with an associated dose conditional on a unit's covariates, the \"conditional-average dose response\" (CADR), is a relevant task in a variety of domains, from healthcare to business, economics, and beyond. Estimating such a response is challenging for several reasons: Firstly, it typically needs to be estimated from observational data, which can be confounded and negatively affect the performance of intervention response estimators used for counterfactual inference. Secondly, the continuity of the dose prevents the adoption of approaches used to estimate responses to binary-valued interventions. That is why the machine learning (ML) community has proposed several tailored CADR estimators. Yet, the proposal of most of these methods requires strong assumptions on the distribution of data and the assignment of interventions, which go beyond the standard assumptions in causal inference. Whereas previous works have so far focused on smooth shifts in covariate distributions across doses, in this work, we will study estimating CADR from clustered data and where different doses are assigned to different segments of a population. On a novel benchmarking dataset, we show the impacts of clustered data on model performance. Additionally, we propose an estimator, CBRNet, that enables the application of representation balancing for CADR estimation through clustering the covariate space and a novel loss function. CBRNet learns cluster-agnostic and hence dose-agnostic covariate representations through representation balancing for unbiased CADR inference. We run extensive experiments to illustrate the workings of our method and compare it with the state of the art in ML for CADR estimation",
    "checked": true,
    "id": "0d56374ae5b058d13a8f733ca50058d39278ca41",
    "semantic_title": "using representation balancing to learn conditional-average dose responses from clustered data",
    "citation_count": 0,
    "authors": [
      "Christopher Bockel-Rickermann",
      "Toon Vanderschueren",
      "Jeroen Berrevoets",
      "Tim Verdonck",
      "Wouter Verbeke"
    ]
  },
  "https://openreview.net/forum?id=TRKwzPnXWQ": {
    "title": "ARVideo: Autoregressive Pretraining for Self-Supervised Video Representation Learning",
    "volume": "main",
    "abstract": "This paper presents a new self-supervised video representation learning framework \\textbf{ARVideo}, which \\textit{autoregressively} predict the next video token in a tailored sequence order. Two key designs are included. First, we organize autoregressive video tokens into clusters that span both \\textit{spatially} and \\textit{temporally}, thereby enabling a richer aggregation of contextual information compared to the standard spatial-only or temporal-only clusters. Second, we adopt a randomized spatiotemporal prediction order to facilitate learning from multi-dimensional data, addressing the limitations of a handcrafted spatial-first or temporal-first sequence order. Extensive experiments establish ARVideo as an effective paradigm for self-supervised video representation learning. For example, when trained with the ViT-B backbone, ARVideo competitively attains 81.2\\% on Kinetics-400 and 70.9\\% on Something-Something V2, which are on par with the strong benchmark set by VideoMAE. Importantly, ARVideo also demonstrates higher training efficiency, \\ie, it trains 14\\% faster and requires 58\\% less GPU memory compared to VideoMAE",
    "checked": true,
    "id": "82a8b19b00992baea0b7b84053e6de5b5e132630",
    "semantic_title": "arvideo: autoregressive pretraining for self-supervised video representation learning",
    "citation_count": 2,
    "authors": [
      "Sucheng Ren",
      "Hongru Zhu",
      "Chen Wei",
      "Yijiang Li",
      "Alan Yuille",
      "Cihang Xie"
    ]
  },
  "https://openreview.net/forum?id=GGHk5ukO6t": {
    "title": "Dynamics-inspired Structure Hallucination for Protein-protein Interaction Modeling",
    "volume": "main",
    "abstract": "Protein-protein interaction (PPI) represents a central challenge within the biology field, and accurately predicting the consequences of mutations in this context is crucial for drug design and protein engineering. Deep learning (DL) has shown promise in forecasting the effects of such mutations but is hindered by two primary constraints. First, the structures of mutant proteins are often elusive to acquire. Secondly, PPI takes place dynamically, which is rarely integrated into the DL architecture design. To address these obstacles, we present a novel framework named Refine-PPI with two key enhancements. First, we introduce a structure refinement module trained by a mask mutation modeling (MMM) task on available wild-type structures, which is then transferred to hallucinate the inaccessible mutant structures. Second, we employ a new kind of geometric network, called the probability density cloud network (PDC-Net), to capture 3D dynamic variations and encode the atomic uncertainty associated with PPI. Comprehensive experiments on SKEMPI.v2 substantiate the superiority of Refine-PPI over all existing tools for predicting free energy change. These findings underscore the effectiveness of our hallucination strategy and the PDC module in addressing the absence of mutant protein structure and modeling geometric uncertainty",
    "checked": true,
    "id": "2ee11cbabb06f2c6a77c3fa78077aafd5b8fa5b3",
    "semantic_title": "dynamics-inspired structure hallucination for protein-protein interaction modeling",
    "citation_count": 0,
    "authors": [
      "Fang Wu",
      "Stan Z. Li"
    ]
  },
  "https://openreview.net/forum?id=h751wl9xiR": {
    "title": "ALTA: Compiler-Based Analysis of Transformers",
    "volume": "main",
    "abstract": "We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework --- language specification, symbolic interpreter, and weight compiler --- available to the community to enable further applications and insights",
    "checked": true,
    "id": "845f2d82f11c192b956c0053b4f49db90f2a8a48",
    "semantic_title": "alta: compiler-based analysis of transformers",
    "citation_count": 2,
    "authors": [
      "Peter Shaw",
      "James Cohan",
      "Jacob Eisenstein",
      "Kenton Lee",
      "Jonathan Berant",
      "Kristina Toutanova"
    ]
  },
  "https://openreview.net/forum?id=BLDtWlFKhn": {
    "title": "Density of states in neural networks: an in-depth exploration of learning in parameter space",
    "volume": "main",
    "abstract": "Learning in neural networks critically hinges on the intricate geometry of the loss landscape associated with a given task. Traditionally, most research has focused on finding specific weight configurations that minimize the loss. In this work, born from the cross-fertilization of machine learning and theoretical soft matter physics, we introduce a novel approach to examine the weight space across all loss values. Employing the Wang-Landau enhanced sampling algorithm, we explore the neural network density of states -- the number of network parameter configurations that produce a given loss value -- and analyze how it depends on specific features of the training set. Using both real-world and synthetic data, we quantitatively elucidate the relation between data structure and network density of states across different sizes and depths of binary-state networks. This work presents and illustrates a novel, informative analysis method that aims at paving the way for a better understanding of the interplay between structured data and the networks that process, learn, and generate them",
    "checked": true,
    "id": "e5ec33e0a0a443ac9f63eda091b12a87fd4c61e7",
    "semantic_title": "density of states in neural networks: an in-depth exploration of learning in parameter space",
    "citation_count": 0,
    "authors": [
      "Margherita Mele",
      "Roberto Menichetti",
      "Alessandro Ingrosso",
      "Raffaello Potestio"
    ]
  },
  "https://openreview.net/forum?id=HjpD5kpfa3": {
    "title": "Rethinking Spectral Augmentation for Contrast-based Graph Self-Supervised Learning",
    "volume": "main",
    "abstract": "The recent surge in contrast-based graph self-supervised learning has prominently featured an intensified exploration of spectral cues. Spectral augmentation, which involves modifying a graph's spectral properties such as eigenvalues or eigenvectors, is widely believed to enhance model performance. However, an intriguing paradox emerges, as methods grounded in seemingly conflicting assumptions regarding the spectral domain demonstrate notable enhancements in learning performance. Through extensive empirical studies, we find that simple edge perturbations - random edge dropping for node-level and random edge adding for graph-level self-supervised learning - consistently yield comparable or superior performance while being significantly more computationally efficient. This suggests that the computational overhead of sophisticated spectral augmentations may not justify their practical benefits. Our theoretical analysis of the InfoNCE loss bounds for shallow GNNs further supports this observation. The proposed insights represent a significant leap forward in the field, potentially refining the understanding and implementation of graph self-supervised learning",
    "checked": true,
    "id": "4ea0b877368675f030a63f2a8b82477e0a2073b8",
    "semantic_title": "rethinking spectral augmentation for contrast-based graph self-supervised learning",
    "citation_count": 0,
    "authors": [
      "Xiangru Jian",
      "Xinjian Zhao",
      "Wei Pang",
      "Chaolong Ying",
      "Yimu Wang",
      "Yaoyao Xu",
      "Tianshu Yu"
    ]
  },
  "https://openreview.net/forum?id=JQ0agisXny": {
    "title": "A Strong Baseline for Molecular Few-Shot Learning",
    "volume": "main",
    "abstract": "Few-shot learning has recently attracted significant interest in drug discovery, with a recent, fast-growing literature mostly involving convoluted meta-learning strategies. We revisit the more straightforward fine-tuning approach for molecular data, and propose a regularized quadratic-probe loss based on the the Mahalanobis distance. We design a dedicated block-coordinate descent optimizer, which avoid the degenerate solutions of our loss. Interestingly, our simple fine-tuning approach achieves highly competitive performances in comparison to state-of-the-art methods, while being applicable to black-box settings and removing the need for specific episodic pre-training strategies. Furthermore, we introduce a new benchmark to assess the robustness of the competing methods to domain shifts. In this setting, our fine-tuning baseline obtains consistently better results than meta-learning methods",
    "checked": true,
    "id": "dcdf4443c4e17e9e1d76a70adf4619c5aad3d736",
    "semantic_title": "a strong baseline for molecular few-shot learning",
    "citation_count": 0,
    "authors": [
      "Philippe Formont",
      "Hugo Jeannin",
      "Pablo Piantanida",
      "Ismail Ben Ayed"
    ]
  },
  "https://openreview.net/forum?id=u9EHndbiVw": {
    "title": "PROXI: Challenging the GNNs for Link Prediction",
    "volume": "main",
    "abstract": "Over the past decade, Graph Neural Networks (GNNs) have transformed graph representation learning. In the widely adopted message-passing GNN framework, nodes refine their representations by aggregating information from neighboring nodes iteratively. While GNNs excel in various domains, recent theoretical studies have raised concerns about their capabilities. GNNs aim to address various graph-related tasks by utilizing such node representations, however, this one-size-fits-all approach proves suboptimal for diverse tasks. Motivated by these observations, we conduct empirical tests to compare the performance of current GNN models with more conventional and direct methods in link prediction tasks. Introducing our model, PROXI, which leverages proximity information of node pairs in both graph and attribute spaces, we find that standard machine learning (ML) models perform competitively, even outperforming cutting-edge GNN models when applied to these proximity metrics derived from node neighborhoods and attributes. This holds true across both homophilic and heterophilic networks, as well as small and large benchmark datasets, including those from the Open Graph Benchmark (OGB). Moreover, we show that augmenting traditional GNNs with PROXI significantly boosts their link prediction performance. Our empirical findings corroborate the previously mentioned theoretical observations and imply that there exists ample room for enhancement in current GNN models to reach their potential",
    "checked": true,
    "id": "9e534ab6e0e6594cf616ffdd476ee18ddef578f9",
    "semantic_title": "proxi: challenging the gnns for link prediction",
    "citation_count": 0,
    "authors": [
      "Astrit Tola",
      "Jack Myrick",
      "Baris Coskunuzer"
    ]
  },
  "https://openreview.net/forum?id=RfFqBXLDQk": {
    "title": "On Space Folds of ReLU Neural Networks",
    "volume": "main",
    "abstract": "Recent findings suggest that the consecutive layers of ReLU neural networks can be understood geometrically as space folding transformations of the input space, revealing patterns of self-similarity. In this paper, we present the first quantitative analysis of this space folding phenomenon in ReLU neural networks. Our approach focuses on examining how straight paths in the Euclidean input space are mapped to their counterparts in the Hamming activation space. In this process, the convexity of straight lines is generally lost, giving rise to non-convex folding behavior. To quantify this effect, we introduce a novel measure based on range metrics, similar to those used in the study of random walks, and provide the proof for the equivalence of convexity notions between the input and activation spaces. Furthermore, we provide empirical analysis on a geometrical analysis benchmark (CantorNet) as well as an image classification benchmark (MNIST). Our work advances the understanding of the activation space in ReLU neural networks by leveraging the phenomena of geometric folding, providing valuable insights on how these models process input information",
    "checked": true,
    "id": "f306125cf30d0a33bc65c6a1ab7498371fdfb0ea",
    "semantic_title": "on space folds of relu neural networks",
    "citation_count": 2,
    "authors": [
      "Michal Lewandowski",
      "Hamid Eghbalzadeh",
      "Bernhard Heinzl",
      "Raphael Pisoni",
      "Bernhard A. Moser"
    ]
  },
  "https://openreview.net/forum?id=asiBW1bB9b": {
    "title": "Improving Consistency in Large Language Models through Chain of Guidance",
    "volume": "main",
    "abstract": "Consistency is a fundamental dimension of trustworthiness in Large Language Models (LLMs). For humans to be able to trust LLM-based applications, their outputs should be consistent when prompted with inputs that carry the same meaning or intent. Despite this need, there is no known mechanism to control and guide LLMs to be more consistent at inference time. In this paper, we introduce a novel alignment strategy to maximize semantic consistency in LLM outputs. Our proposal is based on \\textbf{Chain of Guidance} (CoG), a multistep prompting technique that generates highly consistent outputs from LLMs. For closed-book question-answering (Q\\&A) tasks, when compared to direct prompting, the outputs generated using CoG show improved consistency. While other approaches like template-based responses and majority voting may offer alternative paths to consistency, our work focuses on exploring the potential of guided prompting. We use synthetic data sets comprised of consistent input-output pairs to fine-tune LLMs to produce consistent {\\it and} correct outputs. Our fine-tuned models are more than twice as consistent compared to base models and show strong generalization capabilities by producing consistent outputs over datasets not used in the fine-tuning process. Code is available at \\url{https://github.com/vijilAI/chain_of_guidance}",
    "checked": true,
    "id": "a19ce065f9f0a0eef3efa9f85859b1f4fc1091c3",
    "semantic_title": "improving consistency in large language models through chain of guidance",
    "citation_count": 5,
    "authors": [
      "Harsh Raj",
      "Vipul Gupta",
      "Domenic Rosati",
      "Subhabrata Majumdar"
    ]
  },
  "https://openreview.net/forum?id=H4S4ETc8c9": {
    "title": "Evaluation of Best-of-N Sampling Strategies for Language Model Alignment",
    "volume": "main",
    "abstract": "Best-of-N (BoN) sampling with a reward model has been shown to be an effective strategy for aligning Large Language Models (LLMs) with human preferences at the time of decoding. BoN sampling is susceptible to a problem known as reward hacking. Since the reward model is an imperfect proxy for the true objective, an excessive focus on optimizing its value can lead to a compromise of its performance on the true objective. Previous work proposes Regularized BoN sampling (RBoN), a BoN sampling with regularization to the objective, and shows that it outperforms BoN sampling so that it mitigates reward hacking and empirically (Jinnai et al., 2024). However, Jinnai et al. (2024) introduce RBoN based on a heuristic and they lack the analysis of why such regularization strategy improves the performance of BoN sampling. The aim of this study is to analyze the effect of BoN sampling on regularization strategies. Using the regularization strategies corresponds to robust optimization, which maximizes the worst case over a set of possible perturbations in the proxy reward. Although the theoretical guarantees are not directly applicable to RBoN, RBoN corresponds to a practical implementation. This paper proposes an extension of the RBoN framework, called Stochastic RBoN sampling (SRBoN), which is a theoretically guaranteed approach to worst-case RBoN in proxy reward. We then perform an empirical evaluation using the AlpacaFarm and Anthropic's hh-rlhf datasets to evaluate which factors of the regularization strategies contribute to the improvement of the true proxy reward. In addition, we also propose another simple RBoN method, the Sentence Length Regularized BoN, which has a better performance in the experiment as compared to the previous methods",
    "checked": true,
    "id": "aa2e3c52b4c6e847f6703c84f5640cae42dbc73d",
    "semantic_title": "evaluation of best-of-n sampling strategies for language model alignment",
    "citation_count": 5,
    "authors": [
      "Yuki Ichihara",
      "Yuu Jinnai",
      "Tetsuro Morimura",
      "Kenshi Abe",
      "Kaito Ariu",
      "Mitsuki Sakamoto",
      "Eiji Uchibe"
    ]
  },
  "https://openreview.net/forum?id=ScEv13W2f1": {
    "title": "Unsupervised Discovery of Object-Centric Neural Fields",
    "volume": "main",
    "abstract": "We study inferring 3D object-centric scene representations from a single image. While recent methods have shown potential in unsupervised 3D object discovery, they are limited in generalizing to unseen spatial configurations. This limitation stems from the lack of translation invariance in their 3D object representations. Previous 3D object discovery methods entangle objects' intrinsic attributes like shape and appearance with their 3D locations. This entanglement hinders learning generalizable 3D object representations. To tackle this bottleneck, we propose the unsupervised discovery of Object-Centric neural Fields (uOCF), which integrates translation invariance into the object representation. To allow learning object-centric representations from limited real-world images, we further introduce an object prior learning method that transfers object-centric prior knowledge from a synthetic dataset. To evaluate our approach, we collect four new datasets, including two real kitchen environments. Extensive experiments show that our approach significantly improves generalization and sample efficiency and enables unsupervised 3D object discovery in real scenes. Notably, uOCF demonstrates zero-shot generalization to unseen objects from a single real image. We attach our code in the supplementary file, and the project page is available at https://red-fairy.github.io/uOCF/",
    "checked": true,
    "id": "37a37aa17f600ef5622563e378c0cba6a58221d2",
    "semantic_title": "unsupervised discovery of object-centric neural fields",
    "citation_count": 5,
    "authors": [
      "Rundong Luo",
      "Hong-Xing Yu",
      "Jiajun Wu"
    ]
  },
  "https://openreview.net/forum?id=Wt6Iz5XNIO": {
    "title": "Understanding LLM Embeddings for Regression",
    "volume": "main",
    "abstract": "With the rise of large language models (LLMs) for flexibly processing information as strings, a natural application is regression, specifically by preprocessing string representations into LLM embeddings as downstream features for metric prediction. In this paper, we provide one of the first comprehensive investigations into embedding-based regression and demonstrate that LLM embeddings as features can be better for high-dimensional regression tasks than using traditional feature engineering. This regression performance can be explained in part due to LLM embeddings over numeric data inherently preserving Lipschitz continuity over the feature space. Furthermore, we quantify the contribution of different model effects, most notably model size and language understanding, which we find surprisingly do not always improve regression performance",
    "checked": true,
    "id": "36f1a2c9621a0f25fd35bf6c6fbb3f99341b4965",
    "semantic_title": "understanding llm embeddings for regression",
    "citation_count": 8,
    "authors": [
      "Eric Tang",
      "Bangding Yang",
      "Xingyou Song"
    ]
  },
  "https://openreview.net/forum?id=5qKI2dkrjL": {
    "title": "APR-CNN: Convolutional Neural Networks for the Adaptive Particle Representation of Large Microscopy Images",
    "volume": "main",
    "abstract": "We present APR-CNN, a novel class of convolutional neural networks designed for efficient and scalable three-dimensional microscopy image analysis. APR-CNNs operate natively on a sparse, multi-resolution image representation known as the Adaptive Particle Representation (APR). This significantly reduces memory and compute requirements compared to traditional pixel-based CNNs. We introduce APR-native layers for convolution, pooling, and upsampling, along with hybrid architectures that combine APR and pixel layers to balance accuracy and computational efficiency. We show in benchmarks that APR-CNNs achieve comparable segmentation accuracy to pixel-based CNNs while drastically reducing memory usage and inference time. We further showcase the potential of APR-CNNs in large-scale volumetric image analysis, reducing inference times from weeks to days. This opens up new avenues for applying deep learning to large, high-resolution, three-dimensional biomedical datasets with constrained computational resources",
    "checked": true,
    "id": "881cd10de5d261248c70ae22dab09ac590e367d5",
    "semantic_title": "apr-cnn: convolutional neural networks for the adaptive particle representation of large microscopy images",
    "citation_count": 0,
    "authors": [
      "Joel Jonsson",
      "Bevan Leslie Cheeseman",
      "Ivo Sbalzarini"
    ]
  },
  "https://openreview.net/forum?id=zjxKrb4ehr": {
    "title": "On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates",
    "volume": "main",
    "abstract": "We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions avoiding any Lipschitzness assumption on the score function. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm. Beyond the motivating example and in order to allow for the use of a diverse range of stochastic optimizers, we present our results using an $L^2$-accurate score estimation assumption, which crucially is formed under an expectation with respect to the stochastic optimizer and our novel auxiliary process that uses only known information. This approach yields the best known convergence rate for our sampling algorithm",
    "checked": true,
    "id": "93e13d702f6ffbd31b05051504041bf4b3b28c9e",
    "semantic_title": "on diffusion-based generative models and their error bounds: the log-concave case with full convergence estimates",
    "citation_count": 5,
    "authors": [
      "Stefano Bruno",
      "Ying Zhang",
      "Dongyoung Lim",
      "Omer Deniz Akyildiz",
      "Sotirios Sabanis"
    ]
  },
  "https://openreview.net/forum?id=A1R1cQ93Cb": {
    "title": "Relax and penalize: a new bilevel approach to mixed-binary hyperparameter optimization",
    "volume": "main",
    "abstract": "In recent years, bilevel approaches have become very popular to efficiently estimate high-dimensional hyperparameters of machine learning models. However, to date, binary parameters are handled by continuous relaxation and rounding strategies, which could lead to inconsistent solutions. In this context, we tackle the challenging optimization of mixed-binary hyperparameters by resorting to an equivalent continuous bilevel reformulation based on an appropriate penalty term. We propose an algorithmic framework that, under suitable assumptions, is guaranteed to provide mixed-binary solutions. Moreover, the generality of the method allows to safely use existing continuous bilevel solvers within the proposed framework. We evaluate the performance of our approach for two specific machine learning problems, i.e., the estimation of the group-sparsity structure in regression problems and the data distillation problem. The reported results show that our method is competitive with state-of-the-art approaches based on relaxation and rounding",
    "checked": true,
    "id": "e111c488f0bfddd0d196d6ba932d97b52f44c2a5",
    "semantic_title": "relax and penalize: a new bilevel approach to mixed-binary hyperparameter optimization",
    "citation_count": 0,
    "authors": [
      "Sara Venturini",
      "Marianna De Santis",
      "Jordan Patracone",
      "Martin Schmidt",
      "Francesco Rinaldi",
      "Saverio Salzo"
    ]
  },
  "https://openreview.net/forum?id=nmBleuFzaN": {
    "title": "Maxwell's Demon at Work: Efficient Pruning by Leveraging Saturation of Neurons",
    "volume": "main",
    "abstract": "When training neural networks, dying neurons —units becoming inactive or saturated— are traditionally seen as harmful. This paper sheds new light on this phenomenon. By exploring the impact of various hyperparameter configurations on dying neurons during training, we gather insights on how to improve upon sparse training approaches to pruning. We introduce Demon Pruning (DemP), a method that controls the proliferation of dead neurons through a combination of noise injection on active units and a one-cycled schedule regularization strategy, dynamically leading to network sparsity. Experiments on CIFAR-10 and ImageNet datasets demonstrate that DemP outperforms existing dense-to-sparse structured pruning methods, achieving better accuracy-sparsity tradeoffs while speeding up training up to 3.56$\\times$. These findings provide a novel perspective on dying neurons as a resource for efficient model compression and optimization",
    "checked": true,
    "id": "0638e1ecf313099120106a78bd23fd92863b9e75",
    "semantic_title": "maxwell's demon at work: efficient pruning by leveraging saturation of neurons",
    "citation_count": 1,
    "authors": [
      "Simon Dufort-Labbé",
      "Pierluca D'Oro",
      "Evgenii Nikishin",
      "Irina Rish",
      "Pierre-Luc Bacon",
      "Razvan Pascanu",
      "Aristide Baratin"
    ]
  },
  "https://openreview.net/forum?id=ZMliWjMCor": {
    "title": "Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian Approach",
    "volume": "main",
    "abstract": "Federated Learning (FL) aims to infer a shared model from private and decentralized data stored by multiple clients. Personalized FL (PFL) enhances the model's fit for each client by adapting the global model to the clients. A significant level of personalization is required for highly heterogeneous clients but can be challenging to achieve, especially when clients' datasets are small. We introduce PAC-PFL for PFL of probabilistic models. PAC-PFL infers a shared hyper-posterior and treats each client's posterior inference as the personalization step. Unlike previous PFL algorithms, PAC-PFL does not regularize all personalized models towards a single shared model, thereby greatly enhancing its personalization flexibility. By establishing and minimizing a PAC-Bayesian generalization bound on the average true loss of clients, PAC-PFL effectively mitigates overfitting even in data-poor scenarios. Additionally, PAC-PFL provides generalization bounds for new clients joining later. PAC-PFL achieves accurate and well-calibrated predictions, as supported by our experiments",
    "checked": true,
    "id": "94e5c067e37c5212020d6619a921018ef287120e",
    "semantic_title": "personalized federated learning of probabilistic models: a pac-bayesian approach",
    "citation_count": 3,
    "authors": [
      "Mahrokh Ghoddousi Boroujeni",
      "Andreas Krause",
      "Giancarlo Ferrari-Trecate"
    ]
  },
  "https://openreview.net/forum?id=DrMCDS88IL": {
    "title": "Wasserstein Coreset via Sinkhorn Loss",
    "volume": "main",
    "abstract": "Coreset selection, a technique for compressing large datasets while preserving performance, is crucial for modern machine learning. This paper presents a novel method for generating high-quality Wasserstein coresets using the Sinkhorn loss, a powerful tool with computational advantages. However, existing approaches suffer from numerical instability in Sinkhorn's algorithm. We address this by proposing stable algorithms for the computation and differentiation of the Sinkhorn optimization problem, including an analytical formula for the derivative of the Sinkhorn loss and a rigorous stability analysis of our method. Extensive experiments demonstrate that our approach significantly outperforms existing methods in terms of sample selection quality, computational efficiency, and achieving a smaller Wasserstein distance",
    "checked": true,
    "id": "eaa11aee30abe5267490cde64c0825004369e758",
    "semantic_title": "wasserstein coreset via sinkhorn loss",
    "citation_count": 0,
    "authors": [
      "Haoyun Yin",
      "Yixuan Qiu",
      "Xiao Wang"
    ]
  },
  "https://openreview.net/forum?id=tzW948kU6x": {
    "title": "Diffusion on Graph: Augmentation of Graph Structure for Node Classification",
    "volume": "main",
    "abstract": "Graph diffusion models have recently been proposed to synthesize entire graphs, such as molecule graphs. Although existing methods have shown great performance in generating entire graphs for graph-level learning tasks, no graph diffusion models have been developed to generate synthetic graph structures, that is, synthetic nodes and associated edges within a given graph, for node-level learning tasks. Inspired by the research in the computer vision literature using synthetic data for enhanced performance, we propose Diffusion on Graph (DoG), which generates synthetic graph structures to boost the performance of GNNs. The synthetic graph structures generated by DoG are combined with the original graph to form an augmented graph for the training of node-level learning tasks, such as node classification and graph contrastive learning (GCL). To improve the efficiency of the generation process, a Bi-Level Neighbor Map Decoder (BLND) is introduced in DoG. To mitigate the adverse effect of the noise introduced by the synthetic graph structures, a low-rank regularization method is proposed for the training of graph neural networks (GNNs) on the augmented graphs. Extensive experiments on various graph datasets for semi-supervised node classification and graph contrastive learning have been conducted to demonstrate the effectiveness of DoG with low-rank regularization. The code of DoG is available at \\url{https://github.com/Statistical-Deep-Learning/DoG}",
    "checked": true,
    "id": "3f05797344d43e54daa8e98664c4920ccd21e37f",
    "semantic_title": "diffusion on graph: augmentation of graph structure for node classification",
    "citation_count": 0,
    "authors": [
      "Yancheng Wang",
      "Changyu Liu",
      "Yingzhen Yang"
    ]
  },
  "https://openreview.net/forum?id=8rxtL0kZnX": {
    "title": "Hypergraph Neural Networks through the Lens of Message Passing: A Common Perspective to Homophily and Architecture Design",
    "volume": "main",
    "abstract": "Most of the current learning methodologies and benchmarking datasets in the hypergraph realm are obtained by \\emph{lifting} procedures from their graph analogs, leading to overshadowing specific characteristics of hypergraphs. This paper attempts to confront some pending questions in that regard: Q1 Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HNNs)? Q2 How do models that employ unique characteristics of higher-order networks perform compared to lifted models? Q3 Do well-established hypergraph datasets provide a meaningful benchmark for HNNs? To address them, we first introduce a novel conceptualization of homophily in higher-order networks based on a Message Passing (MP) scheme, unifying both the analytical examination and the modeling of higher-order networks. Further, we investigate some natural strategies for processing higher-order structures within HNNs (such as keeping hyperedge-dependent node representations or performing node/hyperedge stochastic samplings), leading us to the most general MP formulation up to date --MultiSet. Finally, we conduct an extensive set of experiments that contextualize our proposals",
    "checked": true,
    "id": "f1cb37f9a8846b8627465d460b20fc2e8f62fca2",
    "semantic_title": "hypergraph neural networks through the lens of message passing: a common perspective to homophily and architecture design",
    "citation_count": 11,
    "authors": [
      "Lev Telyatnikov",
      "Maria Sofia Bucarelli",
      "Guillermo Bernardez",
      "Olga Zaghen",
      "Simone Scardapane",
      "Pietro Lio"
    ]
  },
  "https://openreview.net/forum?id=sbmp55k6iE": {
    "title": "Increasing Both Batch Size and Learning Rate Accelerates Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "The performance of mini-batch stochastic gradient descent (SGD) strongly depends on setting the batch size and learning rate to minimize the empirical loss in training the deep neural network. In this paper, we present theoretical analyses of mini-batch SGD with four schedulers: (i) constant batch size and decaying learning rate scheduler, (ii) increasing batch size and decaying learning rate scheduler, (iii) increasing batch size and increasing learning rate scheduler, and (iv) increasing batch size and warm-up decaying learning rate scheduler. We show that mini-batch SGD using scheduler (i) does not always minimize the expectation of the full gradient norm of the empirical loss, whereas it does using any of schedulers (ii), (iii), and (iv). Furthermore, schedulers (iii) and (iv) accelerate mini-batch SGD. The paper also provides numerical results of supporting analyses showing that using scheduler (iii) or (iv) minimizes the full gradient norm of the empirical loss faster than using scheduler (i) or (ii)",
    "checked": true,
    "id": "ad900c93cce11b7edbc914ee70538309e30373d7",
    "semantic_title": "increasing both batch size and learning rate accelerates stochastic gradient descent",
    "citation_count": 2,
    "authors": [
      "Hikaru Umeda",
      "Hideaki Iiduka"
    ]
  },
  "https://openreview.net/forum?id=JEHIVfjmOf": {
    "title": "JoIN: Joint GANs Inversion for Intrinsic Image Decomposition",
    "volume": "main",
    "abstract": "Intrinsic Image Decomposition (IID) is a challenging inverse problem that seeks to decompose a natural image into its underlying intrinsic components such as albedo and shading. While recent image decomposition methods rely on learning-based priors on these components, they often suffer from component cross-contamination owing to joint training of priors; or from Sim-to-Real gap since the priors trained on synthetic data are kept frozen during the inference on real images. In this work, we propose to solve the intrinsic image decomposition problem using a bank of Generative Adversarial Networks (GANs) as priors where each GAN is independently trained only on a single intrinsic component, providing stronger and more disentangled priors. At the core of our approach is the idea that the latent space of a GAN is a well-suited optimization domain to solve inverse problems. Given an input image, we propose to jointly invert the latent codes of a set of GANs and combine their outputs to reproduce the input. Contrary to all existing GAN inversion methods that are limited to inverting only a single GAN, our proposed approach, JoIN, is able to jointly invert multiple GANs using only a single image as supervision while still maintaining distribution priors of each intrinsic component. We show that our approach is modular, allowing various forward imaging models, and that it can successfully decompose both synthetic and real images. Further, taking inspiration from existing GAN inversion approaches, we allow for careful fine-tuning of the generator priors during the inference on real images. This way, our method is able to achieve excellent generalization on real images even though it uses only synthetic data to train the GAN priors. We demonstrate the success of our approach through exhaustive qualitative and quantitative evaluations and ablation studies on various datasets",
    "checked": true,
    "id": "db139e9df8ef1c0d2aeba88169394508c9a6fb94",
    "semantic_title": "join: joint gans inversion for intrinsic image decomposition",
    "citation_count": 2,
    "authors": [
      "Viraj Shah",
      "Svetlana Lazebnik",
      "Julien Philip"
    ]
  },
  "https://openreview.net/forum?id=1QeI99nH9k": {
    "title": "Robust High-Dimensional Mean Estimation With Low Data Size, an Empirical Study",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "29bf80275de8817de20484f57d012d7d2be50083",
    "semantic_title": "robust high-dimensional mean estimation with low data size, an empirical study",
    "citation_count": 0,
    "authors": [
      "Cullen Anderson",
      "Jeff M. Phillips"
    ]
  },
  "https://openreview.net/forum?id=7CUluLpLxV": {
    "title": "Explaining Explainability: Recommendations for Effective Use of Concept Activation Vectors",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "6309f33979d4384ed2092088cafb1bb15563c6cc",
    "semantic_title": "explaining explainability: recommendations for effective use of concept activation vectors",
    "citation_count": 3,
    "authors": [
      "Angus Nicolson",
      "Lisa Schut",
      "Alison Noble",
      "Yarin Gal"
    ]
  },
  "https://openreview.net/forum?id=IrBYuh9W3T": {
    "title": "What Makes ImageNet Look Unlike LAION",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0609864d2aee4ed04671304b9de7e94db603fe1a",
    "semantic_title": "what makes imagenet look unlike laion",
    "citation_count": 10,
    "authors": [
      "Ali Shirali",
      "Moritz Hardt"
    ]
  },
  "https://openreview.net/forum?id=Bmy82p2eez": {
    "title": "Continual Learning from Simulated Interactions via Multitask Prospective Rehearsal for Bionic Limb Behavior Modeling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "2c6a7bced720785ff13119378660b14822418ddb",
    "semantic_title": "continual learning from simulated interactions via multitask prospective rehearsal for bionic limb behavior modeling",
    "citation_count": 0,
    "authors": [
      "Sharmita Dey",
      "Benjamin Paassen",
      "Sarath Ravindran Nair",
      "Sabri Boughorbel",
      "Arndt F. Schilling"
    ]
  },
  "https://openreview.net/forum?id=DYCSRf3vby": {
    "title": "Geometry-Aware visualization of high dimensional Symmetric Positive Definite matrices",
    "volume": "main",
    "abstract": "Symmetric Positive Definite (SPD) matrices are pervasive in machine learning, from data features (such as covariance matrices) to optimization process.These matrices induce a Riemannian structure, where the curvature plays a critical role in the success of approaches based on those geometries. Yet, for ML practitioners wanting to visualize SPD matrices, the existing (flat) Euclidean approaches will hide the curvature of the manifold. To overcome this lack of expressivity in the existing algorithms, we introduce Riemannian versions of two state-of-the-art techniques, namely t-SNE and Multidimensional Scaling. Therefore, we are able to reduce a set of $c \\times c$ SPD matrices into a set of $2 \\times 2$ SPD matrices in order to capture the curvature information and avoid any distortion induced by flattening the representation in an Euclidean setup. Moreover, our approaches pave the way for targeting more general dimensionality reduction applications while preserving the geometry of the data. We performed experiments on controlled synthetic dataset to ensure that the low-dimensional representation preserves the geometric properties of both SPD Gaussians and geodesics. We also conduct experiments on various real datasets, such as video, anomaly detection, brain signal and others",
    "checked": true,
    "id": "0f84816eedf3c092cf74e654eb9cfa4a04f560d5",
    "semantic_title": "geometry-aware visualization of high dimensional symmetric positive definite matrices",
    "citation_count": 1,
    "authors": [
      "Thibault de Surrel",
      "Sylvain Chevallier",
      "Fabien Lotte",
      "Florian Yger"
    ]
  },
  "https://openreview.net/forum?id=VM8bNd5A09": {
    "title": "CNN Interpretability with Multivector Tucker Saliency Maps for Self-Supervised Models",
    "volume": "main",
    "abstract": "Interpreting the decisions of Convolutional Neural Networks (CNNs) is essential for understanding their behavior, yet it remains a significant challenge, particularly for self-supervised models. Most existing methods for generating saliency maps rely on reference labels, restricting their use to supervised tasks. EigenCAM is the only notable label-independent alternative, leveraging Singular Value Decomposition to generate saliency maps applicable across CNN models, but it does not fully exploit the tensorial structure of feature maps. In this work, we introduce the Tucker Saliency Map (TSM) method, which applies Tucker tensor decomposition to better capture the inherent structure of feature maps, producing more accurate singular vectors and values. These are used to generate high-fidelity saliency maps, effectively highlighting objects of interest in the input. We further extend EigenCAM and TSM into multivector variants—Multivec-EigenCAM and Multivector Tucker Saliency Maps (MTSM)—which utilize all singular vectors and values, further improving saliency map quality. Quantitative evaluations on supervised classification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve competitive performance with label-dependent methods. Moreover, TSM enhances interpretability by approximately $50\\%$ over EigenCAM for both supervised and self-supervised models. Multivec-EigenCAM and MTSM further advance state-of-the-art interpretability performance on self-supervised models, with MTSM achieving the best results",
    "checked": true,
    "id": "3917390c0b121fce89eaf486bef35b134859336e",
    "semantic_title": "cnn interpretability with multivector tucker saliency maps for self-supervised models",
    "citation_count": 0,
    "authors": [
      "Aymene Mohammed Bouayed",
      "Samuel Deslauriers-gauthier",
      "Adrian IACOVELLI",
      "David Naccache"
    ]
  },
  "https://openreview.net/forum?id=YxXyRSlZ4b": {
    "title": "Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach",
    "volume": "main",
    "abstract": "Lattice reduction is a combinatorial optimization problem aimed at finding the most orthogonal basis in a given lattice. The Lenstra–Lenstra–Lovász (LLL) algorithm is the best algorithm in the literature for solving this problem. In light of recent research on algorithm discovery, in this work, we would like to answer this question: is it possible to parametrize the algorithm space for lattice reduction problem with neural networks and find an algorithm without supervised data? Our strategy is to use equivariant and invariant parametrizations and train in a self-supervised way. We design a deep neural model outputting factorized unimodular matrices and train it in a self-supervised manner by penalizing non-orthogonal lattice bases. We incorporate the symmetries of lattice reduction into the model by making it invariant to isometries and scaling of the ambient space and equivariant with respect to the hyperocrahedral group permuting and flipping the lattice basis elements. We show that this approach yields an algorithm with comparable complexity and performance to the LLL algorithm on a set of benchmarks. Additionally, motivated by certain applications for wireless communication, we extend our method to a convolutional architecture which performs joint reduction of spatially-correlated lattices arranged in a grid, thereby amortizing its cost over multiple lattices",
    "checked": true,
    "id": "7e0276853f5475f8b62125d025e40f2bbdd08119",
    "semantic_title": "neural lattice reduction: a self-supervised geometric deep learning approach",
    "citation_count": 2,
    "authors": [
      "Giovanni Luca Marchetti",
      "Gabriele Cesa",
      "Kumar Pratik",
      "Arash Behboodi"
    ]
  },
  "https://openreview.net/forum?id=tzFjcVqmxw": {
    "title": "Enhancing Remaining Useful Life Prediction with Ensemble Multi-Term Fourier Graph Neural Networks",
    "volume": "main",
    "abstract": "Remaining useful life (RUL) prediction is crucial in predictive maintenance. Recently, deep learning forecasting methods, especially Spatio-Temporal Graph Neural Networks (ST-GNNs), have achieved remarkable performance in RUL prediction. Most existing ST-GNNs require searching for the graph structure before utilizing GNNs to learn spatial graph representation, and they necessitate a temporal model such as LSTM to leverage the temporal dependencies in a fixed lookback window. However, such an approach has several limitations. Firstly, it demands substantial computational resources to learn graph structures for the time series data. Secondly, independently learning spatial and temporal information disregards their inherent correlation, and thirdly, capturing information within a fixed lookback window ignores long-term dependencies across the entire time series. To mitigate the issues above, instead of treating the data within the lookback window as a sequence of graphs in ST-GNN methods, we regard it as a complete graph and employ a Fourier Graph Neural Network (FGN) to learn the spatiotemporal information within this graph in the frequency space. Additionally, we create training and test graphs with varying sizes of lookback windows, enabling the model to learn both short-term and long-term dependencies and provide multiple predictions for ensemble averaging. We also consider scenarios where sensor signals exhibit multiple operation conditions and design a sequence decomposition plugin to denoise input signals, aiming to enhance the performance of FGN. We evaluate the proposed model on two benchmark datasets, demonstrating its superior performance on the RUL prediction task compared to state-of-the-art approaches",
    "checked": true,
    "id": "35f678dd6c135dfa85aa91979a5e110088ed3eee",
    "semantic_title": "enhancing remaining useful life prediction with ensemble multi-term fourier graph neural networks",
    "citation_count": 0,
    "authors": [
      "Ya Song",
      "Laurens Bliek",
      "Yaoxin Wu",
      "Yingqian Zhang"
    ]
  },
  "https://openreview.net/forum?id=Wnd0XY0twh": {
    "title": "Data Augmentation Policy Search for Long-Term Forecasting",
    "volume": "main",
    "abstract": "Data augmentation serves as a popular regularization technique to combat overfitting challenges in neural networks. While automatic augmentation has demonstrated success in image classification tasks, its application to time-series problems, particularly in long-term forecasting, has received comparatively less attention. To address this gap, we introduce a time-series automatic augmentation approach named TSAA, which is both efficient and easy to implement. The solution involves tackling the associated bilevel optimization problem through a two-step process: initially training a non-augmented model for a limited number of epochs, followed by an iterative split procedure. During this iterative process, we alternate between identifying a robust augmentation policy through Bayesian optimization and refining the model while discarding suboptimal runs. Extensive evaluations on challenging univariate and multivariate forecasting benchmark problems demonstrate that TSAA consistently outperforms several robust baselines, suggesting its potential integration into prediction pipelines. Code is available at this repository: \\href{https://github.com/azencot-group/TSAA}{https://github.com/azencot-group/TSAA}",
    "checked": true,
    "id": "233d8d32faecb7a7e5544edaf437fe3f968d8cae",
    "semantic_title": "data augmentation policy search for long-term forecasting",
    "citation_count": 5,
    "authors": [
      "Liran Nochumsohn",
      "Omri Azencot"
    ]
  },
  "https://openreview.net/forum?id=M3SkSMfWcP": {
    "title": "Adaptive Multi-step Refinement Network for Robust Point Cloud Registration",
    "volume": "main",
    "abstract": "Point Cloud Registration (PCR) estimates the relative rigid transformation between two point clouds of the same scene. Despite significant progress with learning-based approaches, existing methods still face challenges when the overlapping region between the two point clouds is small. In this paper, we propose an adaptive multi-step refinement network that refines the registration quality at each step by leveraging the information from the preceding step. To achieve this, we introduce a training procedure and a refinement network. Firstly, to adapt the network to the current step, we utilize a generalized one-way attention mechanism, which prioritizes the last step's estimated overlapping region, and we condition the network on step indices. Secondly, instead of training the network to map either random transformations or a fixed pre-trained model's estimations to the ground truth, we train it on transformations with varying registration qualities, ranging from accurate to inaccurate, thereby enhancing the network's adaptiveness and robustness. Despite its conceptual simplicity, our method achieves state-of-the-art performance on both the 3DMatch/3DLoMatch and KITTI benchmarks. Notably, on 3DLoMatch, our method reaches 80.4% recall rate, with an absolute improvement of 1.2%",
    "checked": true,
    "id": "681d3d3ddc1319bed1f515197708a98467b3cd0c",
    "semantic_title": "adaptive multi-step refinement network for robust point cloud registration",
    "citation_count": 4,
    "authors": [
      "Zhi Chen",
      "Yufan Ren",
      "Tong Zhang",
      "Zheng Dang",
      "Wenbing Tao",
      "Sabine Susstrunk",
      "Mathieu Salzmann"
    ]
  },
  "https://openreview.net/forum?id=zKv8qULV6n": {
    "title": "LLaVA-OneVision: Easy Visual Task Transfer",
    "volume": "main",
    "abstract": "We present LLaVA-OneVision, a family of open large multimodal models (LMMs) developed by consolidating our insights into data, models, and visual representations in the LLaVA-NeXT blog series. Our experimental results demonstrate that LLaVA-OneVision is the first single model that can simultaneously push the performance boundaries of open LMMs in three important computer vision scenarios: single-image, multi-image, and video scenarios. Importantly, the design of LLaVA-OneVision allows strong transfer learning across different modalities/scenarios, yielding new emerging capabilities. In particular, strong video understanding and cross-scenario capabilities are demonstrated through task transfer from images to videos",
    "checked": true,
    "id": "1a71f7b216b710b936da666027014adb83af8e7a",
    "semantic_title": "llava-onevision: easy visual task transfer",
    "citation_count": 865,
    "authors": [
      "Bo Li",
      "Yuanhan Zhang",
      "Dong Guo",
      "Renrui Zhang",
      "Feng Li",
      "Hao Zhang",
      "Kaichen Zhang",
      "Peiyuan Zhang",
      "Yanwei Li",
      "Ziwei Liu",
      "Chunyuan Li"
    ]
  },
  "https://openreview.net/forum?id=F5ALCh3GWG": {
    "title": "On the Regularization of Learnable Embeddings for Time Series Forecasting",
    "volume": "main",
    "abstract": "In forecasting multiple time series, accounting for the individual features of each sequence can be challenging. To address this, modern deep learning methods for time series analysis combine a shared (global) model with local layers, specific to each time series, often implemented as learnable embeddings. Ideally, these local embeddings should encode meaningful representations of the unique dynamics of each sequence. However, when these are learned end-to-end as parameters of a forecasting model, they may end up acting as mere sequence identifiers. Shared processing blocks may then become reliant on such identifiers, limiting their transferability to new contexts. In this paper, we address this issue by investigating methods to regularize the learning of local learnable embeddings for time series processing. Specifically, we perform the first extensive empirical study on the subject and show how such regularizations consistently improve performance in widely adopted architectures. Furthermore, we show that methods attempting to prevent the co-adaptation of local and global parameters by means of embeddings perturbation are particularly effective in this context. In this regard, we include in the comparison several perturbation-based regularization methods, going as far as periodically resetting the embeddings during training. The obtained results provide an important contribution to understanding the interplay between learnable local parameters and shared processing layers: a key challenge in modern time series processing models and a step toward developing effective foundation models for time series",
    "checked": true,
    "id": "1d6ccf45768991eca4c46c76b41246e675494885",
    "semantic_title": "on the regularization of learnable embeddings for time series forecasting",
    "citation_count": 0,
    "authors": [
      "Luca Butera",
      "Giovanni De Felice",
      "Andrea Cini",
      "Cesare Alippi"
    ]
  },
  "https://openreview.net/forum?id=JQGmbVK4Fr": {
    "title": "Towards context and domain-aware algorithms for scene analysis",
    "volume": "main",
    "abstract": "Interpersonal interactions and social situations in multimedia content encompass a rich blend of visual, textual, audio and contextual cues as well. However, contextual data integration in multimodal scene analysis research has often been overlooked, leading to incomplete interpretations. For instance, recognizing that two combatants in a video are positioned within a designated ring with a dedicated referee drastically alters the perception from a simple scuffle to a structured martial arts contest. This paper presents an innovative approach to scene analysis in video content, which not only incorporates contextual data but also emphasizes the most significant features during training. Additionally, we introduce a methodology for integrating domain knowledge into our framework. We evaluate our proposed methodology using two comprehensive datasets, demonstrating promising results compared to a baseline study using one of the datasets. These findings underscore the importance of integrating contextual data into multimodal video analysis, while also recognizing the challenges associated with their utilization",
    "checked": true,
    "id": "1a929b74c08dd0df0946af7fd833c489ab2765b5",
    "semantic_title": "towards context and domain-aware algorithms for scene analysis",
    "citation_count": 0,
    "authors": [
      "Ibrahim Serouis",
      "Florence Sèdes"
    ]
  },
  "https://openreview.net/forum?id=P5y82LKGbY": {
    "title": "DELTA: Dual Consistency Delving with Topological Uncertainty for Active Graph Domain Adaptation",
    "volume": "main",
    "abstract": "Graph domain adaptation has recently enabled knowledge transfer across different graphs. However, without the semantic information on target graphs, the performance on target graphs is still far from satisfactory. To address the issue, we study the problem of active graph domain adaptation, which selects a small quantitative of informative nodes on the target graph for extra annotation. This problem is highly challenging due to the complicated topological relationships and the distribution discrepancy across graphs. In this paper, we propose a novel approach named Dual Consistency Delving with Topological Uncertainty (DELTA) for active graph domain adaptation. Our DELTA consists of an edge-oriented graph subnetwork and a path-oriented graph subnetwork, which can explore topological semantics from complementary perspectives. In particular, our edge-oriented graph subnetwork utilizes the message passing mechanism to learn neighborhood information, while our path-oriented graph subnetwork explores high-order relationships from substructures. To jointly learn from two subnetworks, we roughly select informative candidate nodes with the consideration of consistency across two subnetworks. Then, we aggregate local semantics from its K-hop subgraph based on node degrees for topological uncertainty estimation. To overcome potential distribution shifts, we compare target nodes and their corresponding source nodes for discrepancy scores as an additional component for fine selection. Extensive experiments on benchmark datasets demonstrate that DELTA outperforms various state-of-the-art approaches. The code implementation of DELTA is available at https://github.com/goose315/DELTA",
    "checked": true,
    "id": "fcc2cf3c39721b1b3d70d2dffeffb3bdb76a1c75",
    "semantic_title": "delta: dual consistency delving with topological uncertainty for active graph domain adaptation",
    "citation_count": 1,
    "authors": [
      "Pengyun Wang",
      "Yadi Cao",
      "Chris Russell",
      "Yanxin Shen",
      "Junyu Luo",
      "Ming Zhang",
      "Siyu Heng",
      "Xiao Luo"
    ]
  },
  "https://openreview.net/forum?id=gwXfZ3xkUq": {
    "title": "When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training",
    "volume": "main",
    "abstract": "Extending context window sizes allows large language models (LLMs) to process longer sequences and handle more complex tasks. Rotary Positional Embedding (RoPE) has become the de facto standard due to its relative positional encoding properties that benefit long-context training. However, we observe that using RoPE with BFloat16 format results in numerical issues, causing it to deviate from its intended relative positional encoding, especially in long-context scenarios. This issue arises from BFloat16's limited precision and accumulates as context length increases, with the first token contributing significantly to this problem. Despite its limitations, BFloat16 remains desirable for its computational efficiency, particularly given the substantial memory overhead required to extend the context window. To improve long-context training under BFloat16, we develop AnchorAttention, a plug-and-play attention method that enhances long-context capabilities, and speeds up training. AnchorAttention reduces unnecessary attention computations, maintains semantic coherence, and boosts computational efficiency by treating the first token as a shared anchor with a consistent position ID, making it visible to all documents within the training context. Experiments on three types of LLMs demonstrate that AnchorAttention significantly improves long-context performance and reduces training time by over 50\\% compared to standard full attention mechanisms, while preserving the original LLM's capabilities on general tasks",
    "checked": true,
    "id": "853e540102e92f8150e14be5f7daf943f0a88194",
    "semantic_title": "when precision meets position: bfloat16 breaks down rope in long-context training",
    "citation_count": 1,
    "authors": [
      "Haonan Wang",
      "Qian Liu",
      "Chao Du",
      "Tongyao Zhu",
      "Cunxiao Du",
      "Kenji Kawaguchi",
      "Tianyu Pang"
    ]
  },
  "https://openreview.net/forum?id=UYXPt7HUdl": {
    "title": "Score-Based Denoising Diffusion Models for Photon-Starved Image Restoration Problems",
    "volume": "main",
    "abstract": "Score-based denoising diffusion models have recently emerged as a powerful strategy to solve image restoration problems. Early diffusion models required problem-specific training. However, modern approaches can combine a likelihood function that is specified during test-time with a foundational pretrained diffusion model, which is used as an implicit prior in a Plug-and-Play (PnP) manner. This approach has been shown to deliver state-of-the-art performance in a wide range of image restoration problems involving Gaussian and mild Poisson noise. With extreme computer vision applications in mind, this paper presents the first PnP denoising diffusion method for photon-starved imaging problems. These problems arise in new quantum-enhanced imaging systems that exploit the particle nature of light to exceed the limitations of classical imaging. The problems involve highly challenging noise statistics, such as binomial, geometric, and low-intensity Poisson noise, which are difficult because of high uncertainty about the solution and because the models exhibit poor regularity properties (e.g., exploding scores, constraints). The proposed method is demonstrated on a series of challenging photon-starved imaging experiments with as little as 1 photon per pixel, where it delivers remarkably accurate solutions and outperforms alternative strategies from the state-of-the-art",
    "checked": true,
    "id": "756efc5cfb34e7da5c3901332f738e609401d86b",
    "semantic_title": "score-based denoising diffusion models for photon-starved image restoration problems",
    "citation_count": 2,
    "authors": [
      "Savvas Melidonis",
      "Yiming Xi",
      "Konstantinos C. Zygalakis",
      "Yoann Altmann",
      "Marcelo Pereyra"
    ]
  },
  "https://openreview.net/forum?id=W50i7r3DHE": {
    "title": "Instance-Aware Graph Prompt Learning",
    "volume": "main",
    "abstract": "Graph neural networks stand as the predominant technique for graph representation learning owing to their strong expressive power, yet the performance highly depends on the availability of high-quality labels in an end-to-end manner. Thus the pretraining and fine-tuning paradigm has been proposed to mitigate the label cost issue. Subsequently, the gap between the pretext tasks and downstream tasks has spurred the development of graph prompt learning which inserts a set of graph prompts into the original graph data with minimal parameters while preserving competitive performance. However, the current exploratory works are still limited since they all concentrate on learning fixed task-specific prompts which may not generalize well across the diverse instances that the task comprises. To tackle this challenge, we introduce Instance-Aware Graph Prompt Learning (IA-GPL) in this paper, aiming to generate distinct prompts tailored to different input instances. The process involves generating intermediate prompts for each instance using a lightweight architecture, quantizing these prompts through trainable codebook vectors, and employing the exponential moving average technique to ensure stable training. Extensive experiments conducted on multiple datasets and settings showcase the superior performance of IA-GPL compared to state-of-the-art baselines",
    "checked": true,
    "id": "fe1a5e0624e45210780eaa264eda5c37f792d087",
    "semantic_title": "instance-aware graph prompt learning",
    "citation_count": 0,
    "authors": [
      "Jiazheng Li",
      "Jundong Li",
      "Chuxu Zhang"
    ]
  },
  "https://openreview.net/forum?id=xpnPYfufhz": {
    "title": "Partially Frozen Random Networks Contain Compact Strong Lottery Tickets",
    "volume": "main",
    "abstract": "Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning—strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated that SLTs could also be found within a randomly pruned source network. This phenomenon can be exploited to further compress the small memory size required by SLTs. However, their method is limited to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method for reducing the SLT memory size without restricting the sparsity of the SLTs that can be found. A random subset of the initial weights is frozen by either permanently pruning them or locking them as a fixed part of the SLT, resulting in a smaller model size. Experimental results show that Edge-Popup (Ramanujan et al., 2020; Sreenivasan et al., 2022) finds SLTs with better accuracy-to-model size trade-off within frozen networks than within dense or randomly pruned source networks. In particular, freezing $70\\%$ of a ResNet on ImageNet provides $3.3\\times$ compression compared to the SLT found within a dense counterpart, raises accuracy by up to $14.12$ points compared to the SLT found within a randomly pruned counterpart, and offers a better accuracy-model size trade-off than both",
    "checked": true,
    "id": "97921e5a4a903da39517976017733925c693da80",
    "semantic_title": "partially frozen random networks contain compact strong lottery tickets",
    "citation_count": 0,
    "authors": [
      "Hikari Otsuka",
      "Daiki Chijiwa",
      "Ángel López García-Arias",
      "Yasuyuki Okoshi",
      "Kazushi Kawamura",
      "Thiem Van Chu",
      "Daichi Fujiki",
      "Susumu Takeuchi",
      "Masato Motomura"
    ]
  },
  "https://openreview.net/forum?id=c7AAHdEYz5": {
    "title": "Label Distribution Shift-Aware Prediction Refinement for Test-Time Adaptation",
    "volume": "main",
    "abstract": "Test-time adaptation (TTA) is an effective approach to mitigate performance degradation of trained models when encountering input distribution shifts at test time. However, existing TTA methods often suffer significant performance drops when facing additional class distribution shifts. We first analyze TTA methods under label distribution shifts and identify the presence of class-wise confusion patterns commonly observed across different covariate shifts. Based on this observation, we introduce label Distribution shift-Aware prediction Refinement for Test-time adaptation (DART), a novel TTA method that refines the predictions by focusing on class-wise confusion patterns. DART trains a prediction refinement module during an intermediate time by exposing it to several batches with diverse class distributions using the training dataset. This module is then used during test time to detect and correct class distribution shifts, significantly improving pseudo-label accuracy for test data. Our method exhibits 5-18% gains in accuracy under label distribution shifts on CIFAR-10C, without any performance degradation when there is no label distribution shift. Extensive experiments on CIFAR, PACS, OfficeHome, and ImageNet benchmarks demonstrate DART's ability to correct inaccurate predictions caused by test-time distribution shifts. This improvement leads to enhanced performance in existing TTA methods, making DART a valuable plug-in tool",
    "checked": true,
    "id": "695573eff1cc003ed97e6b97b366a4e8d0e3c178",
    "semantic_title": "label distribution shift-aware prediction refinement for test-time adaptation",
    "citation_count": 0,
    "authors": [
      "Minguk Jang",
      "Hye Won Chung"
    ]
  },
  "https://openreview.net/forum?id=Q7aXOnEGgU": {
    "title": "On the Sample Complexity of One Hidden Layer Networks with Equivariance, Locality and Weight Sharing",
    "volume": "main",
    "abstract": "Weight sharing, equivariance, and local filters, as in convolutional neural networks, are believed to contribute to the sample efficiency of neural networks. However, it is not clear how each one of these design choices contributes to the generalization error. Through the lens of statistical learning theory, we aim to provide insight into this question by characterizing the relative impact of each choice on the sample complexity. We obtain lower and upper sample complexity bounds for a class of single hidden layer networks. For a large class of activation functions, the bounds depend merely on the norm of filters and are dimension-independent. We also provide bounds for max-pooling and an extension to multi-layer networks, both with mild dimension dependence. We provide a few takeaways from the theoretical results. It can be shown that depending on the weight-sharing mechanism, the non-equivariant weight-sharing can yield a similar generalization bound as the equivariant one. We show that locality has generalization benefits, however the uncertainty principle implies a trade-off between locality and expressivity. We conduct extensive experiments and highlight some consistent trends for these models",
    "checked": true,
    "id": "36526d1c7a4adaf8b5e276261903d7464dc8f89d",
    "semantic_title": "on the sample complexity of one hidden layer networks with equivariance, locality and weight sharing",
    "citation_count": 0,
    "authors": [
      "Arash Behboodi",
      "Gabriele Cesa"
    ]
  },
  "https://openreview.net/forum?id=2wgnepQjyF": {
    "title": "Selective Prediction via Training Dynamics",
    "volume": "main",
    "abstract": "Selective Prediction is the task of rejecting inputs a model would predict incorrectly on. This involves a trade-off between input space coverage (how many data points are accepted) and model utility (how good is the performance on accepted data points). Current methods for selective prediction typically impose constraints on either the model architecture or the optimization objective; this inhibits their usage in practice and introduces unknown interactions with pre-existing loss functions. In contrast to prior work, we show that state-of-the-art se- lective prediction performance can be attained solely from studying the (discretized) training dynamics of a model. We propose a general framework that, given a test input, monitors metrics capturing the instability of predictions from intermediate models (i.e., checkpoints) obtained during training w.r.t. the final model's prediction. In particular, we reject data points exhibiting too much disagreement with the final prediction at late stages in training. The proposed rejection mechanism is domain-agnostic (i.e., it works for both discrete and real-valued prediction) and can be flexibly combined with existing selective prediction approaches as it does not require any train-time modifications. Our experimental evaluation on image classification, regression, and time series problems shows that our method beats past state-of-the-art accuracy/utility trade-offs on typical selective prediction benchmarks",
    "checked": true,
    "id": "064f5e3466986f347beab1be82a7d9e625bd7dfc",
    "semantic_title": "selective prediction via training dynamics",
    "citation_count": 0,
    "authors": [
      "Stephan Rabanser",
      "Anvith Thudi",
      "Kimia Hamidieh",
      "Adam Dziedzic",
      "Israfil Bahceci",
      "Akram Bin Sediq",
      "HAMZA SOKUN",
      "Nicolas Papernot"
    ]
  },
  "https://openreview.net/forum?id=pxxmUKKgel": {
    "title": "How Does Code Pretraining Affect Language Model Task Performance?",
    "volume": "main",
    "abstract": "Large language models are increasingly trained on corpora containing both natural language and non-linguistic data like source code. Aside from aiding programming-related tasks, anecdotal evidence suggests that including code in pretraining corpora may improve performance on other, unrelated tasks, yet to date no work has been able to establish a causal connection by controlling between language and code data. Here we do just this. We pretrain language models on datasets which interleave natural language and code in two different settings: competitive, in which the total volume of data seen during pretraining is held constant; and additive, in which the volume of language data is held constant. We study how the pretraining mixture affects performance on (a) compositionality, measured by generalization accuracy on semantic parsing and syntactic transformation tasks, and more broadly on (b) downstream non-code-related objectives, measured by performance on tasks from the BigBench benchmark. We find that pretraining on higher proportions of code improves performance on compositional tasks involving structured output (like semantic parsing), and mathematics. Conversely, increase code mixture can harm performance on other tasks, including on tasks that requires sensitivity to linguistic structure such as syntax or morphology, and tasks measuring real-world knowledge",
    "checked": true,
    "id": "3e1b14f6bcc7a4b3c756585898d4f36cab64fd64",
    "semantic_title": "how does code pretraining affect language model task performance?",
    "citation_count": 13,
    "authors": [
      "Jackson Petty",
      "Sjoerd van Steenkiste",
      "Tal Linzen"
    ]
  },
  "https://openreview.net/forum?id=uDRzORdPT7": {
    "title": "DeepRRTime: Robust Time-series Forecasting with a Regularized INR Basis",
    "volume": "main",
    "abstract": "This work presents a simple, inexpensive, theoretically motivated regularization term to enhance the robustness of deep time-index models for time-series forecasting. Recently, DeepTime demonstrated that this class of models can rival state-of-the-art deep historical-value models on the long time-series forecasting (LTSF) benchmarks. The DeepTime framework comprises two key components: (1) a time-indexed basis parameterized as an implicit neural representation (INR), and (2) a meta-learning formulation that fits observed data to this basis via ridge regression, then extrapolates the result to generate forecasts. Our regularization term encourages the time-indexed basis elements to be more unit standardized and less mutually correlated, intended to enable more robust ridge regression. The regularized variant matches or outperforms DeepTime on all LTSF benchmarks. Moreover, it is significantly more resilient to missing values in the lookback window at test time, enhances forecast accuracy when applied to higher-frequency data than it was trained on, and boosts performance when trained on smaller datasets. Overall, we conclude that our regularized approach sets a new state-of-the-art for deep time-index models",
    "checked": true,
    "id": "a2c1fc78ed92c94340ceb649b59715518f111b22",
    "semantic_title": "deeprrtime: robust time-series forecasting with a regularized inr basis",
    "citation_count": 0,
    "authors": [
      "Chandramouli Shama Sastry",
      "Mahdi Gilany",
      "Kry Yik-Chau Lui",
      "Martin Magill",
      "Alexander Pashevich"
    ]
  },
  "https://openreview.net/forum?id=Lt2H8Bd8jF": {
    "title": "Iterated $Q$-Network: Beyond One-Step Bellman Updates in Deep Reinforcement Learning",
    "volume": "main",
    "abstract": "The vast majority of Reinforcement Learning methods is largely impacted by the computation effort and data requirements needed to obtain effective estimates of action-value functions, which in turn determine the quality of the overall performance and the sample-efficiency of the learning procedure. Typically, action-value functions are estimated through an iterative scheme that alternates the application of an empirical approximation of the Bellman operator and a subsequent projection step onto a considered function space. It has been observed that this scheme can be potentially generalized to carry out multiple iterations of the Bellman operator at once, benefiting the underlying learning algorithm. However, until now, it has been challenging to effectively implement this idea, especially in high-dimensional problems. In this paper, we introduce iterated $Q$-Network (i-QN), a novel principled approach that enables multiple consecutive Bellman updates by learning a tailored sequence of action-value functions where each serves as the target for the next. We show that i-QN is theoretically grounded and that it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate the advantages of i-QN in Atari $2600$ games and MuJoCo continuous control problems",
    "checked": false,
    "id": "46233f3c5a0df20b9d7089586dfb54459aa148d1",
    "semantic_title": "iterated q-network: beyond one-step bellman updates in deep reinforcement learning",
    "citation_count": 3,
    "authors": [
      "Théo Vincent",
      "Daniel Palenicek",
      "Boris Belousov",
      "Jan Peters",
      "Carlo D'Eramo"
    ]
  },
  "https://openreview.net/forum?id=jZBAVFGUUo": {
    "title": "Towards Measuring Predictability: To which extent data-driven approaches can extract deterministic relations from data exemplified with time series prediction and classification",
    "volume": "main",
    "abstract": "Minimizing loss functions is one important ingredient for machine learning to fit parameters such that the machine learning models extract relations hidden in the data. The smaller the loss function value on various splittings of a dataset, the better the machine learning model is assumed to perform. However, datasets are usually generated by dynamics consisting of deterministic components, where relations are clearly defined and consequently learnable, as well as stochastic parts where outcomes are random and thus not predictable. Depending on the amplitude of the deterministic and stochastic processes, the best achievable loss function value varies and is usually not known in real data science scenarios. In this research, a statistical framework is developed that provides measures to address the predictability of a target given the available input data and, after training a machine learning model, how much of the deterministic relations have been missed by the model. Consequently, the presented framework allows to differentiate model errors into unpredictable parts regarding the given input and a systematic miss of deterministic relations. The work extends the definition of model success or failure as well as the convergence of a training process. Moreover, it is demonstrated how such measures can enrich the procedure of model training. The framework is showcased with time series data on different synthetic and real-world datasets. The code is available at https://github.com/Saleh-Gholam-Zadeh/predictability_measure",
    "checked": true,
    "id": "37b10a59ae5979b2a9d67b63806a6453901c65cc",
    "semantic_title": "towards measuring predictability: to which extent data-driven approaches can extract deterministic relations from data exemplified with time series prediction and classification",
    "citation_count": 0,
    "authors": [
      "Saleh GHOLAM ZADEH",
      "Vaisakh Shaj",
      "Patrick Jahnke",
      "Gerhard Neumann",
      "Tim Breitenbach"
    ]
  },
  "https://openreview.net/forum?id=wIgRV336hC": {
    "title": "Minimax Lower Bounds for Estimating Distributions on Low-dimensional Spaces",
    "volume": "main",
    "abstract": "Recent statistical analyses of Generative Adversarial Networks (GAN) suggest that the error in estimating the target distribution in terms of the $\\beta$-H\\\"{o}lder Integral Probability Metric (IPM) scales as $\\mathcal{O}\\left(n^{-\\frac{\\beta}{\\overline{d}_{\\mathbb{M}}+\\delta}} \\vee n^{-1/2} \\log n \\right)$. Here $\\overline{d}_{\\mathbb{M}}$ is the upper Minkowski dimension of the corresponding support $\\mathbb{M}$ of the data distribution and $\\delta$ is a positive constant. It is, however, unknown as to whether this rate is minimax optimal, i.e. whether there are estimators that achieve a better test-error rate. This paper demonstrates that the minimax rate for estimating unknown distributions in the $\\beta$-H\\\"{o}lder IPM on $\\mathbb{M}$ scales as $\\Omega\\left(n^{-\\frac{\\beta}{\\underline{d}_{\\mathbb{M}}-\\delta}} \\vee n^{-1/2}\\right)$, where $\\underline{d}_{\\mathbb{M}}$ is the lower Minkowski dimension of $\\mathbb{M}$. Thus if the low-dimensional structure $\\mathbb{M}$ is regular in the Minkowski sense, i.e. $\\overline{d}_{\\mathbb{M}} = \\underline{d}_{\\mathbb{M}}$, GANs are roughly minimax optimal in estimating distributions on $\\mathbb{M}$. Further, the paper shows that the minimax estimation rate in the $p$-Wasserstein metric scales as $\\Omega\\left(n^{-\\frac{1}{\\underline{d}_{\\mathbb{M}}-\\delta}} \\vee n^{-1/(2p)}\\right)$",
    "checked": true,
    "id": "d9e8f6923d10eed08cb28aaadcd7c835791f2055",
    "semantic_title": "minimax lower bounds for estimating distributions on low-dimensional spaces",
    "citation_count": 0,
    "authors": [
      "Saptarshi Chakraborty"
    ]
  },
  "https://openreview.net/forum?id=XWAXcxNg4n": {
    "title": "Test-Time Adaptation with Source Based Auxiliary Tasks",
    "volume": "main",
    "abstract": "This work tackles a key challenge in Test Time Adaptation~(TTA): adapting on limited data. This challenge arises naturally from two scenarios. (i) Current TTA methods are limited by the bandwidth with which the stream reveals data, since conducting several adaptation steps on each revealed batch from the stream will lead to overfitting. (ii) In many realistic scenarios, the stream reveals insufficient data for the model to fully adapt to a given distribution shift. We tackle the first scenario problem with auxiliary tasks where we leverage unlabeled data from the training distribution. In particular, we propose distilling the predictions of an originally pretrained model on clean data during adaptation. We found that our proposed auxiliary task significantly accelerates the adaptation to distribution shifts. We report a performance improvement over the state of the art by 1.5\\% and 6\\% on average across all corruptions on ImageNet-C under episodic and continual evaluation, respectively. To combat the second scenario of limited data, we analyze the effectiveness of combining federated adaptation with our proposed auxiliary task across different models even when different clients observe different distribution shifts. We find that not only federated averaging enhances adaptation, but combining it with our auxiliary task provides a notable 6\\% performance gains over previous TTA methods",
    "checked": true,
    "id": "3377fd05c9cbb2fcb50d6a32adbad30b8da4f6aa",
    "semantic_title": "test-time adaptation with source based auxiliary tasks",
    "citation_count": 1,
    "authors": [
      "Motasem Alfarra",
      "Alvaro Correia",
      "Bernard Ghanem",
      "Christos Louizos"
    ]
  },
  "https://openreview.net/forum?id=HlzjI2fn2T": {
    "title": "On the stability of gradient descent with second order dynamics for time-varying cost functions",
    "volume": "main",
    "abstract": "Gradient based optimization algorithms deployed in Machine Learning (ML) applications are often analyzed and compared by their convergence rates or regret bounds. While these rates and bounds convey valuable information they don't always directly translate to stability guarantees. Stability and similar concepts, like robustness, will become ever more important as we move towards deploying models in real-time and safety critical systems. In this work we build upon the results in Gaudio et al. 2021 and Moreu & Annaswamy 2022 for gradient descent with second order dynamics when applied to explicitly time varying cost functions and provide more general stability guarantees. These more general results can aid in the design and certification of these optimization schemes so as to help ensure safe and reliable deployment for real-time learning applications. We also hope that the techniques provided here will stimulate and cross-fertilize the analysis that occurs on the same algorithms from the online learning and stochastic optimization communities",
    "checked": true,
    "id": "6b777bc1ac928c5bb66730b9b836df361cd0413b",
    "semantic_title": "on the stability of gradient descent with second order dynamics for time-varying cost functions",
    "citation_count": 0,
    "authors": [
      "Travis E Gibson",
      "Sawal Acharya",
      "Anjali Parashar",
      "Joseph Emilio Gaudio",
      "Anuradha Annaswamy"
    ]
  },
  "https://openreview.net/forum?id=O4CQ5AM5yP": {
    "title": "REX: GPU-Accelerated Sim2Real Framework with Delay and Dynamics Estimation",
    "volume": "main",
    "abstract": "Sim2real, the transfer of control policies from simulation to the real world, is crucial for efficiently solving robotic tasks without the risks associated with real-world learning. However, discrepancies between simulated and real environments, especially due to unmodeled dynamics and latencies, significantly impact the performance of these transferred policies. In this paper, we address the challenges of sim2real transfer caused by latency and asynchronous dynamics in real-world robotic systems. Our approach involves developing a novel framework, REX (Robotic Environments with jaX), that uses a graph-based simulation model to incorporate latency effects while optimizing for parallelization on accelerator hardware. Our framework simulates the asynchronous, hierarchical nature of real-world systems, while simultaneously estimating system dynamics and delays from real-world data and implementing delay compensation strategies to minimize the sim2real gap. We validate our approach on two real-world systems, demonstrating its effectiveness in improving sim2real performance by accurately modeling both system dynamics and delays. Our results show that the proposed framework supports both accelerated simulation and real-time processing, making it valuable for robot learning",
    "checked": true,
    "id": "84440e6c10f8e59c8f0ce4852b62a20a5eb03f97",
    "semantic_title": "rex: gpu-accelerated sim2real framework with delay and dynamics estimation",
    "citation_count": 0,
    "authors": [
      "Bas van der Heijden",
      "Jens Kober",
      "Robert Babuska",
      "Laura Ferranti"
    ]
  },
  "https://openreview.net/forum?id=udVkqIDYSM": {
    "title": "Wonderful Team: Zero-Shot Physical Task Planning with Visual LLMs",
    "volume": "main",
    "abstract": "We introduce Wonderful Team, a multi-agent Vision Large Language Model (VLLM) framework for executing high-level robotic planning in a zero-shot regime. In our context, zero-shot high-level planning means that for a novel environment, we provide a VLLM with an image of the robot's surroundings and a task description, and the VLLM outputs the sequence of actions necessary for the robot to complete the task. Unlike previous methods for high-level visual planning for robotic manipulation, our method uses VLLMs for the entire planning process, enabling a more tightly integrated loop between perception, control, and planning. As a result, Wonderful Team's performance on real-world semantic and physical planning tasks often exceeds methods that rely on separate vision systems. For example, we see an average 40% success rate improvement on VimaBench over prior methods such as NLaP, an average 30% improvement over Trajectory Generators on tasks from the Trajectory Generator paper, including drawing and wiping a plate, and an average 70% improvement over Trajectory Generators on a new set of semantic reasoning tasks including environment rearrangement with implicit linguistic constraints. We hope these results highlight the rapid improvements of VLLMs in the past year, and motivate the community to consider VLLMs as an option for some high-level robotic planning problems in the future",
    "checked": true,
    "id": "b7a7081a6cd7f3e9887d9685ee9b65dee1af2f82",
    "semantic_title": "wonderful team: zero-shot physical task planning with visual llms",
    "citation_count": 0,
    "authors": [
      "Zidan Wang",
      "Rui Shen",
      "Bradly C. Stadie"
    ]
  },
  "https://openreview.net/forum?id=v47f4DwYZb": {
    "title": "Graph-level Representation Learning with Joint-Embedding Predictive Architectures",
    "volume": "main",
    "abstract": "Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a novel and powerful technique for self-supervised representation learning. They aim to learn an energy-based model by predicting the latent representation of a target signal y from the latent representation of a context signal x. JEPAs bypass the need for negative and positive samples, traditionally required by contrastive learning while avoiding the overfitting issues associated with generative pretraining. In this paper, we show that graph-level representations can be effectively modeled using this paradigm by proposing a Graph Joint-Embedding Predictive Architecture (Graph-JEPA). In particular, we employ masked modeling and focus on predicting the latent representations of masked subgraphs starting from the latent representation of a context subgraph. To endow the representations with the implicit hierarchy that is often present in graph-level concepts, we devise an alternative prediction objective that consists of predicting the coordinates of the encoded subgraphs on the unit hyperbola in the 2D plane. Through multiple experimental evaluations, we show that Graph-JEPA can learn highly semantic and expressive representations, as shown by the downstream performance in graph classification, regression, and distinguishing non-isomorphic graphs. The code is available at https://github.com/geriskenderi/graph-jepa",
    "checked": true,
    "id": "ab599a501d82d6d1c54d6db0574bf7f4f5a0a825",
    "semantic_title": "graph-level representation learning with joint-embedding predictive architectures",
    "citation_count": 5,
    "authors": [
      "Geri Skenderi",
      "Hang Li",
      "Jiliang Tang",
      "Marco Cristani"
    ]
  },
  "https://openreview.net/forum?id=L7sQ8CW2FY": {
    "title": "Conformalized Credal Regions for Classification with Ambiguous Ground Truth",
    "volume": "main",
    "abstract": "An open question in Imprecise Probabilistic Machine Learning is how to empirically derive a credal region (i.e., a closed and convex family of probabilities on the output space) from the available data, without any prior knowledge or assumption. In classification problems, credal regions are a tool that is able to provide provable guarantees under realistic assumptions by characterizing the uncertainty about the distribution of the labels. Building on previous work, we show that credal regions can be directly constructed using conformal methods. This allows us to provide a novel extension of classical conformal prediction to problems with ambiguous ground truth, that is, when the exact labels for given inputs are not exactly known. The resulting construction enjoys desirable practical and theoretical properties: (i) conformal coverage guarantees, (ii) smaller prediction sets (compared to classical conformal prediction regions) and (iii) disentanglement of uncertainty sources (epistemic, aleatoric). We empirically verify our findings on both synthetic and real datasets",
    "checked": true,
    "id": "33dc60f595b7c84be7637680883c500e9c30ed24",
    "semantic_title": "conformalized credal regions for classification with ambiguous ground truth",
    "citation_count": 5,
    "authors": [
      "Michele Caprio",
      "David Stutz",
      "Shuo Li",
      "Arnaud Doucet"
    ]
  },
  "https://openreview.net/forum?id=2nRcWy3RLM": {
    "title": "Bridging Causality, Individual Fairness, and Adversarial Robustness in the Absence of Structural Causal Model",
    "volume": "main",
    "abstract": "Despite the essential need for comprehensive considerations in responsible AI, factors such as robustness, fairness, and causality are often studied in isolation. Adversarial perturbation, used to identify vulnerabilities in models, and individual fairness, aiming for equitable treatment of similar individuals, despite initial differences, both depend on metrics to generate comparable input data instances. Previous attempts to define such joint metrics often lack general assumptions about data and were unable to reflect counterfactual proximity. To address this, our paper introduces a \\emph{causal fair metric} formulated based on causal structures encompassing sensitive attributes and protected causal perturbation. To enhance the practicality of our metric, we propose metric learning as a method for metric estimation and deployment in real-world problems in the absence of structural causal models. We also demonstrate the applications of the causal fair metric in classifiers. Empirical evaluation of real-world and synthetic datasets illustrates the effectiveness of our proposed metric in achieving an accurate classifier with fairness, resilience to adversarial perturbations, and a nuanced understanding of causal relationships",
    "checked": true,
    "id": "1fffbc79680c443dcc29741b9c658cc8aeea78eb",
    "semantic_title": "bridging causality, individual fairness, and adversarial robustness in the absence of structural causal model",
    "citation_count": 1,
    "authors": [
      "Ahmad Reza Ehyaei",
      "Golnoosh Farnadi",
      "Samira Samadi"
    ]
  },
  "https://openreview.net/forum?id=8tMMCf4YYn": {
    "title": "Partially Personalized Federated Learning: Breaking the Curse of Data Heterogeneity",
    "volume": "main",
    "abstract": "We consider a partially personalized formulation of Federated Learning (FL) that strikes a balance between the flexibility of personalization and cooperativeness of global training. In our framework, we split the variables into global parameters, which are shared across all clients, and individual local parameters, which are kept private. We prove that under the right split of parameters, it is possible to find global parameters that allow each client to fit their data perfectly, and refer to the obtained problem as overpersonalized. For instance, the shared global parameters can be used to learn good data representations, whereas the personalized layers are fine-tuned for a specific client. Moreover, we present a simple algorithm for the partially personalized formulation that offers significant benefits to all clients. In particular, it breaks the curse of data heterogeneity in several settings, such as training with local steps, asynchronous training, and Byzantine-robust training",
    "checked": true,
    "id": "89de9757f408b499d45b741d8b91db08c181dada",
    "semantic_title": "partially personalized federated learning: breaking the curse of data heterogeneity",
    "citation_count": 11,
    "authors": [
      "Konstantin Mishchenko",
      "Rustem Islamov",
      "Eduard Gorbunov",
      "Samuel Horváth"
    ]
  },
  "https://openreview.net/forum?id=gLQ801ewwp": {
    "title": "Identifying Axiomatic Mathematical Transformation Steps using Tree-Structured Pointer Networks",
    "volume": "main",
    "abstract": "The classification of mathematical relations has become a new area of research in deep learning. A major focus lies on determining mathematical equivalence. While previous work has simply approached the task as a binary classification without providing further insight into the underlying decision, we aim to iteratively find a sequence of necessary steps to transform a mathematical expression into an arbitrary equivalent form. Each step in this sequence is specified by an axiom together with its position of application. We denote this task as Stepwise Equation Transformation Identification (SETI) task. To solve the task efficiently, we further propose TreePointerNet, a novel architecture which exploits the inherent tree structure of mathematical equations and consists of three key building blocks: (i) a transformer model tailored to work on hierarchically tree-structured equations, making use of (ii) a copy-pointer mechanism to extract the exact location of a transformation in the tree and finally (iii) custom embeddings that map distinguishable occurrences of the same token type to a common embedding. In addition, we introduce new datasets of equations for the SETI task. We benchmark our model against various baselines and perform an ablation study to quantify the influence of our custom embeddings and the copy-pointer component. Furthermore, we test the robustness of our model on data of unseen complexity. Our results clearly show that incorporating the hierarchical structure, embeddings and copy-pointer into a single model is highly beneficial for solving the SETI task",
    "checked": true,
    "id": "5dbdaba12b85215ada611c33b80f431b89b5551d",
    "semantic_title": "identifying axiomatic mathematical transformation steps using tree-structured pointer networks",
    "citation_count": 0,
    "authors": [
      "Sebastian Wankerl",
      "Jan Pfister",
      "Andrzej Dulny",
      "Gerhard Götz",
      "Andreas Hotho"
    ]
  },
  "https://openreview.net/forum?id=p9KSFrTLx0": {
    "title": "Mixture Degree-Corrected Stochastic Block Model for Multi-Group Community Detection in Multiplex Graphs",
    "volume": "main",
    "abstract": "Multiplex graphs have emerged as a powerful tool for modeling complex data structures due to their ability to handle multiple relational layers. Clustering within a multiplex graph can involve merging vertices into communities that are consistent across all layers, grouping similar layers into clusters, or creating overlapping clusters among vertices and layers. However, a multiplex graph may exhibit distinct vertex communities based on the specific layers to which a vertex is connected. This scenario, termed multi-group community detection, significantly enhances the accuracy of clustering processes and aids in the interpretation of partitions. To date, the current literature on state-of-the-art community detection has not extensively addressed this modeling approach. In this paper, we introduce a novel methodology referred to as the \"Mixture Degree-Corrected Stochastic Block Model.\" This generative model, an extension of the widely utilized Degree-Corrected Stochastic Block Model (DCSBM), is designed to cluster similar layers by their community structures while simultaneously identifying communities within each layer's group. We provide a rigorous definition of the model and utilize an iterative technique to perform inference computations. Furthermore, we assess the identifiability of our proposed model and demonstrate the consistency of the maximum likelihood function through analytical analysis. The effectiveness of our method is evaluated using both real-word data sets and synthetic graphs",
    "checked": true,
    "id": "1d060acf3a6bdd0c5abf38882665851ff46ebc8d",
    "semantic_title": "mixture degree-corrected stochastic block model for multi-group community detection in multiplex graphs",
    "citation_count": 0,
    "authors": [
      "Noureddine Henka",
      "Mohamad Assaad",
      "Sami Tazi"
    ]
  },
  "https://openreview.net/forum?id=x1dXvvElVd": {
    "title": "Interpreting Neurons in Deep Vision Networks with Language Models",
    "volume": "main",
    "abstract": "In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks. DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from. Additionally, DnD is training-free, meaning we don't train any new models and can easily leverage more capable general purpose models in the future. We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions. Specifically, our method on average provides the highest quality labels and is more than 2× as likely to be selected as the best explanation for a neuron than the best baseline. Finally, we present a use case providing critical insights into land cover prediction models for sustainability applications",
    "checked": true,
    "id": "29c8873ec974145a3a2f847b105b5cff0d8dd85b",
    "semantic_title": "interpreting neurons in deep vision networks with language models",
    "citation_count": 7,
    "authors": [
      "Nicholas Bai",
      "Rahul Ajay Iyer",
      "Tuomas Oikarinen",
      "Akshay R. Kulkarni",
      "Tsui-Wei Weng"
    ]
  },
  "https://openreview.net/forum?id=f6yMdmrD2g": {
    "title": "Cooperative Minibatching in Graph Neural Networks",
    "volume": "main",
    "abstract": "Training large scale Graph Neural Networks (GNNs) requires significant computational resources, and the process is highly data-intensive. One of the most effective ways to reduce resource requirements is minibatch training coupled with graph sampling. GNNs have the unique property that items in a minibatch have overlapping data. However, the commonly implemented Independent Minibatching approach assigns each Processing Element (PE, i.e., cores and/or GPUs) its own minibatch to process, leading to duplicated computations and input data access across PEs. This amplifies the Neighborhood Explosion Phenomenon (NEP), which is the main bottleneck limiting scaling. To reduce the effects of NEP in the multi-PE setting, we propose a new approach called Cooperative Minibatching. Our approach capitalizes on the fact that the size of the sampled subgraph is a concave function of the batch size, leading to significant reductions in the amount of work as batch sizes increase. Hence, it is favorable for processors equipped with a fast interconnect to work on a large minibatch together as a single larger processor, instead of working on separate smaller minibatches, even though global batch size is identical. We also show how to take advantage of the same phenomenon in serial execution by generating dependent consecutive minibatches. Our experimental evaluations show up to 4x bandwidth savings for fetching vertex embeddings, by simply increasing this dependency without harming model convergence. Combining our proposed approaches, we achieve up to 64\\% speedup over Independent Minibatching on single-node multi GPU systems, using same resources",
    "checked": true,
    "id": "51cde01d005f61c7f545c8789d0b407fbde72d2e",
    "semantic_title": "cooperative minibatching in graph neural networks",
    "citation_count": 1,
    "authors": [
      "Muhammed Fatih Balin",
      "Dominique LaSalle",
      "Umit Catalyurek"
    ]
  },
  "https://openreview.net/forum?id=Ss9MTTN7OL": {
    "title": "Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) represent a significant advancement in artificial intelligence, finding applications across various domains. However, their reliance on massive internet-sourced datasets for training brings notable privacy issues, which are exacerbated in critical domains (e.g., healthcare). Moreover, certain application-specific scenarios may require fine-tuning these models on private data. This survey critically examines the privacy threats associated with LLMs, emphasizing the potential for these models to memorize and inadvertently reveal sensitive information. We explore current threats by reviewing privacy attacks on LLMs and propose comprehensive solutions for integrating privacy mechanisms throughout the entire learning pipeline. These solutions range from anonymizing training datasets to implementing differential privacy during training or inference and machine unlearning after training. Our comprehensive review of existing literature highlights ongoing challenges, available tools, and future directions for preserving privacy in LLMs. This work aims to guide the development of more secure and trustworthy AI systems by providing a thorough understanding of privacy preservation methods and their effectiveness in mitigating risks",
    "checked": true,
    "id": "71bf73fcc95350918b2b7c2148b591a32bc582d0",
    "semantic_title": "preserving privacy in large language models: a survey on current threats and solutions",
    "citation_count": 0,
    "authors": [
      "Michele Miranda",
      "Elena Sofia Ruzzetti",
      "Andrea Santilli",
      "Fabio Massimo Zanzotto",
      "Sébastien Bratières",
      "Emanuele Rodolà"
    ]
  },
  "https://openreview.net/forum?id=OGaTF9iOxi": {
    "title": "Maximum Mean Discrepancy on Exponential Windows for Online Change Detection",
    "volume": "main",
    "abstract": "Detecting changes is of fundamental importance when analyzing data streams and has many applications, e.g., in predictive maintenance, fraud detection, or medicine. A principled approach to detect changes is to compare the distributions of observations within the stream to each other via hypothesis testing. Maximum mean discrepancy (MMD), a (semi-)metric on the space of probability distributions, provides powerful non-parametric two-sample tests on kernel-enriched domains. In particular, MMD is able to detect any disparity between distributions under mild conditions. However, classical MMD estimators suffer from a quadratic runtime complexity, which renders their direct use for change detection in data streams impractical. In this article, we propose a new change detection algorithm, called Maximum Mean Discrepancy on Exponential Windows (MMDEW), that combines the benefits of MMD with an efficient computation based on exponential windows. We prove that MMDEW enjoys polylogarithmic runtime and logarithmic memory complexity and show empirically that it outperforms the state of the art on benchmark data streams",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Kalinke",
      "Marco Heyden",
      "Georg Gntuni",
      "Edouard Fouché",
      "Klemens Böhm"
    ]
  },
  "https://openreview.net/forum?id=aWRMvXTvPf": {
    "title": "Shapley Values of Structured Additive Regression Models and Application to RKHS Weightings of Functions",
    "volume": "main",
    "abstract": "Shapley values are widely used in machine learning to interpret model predictions. However, they have an important drawback in their computational time, which is exponential in the number of variables in the data. Recent work has yielded algorithms that can efficiently and exactly calculate the Shapley values of specific model families, such as Decision Trees and Generalized Additive Models (GAMs). Unfortunately, these model families are fairly restricted. Consequently, we present STAR-SHAP, an algorithm for efficiently calculating the Shapley values of Structured Additive Regression (STAR) models, a generalization of GAMs which allow any number of variable interactions. While the computational cost of STAR-SHAP scales exponentially in the size of these interactions, it is independent of the total number of variables. This allows the interpretation of more complex and flexible models. As long as the variable interactions are moderately-sized, the computation of the Shapley values will be fast, even on high-dimensional datasets. Since STAR models with more than pairwise interactions (e.g. GA2Ms) are seldom used in practice, we also present a new class of STAR models built on the RKHS Weightings of Functions paradigm. More precisely, we introduce a new RKHS Weighting instantiation, and show how to transform it and other RKHS Weightings into STAR models. We therefore introduce a new family of STAR models, as well as the means to interpret their outputs in a timely manner",
    "checked": true,
    "id": "2a39aeaa20b0692e7fe35550fa5f802501f3bd18",
    "semantic_title": "shapley values of structured additive regression models and application to rkhs weightings of functions",
    "citation_count": 0,
    "authors": [
      "Gabriel Dubé",
      "Mario Marchand"
    ]
  },
  "https://openreview.net/forum?id=WppTEs4Kkn": {
    "title": "On the effects of similarity metrics in decentralized deep learning under distribution shift",
    "volume": "main",
    "abstract": "Decentralized Learning (DL) enables privacy-preserving collaboration among organizations or users to enhance the performance of local deep learning models. However, model aggregation becomes challenging when client data is heterogeneous, and identifying compatible collaborators without direct data exchange remains a pressing issue. In this paper, we investigate the effectiveness of various similarity metrics in DL for identifying peers for model merging, conducting an empirical analysis across multiple datasets with distribution shifts. Our research provides insights into the performance of these metrics, examining their role in facilitating effective collaboration. By exploring the strengths and limitations of these metrics, we contribute to the development of robust DL methods",
    "checked": true,
    "id": "b31e9963381e083ddcea21f44aa3d2ee650ad006",
    "semantic_title": "on the effects of similarity metrics in decentralized deep learning under distribution shift",
    "citation_count": 0,
    "authors": [
      "Edvin Listo Zec",
      "Tom Hagander",
      "Eric Ihre-Thomason",
      "Sarunas Girdzijauskas"
    ]
  },
  "https://openreview.net/forum?id=VmfWywWuYQ": {
    "title": "Interactive Task Planning with Language Models",
    "volume": "main",
    "abstract": "An interactive robot framework accomplishes long-horizon task planning and can easily generalize to new goals or distinct tasks, even during execution. However, most traditional methods require predefined module design, which makes it hard to generalize to different goals. Recent large language model based approaches can allow for more open-ended planning but often require heavy prompt engineering or domain specific pretrained models. To tackle this, we propose a simple framework that achieves interactive task planning with language models by incorporating both high-level planning and low-level skill execution through function calling, leveraging pretrained vision models to ground the scene in language. We verify the robustness of our system on the real world task of making milk tea drinks. Our system is able to generate novel high-level instructions for unseen objectives and successfully accomplishes user tasks. Furthermore, when the user sends a new request, our system is able to replan accordingly with precision based on the new request, task guidelines and previously executed steps. Our approach is easy to adapt to different tasks by merely substituting the task guidelines, without the need for additional complex prompt engineering",
    "checked": true,
    "id": "50b59143bf3469f082b2308fa394bb6d55091a41",
    "semantic_title": "interactive task planning with language models",
    "citation_count": 38,
    "authors": [
      "Boyi Li",
      "Philipp Wu",
      "Pieter Abbeel",
      "Jitendra Malik"
    ]
  },
  "https://openreview.net/forum?id=4o8lIFkpn2": {
    "title": "\\copyright Plug-in Authorization for Human Copyright Protection in Text-to-Image Model",
    "volume": "main",
    "abstract": "This paper addresses the contentious issue of copyright infringement in images generated by text-to-image models, sparking debates among AI developers, content creators, and legal entities. State-of-the-art models create high-quality content without crediting original creators, causing concern in the artistic community and model providers. To mitigate this, we propose the ©Plug-in Authorization framework, introducing three operations: addition, extraction, and combination. Addition involves training a ©plug-in for specific copyright, facilitating proper credit attribution. The extraction allows creators to reclaim copyright from infringing models, and the combination enables users to merge different ©plug-ins. These operations act as permits, incentivizing fair use and providing flexibility in authorization. We present innovative approaches, ``Reverse LoRA'' for extraction and ``EasyMerge'' for seamless combination. Experiments in artist-style replication and cartoon IP recreation demonstrate ©plug-ins' effectiveness, offering a valuable solution for human copyright protection in the age of generative AIs. The code is available at \\url{https://github.com/zc1023/-Plug-in-Authorization.git}",
    "checked": false,
    "id": "17e7b58f99d5dbf6d7a117102f68d01aa84335b3",
    "semantic_title": "\\copyright plug-in authorization for human content copyright protection in text-to-image model",
    "citation_count": 2,
    "authors": [
      "Chao Zhou",
      "Huishuai Zhang",
      "Jiang Bian",
      "Weiming Zhang",
      "Nenghai Yu"
    ]
  },
  "https://openreview.net/forum?id=3Y3o0yFZfu": {
    "title": "Private Fine-tuning of Large Language Models with Zeroth-order Optimization",
    "volume": "main",
    "abstract": "Differentially private stochastic gradient descent (DP-SGD) allows models to be trained in a privacy-preserving manner, but has proven difficult to scale to the era of foundation models. We introduce DP-ZO, a private fine-tuning method for large language models by privatizing zeroth order optimization methods. A key insight into the design of our method is that the direction of the gradient in the zeroth-order optimization we use is random and the only information from training data is the step size, i.e., a scalar. Therefore, we only need to privatize the scalar step size, which is memory-efficient. DP-ZO provides a strong privacy-utility trade-off across different tasks, and model sizes that are comparable to DP-SGD in $(\\varepsilon,\\delta)$-DP. Notably, DP-ZO possesses significant advantages over DP-SGD in memory efficiency, and obtains higher utility in $\\varepsilon$-DP when using the Laplace mechanism",
    "checked": true,
    "id": "27f8c420f0967eba781f0e1c03db7363570b66af",
    "semantic_title": "private fine-tuning of large language models with zeroth-order optimization",
    "citation_count": 26,
    "authors": [
      "Xinyu Tang",
      "Ashwinee Panda",
      "Milad Nasr",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ]
  },
  "https://openreview.net/forum?id=bZzXgheUSD": {
    "title": "ADAPT to Robustify Prompt Tuning Vision Transformers",
    "volume": "main",
    "abstract": "The performance of deep models, including Vision Transformers, is known to be vulnerable to adversarial attacks. Many existing defenses against these attacks, such as adversarial training, rely on full-model fine-tuning to induce robustness in the models. These defenses require storing a copy of the entire model, that can have billions of parameters, for each task. At the same time, parameter-efficient prompt tuning is used to adapt large transformer- based models to downstream tasks without the need to save large copies. In this paper, we examine parameter-efficient prompt tuning of Vision Transformers for downstream tasks under the lens of robustness. We show that previous adversarial defense methods, when applied to the prompt tuning paradigm, suffer from gradient obfuscation and are vulnerable to adaptive attacks. We introduce ADAPT, a novel framework for performing adaptive adversarial training in the prompt tuning paradigm. Our method achieves competitive robust accuracy of ∼ 40% w.r.t. SOTA robustness methods using full-model fine-tuning, by tuning only ∼ 1% of the number of parameters",
    "checked": true,
    "id": "4d143d446b0206d87f043bcdd34b37be182386bc",
    "semantic_title": "adapt to robustify prompt tuning vision transformers",
    "citation_count": 0,
    "authors": [
      "Masih Eskandar",
      "Tooba Imtiaz",
      "Zifeng Wang",
      "Jennifer Dy"
    ]
  },
  "https://openreview.net/forum?id=MO1slfU9xy": {
    "title": "Explanation Shift: How Did the Distribution Shift Impact the Model?",
    "volume": "main",
    "abstract": "The performance of machine learning models on new data is critical for their success in real-world applications. Current methods to detect shifts in the input or output data distributions have limitations in identifying model behaviour changes when no labelled data is available. In this paper, we define \\emph{explanation shift} as the statistical comparison between how predictions from training data are explained and how predictions on new data are explained. We propose explanation shift as a key indicator to investigate the interaction between distribution shifts and learned models. We introduce an Explanation Shift Detector that operates on the explanation distributions, providing more sensitive and explainable changes in interactions between distribution shifts and learned models. We compare explanation shifts with other methods that are based on distribution shifts, showing that monitoring for explanation shifts results in more sensitive indicators for varying model behavior. We provide theoretical and experimental evidence and demonstrate the effectiveness of our approach on synthetic and real data. Additionally, we release an open-source Python package, \\texttt{skshift}, which implements our method and provides usage tutorials for further reproducibility",
    "checked": true,
    "id": "2e2a6732763142c9d3f3676255510dc879efdd60",
    "semantic_title": "explanation shift: how did the distribution shift impact the model?",
    "citation_count": 2,
    "authors": [
      "Carlos Mougan",
      "Klaus Broelemann",
      "Gjergji Kasneci",
      "Thanassis Tiropanis",
      "Steffen Staab"
    ]
  },
  "https://openreview.net/forum?id=zg0hPlABfY": {
    "title": "Enhancing Parameter Efficiency and Generalization in Large Models: A Regularized and Masked Low-Rank Adaptation Approach",
    "volume": "main",
    "abstract": "Large pre-trained models, such as large language models (LLMs), present significant resource challenges for fine-tuning due to their extensive parameter sizes, especially for applications in mobile systems. To address this, Low-Rank Adaptation (LoRA) has been developed to reduce resource consumption while maintaining satisfactory fine-tuning results. Despite its effectiveness, the original LoRA method faces the challenge of suboptimal performance. This paper investigates the intrinsic dimension of the matrix updates approximated by the LoRA method and reveals the performance benefits of increasing this intrinsic dimension. By employing regularization and a gradient masking method that encourages higher intrinsic dimension, the proposed method, termed Regularized and Masked LoRA (RM-LoRA), achieves superior generalization performance with the same or lower trainable parameter budget compared to the original LoRA and its latest variants across various open-source vision and language datasets",
    "checked": true,
    "id": "cd5ed671161e5479e3af3006a7157b614f9e1a1e",
    "semantic_title": "enhancing parameter efficiency and generalization in large models: a regularized and masked low-rank adaptation approach",
    "citation_count": 1,
    "authors": [
      "Yuzhu Mao",
      "Zihao Zhao",
      "Siqi Ping",
      "Yang Liu",
      "Wenbo Ding"
    ]
  },
  "https://openreview.net/forum?id=nu1SjVgSuy": {
    "title": "SPFormer: Enhancing Vision Transformer with Superpixel Representation",
    "volume": "main",
    "abstract": "This work introduces SPFormer, a novel Vision Transformer architecture enhanced by superpixel representation. Addressing the limitations of traditional Vision Transformers' fixed-size, non-adaptive patch partitioning, SPFormer divides the input image into irregular, semantically coherent regions (i.e., superpixels), effectively capturing intricate details. Notably, this is also applicable to intermediate features, and our whole model supports end-to-end training, empirically yielding superior performance across multiple benchmarks. For example, on the challenging ImageNet benchmark, SPFormer outperforms DeiT by 1.4% at the tiny-model size and by 1.1% at the small-model size. Moreover, a standout feature of SPFormer is its inherent explainability — the superpixel structure offers a window into the model's internal processes, providing valuable insights that enhance the model's interpretability and stronger robustness against challenging scenarios like image rotations and occlusions",
    "checked": true,
    "id": "1e63c422fa2ee6cea9a37d9bff985a6fc968e1b5",
    "semantic_title": "spformer: enhancing vision transformer with superpixel representation",
    "citation_count": 4,
    "authors": [
      "Jieru Mei",
      "Liang-Chieh Chen",
      "Alan Yuille",
      "Cihang Xie"
    ]
  },
  "https://openreview.net/forum?id=pWSrm3oP8b": {
    "title": "Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated Tokens",
    "volume": "main",
    "abstract": "Language models are often trained to maximize the likelihood of the next token given past tokens in the training dataset. However, during inference time, they are utilized differently, generating text sequentially and auto-regressively by using previously \\emph{generated} tokens as input to predict the next one. Marginal differences in predictions at each step can cascade over successive steps, resulting in different distributions from what the models were trained for and potentially leading to unpredictable behavior. This paper proposes two simple approaches based on model own generation to address this discrepancy between the training and inference time. Our first approach is Batch-Scheduled Sampling, where, during training, we stochastically choose between the ground-truth token from the dataset and the model's own generated token as input to predict the next token. This is done in an offline manner, modifying the context window by interleaving ground-truth tokens with those generated by the model. Our second approach is Reference-Answer-based Correction, where we explicitly incorporate a self-correction capability into the model during training. This enables the model to effectively self-correct the gaps between the generated sequences and the ground truth data without relying on an external oracle model. By incorporating our proposed strategies during training, we have observed an overall improvement in performance compared to baseline methods, as demonstrated by our extensive experiments using summarization, general question-answering, and math question-answering tasks",
    "checked": true,
    "id": "29c826fe501cc1f5e672cbcc7af7c7b297c57e15",
    "semantic_title": "bridging the training-inference gap in llms by leveraging self-generated tokens",
    "citation_count": 3,
    "authors": [
      "Zhepeng Cen",
      "Yao Liu",
      "Siliang Zeng",
      "Pratik Chaudhari",
      "Huzefa Rangwala",
      "George Karypis",
      "Rasool Fakoor"
    ]
  },
  "https://openreview.net/forum?id=oeg2ncuSPz": {
    "title": "Approximation Rates and VC-Dimension Bounds for (P)ReLU MLP Mixture of Experts",
    "volume": "main",
    "abstract": "Mixture-of-Experts (MoEs) can scale up beyond traditional deep learning models by employing a routing strategy in which each input is processed by a single ``expert'' deep learning model. This strategy allows us to scale up the number of parameters defining the MoE while maintaining sparse activation, i.e., MoEs only load a small number of their total parameters into GPU VRAM for the forward pass depending on the input. In this paper, we provide an approximation and learning-theoretic analysis of mixtures of expert MLPs with (P)ReLU activation functions. We first prove that for every error level $\\varepsilon>0$ and every Lipschitz function $f:[0,1]^n\\to \\mathbb{R}$, one can construct a MoMLP model (a Mixture-of-Experts comprising of (P)ReLU MLPs) which uniformly approximates $f$ to $\\varepsilon$ accuracy over $[0,1]^n$, while only requiring networks of $\\mathcal{O}(\\varepsilon^{-1})$ parameters to be loaded in memory. Additionally, we show that MoMLPs can generalize since the entire MoMLP model has a (finite) VC dimension of $\\tilde{O}(L\\max\\{nL,JW\\})$, if there are $L$ experts and each expert has a depth and width of $J$ and $W$, respectively",
    "checked": true,
    "id": "3a6daf68e04beea2946bc83c1cdd2176651bf9c1",
    "semantic_title": "approximation rates and vc-dimension bounds for (p)relu mlp mixture of experts",
    "citation_count": 1,
    "authors": [
      "Anastasis Kratsios",
      "Haitz Sáez de Ocáriz Borde",
      "Takashi Furuya",
      "Marc T. Law"
    ]
  },
  "https://openreview.net/forum?id=hJHf7PCuVt": {
    "title": "Counterfactual Fairness on Graphs: Augmentations, Hidden Confounders, and Identifiability",
    "volume": "main",
    "abstract": "We consider augmenting graph data with counterfactual generation in order to achieve fairness on downstream tasks. While this direction has been explored previously, existing methods invariably consider oversimplified causal relationships. Moreover, they often rely on unidentifiable models to encode causal relationships, making it hard to identify the true joint distribution and thus recover counterfactual graphs. To tackle these challenges, we introduce a causal model with hidden confounders on graphs, which considers the existence of hidden confounders affecting both node features and graph structures. We use an identifiable graph VAE model to simultaneously estimate hidden confounders and learn generation functions of the causal model. By incorporating a Gaussian mixture prior distribution, we improve the identifiability of our model to recover the joint distribution of observed data and hidden confounders. Using the generated counterfactual graphs, we enforce consistency in the predictions of classifiers for different counterfactual graphs, thereby achieving graph counterfactual fairness in these classifiers. Experimental results demonstrate the effectiveness of our method in improving the counterfactual fairness of classifiers on various graph tasks. Moreover, theoretical analysis, coupled with empirical results, illustrates the capability of our method to successfully identify hidden confounders",
    "checked": true,
    "id": "a3f3c0a49e75256ea6f23b65d0f3f5580368807a",
    "semantic_title": "counterfactual fairness on graphs: augmentations, hidden confounders, and identifiability",
    "citation_count": 0,
    "authors": [
      "Hongyi Ling",
      "Zhimeng Jiang",
      "Na Zou",
      "Shuiwang Ji"
    ]
  },
  "https://openreview.net/forum?id=uF9ZdAwrCT": {
    "title": "In-distribution adversarial attacks on object recognition models using gradient-free search",
    "volume": "main",
    "abstract": "Neural networks are susceptible to small perturbations in the form of 2D rotations and shifts, image crops, and even changes in object colors. Past works attribute these errors to dataset bias, claiming that models fail on these perturbed samples as they do not belong to the training data distribution. Here, we challenge this claim and present evidence of the widespread existence of perturbed images within the training data distribution, which networks fail to classify. We train models on data sampled from parametric distributions, then search inside this data distribution to find such in-distribution adversarial examples. This is done using our gradient-free evolution strategies (ES) based approach which we call CMA-Search. Despite training with a large-scale (0.5 million images), unbiased dataset of camera and light variations, CMA-Search can find a failure inside the data distribution in over 71% cases by perturbing the camera position. With lighting changes, CMA-Search finds misclassifications in 42% cases. These findings also extend to natural images from ImageNet and Co3D datasets. This phenomenon of in-distribution images presents a highly worrisome problem for artificial intelligence---they bypass the need for a malicious agent to add engineered noise to induce an adversarial attack. All code, datasets, and demos are available at https://github.com/Spandan-Madan/in_distribution_adversarial_examples",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Spandan Madan",
      "Tomotake Sasaki",
      "Hanspeter Pfister",
      "Tzu-Mao Li",
      "Xavier Boix"
    ]
  },
  "https://openreview.net/forum?id=KbteA50cni": {
    "title": "Distributed Quasi-Newton Method for Fair and Fast Federated Learning",
    "volume": "main",
    "abstract": "Federated learning (FL) is a promising technology that enables edge devices/clients to collaboratively and iteratively train a machine learning model under the coordination of a central server. The most common approach to FL is first-order methods, where clients send their local gradients to the server in each iteration. However, these methods often suffer from slow convergence rates. As a remedy, second-order methods, such as quasi-Newton, can be employed in FL to accelerate its convergence. Unfortunately, similarly to the first-order FL methods, the application of second-order methods in FL can lead to unfair models, achieving high average accuracy while performing poorly on certain clients' local datasets. To tackle this issue, in this paper we introduce a novel second-order FL framework, dubbed distributed quasi-Newton federated learning (DQN-Fed). This approach seeks to ensure fairness while leveraging the fast convergence properties of quasi-Newton methods in the FL context. Specifically, DQN-Fed helps the server update the global model in such a way that (i) all local loss functions decrease to promote fairness, and (ii) the rate of change in local loss functions aligns with that of the quasi-Newton method. We prove the convergence of DQN-Fed and demonstrate its \\textit{linear-quadratic} convergence rate. Moreover, we validate the efficacy of DQN-Fed across a range of federated datasets, showing that it surpasses state-of-the-art fair FL methods in fairness, average accuracy and convergence speed. The Code for paper is publicly available at \\url{https://anonymous.4open.science/r/DQN-Fed-FDD2}",
    "checked": true,
    "id": "b25baa6579f45bf010587e8579ae90dc5bb12276",
    "semantic_title": "distributed quasi-newton method for fair and fast federated learning",
    "citation_count": 3,
    "authors": [
      "Shayan Mohajer Hamidi",
      "Linfeng Ye"
    ]
  },
  "https://openreview.net/forum?id=hMO8sT9qaD": {
    "title": "Making Reliable and Flexible Decisions in Long-tailed Classification",
    "volume": "main",
    "abstract": "Long-tailed classification is challenging due to its heavy imbalance in class probabilities. While existing methods often focus on overall accuracy or accuracy for tail classes, they overlook a critical aspect: certain types of errors can carry greater risks than others in real-world long-tailed problems. For example, misclassifying patients (a tail class) as healthy individuals (a head class) entails far more serious consequences than the reverse scenario. To address this critical issue, we introduce Making Reliable and Flexible Decisions in Long-tailed Classification (RF-DLC), a novel framework aimed at reliable predictions in long-tailed problems. Leveraging Bayesian Decision Theory, we introduce an integrated gain to seamlessly combine long-tailed data distributions and the decision-making procedure. We further propose an efficient variational optimization strategy for the decision risk objective. Our method adapts readily to diverse utility matrices, which can be designed for specific tasks, ensuring its flexibility for different problem settings. In empirical evaluation, we design a new metric, False Head Rate, to quantify tail-sensitivity risk, along with comprehensive experiments on multiple real-world tasks, including large-scale image classification and uncertainty quantification, to demonstrate the reliability and flexibility of our method",
    "checked": true,
    "id": "cd86dbacb3171292e3fe52bf7922f81f3ca26345",
    "semantic_title": "making reliable and flexible decisions in long-tailed classification",
    "citation_count": 0,
    "authors": [
      "Bolian Li",
      "Ruqi Zhang"
    ]
  },
  "https://openreview.net/forum?id=dzQCRHKRdC": {
    "title": "Stochastic Variance-Reduced Newton: Accelerating Finite-Sum Minimization with Large Batches",
    "volume": "main",
    "abstract": "Stochastic variance reduction has proven effective at accelerating first-order algorithms for solving convex finite-sum optimization tasks such as empirical risk minimization. Incorporating second-order information has proven helpful in further improving the performance of these first-order methods. Yet, comparatively little is known about the benefits of using variance reduction to accelerate popular stochastic second-order methods such as Subsampled Newton. To address this, we propose Stochastic Variance-Reduced Newton (SVRN), a finite-sum minimization algorithm that provably accelerates existing stochastic Newton methods from $O(\\alpha\\log(1/\\epsilon))$ to $O\\big(\\frac{\\log(1/\\epsilon)}{\\log(n)}\\big)$ passes over the data, i.e., by a factor of $O(\\alpha\\log(n))$, where $n$ is the number of sum components and $\\alpha$ is the approximation factor in the Hessian estimate. Surprisingly, this acceleration gets more significant the larger the data size $n$, which is a unique property of SVRN. Our algorithm retains the key advantages of Newton-type methods, such as easily parallelizable large-batch operations and a simple unit step size. We use SVRN to accelerate Subsampled Newton and Iterative Hessian Sketch algorithms, and show that it compares favorably to popular first-order methods with variance~reduction",
    "checked": false,
    "id": "5d01e6c6137c94d0255eb5c03f749b4bb350d796",
    "semantic_title": "second-order information promotes mini-batch robustness in variance-reduced gradients",
    "citation_count": 1,
    "authors": [
      "Michal Derezinski"
    ]
  },
  "https://openreview.net/forum?id=GDN5cFTNaL": {
    "title": "Adjacency Search Embeddings",
    "volume": "main",
    "abstract": "In this study, we propose two novel Adjacency Search Embeddings that are inspired by the theory of identifying s-t minimum cuts: Maximum Adjacency Search (MAS) and Threshold-based Adjacency Search (TAS), which leverage both the node and a subset of its neighborhood to discern a set of nodes well-integrated into higher-order network structures. This serves as context for generating higher-order representations. Our approaches, when used in conjunction with the skip-gram model, exhibit superior effectiveness in comparison to other shallow embedding techniques in tasks such as link prediction and node classification. By incorporating our mechanisms as a preprocessing technique, we show substantial improvements in node classification performance across GNNs like GCN, GraphSage, and Gatv2 on both attributed and non-attributed networks. Furthermore, we substantiate the applicability of our approaches, shedding light on their aptness for specific graph scenarios",
    "checked": true,
    "id": "4092e5eaf704eb37f3087f968a870460a6127763",
    "semantic_title": "adjacency search embeddings",
    "citation_count": 0,
    "authors": [
      "Meher Chaitanya",
      "Kshitijaa Jaglan",
      "Ulrik Brandes"
    ]
  },
  "https://openreview.net/forum?id=4Xz0WBAiX4": {
    "title": "ExCeL: Combined Extreme and Collective Logit Information for Out-of-Distribution Detection",
    "volume": "main",
    "abstract": "Deep learning models often exhibit overconfidence in predicting out-of-distribution (OOD) data, underscoring the crucial role of OOD detection in ensuring reliability in predictions. Among various OOD detection approaches, post-hoc detectors have gained significant popularity, primarily due to their ease of implementation and competitive performance. However, recent benchmarks for OOD detection have revealed a lack of consistency in existing post-hoc methods. This inconsistency in post-hoc detectors can be attributed to their sole reliance either on extreme information, such as the maximum logit, or on collective information (i.e., information spanned across classes or training samples) embedded within the output layer. In this paper, we propose ExCeL, which combines both extreme and collective information within the output layer for enhanced and consistent performance in OOD detection. We leverage the logit of the top predicted class as the extreme information (i.e., the maximum logit), while the collective information is derived in a novel approach that involves assessing the probability of other classes appearing in subsequent ranks across various training samples. Our idea is motivated by the observation that, for in-distribution (ID) data, the ranking of classes beyond the predicted class is more deterministic compared to that in OOD data. Experiments conducted on CIFAR100, ImageNet-200, and ImageNet-1K datasets demonstrate that ExCeL consistently is among the five top-performing methods out of twenty-one existing post-hoc baselines when the joint performance on near-OOD and far-OOD is considered (i.e., in terms of AUROC and FPR95). Furthermore, ExCeL shows the best overall performance across all datasets, unlike other baselines that work best on one dataset but have a performance drop in others",
    "checked": true,
    "id": "3caac35d25967da4544249847c358a8a31f16bf2",
    "semantic_title": "excel: combined extreme and collective logit information for out-of-distribution detection",
    "citation_count": 1,
    "authors": [
      "Naveen Karunanayake",
      "Suranga Seneviratne",
      "Sanjay Chawla"
    ]
  },
  "https://openreview.net/forum?id=8C8LJIqF4y": {
    "title": "Time Series Domain Adaptation via Channel-Selective Representation Alignment",
    "volume": "main",
    "abstract": "Building generalizable and robust multivariate time series models can be challenging for real-world settings that involve significant shifts between training and testing. Existing unsupervised domain adaptation methods often struggle with real world distribution shifts which are often much more severe in some channels than others. To overcome these obstacles, we introduce a novel method called Signal Selection and Screening via Sinkhorn alignment for Time Series domain Adaptation (SSSS-TSA). SSSS-TSA addresses channel-level variations by aligning both individual channel representations and selectively weighted combined channel representations. This dual alignment strategy based on channel selection not only ensures effective adaptation to new domains but also maintains robustness in scenarios with training and testing set shifts or when certain channels are absent or corrupted. We evaluate our method on several time-series classification benchmarks and find that it consistently improves performance over existing methods. These results demonstrate the importance of adaptively selecting and screening different channels to enable more effective alignment across domains",
    "checked": true,
    "id": "3cc5f151763ad0571eda4f96288672692e264b69",
    "semantic_title": "time series domain adaptation via channel-selective representation alignment",
    "citation_count": 0,
    "authors": [
      "Nauman Ahad",
      "Mark A. Davenport",
      "Eva L Dyer"
    ]
  },
  "https://openreview.net/forum?id=OOgsAZdFOt": {
    "title": "Can AI-Generated Text be Reliably Detected? Stress Testing AI Text Detectors Under Various Attacks",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) can perform impressively well in various applications, such as document completion and question-answering. However, the potential for misuse of these models in activities such as plagiarism, generating fake news, and spamming has raised concerns about their responsible use. Consequently, the reliable detection of AI-generated text has become a critical area of research. Recent works have attempted to address this challenge through various methods, including the identification of model signatures in generated text outputs and the application of watermarking techniques to detect AI-generated text. These detectors have shown to be effective under their specific settings. In this paper, we stress-test the robustness of these AI text detectors in the presence of an attacker. We introduce recursive paraphrasing attack to stress test a wide range of detection schemes, including the ones using the watermarking as well as neural network-based detectors, zero-shot classifiers, and retrieval-based detectors. Our experiments conducted on passages, each approximately 300 tokens long, reveal the varying sensitivities of these detectors to our attacks. We also observe that these paraphrasing attacks add slight degradation to the text quality. We analyze the trade-offs between our attack strength and the resulting text quality, measured through human studies, perplexity scores, and accuracy on text benchmarks. Our findings indicate that while our recursive paraphrasing method can significantly reduce detection rates, it only slightly degrades text quality in many cases, highlighting potential vulnerabilities in current detection systems in the presence of an attacker. Additionally, we investigate the susceptibility of watermarked LLMs to spoofing attacks aimed at misclassifying human-written text as AI-generated. We demonstrate that an attacker can infer hidden AI text signatures without white-box access to the detection method, potentially leading to reputational risks for LLM developers. Finally, we provide a theoretical framework connecting the AUROC of the best possible detector to the Total Variation distance between human and AI text distributions. This analysis offers insights into the fundamental challenges of reliable detection as language models continue to advance",
    "checked": true,
    "id": "42f7d83e6c20fd4aaf3e3f53b18ab7db221ee300",
    "semantic_title": "can ai-generated text be reliably detected? stress testing ai text detectors under various attacks",
    "citation_count": 5,
    "authors": [
      "Vinu Sankar Sadasivan",
      "Aounon Kumar",
      "Sriram Balasubramanian",
      "Wenxiao Wang",
      "Soheil Feizi"
    ]
  },
  "https://openreview.net/forum?id=aiOHc1LGpD": {
    "title": "Differentially Private Gradient Flow based on the Sliced Wasserstein Distance",
    "volume": "main",
    "abstract": "Safeguarding privacy in sensitive training data is paramount, particularly in the context of generative modeling. This can be achieved through either differentially private stochastic gradient descent or a differentially private metric for training models or generators. In this paper, we introduce a novel differentially private generative modeling approach based on a gradient flow in the space of probability measures. To this end, we define the gradient flow of the Gaussian-smoothed Sliced Wasserstein Distance, including the associated stochastic differential equation (SDE). By discretizing and defining a numerical scheme for solving this SDE, we demonstrate the link between smoothing and differential privacy based on a Gaussian mechanism, due to a specific form of the SDE's drift term. We then analyze the differential privacy guarantee of our gradient flow, which accounts for both the smoothing and the Wiener process introduced by the SDE itself. Experiments show that our proposed model can generate higher-fidelity data at a low privacy budget compared to a generator-based model, offering a promising alternative",
    "checked": false,
    "id": "3e829b9802da22b9cb8fac2d3d61a3406030cb85",
    "semantic_title": "differentially private gradient flow based on the sliced wasserstein distance for non-parametric generative modeling",
    "citation_count": 3,
    "authors": [
      "Ilana Sebag",
      "Muni Sreenivas Pydi",
      "Jean-Yves Franceschi",
      "Alain Rakotomamonjy",
      "Mike Gartrell",
      "Jamal Atif",
      "Alexandre Allauzen"
    ]
  },
  "https://openreview.net/forum?id=dbaGuiYsTl": {
    "title": "Wasserstein Modality Alignment Makes Your Multimodal Transformer More Robust",
    "volume": "main",
    "abstract": "Multimodal fusion with a multimodal transformer is an effective method for both early and late fusion paradigms. However, in a multimodal transformer, the modality fusion is performed solely through the self-attention mechanism, which is originally designed for unimodal token sequences. To improve the self-attention mechanism for handling multimodal input, a parametric adapter model, like the Q-former in BLIP-2, is often used to align tokens from different modalities. Our empirical study unveils that only using the self-attention layer to perform the modality fusion makes the model less robust to missing modalities and input noise, as the model will overly rely on one certain modality. To improve the robustness of the transformer, our paper proposes an implicit approach based on Wasserstein distance that aligns tokens from different modalities without using any additional trainable parameters. Our empirical study shows that the implicit modality alignment improves the effectiveness of the multimodal Transformer in discriminative tasks, as well as its robustness to input noise and missing modalities. We conduct experiments on four downstream task datasets, including 2-modalities and 3-modalities tasks. We also consider different fusion paradigms, i.e., early and late fusion. The experimental results show that our proposed method has a significant improvement in both performance and robustness over all baselines across all datasets and fusion paradigms",
    "checked": true,
    "id": "e4bbca2a022d291de0f7f9ae0ef5a6445bb9e7c3",
    "semantic_title": "wasserstein modality alignment makes your multimodal transformer more robust",
    "citation_count": 2,
    "authors": [
      "zhuo zhi",
      "Yuxuan Sun",
      "Qiangqiang Wu",
      "Ziquan Liu",
      "Miguel R. D. Rodrigues"
    ]
  },
  "https://openreview.net/forum?id=AFxEdJwQcp": {
    "title": "A thorough reproduction and evaluation of $\\mu$P",
    "volume": "main",
    "abstract": "This paper is an independent empirical reproduction of the claimed benefits of the $\\mu$P parametrization proposed in \\citet{yang2020feature} and \\citet{yang2021tuning}. Under the so-called Standard Parametrization (SP), the weights of neural networks are initialized from the Gaussian distribution with variance scaling as the inverse of ``fan-in'', with the learning rate being the same for every layer. While this guarantees that (pre)activations are $\\mathcal{O}(1)$ at initialization with respect to width, it causes their scale to be width-dependent during training. To address this, \\citet{yang2020feature} and \\citet{yang2021tuning} proposed the Maximal Update Parametrization ($\\mu$P), which is also claimed to make the optimal value of various hyperparameters independent of width. However, despite its alleged benefits, $\\mu$P has not gained much traction among practitioners. Possibly, this could stem from a lack of thorough independent evaluation of $\\mu$P against SP. We address this by independently reproducing the empirical claims of the original works. At the same time, we substantially increase the scale of the experiments, by training $16000$ neural networks of sizes from $500$ to $1$B parameters, and empirically investigate $\\mu$P's effect on outputs, gradient updates, weights, training loss and validation loss. We find that generally $\\mu$P indeed delivers on its promises, even though this does not always translate to improved generalization",
    "checked": false,
    "id": "f203fcf73de35aaa8a385c56bbc2a15d269a81d6",
    "semantic_title": "development of a gluten- and lactose-free bakery product with nutritional and functional potential",
    "citation_count": 0,
    "authors": [
      "Georgios Vlassis",
      "David Belius",
      "Volodymyr Fomichov"
    ]
  },
  "https://openreview.net/forum?id=avDr56QjSI": {
    "title": "Semantic Alignment for Prompt-Tuning in Vision Language Models",
    "volume": "main",
    "abstract": "Going beyond mere fine-tuning of vision-language models (VLMs), learnable prompt tuning has emerged as a promising, resource-efficient alternative. Despite their potential, effectively learning prompts faces the following challenges: (i) training in a low-shot scenario results in overfitting, limiting adaptability, and yielding weaker performance on newer classes or datasets; (ii) prompt-tuning's efficacy heavily relies on the label space, with decreased performance in large class spaces, signaling potential gaps in bridging image and class concepts. In this work, we investigate whether better text semantics can help address these concerns. In particular, we introduce a prompt-tuning method that leverages class descriptions obtained from Large Language Models (LLMs). These class descriptions are used to bridge image and text modalities. Our approach constructs part-level description-guided image and text features, which are subsequently aligned to learn more generalizable prompts. Our comprehensive experiments conducted across 11 benchmark datasets show that our method outperforms established methods, demonstrating substantial improvements",
    "checked": true,
    "id": "874867550b74831bb0292e7723d68e5a54a04d0c",
    "semantic_title": "semantic alignment for prompt-tuning in vision language models",
    "citation_count": 0,
    "authors": [
      "Hari Chandana Kuchibhotla",
      "Sai Srinivas Kancheti",
      "Abbavaram Gowtham Reddy",
      "Vineeth N. Balasubramanian"
    ]
  },
  "https://openreview.net/forum?id=Utjw2z1ale": {
    "title": "Identifying Spurious Correlations using Counterfactual Alignment",
    "volume": "main",
    "abstract": "Models driven by spurious correlations often yield poor generalization performance. We propose the counterfactual (CF) alignment method to detect and quantify spurious correlations of black box classifiers. Our methodology is based on counterfactual images generated with respect to one classifier being input into other classifiers to see if they also induce changes in the outputs of these classifiers. The relationship between these responses can be quantified and used to identify specific instances where a spurious correlation exists. This is validated by observing intuitive trends in face-attribute and waterbird classifiers, as well as by fabricating spurious correlations and detecting their presence, both visually and quantitatively. Furthermore, utilizing the CF alignment method, we demonstrate that we can evaluate robust optimization methods (GroupDRO, JTT, and FLAC) by detecting a reduction in spurious correlations",
    "checked": true,
    "id": "cafa23373aad4d95b286692e5ff21554874c4d45",
    "semantic_title": "identifying spurious correlations using counterfactual alignment",
    "citation_count": 1,
    "authors": [
      "Joseph Paul Cohen",
      "Louis Blankemeier",
      "Akshay S Chaudhari"
    ]
  },
  "https://openreview.net/forum?id=LVQ8BEL5n3": {
    "title": "Numerically Robust Fixed-Point Smoothing Without State Augmentation",
    "volume": "main",
    "abstract": "Practical implementations of Gaussian smoothing algorithms have received a great deal of attention in the last 60 years. However, almost all work focuses on estimating complete time series (``fixed-interval smoothing'', $\\mathcal{O}(K)$ memory) through variations of the Rauch--Tung--Striebel smoother, rarely on estimating the initial states (``fixed-point smoothing'', $\\mathcal{O}(1)$ memory). Since fixed-point smoothing is a crucial component of algorithms for dynamical systems with unknown initial conditions, we close this gap by introducing a new formulation of a Gaussian fixed-point smoother. In contrast to prior approaches, our perspective admits a numerically robust Cholesky-based form (without downdates) and avoids state augmentation, which would needlessly inflate the state-space model and reduce the numerical practicality of any fixed-point smoother code. The experiments demonstrate how a JAX implementation of our algorithm matches the runtime of the fastest methods and the robustness of the most robust techniques while existing implementations must always sacrifice one for the other",
    "checked": true,
    "id": "213183a3d70f78b7cbfbe67c84843281a30e8bbc",
    "semantic_title": "numerically robust fixed-point smoothing without state augmentation",
    "citation_count": 2,
    "authors": [
      "Nicholas Krämer"
    ]
  },
  "https://openreview.net/forum?id=r8UFp9olQ0": {
    "title": "Explicitly Disentangled Representations in Object-Centric Learning",
    "volume": "main",
    "abstract": "Extracting structured representations from raw visual data is an important and long-standing challenge in machine learning. Recently, techniques for unsupervised learning of object-centric representations have raised growing interest. In this context, enhancing the robustness of the latent features can improve the efficiency and effectiveness of the training of downstream tasks. A promising step in this direction is to disentangle the factors that cause variation in the data. Previously, Invariant Slot Attention disentangled position, scale, and orientation from the remaining features. Extending this approach, we focus on separating the shape and texture components. In particular, we propose a novel architecture that biases object-centric models toward disentangling shape and texture components into two non-overlapping subsets of the latent space dimensions. These subsets are known a priori, hence before the training process. Experiments on a range of object-centric benchmarks reveal that our approach achieves the desired disentanglement while also numerically improving baseline performance in most cases. In addition, we show that our method can generate novel textures for a specific object or transfer textures between objects with distinct shapes",
    "checked": true,
    "id": "fb73d0a32c991132f366cb909d47b9d03536162d",
    "semantic_title": "explicitly disentangled representations in object-centric learning",
    "citation_count": 1,
    "authors": [
      "Riccardo Majellaro",
      "Jonathan Collu",
      "Aske Plaat",
      "Thomas M. Moerland"
    ]
  },
  "https://openreview.net/forum?id=Gb4HBGG9re": {
    "title": "Enhanced Federated Optimization: Adaptive Unbiased Client Sampling with Reduced Variance",
    "volume": "main",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm to train a global model across multiple devices without collecting local data. In FL, a server typically selects a subset of clients for each training round to optimize resource usage. Central to this process is the technique of unbiased client sampling, which ensures a representative selection of clients. Current methods primarily utilize a random sampling procedure which, despite its effectiveness, achieves suboptimal efficiency owing to the loose upper bound caused by the sampling variance. In this work, by adopting an independent sampling procedure, we propose a federated optimization framework focused on adaptive unbiased client sampling, improving the convergence rate via an online variance reduction strategy. In particular, we present the first adaptive client sampler, K-Vib, employing an independent sampling procedure. K-Vib achieves a linear speed-up on the regret bound $\\tilde{\\mathcal{O}}\\big(N^{\\frac{1}{3}}T^{\\frac{2}{3}}/K^{\\frac{4}{3}}\\big)$ within a set communication budget $K$. Empirical studies indicate that K-Vib doubles the speed compared to baseline algorithms, demonstrating significant potential in federated optimization",
    "checked": true,
    "id": "0f5283248ed5cd02e6ae394846bd8b246160a439",
    "semantic_title": "enhanced federated optimization: adaptive unbiased client sampling with reduced variance",
    "citation_count": 1,
    "authors": [
      "Dun Zeng",
      "Zenglin Xu",
      "Yu Pan",
      "Xu Luo",
      "Qifan Wang",
      "Xiaoying Tang"
    ]
  },
  "https://openreview.net/forum?id=vmmgFW3ztz": {
    "title": "Leveraging a Simulator for Learning Causal Representations from Post-Treatment Covariates for CATE",
    "volume": "main",
    "abstract": "Treatment effect estimation involves assessing the impact of different treatments on individual outcomes. Current methods estimate Conditional Average Treatment Effect (CATE) using observational datasets where covariates are collected before treatment assignment and outcomes are observed afterward, under assumptions like positivity and unconfoundedness. In this paper, we address a scenario where both covariates and outcomes are gathered after treatment. We show that post-treatment covariates render CATE unidentifiable, and recovering CATE requires learning treatment-independent causal representations. Prior work shows that such representations can be learned through contrastive learning if counterfactual supervision is available in observational data. However, since counterfactuals are rare, other works have explored using simulators that offer synthetic counterfactual supervision. Our goal in this paper is to systematically analyze the role of simulators in estimating CATE. We analyze the CATE error of several baselines and highlight their limitations. We then establish a generalization bound that characterizes the CATE error from jointly training on real and simulated distributions, as a function of the real-simulator mismatch. Finally, we introduce SimPONet, a novel method whose loss function is inspired from our generalization bound. We further show how SimPONet adjusts the simulator's influence on the learning objective based on the simulator's relevance to the CATE task. We experiment with various DGPs, by systematically varying the real-simulator distribution gap to evaluate SimPONet's efficacy against state-of-the-art CATE baselines",
    "checked": true,
    "id": "10ee27f91f35ebe3170d16683a676ef254f94f38",
    "semantic_title": "leveraging a simulator for learning causal representations from post-treatment covariates for cate",
    "citation_count": 0,
    "authors": [
      "Lokesh Nagalapatti",
      "Pranava Singhal",
      "Avishek Ghosh",
      "Sunita Sarawagi"
    ]
  },
  "https://openreview.net/forum?id=INijCSPtbQ": {
    "title": "Preventing Conflicting Gradients in Neural Marked Temporal Point Processes",
    "volume": "main",
    "abstract": "Neural Marked Temporal Point Processes (MTPP) are flexible models to capture complex temporal inter-dependencies between labeled events. These models inherently learn two predictive distributions: one for the arrival times of events and another for the types of events, also known as marks. In this study, we demonstrate that learning a MTPP model can be framed as a two-task learning problem, where both tasks share a common set of trainable parameters that are optimized jointly. We show that this often leads to the emergence of conflicting gradients during training, where task-specific gradients are pointing in opposite directions. When such conflicts arise, following the average gradient can be detrimental to the learning of each individual tasks, resulting in overall degraded performance. To overcome this issue, we introduce novel parametrizations for neural MTPP models that allow for separate modeling and training of each task, effectively avoiding the problem of conflicting gradients. Through experiments on multiple real-world event sequence datasets, we demonstrate the benefits of our framework compared to the original model formulations",
    "checked": true,
    "id": "bb1d72f6bd640c0eaf2109016073f8967c264394",
    "semantic_title": "preventing conflicting gradients in neural marked temporal point processes",
    "citation_count": 0,
    "authors": [
      "Tanguy Bosser",
      "Souhaib Ben Taieb"
    ]
  },
  "https://openreview.net/forum?id=LZ9FmeFeLV": {
    "title": "Towards LifeSpan Cognitive Systems",
    "volume": "main",
    "abstract": "Building a human-like system that continuously interacts with complex environments—whether simulated digital worlds or human society—presents several key challenges. Central to this is enabling continuous, high-frequency interactions, where the interactions are termed experiences. We refer to this envisioned system as the LifeSpan Cognitive System (LSCS). A critical feature of LSCS is its ability to engage in incremental and rapid updates while retaining and accurately recalling past experiences. In this paper we focus on the domain of Large Language Models (LLMs), where we identify two major challenges: (1) Abstraction and Experience Merging, and (2) Long-term Retention with Accurate Recall. These properties are essential for storing new experiences, organizing past experiences, and responding to the environment in ways that leverage relevant historical data. Unlike language models with continual learning, which typically rely on large corpora for fine-tuning and focus on improving performance within specific domains or tasks, LSCS must rapidly and incrementally update with new information from its environment at a high frequency. Existing technologies with the potential of solving the above two major challenges can be classified into four classes based on a conceptual metric called Storage Complexity, which measures the relative space required to store past experiences. Each of these four classes of technologies has its own strengths and limitations while we argue none of them alone can achieve LSCS alone. To this end, we propose a potential instantiation for LSCS that can integrate all four classes of technologies. The new instantiation, serving as a conjecture, operates through two core processes: Absorbing Experiences and Generating Responses",
    "checked": true,
    "id": "12fca89dc57c1162c62f9c24b2a2c8a2d3d2abd3",
    "semantic_title": "towards lifespan cognitive systems",
    "citation_count": 2,
    "authors": [
      "Yu Wang",
      "Chi Han",
      "Tongtong Wu",
      "Xiaoxin He",
      "Wangchunshu Zhou",
      "Nafis Sadeq",
      "Xiusi Chen",
      "Zexue He",
      "Wei Wang",
      "Gholamreza Haffari",
      "Heng Ji",
      "Julian McAuley"
    ]
  },
  "https://openreview.net/forum?id=IIVr4Hu3Oi": {
    "title": "Distributed Multi-Agent Lifelong Learning",
    "volume": "main",
    "abstract": "Lifelong learning (LL) machines are designed to operate safely in dynamic environments by continually updating their knowledge. Conventional LL paradigms often assume that new data come labeled and that each LL machine has to learn independently from its environment. However, human labeling is expensive and impractical in remote conditions where automation is most desired. We introduce the Peer Parallel Lifelong Learning (PEEPLL) framework for distributed Multi-Agent Lifelong Learning, where agents continually learn online by actively requesting assistance from other agents instead of relying on the expensive environment to teach them. Unlike classical distributed AI, where communication scales poorly, lifelong learners need to communicate only on information they have not yet learned. Additionally, agents reply only if they are highly confident: Our TRUE confidence score uses a compute-efficient application of Variational Autoencoder to quantify confidence in prediction without needing data reconstruction. TRUE outperforms traditional Entropy-based confidence scores, reducing communication overhead by 18.05\\% on CIFAR-100 and 5.8\\% on MiniImageNet. To improve system resilience to low-quality or adversarial responses, our agents selectively accept a subset of received responses using the REFINE algorithm, which results in a 51.99\\% increase in the percentage of correct accepted responses on CIFAR-100 and 25.79\\% on MiniImageNet. Like traditional LL agents, PEEPLL agents store a subset of previously acquired knowledge as memory to learn alongside new information to prevent forgetting. We propose a Dynamic Memory-Update mechanism for PEEPLL agents that improves QA's classification performance by 44.17\\% on CIFAR-100 and 26.8\\% on MiniImageNet compared to the baseline Memory-Update mechanism. Our findings demonstrate that a PEEPLL agent can outperform an LL agent even if the latter has environmental supervision available, thus significantly reducing the need for labeling. PEEPLL provides a framework to facilitate research in distributed multi-agent LL, marking a substantial step towards practical, scalable lifelong learning technologies at the edge",
    "checked": true,
    "id": "6a2a9505d2e0e08c54e4b06d78c63f927ff77dae",
    "semantic_title": "distributed multi-agent lifelong learning",
    "citation_count": 1,
    "authors": [
      "Prithviraj Tarale",
      "Edward Rietman",
      "Hava T Siegelmann"
    ]
  },
  "https://openreview.net/forum?id=T5OuTgPxHS": {
    "title": "Dependency-Aware Semi-Structured Sparsity of GLU Variants in Large Language Models",
    "volume": "main",
    "abstract": "The rapid advancement in Large Language Models (LLMs) has markedly enhanced the capabilities of language understanding and generation. However, the substantial model size poses hardware challenges, affecting both memory size for serving and inference latency for token generation. To address those challenges, we propose Dependency-aware Semi-structured Sparsity (DaSS), a new method for the recent prevalent GLU-based LLMs pruning, which incorporates structural dependency into the weight magnitude-based unstructured pruning. We introduce an MLP-specific pruning metric that evaluates the importance of each weight by jointly considering its magnitude and its corresponding MLP intermediate activation norms. DaSS facilitates a balance between the adaptability offered by unstructured pruning and the structural consistency inherent in dependency-based structured pruning. Empirical evaluations on LLaMA2, Mistral, and Gemma model families demonstrate that DaSS not only achieves superior perplexity and accuracy compared to SparseGPT and Wanda in achieving hardware-friendly N:M sparsity patterns but also maintains the computational efficiency of Wanda",
    "checked": true,
    "id": "eeb3655b040d44a30751bfc92312353505f926bd",
    "semantic_title": "dependency-aware semi-structured sparsity of glu variants in large language models",
    "citation_count": 1,
    "authors": [
      "Zhiyu Guo",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ]
  },
  "https://openreview.net/forum?id=0mGho8wrv5": {
    "title": "SelfEval: Leveraging discriminative nature of generative models for evaluation",
    "volume": "main",
    "abstract": "We present an automated way to evaluate the text alignment of text-to-image generative diffusion models using standard image-text recognition datasets. Our method, called SelfEval, uses the generative model to compute the likelihood of real images given text prompts, and the likelihood can be used to perform recognition tasks with the generative model. We evaluate generative models on standard datasets created for multimodal text-image discriminative learning and assess fine-grained aspects of their performance: attribute binding, color recognition, counting, shape recognition, spatial understanding. Existing automated metrics rely on an external pretrained model like CLIP (VLMs) or LLMs, and are sensitive to the exact pretrained model and its limitations. SelfEval sidesteps these issues, and to the best of our knowledge, is the first automated metric to show a high degree of agreement for measuring text-faithfulness with the gold-standard human evaluations across multiple generative models, benchmarks and evaluation metrics. SelfEval also reveals that generative models showcase competitive recognition performance on challenging tasks such as Winoground image-score compared to discriminative models. We hope SelfEval enables easy and reliable automated evaluation for diffusion models",
    "checked": false,
    "id": "f79c7abaaa4f13ad59b292230386cfbb15d4c335",
    "semantic_title": "selfeval: leveraging the discriminative nature of generative models for evaluation",
    "citation_count": 5,
    "authors": [
      "Sai Saketh Rambhatla",
      "Ishan Misra"
    ]
  },
  "https://openreview.net/forum?id=dHljjaNHh1": {
    "title": "Fairness Through Matching",
    "volume": "main",
    "abstract": "Group fairness requires that different protected groups, characterized by a given sensitive attribute, receive equal outcomes overall. Typically, the level of group fairness is measured by the statistical gap between predictions from different protected groups. In this study, we reveal an implicit property of existing group fairness measures, which provides an insight into how the group-fair models behave. Then, we develop a new group-fair constraint based on this implicit property to learn group-fair models. To do so, we first introduce a notable theoretical observation: every group-fair model has an implicitly corresponding transport map between the input spaces of each protected group. Based on this observation, we introduce a new group fairness measure termed Matched Demographic Parity (MDP), which quantifies the averaged gap between predictions of two individuals (from different protected groups) matched by a given transport map. Then, we prove that any transport map can be used in MDP to learn group-fair models, and develop a novel algorithm called Fairness Through Matching (FTM), which learns a group-fair model using MDP constraint with an user-specified transport map. We specifically propose two favorable types of transport maps for MDP, based on the optimal transport theory, and discuss their advantages. Experiments reveal that FTM successfully trains group-fair models with certain desirable properties by choosing the transport map accordingly",
    "checked": true,
    "id": "122596d081ef19fd126790a7039184099624232c",
    "semantic_title": "fairness through matching",
    "citation_count": 2,
    "authors": [
      "Kunwoong Kim",
      "Insung Kong",
      "Jongjin Lee",
      "Minwoo Chae",
      "Sangchul Park",
      "Yongdai Kim"
    ]
  },
  "https://openreview.net/forum?id=V2SD2uVKEE": {
    "title": "Zero-shot CLIP Class Forgetting via Text-image Space Adaptation",
    "volume": "main",
    "abstract": "Efficient class forgetting has attracted significant interest due to the high computational cost of retraining models from scratch whenever classes need to be forgotten. This need arises from data privacy regulations, the necessity to remove outdated information, and the possibility to enhance model robustness and security. In this paper we address class forgetting in vision-language CLIP model. Modern class forgetting methods for CLIP have demonstrated that zero-shot forgetting is achievable by generating synthetic data and fine-tuning both visual and textual encoders with a regularization loss. Our approach shows that class forgetting in CLIP can be accomplished in a zero-shot manner without any visual data by adapting the shared vision-text space of CLIP, thereby making the class forgetting process more efficient. Our method delivers superior results, demonstrating strong performance and complete class removal, regardless of the visual encoder used in CLIP. Furthermore, we explore what exactly is being targeted by the class forgetting algorithm discovering some interesting properties of CLIP features",
    "checked": true,
    "id": "594a08af403e3b54a55ef4ad9577d1add2ad7430",
    "semantic_title": "zero-shot clip class forgetting via text-image space adaptation",
    "citation_count": 2,
    "authors": [
      "Alexey Kravets",
      "Vinay P. Namboodiri"
    ]
  },
  "https://openreview.net/forum?id=lTX4bYREAZ": {
    "title": "A Scalable Approach for Mapper via Efficient Spatial Search",
    "volume": "main",
    "abstract": "Topological Data Analysis (TDA) is a branch of applied mathematics that studies the shape of high dimensional datasets using ideas from algebraic topology. The Mapper algorithm is a widely used tool in Topological Data Analysis, used for uncovering hidden structures in complex data. However, existing implementations often rely on naive and inefficient methods for constructing the open covers that Mapper is based on, leading to performance issues, especially with large, high-dimensional datasets. In this study, we introduce a novel, more scalable method for constructing open covers for Mapper, leveraging techniques from computational geometry. Our approach significantly enhances efficiency, improving Mapper's performance for large high-dimensional data. We will present theoretical insights into our method and demonstrate its effectiveness through experimental evaluations on well-known datasets, showcasing substantial improvements in visualization quality and computational performance. We implemented our method in a new Python library called \\emph{tda-mapper}, which is freely available at \\url{https://github.com/lucasimi/tda-mapper-python}, providing a powerful tool for TDA practitioners and researchers",
    "checked": true,
    "id": "04d34f81b96a36d023ba9d424cee502811e36a5e",
    "semantic_title": "a scalable approach for mapper via efficient spatial search",
    "citation_count": 0,
    "authors": [
      "Luca Simi"
    ]
  },
  "https://openreview.net/forum?id=VIkycTWDWo": {
    "title": "Doubly Robust Conditional VAE via Decoder Calibration: An Implicit KL Annealing Approach",
    "volume": "main",
    "abstract": "Several variants of Variational Autoencoders have been developed to address inherent limitations. Specifically, $\\sigma$-VAE utilizes a scaled identity matrix $\\sigma^2 I$ in the decoder variance, while $\\beta$-VAE introduces a hyperparameter $\\beta$ to reweight the negative ELBO loss. However, a unified theoretical and practical understanding of model optimality remains unclear. For example, existing learning theories on the global optimality of VAE provide limited insight into their empirical success. Previous work showed the mathematical equivalence between the variance scalar $\\sigma^2$ and the hyperparameter $\\beta$ in shaping the loss landscape. While $\\beta$-annealing is widely used, how to implement $\\sigma$-annealing is still unclear. This paper presents a comprehensive analysis of $\\sigma$-CVAE, highlighting its enhanced expressiveness in parameterizing conditional densities while addressing the associated estimation challenges arising from suboptimal variational inference. In particular, we propose Calibrated Robust $\\sigma$-CVAE, a doubly robust algorithm that facilitates accurate estimation of $\\sigma$ while effectively preventing the posterior collapse of $\\phi$. Our approach, leveraging functional neural decomposition and KL annealing techniques, provides a unified framework to understand both $\\sigma$-VAE and $\\beta$-VAE regarding parameter optimality and training dynamics. Experimental results on synthetic and real-world datasets demonstrate the superior performance of our method across various conditional density estimation tasks, highlighting its significance for accurate and reliable probabilistic modeling",
    "checked": true,
    "id": "c0fde934ffbfbb563c093ed69014253766c83895",
    "semantic_title": "doubly robust conditional vae via decoder calibration: an implicit kl annealing approach",
    "citation_count": 1,
    "authors": [
      "Chuanhui Liu",
      "Xiao Wang"
    ]
  },
  "https://openreview.net/forum?id=IZrt6hB2sI": {
    "title": "Improving CLIP Counting Accuracy via Parameter-Efficient Fine-Tuning",
    "volume": "main",
    "abstract": "We focus on addressing the object counting limitations of vision-language models, with a particular emphasis on Contrastive Language-Image Pre-training (CLIP) models. Centered on our hypothesis that counting knowledge can be abstracted into linear vectors within the text embedding space, we develop a parameter-efficient fine-tuning method and several zero-shot methods to improve CLIP's counting accuracy. Through comprehensive experiments, we demonstrate that our learning-based method not only outperforms full-model fine-tuning in counting accuracy but also retains the broad capabilities of pre-trained CLIP models. Our zero-shot text embedding editing techniques are also effective in situations where training data is scarce, and can be extended to improve Stable Diffusion's ability to generate images with precise object counts. We also contribute two specialized datasets to train and evaluate CLIP's counting capabilities. Our code is available at https://github.com/UW-Madison-Lee-Lab/CLIP_Counting",
    "checked": true,
    "id": "f09198f59b25e1f9bb8597746888cd7b35453e4f",
    "semantic_title": "improving clip counting accuracy via parameter-efficient fine-tuning",
    "citation_count": 0,
    "authors": [
      "Ruisu Zhang",
      "Yicong Chen",
      "Kangwook Lee"
    ]
  },
  "https://openreview.net/forum?id=ccu0M3nmlF": {
    "title": "Transfer Learning in $\\ell_1$ Regularized Regression: Hyperparameter Selection Strategy based on Sharp Asymptotic Analysis",
    "volume": "main",
    "abstract": "Transfer learning techniques aim to leverage information from multiple related datasets to enhance prediction quality against a target dataset. Such methods have been adopted in the context of high-dimensional sparse regression, and some Lasso-based algorithms have been invented: Trans-Lasso and Pretraining Lasso are such examples. These algorithms require the statistician to select hyperparameters that control the extent and type of information transfer from related datasets. However, selection strategies for these hyperparameters, as well as the impact of these choices on the algorithm's performance, have been largely unexplored. To address this, we conduct a thorough, precise study of the algorithm in a high-dimensional setting via an asymptotic analysis using the replica method. Our approach reveals a surprisingly simple behavior of the algorithm: Ignoring one of the two types of information transferred to the fine-tuning stage has little effect on generalization performance, implying that efforts for hyperparameter selection can be significantly reduced. Our theoretical findings are also empirically supported by \\rev{applications on real-world and semi-artificial datasets using the IMDb and MNIST datasets, respectively",
    "checked": false,
    "id": "f352eeaa059d0bed2668af7b813f8145d7c15beb",
    "semantic_title": "transfer learning in ℓ1 regularized regression: hyperparameter selection strategy based on sharp asymptotic analysis",
    "citation_count": 1,
    "authors": [
      "Koki Okajima",
      "Tomoyuki Obuchi"
    ]
  },
  "https://openreview.net/forum?id=qbrE0LR7fF": {
    "title": "Evaluating Posterior Probabilities: Decision Theory, Proper Scoring Rules, and Calibration",
    "volume": "main",
    "abstract": "Most machine learning classifiers are designed to output posterior probabilities for the classes given the input sample. These probabilities may be used to make the categorical decision on the class of the sample; provided as input to a downstream system; or provided to a human for interpretation. Evaluating the quality of the posteriors generated by these system is an essential problem which was addressed decades ago with the invention of proper scoring rules (PSRs). Unfortunately, much of the recent machine learning literature uses calibration metrics---most commonly, the expected calibration error (ECE)---as a proxy to assess posterior performance. The problem with this approach is that calibration metrics reflect only one aspect of the quality of the posteriors, ignoring the discrimination performance. For this reason, we argue that calibration metrics should play no role in the assessment of posterior quality. Expected PSRs should instead be used for this job, preferably normalized for ease of interpretation. In this work, we first give a brief review of PSRs from a practical perspective, motivating their definition using Bayes decision theory. We discuss why expected PSRs provide a principled measure of the quality of a system's posteriors and why calibration metrics are not the right tool for this job. We argue that calibration metrics, while not useful for performance assessment, may be used as diagnostic tools during system development. With this purpose in mind, we discuss a simple and practical calibration metric, called calibration loss, derived from a decomposition of expected PSRs. We compare this metric with the ECE and with the expected score divergence calibration metric from the PSR literature and argue, using theoretical and empirical evidence, that calibration loss is superior to these two metrics",
    "checked": true,
    "id": "b95028d2999cf25003166e3915e8e07e05584e61",
    "semantic_title": "evaluating posterior probabilities: decision theory, proper scoring rules, and calibration",
    "citation_count": 4,
    "authors": [
      "Luciana Ferrer",
      "Daniel Ramos"
    ]
  },
  "https://openreview.net/forum?id=LdflD41Gn8": {
    "title": "On the Properties and Estimation of Pointwise Mutual Information Profiles",
    "volume": "main",
    "abstract": "The pointwise mutual information profile, or simply profile, is the distribution of pointwise mutual information for a given pair of random variables. One of its important properties is that its expected value is precisely the mutual information between these random variables. In this paper, we analytically describe the profiles of multivariate normal distributions and show that for an expressive family of distributions, termed Bend and Mix Models, the profile can be accurately estimated using Monte Carlo methods. We then show how Bend and Mix Models can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how Bend and Mix Models can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary. The accompanying code is available at https://github.com/cbg-ethz/bmi",
    "checked": true,
    "id": "448cfe66236ce0cae83f0b2b2cb0db651979b48b",
    "semantic_title": "on the properties and estimation of pointwise mutual information profiles",
    "citation_count": 3,
    "authors": [
      "Paweł Czyż",
      "Frederic Grabowski",
      "Julia E Vogt",
      "Niko Beerenwinkel",
      "Alexander Marx"
    ]
  },
  "https://openreview.net/forum?id=BlYIPa0Fx1": {
    "title": "An analysis of the noise schedule for score-based generative models",
    "volume": "main",
    "abstract": "Score-based generative models (SGMs) aim at estimating a target data distribution by learning score functions using only noise-perturbed samples from the target. Recent literature has focused extensively on assessing the error between the target and estimated distributions, gauging the generative quality through the Kullback-Leibler (KL) divergence and Wasserstein distances. Under mild assumptions on the data distribution, we establish an upper bound for the KL divergence between the target and the estimated distributions, explicitly depending on any time-dependent noise schedule. Under additional regularity assumptions, taking advantage of favorable underlying contraction mechanisms, we provide a tighter error bound in Wasserstein distance compared to state-of-the-art results. In addition to being tractable, this upper bound jointly incorporates properties of the target distribution and SGM hyperparameters that need to be tuned during training. Finally, we illustrate these bounds through numerical experiments using simulated and CIFAR-10 datasets, identifying an optimal range of noise schedules within a parametric family",
    "checked": true,
    "id": "804a0ca9961430066376061e2541f6621695962b",
    "semantic_title": "an analysis of the noise schedule for score-based generative models",
    "citation_count": 7,
    "authors": [
      "Stanislas Strasman",
      "Antonio Ocello",
      "Claire Boyer",
      "Sylvain Le Corff",
      "Vincent Lemaire"
    ]
  },
  "https://openreview.net/forum?id=PtD2gVmb3J": {
    "title": "Global Safe Sequential Learning via Efficient Knowledge Transfer",
    "volume": "main",
    "abstract": "Sequential learning methods, such as active learning and Bayesian optimization, aim to select the most informative data for task learning. In many applications, however, data selection is constrained by unknown safety conditions, motivating the development of safe learning approaches. A promising line of safe learning methods uses Gaussian processes to model safety conditions, restricting data selection to areas with high safety confidence. However, these methods are limited to local exploration around an initial seed dataset, as safety confidence centers around observed data points. As a consequence, task exploration is slowed down and safe regions disconnected from the initial seed dataset remain unexplored. In this paper, we propose safe transfer sequential learning to accelerate task learning and to expand the explorable safe region. By leveraging abundant offline data from a related source task, our approach guides exploration in the target task more effectively. We also provide a theoretical analysis to explain why single-task method cannot cope with disconnected regions. Finally, we introduce a computationally efficient approximation of our method that reduces runtime through pre-computations. Our experiments demonstrate that this approach, compared to state-of-the-art methods, learns tasks with lower data consumption and enhances global exploration across multiple disjoint safe regions, while maintaining comparable computational efficiency",
    "checked": true,
    "id": "ea0099c1d04b1eca53b7a7fd911f54f3bd89181d",
    "semantic_title": "global safe sequential learning via efficient knowledge transfer",
    "citation_count": 2,
    "authors": [
      "Cen-You Li",
      "Olaf Dünnbier",
      "Marc Toussaint",
      "Barbara Rakitsch",
      "Christoph Zimmer"
    ]
  },
  "https://openreview.net/forum?id=QQE5j2OsLW": {
    "title": "Can Optimization Trajectories Explain Multi-Task Transfer?",
    "volume": "main",
    "abstract": "Despite the widespread adoption of multi-task training in deep learning, little is understood about how multi-task learning (MTL) affects generalization. Prior work has conjectured that the negative effects of MTL are due to optimization challenges that arise during training, and many optimization methods have been proposed to improve multi-task performance. However, recent work has shown that these methods fail to consistently improve multi-task generalization. In this work, we seek to improve our understanding of these failures by empirically studying how MTL impacts the optimization of tasks, and whether this impact can explain the effects of MTL on generalization. We show that MTL results in a generalization gap (a gap in generalization at comparable training loss) between single-task and multi-task trajectories early into training. However, we find that factors of the optimization trajectory previously proposed to explain generalization gaps in single-task settings cannot explain the generalization gaps between single-task and multi-task models. Moreover, we show that the amount of gradient conflict between tasks is correlated with negative effects to task optimization, but is not predictive of generalization. Our work sheds light on the underlying causes for failures in MTL and, importantly, raises questions about the role of general purpose multi-task optimization algorithms",
    "checked": true,
    "id": "f5ff48062127ef0c7f9e3c1f5e85ed796386b8a0",
    "semantic_title": "can optimization trajectories explain multi-task transfer?",
    "citation_count": 1,
    "authors": [
      "David Mueller",
      "Mark Dredze",
      "Nicholas Andrews"
    ]
  },
  "https://openreview.net/forum?id=yzbAFf8vd5": {
    "title": "A comparison between humans and AI at recognizing objects in unusual poses",
    "volume": "main",
    "abstract": "Deep learning is closing the gap with human vision on several object recognition benchmarks. Here we investigate this gap in the context of challenging images where objects are seen in unusual poses. We find that humans excel at recognizing objects in such poses. In contrast, state-of-the-art deep networks for vision (EfficientNet, SWAG, ViT, SWIN, BEiT, ConvNext) and state-of-the-art large vision-language models (Claude 3.5, Gemini 1.5, GPT-4) are systematically brittle on unusual poses, with the exception of Gemini showing excellent robustness to that condition. As we limit image exposure time, human performance degrades to the level of deep networks, suggesting that additional mental processes (requiring additional time) are necessary to identify objects in unusual poses. An analysis of error patterns of humans vs. networks reveals that even time-limited humans are dissimilar to feed-forward deep networks. In conclusion, our comparison reveals that humans are overall more robust than deep networks and that they rely on different mechanisms for recognizing objects in unusual poses. Understanding the nature of the mental processes taking place during extra viewing time may be key to reproduce the robustness of human vision in silico. All code and data is available",
    "checked": true,
    "id": "4480a0d4555694781aee528371c9f231f8c08817",
    "semantic_title": "a comparison between humans and ai at recognizing objects in unusual poses",
    "citation_count": 2,
    "authors": [
      "Netta Ollikka",
      "Amro Kamal Mohamed Abbas",
      "Andrea Perin",
      "Markku Kilpeläinen",
      "Stephane Deny"
    ]
  },
  "https://openreview.net/forum?id=V6ia5hWIMD": {
    "title": "νSAM: Memory-Efficient Sharpness-Aware Minimization via Nuclear Norm Constraints",
    "volume": "main",
    "abstract": "Sharpness-aware minimization (SAM) has been shown to improve the generalization of neural networks. However, the method comes at the expense of storing a perturbation of the model parameters, which can be restrictive when memory bound. We design a variant of SAM, called $\\nu$SAM, which obtains a low-rank perturbation by modifying the perturbation constraint. The update almost entirely removes the memory footprint of the perturbation without increasing the computational complexity, thus achieving close to a $1/3$ memory saving regarding the parameters when using SGD as the base optimizer. We demonstrate comparable performance of $\\nu$SAM with SAM on vision transformers both when training models from scratch and for fine-tuning. Interestingly, $\\nu$SAM seems to significantly improve performance for MLP-Mixer architectures across both settings. The results are corroborated theoretically, where we show that SAM with an \\emph{arbitrary} norm choice (which includes $\\nu$SAM) can converge even with fixed perturbation radius",
    "checked": true,
    "id": "3a222aa22ebb10325ddfe1df696876bc4fe6af6c",
    "semantic_title": "νsam: memory-efficient sharpness-aware minimization via nuclear norm constraints",
    "citation_count": 1,
    "authors": [
      "Thomas Pethick",
      "Parameswaran Raman",
      "Lenon Minorics",
      "Mingyi Hong",
      "Shoham Sabach",
      "Volkan Cevher"
    ]
  },
  "https://openreview.net/forum?id=WEYMCLu8u7": {
    "title": "Event-Triggered Time-Varying Bayesian Optimization",
    "volume": "main",
    "abstract": "We consider the problem of sequentially optimizing a time-varying objective function using time-varying Bayesian optimization (TVBO). Current approaches to TVBO require prior knowledge of a constant rate of change to cope with stale data arising from time variations. However, in practice, the rate of change is usually unknown. We propose an event-triggered algorithm, ET-GP-UCB, that treats the optimization problem as static until it detects changes in the objective function and then resets the dataset. This allows the algorithm to adapt online to realized temporal changes without the need for exact prior knowledge. The event trigger is based on probabilistic uniform error bounds used in Gaussian process regression. We derive regret bounds for adaptive resets without exact prior knowledge of the temporal changes and show in numerical experiments that ET-GP-UCB outperforms competing GP-UCB algorithms on both synthetic and real-world data. The results demonstrate that ET-GP-UCB is readily applicable without extensive hyperparameter tuning",
    "checked": false,
    "id": "5611913af9cff3094b1d0f9790d70cbcb1b67e8a",
    "semantic_title": "event-triggered safe bayesian optimization on quadcopters",
    "citation_count": 3,
    "authors": [
      "Paul Brunzema",
      "Alexander von Rohr",
      "Friedrich Solowjow",
      "Sebastian Trimpe"
    ]
  },
  "https://openreview.net/forum?id=PTTa3U29NR": {
    "title": "Optimization Dynamics of Equivariant and Augmented Neural Networks",
    "volume": "main",
    "abstract": "We investigate the optimization of neural networks on symmetric data, and compare the strategy of constraining the architecture to be equivariant to that of using data augmentation. Our analysis reveals that the relative geometry of the admissible and the equivariant layers, respectively, plays a key role. Under natural assumptions on the data, network, loss, and group of symmetries, we show that compatibility of the spaces of admissible layers and equivariant layers, in the sense that the corresponding orthogonal projections commute, implies that the sets of equivariant stationary points are identical for the two strategies. If the linear layers of the network also are given a unitary parametrization, the set of equivariant layers is even invariant under the gradient flow for augmented models. Our analysis however also reveals that even in the latter situation, stationary points may be unstable for augmented training although they are stable for the manifestly equivariant models",
    "checked": true,
    "id": "d1b523d58370258bcad096cc08071a7511ac1ff6",
    "semantic_title": "optimization dynamics of equivariant and augmented neural networks",
    "citation_count": 7,
    "authors": [
      "Oskar Nordenfors",
      "Fredrik Ohlsson",
      "Axel Flinth"
    ]
  },
  "https://openreview.net/forum?id=QplBL2pV4Z": {
    "title": "Federated Learning on Virtual Heterogeneous Data with Local-Global Dataset Distillation",
    "volume": "main",
    "abstract": "While Federated Learning (FL) is gaining popularity for training machine learning models in a decentralized fashion, numerous challenges persist, such as asynchronization, computational expenses, data heterogeneity, and gradient and membership privacy attacks. Lately, dataset distillation has emerged as a promising solution for addressing the aforementioned challenges by generating a compact synthetic dataset that preserves a model's training efficacy. However, we discover that using distilled local datasets can amplify the heterogeneity issue in FL. To address this, we propose Federated Learning on Virtual Heterogeneous Data with Local-Global Dataset Distillation (FedLGD), where we seamlessly integrate dataset distillation algorithms into FL pipeline and train FL using a smaller synthetic dataset (referred as virtual data). Specifically, to harmonize the domain shifts, we propose iterative distribution matching to inpaint global information to *local virtual data* and use federated gradient matching to distill *global virtual data* that serve as anchor points to rectify heterogeneous local training, without compromising data privacy. We experiment on both benchmark and real-world datasets that contain heterogeneous data from different sources, and further scale up to an FL scenario that contains a large number of clients with heterogeneous and class-imbalanced data. Our method outperforms *state-of-the-art* heterogeneous FL algorithms under various settings",
    "checked": true,
    "id": "05e345f6e18684c057631a1ff4d0ab324fd4e6fb",
    "semantic_title": "federated learning on virtual heterogeneous data with local-global dataset distillation",
    "citation_count": 8,
    "authors": [
      "Chun-Yin Huang",
      "Ruinan Jin",
      "Can Zhao",
      "Daguang Xu",
      "Xiaoxiao Li"
    ]
  },
  "https://openreview.net/forum?id=XL1N6iLr0G": {
    "title": "An Attribute-based Method for Video Anomaly Detection",
    "volume": "main",
    "abstract": "Video anomaly detection (VAD) identifies suspicious events in videos, which is critical for crime prevention and homeland security. In this paper, we propose a simple but highly effective VAD method that relies on attribute-based representations. The base version of our method represents every object by its velocity and pose, and computes anomaly scores by density estimation. Surprisingly, this simple representation is sufficient to achieve state-of-the-art performance in ShanghaiTech, the most commonly used VAD dataset. Combining our attribute-based representations with an off-the-shelf, pretrained deep representation yields state-of-the-art performance with a $99.1\\%, 93.7\\%$, and $85.9\\%$ AUROC on Ped2, Avenue, and ShanghaiTech, respectively",
    "checked": true,
    "id": "c5b951e23b3e6897ab888484ac8ed1c52dfd17c4",
    "semantic_title": "an attribute-based method for video anomaly detection",
    "citation_count": 0,
    "authors": [
      "Tal Reiss",
      "Yedid Hoshen"
    ]
  },
  "https://openreview.net/forum?id=8mgX3Uw2Ea": {
    "title": "Making Self-supervised Learning Robust to Spurious Correlation via Learning-speed Aware Sampling",
    "volume": "main",
    "abstract": "Self-supervised learning (SSL) has emerged as a powerful technique for learning rich representations from unlabeled data. The data representations can capture many underlying attributes of data, and are useful in downstream prediction tasks. In real-world settings, spurious correlations between some attributes (e.g. race, gender and age) and labels for downstream tasks often exist, e.g. disease findings are usually more prevalent among elderly patients. In this paper, we investigate SSL in the presence of spurious correlations and show that the SSL training loss can be minimized by capturing only a subset of conspicuous features relevant to those sensitive attributes, despite the presence of other important predictive features for the downstream tasks. To address this issue, we investigate the learning dynamics of SSL and observe that the learning is slower for samples that conflict with such correlations (e.g. elder patients without diseases). Motivated by these findings, we propose a learning-speed aware SSL (LA-SSL) approach, in which we sample each training data with a probability that is inversely related to its learning speed. We evaluate LA-SSL on three datasets that exhibit spurious correlations between different attributes, demonstrating the enhanced robustness of pretrained representations on downstream classification tasks",
    "checked": true,
    "id": "5e336ada1dbc75a34c627f761196d686a1e03997",
    "semantic_title": "making self-supervised learning robust to spurious correlation via learning-speed aware sampling",
    "citation_count": 1,
    "authors": [
      "Weicheng Zhu",
      "Sheng Liu",
      "Carlos Fernandez-Granda",
      "Narges Razavian"
    ]
  },
  "https://openreview.net/forum?id=tRpWaK3pWh": {
    "title": "A Generalization Bound for Nearly-Linear Networks",
    "volume": "main",
    "abstract": "We consider nonlinear networks as perturbations of linear ones. Based on this approach, we present a novel generalization bound that become non-vacuous for networks that are close to being linear. The main advantage over the previous works which propose non-vacuous generalization bounds is that our bound is *a priori*: performing the actual training is not required for evaluating the bound. To the best of our knowledge, it is the first non-vacuous generalization bound for neural nets possessing this property",
    "checked": true,
    "id": "98c17ef89e96e31893861dd0c30517464c9385df",
    "semantic_title": "a generalization bound for nearly-linear networks",
    "citation_count": 0,
    "authors": [
      "Eugene Golikov"
    ]
  },
  "https://openreview.net/forum?id=Qq4ge9Qe31": {
    "title": "Uncertainty-aware Evaluation of Auxiliary Anomalies with the Expected Anomaly Posterior",
    "volume": "main",
    "abstract": "Anomaly detection is the task of identifying examples that do not behave as expected. Because anomalies are rare and unexpected events, collecting real anomalous examples is often challenging in several applications. In addition, learning an anomaly detector with limited (or no) anomalies often yields poor prediction performance. One option is to employ auxiliary synthetic anomalies to improve the model training. However, synthetic anomalies may be of poor quality: anomalies that are unrealistic or indistinguishable from normal samples may deteriorate the detector's performance. Unfortunately, no existing methods quantify the quality of auxiliary anomalies. We fill in this gap and propose the expected anomaly posterior (EAP), an uncertainty-based score function that measures the quality of auxiliary anomalies by quantifying the total uncertainty of an anomaly detector. Experimentally on 40 benchmark datasets of images and tabular data, we show that EAP outperforms 12 adapted data quality estimators in the majority of cases. Code of EAP is available at: https://github.com/Lorenzo-Perini/ExpectedAnomalyPosterior",
    "checked": true,
    "id": "4c769c4ac60649c4559bd5e4edf438667080fda7",
    "semantic_title": "uncertainty-aware evaluation of auxiliary anomalies with the expected anomaly posterior",
    "citation_count": 1,
    "authors": [
      "Lorenzo Perini",
      "Maja Rudolph",
      "Sabrina Schmedding",
      "Chen Qiu"
    ]
  },
  "https://openreview.net/forum?id=BhOJreYmur": {
    "title": "MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks",
    "volume": "main",
    "abstract": "Multimodal fusion leverages information across modalities to learn better feature representations with the goal of improving performance in fusion-based tasks. However, multimodal datasets, especially in medical settings, are typically smaller than their unimodal counterparts, which can impede the performance of multimodal models. Additionally, the increase in the number of modalities is often associated with an overall increase in the size of the multimodal network, which may be undesirable in medical use cases. Utilizing smaller unimodal encoders may lead to sub-optimal performance, particularly when dealing with high-dimensional clinical data. In this paper, we propose the Modality-INformed knowledge Distillation (MIND) framework, a multimodal model compression approach based on knowledge distillation that transfers knowledge from ensembles of pre-trained deep neural networks of varying sizes into a smaller multimodal student. The teacher models consist of unimodal networks, allowing the student to learn from diverse representations. MIND employs multi-head joint fusion models, as opposed to single-head models, enabling the utilization of unimodal encoders in the case of unimodal samples without requiring imputation or masking of absent modalities. As a result, MIND generates an optimized multimodal model, enhancing both multimodal and unimodal representations. It can also be leveraged to balance multimodal learning during training. We evaluate MIND on binary classification and multilabel clinical prediction tasks using clinical time series data and chest X-ray images extracted from publicly available datasets. Additionally, we assess the generalizability of the MIND framework on three non-medical multimodal multiclass benchmark datasets. The experimental results demonstrate that MIND enhances the performance of the smaller multimodal network across all five tasks, as well as various fusion methods and multimodal network architectures, compared to several state-of-the-art baselines",
    "checked": true,
    "id": "30674e419a7148c6d81eff9db9647c3c95390827",
    "semantic_title": "mind: modality-informed knowledge distillation framework for multimodal clinical prediction tasks",
    "citation_count": 0,
    "authors": [
      "Alejandro Guerra-Manzanares",
      "Farah Shamout"
    ]
  },
  "https://openreview.net/forum?id=b68QOenPWy": {
    "title": "Active Learning via Classifier Impact and Greedy Selection for Interactive Image Retrieval",
    "volume": "main",
    "abstract": "Active Learning (AL) is a user-interactive approach aimed at reducing annotation costs by selecting the most crucial examples to label. Although AL has been extensively studied for image classification tasks, the specific scenario of interactive image retrieval has received relatively little attention. This scenario presents unique characteristics, including an open-set and class-imbalanced binary classification, starting with very few labeled samples. We introduce a novel batch-mode Active Learning framework named GAL (Greedy Active Learning) that better copes with this application. It incorporates new acquisition functions for sample selection that measure the impact of each unlabeled sample on the classifier. We further embed this strategy in a greedy selection approach, better exploiting the samples within each batch. We evaluate our framework with both linear (SVM) and non-linear MLP/Gaussian Process classifiers. For the Gaussian Process case, we show a theoretical guarantee on the greedy approximation. Finally, we assess our performance for the interactive content-based image retrieval task on several benchmarks and demonstrate its superiority over existing approaches and common baselines. Code is available at https://github.com/barleah/GreedyAL",
    "checked": true,
    "id": "56de60301579b830d9671767fce1aa6aeacf8795",
    "semantic_title": "active learning via classifier impact and greedy selection for interactive image retrieval",
    "citation_count": 1,
    "authors": [
      "Leah Bar",
      "Boaz Lerner",
      "Nir Darshan",
      "Rami Ben-Ari"
    ]
  },
  "https://openreview.net/forum?id=I4IAwVOZrM": {
    "title": "Lifelong Learning in StyleGAN through Latent Subspaces",
    "volume": "main",
    "abstract": "StyleGAN is one of the most versatile generative models that have emerged in recent times. However, when it is trained continually on a stream of data (potentially previously unseen distributions), it tends to forget the distribution it has learned, as is the case with any other generative model, due to catastrophic forgetting. Recent studies have shown that the latent space of StyleGAN is very versatile, as data from a variety of distributions can be inverted onto it. In this paper, we propose StyleCL, a method that leverages this property to enable lifelong learning in StyleGAN without forgetting. Specifically, given a StyleGAN trained on a certain task (dataset), we propose to learn a latent subspace characterized by a set of dictionary vectors in its latent space, one for each novel, unseen task (or dataset). We also learn a relatively small set of parameters (feature adaptors) in the weight space to complement the dictionary learning in the latent space. Furthermore, we introduce a method that utilizes the similarity between tasks to effectively reuse the feature adaptor parameters from the previous tasks, aiding in the learning process for the current task at hand. Our approach guarantees that the parameters from previous tasks are reused only if they contribute to a beneficial forward transfer of knowledge. Remarkably, StyleCL avoids catastrophic forgetting because the set of dictionary and the feature adaptor parameters are unique for each task. We demonstrate that our method, StyleCL, achieves better generation quality on multiple datasets with significantly fewer additional parameters per task compared to previous methods. This is a consequence of learning task-specific dictionaries in the latent space, which has a much lower dimensionality compared to the weight space. Code for this work is available at \\href{https://github.com/kadarsh22/StyleCL}{link}",
    "checked": true,
    "id": "8a4e56d4adb8af5108a9a2f9df92392d30a13748",
    "semantic_title": "lifelong learning in stylegan through latent subspaces",
    "citation_count": 0,
    "authors": [
      "Adarsh Kappiyath",
      "ANMOL GARG",
      "Ramya Hebbalaguppe",
      "Prathosh AP"
    ]
  },
  "https://openreview.net/forum?id=bwRxXiGO9A": {
    "title": "Towards Cross-Tokenizer Distillation: the Universal Logit Distillation Loss for LLMs",
    "volume": "main",
    "abstract": "Deploying large language models (LLMs) with billions of parameters is often impractical in industrial settings due to constraints like cost, latency, and hardware limitations. Knowledge distillation (KD) provides a solution by compressing the knowledge from large, resource-intensive models into task-specific smaller ones. Various strategies exist, some relying on the text generated by the teacher model, optionally, leveraging its output logits to improve learning. However, these logit-based methods usually require the teacher and student models to share the same tokenizer, which limits their applicability across different model families. In this paper, we propose the Universal Logit Distillation (ULD) loss, which uses optimal transport theory to enable distillation across different architectures and tokenizers. Our results demonstrate that ULD loss effectively facilitates the distillation process, paving the way for a more widespread use of distillation",
    "checked": true,
    "id": "1991666b99d1f9781aab32af504168748c117557",
    "semantic_title": "towards cross-tokenizer distillation: the universal logit distillation loss for llms",
    "citation_count": 19,
    "authors": [
      "Nicolas Boizard",
      "Kevin El Haddad",
      "CELINE HUDELOT",
      "Pierre Colombo"
    ]
  },
  "https://openreview.net/forum?id=CTkABQvnkm": {
    "title": "Decoupled Sequence and Structure Generation for Realistic Antibody Design",
    "volume": "main",
    "abstract": "Recently, deep learning has made rapid progress in antibody design, which plays a key role in the advancement of therapeutics. A dominant paradigm is to train a model to jointly generate the antibody sequence and the structure as a candidate. However, the joint generation requires the model to generate both the discrete amino acid categories and the continuous 3D coordinates; this limits the space of possible architectures and may lead to suboptimal performance. In response, we propose an antibody sequence-structure decoupling (ASSD) framework, which separates sequence generation and structure prediction. Although our approach is simple, our idea allows the use of powerful neural architectures and demonstrates notable performance improvements. We also find that the widely used non-autoregressive generators promote sequences with overly repeating tokens. Such sequences are both out-of-distribution and prone to undesirable developability properties that can trigger harmful immune responses in patients. To resolve this, we introduce a composition-based objective that allows an efficient trade-off between high performance and low token repetition. ASSD shows improved performance in various antibody design experiments, while the composition-based objective successfully mitigates token repetition of non-autoregressive models",
    "checked": true,
    "id": "6828f2dd9c674ac03f0764858f617261c359c6ab",
    "semantic_title": "decoupled sequence and structure generation for realistic antibody design",
    "citation_count": 0,
    "authors": [
      "Nayoung Kim",
      "Minsu Kim",
      "Sungsoo Ahn",
      "Jinkyoo Park"
    ]
  },
  "https://openreview.net/forum?id=pxdSm7PW5Q": {
    "title": "Reviving Life on the Edge: Joint Score-Based Graph Generation of Rich Edge Attributes",
    "volume": "main",
    "abstract": "Graph generation is integral to various engineering and scientific disciplines. Nevertheless, existing methodologies tend to overlook the generation of edge attributes. However, we identify critical applications where edge attributes are essential, making prior methods potentially unsuitable in such contexts. Moreover, while trivial adaptations are available, empirical investigations reveal their limited efficacy as they do not properly model the interplay among graph components. To address this, we propose a joint score-based model of nodes and edges for graph generation that considers all graph components. Our approach offers three key novelties: (1) node and edge attributes are combined in an attention module that generates samples based on the two ingredients, (2) node, edge and adjacency information are mutually dependent during the graph diffusion process, and (3) the framework enables the generation of graphs with rich attributes along the edges, providing a more expressive formulation for generative tasks than existing works. We evaluate our method on challenging benchmarks involving real-world and synthetic datasets in which edge features are crucial. Additionally, we introduce a new synthetic dataset that incorporates edge values. Furthermore, we propose a novel application that greatly benefits from the method due to its nature: the generation of traffic scenes represented as graphs. Our method outperforms other graph generation methods, demonstrating a significant advantage in edge-related measures",
    "checked": true,
    "id": "1f74244a72075f5ee8a88b94f3f8b1450ec18f01",
    "semantic_title": "reviving life on the edge: joint score-based graph generation of rich edge attributes",
    "citation_count": 1,
    "authors": [
      "Nimrod Berman",
      "Eitan Kosman",
      "Dotan Di Castro",
      "Omri Azencot"
    ]
  },
  "https://openreview.net/forum?id=60Gi1w6hte": {
    "title": "Directed Graph Generation with Heat Kernels",
    "volume": "main",
    "abstract": "Existing work on graph generation has, so far, mainly focused on undirected graphs. In this paper we propose a denoising autoencoder-based generative model that exploits the global structure of directed graphs (also called digraphs) via their Laplacian dynamics and enables one-shot generation. Our noising encoder uses closed-form expressions based on the heat equation to corrupt its digraph input with uniform noise. Our decoder reconstructs the corrupted representation by exploiting the global topological information of the graph included in its random walk Laplacian matrix. Our approach generalizes a special class of exponential kernels over discrete structures, called diffusion kernels or heat kernels, to the non-symmetric case via Reproducing Kernel Banach Spaces (RKBS). This connection with heat kernels provides us with a geometrically motivated algorithm related to Gaussian processes and dimensionality reduction techniques such as Laplacian eigenmaps. It also allows us to interpret and exploit the eigenproperties of the Laplacian matrix. We provide an experimental analysis of our approach on different types of synthetic datasets and show that our model is able to generate directed graphs that follow the distribution of the training dataset even if it is multimodal",
    "checked": true,
    "id": "f720220de38a8cdacdb5e8189118c86ef5a5798e",
    "semantic_title": "directed graph generation with heat kernels",
    "citation_count": 1,
    "authors": [
      "Marc T. Law",
      "Karsten Kreis",
      "Haggai Maron"
    ]
  },
  "https://openreview.net/forum?id=eakh1Edffd": {
    "title": "Reinforcement learning with non-ergodic reward increments: robustness via ergodicity transformations",
    "volume": "main",
    "abstract": "Envisioned application areas for reinforcement learning (RL) include autonomous driving, precision agriculture, and finance, which all require RL agents to make decisions in the real world. A significant challenge hindering the adoption of RL methods in these domains is the non-robustness of conventional algorithms. In particular, the focus of RL is typically on the expected value of the return. The expected value is the average over the statistical ensemble of infinitely many trajectories, which can be uninformative about the performance of the average individual. For instance, when we have a heavy-tailed return distribution, the ensemble average can be dominated by rare extreme events. Consequently, optimizing the expected value can lead to policies that yield exceptionally high returns with a probability that approaches zero but almost surely result in catastrophic outcomes in single long trajectories. In this paper, we develop an algorithm that lets RL agents optimize the long-term performance of individual trajectories. The algorithm enables the agents to learn robust policies, which we show in an instructive example with a heavy-tailed return distribution and standard RL benchmarks. The key element of the algorithm is a transformation that we learn from data. This transformation turns the time series of collected returns into one for whose increments expected value and the average over a long trajectory coincide. Optimizing these increments results in robust policies",
    "checked": true,
    "id": "b92ab7d522c15a41021228164d7414824b97843a",
    "semantic_title": "reinforcement learning with non-ergodic reward increments: robustness via ergodicity transformations",
    "citation_count": 0,
    "authors": [
      "Dominik Baumann",
      "Erfaun Noorani",
      "James Price",
      "Ole Peters",
      "Colm Connaughton",
      "Thomas B. Schön"
    ]
  },
  "https://openreview.net/forum?id=bHdEtW5E7O": {
    "title": "Federated Learning with Efficient Local Adaptation for Realized Volatility Prediction",
    "volume": "main",
    "abstract": "Financial markets present unique challenges for Federated Learning (FL) due to fragmented datasets, dynamic participation, and the critical need for precise and reliable predictions. Isolated local datasets often fail to capture the full spectrum of market dynamics, blocking accurate realized volatility predictions. Unlike traditional FL methods that focus on improving convergence during the training process, we propose Federated Learning with Adaptive Robustness and Efficiency for Local Adaptation (FLARE-LA), a novel framework designed to optimize predictive performance after the global training phase. FLARE-LA leverages Taylor-based local linearization and probabilistic optimization to efficiently adapt global models to local data distributions, enabling fast responsiveness to new market conditions. This adaptability ensures trained local models align with real-world scenarios, making FLARE-LA particularly suited to dynamic financial applications. Extensive experimental evaluations demonstrate FLARE-LA's superior performance, showcasing its ability to significantly enhance post-FL outcomes compared to state-of-the-art FL algorithms. The results underscore FLARE-LA's unique capability to drive advancements in financial forecasting and other high-stakes, rapidly evolving domains",
    "checked": true,
    "id": "553ad5cf8632f8588aa67c15262d236f1930aa90",
    "semantic_title": "federated learning with efficient local adaptation for realized volatility prediction",
    "citation_count": 1,
    "authors": [
      "Lei Zhao",
      "Lin Cai",
      "Wu-Sheng Lu"
    ]
  },
  "https://openreview.net/forum?id=MvYddudHuE": {
    "title": "Reweighting Improves Conditional Risk Bounds",
    "volume": "main",
    "abstract": "In this work, we study the weighted empirical risk minimization (weighted ERM) schema, in which an additional data-dependent weight function is incorporated when the empirical risk function is being minimized. We show that under a general ``balanceable\" Bernstein condition, one can design a weighted ERM estimator to achieve superior performance in certain sub-regions over the one obtained from standard ERM, and the superiority manifests itself through a data-dependent constant term in the error bound. These sub-regions correspond to large-margin ones in classification settings and low-variance ones in heteroscedastic regression settings, respectively. Our findings are supported by evidence from synthetic data experiments",
    "checked": true,
    "id": "8524e047929901fdcff4523b1c2088fa2aa358f8",
    "semantic_title": "reweighting improves conditional risk bounds",
    "citation_count": 1,
    "authors": [
      "Yikai Zhang",
      "Jiahe Lin",
      "Fengpei Li",
      "Songzhu Zheng",
      "Anant Raj",
      "Anderson Schneider",
      "Yuriy Nevmyvaka"
    ]
  },
  "https://openreview.net/forum?id=vZGZIIgcG4": {
    "title": "Cost-Efficient Online Decision Making: A Combinatorial Multi-Armed Bandit Approach",
    "volume": "main",
    "abstract": "Online decision making plays a crucial role in numerous real-world applications. In many scenarios, the decision is made based on performing a sequence of tests on the incoming data points. However, performing all tests can be expensive and is not always possible. In this paper, we provide a novel formulation of the online decision making problem based on combinatorial multi-armed bandits and take the (possibly stochastic) cost of performing tests into account. Based on this formulation, we provide a new framework for cost-efficient online decision making which can utilize posterior sampling or BayesUCB for exploration. We provide a theoretical analysis of Thompson Sampling for cost-efficient online decision making, and present various experimental results that demonstrate the applicability of our framework to real-world problems",
    "checked": true,
    "id": "2d97391a1946ba5bc52ab358a4dc12eb6821ac90",
    "semantic_title": "cost-efficient online decision making: a combinatorial multi-armed bandit approach",
    "citation_count": 0,
    "authors": [
      "Arman Rahbar",
      "Niklas Åkerblom",
      "Morteza Haghir Chehreghani"
    ]
  },
  "https://openreview.net/forum?id=DqWvxSQ1TK": {
    "title": "From Promise to Practice: A Study of Common Pitfalls Behind the Generalization Gap in Machine Learning",
    "volume": "main",
    "abstract": "The world of Machine Learning (ML) offers great promise, but often there is a noticeable gap between claims made in research papers and the model's practical performance in real-life applications. This gap can often be attributed to systematic errors and pitfalls that occur during the development phase of ML models. This study aims to systematically identify these errors. For this, we break down the ML process into four main stages: data handling, model design, model evaluation, and reporting. Across these stages, we have identified fourteen common pitfalls based on a comprehensive review of around 60 papers discussing either broad challenges or specific pitfalls within ML pipeline. Moreover, Using the Brain Tumor Segmentation (BraTS) dataset, we perform three experiments to illustrate the impacts of these pitfalls, providing examples of how they can skew results and affect outcomes. In addition, we also perform a review to study the frequency of unclear reporting regarding these pitfalls in ML research. The goal of this review was to assess whether authors have adequately addressed these pitfalls in their reports. For this, we review 126 randomly chosen papers on image segmentation from the ICCV (2013-2021) and MICCAI (2013-2022) conferences from the last ten years. The results from this review show a notable oversight of these issues, with many of the papers lacking clarity on how the pitfalls are handled. This highlights an important gap in current reporting practices within the ML community. The codes for the experiments will be published upon acceptance",
    "checked": true,
    "id": "488409805f0959b6a8cd224336a6dd706ab94c41",
    "semantic_title": "from promise to practice: a study of common pitfalls behind the generalization gap in machine learning",
    "citation_count": 0,
    "authors": [
      "Saeideh Ghanbari Azar",
      "Lorenzo Tronchin",
      "Attila Simkó",
      "Tufve Nyholm",
      "Tommy Löfstedt"
    ]
  },
  "https://openreview.net/forum?id=3mJZfL77WM": {
    "title": "Highway Graph to Accelerate Reinforcement Learning",
    "volume": "main",
    "abstract": "Reinforcement Learning (RL) algorithms often struggle with low training efficiency. A common approach to address this challenge is integrating model-based planning algorithms, such as Monte Carlo Tree Search (MCTS) or Value Iteration (VI), into the environmental model. However, VI faces a significant limitation: it requires iterating over a large tensor with dimensions $|\\mathcal{S}|\\times |\\mathcal{A}| \\times |\\mathcal{S}|$, where $\\mathcal{S}$ and $\\mathcal{A}$ represent the state and action spaces, respectively. This process updates the value of the preceding state $s_{t-1}$ based on the succeeding state $s_t$ through value propagation, resulting in computationally intensive operations. To enhance the training efficiency of RL algorithms, we propose improving the efficiency of the value learning process. In deterministic environments with discrete state and action spaces, we observe that on the sampled empirical state-transition graph, a non-branching sequence of transitions—termed a \\textit{highway}—can take the agent directly from $s_0$ to $s_T$ without deviation through intermediate states. On these non-branching highways, the value-updating process can be streamlined into a single-step operation, eliminating the need for iterative, step-by-step updates. Building on this observation, we introduce a novel graph structure called the \\textit{highway graph} to model state transitions. The highway graph compresses the transition model into a compact representation, where edges can encapsulate multiple state transitions, enabling value propagation across multiple time steps in a single iteration. By integrating the highway graph into RL (as a model-based off-policy RL method), the training process is significantly accelerated, particularly in the early stages of training. Experiments across four categories of environments demonstrate that our method learns significantly faster than established and state-of-the-art model-free and model-based RL algorithms (often by a factor of 10 to 150) while maintaining equal or superior expected returns. Furthermore, a deep neural network-based agent trained using the highway graph exhibits improved generalization capabilities and reduced storage costs",
    "checked": true,
    "id": "aa75604e4a03a101eb8c83e8b53bb0f1b6313f5d",
    "semantic_title": "highway graph to accelerate reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Zidu Yin",
      "Zhen Zhang",
      "Dong Gong",
      "Stefano V Albrecht",
      "Javen Qinfeng Shi"
    ]
  },
  "https://openreview.net/forum?id=DCAeXwLenB": {
    "title": "Optimal Transport for Domain Adaptation through Gaussian Mixture Models",
    "volume": "main",
    "abstract": "Machine learning systems operate under the assumption that training and test data are sampled from a fixed probability distribution. However, this assumptions is rarely verified in practice, as the conditions upon which data was acquired are likely to change. In this context, the adaptation of the unsupervised domain requires minimal access to the data of the new conditions for learning models robust to changes in the data distribution. Optimal transport is a theoretically grounded tool for analyzing changes in distribution, especially as it allows the mapping between domains. However, these methods are usually computationally expensive as their complexity scales cubically with the number of samples. In this work, we explore optimal transport between Gaussian Mixture Models (GMMs), which is conveniently written in terms of the components of source and target GMMs. We experiment with 9 benchmarks, with a total of $85$ adaptation tasks, showing that our methods are more efficient than previous shallow domain adaptation methods, and they scale well with number of samples $n$ and dimensions $d$",
    "checked": true,
    "id": "d224802d61c32b2e5e3b68897042dfd3c4ce19f1",
    "semantic_title": "optimal transport for domain adaptation through gaussian mixture models",
    "citation_count": 1,
    "authors": [
      "Eduardo Fernandes Montesuma",
      "Fred Maurice NGOLE MBOULA",
      "Antoine Souloumiac"
    ]
  },
  "https://openreview.net/forum?id=gpHOtQQPJG": {
    "title": "Optimization and Generalization Guarantees for Weight Normalization",
    "volume": "main",
    "abstract": "Weight normalization (WeightNorm) is widely used in practice for the training of deep neural networks and modern deep learning libraries have built-in implementations of it. In this paper, we provide the first theoretical characterizations of both optimization and generalization of deep WeightNorm models with smooth activation functions. For optimization, from the form of the Hessian of the loss, we note that a small Hessian of the predictor leads to a tractable analysis. Thus, we bound the spectral norm of the Hessian of WeightNorm networks and show its dependence on the network width and weight normalization terms--the latter being unique to networks without WeightNorm. Then, we use this bound to establish training convergence guarantees under suitable assumptions for gradient decent. For generalization, we use WeightNorm to get a uniform convergence based generalization bound, which is independent from the width and depends sublinearly on the depth. Finally, we present experimental results which illustrate how the normalization terms and other quantities of theoretical interest relate to the training of WeightNorm networks",
    "checked": true,
    "id": "d8bfc3f5e3ea2ae2f9fba42b6c8ea5ef6bedf125",
    "semantic_title": "optimization and generalization guarantees for weight normalization",
    "citation_count": 0,
    "authors": [
      "Pedro Cisneros-Velarde",
      "Zhijie Chen",
      "Sanmi Koyejo",
      "Arindam Banerjee"
    ]
  },
  "https://openreview.net/forum?id=LzmsvRTqaJ": {
    "title": "Shared Stochastic Gaussian Process Latent Variable Models: A Multi-modal Generative model for Quasar spectra",
    "volume": "main",
    "abstract": "This work proposes a scalable probabilistic latent variable model based on Gaussian processes in the context of multiple observation spaces. We focus on an application in astrophysics where it is typical for data sets to contain both observed spectral features as well as scientific properties of astrophysical objects such as galaxies or exoplanets. In our application, we study the spectra of very luminous galaxies known as quasars, and their properties, such as the mass of their central supermassive black hole, their accretion rate and their luminosity, and hence, there can be multiple observation spaces. A single data point is then characterised by different classes of observations which may have different likelihoods. Our proposed model extends the baseline stochastic variational Gaussian process latent variable model (GPLVM) to this setting, proposing a seamless generative model where the quasar spectra and the scientific labels can be generatedsimultaneously when modelled with a shared latent space acting as input to different sets of Gaussian process decoders, one for each observation space. Further, this framework allows training in the missing data setting where a large number of dimensions per data point may be unknown or unobserved. We demonstrate high-fidelity reconstructions of the spectra and the scientific labels during test-time inference and briefly discuss the scientific interpretations of the results along with the significance of such a generative model",
    "checked": true,
    "id": "f89ee2626ca15c0109596bc30b097e1cc017ee28",
    "semantic_title": "shared stochastic gaussian process latent variable models: a multi-modal generative model for quasar spectra",
    "citation_count": 0,
    "authors": [
      "Vidhi Lalchand",
      "Anna-Christina Eilers"
    ]
  },
  "https://openreview.net/forum?id=fqkq1MgONB": {
    "title": "BM$^2$: Coupled Schrödinger Bridge Matching",
    "volume": "main",
    "abstract": "A Schrödinger bridge establishes a dynamic transport map between two target distributions via a reference process, simultaneously solving an associated entropic optimal transport problem. We consider the setting where samples from the target distributions are available, and the reference diffusion process admits tractable dynamics. We thus introduce Coupled Bridge Matching (BM$^2$), a simple \\emph{non-iterative} approach for learning Schrödinger bridges with neural networks. A preliminary theoretical analysis of the convergence properties of BM$^2$ is carried out, supported by numerical experiments that demonstrate the effectiveness of our proposal",
    "checked": false,
    "id": "77db7bcb2e4049c35030d7d392e1b34f277cd776",
    "semantic_title": "bm2: coupled schrödinger bridge matching",
    "citation_count": 1,
    "authors": [
      "Stefano Peluchetti"
    ]
  },
  "https://openreview.net/forum?id=wS1fD0ofay": {
    "title": "Partial-Label Learning with a Reject Option",
    "volume": "main",
    "abstract": "In real-world applications, one often encounters ambiguously labeled data, where different annotators assign conflicting class labels. Partial-label learning allows training classifiers in this weakly supervised setting, where state-of-the-art methods already show good predictive performance. However, even the best algorithms give incorrect predictions, which can have severe consequences when they impact actions or decisions. We propose a novel risk-consistent nearest-neighbor-based partial-label learning algorithm with a reject option, that is, the algorithm can reject unsure predictions. Extensive experiments on artificial and real-world datasets show that our method provides the best trade-off between the number and accuracy of non-rejected predictions when compared to our competitors, which use confidence thresholds for rejecting unsure predictions. When evaluated without the reject option, our nearest-neighbor-based approach also achieves competitive prediction performance",
    "checked": true,
    "id": "7afc71707efea99221a318317afc6716e60271dc",
    "semantic_title": "partial-label learning with a reject option",
    "citation_count": 1,
    "authors": [
      "Tobias Fuchs",
      "Florian Kalinke",
      "Klemens Böhm"
    ]
  },
  "https://openreview.net/forum?id=34vtRA3Nvu": {
    "title": "PRIMO: Private Regression in Multiple Outcomes",
    "volume": "main",
    "abstract": "We introduce a new private regression setting we call \\textit{Private Regression in Multiple Outcomes} (PRIMO), inspired by the common situation where a data analyst wants to perform a set of $l$ regressions while preserving privacy, where the features $X$ are shared across all $l$ regressions, and each regression $i \\in [l]$ has a different vector of outcomes $y_i$. Naively applying existing private linear regression techniques $l$ times leads to a $\\sqrt{l}$ multiplicative increase in error over the standard linear regression setting. We apply a variety of techniques including sufficient statistics perturbation (SSP) and geometric projection-based methods to develop scalable algorithms that outperform this baseline across a range of parameter regimes. In particular, we obtain \\textit{no dependence on l} in the asympotic error when $l$ is sufficiently large. We apply our algorithms to the task of private genomic risk prediction for multiple phenotypes. Empirically, we find that even for values of $l$ far smaller than the theory would predict, our projection-based method improves the accuracy relative to the variant that doesn't use the projection",
    "checked": true,
    "id": "04282106606c629639fa0b0a636c5d75c6f7822c",
    "semantic_title": "primo: private regression in multiple outcomes",
    "citation_count": 0,
    "authors": [
      "Seth Neel"
    ]
  },
  "https://openreview.net/forum?id=ytKFKoCpyK": {
    "title": "ODNet: Opinion Dynamics-Inspired Neural Message Passing for Graphs and Hypergraphs",
    "volume": "main",
    "abstract": "Neural message passing serves as a cornerstone framework in graph neural networks, providing a clear and intuitive mathematical guideline for the propagation and aggregation of information among interconnected nodes within graphs. Throughout this process, node representations undergo dynamic updates, considering both the individual states and connections of neighboring nodes. Concurrently, social networks, as prominent forms of interconnected data, form dynamic systems that achieve stability through continuous internal communications and opinion exchanges among social actors along their social ties. Drawing upon the shared concepts between these two domains, our study establishes an explicit connection between message passing and opinion dynamics in sociology. Moreover, we introduce a novel continuous message passing scheme termed ODNet, which integrates bounded confidence to refine the influence weight of local nodes for message propagation. By adjusting the similarity cutoffs of bounded confidence and influence weights within ODNet, we define opinion exchange rules that align with the characteristics of neural message passing and can effectively mitigate the oversmoothing issue. We extend the framework to hypergraphs and formulate corresponding continuous message passing rules, which reveal a close association with particle dynamics. Empirically, we showcase that ODNet enhances prediction performance across various social networks presented as homophilic graphs, heterophilic graphs, and hypergraphs. Notably, our proposed ODNet outperforms existing GNNs with its straightforward construction and robust theoretical foundation",
    "checked": true,
    "id": "3eef868a35888f318ca84f9810fa639ab324a63b",
    "semantic_title": "odnet: opinion dynamics-inspired neural message passing for graphs and hypergraphs",
    "citation_count": 1,
    "authors": [
      "Bingxin Zhou",
      "Outongyi Lv",
      "Jing Wang",
      "Xiang Xiao",
      "Weishu Zhao"
    ]
  },
  "https://openreview.net/forum?id=0u7pWfjri5": {
    "title": "Bigger is not Always Better: Scaling Properties of Latent Diffusion Models",
    "volume": "main",
    "abstract": "We study the scaling properties of latent diffusion models (LDMs) with an emphasis on their sampling efficiency. While improved network architecture and inference algorithms have shown to effectively boost sampling efficiency of diffusion models, the role of model size---a critical determinant of sampling efficiency---has not been thoroughly examined. Through empirical analysis of established text-to-image diffusion models, we conduct an in-depth investigation into how model size influences sampling efficiency across varying sampling steps. Our findings unveil a surprising trend: when operating under a given inference budget, smaller models frequently outperform their larger equivalents in generating high-quality results. Moreover, we extend our study to demonstrate the generalizability of the these findings by applying various diffusion samplers, exploring diverse downstream tasks, evaluating post-distilled models, as well as comparing performance relative to training compute. These findings open up new pathways for the development of LDM scaling strategies which can be employed to enhance generative capabilities within limited inference budgets",
    "checked": true,
    "id": "5addc092e4e2ccc9e04673762194db8075dde7cc",
    "semantic_title": "bigger is not always better: scaling properties of latent diffusion models",
    "citation_count": 13,
    "authors": [
      "Kangfu Mei",
      "Zhengzhong Tu",
      "Mauricio Delbracio",
      "Hossein Talebi",
      "Vishal M. Patel",
      "Peyman Milanfar"
    ]
  },
  "https://openreview.net/forum?id=UrSgGSTM2J": {
    "title": "Minimax Posterior Contraction Rates for Unconstrained Distribution Estimation on $[0,1]^d$ under Wasserstein Distance",
    "volume": "main",
    "abstract": "We obtain asymptotic minimax optimal posterior contraction rates for estimation of probability distributions on $[0,1]^d$ under the Wasserstein-$p$ metrics using Bayesian Histograms. To the best of our knowledge, our analysis is the first to provide minimax posterior contraction rates for every $p \\geq 1$ and problem dimension $d \\geq 1$. Our proof technique takes advantage of the conjugacy of the Bayesian Histogram",
    "checked": false,
    "id": "429d9e8f93c9e07e8fa0764523b82ce63a94adbf",
    "semantic_title": "minimax posterior contraction rates for unconstrained distribution estimation on [0, 1]d under wasserstein distance",
    "citation_count": 0,
    "authors": [
      "Peter Matthew Jacobs",
      "Lekha Patel",
      "Anirban Bhattacharya",
      "Debdeep Pati"
    ]
  },
  "https://openreview.net/forum?id=9CWU8Oi86d": {
    "title": "Localize-and-Stitch: Efficient Model Merging via Sparse Task Arithmetic",
    "volume": "main",
    "abstract": "Model merging offers an effective strategy to combine the strengths of multiple finetuned models into a unified model that preserves the specialized capabilities of each. Existing methods merge models in a global manner, performing arithmetic operations across all model parameters. However, such global merging often leads to task interference, degrading the performance of the merged model. In this work, we introduce Localize-and-Stitch, a novel approach that merges models in a localized way. Our algorithm works in two steps: i) Localization: identify tiny ($1\\%$ of the total parameters) localized regions in the finetuned models containing essential skills for the downstream tasks, and ii) Stitching: reintegrate only these essential regions back into the pretrained model for task synergy. We demonstrate that our approach effectively locates sparse regions responsible for finetuned performance, and the localized regions could be treated as compact and interpretable representations of the finetuned models (tasks). Empirically, we evaluate our method on various vision and language benchmarks, showing that it outperforms existing model merging methods under different data availability scenarios. Beyond strong empirical performance, our algorithm also facilitates model compression and preserves pretrained knowledge, enabling flexible and continual skill composition from multiple finetuned models with minimal storage and computational overhead",
    "checked": true,
    "id": "292233bff38fe6e8336ce55619ef5513dc63b359",
    "semantic_title": "localize-and-stitch: efficient model merging via sparse task arithmetic",
    "citation_count": 25,
    "authors": [
      "Yifei He",
      "Yuzheng Hu",
      "Yong Lin",
      "Tong Zhang",
      "Han Zhao"
    ]
  },
  "https://openreview.net/forum?id=yawWz4qWkF": {
    "title": "Attention Mechanisms Don't Learn Additive Models: Rethinking Feature Importance for Transformers",
    "volume": "main",
    "abstract": "We address the critical challenge of applying feature attribution methods to the transformer architecture, which dominates current applications in natural language processing and beyond. Traditional attribution methods to explainable AI (XAI) explicitly or implicitly rely on linear or additive surrogate models to quantify the impact of input features on a model's output. In this work, we formally prove an alarming incompatibility: transformers are structurally incapable of representing linear or additive surrogate models used for feature attribution, undermining the grounding of these conventional explanation methodologies. To address this discrepancy, we introduce the Softmax-Linked Additive Log Odds Model (SLALOM), a novel surrogate model specifically designed to align with the transformer framework. SLALOM demonstrates the capacity to deliver a range of insightful explanations with both synthetic and real-world datasets. We highlight SLALOM's unique efficiency-quality curve by showing that SLALOM can produce explanations with substantially higher fidelity than competing surrogate models or provide explanations of comparable quality at a fraction of their computational costs. We release code for SLALOM as an open-source project online at https://github.com/tleemann/slalom_explanations",
    "checked": true,
    "id": "c866c488748d67686630de5e14978b837d6ce281",
    "semantic_title": "attention mechanisms don't learn additive models: rethinking feature importance for transformers",
    "citation_count": 5,
    "authors": [
      "Tobias Leemann",
      "Alina Fastowski",
      "Felix Pfeiffer",
      "Gjergji Kasneci"
    ]
  },
  "https://openreview.net/forum?id=CNaiJRcX84": {
    "title": "S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks",
    "volume": "main",
    "abstract": "Spiking Neural Networks (SNNs) are biologically plausible models that have been identified as potentially apt for deploying energy-efficient intelligence at the edge, particularly for sequential learning tasks. However, training of SNNs poses significant challenges due to the necessity for precise temporal and spatial credit assignment. Back-propagation through time (BPTT) algorithm, whilst the most widely used method for addressing these issues, incurs high computational cost due to its temporal dependency. In this work, we propose S-TLLR, a novel three-factor temporal local learning rule inspired by the Spike-Timing Dependent Plasticity (STDP) mechanism, aimed at training deep SNNs on event-based learning tasks. Furthermore, S-TLLR is designed to have low memory and time complexities, which are independent of the number of time steps, rendering it suitable for online learning on low-power edge devices. To demonstrate the scalability of our proposed method, we have conducted extensive evaluations on event-based datasets spanning a wide range of applications, such as image and gesture recognition, audio classification, and optical flow estimation. S-TLLR achieves comparable accuracy to BPTT (within $\\pm2\\%$ for most tasks), while reducing memory usage by $5-50\\times$ and multiply-accumulate (MAC) operations by $1.3-6.6\\times$, particularly when updates are restricted to the last few time-steps",
    "checked": true,
    "id": "c1f9d14ad82a489e7cfcceaf93e989476d84a0ec",
    "semantic_title": "s-tllr: stdp-inspired temporal local learning rule for spiking neural networks",
    "citation_count": 6,
    "authors": [
      "Marco Paul E. Apolinario",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=iVV7IzI55V": {
    "title": "On Inherent Adversarial Robustness of Active Vision Systems",
    "volume": "main",
    "abstract": "Deep Neural Networks (DNNs) are susceptible to adversarial inputs, such as imperceptible noise and naturally occurring challenging samples. This vulnerability likely arises from their passive, one-shot processing approach. In contrast, neuroscience suggests that human vision robustly identifies salient object features by actively switching between multiple fixation points (saccades) and processing surroundings with non-uniform resolution (foveation). This information is processed via two pathways: the dorsal (where) and ventral (what) streams, which identify relevant input portions and discard irrelevant details. Building on this perspective, we outline a deep learning-based active dorsal-ventral vision system and adapt two prior methods, FALcon and GFNet, within this framework to evaluate their robustness. We conduct a comprehensive robustness analysis across three categories: adversarially crafted inputs evaluated under transfer attack scenarios, natural adversarial images, and foreground-distorted images. By learning from focused, downsampled glimpses at multiple distinct fixation points, these active methods significantly enhance the robustness of passive networks, achieving a 2-21 % increase in accuracy. This improvement is demonstrated against state-of-the-art transferable black-box attack. On ImageNet-A, a benchmark for naturally occurring hard samples, we show how distinct predictions from multiple fixation points yield performance gains of 1.5-2 times for both CNN and Transformer based networks. Lastly, we qualitatively demonstrate how an active vision system aligns more closely with human perception for structurally distorted images. This alignment leads to more stable and resilient predictions, with lesser catastrophic mispredictions. In contrast, passive methods, which rely on single-shot learning and inference, often lack the necessary structural understanding",
    "checked": true,
    "id": "94401d8b0568ea402d48e804a09419bd5519b4d8",
    "semantic_title": "on inherent adversarial robustness of active vision systems",
    "citation_count": 0,
    "authors": [
      "Amitangshu Mukherjee",
      "Timur Ibrayev",
      "Kaushik Roy"
    ]
  },
  "https://openreview.net/forum?id=AjJTg5M0r8": {
    "title": "Slicing Unbalanced Optimal Transport",
    "volume": "main",
    "abstract": "Optimal transport (OT) is a powerful framework to compare probability measures, a fundamental task in many statistical and machine learning problems. Substantial advances have been made in designing OT variants which are either computationally and statistically more efficient or robust. Among them, sliced OT distances have been extensively used to mitigate optimal transport's cubic algorithmic complexity and curse of dimensionality. In parallel, unbalanced OT was designed to allow comparisons of more general positive measures, while being more robust to outliers. In this paper, we bridge the gap between those two concepts and develop a general framework for efficiently comparing positive measures. We notably formulate two different versions of sliced unbalanced OT, and study the associated topology and statistical properties. We then develop a GPU-friendly Frank-Wolfe like algorithm to compute the corresponding loss functions, and show that the resulting methodology is modular as it encompasses and extends prior related work. We finally conduct an empirical analysis of our loss functions and methodology on both synthetic and real datasets, to illustrate their computational efficiency, relevance and applicability to real-world scenarios including geophysical data",
    "checked": true,
    "id": "3c65b865f521f5955e2048b2d2ce8dca75ccd8ec",
    "semantic_title": "slicing unbalanced optimal transport",
    "citation_count": 4,
    "authors": [
      "Clément Bonet",
      "Kimia Nadjahi",
      "Thibault Sejourne",
      "Kilian FATRAS",
      "Nicolas Courty"
    ]
  },
  "https://openreview.net/forum?id=yBgTVWccIx": {
    "title": "DafnyBench: A Benchmark for Formal Software Verification",
    "volume": "main",
    "abstract": "We introduce DafnyBench, the largest benchmark of its kind for training and evaluating machine learning systems for formal software verification. We test the ability of LLMs such as GPT-4 and Claude 3 to auto-generate enough annotations for the Dafny formal verification engine to successfully verify over 750 programs with about 53,000 lines of code. The best model and prompting scheme achieved 68% success rate, and we quantify how this rate improves when retrying with error message feedback and how it deteriorates with the amount of required code and annotations. We hope that DafnyBench will enable rapid improvements from this baseline as LLMs and verification techniques grow in quality",
    "checked": true,
    "id": "acaf7fe5474cf3bf79f25522dd53a953dc310897",
    "semantic_title": "dafnybench: a benchmark for formal software verification",
    "citation_count": 12,
    "authors": [
      "Chloe R Loughridge",
      "Qinyi Sun",
      "Seth Ahrenbach",
      "Federico Cassano",
      "Chuyue Sun",
      "Ying Sheng",
      "Anish Mudide",
      "Md Rakib Hossain Misu",
      "Nada Amin",
      "Max Tegmark"
    ]
  },
  "https://openreview.net/forum?id=x8wscCAJ2m": {
    "title": "Sparse Neural Architectures via Deterministic Ramanujan Graphs",
    "volume": "main",
    "abstract": "We present a method to construct sparse neural networks using the theory of expander graphs. Expanders are sparse but well connected graph structures that are used for designing resilient networks. A Ramanujan graph is an extremal expander in terms of the spectral gap of its eigenvalues. In this work, bipartite Ramanujan expanders are deterministically constructed and used as connection structures of the convolutional and fully connected layers of a neural network. The Ramanujan graphs occur either as Cayley graphs of certain algebraic groups or as Ramanujan $r$-coverings of the full $(k,l)$ bi-regular bipartite graph on $k + l$ vertices. The proposed sparse networks are found to provide comparable performance to a fully dense network on benchmark datasets achieving an extremely low network density",
    "checked": true,
    "id": "877ee1031395aee57887f0410d34b25dc9014b9b",
    "semantic_title": "sparse neural architectures via deterministic ramanujan graphs",
    "citation_count": 0,
    "authors": [
      "Suryam Arnav Kalra",
      "Arindam Biswas",
      "Pabitra Mitra",
      "BISWAJIT BASU"
    ]
  },
  "https://openreview.net/forum?id=JHxrh00W1j": {
    "title": "Masked Capsule Autoencoders",
    "volume": "main",
    "abstract": "We propose Masked Capsule Autoencoders (MCAE), the first Capsule Network that utilises pretraining in a modern self-supervised paradigm, specifically the masked image modelling framework. Capsule Networks have emerged as a powerful alternative to Convolutional Neural Networks (CNNs). They have shown favourable properties when compared to Vision Transformers (ViT), but have struggled to effectively learn when presented with more complex data. This has led to Capsule Network models that do not scale to modern tasks. Our proposed MCAE model alleviates this issue by reformulating the Capsule Network to use masked image modelling as a pretraining stage before finetuning in a supervised manner. Across several experiments and ablations studies we demonstrate that similarly to CNNs and ViTs, Capsule Networks can also benefit from self-supervised pretraining, paving the way for further advancements in this neural network domain. For instance, by pretraining on the Imagenette dataset---consisting of 10 classes of Imagenet-sized images---we achieve state-of-the-art results for Capsule Networks, demonstrating a 9\\% improvement compared to our baseline model. Thus, we propose that Capsule Networks benefit from and should be trained within a masked image modelling framework, using a novel capsule decoder, to enhance a Capsule Network's performance on realistically sized images",
    "checked": true,
    "id": "152195ac839bb33d1cad9520d39f7ffc52b6e651",
    "semantic_title": "masked capsule autoencoders",
    "citation_count": 2,
    "authors": [
      "Miles Everett",
      "Mingjun Zhong",
      "Georgios Leontidis"
    ]
  },
  "https://openreview.net/forum?id=gqh0yzPYdo": {
    "title": "No Detail Left Behind: Revisiting Self-Retrieval for Fine-Grained Image Captioning",
    "volume": "main",
    "abstract": "Image captioning systems are unable to generate fine-grained captions as they are trained on data that is either noisy (alt-text) or generic (human annotations). This is further exacerbated by maximum likelihood training that encourages generation of frequently occurring phrases. Previous works have tried to address this limitation by fine-tuning captioners with a self-retrieval (SR) reward. However, we find that SR fine-tuning has a tendency to reduce caption faithfulness and even hallucinate. In this work, we circumvent this bottleneck by improving the MLE initialization of the captioning system and designing a curriculum for the SR fine-tuning process. To this extent, we present (1) Visual Caption Boosting, a novel framework to instill fine-grainedness in generic image captioning datasets while remaining anchored in human annotations; and (2) BagCurri, a carefully designed training curriculum that more optimally leverages the contrastive nature of the self-retrieval reward. Jointly, they enable the captioner to describe fine-grained aspects in the image while preserving faithfulness to ground-truth captions. Our approach outperforms previous work by +8.9% on SR against 99 random distractors (RD100) (Dessi et al., 2023); and +7.6% on ImageCoDe. Additionally, existing metrics to evaluate captioning systems fail to reward diversity or evaluate a model's fine-grained understanding ability. Our third contribution addresses this by proposing self-retrieval from the lens of evaluation. We introduce TrueMatch, a benchmark comprising bags of highly similar images that uses SR to assess the captioner's ability to capture subtle visual distinctions. We evaluate and compare several state-of-the-art open-source MLLMs on TrueMatch, and find that our SR approach outperforms them all by a significant margin (e.g. +4.8% - 7.1% over Cambrian) while having 1-2 orders of magnitude fewer parameters. We also outperform vanilla SR by +14.4% to +19.5%",
    "checked": true,
    "id": "eeabbd20e8edbb1ad9ba38be1e38eece0ee92fc4",
    "semantic_title": "no detail left behind: revisiting self-retrieval for fine-grained image captioning",
    "citation_count": 1,
    "authors": [
      "Manu Gaur",
      "Darshan Singh S",
      "Makarand Tapaswi"
    ]
  },
  "https://openreview.net/forum?id=Conma3qnaT": {
    "title": "Effective Backdoor Mitigation in Vision-Language Models Depends on the Pre-training Objective",
    "volume": "main",
    "abstract": "Despite the advanced capabilities of contemporary machine learning (ML) models, they remain vulnerable to adversarial and backdoor attacks. This vulnerability is particularly concerning in real-world deployments, where compromised models may exhibit unpredictable behavior in critical scenarios. Such risks are heightened by the prevalent practice of collecting massive, internet-sourced datasets for training multimodal models, as these datasets may harbor backdoors. Various techniques have been proposed to mitigate the effects of backdooring in multimodal models, such as CleanCLIP, which is the current state-of-the-art approach. In this work, we demonstrate that the efficacy of CleanCLIP in mitigating backdoors is highly dependent on the particular objective used during model pre-training. We observe that stronger pre-training objectives that lead to higher zero-shot classification performance correlate with harder to remove backdoors behaviors. We show this by training multimodal models on two large datasets consisting of 3 million (CC3M) and 6 million (CC6M) datapoints, under various pre-training objectives, followed by poison removal using CleanCLIP. We find that CleanCLIP, even with extensive hyperparameter tuning, is ineffective in poison removal when stronger pre-training objectives are used. Our findings underscore critical considerations for ML practitioners who train models using large-scale web-curated data and are concerned about potential backdoor threats",
    "checked": true,
    "id": "8ff5ea8835b252ebf7028e7c3942d1b179146658",
    "semantic_title": "effective backdoor mitigation in vision-language models depends on the pre-training objective",
    "citation_count": 1,
    "authors": [
      "Sahil Verma",
      "Gantavya Bhatt",
      "Avi Schwarzschild",
      "Soumye Singhal",
      "Arnav Mohanty Das",
      "Chirag Shah",
      "John P Dickerson",
      "Pin-Yu Chen",
      "Jeff Bilmes"
    ]
  },
  "https://openreview.net/forum?id=XDbY3qhM42": {
    "title": "Improving GFlowNets for Text-to-Image Diffusion Alignment",
    "volume": "main",
    "abstract": "Diffusion models have become the de-facto approach for generating visual data, which are trained to match the distribution of the training dataset. In addition, we also want to control generation to fulfill desired properties such as alignment to a text description, which can be specified with a black-box reward function. Prior works fine-tune pretrained diffusion models to achieve this goal through reinforcement learning-based algorithms. Nonetheless, they suffer from issues including slow credit assignment as well as low quality in their generated samples. In this work, we explore techniques that do not directly maximize the reward but rather generate high-reward images with relatively high probability --- a natural scenario for the framework of generative flow networks (GFlowNets). To this end, we propose the Diffusion Alignment with GFlowNet (DAG) algorithm to post-train diffusion models with black-box property functions. Extensive experiments on Stable Diffusion and various reward specifications corroborate that our method could effectively align large-scale text-to-image diffusion models with given reward information",
    "checked": true,
    "id": "4da96a97a09dab8181c90a3cb195ee0ccb7e8601",
    "semantic_title": "improving gflownets for text-to-image diffusion alignment",
    "citation_count": 10,
    "authors": [
      "Dinghuai Zhang",
      "Yizhe Zhang",
      "Jiatao Gu",
      "Ruixiang ZHANG",
      "Joshua M. Susskind",
      "Navdeep Jaitly",
      "Shuangfei Zhai"
    ]
  },
  "https://openreview.net/forum?id=oYP2Pd5aQt": {
    "title": "AlgoFormer: An Efficient Transformer Framework with Algorithmic Structures",
    "volume": "main",
    "abstract": "Besides natural language processing, transformers exhibit extraordinary performance in solving broader applications, including scientific computing and computer vision. Previous works try to explain this from the expressive power and capability perspectives that standard transformers are capable of performing some algorithms. To empower transformers with algorithmic capabilities and motivated by the recently proposed looped transformer (Yang et al., 2024; Giannou et al., 2023), we design a novel transformer framework, dubbed Algorithm Transformer (abbreviated as AlgoFormer). We provide an insight that efficient transformer architectures can be designed by leveraging prior knowledge of tasks and the underlying structure of potential algorithms. Compared with the standard transformer and vanilla looped transformer, the proposed AlgoFormer can perform efficiently in algorithm representation in some specific tasks. In particular, inspired by the structure of human-designed learning algorithms, our transformer framework consists of a pre-transformer that is responsible for task preprocessing, a looped transformer for iterative optimization algorithms, and a post-transformer for producing the desired results after post-processing. We provide theoretical evidence of the expressive power of the AlgoFormer in solving some challenging problems, mirroring human-designed algorithms. Furthermore, some theoretical and empirical results are presented to show that the designed transformer has the potential to perform algorithm representation and learning. Experimental results demonstrate the empirical superiority of the proposed transformer in that it outperforms the standard transformer and vanilla looped transformer in some specific tasks. An extensive experiment on real language tasks (e.g., neural machine translation of German and English, and text classification) further validates the expressiveness and effectiveness of AlgoFormer",
    "checked": true,
    "id": "3bbc4e7e18393162746849919af753dda454179c",
    "semantic_title": "algoformer: an efficient transformer framework with algorithmic structures",
    "citation_count": 3,
    "authors": [
      "Yihang Gao",
      "Chuanyang Zheng",
      "Enze Xie",
      "Han Shi",
      "Tianyang Hu",
      "Yu Li",
      "Michael Ng",
      "Zhenguo Li",
      "Zhaoqiang Liu"
    ]
  },
  "https://openreview.net/forum?id=Og3VxBFhwj": {
    "title": "Linear Convergence of Decentralized FedAvg for PL Objectives: The Interpolation Regime",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "0c12499e6c4b696c4def275771f074030562e51f",
    "semantic_title": "linear convergence of decentralized fedavg for pl objectives: the interpolation regime",
    "citation_count": 0,
    "authors": [
      "Shruti P Maralappanavar",
      "Prashant Khanduri",
      "Bharath B N"
    ]
  },
  "https://openreview.net/forum?id=XxbQAsxrRC": {
    "title": "Maximally Expressive GNNs for Outerplanar Graphs",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "17b607bc4616dfd6ad66f2c361cc60de2f1089a8",
    "semantic_title": "maximally expressive gnns for outerplanar graphs",
    "citation_count": 8,
    "authors": [
      "Franka Bause",
      "Fabian Jogl",
      "Patrick Indri",
      "Tamara Drucks",
      "David Penz",
      "Nils Morten Kriege",
      "Thomas Gärtner",
      "Pascal Welke",
      "Maximilian Thiessen"
    ]
  },
  "https://openreview.net/forum?id=aV6dCg1VFV": {
    "title": "Investigating the impact of missing value handling on Boosted trees and Deep learning for Tabular data: A Claim Reserving case study",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "28039c593c49594203b20167e0258c9689ea640b",
    "semantic_title": "investigating the impact of missing value handling on boosted trees and deep learning for tabular data: a claim reserving case study",
    "citation_count": 0,
    "authors": [
      "Alexander Larionov",
      "Niall M. Adams",
      "Kevin N. Webster"
    ]
  },
  "https://openreview.net/forum?id=IK2cR89z45": {
    "title": "Personalized Privacy Amplification via Importance Sampling",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "5b9e5b633b8b25388bfa05319ef7072033c762f1",
    "semantic_title": "personalized privacy amplification via importance sampling",
    "citation_count": 0,
    "authors": [
      "Dominik Fay",
      "Sebastian Mair",
      "Jens Sjölund"
    ]
  },
  "https://openreview.net/forum?id=bwyHf5eery": {
    "title": "A Note on Generalization in Variational Autoencoders: How Effective Is Synthetic Data and Overparameterization?",
    "volume": "main",
    "abstract": "Variational autoencoders (VAEs) are deep probabilistic models that are used in scientific applications. Many works try to mitigate this problem from the probabilistic methods perspective by new inference techniques or training procedures. In this paper, we approach the problem instead from the deep learning perspective by investigating the effectiveness of using synthetic data and overparameterization for improving the generalization performance. Our motivation comes from (1) the recent discussion on whether the increasing amount of publicly accessible synthetic data will improve or hurt currently trained generative models; and (2) the modern deep learning insights that overparameterization improves generalization. Our investigation shows how both training on samples from a pre-trained diffusion model, and using more parameters at certain layers are able to effectively mitigate overfitting in VAEs, therefore improving their generalization, amortized inference, and robustness performance. Our study provides timely insights in the current era of synthetic data and scaling laws",
    "checked": true,
    "id": "b7eb0bf32b6b200472c3518843013ffdf8aa0e3c",
    "semantic_title": "a note on generalization in variational autoencoders: how effective is synthetic data and overparameterization?",
    "citation_count": 0,
    "authors": [
      "Tim Z. Xiao",
      "Johannes Zenn",
      "Robert Bamler"
    ]
  },
  "https://openreview.net/forum?id=kzPNHQ8ByY": {
    "title": "Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of efficient exploration due to the exponential increase in the size of the joint state-action space. While demonstration-guided learning has proven beneficial in single-agent settings, its direct applicability to MARL is hindered by the practical difficulty of obtaining joint expert demonstrations. In this work, we introduce a novel concept of personalized expert demonstrations, tailored for each individual agent or, more broadly, each individual type of agent within a heterogeneous team. These demonstrations solely pertain to single-agent behaviors and how each agent can achieve personal goals without encompassing any cooperative elements, thus naively imitating them will not achieve cooperation due to potential conflicts. To this end, we propose an approach that selectively utilizes personalized expert demonstrations as guidance and allows agents to learn to cooperate, namely personalized expert-guided MARL (PegMARL). This algorithm utilizes two discriminators: the first provides incentives based on the alignment of individual agent behavior with demonstrations, and the second regulates incentives based on whether the behaviors lead to the desired outcome. We evaluate PegMARL using personalized demonstrations in both discrete and continuous environments. The results demonstrate that PegMARL learns near-optimal policies even when provided with suboptimal demonstrations and outperforms state-of-the-art MARL algorithms in solving coordinated tasks. We also showcase PegMARL's capability of leveraging joint demonstrations in the StarCraft scenario and converging effectively even with demonstrations from non-co-trained policies",
    "checked": true,
    "id": "a3993a96a8883749032da5fc865976d04c899de4",
    "semantic_title": "beyond joint demonstrations: personalized expert guidance for efficient multi-agent reinforcement learning",
    "citation_count": 4,
    "authors": [
      "Peihong Yu",
      "Manav Mishra",
      "Alec Koppel",
      "Carl Busart",
      "Priya Narayan",
      "Dinesh Manocha",
      "Amrit Singh Bedi",
      "Pratap Tokekar"
    ]
  },
  "https://openreview.net/forum?id=Vq0wMFBjo2": {
    "title": "Pre-trained Vision-Language Models Learn Discoverable Visual Concepts",
    "volume": "main",
    "abstract": "Do vision-language models (VLMs) pre-trained to caption an image of a durian learn visual concepts such as brown (color) and spiky (texture) at the same time? We aim to answer this question as visual concepts learned \"for free\" would enable wide applications such as neuro-symbolic reasoning or human-interpretable object classification. We assume that the visual concepts, if captured by pre-trained VLMs, can be extracted by their vision-language interface with text-based concept prompts. We observe that recent works prompting VLMs with concepts often differ in their strategies to define and evaluate the visual concepts, leading to conflicting conclusions. We propose a new concept definition strategy based on two observations: First, certain concept prompts include shortcuts that recognize correct concepts for wrong reasons; Second, multimodal information (e.g. visual discriminativeness, and textual knowledge) should be leveraged when selecting the concepts. Our proposed concept discovery and learning (CDL) framework is thus designed to identify a diverse list of generic visual concepts (e.g. spiky as opposed to spiky durian), which are ranked and selected based on visual and language mutual information. We carefully design quantitative and human evaluations of the discovered concepts on nine diverse visual recognition datasets, which confirm that pre-trained VLMs do learn visual concepts that provide accurate and thorough descriptions for the recognized objects. All code and models are publicly released",
    "checked": true,
    "id": "0f9784f5541376ad68dbff8251e49c69458fcd82",
    "semantic_title": "pre-trained vision-language models learn discoverable visual concepts",
    "citation_count": 10,
    "authors": [
      "Yuan Zang",
      "Tian Yun",
      "Hao Tan",
      "Trung Bui",
      "Chen Sun"
    ]
  },
  "https://openreview.net/forum?id=o58uy91V2V": {
    "title": "On the Detection of Reviewer-Author Collusion Rings From Paper Bidding",
    "volume": "main",
    "abstract": "Collusion rings pose a significant threat to peer review. In these rings, reviewers who are also authors coordinate to manipulate paper assignments, often by strategically bidding on each other's papers. A promising solution is to detect collusion through these manipulated bids, enabling conferences to take appropriate action. However, while methods exist for detecting other types of fraud, no research has yet shown that identifying collusion rings is feasible. In this work, we consider the question of whether it is feasible to detect collusion rings from the paper bidding. We conduct an empirical analysis of two realistic conference bidding datasets and evaluate existing algorithms for fraud detection in other applications. We find that collusion rings can achieve considerable success at manipulating the paper assignment while remaining hidden from detection: for example, in one dataset, undetected colluders are able to achieve assignment to up to 30% of the papers authored by other colluders. In addition, when 10 colluders bid on all of each other's papers, no detection algorithm outputs a group of reviewers with more than 31% overlap with the true colluders. These results suggest that collusion cannot be effectively detected from the bidding using popular existing tools, demonstrating the need to develop more complex detection algorithms as well as those that leverage additional metadata (e.g., reviewer-paper text-similarity scores)",
    "checked": true,
    "id": "f958280f92eb3b23608f5525b94b1a7c25dfff0b",
    "semantic_title": "on the detection of reviewer-author collusion rings from paper bidding",
    "citation_count": 9,
    "authors": [
      "Steven Jecmen",
      "Nihar B Shah",
      "Fei Fang",
      "Leman Akoglu"
    ]
  },
  "https://openreview.net/forum?id=ZA7D4nQuQF": {
    "title": "Transformers in Uniform TC$^0$",
    "volume": "main",
    "abstract": "Previous work has shown that the languages recognized by average-hard attention transformers (AHATs) and softmax-attention transformers (SMATs) are within the circuit complexity class TC$^0$. However, these results assume limited-precision arithmetic: using floating-point numbers with O(log n) bits (where n is the length of the input string), Strobl showed that AHATs can be approximated in L-uniform TC$^0$, and Merrill and Sabharwal showed that SMATs can be approximated in DLOGTIME-uniform TC$^0$. Here, we improve these results, showing that AHATs with no approximation, SMATs with O(poly(n)) bits of floating-point precision, and SMATs with at most $2^{−O(poly(n))}$ absolute error are all in DLOGTIME-uniform TC$^0$",
    "checked": true,
    "id": "8acceeac7284365c0782e827e4dab26b7af541b2",
    "semantic_title": "transformers in uniform tc$^0$",
    "citation_count": 7,
    "authors": [
      "David Chiang"
    ]
  },
  "https://openreview.net/forum?id=SeGNvJJjbs": {
    "title": "Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences",
    "volume": "main",
    "abstract": "One-step text-to-image generator models offer advantages such as swift inference efficiency, flexible architectures, and state-of-the-art generation performance. In this paper, we study the problem of aligning one-step generator models with human preferences for the first time. Inspired by the success of reinforcement learning using human feedback (RLHF), we formulate the alignment problem as maximizing expected human reward functions while adding an Integral Kullback-Leibler divergence term to prevent the generator from diverging. By overcoming technical challenges, we introduce Diff-Instruct++ (DI++), the first, fast-converging and image data-free human preference alignment method for one-step text-to-image generators. We also introduce novel theoretical insights, showing that using CFG for diffusion distillation is secretly doing RLHF with DI++. Such an interesting finding brings understanding and potential contributions to future research involving CFG. In the experiment sections, we align both UNet-based and DiT-based one-step generators using DI++, which use the Stable Diffusion 1.5 and the PixelArt-$\\alpha$ as the reference diffusion processes. The resulting DiT-based one-step text-to-image model achieves a strong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO validation prompt dataset. It also achieves a leading Human preference Score (HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable Diffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\\alpha$. Both theoretical contributions and empirical evidence indicate that DI++ is a strong human-preference alignment approach for one-step text-to-image models",
    "checked": true,
    "id": "4aabb3802133c76c21be9e98e81cd43d020b0863",
    "semantic_title": "diff-instruct++: training one-step text-to-image generator model to align with human preferences",
    "citation_count": 9,
    "authors": [
      "Weijian Luo"
    ]
  },
  "https://openreview.net/forum?id=KqRnsEMYLx": {
    "title": "Fourier PINNs: From Strong Boundary Conditions to Adaptive Fourier Bases",
    "volume": "main",
    "abstract": "Interest is rising in Physics-Informed Neural Networks (PINNs) as a mesh-free alternative to traditional numerical solvers for partial differential equations (PDEs). However, PINNs often struggle to learn high-frequency and multi-scale target solutions. To tackle this problem, we first study a strong Boundary Condition (BC) version of PINNs for Dirichlet BCs and observe a consistent decline in relative error compared to the standard PINNs. We then perform a theoretical analysis based on the Fourier transform and convolution theorem. We find that strong BC PINNs can better learn the amplitudes of high-frequency components of the target solutions. However, constructing the architecture for strong BC PINNs is difficult for many BCs and domain geometries. Enlightened by our theoretical analysis, we propose Fourier PINNs --- a simple, general, yet powerful method that augments PINNs with pre-specified, dense Fourier bases. Our proposed architecture likewise learns high-frequency components better but places no restrictions on the particular BCs or problem domains. We develop an adaptive learning and basis selection algorithm via alternating neural net basis optimization, Fourier and neural net basis coefficient estimation, and coefficient truncation. This scheme can flexibly identify the significant frequencies while weakening the nominal frequencies to better capture the target solution's power spectrum. We show the advantage of our approach through a set of systematic experiments",
    "checked": true,
    "id": "14ad4ef624494a90b2bd0274057dbc6d69970e40",
    "semantic_title": "fourier pinns: from strong boundary conditions to adaptive fourier bases",
    "citation_count": 2,
    "authors": [
      "Madison Cooley",
      "Varun Shankar",
      "Mike Kirby",
      "Shandian Zhe"
    ]
  },
  "https://openreview.net/forum?id=nxQtoHHcj9": {
    "title": "An Analysis of Model Robustness across Concurrent Distribution Shifts",
    "volume": "main",
    "abstract": "Machine learning models, meticulously optimized for source data, often fail to predict target data when faced with distribution shifts (DSs). Previous benchmarking studies, though extensive, have mainly focused on simple DSs. Recognizing that DSs often occur in more complex forms in real-world scenarios, we broaden our study to include multiple concurrent shifts, such as unseen domain shifts combined with spurious correlations. We evaluate 26 algorithms that range from simple heuristic augmentations to zero-shot inference using foundation models, across 168 source-target pairs from eight datasets. Our analysis of over 100K models reveals that (i) concurrent DSs typically worsen performance compared to a single shift, with certain exceptions, (ii) if a model improves generalization for one distribution shift, it tends to be effective for others, (iii) heuristic data augmentations achieve the best overall performance on both synthetic and real-world datasets",
    "checked": true,
    "id": "21c14c75269af4dd5c5302c297ebdd364ea07959",
    "semantic_title": "an analysis of model robustness across concurrent distribution shifts",
    "citation_count": 0,
    "authors": [
      "Myeongho Jeon",
      "Suhwan Choi",
      "Hyoje Lee",
      "Teresa Yeo"
    ]
  },
  "https://openreview.net/forum?id=ZnWqtPhHM7": {
    "title": "Prompt Tuning Vision Language Models with Margin Regularizer for Few-Shot Learning under Distribution Shifts",
    "volume": "main",
    "abstract": "Recently, Vision-Language foundation models like CLIP and ALIGN, which are pre-trained on large-scale data have shown remarkable zero-shot generalization to diverse datasets with different classes and even domains. In this work, we take a step further and analyze whether these models can be adapted to target datasets having very different distributions and classes compared to what these models have been trained on, using only a few labeled examples from the target dataset. In such scenarios, finetuning large pretrained models is challenging due to problems of overfitting as well as loss of generalization, and has not been well explored in prior literature. Since, the pre-training data of such models are unavailable, it is difficult to comprehend the performance on various downstream datasets. First, we try to answer the question: Given a target dataset with a few labelled examples, can we estimate whether further fine-tuning can enhance the performance compared to zero-shot evaluation? by analyzing the common vision-language embedding space. Based on the analysis, we propose a novel prompt-tuning method, PromptMargin for adapting such large-scale VLMs directly on the few target samples. PromptMargin effectively tunes the text as well as visual prompts for this task, and has two main modules: 1) Firstly, we use a selective augmentation strategy to complement the few training samples in each task; 2) Additionally, to ensure robust training in the presence of unfamiliar class names, we increase the inter-class margin for improved class discrimination using a novel Multimodal Margin Regularizer. Extensive experiments and analysis across fifteen target benchmark datasets, with varying degrees of distribution shifts from natural images, shows the effectiveness of the proposed framework over the existing state-of-the-art approaches applied to this setting",
    "checked": true,
    "id": "32b59d1ea97c180de5657b4aebb95d50e015d101",
    "semantic_title": "prompt tuning vision language models with margin regularizer for few-shot learning under distribution shifts",
    "citation_count": 1,
    "authors": [
      "Debarshi Brahma",
      "Anuska Roy",
      "Soma Biswas"
    ]
  },
  "https://openreview.net/forum?id=JN7iNWaPTe": {
    "title": "Mental Modelling of Reinforcement Learning Agents by Language Models",
    "volume": "main",
    "abstract": "Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models already exhibit some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it remains underexplored how the world knowledge these pre-trained models have memorized can be utilised to comprehend an agent's behaviour in the physical world. This paper empirically examines, for the first time, how well large language models (LLMs) can build a mental model of reinforcement learning (RL) agents, termed agent mental modelling, by reasoning about an agent's behaviour and its effect on states from agent interaction history. This research attempts to unveil the potential of leveraging LLMs for elucidating RL agent behaviour, addressing a key challenge in explainable RL. To this end, we propose specific evaluation metrics and test them on selected RL task datasets of varying complexity, reporting findings on agent mental model establishment. Our results disclose that LLMs are not yet capable of fully realising the mental modelling of agents through inference alone without further innovations. This work thus provides new insights into the capabilities and limitations of modern LLMs, highlighting that while they show promise in understanding agents with a longer history context, preexisting beliefs within LLMs about behavioural optimum and state complexity limit their ability to fully comprehend an agent's behaviour and action effects",
    "checked": true,
    "id": "237e85a482b41c59012f468d7c0e573e550605c8",
    "semantic_title": "mental modelling of reinforcement learning agents by language models",
    "citation_count": 0,
    "authors": [
      "Wenhao Lu",
      "Xufeng Zhao",
      "Josua Spisak",
      "Jae Hee Lee",
      "Stefan Wermter"
    ]
  },
  "https://openreview.net/forum?id=PzmaWLqK0e": {
    "title": "Reward-based Autonomous Online Learning Framework for Resilient Cooperative Target Monitoring using a Swarm of Robots",
    "volume": "main",
    "abstract": "This paper addresses the problem of decentralized cooperative monitoring of an agile target using a swarm of robots undergoing dynamic sensor failures. Each robot is equipped with a proprioceptive sensor suite for the estimation of its own pose and an exteroceptive sensor suite for target detection and position estimation with a limited field of view. Further, the robots use broadcast-based communication modules with a limited communication radius and bandwidth. The uncertainty in the system and the environment can lead to intermittent communication link drops, target visual loss, and large biases in the sensors' estimation output due to temporary or permanent failures. Robotic swarms often operate without leaders, supervisors, or landmarks, i.e., without the availability of ground truth regarding pose information. In such scenarios, each robot is required to exhibit autonomous learning by taking charge of its own learning process while making the most out of available information. In this regard, a novel Autonomous Online Learning (AOL) framework has been proposed, in which a decentralized online learning mechanism driven by reward-like signals, is intertwined with an implicit adaptive consensus-based, two-layered, weighted information fusion process that utilizes the robots' observations and their shared information, thereby ensuring resilience in the robotic swarm. In order to study the effect of loss or reward design in the local and social learning layers, three AOL variants are presented. A novel perturbation-greedy reward design is introduced in the learning layers of two variants, leading to exploration-exploitation in their information fusion's weights' space. Convergence analysis of the weights is carried out, showing that the weights converge under reasonable assumptions. Simulation results show that the AOL variant using the perturbation-greedy reward in its local learning layer performs the best, doing $182.2\\%$ to $652\\%$ and $94.7\\%$ to $150.4\\%$ better than the baselines in terms of detection score and closeness score per robot, respectively, as the total number of robots is increased from $5$ to $30$. Further, AOL's Sim2Real implementation has been validated using a ROS-Gazebo setup",
    "checked": true,
    "id": "c92c636bb9a6ce3289070a4c0e4001e47b646fc4",
    "semantic_title": "reward-based autonomous online learning framework for resilient cooperative target monitoring using a swarm of robots",
    "citation_count": 0,
    "authors": [
      "Shubhankar Gupta",
      "Saksham Sharma",
      "Suresh Sundaram"
    ]
  },
  "https://openreview.net/forum?id=edULLIVnoc": {
    "title": "Ask Your Distribution Shift if Pre-Training is Right for You",
    "volume": "main",
    "abstract": "Pre-training is a widely used approach to develop models that are robust to distribution shifts. However, in practice, its effectiveness varies: fine-tuning a pre-trained model improves robustness significantly in some cases but *not at all* in others (compared to training from scratch). In this work, we seek to characterize the failure modes that pre-training *can* and *cannot* address. In particular, we focus on two possible failure modes of models under distribution shift: poor extrapolation (e.g., they cannot generalize to a different domain) and biases in the training data (e.g., they rely on spurious features). Our study suggests that, as a rule of thumb, pre-training can help mitigate poor extrapolation but not dataset biases. After providing theoretical motivation and empirical evidence for this finding, we explore two of its implications for developing robust models: (1) pre-training and interventions designed to prevent exploiting biases have complementary robustness benefits, and (2) fine-tuning on a (very) small, non-diverse but *de-biased* dataset can result in significantly more robust models than fine-tuning on a large and diverse but biased dataset",
    "checked": true,
    "id": "853b25aab28b2b50ab8f9279e0a5b74fafdca5c3",
    "semantic_title": "ask your distribution shift if pre-training is right for you",
    "citation_count": 3,
    "authors": [
      "Benjamin Cohen-Wang",
      "Joshua Vendrow",
      "Aleksander Madry"
    ]
  },
  "https://openreview.net/forum?id=YkycjbKjYP": {
    "title": "SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis",
    "volume": "featured",
    "abstract": "Persistent dynamic scene modeling for tracking and novel-view synthesis remains challenging, particularly due to the complexity of capturing accurate deformations while maintaining computational efficiency. In this paper, we present SCas4D, a novel cascaded optimization framework that leverages inherent structural patterns in 3D Gaussian Splatting (3DGS) for dynamic scenes. Our key insight is that real-world deformations often exhibit hierarchical patterns, where groups of Gaussians undergo similar transformations. By employing a structural cascaded optimization approach that progressively refines deformations from coarse part-level to fine point-level adjustments, SCas4D achieves convergence within 100 iterations per time frame while maintaining competitive quality to the state-of-the-art method with only 1/20th of the training iterations. We further demonstrate our method's effectiveness in self-supervised articulated object segmentation, establishing a natural capability from our representation. Extensive experiments demonstrate our method's effectiveness in novel view synthesis and dense point tracking tasks. Please find our project page at https://github-tree-0.github.io/SCas4D-project-page/",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jipeng Lyu",
      "Jiahua Dong",
      "Yu-Xiong Wang"
    ]
  },
  "https://openreview.net/forum?id=xQbRFHfgGL": {
    "title": "SEE-DPO: Self Entropy Enhanced Direct Preference Optimization",
    "volume": "featured",
    "abstract": "Direct Preference Optimization (DPO) has been successfully used to align large language models (LLMs) according to human preferences, and more recently it has also been applied to improving the quality of text-to-image diffusion models. However, DPO-based methods such as SPO, Diffusion-DPO, and D3PO are highly susceptible to overfitting and reward hacking, especially when the generative model is optimized to fit out-of-distribution during prolonged training. To overcome these challenges and stabilize the training of diffusion models, we introduce a self-entropy regularization mechanism in reinforcement learning from human feedback. This enhancement improves DPO training by encouraging broader exploration and greater robustness. Our regularization technique effectively mitigates reward hacking, leading to improved stability and enhanced image quality across the latent space. Extensive experiments demonstrate that integrating human feedback with self-entropy regularization can significantly boost image diversity and specificity, achieving state-of-the-art results on key image generation metrics",
    "checked": true,
    "id": "c759d61941a5b4f62531559ceac580e089965c55",
    "semantic_title": "see-dpo: self entropy enhanced direct preference optimization",
    "citation_count": 4,
    "authors": [
      "Shivanshu Shekhar",
      "Shreyas Singh",
      "Tong Zhang"
    ]
  },
  "https://openreview.net/forum?id=Y8EspxaksH": {
    "title": "Faithful Interpretation for Graph Neural Networks",
    "volume": "reprod",
    "abstract": "Currently, attention mechanisms have garnered increasing attention in Graph Neural Networks (GNNs), such as Graph Attention Networks (GATs) and Graph Transformers (GTs). This is due to not only the commendable boost in performance they offer but also their capacity to provide a more lucid rationale for model behaviors, which are often viewed as inscrutable. However, Attention-based GNNs have demonstrated instability in interpretability when subjected to various sources of perturbations during both training and testing phases, including factors like additional edges or nodes. In this paper, we propose a solution to this problem by introducing a novel notion called Faithful Graph Attention-based Interpretation (FGAI). In particular, FGAI has four crucial properties in terms of stability and sensitivity to interpretation and the final output distribution. Built upon this notion, we propose an efficient methodology for obtaining FGAI, which can be viewed as an ad hoc modification to the canonical Attention-based GNNs. To validate our proposed solution, we introduce two novel metrics tailored for graph interpretation assessment. Experimental results demonstrate that FGAI exhibits superior stability and preserves the interpretability of attention under various forms of perturbations and randomness, which makes FGAI a more faithful and reliable explanation tool",
    "checked": true,
    "id": "3c9c740ed44effc8dd3e9abd57601b651ed474e9",
    "semantic_title": "faithful interpretation for graph neural networks",
    "citation_count": 3,
    "authors": [
      "Lijie Hu",
      "Tianhao Huang",
      "Lu Yu",
      "Wanyu Lin",
      "Tianhang Zheng",
      "Di Wang"
    ]
  },
  "https://openreview.net/forum?id=mAiMKnr9r5": {
    "title": "Random Policy Enables In-Context Reinforcement Learning within Trust Horizons",
    "volume": "featured",
    "abstract": "Pretrained foundation models (FMs) have exhibited extraordinary in-context learning performance, allowing zero-shot (or few-shot) generalization to new environments/tasks not encountered during the pretraining. In the case of reinforcement learning (RL), in-context RL (ICRL) emerges when pretraining FMs on decision-making problems in an autoregressive-supervised manner. Nevertheless, the current state-of-the-art ICRL algorithms, such as Algorithm Distillation, Decision Pretrained Transformer and Decision Importance Transformer, impose stringent requirements on the pretraining dataset concerning the behavior (source) policies, context information, and action labels, etc. Notably, these algorithms either demand optimal policies or require varying degrees of well-trained behavior policies for all pretraining environments. This significantly hinders the application of ICRL to real-world scenarios, where acquiring optimal or well-trained policies for a substantial volume of real-world training environments can be prohibitively expensive or even intractable. To overcome this challenge, we introduce a novel approach, termed State-Action Distillation (SAD), that allows to generate an effective pretraining dataset guided solely by random policies. In particular, SAD selects query states and corresponding action labels by distilling the outstanding state-action pairs from the entire state and action spaces by using random policies within a trust horizon, and then inherits the classical autoregressive-supervised mechanism during the pretraining. To the best of our knowledge, this is the first work that enables effective ICRL under (e.g., uniform) random policies and random contexts. We also establish the quantitative analysis of the trustworthiness as well as the performance guarantees of our SAD approach. Moreover, our empirical results across multiple popular ICRL benchmark environments demonstrate that, on average, SAD outperforms the best baseline by 236.3% in the offline evaluation and by 135.2% in the online evaluation",
    "checked": true,
    "id": "ea1f6767a48ea504113fa26066c7e6dcdbe557e4",
    "semantic_title": "random policy enables in-context reinforcement learning within trust horizons",
    "citation_count": 1,
    "authors": [
      "Weiqin Chen",
      "Santiago Paternain"
    ]
  },
  "https://openreview.net/forum?id=1p9hQTbjgo": {
    "title": "MiniFold: Simple, Fast, and Accurate Protein Structure Prediction",
    "volume": "featured",
    "abstract": "Protein structure prediction has emerged as a powerful tool for biologists and drug makers. However, the computational cost of state-of-the-art models such as AlphaFold limits their scalability and makes training and fine-tuning prohibitively expensive. Although previous work has achieved considerable inference speedups by replacing the multiple sequence alignment step with protein language models, the overall architecture of structure prediction models, inherited from AlphaFold2, has remained largely unchanged. In this work, we show that protein language model-based structure predictors can be dramatically simplified at little to no loss in accuracy. Our model, MiniFold, consists of a redesigned Evoformer and a lightweight structure module. We also propose two novel GPU kernels, tailored to the proposed architecture. Equipped with the same ESM2 protein language model, MiniFold is competitive with ESMFold on the standard CAMEO and CASP datasets while achieving training and inference speedups of up to 20x, and significant reductions in peak memory. Our results show that MiniFold is an effective solution for large-scale applications and resource-constrained environments",
    "checked": true,
    "id": "2336218cfa3a752e645e9decb969dc32ab669350",
    "semantic_title": "minifold: simple, fast, and accurate protein structure prediction",
    "citation_count": 0,
    "authors": [
      "Jeremy Wohlwend",
      "Mateo Reveiz",
      "Matt McPartlon",
      "Axel Feldmann",
      "Wengong Jin",
      "Regina Barzilay"
    ]
  },
  "https://openreview.net/forum?id=ssXSrZ94sR": {
    "title": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection",
    "volume": "featured",
    "abstract": "Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, increasing the diversity of available DAOD benchmarks, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes $\\rightarrow$ Foggy Cityscapes, +5.7 AP50 on Sim10k $\\rightarrow$ Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC-DAOD. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and method offer a critical reset for DAOD and provide a strong foundation for future research",
    "checked": true,
    "id": "d06a8d3ed21fc9bc6606b468177f98eee2d0c2c1",
    "semantic_title": "align and distill: unifying and improving domain adaptive object detection",
    "citation_count": 6,
    "authors": [
      "Justin Kay",
      "Timm Haucke",
      "Suzanne Stathatos",
      "Siqi Deng",
      "Erik Young",
      "Pietro Perona",
      "Sara Beery",
      "Grant Van Horn"
    ]
  },
  "https://openreview.net/forum?id=x6fXnsM9Ez": {
    "title": "The 2023 Foundation Model Transparency Index",
    "volume": "featured",
    "abstract": "Foundation models have rapidly permeated society, catalyzing a wave of generative AI applications spanning enterprise and consumer-facing contexts. While the societal impact of foundation models is growing, transparency is on the decline, mirroring the opacity that has plagued past digital technologies (e.g. social media). Reversing this trend is essential: transparency is a vital precondition for public accountability, scientific innovation, and effective governance. To assess the transparency of the foundation model ecosystem and help improve transparency over time, we introduce the Foundation Model Transparency Index. The Foundation Model Transparency Index specifies 100 fine-grained indicators that comprehensively codify transparency for foundation models, spanning the upstream resources used to build a foundation model (e.g data, labor, compute), details about the model itself (e.g. size, capabilities, risks), and the downstream use (e.g. distribution channels, usage policies, affected geographies). We score 10 major foundation model developers (e.g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency. To facilitate and standardize assessment, we score developers in relation to their practices for their flagship foundation model (e.g. GPT-4 for OpenAI, PaLM 2 for Google, Llama 2 for Meta). We present 10 top-level findings about the foundation model ecosystem: for example, no developer currently discloses significant information about the downstream impact of its flagship model, such as the number of users, affected market sectors, or how users can seek redress for harm. Overall, the Foundation Model Transparency Index establishes the level of transparency today to drive progress on foundation model governance via industry standards and regulatory intervention",
    "checked": true,
    "id": "f72583e1808c7f1d475161904d3654da5a9937ff",
    "semantic_title": "the 2023 foundation model transparency index",
    "citation_count": 7,
    "authors": [
      "Rishi Bommasani",
      "Kevin Klyman",
      "Shayne Longpre",
      "Sayash Kapoor",
      "Nestor Maslej",
      "Betty Xiong",
      "Daniel Zhang",
      "Percy Liang"
    ]
  },
  "https://openreview.net/forum?id=1Avb4jYjLb": {
    "title": "Loss-to-Loss Prediction: Scaling Laws for All Datasets",
    "volume": "featured",
    "abstract": "While scaling laws provide a reliable methodology for predicting train loss across compute scales for a single data distribution, less is known about how these predictions should change as we change the distribution. In this paper, we derive a strategy for predicting one loss from another and apply it to predict across different pre-training datasets and from pre-training data to downstream task data. Our predictions extrapolate well even at 20x the largest FLOP budget used to fit the curves. More precisely, we find that there are simple shifted power law relationships between (1) the train losses of two models trained on two separate datasets when the models are paired by training compute (train-to-train), (2) the train loss and the test loss on any downstream distribution for a single model (train-to-test), and (3) the test losses of two models trained on two separate train datasets (test-to-test). The results hold up for pre-training datasets that differ substantially (some are entirely code and others have no code at all) and across a variety of downstream tasks. Finally, we find that in some settings these shifted power law relationships can yield more accurate predictions than extrapolating single-dataset scaling laws",
    "checked": true,
    "id": "d25995954356cdc286eb2a53dc99b7484a111890",
    "semantic_title": "loss-to-loss prediction: scaling laws for all datasets",
    "citation_count": 4,
    "authors": [
      "David Brandfonbrener",
      "Nikhil Anand",
      "Nikhil Vyas",
      "Eran Malach",
      "Sham M. Kakade"
    ]
  },
  "https://openreview.net/forum?id=Y7dRmpGiHj": {
    "title": "What is the Relationship between Tensor Factorizations and Circuits (and How Can We Exploit it)?",
    "volume": "featured",
    "abstract": "This paper establishes a rigorous connection between circuit representations and tensor factorizations, two seemingly distinct yet fundamentally related areas. By connecting these fields, we highlight a series of opportunities that can benefit both communities. Our work generalizes popular tensor factorizations within the circuit language, and unifies various circuit learning algorithms under a single, generalized hierarchical factorization framework. Specifically, we introduce a modular \"Lego block\" approach to build tensorized circuit architectures. This, in turn, allows us to systematically construct and explore various circuit and tensor factorization models while maintaining tractability. This connection not only clarifies similarities and differences in existing models, but also enables the development of a comprehensive pipeline for building and optimizing new circuit/tensor factorization architectures. We show the effectiveness of our framework through extensive empirical evaluations, and highlight new research opportunities for tensor factorizations in probabilistic modeling",
    "checked": true,
    "id": "ec85daf828d493f137755da8ff6a5e31d851d188",
    "semantic_title": "what is the relationship between tensor factorizations and circuits (and how can we exploit it)?",
    "citation_count": 12,
    "authors": [
      "Lorenzo Loconte",
      "Antonio Mari",
      "Gennaro Gala",
      "Robert Peharz",
      "Cassio de Campos",
      "Erik Quaeghebeur",
      "Gennaro Vessio",
      "Antonio Vergari"
    ]
  },
  "https://openreview.net/forum?id=YCt8lsIDwA": {
    "title": "Diversify, Don't Fine-Tune: Scaling Up Visual Recognition Training with Synthetic Images",
    "volume": "featured",
    "abstract": "Recent advances in generative deep learning have enabled the creation of high-quality synthetic images in text-to-image generation. While prior research indicates that fine-tuning a pretrained diffusion model on ImageNet and generating synthetic training images can boost an ImageNet classifier's performance, when synthetic images start to outnumber real ones in training, the classifier performance starts to degrade, underscoring the scalability challenge of training with synthetic data. In this paper, we delve into the necessity of generative fine-tuning for achieving recognition performance improvements and investigate the scalability of training with large-scale synthetic images. We find that leveraging off-the-shelf generative models without fine-tuning, while addressing challenges of class name ambiguity, limited prompt diversity, and domain shifts effectively mitigates performance degradation from large-scale synthetic data. Specifically, we leverage large language models (LLMs) and CLIP to resolve class name ambiguity. To diversify images, we propose contextualized diversification (CD) and stylized diversification (SD) methods, also prompted by LLMs. Finally, to mitigate domain shifts, we leverage domain adaptation techniques with auxiliary batch normalization for synthetic images. Our framework consistently boosts recognition model performance with increased synthetic data, even up to 6 times the original ImageNet size. Models trained with our approach demonstrate significant in-domain improvement on ImageNet-val (1.20\\% to 2.35\\% across various architectures) and strong out-of-domain generalization on ImageNet-Sketch and -Rendition ($\\sim$10\\% improvement with large vision transformers)",
    "checked": true,
    "id": "51188d57ae276780f0f8d580300ce4d371455349",
    "semantic_title": "diversify, don't fine-tune: scaling up visual recognition training with synthetic images",
    "citation_count": 15,
    "authors": [
      "Zhuoran Yu",
      "Chenchen Zhu",
      "Sean Culatana",
      "Raghuraman Krishnamoorthi",
      "Fanyi Xiao",
      "Yong Jae Lee"
    ]
  },
  "https://openreview.net/forum?id=a0rytDAGUD": {
    "title": "Reproducibility Study of \"Improving Interpretation Faithfulness For Vision Transformers",
    "volume": "reprod",
    "abstract": "This paper attempts to reproduce the findings of the study \"Improving Interpretation Faith-fulness For Vision Transformers\" Hu et al. (2024). The authors focus on making visual transformers (ViTs) more robust to adversarial attacks, and calling these robust ViTs faithful ViTs (FViTs). In their paper they propose a universal method to transform ViTs to FViTs called denoised diffusion smoothing (DDS). The reproduction of the authors study suffers from certain challenges, but the main claims still hold. Furthermore, this study extends the original paper by trying different diffusion models for DDS and tries to generalize the increased robustness of FViTs",
    "checked": true,
    "id": "6b01db13b76e272588ddc03ac5e2337e15b05105",
    "semantic_title": "reproducibility study of \"improving interpretation faithfulness for vision transformers",
    "citation_count": 0,
    "authors": [
      "Meher Changlani",
      "Benjamin Hucko",
      "Ioannis Kechagias",
      "Aswin Krishna Mahadevan"
    ]
  },
  "https://openreview.net/forum?id=cPtqOkxQqH": {
    "title": "Revisiting XRec: How Collaborative Signals Influence LLM-Based Recommendation Explanations",
    "volume": "reprod",
    "abstract": "Recommender systems help users navigate large volumes of online content by offering personalized recommendations. However, the increasing reliance on deep learning-based techniques has made these systems opaque and difficult to interpret. To address this, XRec (Ma et al., 2024) was introduced as a novel framework that integrates collaborative signals and textual descriptions of past interactions into Large Language Models (LLMs) to generate natural language explanations for recommendations. In this work, we reproduce and expand upon the findings of Ma et al. (2024). While our results validate most of the original authors' claims, we were unable to fully replicate the reported performance improvements from injecting collaborative information into every LLM attention layer, nor the claimed effects of data sparsity. Beyond replication, our contributions provide evidence that the Graph Neural Network (GNN) component does not enhance explainability. Instead, the observed performance improvement is attributed to the Collaborative Information Adapter, which can act as a form of soft prompting, efficiently encoding task-specific information. This finding aligns with prior research suggesting that lightweight adaptation mechanisms can condition frozen LLMs for specific downstream tasks. Our implementation is open-source",
    "checked": true,
    "id": "11e5016bc202258d52a5769b11e2f8a7223c1cda",
    "semantic_title": "revisiting xrec: how collaborative signals influence llm-based recommendation explanations",
    "citation_count": 0,
    "authors": [
      "Cătălin-Emanuel Brița",
      "Hieu Nguyen",
      "Lubov Chalakova",
      "Nikola Petrov"
    ]
  },
  "https://openreview.net/forum?id=xeGWsmqFS8": {
    "title": "Pitfalls in Evaluating Inference-time Methods for Improving LLM Reliability",
    "volume": "survey",
    "abstract": "Though Large Language Models (LLMs) have demonstrated remarkable capabilities, they are still prone to outputting falsehoods using seemingly persuasive language. Many recent works attempt to address this problem by using LLMs in a framework where a single seed prompt results in a series of interactions involving augmented prompts with an otherwise unchanged LLM, and the results are aggregated with a goal of producing a more reliable output. We consider the replicability and generalizability of evaluations of inference-time methods intended to improve the reliability of responses from a base LLMs. We survey how methods have been evaluated in the literature and find a great variety of benchmarks and models in use. Motivated by this, we conduct our own evaluation to evaluate the effectiveness of a few methods across a range of benchmarks and models. Our evaluation reveals that while these techniques show promise in improving reliability, there is still significant variability in performance across different domains and tasks, and methods that show substantial improvements on weaker base models often do not improve reliability for better base models",
    "checked": true,
    "id": "86bdb560b1fa46c5cf81597f4072f7bf8d640ecf",
    "semantic_title": "pitfalls in evaluating inference-time methods for improving llm reliability",
    "citation_count": 0,
    "authors": [
      "Michael M. Jerge",
      "David Evans"
    ]
  },
  "https://openreview.net/forum?id=946cT3Jsq5": {
    "title": "Revisiting Discover-then-Name Concept Bottleneck Models: A Reproducibility Study",
    "volume": "reprod",
    "abstract": "Concept Bottleneck Models (CBMs) (Koh et al., 2020) are a class of interpretable deep learning frameworks that improve transparency by mapping input data into human-understandable concepts. Recent advances, including the Discover-then-Name CBM proposed by Rao et al. (2024), eliminate reliance on external language models by automating concept discovery and naming using a CLIP feature extractor and sparse autoencoder. This study focuses on replicating the key findings reported by Rao et al. (2024). We conclude that the core conceptual ideas are reproducible, but not to the extent presented in the original work. Many representations of active neurons appear to be misaligned with their assigned concepts, indicating a lack of faithfulness of the DN-CBM's explanations. To address this, we propose a model extension: an enhanced alignment method that we evaluate through a user study. Our extended model provides more interpretable concepts (with statistical significance), at the cost of a slight decrease in accuracy",
    "checked": true,
    "id": "09d16e40658ee6b71827ed833800b3b463d00ba5",
    "semantic_title": "revisiting discover-then-name concept bottleneck models: a reproducibility study",
    "citation_count": 0,
    "authors": [
      "Freek Byrman",
      "Emma Kasteleyn",
      "Bart Kuipers",
      "Daniel Uyterlinde"
    ]
  },
  "https://openreview.net/forum?id=dfUebM9asV": {
    "title": "Dynamics of the accelerated t-SNE",
    "volume": "reprod",
    "abstract": "This paper investigates the dynamics of t-Stochastic Neighbor Embedding (t-SNE), a popular tool for visualizing complex datasets in exploratory data analysis, optimized by the Nesterov's accelerated gradient method. Building on the foundational work that connects t-SNE with spectral clustering and dynamical systems, we extend the analysis to include accelerated dynamics which is not addressed in the previous work, revealing the emergence of Bessel and modified Bessel functions as a novel aspect of the algorithm's behavior characterizing the temporal evolution of the accelerated t-SNE. Because the ordinary differential equation corresponding to the optimization process under consideration has a closed-form solution, by performing eigenvalue decomposition of the data's adjacency matrix as a pre-processing step, we can obtain low-dimensional embeddings at any point in time without performing sequential optimization. This advancement not only enhances the practical utility of t-SNE but also contributes to a deeper understanding of its underlying dynamics",
    "checked": true,
    "id": "08b286eba36f0969dfff7912636123edf77f182b",
    "semantic_title": "dynamics of the accelerated t-sne",
    "citation_count": 0,
    "authors": [
      "Kyoichi Iwasaki",
      "Hideitsu Hino"
    ]
  },
  "https://openreview.net/forum?id=vKUPXuEzj8": {
    "title": "Reproducibility Study of 'SLICE: Stabilized LIME for Consistent Explanations for Image Classification",
    "volume": "reprod",
    "abstract": "This paper presents a reproducibility study of SLICE: Stabilized LIME for Consistent Explanations for Image Classification by Bora et al. (2024). SLICE enhances LIME by incorporating Sign Entropy-based Feature Elimination (SEFE) to remove unstable superpixels and an adaptive perturbation strategy using Gaussian blur to improve consistency in feature importance rankings. The original work claims that SLICE significantly improves explanation stability and fidelity. Our study systematically verifies these claims through extensive experimentation using the Oxford-IIIT Pets, PASCAL VOC, and MS COCO datasets. Our results confirm that SLICE achieves higher consistency than LIME, supporting its ability to reduce instability. However, our fidelity analysis challenges the claim of superior performance, as LIME often achieves higher Ground Truth Overlap (GTO) scores, indicating stronger alignment with object segmentations. To further investigate fidelity, we introduce an alternative AOPC evaluation to ensure a fair comparison across methods. Additionally, we propose GRID-LIME, a structured grid-based alternative to LIME, which improves stability while maintaining computational efficiency. Our findings highlight trade-offs in post-hoc explainability methods and emphasize the need for fairer fidelity evaluations. Our implementation is publicly available at our GitHub repository",
    "checked": true,
    "id": "b268aa7ca1e93a1514a1a07e9f05673362876f74",
    "semantic_title": "reproducibility study of 'slice: stabilized lime for consistent explanations for image classification",
    "citation_count": 0,
    "authors": [
      "Aritra Bandyopadhyay",
      "Chiranjeev Bindra",
      "Roan van Blanken",
      "Arijit Ghosh"
    ]
  },
  "https://openreview.net/forum?id=TJRyDi7mwH": {
    "title": "NeoBERT: A Next Generation BERT",
    "volume": "reprod",
    "abstract": "Recent innovations in architecture, pre-training, and fine-tuning have led to the remarkable in-context learning and reasoning abilities of large auto-regressive language models such as LLaMA and DeepSeek. In contrast, encoders like BERT and RoBERTa have not seen the same level of progress despite being foundational for many downstream NLP applications. To bridge this gap, we introduce NeoBERT, a next-generation encoder that redefines the capabilities of bidirectional models by integrating state-of-the-art advancements in architecture, modern data, and optimized pre-training methodologies. NeoBERT is designed for seamless adoption: it serves as a plug-and-play replacement for existing base models, relies on an optimal depth-to-width ratio, and leverages an extended context length of 4,096 tokens. Despite its compact 250M parameter footprint, it achieves state-of-the-art results on the massive MTEB benchmark, outperforming BERT$_{large}$, RoBERTa$_{large}$, NomicBERT, and ModernBERT under identical fine-tuning conditions. In addition, we rigorously evaluate the impact of each modification on GLUE and design a uniform fine-tuning and evaluation framework for MTEB. We release all code, data, checkpoints, and training scripts to accelerate research and real-world adoption",
    "checked": false,
    "id": "ffa99ecba6035e38c68c4b7495d43dba6738b93f",
    "semantic_title": "neobert: a next-generation bert",
    "citation_count": 1,
    "authors": [
      "Lola Le Breton",
      "Quentin Fournier",
      "John Xavier Morris",
      "Mariam El Mezouar",
      "Sarath Chandar"
    ]
  },
  "https://openreview.net/forum?id=855yo1Ubt2": {
    "title": "An Expanded Benchmark that Rediscovers and Affirms the Edge of Uncertainty Sampling for Active Learning in Tabular Datasets",
    "volume": "reprod",
    "abstract": "Active Learning (AL) addresses the crucial challenge of enabling machines to efficiently gather labeled examples through strategic queries. Among the many AL strategies, Uncertainty Sampling (US) stands out as one of the most widely adopted. US queries the example(s) that the current model finds uncertain, proving to be both straightforward and effective. Despite claims in the literature suggesting superior alternatives to US, community-wide acceptance remains elusive. In fact, existing benchmarks for tabular datasets present conflicting conclusions on the continued competitiveness of US. In this study, we review the literature on AL strategies in the last decade and build the most comprehensive open-source AL benchmark to date to understand the relative merits of different AL strategies. The benchmark surpasses existing ones by encompassing a broader coverage of strategies, models, and data. Through our investigation of the conflicting conclusions in existing tabular AL benchmarks by evaluation under broad AL experimental settings, we uncover fresh insights into the often-overlooked issue of using machine learning models--**model compatibility** in the context of US. Specifically, we notice that adopting the different models for the querying unlabeled examples and learning tasks would degrade US's effectiveness. Notably, our findings affirm that US maintains a competitive edge over other strategies when paired with compatible models. These findings have practical implications and provide a concrete recipe for AL practitioners, empowering them to make informed decisions when working with tabular classifications with limited labeled data. The code for this project is available on https://github.com/ariapoy/active-learning-benchmark",
    "checked": true,
    "id": "a5a1fa78bf7378b70160c09c54c777961426e902",
    "semantic_title": "an expanded benchmark that rediscovers and affirms the edge of uncertainty sampling for active learning in tabular datasets",
    "citation_count": 0,
    "authors": [
      "Po-Yi Lu",
      "Yi-Jie Cheng",
      "Chun-Liang Li",
      "Hsuan-Tien Lin"
    ]
  },
  "https://openreview.net/forum?id=H6DtMcZf5s": {
    "title": "Remembering to Be Fair Again: Reproducing Non-Markovian Fairness in Sequential Decision Making",
    "volume": "reprod",
    "abstract": "Ensuring long-term fairness in sequential decision-making is a key challenge in machine learning. Alamdari et al. (2024) introduced FairQCM, a reinforcement learning algorithm that enforces fairness in non-Markovian settings via memory augmentations and counterfactual reasoning. We reproduce and extend their findings by validating their claims and introducing novel enhancements. We confirm that FairQCM outperforms standard baselines in fairness enforcement and sample efficiency across different environments. However, alternative fairness metrics (Egalitarian, Gini) yield mixed results, and counterfactual memories show limited impact on fairness improvement. Further, we introduce a realistic COVID-19 vaccine allocation environment based on SEIR, a popular compartmental model of epidemiology. To accommodate continuous action spaces, we develop FairSCM, which integrates counterfactual memories into a Soft Actor-Critic framework. Our results reinforce that counterfactual memories provide little fairness benefit and, in fact, hurt performance, especially in complex, dynamic settings. The original code, modified to be 70% more efficient, and our extensions are available on GitHub: https://github.com/bozo22/remembering-to-be-fair-again",
    "checked": true,
    "id": "c0cd1005e34c909cff400937de5558dcbec49906",
    "semantic_title": "remembering to be fair again: reproducing non-markovian fairness in sequential decision making",
    "citation_count": 0,
    "authors": [
      "Domonkos Nagy",
      "Lohithsai Yadala Chanchu",
      "Krystof Bobek",
      "Xin Zhou",
      "Jacobus Smit"
    ]
  },
  "https://openreview.net/forum?id=zLfLTHOdZW": {
    "title": "[RE] GNNBoundary: Towards Explaining Graph Neural Networks through the Lens of Decision Boundaries",
    "volume": "reprod",
    "abstract": "Graph Neural Networks (GNNs) can model complex relationships while posing significant interpretability challenges due to the unique and varying properties of graph structures, which hinder the adaptation of existing methods from other domains. To address interpretability challenges in GNNs, GNNBoundary was designed as a model-level explainability tool to provide insights into their overall behavior. This paper aims to thoroughly evaluate the reproducibility, robustness, and practical applicability of the findings presented in the original work by replicating and extending their experiments, highlighting both strengths and limitations while considering potential future improvements. Our results show that while the algorithm can reliably generate near-boundary graphs in certain settings, its performance is highly sensitive to hyperparameter choices and suffers from convergence issues. Furthermore, we find that the generated solutions lack diversity, often representing only a single region on the decision boundary, which limits their effectiveness in broader decision boundary analysis. All the code used throughout the research is publicly available on GitHub",
    "checked": true,
    "id": "019de0702d2c46a4950e100e2b5296952e17341b",
    "semantic_title": "[re] gnnboundary: towards explaining graph neural networks through the lens of decision boundaries",
    "citation_count": 0,
    "authors": [
      "Tyme Chatupanyachotikul",
      "Leonard Horns",
      "Matei Nastase"
    ]
  },
  "https://openreview.net/forum?id=l9rATNBB8Y": {
    "title": "Privacy Awareness for Information-Sharing Assistants: A Case-study on Form-filling with Contextual Integrity",
    "volume": "reprod",
    "abstract": "Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize the design of privacy-conscious assistants that conform with *contextual integrity* (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of human annotations of common webform applications, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields strong results",
    "checked": true,
    "id": "e2125816783970113d1557934cba8f3c203ee73e",
    "semantic_title": "privacy awareness for information-sharing assistants: a case-study on form-filling with contextual integrity",
    "citation_count": 0,
    "authors": [
      "Sahra Ghalebikesabi",
      "Eugene Bagdasarian",
      "Ren Yi",
      "Itay Yona",
      "Ilia Shumailov",
      "Aneesh Pappu",
      "Chongyang Shi",
      "Laura Weidinger",
      "Robert Stanforth",
      "Leonard Berrada",
      "Pushmeet Kohli",
      "Po-Sen Huang",
      "Borja Balle"
    ]
  },
  "https://openreview.net/forum?id=sXr1fRjs1N": {
    "title": "Contextualized Messages Boost Graph Representations",
    "volume": "reprod",
    "abstract": "Graph neural networks (GNNs) have gained significant attention in recent years for their ability to process data that may be represented as graphs. This has prompted several studies to explore their representational capability based on the graph isomorphism task. Notably, these works inherently assume a countable node feature representation, potentially limiting their applicability. Interestingly, only a few study GNNs with uncountable node feature representation. In the paper, a new perspective on the representational capability of GNNs is investigated across all levels—node-level, neighborhood-level, and graph-level—when the space of node feature representation is uncountable. Specifically, the injective and metric requirements of previous works are softly relaxed by employing a pseudometric distance on the space of input to create a soft-injective function such that distinct inputs may produce similar outputs if and only if the pseudometric deems the inputs to be sufficiently similar on some representation. As a consequence, a simple and computationally efficient soft-isomorphic relational graph convolution network (SIR-GCN) that emphasizes the contextualized transformation of neighborhood feature representations via anisotropic and dynamic message functions is proposed. Furthermore, a mathematical discussion on the relationship between SIR-GCN and key GNNs in literature is laid out to put the contribution into context, establishing SIR-GCN as a generalization of classical GNN methodologies. To close, experiments on synthetic and benchmark datasets demonstrate the relative superiority of SIR-GCN, outperforming comparable models in node and graph property prediction tasks",
    "checked": true,
    "id": "eccd1ab224461365b50c04e26eacad4f22785003",
    "semantic_title": "contextualized messages boost graph representations",
    "citation_count": 2,
    "authors": [
      "Brian Godwin Lim",
      "Galvin Brice Sy Lim",
      "Renzo Roel Tan",
      "Kazushi Ikeda"
    ]
  },
  "https://openreview.net/forum?id=yeITEuhv4Q": {
    "title": "Revisiting Deep Hybrid Models for Out-of-Distribution Detection",
    "volume": "reprod",
    "abstract": "Deep hybrid models (DHMs) for out-of-distribution (OOD) detection, jointly training a deep feature extractor with a classification head and a density estimation head based on a normalising flow, provide a conceptually appealing approach to visual OOD detection. The paper that introduced this approach reported 100% AuROC in experiments on two standard benchmarks, including one based on the CIFAR-10 data. As there are no implementations available, we set out to reproduce the approach by carefully filling in gaps in the description of the algorithm. Although we were unable to attain 100% OOD detection rates, and our results indicate that such performance is impossible on the CIFAR-10 benchmark, we achieved good OOD performance. We provide a detailed analysis of when the architecture fails and argue that it introduces an adversarial relationship between the classification component and the density estimator, rendering it highly sensitive to the balance of these two components and yielding a collapsed feature space without careful fine-tuning. Our implementation of DHMs is publicly available",
    "checked": true,
    "id": "996c21986a229396457ee7e2bc21c577b96703cd",
    "semantic_title": "revisiting deep hybrid models for out-of-distribution detection",
    "citation_count": 0,
    "authors": [
      "Paul-Ruben Schlumbom",
      "Eibe Frank"
    ]
  },
  "https://openreview.net/forum?id=mSoDRZXsqj": {
    "title": "Towards Graph Foundation Models: A Study on the Generalization of Positional and Structural Encodings",
    "volume": "reprod",
    "abstract": "Recent advances in integrating positional and structural encodings (PSEs) into graph neural networks (GNNs) have significantly enhanced their performance across various graph learning tasks. However, the general applicability of these encodings and their potential to serve as foundational representations for graphs remain uncertain. This paper investigates the fine-tuning efficiency, scalability with sample size, and generalization capability of learnable PSEs across diverse graph datasets. Specifically, we evaluate their potential as universal pre-trained models that can be easily adapted to new tasks with minimal fine-tuning and limited data. Furthermore, we assess the expressivity of the learned representations, particularly, when used to augment downstream GNNs. We demonstrate through extensive benchmarking and empirical analysis that PSEs generally enhance downstream models. However, some datasets may require specific PSE-augmentations to achieve optimal performance. Nevertheless, our findings highlight their significant potential to become integral components of future graph foundation models. We provide new insights into the strengths and limitations of PSEs, contributing to the broader discourse on foundation models in graph learning",
    "checked": true,
    "id": "9f0d3a0b7c9a196541e8f3480bec8660892a252b",
    "semantic_title": "towards graph foundation models: a study on the generalization of positional and structural encodings",
    "citation_count": 1,
    "authors": [
      "Billy Joe Franks",
      "Moshe Eliasof",
      "Semih Cantürk",
      "Guy Wolf",
      "Carola-Bibiane Schönlieb",
      "Sophie Fellenz",
      "Marius Kloft"
    ]
  },
  "https://openreview.net/forum?id=rKAkp1f3R7": {
    "title": "Shedding Light on Problems with Hyperbolic Graph Learning",
    "volume": "reprod",
    "abstract": "Recent papers in the graph machine learning literature have introduced a number of approaches for hyperbolic representation learning. The asserted benefits are improved performance on a variety of graph tasks, node classification and link prediction included. Claims have also been made about the geometric suitability of particular hierarchical graph datasets to representation in hyperbolic space. Despite these claims, our work makes a surprising discovery: when simple Euclidean models with comparable numbers of parameters are properly trained in the same environment, in most cases, they perform as well, if not better, than all introduced hyperbolic graph representation learning models, even on graph datasets previously claimed to be the most hyperbolic as measured by Gromov $\\delta$-hyperbolicity (i.e., perfect trees). This observation gives rise to a simple question: how can this be? We answer this question by taking a careful look at the field of hyperbolic graph representation learning as it stands today, and find that a number of results do not diligently present baselines, make faulty modelling assumptions when constructing algorithms, and use misleading metrics to quantify geometry of graph datasets. We take a closer look at each of these three problems, elucidate the issues, perform an analysis of methods, and introduce a parametric family of benchmark datasets to ascertain the applicability of (hyperbolic) graph neural networks",
    "checked": true,
    "id": "391a80a4254767b2491d812da3fed5bec1e80430",
    "semantic_title": "shedding light on problems with hyperbolic graph learning",
    "citation_count": 1,
    "authors": [
      "Isay Katsman",
      "Anna Gilbert"
    ]
  },
  "https://openreview.net/forum?id=IPmzyQSiQE": {
    "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder",
    "volume": "reprod",
    "abstract": "This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on the short-context MTEB benchmark and the long context LoCo benchmark. We release the training code and model weights under an Apache 2.0 license. In contrast with other open-source models, we release the full curated training data and code that allows for full replication of nomic-embed-text-v1. You can find code and data to replicate the model at \\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}",
    "checked": true,
    "id": "03bdd9cbb3b768ff3e96c97b28e106748b6e4fd0",
    "semantic_title": "nomic embed: training a reproducible long context text embedder",
    "citation_count": 124,
    "authors": [
      "Zach Nussbaum",
      "John Xavier Morris",
      "Andriy Mulyar",
      "Brandon Duderstadt"
    ]
  },
  "https://openreview.net/forum?id=wcxrJcJ7vq": {
    "title": "The Elusive Pursuit of Reproducing PATE-GAN: Benchmarking, Auditing, Debugging",
    "volume": "reprod",
    "abstract": "Synthetic data created by differentially private (DP) generative models is increasingly used in real-world settings. In this context, PATE-GAN has emerged as one of the most popular algorithms, combining Generative Adversarial Networks (GANs) with the private training approach of PATE (Private Aggregation of Teacher Ensembles). In this paper, we set out to reproduce the utility evaluation from the original PATE-GAN paper, compare available implementations, and conduct a privacy audit. More precisely, we analyze and benchmark six open-source PATE-GAN implementations, including three by (a subset of) the original authors. First, we shed light on architecture deviations and empirically demonstrate that none reproduce the utility performance reported in the original paper. We then present an in-depth privacy evaluation, which includes DP auditing, and show that \\textit{all implementations leak more privacy than intended}. Furthermore, we uncover \\textit{19 privacy violations} and 5 other bugs in these six open-source implementations. Lastly, our codebase is available from: \\url{https://github.com/spalabucr/pategan-audit}",
    "checked": true,
    "id": "183963ed2f003702b13320fab72e6e674cf95a5d",
    "semantic_title": "the elusive pursuit of reproducing pate-gan: benchmarking, auditing, debugging",
    "citation_count": 9,
    "authors": [
      "Georgi Ganev",
      "Meenatchi Sundaram Muthu Selva Annamalai",
      "Emiliano De Cristofaro"
    ]
  },
  "https://openreview.net/forum?id=wF3ZtSlOcT": {
    "title": "Multivariate Dense Retrieval: A Reproducibility Study under a Memory-limited Setup",
    "volume": "reprod",
    "abstract": "The current paradigm in dense retrieval is to represent queries and passages as low-dimensional real-valued vectors using neural language models, and then compute query-passage similarity as the dot product of these vector representations. A limitation of this approach is that these learned representations cannot capture or express uncertainty. At the same time, information retrieval over large corpora contains several sources of uncertainty, such as misspelled or ambiguous text. Consequently, retrieval methods that incorporate uncertainty estimation are more likely to generalize well to such data distribution shifts. The multivariate representation learning (MRL) framework proposed by Zamani & Bendersky (2023) is the first method that works in the direction of modeling uncertainty in dense retrieval. This framework represents queries and passages as multivariate normal distributions and computes query-passage similarity as the negative Kullback-Leibler (KL) divergence between these distributions. Furthermore, MRL formulates KL divergence as a dot product, allowing for efficient first-stage retrieval using standard maximum inner product search. In this paper, we attempt to reproduce MRL under memory constraints (e.g., an academic computational budget). In particular, we focus on a memory-limited, single GPU setup. We find that the original work (i) introduces a typographical/mathematical error early in the formulation of the method that propagates to the rest of the original paper's mathematical formulations, and (ii) does not fully specify certain important design choices that can strongly influence performance. In light of the aforementioned, we address the mathematical error and make some reasonable design choices when important details are unspecified. Additionally, we expand on the results from the original paper with a thorough ablation study which provides more insight into the impact of the framework's different components. While we confirm that MRL can have state-of-the-art performance, we could not reproduce the results reported in the original paper or uncover the reported trends against the baselines under a memory-limited setup that facilitates fair comparisons of MRL against its baselines. Our analysis offers insights as to why that is the case. Most importantly, our empirical results suggest that the variance definition in MRL does not consistently capture uncertainty. The source code for our reproducibility study is available at: https://github.com/samarthbhargav/multivariate_ir/",
    "checked": true,
    "id": "8a206e589da4a147ed954b5df0706e685788bd15",
    "semantic_title": "multivariate dense retrieval: a reproducibility study under a memory-limited setup",
    "citation_count": 0,
    "authors": [
      "Georgios Sidiropoulos",
      "Samarth Bhargav",
      "Panagiotis Eustratiadis",
      "Evangelos Kanoulas"
    ]
  },
  "https://openreview.net/forum?id=knv4lQFVoE": {
    "title": "A general framework of Riemannian adaptive optimization methods with a convergence analysis",
    "volume": "reprod",
    "abstract": "This paper proposes a general framework of Riemannian adaptive optimization methods. The framework encapsulates several stochastic optimization algorithms on Riemannian manifolds and incorporates the mini-batch strategy that is often used in deep learning. Within this framework, we also propose AMSGrad on embedded submanifolds of Euclidean space. Moreover, we give convergence analyses valid for both a constant and a diminishing step size. Our analyses also reveal the relationship between the convergence rate and mini-batch size. In numerical experiments, we applied the proposed algorithm to principal component analysis and the low-rank matrix completion problem, which can be considered to be Riemannian optimization problems. Python implementations of the methods used in the numerical experiments are available at https://github.com/iiduka-researches/202408-adaptive",
    "checked": true,
    "id": "cbbd640cced2ef1c0ba4ce11c9dbb62c22cd9e48",
    "semantic_title": "a general framework of riemannian adaptive optimization methods with a convergence analysis",
    "citation_count": 0,
    "authors": [
      "Hiroyuki Sakai",
      "Hideaki Iiduka"
    ]
  },
  "https://openreview.net/forum?id=f7OkIurx4b": {
    "title": "A Survey of Reinforcement Learning from Human Feedback",
    "volume": "survey",
    "abstract": "Reinforcement learning from human feedback (RLHF) is a variant of reinforcement learning (RL) that learns from human feedback instead of relying on an engineered reward function. Building on prior work on the related setting of preference-based reinforcement learning (PbRL), it stands at the intersection of artificial intelligence and human-computer interaction. This positioning provides a promising approach to enhance the performance and adaptability of intelligent systems while also improving the alignment of their objectives with human values. The success in training large language models (LLMs) has impressively demonstrated this potential in recent years, where RLHF has played a decisive role in directing the model's capabilities towards human objectives. This article provides an overview of the fundamentals of RLHF, exploring how RL agents interact with human feedback. While recent focus has been on RLHF for LLMs, our survey covers the technique across multiple domains. We provide our most comprehensive coverage in control and robotics, where many fundamental techniques originate, alongside a dedicated LLM section. We examine the core principles that underpin RLHF, how algorithms and human feedback work together, and discuss the main research trends in the field. Our goal is to give researchers and practitioners a clear understanding of this rapidly growing field",
    "checked": true,
    "id": "6f9dbae279fa0c3a90d12f3b0f271dc8e6274817",
    "semantic_title": "a survey of reinforcement learning from human feedback",
    "citation_count": 155,
    "authors": [
      "Timo Kaufmann",
      "Paul Weng",
      "Viktor Bengs",
      "Eyke Hüllermeier"
    ]
  },
  "https://openreview.net/forum?id=ECBepTWAFG": {
    "title": "A User's Guide to Sampling Strategies for Sliced Optimal Transport",
    "volume": "survey",
    "abstract": "This paper serves as a user's guide to sampling strategies for sliced optimal transport. We provide reminders and additional regularity results on the Sliced Wasserstein distance. We detail the construction methods, generation time complexity, theoretical guarantees, and conditions for each strategy. Additionally, we provide insights into their suitability for sliced optimal transport in theory. Extensive experiments on both simulated and real-world data offer a representative comparison of the strategies, culminating in practical recommendations for their best usage",
    "checked": true,
    "id": "48561a1a35c90c8e187682e340a79aff67aa46f4",
    "semantic_title": "a user's guide to sampling strategies for sliced optimal transport",
    "citation_count": 2,
    "authors": [
      "Keanu Sisouk",
      "Julie Delon",
      "Julien Tierny"
    ]
  },
  "https://openreview.net/forum?id=gOk34vUHtz": {
    "title": "A Survey of State Representation Learning for Deep Reinforcement Learning",
    "volume": "survey",
    "abstract": "Representation learning methods are an important tool for addressing the challenges posed by complex observations spaces in sequential decision making problems. Recently, many methods have used a wide variety of types of approaches for learning meaningful state representations in reinforcement learning, allowing better sample efficiency, generalization, and performance. This survey aims to provide a broad categorization of these methods within a model-free online setting, exploring how they tackle the learning of state representations differently. We categorize the methods into six main classes, detailing their mechanisms, benefits, and limitations. Through this taxonomy, our aim is to enhance the understanding of this field and provide a guide for new researchers. We also discuss techniques for assessing the quality of representations, and detail relevant future directions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayoub Echchahed",
      "Pablo Samuel Castro"
    ]
  },
  "https://openreview.net/forum?id=fzmw8Joug4": {
    "title": "Monocular Dynamic Gaussian Splatting: Fast, Brittle, and Scene Complexity Rules",
    "volume": "survey",
    "abstract": "Gaussian splatting methods are emerging as a popular approach for converting multi-view image data into scene representations that allow view synthesis. In particular, there is interest in enabling view synthesis for dynamic scenes using only monocular input data---an ill-posed and challenging problem. The fast pace of work in this area has produced multiple simultaneous papers that claim to work best, which cannot all be true. In this work, we organize, benchmark, and analyze many Gaussian-splatting-based methods, providing apples-to-apples comparisons that prior works have lacked. We use multiple existing datasets and a new instructive synthetic dataset designed to isolate factors that affect reconstruction quality. We systematically categorize Gaussian splatting methods into specific motion representation types and quantify how their differences impact performance. Empirically, we find that their rank order is well-defined in synthetic data, but the complexity of real-world data currently overwhelms the differences. Furthermore, the fast rendering speed of all Gaussian-based methods comes at the cost of brittleness in optimization. We summarize our experiments into a list of findings that can help to further progress in this lively problem setting",
    "checked": true,
    "id": "7a346224894ac54449fa528071cc4b679bae29e5",
    "semantic_title": "monocular dynamic gaussian splatting: fast, brittle, and scene complexity rules",
    "citation_count": 2,
    "authors": [
      "Yiqing Liang",
      "Mikhail Okunev",
      "Mikaela Angelina Uy",
      "Runfeng Li",
      "Leonidas Guibas",
      "James Tompkin",
      "Adam W Harley"
    ]
  },
  "https://openreview.net/forum?id=tf6A9EYMo6": {
    "title": "Personalization of Large Language Models: A Survey",
    "volume": "survey",
    "abstract": "Personalization of Large Language Models (LLMs) has recently become increasingly important with a wide range of applications. Despite the importance and recent progress, most existing works on personalized LLMs have focused either entirely on (a) personalized text generation or (b) leveraging LLMs for personalization-related downstream applications, such as recommendation systems. In this work, we bridge the gap between these two separate main directions for the first time by introducing a taxonomy for personalized LLM usage and summarizing the key differences and challenges. We provide a formalization of the foundations of personalized LLMs that consolidates and expands notions of personalization of LLMs, defining and discussing novel facets of personalization, usage, and desiderata of personalized LLMs. We then unify the literature across these diverse fields and usage scenarios by proposing systematic taxonomies for the granularity of personalization, personalization techniques, datasets, evaluation methods, and applications of personalized LLMs. Finally, we highlight challenges and important open problems that remain to be addressed. By unifying and surveying recent research using the proposed taxonomies, we aim to provide a clear guide to the existing literature and different facets of personalization in LLMs, empowering both researchers and practitioners",
    "checked": true,
    "id": "97cab6c9c1e8f067f35868c4f4854fa54a2b30dc",
    "semantic_title": "personalization of large language models: a survey",
    "citation_count": 0,
    "authors": [
      "Zhehao Zhang",
      "Ryan A. Rossi",
      "Branislav Kveton",
      "Yijia Shao",
      "Diyi Yang",
      "Hamed Zamani",
      "Franck Dernoncourt",
      "Joe Barrow",
      "Tong Yu",
      "Sungchul Kim",
      "Ruiyi Zhang",
      "Jiuxiang Gu",
      "Tyler Derr",
      "Hongjie Chen",
      "Junda Wu",
      "Xiang Chen",
      "Zichao Wang",
      "Subrata Mitra",
      "Nedim Lipka",
      "Nesreen K. Ahmed",
      "Yu Wang"
    ]
  },
  "https://openreview.net/forum?id=wHECkBOwyt": {
    "title": "Efficient Diffusion Models: A Survey",
    "volume": "survey",
    "abstract": "Diffusion models have emerged as powerful generative models capable of producing high-quality contents such as images, videos, and audio, demonstrating their potential to revolutionize digital content creation. However, these capabilities come at the cost of significant computational resources and lengthy generation time, underscoring the critical need to develop efficient techniques for practical deployment. In this survey, we provide a systematic and comprehensive review of research on efficient diffusion models. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient diffusion model topics from algorithm-level, system-level, and framework perspective, respectively. We have also created a GitHub repository where we organize the papers featured in this survey at github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient diffusion model research and inspire them to contribute to this important and exciting field",
    "checked": true,
    "id": "8431624a3e9f5db968d52a1fecc26c7dc1ade0d5",
    "semantic_title": "efficient diffusion models: a survey",
    "citation_count": 10,
    "authors": [
      "Hui Shen",
      "Jingxuan Zhang",
      "Boning Xiong",
      "Rui Hu",
      "Shoufa Chen",
      "Zhongwei Wan",
      "Xin Wang",
      "Yu Zhang",
      "Zixuan Gong",
      "Guangyin Bao",
      "Chaofan Tao",
      "Yongfeng Huang",
      "Ye Yuan",
      "Mi Zhang"
    ]
  },
  "https://openreview.net/forum?id=ewwNKwh6SK": {
    "title": "Conditional Image Synthesis with Diffusion Models: A Survey",
    "volume": "survey",
    "abstract": "Conditional image synthesis based on user-specified requirements is a key component in creating complex visual content. In recent years, diffusion-based generative modeling has become a highly effective way for conditional image synthesis, leading to exponential growth in the literature. However, the complexity of diffusion-based modeling, the wide range of image synthesis tasks, and the diversity of conditioning mechanisms present significant challenges for researchers to keep up with rapid developments and to understand the core concepts on this topic. In this survey, we categorize existing works based on how conditions are integrated into the two fundamental components of diffusion-based modeling, i.e., the denoising network and the sampling process. We specifically highlight the underlying principles, advantages, and potential challenges of various conditioning approaches during the training, re-purposing, and specialization stages to construct a desired denoising network. We also summarize six mainstream conditioning mechanisms in the sampling process. All discussions are centered around popular applications. Finally, we pinpoint several critical yet still unsolved problems and suggest some possible solutions for future research",
    "checked": true,
    "id": "611cac8592775665b3985ceb7e2d745d87277334",
    "semantic_title": "conditional image synthesis with diffusion models: a survey",
    "citation_count": 10,
    "authors": [
      "Zheyuan Zhan",
      "Defang Chen",
      "Jian-Ping Mei",
      "Zhenghe Zhao",
      "Jiawei Chen",
      "Chun Chen",
      "Siwei Lyu",
      "Can Wang"
    ]
  },
  "https://openreview.net/forum?id=ZiJYahyXLU": {
    "title": "Machine Learning with Physics Knowledge for Prediction: A Survey",
    "volume": "survey",
    "abstract": "This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning",
    "checked": true,
    "id": "d6450a20dc6ab704d151a9bac525017bd48fc1cf",
    "semantic_title": "machine learning with physics knowledge for prediction: a survey",
    "citation_count": 0,
    "authors": [
      "Joe Watson",
      "Chen Song",
      "Oliver Weeger",
      "Theo Gruner",
      "An Thai Le",
      "Kay Hansel",
      "Ahmed Hendawy",
      "Oleg Arenz",
      "Will Trojak",
      "Miles Cranmer",
      "Carlo D'Eramo",
      "Fabian Buelow",
      "Tanmay Goyal",
      "Jan Peters",
      "Martin W Hoffmann"
    ]
  },
  "https://openreview.net/forum?id=CsoSWpR5xC": {
    "title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios",
    "volume": "survey",
    "abstract": "Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model (LLM)-based social agents. While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress. To address this gap, we systematically review existing research on LLM-based social agents within game-theoretic scenarios. Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol. The game framework encompasses diverse game scenarios, ranging from choice-focusing to communication-focusing games. The social agent part explores agents' preferences, beliefs, and reasoning abilities, as well as their interactions and synergistic effects on decision-making. The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance. Additionally, we analyze the performance of current social agents across various game scenarios. By reflecting on the current research and identifying future research directions, this survey provides insights to advance the development and evaluation of social agents in game-theoretic scenarios",
    "checked": true,
    "id": "30dcacbf0b7a93196e07c721be35274afdcb4aa4",
    "semantic_title": "a survey on large language model-based social agents in game-theoretic scenarios",
    "citation_count": 7,
    "authors": [
      "Xiachong Feng",
      "Longxu Dou",
      "Minzhi Li",
      "Qinghao Wang",
      "Yu Guo",
      "Haochuan Wang",
      "Chang Ma",
      "Lingpeng Kong"
    ]
  },
  "https://openreview.net/forum?id=D1PPuk8ZBI": {
    "title": "When Should Reinforcement Learning Use Causal Reasoning?",
    "volume": "survey",
    "abstract": "Reinforcement learning (RL) and causal reasoning naturally complement each other. The goal of causal reasoning is to predict the effects of interventions in an environment, while the goal of reinforcement learning is to select interventions that maximize the rewards the agent receives from the environment. Reinforcement learning includes the two most powerful sources of information for estimating causal relationships: temporal ordering and the ability to act on an environment. This paper provides a theoretical study examining which reinforcement learning settings we can expect to benefit from causal reasoning, and how. According to our analysis, the key factor is {\\em whether the behavioral policy---which generates the data---can be executed by the learning agent}, meaning that the observation signal available to the learning agent comprises all observations used by the behavioral policy. Common RL settings with behavioral policies that are executable by the learning agent include on-policy learning and online exploration, where the learning agent uses a behavioral policy to explore the environment. Common RL settings with behavioral policies that are not executable by the learning agent include offline learning with a partially observable state space and asymmetric imitation learning where the demonstrator has access to more observations than the imitator. Using the theory of causal graphs, we show formally that when the behavioral policy is executable by the learning agent, conditional probabilities are causal, and can therefore be used to estimate expected rewards as done in traditional RL. However, when the behavioral policy is not executable by the learning agent, conditional probabilities may be confounded and provide misleading estimates of expected rewards. For confounded settings, we describe previous and new methods for leveraging causal reasoning",
    "checked": true,
    "id": "1ea0a4c86eaf441a6aafe6b52213985cd06304d9",
    "semantic_title": "when should reinforcement learning use causal reasoning?",
    "citation_count": 0,
    "authors": [
      "Oliver Schulte",
      "Pascal Poupart"
    ]
  },
  "https://openreview.net/forum?id=fHf4jbIfex": {
    "title": "Graph Theory-Based Deep Graph Similarity Learning: A Unified Survey of Pipeline, Techniques, and Challenges",
    "volume": "survey",
    "abstract": "Graph similarity computation, which measures the resemblance between graphs, is a crucial operation in fields such as graph search. Recent advances in graph neural networks have enabled the embedding of graphs into low-dimensional vector spaces, where the sim- ilarity or distance between graphs can be efficiently quantified. However, these methods are often tailored to specific tasks and function as black boxes, limiting both generalization and interpretability. To address these challenges, there is growing interest in incorporating domain-agnostic and interpretable concepts from graph theory—such as subgraph isomorphism, maximum common subgraph, and graph edit distance—into graph similarity learning as training objectives. This survey presents a comprehensive review of recent advancements in deep graph similarity learning, focusing on models that integrate these graph theory concepts. Despite the different training objectives of these approaches, they share significant commonalities in the training pipeline, techniques, and challenges. We analyze them within a unified lens referred to as graph theory-based deep similarity learning (GTDGSL) methods. We systematically compare existing GTDGSL methods alongside their common training pipeline, highlighting the technique trend and discussing key challenges, applications, and future research directions in this domain. We organize the papers included in this survey and their open-source implementations at https://github.com/liuzhouyang/Graph-Theory-Based-Deep-Graph-Similarity-Learning-Survey",
    "checked": true,
    "id": "6d77947ac450086ece791c10a8a32e74d2d0d5c2",
    "semantic_title": "graph theory-based deep graph similarity learning: a unified survey of pipeline, techniques, and challenges",
    "citation_count": 1,
    "authors": [
      "Zhouyang LIU",
      "Ning Liu",
      "Yixin Chen",
      "Ziqing Wen",
      "Jiezhong He",
      "Dongsheng Li"
    ]
  },
  "https://openreview.net/forum?id=u0azVc9Y0y": {
    "title": "A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning",
    "volume": "survey",
    "abstract": "The availability of performant pre-trained models has led to a proliferation of fine-tuned expert models that are specialized to a particular domain or task. Model MoErging methods aim to recycle expert models to create an aggregate system with improved performance or generalization. A key component of MoErging methods is the creation of a router that decides which expert model(s) to use for a particular input or application. The promise, effectiveness, and large design space of MoErging has spurred the development of many new methods over the past few years. This rapid pace of development has made it challenging to compare different MoErging methods, which are rarely compared to one another and are often validated in different experimental setups. To remedy such gaps, we present a comprehensive survey of MoErging methods that includes a novel taxonomy for cataloging key design choices and clarifying suitable applications for each method. Apart from surveying MoErging research, we inventory software tools and applications that make use of MoErging. We additionally discuss related fields of study such as model merging, multitask learning, and mixture-of-experts models. Taken as a whole, our survey provides a unified overview of existing MoErging methods and creates a solid foundation for future work in this burgeoning field",
    "checked": true,
    "id": "1572367adc39eb367c24335ac4218aec7bc08d83",
    "semantic_title": "a survey on model moerging: recycling and routing among specialized experts for collaborative learning",
    "citation_count": 25,
    "authors": [
      "Prateek Yadav",
      "Colin Raffel",
      "Mohammed Muqeeth",
      "Lucas Caccia",
      "Haokun Liu",
      "Tianlong Chen",
      "Mohit Bansal",
      "Leshem Choshen",
      "Alessandro Sordoni"
    ]
  },
  "https://openreview.net/forum?id=1BqXkjNEGP": {
    "title": "Autoregressive Models in Vision: A Survey",
    "volume": "survey",
    "abstract": "Autoregressive modeling has been a huge success in the field of natural language processing (NLP). Recently, autoregressive models have emerged as a significant area of focus in computer vision, where they excel in producing high-quality visual content. Autoregressive models in NLP typically operate on subword tokens. However, the representation strategy in computer vision can vary in different levels, i.e., pixel-level, token-level, or scale-level, reflecting the diverse and hierarchical nature of visual data compared to the sequential structure of language. This survey comprehensively examines the literature on autoregressive models applied to vision. To improve readability for researchers from diverse research backgrounds, we start with preliminary sequence representation and modeling in vision. Next, we divide the fundamental frameworks of visual autoregressive models into three general sub-categories, including pixel-based, token-based, and scale-based models based on the representation strategy. We then explore the interconnections between autoregressive models and other generative models. Furthermore, we present a multifaceted categorization of autoregressive models in computer vision, including image generation, video generation, 3D generation, and multimodal generation. We also elaborate on their applications in diverse domains, including emerging domains such as embodied AI and 3D medical AI, with about 250 related references. Finally, we highlight the current challenges to autoregressive models in vision with suggestions about potential research directions. We have also set up a Github repository to organize the papers included in this survey at: https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey",
    "checked": true,
    "id": "1a7d4887ca8f83bdfbb71ed00f8ad0f6c4e1d4c4",
    "semantic_title": "autoregressive models in vision: a survey",
    "citation_count": 0,
    "authors": [
      "Jing Xiong",
      "Gongye Liu",
      "Lun Huang",
      "Chengyue Wu",
      "Taiqiang Wu",
      "Yao Mu",
      "Yuan Yao",
      "Hui Shen",
      "Zhongwei Wan",
      "Jinfa Huang",
      "Chaofan Tao",
      "Shen Yan",
      "Huaxiu Yao",
      "Lingpeng Kong",
      "Hongxia Yang",
      "Mi Zhang",
      "Guillermo Sapiro",
      "Jiebo Luo",
      "Ping Luo",
      "Ngai Wong"
    ]
  },
  "https://openreview.net/forum?id=M7Lhr2anjg": {
    "title": "Expressivity of Representation Learning on Continuous-Time Dynamic Graphs: An Information-Flow Centric Review",
    "volume": "survey",
    "abstract": "Graphs are ubiquitous in real-world applications, ranging from social networks to biological systems, and have inspired the development of Graph Neural Networks (GNNs) for learning expressive representations. While most research has centered on static graphs, many real-world scenarios involve dynamic, temporally evolving graphs, motivating the need for Continuous-Time Dynamic Graph (CTDG) models. This paper provides a comprehensive review of Graph Representation Learning (GRL) on CTDGs with a focus on Self-Supervised Representation Learning (SSRL). We introduce a novel theoretical framework that analyzes the expressivity of CTDG models through an Information-Flow (IF) lens, quantifying their ability to propagate and encode temporal and structural information. Leveraging this framework, we categorize existing CTDG methods based on their suitability for different graph types and application scenarios. Within the same scope, we examine the design of SSRL methods tailored to CTDGs, such as predictive and contrastive approaches, highlighting their potential to mitigate the reliance on labeled data. Empirical evaluations on synthetic and real-world datasets validate our theoretical insights, demonstrating the strengths and limitations of various methods across long-range, bi-partite and community-based graphs. This work offers both a theoretical foundation and practical guidance for selecting and developing CTDG models, advancing the understanding of GRL in dynamic settings",
    "checked": true,
    "id": "04d443232131ff2370a62eb20b91b21811babb12",
    "semantic_title": "expressivity of representation learning on continuous-time dynamic graphs: an information-flow centric review",
    "citation_count": 0,
    "authors": [
      "Sofiane ENNADIR",
      "Gabriela Zarzar Gandler",
      "Filip Cornell",
      "Lele Cao",
      "Oleg Smirnov",
      "Tianze Wang",
      "Levente Zólyomi",
      "Björn Brinne",
      "Sahar Asadi"
    ]
  },
  "https://openreview.net/forum?id=vz5P1Kbt6t": {
    "title": "Adaptive Physics-informed Neural Networks: A Survey",
    "volume": "survey",
    "abstract": "Physics-informed neural networks (PINNs) have emerged as a promising approach for solving partial differential equations (PDEs) using neural networks, particularly in data-scarce scenarios due to their unsupervised training capability. However, a key limitation is the need for re-optimization with each change in PDE parameters, similar to the challenge in traditional numerical methods where each system of equations corresponds to a specific PDE instance. This characteristic poses a barrier to the widespread adoption of PINNs across scientific and engineering applications. This survey explores research addressing this limitation through transfer learning and meta-learning, synthesizing insights to establish a foundation for efficient data generation strategies tailored to PINNs. These methods can potentially improve PINNs' training efficiency, enabling quicker adaptation to new PDEs with fewer data and computational demands. While numerical methods directly solve systems of equations to derive solutions, neural networks implicitly learn solutions by adjusting their parameters. One notable advantage of neural networks lies in their capacity to abstract away from specific problem domains, enabling them to retain, discard, or adapt learned representations to efficiently address similar problems. By understanding how these techniques can be applied to PINNs, this survey seeks to identify promising directions for future research to enable the widespread adoption of PINNs across a wide range of scientific and engineering applications",
    "checked": true,
    "id": "8d5c533c2de427131ef090c05d36400967130394",
    "semantic_title": "adaptive physics-informed neural networks: a survey",
    "citation_count": 0,
    "authors": [
      "Edgar Torres",
      "Mathias Niepert"
    ]
  },
  "https://openreview.net/forum?id=1nO4qFMiS0": {
    "title": "Open Problems in Technical AI Governance",
    "volume": "survey",
    "abstract": "AI progress is creating a growing range of risks and opportunities, but it is often unclear how they should be navigated. In many cases, the barriers and uncertainties faced are at least partly technical. Technical AI governance, referring to technical analysis and tools for supporting the effective governance of AI, seeks to address such challenges. It can help to (a) identify areas where intervention is needed, (b) assess the efficacy of potential governance actions, and (c) enhance governance options by designing mechanisms for enforcement, incentivization, or compliance. In this paper, we explain what technical AI governance is, outline why it is important, and present a taxonomy and incomplete catalog of its open problems. This paper is intended as a resource for technical researchers or research funders looking to contribute to AI governance",
    "checked": true,
    "id": "4cd38b5ff4891690547e9bdcc893cddf0bbf5e48",
    "semantic_title": "open problems in technical ai governance",
    "citation_count": 0,
    "authors": [
      "Anka Reuel",
      "Benjamin Bucknall",
      "Stephen Casper",
      "Timothy Fist",
      "Lisa Soder",
      "Onni Aarne",
      "Lewis Hammond",
      "Lujain Ibrahim",
      "Alan Chan",
      "Peter Wills",
      "Markus Anderljung",
      "Ben Garfinkel",
      "Lennart Heim",
      "Andrew Trask",
      "Gabriel Mukobi",
      "Rylan Schaeffer",
      "Mauricio Baker",
      "Sara Hooker",
      "Irene Solaiman",
      "Sasha Luccioni",
      "Nitarshan Rajkumar",
      "Nicolas Moës",
      "Jeffrey Ladish",
      "David Bau",
      "Paul Bricman",
      "Neel Guha",
      "Jessica Newman",
      "Yoshua Bengio",
      "Tobin South",
      "Alex Pentland",
      "Sanmi Koyejo",
      "Mykel Kochenderfer",
      "Robert Trager"
    ]
  },
  "https://openreview.net/forum?id=FJgtVfUxLQ": {
    "title": "A Survey on the Honesty of Large Language Models",
    "volume": "survey",
    "abstract": "Honesty is a fundamental principle for aligning large language models (LLMs) with human values, requiring these models to recognize what they know and don't know and be able to faithfully express their knowledge. Despite promising, current LLMs still exhibit significant dishonest behaviors, such as confidently presenting wrong answers or failing to express what they know. In addition, research on the honesty of LLMs also faces challenges, including varying definitions of honesty, difficulties in distinguishing between known and unknown knowledge, and a lack of comprehensive understanding of related research. To address these issues, we provide a survey on the honesty of LLMs, covering its clarification, evaluation approaches, and strategies for improvement. Moreover, we offer insights for future research, aiming to inspire further exploration in this important area",
    "checked": true,
    "id": "8c0bd83a241bc73a1e5267cf3abe05d8b4706570",
    "semantic_title": "a survey on the honesty of large language models",
    "citation_count": 6,
    "authors": [
      "Siheng Li",
      "Cheng Yang",
      "Taiqiang Wu",
      "Chufan Shi",
      "Yuji Zhang",
      "Xinyu Zhu",
      "Zesen Cheng",
      "Deng Cai",
      "Mo Yu",
      "Lemao Liu",
      "Jie Zhou",
      "Yujiu Yang",
      "Ngai Wong",
      "Xixin Wu",
      "Wai Lam"
    ]
  },
  "https://openreview.net/forum?id=QTsJXSvAI2": {
    "title": "Where Do We Stand with Implicit Neural Representations? A Technical and Performance Survey",
    "volume": "survey",
    "abstract": "Implicit Neural Representations (INRs) have emerged as a paradigm in knowledge representation, offering exceptional flexibility and performance across a diverse range of applications. INRs leverage multilayer perceptrons (MLPs) to model data as continuous implicit functions, providing critical advantages such as resolution independence, memory efficiency, and generalisation beyond discretised data structures. Their ability to solve complex inverse problems makes them particularly effective for tasks including audio reconstruction, image representation, 3D object reconstruction, and high-dimensional data synthesis. This survey provides a comprehensive review of state-of-the-art INR methods, introducing a clear taxonomy that categorises them into four key areas: activation functions, position encoding, combined strategies, and network structure optimisation. We rigorously analyse their critical properties—such as full differentiability, smoothness, compactness, and adaptability to varying resolutions—while also examining their strengths and limitations in addressing locality biases and capturing fine details. Our experimental comparison offers new insights into the trade-offs between different approaches, showcasing the capabilities and challenges of the latest INR techniques across various tasks. In addition to identifying areas where current methods excel, we highlight key limitations and potential avenues for improvement, such as developing more expressive activation functions, enhancing positional encoding mechanisms, and improving scalability for complex, high-dimensional data. This survey serves as a roadmap for researchers, offering practical guidance for future exploration in the field of INRs. We aim to foster new methodologies by outlining promising research directions for INRs and applications",
    "checked": true,
    "id": "07643961babde528905ed94de0f9ec8c58e083c9",
    "semantic_title": "where do we stand with implicit neural representations? a technical and performance survey",
    "citation_count": 11,
    "authors": [
      "Amer Essakine",
      "Yanqi Cheng",
      "Chun-Wun Cheng",
      "Lipei Zhang",
      "Zhongying Deng",
      "Lei Zhu",
      "Carola-Bibiane Schönlieb",
      "Angelica I Aviles-Rivero"
    ]
  },
  "https://openreview.net/forum?id=sZdtTJInUg": {
    "title": "Class Incremental Learning from First Principles: A Review",
    "volume": "survey",
    "abstract": "Continual learning systems attempt to efficiently learn over time without forgetting previously acquired knowledge. In recent years, there has been an explosion of work on continual learning, mainly focused on the class-incremental learning (CIL) setting. In this review, we take a step back and reconsider the CIL problem. We reexamine the problem definition and describe its unique challenges, contextualize existing solutions by analyzing non-continual approaches, and investigate the implications of various problem configurations. Our goal is to provide an alternative perspective to existing work on CIL and direct attention toward unexplored aspects of the problem",
    "checked": true,
    "id": "bf16f3a226c9d51dd2b872eb29209f05b784d635",
    "semantic_title": "class incremental learning from first principles: a review",
    "citation_count": 0,
    "authors": [
      "Neil Ashtekar",
      "Jingxi Zhu",
      "Vasant G Honavar"
    ]
  },
  "https://openreview.net/forum?id=ukLxqA8zXj": {
    "title": "Evaluating Interpretable Methods via Geometric Alignment of Functional Distortions",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "89290fff9bbf24950491958a697f5e3bfc038206",
    "semantic_title": "evaluating interpretable methods via geometric alignment of functional distortions",
    "citation_count": 0,
    "authors": [
      "Anna Hedström",
      "Philine Lou Bommer",
      "Thomas F Burns",
      "Sebastian Lapuschkin",
      "Wojciech Samek",
      "Marina MC Höhne"
    ]
  },
  "https://openreview.net/forum?id=RGsdAwWuu6": {
    "title": "Unified Risk Analysis for Weakly Supervised Learning",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "4ecae9ae0e0f29cfd6ca38e1808db899247f5c0c",
    "semantic_title": "unified risk analysis for weakly supervised learning",
    "citation_count": 0,
    "authors": [
      "Chao-Kai Chiang",
      "Masashi Sugiyama"
    ]
  },
  "https://openreview.net/forum?id=YxKJihRcby": {
    "title": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey)",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "ea018112b3ba92beabaab67ae7f7d70ac6b375af",
    "semantic_title": "deep neural networks and brain alignment: brain encoding and decoding (survey)",
    "citation_count": 15,
    "authors": [
      "SUBBA REDDY OOTA",
      "Zijiao Chen",
      "Manish Gupta",
      "Bapi Raju Surampudi",
      "Gael Jobard",
      "Frederic Alexandre",
      "Xavier Hinaut"
    ]
  },
  "https://openreview.net/forum?id=WUQsBiJqyP": {
    "title": "A Comprehensive Survey on Inverse Constrained Reinforcement Learning: Definitions, Progress and Challenges",
    "volume": "survey",
    "abstract": "",
    "checked": true,
    "id": "bd87f724846d6f92bbc17b0050eb89eb0b5337ac",
    "semantic_title": "a comprehensive survey on inverse constrained reinforcement learning: definitions, progress and challenges",
    "citation_count": 3,
    "authors": [
      "Guiliang Liu",
      "Sheng Xu",
      "Shicheng Liu",
      "Ashish Gaurav",
      "Sriram Ganapathi Subramanian",
      "Pascal Poupart"
    ]
  },
  "https://openreview.net/forum?id=wZLWuFHxt5": {
    "title": "A Survey of Recent Backdoor Attacks and Defenses in Large Language Models",
    "volume": "survey",
    "abstract": "Large Language Models (LLMs), which bridge the gap between human language understanding and complex problem-solving, achieve state-of-the-art performance on several NLP tasks, particularly in few-shot and zero-shot settings. Despite the demonstrable efficacy of LLMs, due to constraints on computational resources, users have to engage with open-source language models or outsource the entire training process to third-party platforms. However, research has demonstrated that language models are susceptible to potential security vulnerabilities, particularly in backdoor attacks. Backdoor attacks are designed to introduce targeted vulnerabilities into language models by poisoning training samples or model weights, allowing attackers to manipulate model responses through malicious triggers. While existing surveys on backdoor attacks provide a comprehensive overview, they lack an in-depth examination of backdoor attacks specifically targeting LLMs. To bridge this gap and grasp the latest trends in the field, this paper presents a novel perspective on backdoor attacks for LLMs by focusing on fine-tuning methods. Specifically, we systematically classify backdoor attacks into three categories: full-parameter fine-tuning, parameter-efficient fine-tuning, and no fine-tuning. Based on insights from a substantial review, we also discuss crucial issues for future research on backdoor attacks, such as further exploring attack algorithms that do not require fine-tuning, or developing more covert attack algorithms",
    "checked": true,
    "id": "9d5d835bcf5e0ab22fdf156bf0dea10b05894d56",
    "semantic_title": "a survey of recent backdoor attacks and defenses in large language models",
    "citation_count": 0,
    "authors": [
      "Shuai Zhao",
      "Meihuizi Jia",
      "Zhongliang Guo",
      "Leilei Gan",
      "XIAOYU XU",
      "Xiaobao Wu",
      "Jie Fu",
      "Feng Yichao",
      "Fengjun Pan",
      "Anh Tuan Luu"
    ]
  },
  "https://openreview.net/forum?id=RJT1baPhdV": {
    "title": "Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models",
    "volume": "survey",
    "abstract": "Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each category, representative methods are elaborated to describe the landscape of relevant research. In addition, comparison between the latest methods is conducted on their officially reported results to provide in-depth discussions on their limitations. Finally, we summarize the open challenges and propose the promosing avenues for future studies. All related contents are available at https://github.com/yuleiqin/fantastic-data-engineering",
    "checked": true,
    "id": "51f0c3b06861c79fbb283022df109818ce4ebe51",
    "semantic_title": "unleashing the power of data tsunami: a comprehensive survey on data assessment and selection for instruction tuning of language models",
    "citation_count": 13,
    "authors": [
      "Yulei Qin",
      "Yuncheng Yang",
      "Pengcheng Guo",
      "Gang Li",
      "Hang Shao",
      "Yuchen Shi",
      "Zihan Xu",
      "Yun Gu",
      "Ke Li",
      "Xing Sun"
    ]
  },
  "https://openreview.net/forum?id=ON7dtdEHVQ": {
    "title": "(Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models",
    "volume": "expert",
    "abstract": "Epistemic uncertainty is crucial for safety-critical applications and data acquisition tasks. Yet, we find an important phenomenon in deep learning models: an epistemic uncertainty collapse as model complexity increases, challenging the assumption that larger models invariably offer better uncertainty quantification. We introduce implicit ensembling as a possible explanation for this phenomenon. To investigate this hypothesis, we provide theoretical analysis and experiments that demonstrate uncertainty collapse in explicit ensembles of ensembles and show experimental evidence of similar collapse in wider models across various architectures, from simple MLPs to state-of-the-art vision models including ResNets and Vision Transformers. We further develop implicit ensemble extraction techniques to decompose larger models into diverse sub-models, showing we can thus recover epistemic uncertainty. We explore the implications of these findings for uncertainty estimation",
    "checked": true,
    "id": "1907135de3cddae03e7839ab5559513c84f63d90",
    "semantic_title": "(implicit) ensembles of ensembles: epistemic uncertainty collapse in large models",
    "citation_count": 4,
    "authors": [
      "Andreas Kirsch"
    ]
  },
  "https://openreview.net/forum?id=7A96yteeF9": {
    "title": "Latent mixed-effect models for high-dimensional longitudinal data",
    "volume": "expert",
    "abstract": "Modelling longitudinal data is an important yet challenging task. These datasets can be high-dimensional, contain non-linear effects and feature time-varying covariates. Gaussian process (GP) prior-based variational autoencoders (VAEs) have emerged as a promising approach due to their ability to model time-series data. However, they are costly to train and struggle to fully exploit the rich covariates characteristic of longitudinal data, making them difficult for practitioners to use effectively. In this work, we leverage linear mixed models (LMMs) and amortized variational inference to provide conditional priors for VAEs, and propose LMM-VAE, a scalable, interpretable and identifiable model. We highlight theoretical connections between it and GP-based techniques, providing a unified framework for this class of methods. Our proposal performs competitively compared to existing approaches across simulated and real-world datasets",
    "checked": true,
    "id": "3034539de0a8b5aa6850ad9bbdd37c52d06c5eb8",
    "semantic_title": "latent mixed-effect models for high-dimensional longitudinal data",
    "citation_count": 0,
    "authors": [
      "Priscilla Ong",
      "Manuel Haussmann",
      "Otto Lönnroth",
      "Harri Lähdesmäki"
    ]
  },
  "https://openreview.net/forum?id=9L0B5N5hUX": {
    "title": "Investigating Generalization Behaviours of Generative Flow Networks",
    "volume": "expert",
    "abstract": "Generative Flow Networks (GFlowNets, GFNs) are a generative framework for learning unnormalized probability mass functions over discrete spaces. Since their inception, GFlowNets have proven to be useful for learning generative models in applications where the majority of the discrete space is unvisited during training. This has inspired some to hypothesize that GFlowNets, when paired with deep neural networks (DNNs), have favorable generalization properties. In this work, we empirically verify some of the hypothesized mechanisms of generalization of GFlowNets. We accomplish this by introducing a novel graph-based benchmark environment where reward difficulty can be easily varied, $p(x)$ can be computed exactly, and an unseen test set can be constructed to quantify generalization performance. Using this graph-based environment, we are able to systematically test the hypothesized mechanisms of generalization of GFlowNets and put forth a set of empirical observations that summarize our findings. In particular, we find (and confirm) that the functions that GFlowNets learn to approximate have an implicit underlying structure which facilitate generalization. Surprisingly ---and somewhat contradictory to existing knowledge--- we also find that GFlowNets are sensitive to being trained offline and off-policy. However, the reward implicitly learned by GFlowNets is robust to changes in the training distribution",
    "checked": true,
    "id": "8cb0ddbba810bf09f0a763762dfb08ed2270679c",
    "semantic_title": "investigating generalization behaviours of generative flow networks",
    "citation_count": 4,
    "authors": [
      "Lazar Atanackovic",
      "Emmanuel Bengio"
    ]
  },
  "https://openreview.net/forum?id=xdWP1d8BxI": {
    "title": "Sparse Decomposition of Graph Neural Networks",
    "volume": "expert",
    "abstract": "Graph Neural Networks (GNN) exhibit superior performance in graph representation learning, but their inference cost can be high, due to an aggregation operation that can require a memory fetch for a very large number of nodes. This inference cost is the major obstacle to deploying GNN models with \\emph{online prediction} to reflect the potentially dynamic node features. To address this, we propose an approach to reduce the number of nodes that are included during aggregation. We achieve this through a sparse decomposition, learning to approximate node representations using a weighted sum of linearly transformed features of a carefully selected subset of nodes within the extended neighbourhood. The approach achieves linear complexity with respect to the average node degree and the number of layers in the graph neural network. We introduce an algorithm to compute the optimal parameters for the sparse decomposition, ensuring an accurate approximation of the original GNN model, and present effective strategies to reduce the training time and improve the learning process. We demonstrate via extensive experiments that our method outperforms other baselines designed for inference speedup, achieving significant accuracy gains with comparable inference times for both node classification and spatio-temporal forecasting tasks",
    "checked": true,
    "id": "2ceb5b6cf86709afbf544a886d493283540b138b",
    "semantic_title": "sparse decomposition of graph neural networks",
    "citation_count": 0,
    "authors": [
      "Yaochen Hu",
      "Mai Zeng",
      "Ge Zhang",
      "Pavel Rumiantsev",
      "Liheng Ma",
      "Yingxue Zhang",
      "Mark Coates"
    ]
  },
  "https://openreview.net/forum?id=5298fKGmv3": {
    "title": "The BrowserGym Ecosystem for Web Agent Research",
    "volume": "expert",
    "abstract": "The BrowserGym ecosystem addresses the growing need for efficient evaluation and benchmarking of web agents, particularly those leveraging automation and Large Language Models (LLMs) for web interaction tasks. Many existing benchmarks suffer from fragmentation and inconsistent evaluation methodologies, making it challenging to achieve reliable comparisons and reproducible results. In an earlier work, Drouin et al. (2024) introduced BrowserGym which aims to solve this by providing a unified, gym-like environment with well-defined observation and actionspaces, facilitating standardized evaluation across diverse benchmarks. We propose an extended BrowserGym-based ecosystem for web agent research, which unifies existing benchmarks from the literature and includes AgentLab, a complementary framework that aids in agent creation, testing, and analysis. Our proposed ecosystem offers flexibility for integrating new benchmarks while ensuring consistent evaluation and comprehensive experiment management. This standardized approach seeks to reduce the time and complexity of developing web agents, supporting more reliable comparisons and facilitating in-depth analysis of agent behaviors, and could result in more adaptable, capable agents, ultimately accelerating innovation in LLM-driven automation. As a supporting evidence, we conduct the first large-scale, multi-benchmark web agent experiment and compare the performance of 6 state-of-the-art LLMs across 6 popular web agent benchmarks made available in BrowserGym. Among other findings, our results highlight a large discrepancy between OpenAI and Anthropic's latests models, with Claude-3.5-Sonnet leading the way on almost all benchmarks, except on vision-related tasks where GPT-4o is superior. Despite these advancements, our results emphasize that building robust and efficient web agents remains a significant challenge, due to the inherent complexity of real-world web environments and the limitations of current models",
    "checked": true,
    "id": "cdee27ca18f11adae733aa9baf1b1377b864cfa1",
    "semantic_title": "the browsergym ecosystem for web agent research",
    "citation_count": 18,
    "authors": [
      "Thibault Le Sellier de Chezelles",
      "Maxime Gasse",
      "Alexandre Lacoste",
      "Massimo Caccia",
      "Alexandre Drouin",
      "Léo Boisvert",
      "Megh Thakkar",
      "Tom Marty",
      "Rim Assouel",
      "Sahar Omidi Shayegan",
      "Lawrence Keunho Jang",
      "Xing Han Lù",
      "Ori Yoran",
      "Dehan Kong",
      "Frank F. Xu",
      "Siva Reddy",
      "Graham Neubig",
      "Quentin Cappart",
      "Russ Salakhutdinov",
      "Nicolas Chapados"
    ]
  },
  "https://openreview.net/forum?id=SbGt90dxdp": {
    "title": "Variation Matters: from Mitigating to Embracing Zero-Shot NAS Ranking Function Variation",
    "volume": "expert",
    "abstract": "Neural Architecture Search (NAS) is a powerful automatic alternative to manual design of a neural network. In the zero-shot version, a fast ranking function is used to compare architectures without training them. The outputs of the ranking functions often vary significantly due to different sources of randomness, including the evaluated architecture's weights' initialization or the batch of data used for calculations. A common approach to addressing the variation is to average a ranking function output over several evaluations. We propose taking into account the variation in a different manner, by viewing the ranking function output as a random variable representing a proxy performance metric. During the search process, we strive to construct a stochastic ordering of the performance metrics to determine the best architecture. Our experiments show that the proposed stochastic ordering can effectively boost performance of a search on standard benchmark search spaces",
    "checked": true,
    "id": "0d3b9fcfb997456bab0ccc8a3c4a98eddafc554f",
    "semantic_title": "variation matters: from mitigating to embracing zero-shot nas ranking function variation",
    "citation_count": 0,
    "authors": [
      "Pavel Rumiantsev",
      "Mark Coates"
    ]
  },
  "https://openreview.net/forum?id=FcyHZ6Q4k0": {
    "title": "Necessary and Sufficient Watermark for Large Language Models",
    "volume": "expert",
    "abstract": "Large language models (LLMs) can now generate texts that are indistinguishable from those written by humans. Such remarkable performance of LLMs increases their risk of being used for malicious purposes. Thus, it is necessary to develop methods for distinguishing texts written by LLMs from those written by humans. Watermarking is one of the most powerful methods for achieving this. Although existing methods have successfully detected texts generated by LLMs, they inevitably degrade the text quality. In this study, we propose the Necessary and Sufficient Watermark (NS-Watermark) for inserting watermarks into generated texts with minimum text quality degradation. More specifically, we derive minimum constraints required to be imposed on the generated texts to distinguish whether LLMs or humans write the texts, and we formulate the NS-Watermark as a constrained optimization problem. Through the experiments, we demonstrate that the NS-Watermark can generate more natural texts than existing watermarking methods and distinguish more accurately between texts written by LLMs and those written by humans. Especially in machine translation tasks, the NS-Watermark can outperform the existing watermarking method by up to 30 BLEU scores",
    "checked": true,
    "id": "9c78484d28cfaa71894c28c75aabe83d24d67705",
    "semantic_title": "necessary and sufficient watermark for large language models",
    "citation_count": 8,
    "authors": [
      "Yuki Takezawa",
      "Ryoma Sato",
      "Han Bao",
      "Kenta Niwa",
      "Makoto Yamada"
    ]
  },
  "https://openreview.net/forum?id=jrUUk5Fskm": {
    "title": "Personalized Negative Reservoir for Incremental Learning in Recommender Systems",
    "volume": "expert",
    "abstract": "Recommender systems have become an integral part of online platforms. Every day the volume of training data is expanding and the number of user interactions is constantly increasing. The exploration of larger and more expressive models has become a necessary pursuit to improve user experience. However, this progression carries with it an increased computational burden. In commercial settings, once a recommendation system model has been trained and deployed it typically needs to be updated frequently as new client data arrive. Cumulatively, the mounting volume of data is guaranteed to eventually make full batch retraining of the model from scratch computationally infeasible. Naively fine-tuning solely on the new data runs into the well-documented problem of catastrophic forgetting. Despite the fact that negative sampling is a crucial part of training with implicit feedback, no specialized technique exists that is tailored to the incremental learning framework. In this work, we propose a personalized negative reservoir strategy, which is used to obtain negative samples for the standard triplet loss of graph-based recommendation systems. Our technique balances alleviation of forgetting with plasticity by encouraging the model to remember stable user preferences and selectively forget when user interests change. We derive the mathematical formulation of a negative sampler to populate and update the reservoir. We integrate our design in three SOTA and commonly used incremental recommendation models. We show that these concrete realizations of our negative reservoir framework achieve state-of-the-art results for standard benchmarks using multiple top-k evaluation metrics",
    "checked": true,
    "id": "8c659df0ec487a5e4f42d1f46ea93227a47e5fce",
    "semantic_title": "personalized negative reservoir for incremental learning in recommender systems",
    "citation_count": 1,
    "authors": [
      "Antonios Valkanas",
      "Yuening Wang",
      "Yingxue Zhang",
      "Mark Coates"
    ]
  },
  "https://openreview.net/forum?id=hGaWq5Buj7": {
    "title": "The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers",
    "volume": "expert",
    "abstract": "Evaluation of large language models for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), or more recently using human preferences of LLM responses. As LLMs are increasingly used as programmer assistants, we study whether gains on existing benchmarks or more preferred LLM responses translate to programmer productivity when coding with LLMs, including time spent coding. We introduce RealHumanEval, a web interface to measure the ability of LLMs to assist programmers, through either autocomplete or chat support. We conducted a user study (N=243) using RealHumanEval in which users interacted with seven LLMs of varying base model performance. Despite static benchmarks not incorporating humans-in-the-loop, we find that improvements in benchmark performance lead to increased programmer productivity; however gaps in benchmark versus human performance are not proportional---a trend that holds across both forms of LLM support. In contrast, we find that programmer preferences do not correlate with their actual performance, motivating the need for better proxy signals. We open-source RealHumanEval to enable human-centric evaluation of new models and the study data to facilitate efforts to improve code models",
    "checked": true,
    "id": "abd61863fc793d5fa0334b80dea2130ad543de70",
    "semantic_title": "the realhumaneval: evaluating large language models' abilities to support programmers",
    "citation_count": 22,
    "authors": [
      "Hussein Mozannar",
      "Valerie Chen",
      "Mohammed Alsobay",
      "Subhro Das",
      "Sebastian Zhao",
      "Dennis Wei",
      "Manish Nagireddy",
      "Prasanna Sattigeri",
      "Ameet Talwalkar",
      "David Sontag"
    ]
  }
}