{
  "https://proceedings.mlr.press/v206/zhao23a.html": {
    "title": "Blessing of Class Diversity in Pre-training",
    "abstract": "This paper presents a new statistical analysis aiming to explain the recent superior achievements of the pre-training techniques in natural language processing (NLP). We prove that when the classes of the pre-training task (e.g., different words in the masked language model task) are sufficiently diverse, in the sense that the least singular value of the last linear layer in pre-training (denoted as $\\tilde{\\nu}$) is large, then pre-training can significantly improve the sample efficiency of downstream tasks. Specially, we show the transfer learning excess risk enjoys an $O\\left(\\frac{1}{\\tilde{\\nu} \\sqrt{n}}\\right)$ rate, in contrast to the $O\\left(\\frac{1}{\\sqrt{m}}\\right)$ rate in the standard supervised learning. Here, $n$ is the number of pre-training data and $m$ is the number of data in the downstream task, and typically $n \\gg m$. Our proof relies on a vector-form Rademacher complexity chain rule for disassembling composite function classes and a modified self-concordance condition. These techniques can be of independent interest",
    "volume": "main",
    "checked": true,
    "id": "70ce7b8e8e12f17131572322c20e487c55bfa379",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/hagele23a.html": {
    "title": "BaCaDI: Bayesian Causal Discovery with Unknown Interventions",
    "abstract": "Inferring causal structures from experimentation is a central task in many domains. For example, in biology, recent advances allow us to obtain single-cell expression data under multiple interventions such as drugs or gene knockouts. However, the targets of the interventions are often uncertain or unknown and the number of observations limited. As a result, standard causal discovery methods can no longer be reliably used. To fill this gap, we propose a Bayesian framework (BaCaDI) for discovering and reasoning about the causal structure that underlies data generated under various unknown experimental or interventional conditions. BaCaDI is fully differentiable, which allows us to infer the complex joint posterior over the intervention targets and the causal structure via efficient gradient-based variational inference. In experiments on synthetic causal discovery tasks and simulated gene-expression data, BaCaDI outperforms related methods in identifying causal structures and intervention targets",
    "volume": "main",
    "checked": true,
    "id": "6c3e3488fd96083ca8c1c791b8dbce543fbcecdd",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/maus23a.html": {
    "title": "Discovering Many Diverse Solutions with Bayesian Optimization",
    "abstract": "Bayesian optimization (BO) is a popular approach for sample-efficient optimization of black-box objective functions. While BO has been successfully applied to a wide range of scientific applications, traditional approaches to single-objective BO only seek to find a single best solution. This can be a significant limitation in situations where solutions may later turn out to be intractable, for example, a designed molecule may turn out to later violate constraints that can only be evaluated after the optimization process has concluded. To address this issue, we propose rank-ordered Bayesian Optimization with trustregions (ROBOT) which aims to find a portfolio of high-performing solutions that are diverse according to a user-specified diversity measure. We evaluate ROBOT on several real-world applications and show that it can discover large sets of high-performing diverse solutions while requiring few additional function evaluations compared to finding a single best solution",
    "volume": "main",
    "checked": true,
    "id": "55facf524cc803a23a764225ec0ee89e36b26808",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/li23a.html": {
    "title": "Multilevel Bayesian Quadrature",
    "abstract": "Multilevel Monte Carlo is a key tool for approximating integrals involving expensive scientific models. The idea is to use approximations of the integrand to construct an estimator with improved accuracy over classical Monte Carlo. We propose to further enhance multilevel Monte Carlo through Bayesian surrogate models of the integrand, focusing on Gaussian process models and the associated Bayesian quadrature estimators. We show, using both theory and numerical experiments, that our approach can lead to significant improvements in accuracy when the integrand is expensive and smooth, and when the dimensionality is small or moderate. We conclude the paper with a case study illustrating the potential impact of our method in landslide-generated tsunami modelling, where the cost of each integrand evaluation is typically too large for operational settings",
    "volume": "main",
    "checked": true,
    "id": "1c15dbc76a41c412a771442cdfd7513a761188dc",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/presman23a.html": {
    "title": "Distance-to-Set Priors and Constrained Bayesian Inference",
    "abstract": "Constrained learning is prevalent in many statistical tasks. Recent work proposes distance-to-set penalties to derive estimators under general constraints that can be specified as sets, but focuses on obtaining point estimates that do not come with corresponding measures of uncertainty. To remedy this, we approach distance-to-set regularization from a Bayesian lens. We consider a class of smooth distance-to-set priors, showing that they yield well-defined posteriors toward quantifying uncertainty for constrained learning problems. We discuss relationships and advantages over prior work on Bayesian constraint relaxation. Moreover, we prove that our approach is optimal in an information geometric-sense for finite penalty parameters $\\rho$, and enjoys favorable statistical properties when $\\rho \\rightarrow \\infty$. The method is designed to perform effectively within gradient based MCMC samplers, as illustrated on a suite of simulated and real data applications",
    "volume": "main",
    "checked": true,
    "id": "ef20d09ee15d195a257d563e70050abd6bc7f123",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/yao23a.html": {
    "title": "Error Estimation for Random Fourier Features",
    "abstract": "Random Fourier Features (RFF) is among the most popular and broadly applicable approaches for scaling up kernel methods. In essence, RFF allows the user to avoid costly computations with a large kernel matrix via a fast randomized approximation. However, a pervasive difficulty in applying RFF is that the user does not know the actual error of the approximation, or how this error will propagate into downstream learning tasks. Up to now, the RFF literature has primarily dealt with these uncertainties using theoretical error bounds, but from a user’s standpoint, such results are typically impractical—either because they are highly conservative or involve unknown quantities. To tackle these general issues in a data-driven way, this paper develops a bootstrap approach to numerically estimate the errors of RFF approximations. Three key advantages of this approach are: (1) The error estimates are specific to the problem at hand, avoiding the pessimism of worst-case bounds. (2) The approach is flexible with respect to different uses of RFF, and can even estimate errors in downstream learning tasks. (3) The approach enables adaptive computation, in the sense that the user can quickly inspect the error of a rough initial kernel approximation and then predict how much extra work is needed. Furthermore, in exchange for all of these benefits, the error estimates can be obtained at a modest computational cost",
    "volume": "main",
    "checked": true,
    "id": "7b12cf3834392bfcf346b7019f52dcae476f2c9d",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/ma23a.html": {
    "title": "Noisy Low-rank Matrix Optimization: Geometry of Local Minima and Convergence Rate",
    "abstract": "This paper is concerned with low-rank matrix optimization, which has found a wide range of applications in machine learning. This problem in the special case of matrix sensing has been studied extensively through the notion of Restricted Isometry Property (RIP), leading to a wealth of results on the geometric landscape of the problem and the convergence rate of common algorithms. However, the existing results can handle the problem in the case with a general objective function subject to noisy data only when the RIP constant is close to 0. In this paper, we develop a new mathematical framework to solve the above-mentioned problem with a far less restrictive RIP constant. We prove that as long as the RIP constant of the noiseless objective is less than 1/3, any spurious local solution of the noisy optimization problem must be close to the ground truth solution. By working through the strict saddle property, we also show that an approximate solution can be found in polynomial time. We characterize the geometry of the spurious local minima of the problem in a local region around the ground truth in the case when the RIP constant is greater than 1/3. Compared to the existing results in the literature, this paper offers the strongest RIP bound, and provides a complete theoretical analysis on the global and local optimization landscapes of general low-rank optimization problems under random corruptions from any finite-variance family",
    "volume": "main",
    "checked": true,
    "id": "984d12f73203c209da64fb17b6838c517c912e63",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v206/redberg23a.html": {
    "title": "Generalized PTR: User-Friendly Recipes for Data-Adaptive Algorithms with Differential Privacy",
    "abstract": "The “Propose-Test-Release” (PTR) framework [Dwork and Lei, 2009] is a classic recipe for designing differentially private (DP) algorithms that are data-adaptive, i.e. those that add less noise when the input dataset is “nice”. We extend PTR to a more general setting by privately testing data-dependent privacy losses rather than local sensitivity, hence making it applicable beyond the standard noise-adding mechanisms, e.g. to queries with unbounded or undefined sensitivity. We demonstrate the versatility of generalized PTR using private linear regression as a case study. Additionally, we apply our algorithm to solve an open problem from “Private Aggregation of Teacher Ensembles (PATE)” [Papernot et al., 2017, 2018] - privately releasing the entire model with a delicate data-dependent analysis",
    "volume": "main",
    "checked": true,
    "id": "ad67c99e5a4a0c9336406d64e3332e3677238bd9",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/metelli23a.html": {
    "title": "A Tale of Sampling and Estimation in Discounted Reinforcement Learning",
    "abstract": "The most relevant problems in discounted reinforcement learning involve estimating the mean of a function under the stationary distribution of a Markov reward process, such as the expected return in policy evaluation, or the policy gradient in policy optimization. In practice, these estimates are produced through a finite-horizon episodic sampling, which neglects the mixing properties of the Markov process. It is mostly unclear how this mismatch between the practical and the ideal setting affects the estimation, and the literature lacks a formal study on the pitfalls of episodic sampling, and how to do it optimally. In this paper, we present a minimax lower bound on the discounted mean estimation problem that explicitly connects the estimation error with the mixing properties of the Markov process and the discount factor. Then, we provide a statistical analysis on a set of notable estimators and the corresponding sampling procedures, which includes the finite-horizon estimators often used in practice. Crucially, we show that estimating the mean by directly sampling from the discounted kernel of the Markov process brings compelling statistical properties w.r.t. the alternative estimators, as it matches the lower bound without requiring a careful tuning of the episode horizon",
    "volume": "main",
    "checked": true,
    "id": "1e1c9d41d8738f39c3add21c76ab500dc16caf9b",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/marchetti23a.html": {
    "title": "An Efficient and Continuous Voronoi Density Estimator",
    "abstract": "We introduce a non-parametric density estimator deemed Radial Voronoi Density Estimator (RVDE). RVDE is grounded in the geometry of Voronoi tessellations and as such benefits from local geometric adaptiveness and broad convergence properties. Due to its radial definition RVDE is continuous and computable in linear time with respect to the dataset size. This amends for the main shortcomings of previously studied VDEs, which are highly discontinuous and computationally expensive. We provide a theoretical study of the modes of RVDE as well as an empirical investigation of its performance on high-dimensional data. Results show that RVDE outperforms other non-parametric density estimators, including recently introduced VDEs",
    "volume": "main",
    "checked": true,
    "id": "6e667ea3a5b15cf32f29ef9ec04cf806dd9a9a98",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/turner23a.html": {
    "title": "Safe Sequential Testing and Effect Estimation in Stratified Count Data",
    "abstract": "Sequential decision making significantly speeds up research and is more cost-effective compared to fixed-n methods. We present a method for sequential decision making for stratified count data that retains Type-I error guarantee or false discovery rate under optional stopping, using e-variables. We invert the method to construct stratified anytime-valid confidence sequences, where cross-talk between subpopulations in the data can be allowed during data collection to improve power. Finally, we combine information collected in separate subpopulations through pseudo-Bayesian averaging and switching to create effective estimates for the minimal, mean and maximal treatment effects in the subpopulations",
    "volume": "main",
    "checked": true,
    "id": "8ec3ca03656accc2825e9163a6937aadc903b077",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/kuntz23a.html": {
    "title": "Particle algorithms for maximum likelihood training of latent variable models",
    "abstract": "Neal and Hinton (1998) recast maximum likelihood estimation of any given latent variable model as the minimization of a free energy functional F, and the EM algorithm as coordinate descent applied to F. Here, we explore alternative ways to optimize the functional. In particular, we identify various gradient flows associated with F and show that their limits coincide with F’s stationary points. By discretizing the flows, we obtain practical particle-based algorithms for maximum likelihood estimation in broad classes of latent variable models. The novel algorithms scale to high-dimensional settings and perform well in numerical experiments",
    "volume": "main",
    "checked": true,
    "id": "c6bb2c03f14faeadfdab7821619488c62ce6f263",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/moss23a.html": {
    "title": "Inducing Point Allocation for Sparse Gaussian Processes in High-Throughput Bayesian Optimisation",
    "abstract": "Sparse Gaussian processes are a key component of high-throughput Bayesian optimisation (BO) loops; however, we show that existing methods for allocating their inducing points severely hamper optimisation performance. By exploiting the quality-diversity decomposition of determinantal point processes, we propose the first inducing point allocation strategy designed specifically for use in BO. Unlike existing methods which seek only to reduce global uncertainty in the objective function, our approach provides the local high-fidelity modelling of promising regions required for precise optimisation. More generally, we demonstrate that our proposed framework provides a flexible way to allocate modelling capacity in sparse models and so is suitable for a broad range of downstream sequential decision making tasks",
    "volume": "main",
    "checked": true,
    "id": "d00d77661a9b11bdae4994219ec64c9a89c66a32",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v206/sansford23a.html": {
    "title": "Implications of sparsity and high triangle density for graph representation learning",
    "abstract": "Recent work has shown that sparse graphs containing many triangles cannot be reproduced using a finite-dimensional representation of the nodes, in which link probabilities are inner products. Here, we show that such graphs can be reproduced using an infinite-dimensional inner product model, where the node representations lie on a low-dimensional manifold. Recovering a global representation of the manifold is impossible in a sparse regime. However, we can zoom in on local neighbourhoods, where a lower-dimensional representation is possible. As our constructions allow the points to be uniformly distributed on the manifold, we find evidence against the common perception that triangles imply community structure",
    "volume": "main",
    "checked": true,
    "id": "0d630f78313f36c9dca1f9c573842d2ce902c2b2",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/bunne23a.html": {
    "title": "The Schrödinger Bridge between Gaussian Measures has a Closed Form",
    "abstract": "The static optimal transport $(\\mathrm{OT})$ problem between Gaussians seeks to recover an optimal map, or more generally a coupling, to morph a Gaussian into another. It has been well studied and applied to a wide variety of tasks. Here we focus on the dynamic formulation of OT, also known as the Schrödinger bridge (SB) problem, which has recently seen a surge of interest in machine learning due to its connections with diffusion-based generative models. In contrast to the static setting, much less is known about the dynamic setting, even for Gaussian distributions. In this paper, we provide closed-form expressions for SBs between Gaussian measures. In contrast to the static Gaussian OT problem, which can be simply reduced to studying convex programs, our framework for solving SBs requires significantly more involved tools such as Riemannian geometry and generator theory. Notably, we establish that the solutions of SBs between Gaussian measures are themselves Gaussian processes with explicit mean and covariance kernels, and thus are readily amenable for many downstream applications such as generative modeling or interpolation. To demonstrate the utility, we devise a new method for modeling the evolution of single-cell genomics data and report significantly improved numerical stability compared to existing SB-based approaches",
    "volume": "main",
    "checked": false,
    "id": "76406effefded8853e48bca46b05f2f49a78fdb0",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v206/jothimurugesan23a.html": {
    "title": "Federated Learning under Distributed Concept Drift",
    "abstract": "Federated Learning (FL) under distributed concept drift is a largely unexplored area. Although concept drift is itself a well-studied phenomenon, it poses particular challenges for FL, because drifts arise staggered in time and space (across clients). Our work is the first to explicitly study data heterogeneity in both dimensions. We first demonstrate that prior solutions to drift adaptation, with their single global model, are ill-suited to staggered drifts, necessitating multiple-model solutions. We identify the problem of drift adaptation as a time-varying clustering problem, and we propose two new clustering algorithms for reacting to drifts based on local drift detection and hierarchical clustering. Empirical evaluation shows that our solutions achieve significantly higher accuracy than existing baselines, and are comparable to an idealized algorithm with oracle knowledge of the ground-truth clustering of clients to concepts at each time step",
    "volume": "main",
    "checked": true,
    "id": "baefa660f5c9111764216c7b22d00236b88e3ac2",
    "citation_count": 7
  },
  "https://proceedings.mlr.press/v206/wang23e.html": {
    "title": "Data Banzhaf: A Robust Data Valuation Framework for Machine Learning",
    "abstract": "Data valuation has wide use cases in machine learning, including improving data quality and creating economic incentives for data sharing. This paper studies the robustness of data valuation to noisy model performance scores. Particularly, we find that the inherent randomness of the widely used stochastic gradient descent can cause existing data value notions (e.g., the Shapley value and the Leave-one-out error) to produce inconsistent data value rankings across different runs. To address this challenge, we introduce the concept of safety margin, which measures the robustness of a data value notion. We show that the Banzhaf value, a famous value notion that originated from cooperative game theory literature, achieves the largest safety margin among all semivalues (a class of value notions that satisfy crucial properties entailed by ML applications and include the famous Shapley value and Leave-one-out error). We propose an algorithm to efficiently estimate the Banzhaf value based on the Maximum Sample Reuse (MSR) principle. Our evaluation demonstrates that the Banzhaf value outperforms the existing semivalue-based data value notions on several ML tasks such as learning with weighted samples and noisy label detection. Overall, our study suggests that when the underlying ML algorithm is stochastic, the Banzhaf value is a promising alternative to the other semivalue-based data value schemes given its computational advantage and ability to robustly differentiate data quality",
    "volume": "main",
    "checked": true,
    "id": "6fa3f84affb5af66ec3fe94e618e0124493bb28e",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/xi23a.html": {
    "title": "Indeterminacy in Generative Models: Characterization and Strong Identifiability",
    "abstract": "Most modern probabilistic generative models, such as the variational autoencoder (VAE), have certain indeterminacies that are unresolvable even with an infinite amount of data. Different tasks tolerate different indeterminacies, however recent applications have indicated the need for strongly identifiable models, in which an observation corresponds to a unique latent code. Progress has been made towards reducing model indeterminacies while maintaining flexibility, and recent work excludes many—but not all—indeterminacies. In this work, we motivate model-identifiability in terms of task-identifiability, then construct a theoretical framework for analyzing the indeterminacies of latent variable models, which enables their precise characterization in terms of the generator function and prior distribution spaces. We reveal that strong identifiability is possible even with highly flexible nonlinear generators, and give two such examples. One is a straightforward modification of iVAE (Khemakhem et al., 2020); the other uses triangular monotonic maps, leading to novel connections between optimal transport and identifiability",
    "volume": "main",
    "checked": true,
    "id": "7321b03e135a950a4380d0f5dae0073c61742715",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/sharma23a.html": {
    "title": "Do Bayesian Neural Networks Need To Be Fully Stochastic?",
    "abstract": "We investigate the benefit of treating all the parameters in a Bayesian neural network stochastically and find compelling theoretical and empirical evidence that this standard construction may be unnecessary. To this end, we prove that expressive predictive distributions require only small amounts of stochasticity. In particular, partially stochastic networks with only n stochastic biases are universal probabilistic predictors for n-dimensional predictive problems. In empirical investigations, we find no systematic benefit of full stochasticity across four different inference modalities and eight datasets; partially stochastic networks can match and sometimes even outperform fully stochastic networks, despite their reduced memory costs",
    "volume": "main",
    "checked": true,
    "id": "b059d640377740dbd65daa866412f03916765c70",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v206/ting-li23a.html": {
    "title": "Mode-Seeking Divergences: Theory and Applications to GANs",
    "abstract": "Generative adversarial networks (GANs) represent a game between two neural network machines designed to learn the distribution of data. It is commonly observed that different GAN formulations and divergence/distance measures used could lead to considerably different performance results, especially when the data distribution is multi-modal. In this work, we give a theoretical characterization of the mode-seeking behavior of general f-divergences and Wasserstein distances, and prove a performance guarantee for the setting where the underlying model is a mixture of multiple symmetric quasiconcave distributions. This can help us understand the trade-off between the quality and diversity of the trained GANs’ output samples. Our theoretical results show the mode-seeking nature of the Jensen-Shannon (JS) divergence over standard KL-divergence and Wasserstein distance measures. We subsequently demonstrate that a hybrid of JS-divergence and Wasserstein distance measures minimized by Lipschitz GANs mimics the mode-seeking behavior of the JS-divergence. We present numerical results showing the mode-seeking nature of the JS-divergence and its hybrid with the Wasserstein distance while highlighting the mode-covering properties of KL-divergence and Wasserstein distance measures. Our numerical experiments indicate the different behavior of several standard GAN formulations in application to benchmark Gaussian mixture and image datasets",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/huang23c.html": {
    "title": "Fix-A-Step: Semi-supervised Learning From Uncurated Unlabeled Data",
    "abstract": "Semi-supervised learning (SSL) promises improved accuracy compared to training classifiers on small labeled datasets by also training on many unlabeled images. In real applications like medical imaging, unlabeled data will be collected for expediency and thus uncurated: possibly different from the labeled set in classes or features. Unfortunately, modern deep SSL often makes accuracy worse when given uncurated unlabeled data. Recent complex remedies try to detect out-of-distribution unlabeled images and then discard or downweight them. Instead, we introduce Fix-A-Step, a simpler procedure that views all uncurated unlabeled images as potentially helpful. Our first insight is that even uncurated images can yield useful augmentations of labeled data. Second, we modify gradient descent updates to prevent optimizing a multi-task SSL loss from hurting labeled-set accuracy. Fix-A-Step can “repair” many common deep SSL methods, improving accuracy on CIFAR benchmarks across all tested methods and levels of artificial class mismatch. On a new medical SSL benchmark called Heart2Heart, Fix-A-Step can learn from 353,500 truly uncurated ultrasound images to deliver gains that generalize across hospitals",
    "volume": "main",
    "checked": true,
    "id": "bdc59d8b0762dcb67b1a04e04e871b0a987f3d50",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/thornton23a.html": {
    "title": "Rethinking Initialization of the Sinkhorn Algorithm",
    "abstract": "While the optimal transport (OT) problem was originally formulated as a linear program, the addition of entropic regularization has proven beneficial both computationally and statistically, for many applications. The Sinkhorn fixed-point algorithm is the most popular approach to solve this regularized problem, and, as a result, multiple attempts have been made to reduce its runtime using, e.g., annealing in the regularization parameter, momentum or acceleration. The premise of this work is that initialization of the Sinkhorn algorithm has received comparatively little attention, possibly due to two preconceptions: since the regularized OT problem is convex, it may not be worth crafting a good initialization, since any is guaranteed to work; secondly, because the outputs of the Sinkhorn algorithm are often unrolled in end-to-end pipelines, a data-dependent initialization would bias Jacobian computations. We challenge this conventional wisdom, and show that data-dependent initializers result in dramatic speed-ups, with no effect on differentiability as long as implicit differentiation is used. Our initializations rely on closed-forms for exact or approximate OT solutions that are known in the 1D, Gaussian or GMM settings. They can be used with minimal tuning, and result in consistent speed-ups for a wide variety of OT problems",
    "volume": "main",
    "checked": true,
    "id": "77a6a4e09d8a19d76767c302ed09d60839a64518",
    "citation_count": 5
  },
  "https://proceedings.mlr.press/v206/jethani23a.html": {
    "title": "Don't be fooled: label leakage in explanation methods and the importance of their quantitative evaluation",
    "abstract": "Feature attribution methods identify which features of an input most influence a model’s output. Most widely-used feature attribution methods (such as SHAP, LIME, and Grad-CAM) are “class-dependent” methods in that they generate a feature attribution vector as a function of class. In this work, we demonstrate that class-dependent methods can “leak” information about the selected class, making that class appear more likely than it is. Thus, an end user runs the risk of drawing false conclusions when interpreting an explanation generated by a class-dependent method. In contrast, we introduce “distribution-aware” methods, which favor explanations that keep the label’s distribution close to its distribution given all features of the input. We introduce SHAP-KL and FastSHAP-KL, two baseline distribution-aware methods that compute Shapley values. Finally, we perform a comprehensive evaluation of seven class-dependent and three distribution-aware methods on three clinical datasets of different high-dimensional data types: images, biosignals, and text",
    "volume": "main",
    "checked": true,
    "id": "2a77195fa6ba9ab041f4dd5f1e18a9bba582904f",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/dohmatob23a.html": {
    "title": "Origins of Low-Dimensional Adversarial Perturbations",
    "abstract": "Machine learning models are known to be susceptible to adversarial perturbations. Even more concerning is the fact that these adversarial perturbations can be found by black-box search using surprisingly few queries, which essentially restricts the perturbation to a subspace of dimension $k$—much smaller than the dimension $d$ of the image space. This intriguing phenomenon raises the question: Is the vulnerability to black-box attacks inherent or can we hope to prevent them? In this paper, we initiate a rigorous study of the phenomenon of low-dimensional adversarial perturbations (LDAPs). Our result characterizes precisely the sufficient conditions for the existence of LDAPs, and we show that these conditions hold for neural networks under practical settings, including the so-called lazy regime wherein the parameters of the trained network remain close to their values at initialization. Our theoretical results are confirmed by experiments on both synthetic and real data",
    "volume": "main",
    "checked": true,
    "id": "10a31b65fe2e2b82ff79e1242d653dfc0c0ebbf8",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/crawford23a.html": {
    "title": "Scalable Bicriteria Algorithms for Non-Monotone Submodular Cover",
    "abstract": "In this paper, we consider the optimization problem Submodular Cover (SC), which is to find a minimum cost subset of a ground set $U$ such that the value of a submodular function $f$ is above a threshold $\\tau$. In contrast to most existing work on SC, it is not assumed that $f$ is monotone. Two bicriteria approximation algorithms are presented for SC that, for input parameter $0 < \\epsilon < 1$, give $O( 1 / \\epsilon^2 )$ ratio to the optimal cost and ensures the function $f$ is at least $\\tau(1 - \\epsilon)/2$. A lower bound shows that under the value query model shows that no polynomial-time algorithm can ensure that $f$ is larger than $\\tau/2$. Further, the algorithms presented are scalable to large data sets, processing the ground set in a stream. Similar algorithms developed for SC also work for the related optimization problem of Submodular Maximization (KCSM). Finally, the algorithms are demonstrated to be effective in experiments involving graph cut and data summarization functions",
    "volume": "main",
    "checked": true,
    "id": "2c0b816d1c210163c4cf3f697635a25baeb195c4",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/wang23p.html": {
    "title": "Huber-robust confidence sequences",
    "abstract": "Confidence sequences are confidence intervals that can be sequentially tracked, and are valid at arbitrary data-dependent stopping times. This paper presents confidence sequences for a univariate mean of an unknown distribution with a known upper bound on the p-th central moment (p $>$ 1), but allowing for (at most) $\\varepsilon$ fraction of arbitrary distribution corruption, as in Huber’s contamination model. We do this by designing new robust exponential supermartingales, and show that the resulting confidence sequences attain the optimal width achieved in the nonsequential setting. Perhaps surprisingly, the constant margin between our sequential result and the lower bound is smaller than even fixed-time robust confidence intervals based on the trimmed mean, for example. Since confidence sequences are a common tool used within A/B/n testing and bandits, these results open the door to sequential experimentation that is robust to outliers and adversarial corruptions",
    "volume": "main",
    "checked": true,
    "id": "70c642ee4ad20ee2a26989da8f8eec2f567217c9",
    "citation_count": 5
  },
  "https://proceedings.mlr.press/v206/iyengar23a.html": {
    "title": "Hedging against Complexity: Distributionally Robust Optimization with Parametric Approximation",
    "abstract": "Empirical risk minimization (ERM) and distributionally robust optimization (DRO) are popular approaches for solving stochastic optimization problems that appear in operations management and machine learning. Existing generalization error bounds for these methods depend on either the complexity of the cost function or dimension of the uncertain parameters; consequently, the performance of these methods is poor for high-dimensional problems with objective functions under high complexity. We propose a simple approach in which the distribution of uncertain parameters is approximated using a parametric family of distributions. This mitigates both sources of complexity; however, it introduces a model misspecification error. We show that this new source of error can be controlled by suitable DRO formulations. Our proposed parametric DRO approach has significantly improved generalization bounds over existing ERM / DRO methods and parametric ERM for a wide variety of settings. Our method is particularly effective under distribution shifts. We also illustrate the superior performance of our approach on both synthetic and real-data portfolio optimization and regression tasks",
    "volume": "main",
    "checked": true,
    "id": "4a3667b5ce0a0da1eccb09275fb5250973233b84",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/mozannar23a.html": {
    "title": "Who Should Predict? Exact Algorithms For Learning to Defer to Humans",
    "abstract": "Automated AI classifiers should be able to defer the prediction to a human decision maker to ensure more accurate predictions. In this work, we jointly train a classifier with a rejector, which decides on each data point whether the classifier or the human should predict. We show that prior approaches can fail to find a human-AI system with low mis-classification error even when there exists a linear classifier and rejector that have zero error (the realizable setting). We prove that obtaining a linear pair with low error is NP-hard even when the problem is realizable. To complement this negative result, we give a mixed-integer-linear-programming (MILP) formulation that can optimally solve the problem in the linear setting. However, the MILP only scales to moderately-sized problems. Therefore, we provide a novel surrogate loss function that is realizable-consistent and performs well empirically. We test our approaches on a comprehensive set of datasets and compare to a wide range of baselines",
    "volume": "main",
    "checked": true,
    "id": "cf33602ef6d80dd8013cfcad0ee573706f001481",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/xia23b.html": {
    "title": "Implicit Graphon Neural Representation",
    "abstract": "Graphons are general and powerful models for generating graphs of varying size. In this paper, we propose to directly model graphons using neural networks, obtaining Implicit Graphon Neural Representation (IGNR). Existing work in modeling and reconstructing graphons often approximates a target graphon by a fixed resolution piece-wise constant representation. Our IGNR has the benefit that it can represent graphons up to arbitrary resolutions, and enables natural and efficient generation of arbitrary sized graphs with desired structure once the model is learned. Furthermore, we allow the input graph data to be unaligned and have different sizes by leveraging the Gromov-Wasserstein distance. We first demonstrate the effectiveness of our model by showing its superior performance on a graphon learning task. We then propose an extension of IGNR that can be incorporated into an auto-encoder framework, and demonstrate its good performance under a more general setting of graphon learning. We also show that our model is suitable for graph representation learning and graph generation",
    "volume": "main",
    "checked": true,
    "id": "bee4e4bd4234915f0a9904186196a7f73deda4fd",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/angus-chan23a.html": {
    "title": "Fitting low-rank models on egocentrically sampled partial networks",
    "abstract": "The statistical modeling of random networks has been widely used to uncover interaction mechanisms in complex systems and to predict unobserved links in real-world networks. In many applications, network connections are collected via egocentric sampling: a subset of nodes is sampled first, after which all links involving this subset are recorded; all other information is missing. Compared with the assumption of “uniformly missing at random”, egocentrically sampled partial networks require specially designed modeling strategies. Current statistical methods are either computationally infeasible or based on intuitive designs without theoretical justification. Here, we propose an approach to fit general low-rank models for egocentrically sampled networks, which include several popular network models. This method is based on graph spectral properties and is computationally efficient for large-scale networks. It results in consistent recovery of missing subnetworks due to egocentric sampling for sparse networks. To our knowledge, this method offers the first theoretical guarantee for egocentric partial network estimation in the scope of low-rank models. We evaluate the technique on several synthetic and real-world networks and show that it delivers competitive performance in link prediction tasks",
    "volume": "main",
    "checked": true,
    "id": "5f0474d04d654f6cd654c1a5e61ad5fdbdb88f8e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/tahmasebi23a.html": {
    "title": "The Power of Recursion in Graph Neural Networks for Counting Substructures",
    "abstract": "To achieve a graph representation, most Graph Neural Networks (GNNs) follow two steps: first, each graph is decomposed into a number of subgraphs (which we call the recursion step), and then the collection of subgraphs is encoded by several iterative pooling steps. While recently proposed higher-order networks show a remarkable increase in the expressive power through a single recursion on larger neighborhoods followed by iterative pooling, the power of deeper recursion in GNNs without any iterative pooling is still not fully understood. To make it concrete, we consider a pure recursion-based GNN which we call Recursive Neighborhood Pooling GNN (RNP-GNN). The expressive power of an RNP-GNN and its computational cost quantifies the power of (pure) recursion for a graph representation network. We quantify the power by means of counting substructures, which is one main limitation of the Message Passing graph Neural Networks (MPNNs), and show how RNP-GNN can exploit the sparsity of the underlying graph to achieve low-cost powerful representations. We also compare the recent lower bounds on the time complexity and show how recursion-based networks are near optimal",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/wongso23a.html": {
    "title": "Using Sliced Mutual Information to Study Memorization and Generalization in Deep Neural Networks",
    "abstract": "In this paper, we study the memorization and generalization behaviour of deep neural networks (DNNs) using sliced mutual information (SMI), which is the average of the mutual information (MI) between one-dimensional random projections. We argue that the SMI between features in a DNN ($T$) and ground truth labels ($Y$), $SI(T;Y)$, can be seen as a form of usable information that the features contain about the labels. We show theoretically that $SI(T;Y)$ can encode geometric properties of the feature distribution, such as its spherical soft-margin and intrinsic dimensionality, in a way that MI cannot. Additionally, we present empirical evidence showing how $SI(T;Y)$ can capture memorization and generalization in DNNs. In particular, we find that, in the presence of label noise, all layers start to memorize but the earlier layers stabilize more quickly than the deeper layers. Finally, we point out that, in the context of Bayesian Neural Networks, the SMI between the penultimate layer and the output represents the worst case uncertainty of the network’s output",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/sakaue23a.html": {
    "title": "Improved Generalization Bound and Learning of Sparsity Patterns for Data-Driven Low-Rank Approximation",
    "abstract": "Learning sketching matrices for fast and accurate low-rank approximation (LRA) has gained increasing attention. Recently, Bartlett, Indyk, and Wagner (COLT 2022) presented a generalization bound for the learning-based LRA. Specifically, for rank-$k$ approximation using an $m \\times n$ learned sketching matrix with $s$ non-zeros in each column, they proved an $\\tilde O(nsm)$ bound on the fat shattering dimension ($\\tilde O$ hides logarithmic factors). We build on their work and make two contributions. (1) We present a better $\\tilde O(nsk)$ bound ($k \\le m$). En route to obtaining this result, we give a low-complexity Goldberg–Jerrum algorithm for computing pseudo-inverse matrices, which would be of independent interest. (2) We alleviate an assumption of the previous study that sketching matrices have a fixed sparsity pattern. We prove that learning positions of non-zeros increases the fat shattering dimension only by $O(ns\\log n)$. In addition, experiments confirm the practical benefit of learning sparsity patterns",
    "volume": "main",
    "checked": true,
    "id": "87c5325b54a83c94a1bb5ed50407ef78782dacb4",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/schmitt23a.html": {
    "title": "Meta-Uncertainty in Bayesian Model Comparison",
    "abstract": "Bayesian model comparison (BMC) offers a principled probabilistic approach to study and rank competing models. In standard BMC, we construct a discrete probability distribution over the set of possible models, conditional on the observed data of interest. These posterior model probabilities (PMPs) are measures of uncertainty, but—when derived from a finite number of observations—are also uncertain themselves. In this paper, we conceptualize distinct levels of uncertainty which arise in BMC. We explore a fully probabilistic framework for quantifying meta-uncertainty, resulting in an applied method to enhance any BMC workflow. Drawing on both Bayesian and frequentist techniques, we represent the uncertainty over the uncertain PMPs via meta-models which combine simulated and observed data into a predictive distribution for PMPs on new data. We demonstrate the utility of the proposed method in the context of conjugate Bayesian regression, likelihood-based inference with Markov chain Monte Carlo, and simulation-based inference with neural networks",
    "volume": "main",
    "checked": true,
    "id": "8a30505df153a10f9e1d61e1081fc5915c1b6500",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/shen23a.html": {
    "title": "PAC Learning of Halfspaces with Malicious Noise in Nearly Linear Time",
    "abstract": "We study the problem of efficient PAC learning of halfspaces in $\\mathbb{R}^d$ in the presence of the malicious noise, where a fraction of the training samples are adversarially corrupted. A series of recent works have developed polynomial-time algorithms that enjoy near-optimal sample complexity and noise tolerance, yet leaving open whether a linear-time algorithm exists and matches these appealing statistical performance guarantees. In this work, we give an affirmative answer by developing an algorithm that runs in time $\\tilde{O}(m d )$, where $m = \\tilde{O}(\\frac{d}{\\epsilon})$ is the sample size and $\\epsilon \\in (0, 1)$ is the target error rate. Notably, the computational complexity of all prior algorithms suffer either a high order dependence on the problem size, or is implicitly proportional to $\\frac{1}{\\epsilon^2}$ through the sample size. Our key idea is to combine localization and an approximate version of matrix multiplicative weights update method to progressively downweight the contribution of the corrupted samples while refining the learned halfspace",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/lin-hau23a.html": {
    "title": "Entropic Risk Optimization in Discounted MDPs",
    "abstract": "Risk-averse Markov Decision Processes (MDPs) have optimal policies that achieve high returns with low variability, but these MDPs are often difficult to solve. Only a few practical risk-averse objectives admit a dynamic programming (DP) formulation, which is the mainstay of most MDP and RL algorithms. We derive a new DP formulation for discounted risk-averse MDPs with Entropic Risk Measure (ERM) and Entropic Value at Risk (EVaR) objectives. Our DP formulation for ERM, which is possible because of our novel definition of value function with time-dependent risk levels, can approximate optimal policies in a time that is polynomial in the approximation error. We then use the ERM algorithm to optimize the EVaR objective in polynomial time using an optimized discretization scheme. Our numerical results show the viability of our formulations and algorithms in discounted MDPs",
    "volume": "main",
    "checked": false,
    "id": "7b313679816e3ce1c7153f27c8ab60e1b4b993b0",
    "citation_count": 21
  },
  "https://proceedings.mlr.press/v206/wirth23a.html": {
    "title": "Acceleration of Frank-Wolfe Algorithms with Open-Loop Step-Sizes",
    "abstract": "Frank-Wolfe algorithms (FW) are popular first-order methods for solving constrained convex optimization problems that rely on a linear minimization oracle instead of potentially expensive projection-like oracles. Many works have identified accelerated convergence rates under various structural assumptions on the optimization problem and for specific FW variants when using line-search or short-step, requiring feedback from the objective function. Little is known about accelerated convergence regimes when utilizing open-loop step-size rules, a.k.a. FW with pre-determined step-sizes, which are algorithmically extremely simple and stable. Not only is FW with open-loop step-size rules not always subject to the same convergence rate lower bounds as FW with line-search or short-step, but in some specific cases, such as kernel herding in infinite dimensions, it has been empirically observed that FW with open-loop step-size rules leads to faster convergence than FW with line-search or short-step. We propose a partial answer to this unexplained phenomenon in kernel herding, characterize a general setting for which FW with open-loop step-size rules converges non-asymptotically faster than with line-search or short-step, and derive several accelerated convergence results for FW with open-loop step-size rules",
    "volume": "main",
    "checked": true,
    "id": "249b52bf2927df72a929134d3bf4c4ab8244d9bc",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/qin23a.html": {
    "title": "An Online and Unified Algorithm for Projection Matrix Vector Multiplication with Application to Empirical Risk Minimization",
    "abstract": "Online matrix vector multiplication is a fundamental step and bottleneck in many machine learning algorithms. It is defined as follows: given a matrix at the pre-processing phase, at each iteration one receives a query vector and needs to form the matrix-vector product (approximately) before observing the next vector. In this work, we study a particular instance of such problem called the online projection matrix vector multiplication. Via a reduction, we show it suffices to solve the inverse maintenance problem. Additionally, our framework supports dimensionality reduction to speed up the computation that approximates the matrix-vector product with an optimization-friendly error guarantee. Moreover, our unified approach can handle both data-oblivious sketching and data-dependent sampling. Finally, we demonstrate the effectiveness of our framework by speeding up the empirical risk minimization solver",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/zhang23a.html": {
    "title": "Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision",
    "abstract": "Programmatic Weak Supervision (PWS) has emerged as a widespread paradigm to synthesize training labels efficiently. The core component of PWS is the label model, which infers true labels by aggregating the outputs of multiple noisy supervision sources abstracted as labeling functions (LFs). Existing statistical label models typically rely only on the outputs of LF, ignoring the instance features when modeling the underlying generative process. In this paper, we attempt to incorporate the instance features into a statistical label model via the proposed FABLE. In particular, it is built on a mixture of Bayesian label models, each corresponding to a global pattern of correlation, and the coefficients of the mixture components are predicted by a Gaussian Process classifier based on instance features. We adopt an auxiliary variable-based variational inference algorithm to tackle the non-conjugate issue between the Gaussian Process and Bayesian label models. Extensive empirical comparison on eleven benchmark datasets sees FABLE achieving the highest averaged performance across nine baselines. Our implementation of FABLE can be found in https://github.com/JieyuZ2/wrench/blob/main/wrench/labelmodel/fable.py",
    "volume": "main",
    "checked": true,
    "id": "57ebeaf2e471e7ea5d14851db4cf63a337e8138d",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/beznosikov23a.html": {
    "title": "Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient Methods",
    "abstract": "Stochastic Gradient Descent-Ascent (SGDA) is one of the most prominent algorithms for solving min-max optimization and variational inequalities problems (VIP) appearing in various machine learning tasks. The success of the method led to several advanced extensions of the classical SGDA, including variants with arbitrary sampling, variance reduction, coordinate randomization, and distributed variants with compression, which were extensively studied in the literature, especially during the last few years. In this paper, we propose a unified convergence analysis that covers a large variety of stochastic gradient descent-ascent methods, which so far have required different intuitions, have different applications and have been developed separately in various communities. A key to our unified framework is a parametric assumption on the stochastic estimates. Via our general theoretical framework, we either recover the sharpest known rates for the known special cases or tighten them. Moreover, to illustrate the flexibility of our approach we develop several new variants of SGDA such as a new variance-reduced method (L-SVRGDA), new distributed methods with compression (QSGDA, DIANA-SGDA, VR-DIANA-SGDA), and a new method with coordinate randomization (SEGA-SGDA). Although variants of the new methods are known for solving minimization problems, they were never considered or analyzed for solving min-max problems and VIPs. We also demonstrate the most important properties of the new methods through extensive numerical experiments",
    "volume": "main",
    "checked": true,
    "id": "9d5289ba92e95b51431f93964329f9a046a9d266",
    "citation_count": 19
  },
  "https://proceedings.mlr.press/v206/panos23a.html": {
    "title": "Scalable marked point processes for exchangeable and non-exchangeable event sequences",
    "abstract": "We adopt the interpretability offered by a parametric, Hawkes-process-inspired conditional probability mass function for the marks and apply variational inference techniques to derive a general and scalable inferential framework for marked point processes. The framework can handle both exchangeable and non-exchangeable event sequences with minimal tuning and without any pre-training. This contrasts with many parametric and non-parametric state-of-the-art methods that typically require pre-training and/or careful tuning, and can only handle exchangeable event sequences. The framework’s competitive computational and predictive performance against other state-of-the-art methods are illustrated through real data experiments. Its attractiveness for large-scale applications is demonstrated through a case study involving all events occurring in an English Premier League season",
    "volume": "main",
    "checked": true,
    "id": "2549854bcac49cab2a1f6405cf40d67e88930d7e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/jankowiak23a.html": {
    "title": "Bayesian Variable Selection in a Million Dimensions",
    "abstract": "Bayesian variable selection is a powerful tool for data analysis, as it offers a principled method for variable selection that accounts for prior information and uncertainty. However, wider adoption of Bayesian variable selection has been hampered by computational challenges, especially in difficult regimes with a large number of covariates P or non-conjugate likelihoods. To scale to the large P regime we introduce an efficient Markov Chain Monte Carlo scheme whose cost per iteration is sublinear in P (though linear in the number of data points). In addition we show how this scheme can be extended to generalized linear models for count data, which are prevalent in biology, ecology, economics, and beyond. In particular we design efficient algorithms for variable selection in binomial and negative binomial regression, which includes logistic regression as a special case. In experiments we demonstrate the effectiveness of our methods, including on cancer and maize genomic data",
    "volume": "main",
    "checked": true,
    "id": "13d1397f39d19e7056f8dea85320f02ee6bdf622",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/khan23a.html": {
    "title": "Barlow Graph Auto-Encoder for Unsupervised Network Embedding",
    "abstract": "Network embedding has emerged as a promising research field for network analysis. Recently, an approach, named Barlow Twins, has been proposed for self-supervised learning in computer vision by applying the redundancy-reduction principle to the embedding vectors corresponding to two distorted versions of the image samples. Motivated by this, we propose Barlow Graph Auto-Encoder, a simple yet effective architecture for learning network embedding. It aims to maximize the similarity between the embedding vectors of immediate and larger neighborhoods of a node while minimizing the redundancy between the components of these projections. In addition, we also present the variational counterpart named Barlow Variational Graph Auto-Encoder. We demonstrate the effectiveness of our approach in learning multiple graph-related tasks, i.e., link prediction, clustering, and downstream node classification, by providing extensive comparisons with several well-known techniques on eight benchmark datasets",
    "volume": "main",
    "checked": true,
    "id": "8afcdc6053f5d5c51408829fb790f836b549f778",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/tit23a.html": {
    "title": "Gradient-Informed Neural Network Statistical Robustness Estimation",
    "abstract": "Deep neural networks are robust against random corruptions of the inputs to some extent. This global sense of safety is not sufficient in critical applications where probabilities of failure must be assessed with accuracy. Some previous works applied known statistical methods from the field of rare event analysis to classification. Yet, they use classifiers as black-box models without taking into account gradient information, readily available for deep learning models via auto-differentiation. We propose a new and highly efficient estimator of probabilities of failure dedicated to neural networks as it leverages the fast computation of gradients of the model through back-propagation",
    "volume": "main",
    "checked": false,
    "id": "4c662283cff51cb0b6c2baf51cde7a9e30a19d06",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/nika23a.html": {
    "title": "Online Defense Strategies for Reinforcement Learning Against Adaptive Reward Poisoning",
    "abstract": "We consider the problem of defense against reward-poisoning attacks in reinforcement learning and formulate it as a game in $T$ rounds between a defender and an adaptive attacker in an adversarial environment. To address this problem, we design two novel defense algorithms. First, we propose Exp3-DARP, a defense algorithm that uses Exp3 as a hyperparameter learning subroutine, and show that it achieves order-optimal $\\tilde{\\Theta}(T^{1/2})$ bounds on our notion of regret with respect to a defense that always picks the optimal parameter in hindsight. We show that the order of $T$ in the bounds cannot be improved when the reward arrival process is adversarial, even if the feedback model of the defense is stronger. However, assuming that the environment is stochastic, we propose OMDUCB-DARP that uses estimates of costs as proxies to update the randomized strategy of the learner and are able to substantially improve the bounds proportional to how smoothly the attacker’s strategy changes. Furthermore, we show that weaker types of defense, that do not take into account the attack structure and the poisoned rewards, suffer linear regret with respect to a defender that always selects the optimal parameter in hindsight when faced with an adaptive attacker that uses a no-regret algorithm to learn the behavior of the defense. Finally, we support our theoretical results with experimental evaluations on three different environments, showcasing the efficiency of our methods",
    "volume": "main",
    "checked": false,
    "id": "650387bc1ad4ac0a2730303b366749bd3021c779",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/cabannnes23a.html": {
    "title": "A Case of Exponential Convergence Rates for SVM",
    "abstract": "Optimizing the misclassification risk is in general NP-hard. Tractable solvers can be obtained by considering a surrogate regression problem. While convergence to the regression function is typically sublinear, the corresponding classification error can decay much faster. Fast and super fast rates (up to exponential) have been established for general smooth losses on problems where a hard margin is present between classes. This leaves out models based on non-smooth losses such as support vector machines, and problems where there is no hard margin, begging several questions. Are such models incapable of fast convergence? Are they therefore structurally inferior? Is the hard margin condition really necessary to obtain exponential convergence? Developing a new strategy, we provide an answer to these questions. In particular, we show not only that support vector machines can indeed converge exponentially fast, but also that they can do so even without hard margin",
    "volume": "main",
    "checked": true,
    "id": "3abe7af72acc06e37ec50aadf323f9f5d167f54a",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/xu23a.html": {
    "title": "Finding Regularized Competitive Equilibria of Heterogeneous Agent Macroeconomic Models via Reinforcement Learning",
    "abstract": "We study a heterogeneous agent macroeconomic model with an infinite number of households and firms competing in a labor market. Each household earns income and engages in consumption at each time step while aiming to maximize a concave utility subject to the underlying market conditions. The households aim to find the optimal saving strategy that maximizes their discounted cumulative utility given the market condition, while the firms determine the market conditions through maximizing corporate profit based on the household population behavior. The model captures a wide range of applications in macroeconomic studies, and we propose a data-driven reinforcement learning framework that finds the regularized competitive equilibrium of the model. The proposed algorithm enjoys theoretical guarantees in converging to the equilibrium of the market at a sub-linear rate",
    "volume": "main",
    "checked": false,
    "id": "f4fa19bfbb20a6d8823f5461a0de19ad9140bfa6",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v206/bartels23a.html": {
    "title": "Adaptive Cholesky Gaussian Processes",
    "abstract": "We present a method to approximate Gaussian process regression models to large datasets by considering only a subset of the data. Our approach is novel in that the size of the subset is selected on the fly during exact inference with little computational overhead. From an empirical observation that the log-marginal likelihood often exhibits a linear trend once a sufficient subset of a dataset has been observed, we conclude that many large datasets contain redundant information that only slightly affects the posterior. Based on this, we provide probabilistic bounds on the full model evidence that can identify such subsets. Remarkably, these bounds are largely composed of terms that appear in intermediate steps of the standard Cholesky decomposition, allowing us to modify the algorithm to adaptively stop the decomposition once enough data have been observed",
    "volume": "main",
    "checked": true,
    "id": "5d2db467b948d012ead791886c5280f0de4b1889",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/yeh23a.html": {
    "title": "Sample Complexity of Kernel-Based Q-Learning",
    "abstract": "Modern reinforcement learning (RL) often faces an enormous state-action space. Existing analytical results are typically for settings with a small number of state-actions, or simple models such as linearly modeled Q functions. To derive statistically efficient RL policies handling large state-action spaces, with more general Q functions, some recent works have considered nonlinear function approximation using kernel ridge regression. In this work, we derive sample complexities for kernel based Q-learning when a generative model exists. We propose a non-parametric Q-learning algorithm which finds an $\\varepsilon$-optimal policy in an arbitrarily large scale discounted MDP. The sample complexity of the proposed algorithm is order optimal with respect to $\\varepsilon$ and the complexity of the kernel (in terms of its information gain). To the best of our knowledge, this is the first result showing a finite sample complexity under such a general model",
    "volume": "main",
    "checked": true,
    "id": "aa736b18624de46058b67574edd779a0eff885ed",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/hendrikx23a.html": {
    "title": "A principled framework for the design and analysis of token algorithms",
    "abstract": "We consider a decentralized optimization problem, in which n nodes collaborate to optimize a global objective function using local communications only. While many decentralized algorithms focus on gossip communications (pairwise averaging), we consider a different scheme, in which a “token” that contains the current estimate of the model performs a random walk over the network, and updates its model using the local model of the node it is at. Indeed, token algorithms generally benefit from improved communication efficiency and privacy guarantees. We frame the token algorithm as a randomized gossip algorithm on a conceptual graph, which allows us to prove a series of convergence results for variance-reduced and accelerated token algorithms for the complete graph. We also extend these results to the case of multiple tokens by extending the conceptual graph, and to general graphs by tweaking the communication procedure. The reduction from token to well-studied gossip algorithms leads to tight rates for many token algorithms, and we illustrate their performance empirically",
    "volume": "main",
    "checked": true,
    "id": "9ec9e84b9bdb312a897c11a1ef187d84664820c3",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v206/heidari23a.html": {
    "title": "Learning k-qubit Quantum Operators via Pauli Decomposition",
    "abstract": "Motivated by the limited qubit capacity of current quantum systems, we study the quantum sample complexity of k-qubit quantum operators, i.e., operations applicable on only k out of d qubits. The problem is studied according to the quantum probably approximately correct (QPAC) model abiding by quantum mechanical laws such as no-cloning, state collapse, and measurement incompatibility. With the delicacy of quantum samples and the richness of quantum operations, one expects a significantly larger quantum sample complexity. This paper proves the contrary. We show that the quantum sample complexity of k-qubit quantum operations is comparable to the classical sample complexity of their counterparts (juntas), at least when $\\frac{k}{d}\\ll 1$. This is surprising, especially since sample duplication is prohibited, and measurement incompatibility would lead to an exponentially larger sample complexity with standard methods. Our approach is based on the Pauli decomposition of quantum operators and a technique called Quantum Shadow Sampling (QSS) to reduce the sample complexity exponentially. The results are proved by developing (i) a connection between the learning loss and the Pauli decomposition; (ii) a scalable QSS circuit for estimating the Pauli coefficients; and (iii) a quantum algorithm for learning $k$-qubit operators with sample complexity $O(\\frac{k4^k}{\\epsilon^2}\\log d)$",
    "volume": "main",
    "checked": true,
    "id": "9820fe07b2c0945f97ea588083cb1a51c631933d",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/zeng23a.html": {
    "title": "Semi-Verified PAC Learning from the Crowd",
    "abstract": "We study the problem of crowdsourced PAC learning of threshold functions. This is a challenging problem and only recently have query-efficient algorithms been established under the assumption that a noticeable fraction of the workers are perfect. In this work, we investigate a more challenging case where the majority may behave adversarially and the rest behave as the Massart noise – a significant generalization of the perfectness assumption. We show that under the semi-verified model of Charikar et al. (2017), where we have (limited) access to a trusted oracle who always returns correct annotations, it is possible to PAC learn the underlying hypothesis class with a manageable amount of label queries. Moreover, we show that the labeling cost can be drastically mitigated via the more easily obtained comparison queries. Orthogonal to recent developments in semi-verified or list-decodable learning that crucially rely on data distributional assumptions, our PAC guarantee holds by exploring the wisdom of the crowd",
    "volume": "main",
    "checked": true,
    "id": "2039800d7e971b067e33409e31d798902d31ba97",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/sharoni23a.html": {
    "title": "On the Capacity Limits of Privileged ERM",
    "abstract": "We study the supervised learning paradigm called Learning Using Privileged Information, first suggested by Vapnik and Vashist (2009). In this paradigm, in addition to the examples and labels, additional (privileged) information is provided only for training examples. The goal is to use this information to improve the classification accuracy of the resulting classifier, where this classifier can only use the non-privileged information of new example instances to predict their label. We study the theory of privileged learning with the zero-one loss under the natural Privileged ERM algorithm proposed in Peshyony and Vapnik (2010). We provide a counter example to a claim made in that work regarding the VC dimension of the loss class induced by this problem; We conclude that the claim is incorrect. We then provide a correct VC dimension analysis which gives both lower and upper bounds on the capacity of the Privileged ERM loss class. We further show, via a generalization analysis, that worst-case guarantees for Privileged ERM cannot improve over standard non-privileged ERM, unless the capacity of the privileged information is similar or smaller to that of the non-privileged information. This result points to an important limitation of the Privileged ERM approach. In our closing discussion, we suggest another way in which Privileged ERM might still be helpful, even when the capacity of the privileged information is large",
    "volume": "main",
    "checked": true,
    "id": "dfe523f49fedc2a7c2ca5e35d9b23e195e892e9e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/lee23a.html": {
    "title": "USIM Gate: UpSampling Module for Segmenting Precise Boundaries concerning Entropy",
    "abstract": "Deep learning (DL) techniques for precise semantic segmentation have remained a challenge because of the vague boundaries of target objects caused by the low resolution of images. Despite the improved segmentation performance using up/downsampling operations in early DL models, conventional operators cannot fully preserve spatial information and thus generate vague boundaries of target objects. Therefore, for the precise segmentation of target objects in many domains, this paper presents two novel operators: (1) upsampling interpolation method (USIM), an operator that upsamples input feature maps and combines feature maps into one while preserving the spatial information of both inputs, and (2) USIM gate (UG), an advanced USIM operator with boundary-attention mechanisms. We designed our experiments using aerial images where the boundaries critically influence the results. Furthermore, we verified the feasibility that our approach effectively segments target objects using the cityscapes dataset. The experimental results demonstrate that using the USIM and UG with state-of-the-art DL models can improve the segmentation performance with clear boundaries of target objects (Intersection over Union: +6.9$%$; BJ: +10.1$%$). Furthermore, mathematical proofs verify that the USIM and UG contribute to the handling of spatial information",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/yang23a.html": {
    "title": "Bayesian Structure Scores for Probabilistic Circuits",
    "abstract": "Probabilistic circuits (PCs) are a prominent representation of probability distributions with tractable inference. While parameter learning in PCs is rigorously studied, structure learning is often more based on heuristics than on principled objectives. In this paper, we develop Bayesian structure scores for deterministic PCs, i.e., the structure likelihood with parameters marginalized out, which are well known as rigorous objectives for structure learning in probabilistic graphical models. When used within a greedy cutset algorithm, our scores effectively protect against overfitting and yield a fast and almost hyper-parameter-free structure learner, distinguishing it from previous approaches. In experiments, we achieve good trade-offs between training time and model fit in terms of log-likelihood. Moreover, the principled nature of Bayesian scores unlocks PCs for accommodating frameworks such as structural expectation-maximization",
    "volume": "main",
    "checked": true,
    "id": "9a0151114fe5ecfbcce03fc17f8e2304955ac72d",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/geffner23a.html": {
    "title": "Langevin Diffusion Variational Inference",
    "abstract": "Many methods that build powerful variational distributions based on unadjusted Langevin transitions exist. Most of these were developed using a wide range of different approaches and techniques. Unfortunately, the lack of a unified analysis and derivation makes developing new methods and reasoning about existing ones a challenging task. We address this giving a single analysis that unifies and generalizes these existing techniques. The main idea is to augment the target and variational by numerically simulating the underdamped Langevin diffusion process and its time reversal. The benefits of this approach are twofold: it provides a unified formulation for many existing methods, and it simplifies the development of new ones. In fact, using our formulation we propose a new method that combines the strengths of previously existing algorithms; it uses underdamped Langevin transitions and powerful augmentations parameterized by a score network. Our empirical evaluation shows that our proposed method consistently outperforms relevant baselines in a wide range of tasks",
    "volume": "main",
    "checked": true,
    "id": "8d10253815e7f307e71fb108f983a1e22d7d1c9d",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/azizi23a.html": {
    "title": "Overcoming Prior Misspecification in Online Learning to Rank",
    "abstract": "The recent literature on online learning to rank (LTR) has established the utility of prior knowledge to Bayesian ranking bandit algorithms. However, a major limitation of existing work is the requirement for the prior used by the algorithm to match the true prior. In this paper, we propose and analyze adaptive algorithms that address this issue and additionally extend these results to the linear and generalized linear models. We also consider scalar relevance feedback on top of click feedback. Moreover, we demonstrate the efficacy of our algorithms using both synthetic and real-world experiments",
    "volume": "main",
    "checked": true,
    "id": "25a6d38ee4770f96e3c5b12f04a28723ef0f03c4",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/qian23a.html": {
    "title": "Catalyst Acceleration of Error Compensated Methods Leads to Better Communication Complexity",
    "abstract": "Communication overhead is well known to be a key bottleneck in large scale distributed learning, and a particularly successful class of methods which help to overcome this bottleneck is based on the idea of communication compression. Some of the most practically effective gradient compressors, such as TopK, are biased, which causes convergence issues unless one employs a well designed error compensation/feedback mechanism. Error compensation is therefore a fundamental technique in the distributed learning literature. In a recent development, Qian et al (NeurIPS 2021) showed that the error-compensation mechanism can be combined with acceleration/momentum, which is another key and highly successful optimization technique. In particular, they developed the error-compensated loop-less Katyusha (ECLK) method, and proved an accelerated linear rate in the strongly convex case. However, the dependence of their rate on the compressor parameter does not match the best dependence obtainable in the non-accelerated error-compensated methods. Our work addresses this problem. We propose several new accelerated error-compensated methods using the catalyst acceleration technique, and obtain results that match the best dependence on the compressor parameter in non-accelerated error-compensated methods up to logarithmic terms",
    "volume": "main",
    "checked": true,
    "id": "deeb54328711874955452a2059700525081a9104",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/ishikawa23a.html": {
    "title": "Kernel Conditional Moment Constraints for Confounding Robust Inference",
    "abstract": "We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value. It can be shown that our estimator contains the recently proposed sharp estimator by Dorn and Guo (2022) as a special case, and our method enables a novel extension of the classical marginal sensitivity model using f-divergence. To construct our estimator, we leverage the kernel method to obtain a tractable approximation to the conditional moment constraints, which traditional non-sharp estimators failed to take into account. In the theoretical analysis, we provide a condition for the choice of the kernel which guarantees no specification error that biases the lower bound estimation. Furthermore, we provide consistency guarantees of policy evaluation and learning. In the experiments with synthetic and real-world data, we demonstrate the effectiveness of the proposed method",
    "volume": "main",
    "checked": true,
    "id": "75fa3edd5274db1837be71a20a4af6afde3b6c25",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/kumagai23a.html": {
    "title": "Meta-learning for Robust Anomaly Detection",
    "abstract": "We propose a meta-learning method to improve the anomaly detection performance on unseen target tasks that have only unlabeled data. Existing meta-learning methods for anomaly detection have shown remarkable performance but require labeled data in target tasks. Although they can treat unlabeled data as normal assuming anomalies in the unlabeled data are negligible, this assumption is often violated in practice. As a result, the methods have low performance. Our method meta-learns with related tasks that have labeled and unlabeled data such that the expected test anomaly detection performance is directly improved when the anomaly detector is adapted to given unlabeled data. Our method is based on autoencoders (AEs), which are widely used neural network-based anomaly detectors. We model anomalous attributes for each unlabeled instance in the reconstruction loss of the AE, which are used to prevent the anomalies from being reconstructed; they can remove the effect of the anomalies. We formulate adaptation to the unlabeled data as a learning problem of the last layer of the AE and the anomalous attributes. This formulation enables the optimum solution to be obtained with a closed-form alternate update formula, which is preferable to efficiently maximize the expected test anomaly detection performance. The effectiveness of our method is experimentally shown with four real-world datasets",
    "volume": "main",
    "checked": false,
    "id": "ee653d99232b45054ef148f513a38dfe0b646477",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v206/hashimoto23a.html": {
    "title": "Learning in RKHM: a C*-Algebraic Twist for Kernel Machines",
    "abstract": "Supervised learning in reproducing kernel Hilbert space (RKHS) and vector-valued RKHS (vvRKHS) has been investigated for more than 30 years. In this paper, we provide a new twist to this rich literature by generalizing supervised learning in RKHS and vvRKHS to reproducing kernel Hilbert C*-module (RKHM), and show how to construct effective positive-definite kernels by considering the perspective of C*-algebra. Unlike the cases of RKHS and vvRKHS, we can use C*-algebras to enlarge representation spaces. This enables us to construct RKHMs whose representation power goes beyond RKHSs, vvRKHSs, and existing methods such as convolutional neural networks. Our framework is suitable, for example, for effectively analyzing image data by allowing the interaction of Fourier components",
    "volume": "main",
    "checked": true,
    "id": "c73066320d865fc530eac172372186eef4b1c926",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/bordt23a.html": {
    "title": "From Shapley Values to Generalized Additive Models and back",
    "abstract": "In explainable machine learning, local post-hoc explanation algorithms and inherently interpretable models are often seen as competing approaches. This work offers a partial reconciliation between the two by establishing a correspondence between Shapley Values and Generalized Additive Models (GAMs). We introduce $n$-Shapley Values, a parametric family of local post-hoc explanation algorithms that explain individual predictions with interaction terms up to order $n$. By varying the parameter $n$, we obtain a sequence of explanations that covers the entire range from Shapley Values up to a uniquely determined decomposition of the function we want to explain. The relationship between $n$-Shapley Values and this decomposition offers a functionally-grounded characterization of Shapley Values, which highlights their limitations. We then show that $n$-Shapley Values, as well as the Shapley Taylor- and Faith-Shap interaction indices, recover GAMs with interaction terms up to order $n$. This implies that the original Shapely Values recover GAMs without variable interactions. Taken together, our results provide a precise characterization of Shapley Values as they are being used in explainable machine learning. They also offer a principled interpretation of partial dependence plots of Shapley Values in terms of the underlying functional decomposition. A package for the estimation of different interaction indices is available at https://github.com/tml-tuebingen/nshap",
    "volume": "main",
    "checked": true,
    "id": "17f9480c4b0495334a4f3b0d6332c3e7f58b76ae",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v206/kuzmanovic23a.html": {
    "title": "Estimating Conditional Average Treatment Effects with Missing Treatment Information",
    "abstract": "Estimating conditional average treatment effects (CATE) is challenging, especially when treatment information is missing. Although this is a widespread problem in practice, CATE estimation with missing treatments has received little attention. In this paper, we analyze CATE estimation in the setting with missing treatments where unique challenges arise in the form of covariate shifts. We identify two covariate shifts in our setting: (i) a covariate shift between the treated and control population; and (ii) a covariate shift between the observed and missing treatment population. We first theoretically show the effect of these covariate shifts by deriving a generalization bound for estimating CATE in our setting with missing treatments. Then, motivated by our bound, we develop the missing treatment representation network (MTRNet), a novel CATE estimation algorithm that learns a balanced representation of covariates using domain adaptation. By using balanced representations, MTRNet provides more reliable CATE estimates in the covariate domains where the data are not fully observed. In various experiments with semi-synthetic and real-world data, we show that our algorithm improves over the state-of-the-art by a substantial margin",
    "volume": "main",
    "checked": true,
    "id": "ebd6491c702866ce55887cacd5dd57bb78b2e079",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/ling23a.html": {
    "title": "Global Convergence of Over-parameterized Deep Equilibrium Models",
    "abstract": "A deep equilibrium model (DEQ) is implicitly defined through an equilibrium point of an infinite-depth weight-tied model with an input-injection. Instead of infinite computations, it solves an equilibrium point directly with root-finding and computes gradients with implicit differentiation. In this paper, the training dynamics of over-parameterized DEQs are investigated, and we propose a novel probabilistic framework to overcome the challenge arising from the weight-sharing and the infinite depth. By supposing a condition on the initial equilibrium point, we prove that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. We further perform a fine-grained non-asymptotic analysis about random DEQs and the corresponding weight-untied models, and show that the required initial condition is satisfied via mild over-parameterization. Moreover, we show that the unique equilibrium point always exists during the training",
    "volume": "main",
    "checked": true,
    "id": "3f9eb5f9988481c4b44bdfdae1af0d99cb7ae54c",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/xu23b.html": {
    "title": "A Tale of Two Efficient Value Iteration Algorithms for Solving Linear MDPs with Large Action Space",
    "abstract": "Markov Decision Process (MDP) with large action space naturally occurs in many applications such as language processing, information retrieval, and recommendation system. There have been various approaches to solve these MDPs through value iteration (VI). Unfortunately, all VI algorithms require expensive linear scans over the entire action space for value function estimation during each iteration. To this end, we present two provable Least-Squares Value Iteration (LSVI) algorithms with runtime complexity sublinear in the number of actions for linear MDPs. We formulate the value function estimation procedure in VI as an approximate maximum inner product search problem and propose a Locality Sensitive Hashing (LSH) type data structure to solve this problem with sublinear time complexity. Our major contribution is combining the guarantees of approximate maximum inner product search with the regret analysis of reinforcement learning. We prove that, with the appropriate choice of approximation factor, there exists a sweet spot. Our proposed Sublinear LSVI algorithms maintain the same regret as the original LSVI algorithms while reducing the runtime complexity to sublinear in the number of actions. To the best of our knowledge, this is the first work that combines LSH with reinforcement learning that results in provable improvements. We hope that our novel way of combining data structures and the iterative algorithm will open the door for further study into the cost reduction in reinforcement learning",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/chauhan23a.html": {
    "title": "Adversarial De-confounding in Individualised Treatment Effects Estimation",
    "abstract": "Observational studies have recently received significant attention from the machine learning community due to the increasingly available non-experimental observational data and the limitations of the experimental studies, such as considerable cost, impracticality, small and less representative sample sizes, etc. In observational studies, de-confounding is a fundamental problem of individualised treatment effects (ITE) estimation. This paper proposes disentangled representations with adversarial training to selectively balance the confounders in the binary treatment setting for the ITE estimation. The adversarial training of treatment policy selectively encourages treatment-agnostic balanced representations for the confounders and helps to estimate the ITE in the observational studies via counterfactual inference. Empirical results on synthetic and real-world datasets, with varying degrees of confounding, prove that our proposed approach improves the state-of-the-art methods in achieving lower error in the ITE estimation",
    "volume": "main",
    "checked": true,
    "id": "4636b77bb74e02363d12278fbebe03fa669fb8a2",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/hess23a.html": {
    "title": "Fast Distributed k-Means with a Small Number of Rounds",
    "abstract": "We propose a new algorithm for k-means clustering in a distributed setting, where the data is distributed across many machines, and a coordinator communicates with these machines to calculate the output clustering. Our algorithm guarantees a cost approximation factor and a number of communication rounds that depend only on the computational capacity of the coordinator. Moreover, the algorithm includes a built-in stopping mechanism, which allows it to use fewer communication rounds whenever possible. We show both theoretically and empirically that in many natural cases, indeed 1-4 rounds suffice. In comparison with the popular k-means$||$ algorithm, our approach allows exploiting a larger coordinator capacity to obtain a smaller number of rounds. Our experiments show that the k-means cost obtained by the proposed algorithm is usually better than the cost obtained by k-means$||$, even when the latter is allowed a larger number of rounds. Moreover, the machine running time in our approach is considerably smaller than that of k-means$||$",
    "volume": "main",
    "checked": true,
    "id": "1239378eeab1ac9da0fa736429e1b31cc0d2dab0",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/sun23a.html": {
    "title": "A New Causal Decomposition Paradigm towards Health Equity",
    "abstract": "Causal decomposition has provided a powerful tool to analyze health disparity problems by assessing the proportion of disparity caused by each mediator (the variable that mediates the effect of the exposure on the health outcome). However, most of these methods lack policy implications, as they fail to account for all sources of disparities caused by the mediator. Besides, its identifiability needs to specify a set to be admissible to make the strong ignorability condition hold, which can be problematic as some variables in this set may induce new spurious features. To resolve these issues, under the framework of the structural causal model, we propose a new decomposition, dubbed as adjusted and unadjusted effects, which is able to include all types of disparity by adjusting each mediator’s distribution from the disadvantaged group to the advantaged ones. Besides, by learning the maximal ancestral graph and implementing causal discovery from heterogeneous data, we can identify the admissible set, followed by an efficient algorithm for estimation. The theoretical correctness and efficacy of our method are demonstrated using a synthetic dataset and a common spine disease dataset",
    "volume": "main",
    "checked": true,
    "id": "cc929d2a9ff6459ea564de6c9521244871adc555",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/minasyan23a.html": {
    "title": "Matching Map Recovery with an Unknown Number of Outliers",
    "abstract": "We consider the problem of finding the matching map between two sets of $d$-dimensional noisy feature-vectors. The distinctive feature of our setting is that we do not assume that all the vectors of the first set have their corresponding vector in the second set. If $n$ and $m$ are the sizes of these two sets, we assume that the matching map that should be recovered is defined on a subset of unknown cardinality $k^*\\le \\min(n,m)$. We show that, in the high-dimensional setting, if the signal-to-noise ratio is larger than $5(d\\log(4nm/\\alpha))^{1/4}$, then the true matching map can be recovered with probability $1-\\alpha$. Interestingly, this threshold does not depend on $k^*$ and is the same as the one obtained in prior work in the case of $k = \\min(n,m)$. The procedure for which the aforementioned property is proved is obtained by a data-driven selection among candidate mappings $\\{\\hat\\pi_k:k\\in[\\min(n,m)]\\}$. Each $\\hat\\pi_k$ minimizes the sum of squares of distances between two sets of size $k$. The resulting optimization problem can be formulated as a minimum-cost flow problem, and thus solved efficiently. Finally, we report the results of numerical experiments on both synthetic and real-world data that illustrate our theoretical results and provide further insight into the properties of the algorithms studied in this work",
    "volume": "main",
    "checked": true,
    "id": "853cad5447b95c73db24fd9c51e9e9b5f89b2ab8",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/kim23a.html": {
    "title": "Characterizing Internal Evasion Attacks in Federated Learning",
    "abstract": "Federated learning allows for clients in a distributed system to jointly train a machine learning model. However, clients’ models are vulnerable to attacks during the training and testing phases. In this paper, we address the issue of adversarial clients performing “internal evasion attacks”: crafting evasion attacks at test time to deceive other clients. For example, adversaries may aim to deceive spam filters and recommendation systems trained with federated learning for monetary gain. The adversarial clients have extensive information about the victim model in a federated learning setting, as weight information is shared amongst clients. We are the first to characterize the transferability of such internal evasion attacks for different learning methods and analyze the trade-off between model accuracy and robustness depending on the degree of similarities in client data. We show that adversarial training defenses in the federated learning setting only display limited improvements against internal attacks. However, combining adversarial training with personalized federated learning frameworks increases relative internal attack robustness by 60$%$ compared to federated adversarial training and performs well under limited system resources",
    "volume": "main",
    "checked": true,
    "id": "2cfc9875befb2c3e47c9846c301b5b954366dd2e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/nguyen23a.html": {
    "title": "Optimal and Private Learning from Human Response Data",
    "abstract": "Item response theory (IRT) is the study of how people make probabilistic decisions, with diverse applications in education testing, recommendation systems, among others. The Rasch model of binary response data, one of the most fundamental models in IRT, remains an active area of research with important practical significance. Recently, Nguyen and Zhang (2022) proposed a new spectral estimation algorithm that is efficient and accurate. In this work, we extend their results in two important ways. Firstly, we obtain a refined entrywise error bound for the spectral algorithm, complementing the ‘average error’ $\\ell_2$ bound in their work. Notably, under mild sampling conditions, the spectral algorithm achieves the minimax optimal entrywise error bound (modulo a log factor). Building on the refined analysis, we also show that the spectral algorithm enjoys optimal sample complexity for top-$K$ recovery (e.g., identifying the best $K$ items from approval/disapproval response data), explaining interesting empirical findings in the previous work. Our second contribution addresses an important but understudied topic in IRT: privacy. Despite the human-centric applications of IRT, there has not been any proposed privacy-preserving mechanism in the literature. We develop a private extension of the spectral algorithm, leveraging its unique Markov chain formulation and the discrete Gaussian mechanism (Canonne et al., 2020). Experiments show that our approach is significantly more accurate than the baselines in the low-to-moderate privacy regime",
    "volume": "main",
    "checked": true,
    "id": "99fdea96a2e814ed1946b6e884cc900cb5584de5",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/stanton23a.html": {
    "title": "Bayesian Optimization with Conformal Prediction Sets",
    "abstract": "Bayesian optimization is a coherent, ubiquitous approach to decision-making under uncertainty, with applications including multi-arm bandits, active learning, and black-box optimization. Bayesian optimization selects decisions (i.e. objective function queries) with maximal expected utility with respect to the posterior distribution of a Bayesian model, which quantifies reducible, epistemic uncertainty about query outcomes. In practice, subjectively implausible outcomes can occur regularly for two reasons: 1) model misspecification and 2) covariate shift. Conformal prediction is an uncertainty quantification method with coverage guarantees even for misspecified models and a simple mechanism to correct for covariate shift. We propose conformal Bayesian optimization, which directs queries towards regions of search space where the model predictions have guaranteed validity, and investigate its behavior on a suite of black-box optimization tasks and tabular ranking tasks. In many cases we find that query coverage can be significantly improved without harming sample-efficiency",
    "volume": "main",
    "checked": true,
    "id": "65e0789496deecda09ebe166c4d13523e9666178",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/xiao23a.html": {
    "title": "Alternating Projected SGD for Equality-constrained Bilevel Optimization",
    "abstract": "Bilevel optimization, which captures the inherent nested structure of machine learning problems, is gaining popularity in many recent applications. Existing works on bilevel optimization mostly consider either the unconstrained problems or the constrained upper-level problems. In this context, this paper considers the stochastic bilevel optimization problems with equality constraints in both upper and lower levels. By leveraging the special structure of the equality constraints problem, the paper first presents an alternating projected SGD approach to tackle this problem and establishes the $\\tilde{\\cal O}(\\epsilon^{-2})$ sample and iteration complexity that matches the state-of-the-art complexity of ALSET Chen et al. (2021) for stochastic unconstrained bilevel problems. To further save the cost of projection, the paper presents an alternating projected SGD approach with lazy projection and establishes the $\\tilde{\\cal O}(\\epsilon^{-2}/T)$ upper-level and $\\tilde{\\cal O}(\\epsilon^{-1.5}/T^{\\frac{3}{4}})$ lower-level projection complexity of this new algorithm, where $T$ is the upper-level projection interval. Application to federated bilevel optimization has been presented to showcase the performance of our algorithms. Our results demonstrate that equality-constrained bilevel optimization with strongly-convex lower-level problems can be solved as efficiently as stochastic single-level optimization problems",
    "volume": "main",
    "checked": false,
    "id": "e39ad5120ed5eaa88f8bf6e8c69b17fd1a3e9369",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/sabato23a.html": {
    "title": "Improved Robust Algorithms for Learning with Discriminative Feature Feedback",
    "abstract": "Discriminative Feature Feedback is a setting first introduced by Dasgupta et al. (2018), which provides a protocol for interactive learning based on feature explanations that are provided by a human teacher. The features distinguish between the labels of pairs of possibly similar instances. That work has shown that learning in this model can have considerable statistical and computational advantages over learning in standard label-based interactive learning models. In this work, we provide new robust interactive learning algorithms for the Discriminative Feature Feedback model, with mistake bounds that are significantly lower than those of previous robust algorithms for this setting. In the adversarial setting, we reduce the dependence on the number of protocol exceptions from quadratic to linear. In addition, we provide an algorithm for a slightly more restricted model, which obtains an even smaller mistake bound for large models with many exceptions. In the stochastic setting, we provide the first algorithm that converges to the exception rate with a polynomial sample complexity. Our algorithm and analysis for the stochastic setting involve a new construction that we call Feature Influence, which may be of wider applicability",
    "volume": "main",
    "checked": true,
    "id": "bf6fe35ccb068019059fa8b1215d7c12df5a381e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/nikolentzos23a.html": {
    "title": "Weisfeiler and Leman go Hyperbolic: Learning Distance Preserving Node Representations",
    "abstract": "In recent years, graph neural networks (GNNs) have emerged as a promising tool for solving machine learning problems on graphs. Most GNNs are members of the family of message passing neural networks (MPNNs). There is a close connection between these models and the Weisfeiler-Leman (WL) test of isomorphism, an algorithm that can successfully test isomorphism for a broad class of graphs. Recently, much research has focused on measuring the expressive power of GNNs. For instance, it has been shown that standard MPNNs are at most as powerful as WL in terms of distinguishing non-isomorphic graphs. However, these studies have largely ignored the distances between the representations of the nodes/graphs which are of paramount importance for learning tasks. In this paper, we define a distance function between nodes which is based on the hierarchy produced by the WL algorithm, and propose a model that learns representations which preserve those distances between nodes. Since the emerging hierarchy corresponds to a tree, to learn these representations, we capitalize on recent advances in the field of hyperbolic neural networks. We empirically evaluate the proposed model on standard graph and node classification datasets where it achieves competitive performance with state-of-the-art models",
    "volume": "main",
    "checked": true,
    "id": "da455a09781e8ce9b4db5ce6f2fc83af775c843d",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/grudzien23a.html": {
    "title": "Can 5th Generation Local Training Methods Support Client Sampling? Yes!",
    "abstract": "The celebrated FedAvg algorithm of McMahan et al. (2017) is based on three components: client sampling (CS), data sampling (DS) and local training (LT). While the first two are reasonably well understood, the third component, whose role is to reduce the number of communication rounds needed to train the model, resisted all attempts at a satisfactory theoretical explanation. Malinovsky et al. (2022) identified four distinct generations of LT methods based on the quality of the provided theoretical communication complexity guarantees. Despite a lot of progress in this area, none of the existing works were able to show that it is theoretically better to employ multiple local gradient-type steps (i.e., to engage in LT) than to rely on a single local gradient-type step only in the important heterogeneous data regime. In a recent breakthrough embodied in their ProxSkip method and its theoretical analysis, Mishchenko et al. (2022) showed that LT indeed leads to provable communication acceleration for arbitrarily heterogeneous data, thus jump-starting the 5th generation of LT methods. However, while these latest generation LT methods are compatible with DS, none of them support CS. We resolve this open problem in the affirmative. In order to do so, we had to base our algorithmic development on new algorithmic and theoretical foundations",
    "volume": "main",
    "checked": false,
    "id": "4d86e6724f969769517c8f64589eb28d463118ae",
    "citation_count": 6
  },
  "https://proceedings.mlr.press/v206/astudillo23a.html": {
    "title": "qEUBO: A Decision-Theoretic Acquisition Function for Preferential Bayesian Optimization",
    "abstract": "Preferential Bayesian optimization (PBO) is a framework for optimizing a decision maker’s latent utility function using preference feedback. This work introduces the expected utility of the best option (qEUBO) as a novel acquisition function for PBO. When the decision maker’s responses are noise-free, we show that qEUBO is one-step Bayes optimal and thus equivalent to the popular knowledge gradient acquisition function. We also show that qEUBO enjoys an additive constant approximation guarantee to the one-step Bayes-optimal policy when the decision maker’s responses are corrupted by noise. We provide an extensive evaluation of qEUBO and demonstrate that it outperforms the state-of-the-art acquisition functions for PBO across many settings. Finally, we show that, under sufficient regularity conditions, qEUBO’s Bayesian simple regret converges to zero at a rate $o(1/n)$ as the number of queries, $n$, goes to infinity. In contrast, we show that simple regret under qEI, a popular acquisition function for standard BO often used for PBO, can fail to converge to zero. Enjoying superior performance, simple computation, and a grounded decision-theoretic justification, qEUBO is a promising acquisition function for PBO",
    "volume": "main",
    "checked": true,
    "id": "70009bd42c858e058b85b38823b68fd3e25b6204",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/raman23a.html": {
    "title": "Bayesian Hierarchical Models for Counterfactual Estimation",
    "abstract": "Counterfactual explanations utilize feature perturbations to analyze the outcome of an original decision and recommend an actionable recourse. We argue that it is beneficial to provide several alternative explanations rather than a single point solution and propose a probabilistic paradigm to estimate a diverse set of counterfactuals. Specifically, we treat the perturbations as random variables endowed with prior distribution functions. This allows sampling multiple counterfactuals from the posterior density, with the added benefit of incorporating inductive biases, preserving domain specific constraints and quantifying uncertainty in estimates. More importantly, we leverage Bayesian hierarchical modeling to share information across different subgroups of a population, which can both improve robustness and measure fairness. A gradient based sampler with superior convergence characteristics efficiently computes the posterior samples. Experiments across several datasets demonstrate that the counterfactuals estimated using our approach are valid, sparse, diverse and feasible",
    "volume": "main",
    "checked": true,
    "id": "61fe60a1d1968914958e9d01be0f67593601c5c0",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/zhang23b.html": {
    "title": "Sequential Gradient Descent and Quasi-Newton's Method for Change-Point Analysis",
    "abstract": "One common approach to detecting change-points is minimizing a cost function over possible numbers and locations of change-points. The framework includes several well-established procedures, such as the penalized likelihood and minimum description length. Such an approach requires finding the cost value repeatedly over different segments of the data set, which can be time-consuming when (i) the data sequence is long and (ii) obtaining the cost value involves solving a non-trivial optimization problem. This paper introduces a new sequential updating method (SE) to find the cost value effectively. The core idea is to update the cost value using the information from previous steps without re-optimizing the objective function. The new method is applied to change-point detection in generalized linear models and penalized regression. Numerical studies show that the new approach can be orders of magnitude faster than the Pruned Exact Linear Time (PELT) method without sacrificing estimation accuracy",
    "volume": "main",
    "checked": true,
    "id": "1dc027ca5c59dc14e7d9e40fda6611bfe2e5c2d0",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/wan23a.html": {
    "title": "Towards Scalable and Robust Structured Bandits: A Meta-Learning Framework",
    "abstract": "Online learning in large-scale structured bandits is known to be challenging due to the curse of dimensionality. In this paper, we propose a unified meta-learning framework for a wide class of structured bandit problems where the parameter space can be factorized to item-level, which covers many popular tasks. Compared with existing approaches, the proposed solution is both scalable to large systems and robust by utilizing a more flexible model. At the core of this framework is a Bayesian hierarchical model that allows information sharing among items via their features, upon which we design a meta Thompson sampling algorithm. Three representative examples are discussed thoroughly. Theoretical analysis and extensive numerical results both support the usefulness of the proposed method",
    "volume": "main",
    "checked": true,
    "id": "cb8088b4c65270e45a7ccdd949094977bb41115d",
    "citation_count": 5
  },
  "https://proceedings.mlr.press/v206/domingo-enrich23a.html": {
    "title": "Compress Then Test: Powerful Kernel Testing in Near-linear Time",
    "abstract": "Kernel two-sample testing provides a powerful framework for distinguishing any pair of distributions based on n sample points. However, existing kernel tests either run in $n^2$ time or sacrifice undue power to improve runtime. To address these shortcomings, we introduce Compress Then Test (CTT), a new framework for high-powered kernel testing based on sample compression. CTT cheaply approximates an expensive test by compressing each n point sample into a small but provably high-fidelity coreset. For standard kernels and subexponential distributions, CTT inherits the statistical behavior of a quadratic-time test—recovering the same optimal detection boundary—while running in near-linear time. We couple these advances with cheaper permutation testing, justified by new power analyses; improved time-vs.-quality guarantees for low-rank approximation; and a fast aggregation procedure for identifying especially discriminating kernels. In our experiments with real and simulated data, CTT and its extensions provide 20–200x speed-ups over state-of-the-art approximate MMD tests with no loss of power",
    "volume": "main",
    "checked": true,
    "id": "675927d8fd2fd3ab6471f11fd6b60c3e0cb4ae63",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/cheng23a.html": {
    "title": "Select and Optimize: Learning to solve large-scale TSP instances",
    "abstract": "Learning-based algorithms to solve TSP are getting popular in recent years, but most existing works cannot solve very large-scale TSP instances within a limited time. To solve this problem, this paper introduces a creative and distinctive method to select and locally optimize sub-parts of a solution. Concretely, we design a novel framework to generalize a small-scale selector-and-optimizer network to large-scale TSP instances by iteratively selecting while optimizing one sub-problem. At each iteration, the running time of sub-problem sampling and selection is significantly reduced due to the full use of parallel computing. Our neural model is well-designed to exploit the characteristics of the sub-problems. Furthermore, we introduce a trick called destroy-and-repair to avoid the local minimum of the iterative algorithm from a global perspective. Extensive experiments show that our method accelerates state-of-the-art learning-based algorithms more than 2x while achieving better solution quality on large-scale TSP instances ranging in size from 200 to 20,000",
    "volume": "main",
    "checked": false,
    "id": "bafdcfffc40d4da1c24108ef3f4f40a539336d61",
    "citation_count": 28
  },
  "https://proceedings.mlr.press/v206/allouah23a.html": {
    "title": "Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity",
    "abstract": "Byzantine machine learning (ML) aims to ensure the resilience of distributed learning algorithms to misbehaving (or Byzantine) machines. Although this problem received significant attention, prior works often assume the data held by the machines to be homogeneous, which is seldom true in practical settings. Data heterogeneity makes Byzantine ML considerably more challenging, since a Byzantine machine can hardly be distinguished from a non-Byzantine outlier. A few solutions have been proposed to tackle this issue, but these provide suboptimal probabilistic guarantees and fare poorly in practice. This paper closes the theoretical gap, achieving optimality and inducing good empirical results. In fact, we show how to automatically adapt existing solutions for (homogeneous) Byzantine ML to the heterogeneous setting through a powerful mechanism, we call nearest neighbor mixing (NNM), which boosts any standard robust distributed gradient descent variant to yield optimal Byzantine resilience under heterogeneity. We obtain similar guarantees (in expectation) by plugging NNM in the distributed stochastic heavy ball method, a practical substitute to distributed gradient descent. We obtain empirical results that significantly outperform state-of-the-art Byzantine ML solutions",
    "volume": "main",
    "checked": true,
    "id": "9df3c8d3011376190bba5fb5593282e3cd1d092b",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v206/banerjee23a.html": {
    "title": "Testing of Horn Samplers",
    "abstract": "Sampling over combinatorial spaces is a fundamental problem in artificial intelligence with a wide variety of applications. Since state-of-the-art techniques heavily rely on heuristics whose rigorous analysis remains beyond the reach of current theoretical tools, the past few years have witnessed interest in the design of techniques to test the quality of samplers. The current state-of-the-art techniques, $\\mathsf{Barbarik}$ and $\\mathsf{Barbarik2}$, focuses on the cases where combinatorial spaces are encoded as Conjunctive Normal Form (CNF) formulas. While CNF is a general-purpose form, often techniques rely on exploiting specific representations to achieve speedup. Of particular interest are Horn clauses, which form the basis of the logic programming tools in AI. In this context, a natural question is whether it is possible to design a tester that can determine the correctness of a given Horn sampler. The primary contribution of this paper is an affirmative answer to the above question. We design the first tester, $\\mathsf{Flash}$, which tests the correctness of a given Horn sampler: given a specific distribution $\\mathcal{I}$ and parameters $\\eta$, $\\varepsilon$, and $\\delta$, the tester $\\mathsf{Flash}$ correctly (with probability at least $ 1-\\delta$) distinguishes whether the underlying distribution of the Horn-sampler is “$\\varepsilon$-close” to $\\mathcal{I}$ or “$\\eta$-far” from $\\mathcal{I}$ by sampling only $\\widetilde{\\mathcal{O}}(\\mathsf{tilt}^3/(\\eta - \\varepsilon)^4)$ samples from the Horn-sampler, where the $\\mathsf{tilt}$ is the ratio of the maximum and the minimum (non-zero) probability masses of $\\mathcal{I}$. We also provide a prototype implementation of $\\mathsf{Flash}$ and test three state-of-the-art samplers on a set of benchmarks",
    "volume": "main",
    "checked": false,
    "id": "8612d7d2f76e54184fa0171adb244aa70e2471b7",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v206/su23a.html": {
    "title": "Coordinate Ascent for Off-Policy RL with Global Convergence Guarantees",
    "abstract": "We revisit the domain of off-policy policy optimization in RL from the perspective of coordinate ascent. One commonly-used approach is to leverage the off-policy policy gradient to optimize a surrogate objective – the total discounted in expectation return of the target policy with respect to the state distribution of the behavior policy. However, this approach has been shown to suffer from the distribution mismatch issue, and therefore significant efforts are needed for correcting this mismatch either via state distribution correction or a counterfactual method. In this paper, we rethink off-policy learning via Coordinate Ascent Policy Optimization (CAPO), an off-policy actor-critic algorithm that decouples policy improvement from the state distribution of the behavior policy without using the policy gradient. This design obviates the need for distribution correction or importance sampling in the policy improvement step of off-policy policy gradient. We establish the global convergence of CAPO with general coordinate selection and then further quantify the convergence rates of several instances of CAPO with popular coordinate selection rules, including the cyclic and the randomized variants of CAPO. We then extend CAPO to neural policies for a more practical implementation. Through experiments, we demonstrate that CAPO provides a competitive approach to RL in practice",
    "volume": "main",
    "checked": true,
    "id": "7486833777655e79dbb1f255eee203900c720462",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/klemmer23a.html": {
    "title": "Positional Encoder Graph Neural Networks for Geographic Data",
    "abstract": "Graph neural networks (GNNs) provide a powerful and scalable solution for modeling continuous spatial data. However, they often rely on Euclidean distances to construct the input graphs. This assumption can be improbable in many real-world settings, where the spatial structure is more complex and explicitly non-Euclidean (e.g., road networks). Here, we propose PE-GNN, a new framework that incorporates spatial context and correlation explicitly into the models. Building on recent advances in geospatial auxiliary task learning and semantic spatial embeddings, our proposed method (1) learns a context-aware vector encoding of the geographic coordinates and (2) predicts spatial autocorrelation in the data in parallel with the main task. On spatial interpolation and regression tasks, we show the effectiveness of our approach, improving performance over different state-of-the-art GNN approaches. We observe that our approach not only vastly improves over the GNN baselines, but can match Gaussian processes, the most commonly utilized method for spatial interpolation problems",
    "volume": "main",
    "checked": true,
    "id": "8dfa164025d0a0e1e801d149aa4fbf4fd5bdee5a",
    "citation_count": 5
  },
  "https://proceedings.mlr.press/v206/gottesman23a.html": {
    "title": "Coarse-Grained Smoothness for Reinforcement Learning in Metric Spaces",
    "abstract": "Principled decision-making in continuous state–action spaces is impossible without some assumptions. A common approach is to assume Lipschitz continuity of the Q-function. We show that, unfortunately, this property fails to hold in many typical domains. We propose a new coarse-grained smoothness definition that generalizes the notion of Lipschitz continuity, is more widely applicable, and allows us to compute significantly tighter bounds on Q-functions, leading to improved learning. We provide a theoretical analysis of our new smoothness definition, and discuss its implications and impact on control and exploration in continuous domains",
    "volume": "main",
    "checked": true,
    "id": "dff6c3efd37f02096041b55691bfce6ee411e4df",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/chen23a.html": {
    "title": "Statistical Analysis of Karcher Means for Random Restricted PSD Matrices",
    "abstract": "Non-asymptotic statistical analysis is often missing for modern geometry-aware machine learning algorithms due to the possibly intricate non-linear manifold structure. This paper studies an intrinsic mean model on the manifold of restricted positive semi-definite matrices and provides a non-asymptotic statistical analysis of the Karcher mean. We also consider a general extrinsic signal-plus-noise model, under which a deterministic error bound of the Karcher mean is provided. As an application, we show that the distributed principal component analysis algorithm, LRC-dPCA, achieves the same performance as the full sample PCA algorithm. Numerical experiments lend strong support to our theories",
    "volume": "main",
    "checked": true,
    "id": "4a26b8a2ef9b95acfc4c9db25d169d014f320357",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v206/rho23a.html": {
    "title": "Differentially Private Synthetic Control",
    "abstract": "Synthetic control is a causal inference tool used to estimate the treatment effects of an intervention by creating synthetic counterfactual data. This approach combines measurements from other similar observations (i.e., donor pool) to predict a counterfactual time series of interest (i.e., target unit) by analyzing the relationship between the target and the donor pool before the intervention. As synthetic control tools are increasingly applied to sensitive or proprietary data, formal privacy protections are often required. In this work, we suggest the first algorithms for differentially private synthetic control with explicit error bounds based on the analysis of the sensitivity of the synthetic control query. Our approach builds upon tools from non-private synthetic control and differentially private empirical risk minimization. We empirically evaluate the performance of our algorithms and show favorable results in a variety of parameter regimes",
    "volume": "main",
    "checked": true,
    "id": "16523286a62bc0daa0552ebf04f3cd50bea2d455",
    "citation_count": 0
  }
}